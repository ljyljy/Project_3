{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# merge all the weather data\n",
    "weather_2016 = glob.glob('./output/*2016.csv')\n",
    "weather_2016.remove('./output/weather_initial_2016.csv')\n",
    "weather_2017 = glob.glob('./output/*2017.csv')\n",
    "weather_2017.remove('./output/weather_initial_2017.csv')\n",
    "df_weather_2016 = pd.read_csv('./output/low_hour_2016.csv')\n",
    "weather_2016.remove('./output/low_hour_2016.csv')\n",
    "for i in weather_2016:\n",
    "    df_weather_2016 = df_weather_2016.merge(pd.read_csv(i), on = 'regionidcity_fill', how = 'left')\n",
    "df_weather_2017 = pd.read_csv('./output/low_hour_2017.csv')\n",
    "weather_2017.remove('./output/low_hour_2017.csv')\n",
    "for i in weather_2017:\n",
    "    df_weather_2017 = df_weather_2017.merge(pd.read_csv(i), on = 'regionidcity_fill', how = 'left')\n",
    "df_weather_2016 = df_weather_2016.fillna(0)\n",
    "df_weather_2017 = df_weather_2017.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (32,34,48,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read train csv\n",
    "df_train_2016 = pd.read_csv('./Resources/train_2016_v2.csv')\n",
    "df_train_2017 = pd.read_csv('./Resources/train_2017.csv')\n",
    "df_prop_2016 = pd.read_csv('./output/prop_2016_refilled.csv')\n",
    "df_prop_2017 = pd.read_csv('./output/prop_2017_refilled.csv')\n",
    "df_merge_2016 = pd.merge(df_train_2016, df_prop_2016, how = 'left', on = 'parcelid')\n",
    "df_merge_2017 = pd.merge(df_train_2017, df_prop_2017, how = 'left', on = 'parcelid')\n",
    "df_merge_no_2017 = df_merge_2017.loc[df_merge_2017['latitude'].isna(),['parcelid', 'logerror', 'transactiondate']]\n",
    "df_merge_no_2017 = df_merge_no_2017.merge(df_prop_2016, how = 'left', on = 'parcelid')\n",
    "df_merge_2017 = pd.concat([df_merge_2017.loc[df_merge_2017['latitude'].notna(),:], df_merge_no_2017], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_2016 = pd.merge(df_merge_2016, df_weather_2016, how = 'left', on = 'regionidcity_fill')\n",
    "df_merge_2017 = pd.merge(df_merge_2017, df_weather_2017, how = 'left', on = 'regionidcity_fill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def zoningcode2int( df, target ):\n",
    "    storenull = df[ target ].isnull()\n",
    "    enc = LabelEncoder( )\n",
    "    df[ target ] = df[ target ].astype( str )\n",
    "\n",
    "    print('fit and transform')\n",
    "    df[ target ]= enc.fit_transform( df[ target ].values )\n",
    "    print( 'num of categories: ', enc.classes_.shape  )\n",
    "    df.loc[ storenull, target ] = np.nan\n",
    "    print('recover the nan value')\n",
    "    return enc\n",
    "\n",
    "def fillna_knn( df, base, target, fraction = 0.1, threshold = 10, n_neighbors = 5 ):\n",
    "    assert isinstance( base , list ) or isinstance( base , np.ndarray ) and isinstance( target, str ) \n",
    "    whole = [ target ] + base\n",
    "    \n",
    "    miss = df[target].isnull()\n",
    "    notmiss = ~miss \n",
    "    nummiss = miss.sum()\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    X_target = df.loc[ notmiss, whole ].sample( frac = fraction )\n",
    "    \n",
    "    enc.fit( X_target[ target ].unique().reshape( (-1,1) ) )\n",
    "    \n",
    "    Y = enc.transform( X_target[ target ].values.reshape((-1,1)) ).toarray()\n",
    "    X = X_target[ base  ]\n",
    "    \n",
    "    print( 'fitting' )\n",
    "    n_neighbors = n_neighbors\n",
    "    clf = neighbors.KNeighborsClassifier( n_neighbors, weights = 'uniform' )\n",
    "    clf.fit( X, Y )\n",
    "    \n",
    "    print( 'the shape of active features: ' ,enc.active_features_.shape )\n",
    "    \n",
    "    print( 'predicting' )\n",
    "    Z = clf.predict(df.loc[miss, base])\n",
    "    \n",
    "    numunperdicted = Z[:,0].sum()\n",
    "    if numunperdicted / nummiss *100 < threshold :\n",
    "        print( 'writing result to df' )    \n",
    "        df.loc[ miss, target ]  = np.dot( Z , enc.active_features_ )\n",
    "        print( 'num of unperdictable data: ', numunperdicted )\n",
    "        return enc\n",
    "    else:\n",
    "        print( 'out of threshold: {}% > {}%'.format( numunperdicted / nummiss *100 , threshold ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting\n",
      "the shape of active features:  (7111,)\n",
      "predicting\n",
      "writing result to df\n",
      "num of unperdictable data:  0.0\n",
      "fitting\n",
      "the shape of active features:  (6479,)\n",
      "predicting\n",
      "writing result to df\n",
      "num of unperdictable data:  0.0\n",
      "fit and transform\n",
      "num of categories:  (1997,)\n",
      "recover the nan value\n",
      "fitting\n",
      "the shape of active features:  (1071,)\n",
      "predicting\n",
      "writing result to df\n",
      "num of unperdictable data:  0.0\n",
      "fit and transform\n",
      "num of categories:  (1908,)\n",
      "recover the nan value\n",
      "fitting\n",
      "the shape of active features:  (985,)\n",
      "predicting\n",
      "writing result to df\n",
      "num of unperdictable data:  0.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df_merge_no_2017 = df_merge_2017.loc[df_merge_2017['latitude'].isna(),:]\n",
    "df_merge_2017 = df_merge_2017.loc[df_merge_2017['latitude'].notna(),:]\n",
    "fillna_knn(df = df_merge_2016, base = ['latitude', 'longitude'], target = 'lotsizesquarefeet', fraction = 0.15)\n",
    "fillna_knn(df = df_merge_2017, base = ['latitude', 'longitude'], target = 'lotsizesquarefeet', fraction = 0.15)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "zoningcode2int(df = df_merge_2016, target = 'propertyzoningdesc')\n",
    "fillna_knn(df = df_merge_2016, base = ['latitude', 'longitude'], target = 'propertyzoningdesc', fraction = 0.15)\n",
    "zoningcode2int(df = df_merge_2017, target = 'propertyzoningdesc')\n",
    "fillna_knn(df = df_merge_2017, base = ['latitude', 'longitude'], target = 'propertyzoningdesc', fraction = 0.15)\n",
    "df_merge_2017 = pd.concat([df_merge_2017, df_merge_no_2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.concat([df_merge_2016, df_merge_2017]).reset_index()\n",
    "df_merge['transactiondate'] = pd.to_datetime(df_merge['transactiondate'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_merge['month'] = df_merge['transactiondate'].dt.month\n",
    "df_merge['year'] = df_merge['transactiondate'].dt.year\n",
    "df_merge.drop(['transactiondate', 'index', 'parcelid'], axis = 1, inplace = True)\n",
    "df_merge.taxdelinquencyflag = df_merge.taxdelinquencyflag.replace('Y', 1)\n",
    "df_merge.hashottuborspa = df_merge.hashottuborspa.replace('True', 1)\n",
    "df_merge.hashottuborspa = df_merge.hashottuborspa.replace('None', 0)\n",
    "df_merge.taxdelinquencyflag = df_merge.taxdelinquencyflag.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv('./output/init_merge.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_2016.to_csv('./output/init_2016.csv', index = False)\n",
    "df_merge_2017.to_csv('./output/init_2017.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
