{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 65.85 MB\n",
      "Memory usage after optimization is: 26.09 MB\n",
      "Decreased by 60.4%\n"
     ]
    }
   ],
   "source": [
    "df_merge = reduce_mem_usage(pd.read_csv('./output/final_merge.csv'))\n",
    "categorical_features = ['airconditioningtypeid', 'hashottuborspa', 'heatingorsystemtypeid', \n",
    "                       'pooltypeid2', 'propertylandusetypeid', 'fips', 'regionidcounty', \n",
    "                       'buildingqualitytypeid_fill', 'regionidcity_fill', 'year', \n",
    "                       'regionidneighborhood_fill', 'taxdelinquencyflag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def check_rmse(outlier_list):\n",
    "    score = 0\n",
    "    params = {\"objective\": \"regression\", \"boosting\": \"gbdt\", \"num_leaves\": 512, \n",
    "              \"learning_rate\": 0.0021, 'bagging_fraction': 0.85, \"reg_lambda\": 0.1, \n",
    "              'reg_alpha':0.1, \"metric\": \"rmse\", 'max_depth': -1, 'min_child_weight': 30,\n",
    "              'verbose': -1, 'min_split_gain':0.1, 'subsample_freq':1, 'sub_feature':  0.5}\n",
    "    kf = KFold(n_splits=3)\n",
    "    feature_list = list(df_merge.columns)\n",
    "    df = df_merge.loc[df_merge.logerror >= - (outlier_list[0]),:]\n",
    "    df = df.loc[df.logerror <= outlier_list[1],:].reset_index()\n",
    "    df = df[feature_list]\n",
    "    feature = df.drop(['logerror'], axis = 1)\n",
    "    target = df.logerror\n",
    "    for train_index,test_index in kf.split(feature):\n",
    "        train_features = feature.loc[train_index]\n",
    "        train_target = target.loc[train_index]\n",
    "\n",
    "        test_features = feature.loc[test_index]\n",
    "        test_target = target.loc[test_index]\n",
    "\n",
    "        d_training = lgb.Dataset(train_features, label=train_target,\n",
    "                                 categorical_feature=categorical_features, free_raw_data=False)\n",
    "        d_test = lgb.Dataset(test_features, label=test_target,\n",
    "                             categorical_feature=categorical_features, free_raw_data=False)\n",
    "\n",
    "        model = lgb.train(params, train_set=d_training, num_boost_round=3000, \n",
    "                          valid_sets=[d_training,d_test], verbose_eval=25, early_stopping_rounds=50)\n",
    "        y_pred_valid = model.predict(test_features)\n",
    "        score += np.sqrt(mean_squared_error(test_target, y_pred_valid)) / 3\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.164597\tvalid_1's rmse: 0.163109\n",
      "[50]\ttraining's rmse: 0.164029\tvalid_1's rmse: 0.163035\n",
      "[75]\ttraining's rmse: 0.163465\tvalid_1's rmse: 0.162965\n",
      "[100]\ttraining's rmse: 0.162933\tvalid_1's rmse: 0.162903\n",
      "[125]\ttraining's rmse: 0.162399\tvalid_1's rmse: 0.162843\n",
      "[150]\ttraining's rmse: 0.161902\tvalid_1's rmse: 0.162783\n",
      "[175]\ttraining's rmse: 0.161453\tvalid_1's rmse: 0.16274\n",
      "[200]\ttraining's rmse: 0.16098\tvalid_1's rmse: 0.162691\n",
      "[225]\ttraining's rmse: 0.160528\tvalid_1's rmse: 0.162655\n",
      "[250]\ttraining's rmse: 0.160117\tvalid_1's rmse: 0.162617\n",
      "[275]\ttraining's rmse: 0.15973\tvalid_1's rmse: 0.162588\n",
      "[300]\ttraining's rmse: 0.159345\tvalid_1's rmse: 0.162557\n",
      "[325]\ttraining's rmse: 0.158977\tvalid_1's rmse: 0.162529\n",
      "[350]\ttraining's rmse: 0.158621\tvalid_1's rmse: 0.16251\n",
      "[375]\ttraining's rmse: 0.158292\tvalid_1's rmse: 0.162492\n",
      "[400]\ttraining's rmse: 0.157934\tvalid_1's rmse: 0.162471\n",
      "[425]\ttraining's rmse: 0.157616\tvalid_1's rmse: 0.162449\n",
      "[450]\ttraining's rmse: 0.157309\tvalid_1's rmse: 0.162435\n",
      "[475]\ttraining's rmse: 0.157036\tvalid_1's rmse: 0.162416\n",
      "[500]\ttraining's rmse: 0.15677\tvalid_1's rmse: 0.162409\n",
      "[525]\ttraining's rmse: 0.156478\tvalid_1's rmse: 0.162393\n",
      "[550]\ttraining's rmse: 0.156209\tvalid_1's rmse: 0.162382\n",
      "[575]\ttraining's rmse: 0.155935\tvalid_1's rmse: 0.162375\n",
      "[600]\ttraining's rmse: 0.155681\tvalid_1's rmse: 0.162368\n",
      "[625]\ttraining's rmse: 0.155452\tvalid_1's rmse: 0.162362\n",
      "[650]\ttraining's rmse: 0.15521\tvalid_1's rmse: 0.162356\n",
      "[675]\ttraining's rmse: 0.154982\tvalid_1's rmse: 0.162348\n",
      "[700]\ttraining's rmse: 0.154777\tvalid_1's rmse: 0.162348\n",
      "[725]\ttraining's rmse: 0.154603\tvalid_1's rmse: 0.162342\n",
      "[750]\ttraining's rmse: 0.154421\tvalid_1's rmse: 0.162341\n",
      "[775]\ttraining's rmse: 0.154245\tvalid_1's rmse: 0.162334\n",
      "[800]\ttraining's rmse: 0.15406\tvalid_1's rmse: 0.162334\n",
      "[825]\ttraining's rmse: 0.153894\tvalid_1's rmse: 0.162328\n",
      "[850]\ttraining's rmse: 0.153728\tvalid_1's rmse: 0.162331\n",
      "Early stopping, best iteration is:\n",
      "[823]\ttraining's rmse: 0.153907\tvalid_1's rmse: 0.162327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.167706\tvalid_1's rmse: 0.156582\n",
      "[50]\ttraining's rmse: 0.167154\tvalid_1's rmse: 0.156498\n",
      "[75]\ttraining's rmse: 0.166601\tvalid_1's rmse: 0.156417\n",
      "[100]\ttraining's rmse: 0.166072\tvalid_1's rmse: 0.156352\n",
      "[125]\ttraining's rmse: 0.165526\tvalid_1's rmse: 0.156287\n",
      "[150]\ttraining's rmse: 0.165027\tvalid_1's rmse: 0.156231\n",
      "[175]\ttraining's rmse: 0.164565\tvalid_1's rmse: 0.15618\n",
      "[200]\ttraining's rmse: 0.164083\tvalid_1's rmse: 0.15614\n",
      "[225]\ttraining's rmse: 0.16361\tvalid_1's rmse: 0.156102\n",
      "[250]\ttraining's rmse: 0.163197\tvalid_1's rmse: 0.156071\n",
      "[275]\ttraining's rmse: 0.1628\tvalid_1's rmse: 0.156042\n",
      "[300]\ttraining's rmse: 0.162396\tvalid_1's rmse: 0.156013\n",
      "[325]\ttraining's rmse: 0.161995\tvalid_1's rmse: 0.155992\n",
      "[350]\ttraining's rmse: 0.161617\tvalid_1's rmse: 0.155974\n",
      "[375]\ttraining's rmse: 0.161275\tvalid_1's rmse: 0.155958\n",
      "[400]\ttraining's rmse: 0.160933\tvalid_1's rmse: 0.155945\n",
      "[425]\ttraining's rmse: 0.160611\tvalid_1's rmse: 0.155938\n",
      "[450]\ttraining's rmse: 0.160298\tvalid_1's rmse: 0.155929\n",
      "[475]\ttraining's rmse: 0.160002\tvalid_1's rmse: 0.155923\n",
      "[500]\ttraining's rmse: 0.15974\tvalid_1's rmse: 0.155912\n",
      "[525]\ttraining's rmse: 0.159435\tvalid_1's rmse: 0.155909\n",
      "[550]\ttraining's rmse: 0.159146\tvalid_1's rmse: 0.155906\n",
      "[575]\ttraining's rmse: 0.158882\tvalid_1's rmse: 0.155907\n",
      "[600]\ttraining's rmse: 0.15862\tvalid_1's rmse: 0.155906\n",
      "[625]\ttraining's rmse: 0.158385\tvalid_1's rmse: 0.155906\n",
      "[650]\ttraining's rmse: 0.158129\tvalid_1's rmse: 0.155908\n",
      "Early stopping, best iteration is:\n",
      "[612]\ttraining's rmse: 0.158502\tvalid_1's rmse: 0.155904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.159463\tvalid_1's rmse: 0.173348\n",
      "[50]\ttraining's rmse: 0.159069\tvalid_1's rmse: 0.173295\n",
      "[75]\ttraining's rmse: 0.158663\tvalid_1's rmse: 0.173244\n",
      "[100]\ttraining's rmse: 0.158273\tvalid_1's rmse: 0.173195\n",
      "[125]\ttraining's rmse: 0.157887\tvalid_1's rmse: 0.17315\n",
      "[150]\ttraining's rmse: 0.157521\tvalid_1's rmse: 0.173107\n",
      "[175]\ttraining's rmse: 0.157198\tvalid_1's rmse: 0.173076\n",
      "[200]\ttraining's rmse: 0.156853\tvalid_1's rmse: 0.173047\n",
      "[225]\ttraining's rmse: 0.156532\tvalid_1's rmse: 0.173017\n",
      "[250]\ttraining's rmse: 0.156226\tvalid_1's rmse: 0.17299\n",
      "[275]\ttraining's rmse: 0.155952\tvalid_1's rmse: 0.172969\n",
      "[300]\ttraining's rmse: 0.155668\tvalid_1's rmse: 0.172948\n",
      "[325]\ttraining's rmse: 0.155389\tvalid_1's rmse: 0.172928\n",
      "[350]\ttraining's rmse: 0.155123\tvalid_1's rmse: 0.172913\n",
      "[375]\ttraining's rmse: 0.154887\tvalid_1's rmse: 0.172899\n",
      "[400]\ttraining's rmse: 0.15464\tvalid_1's rmse: 0.172889\n",
      "[425]\ttraining's rmse: 0.154405\tvalid_1's rmse: 0.172877\n",
      "[450]\ttraining's rmse: 0.154187\tvalid_1's rmse: 0.172869\n",
      "[475]\ttraining's rmse: 0.153976\tvalid_1's rmse: 0.172864\n",
      "[500]\ttraining's rmse: 0.153788\tvalid_1's rmse: 0.172857\n",
      "[525]\ttraining's rmse: 0.153575\tvalid_1's rmse: 0.172851\n",
      "[550]\ttraining's rmse: 0.153375\tvalid_1's rmse: 0.172844\n",
      "[575]\ttraining's rmse: 0.153184\tvalid_1's rmse: 0.172842\n",
      "[600]\ttraining's rmse: 0.152995\tvalid_1's rmse: 0.17284\n",
      "[625]\ttraining's rmse: 0.152831\tvalid_1's rmse: 0.172838\n",
      "[650]\ttraining's rmse: 0.152657\tvalid_1's rmse: 0.172839\n",
      "[675]\ttraining's rmse: 0.152472\tvalid_1's rmse: 0.172841\n",
      "Early stopping, best iteration is:\n",
      "[631]\ttraining's rmse: 0.152793\tvalid_1's rmse: 0.172836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0743715\tvalid_1's rmse: 0.0764297\n",
      "[50]\ttraining's rmse: 0.0742675\tvalid_1's rmse: 0.0763861\n",
      "[75]\ttraining's rmse: 0.0741627\tvalid_1's rmse: 0.0763423\n",
      "[100]\ttraining's rmse: 0.0740673\tvalid_1's rmse: 0.0763038\n",
      "[125]\ttraining's rmse: 0.0739698\tvalid_1's rmse: 0.0762665\n",
      "[150]\ttraining's rmse: 0.0738794\tvalid_1's rmse: 0.0762311\n",
      "[175]\ttraining's rmse: 0.0738092\tvalid_1's rmse: 0.0762015\n",
      "[200]\ttraining's rmse: 0.0737294\tvalid_1's rmse: 0.0761724\n",
      "[225]\ttraining's rmse: 0.0736479\tvalid_1's rmse: 0.0761429\n",
      "[250]\ttraining's rmse: 0.0735828\tvalid_1's rmse: 0.0761149\n",
      "[275]\ttraining's rmse: 0.0735212\tvalid_1's rmse: 0.0760914\n",
      "[300]\ttraining's rmse: 0.0734612\tvalid_1's rmse: 0.0760698\n",
      "[325]\ttraining's rmse: 0.0734015\tvalid_1's rmse: 0.0760491\n",
      "[350]\ttraining's rmse: 0.0733429\tvalid_1's rmse: 0.0760289\n",
      "[375]\ttraining's rmse: 0.0732953\tvalid_1's rmse: 0.0760123\n",
      "[400]\ttraining's rmse: 0.0732405\tvalid_1's rmse: 0.0759959\n",
      "[425]\ttraining's rmse: 0.0731941\tvalid_1's rmse: 0.0759799\n",
      "[450]\ttraining's rmse: 0.073152\tvalid_1's rmse: 0.0759637\n",
      "[475]\ttraining's rmse: 0.0731148\tvalid_1's rmse: 0.0759497\n",
      "[500]\ttraining's rmse: 0.0730803\tvalid_1's rmse: 0.0759364\n",
      "[525]\ttraining's rmse: 0.0730374\tvalid_1's rmse: 0.0759241\n",
      "[550]\ttraining's rmse: 0.072999\tvalid_1's rmse: 0.0759115\n",
      "[575]\ttraining's rmse: 0.0729624\tvalid_1's rmse: 0.0759014\n",
      "[600]\ttraining's rmse: 0.0729272\tvalid_1's rmse: 0.0758917\n",
      "[625]\ttraining's rmse: 0.0729\tvalid_1's rmse: 0.0758833\n",
      "[650]\ttraining's rmse: 0.0728683\tvalid_1's rmse: 0.0758746\n",
      "[675]\ttraining's rmse: 0.072835\tvalid_1's rmse: 0.0758654\n",
      "[700]\ttraining's rmse: 0.072806\tvalid_1's rmse: 0.0758575\n",
      "[725]\ttraining's rmse: 0.0727795\tvalid_1's rmse: 0.0758489\n",
      "[750]\ttraining's rmse: 0.0727537\tvalid_1's rmse: 0.0758423\n",
      "[775]\ttraining's rmse: 0.0727338\tvalid_1's rmse: 0.0758346\n",
      "[800]\ttraining's rmse: 0.0727083\tvalid_1's rmse: 0.075828\n",
      "[825]\ttraining's rmse: 0.0726863\tvalid_1's rmse: 0.0758217\n",
      "[850]\ttraining's rmse: 0.0726607\tvalid_1's rmse: 0.0758162\n",
      "[875]\ttraining's rmse: 0.0726405\tvalid_1's rmse: 0.0758112\n",
      "[900]\ttraining's rmse: 0.0726183\tvalid_1's rmse: 0.0758056\n",
      "[925]\ttraining's rmse: 0.0725986\tvalid_1's rmse: 0.0758004\n",
      "[950]\ttraining's rmse: 0.0725796\tvalid_1's rmse: 0.0757952\n",
      "[975]\ttraining's rmse: 0.0725636\tvalid_1's rmse: 0.0757896\n",
      "[1000]\ttraining's rmse: 0.0725469\tvalid_1's rmse: 0.0757841\n",
      "[1025]\ttraining's rmse: 0.072529\tvalid_1's rmse: 0.0757802\n",
      "[1050]\ttraining's rmse: 0.0725144\tvalid_1's rmse: 0.075776\n",
      "[1075]\ttraining's rmse: 0.0724991\tvalid_1's rmse: 0.0757734\n",
      "[1100]\ttraining's rmse: 0.072487\tvalid_1's rmse: 0.0757698\n",
      "[1125]\ttraining's rmse: 0.0724744\tvalid_1's rmse: 0.0757647\n",
      "[1150]\ttraining's rmse: 0.0724608\tvalid_1's rmse: 0.075761\n",
      "[1175]\ttraining's rmse: 0.0724462\tvalid_1's rmse: 0.0757583\n",
      "[1200]\ttraining's rmse: 0.0724331\tvalid_1's rmse: 0.0757556\n",
      "[1225]\ttraining's rmse: 0.0724192\tvalid_1's rmse: 0.0757512\n",
      "[1250]\ttraining's rmse: 0.0724074\tvalid_1's rmse: 0.0757477\n",
      "[1275]\ttraining's rmse: 0.0723971\tvalid_1's rmse: 0.0757431\n",
      "[1300]\ttraining's rmse: 0.0723884\tvalid_1's rmse: 0.0757409\n",
      "[1325]\ttraining's rmse: 0.0723802\tvalid_1's rmse: 0.0757391\n",
      "[1350]\ttraining's rmse: 0.0723692\tvalid_1's rmse: 0.0757373\n",
      "[1375]\ttraining's rmse: 0.07236\tvalid_1's rmse: 0.0757355\n",
      "[1400]\ttraining's rmse: 0.0723525\tvalid_1's rmse: 0.0757321\n",
      "[1425]\ttraining's rmse: 0.0723396\tvalid_1's rmse: 0.0757298\n",
      "[1450]\ttraining's rmse: 0.0723326\tvalid_1's rmse: 0.0757278\n",
      "[1475]\ttraining's rmse: 0.0723243\tvalid_1's rmse: 0.0757254\n",
      "[1500]\ttraining's rmse: 0.0723181\tvalid_1's rmse: 0.0757234\n",
      "[1525]\ttraining's rmse: 0.0723131\tvalid_1's rmse: 0.0757214\n",
      "[1550]\ttraining's rmse: 0.0723061\tvalid_1's rmse: 0.075719\n",
      "[1575]\ttraining's rmse: 0.0722987\tvalid_1's rmse: 0.0757171\n",
      "[1600]\ttraining's rmse: 0.0722945\tvalid_1's rmse: 0.0757162\n",
      "[1625]\ttraining's rmse: 0.0722891\tvalid_1's rmse: 0.0757145\n",
      "[1650]\ttraining's rmse: 0.0722845\tvalid_1's rmse: 0.075713\n",
      "[1675]\ttraining's rmse: 0.0722805\tvalid_1's rmse: 0.0757112\n",
      "[1700]\ttraining's rmse: 0.0722774\tvalid_1's rmse: 0.0757098\n",
      "[1725]\ttraining's rmse: 0.0722731\tvalid_1's rmse: 0.0757095\n",
      "[1750]\ttraining's rmse: 0.0722691\tvalid_1's rmse: 0.0757078\n",
      "[1775]\ttraining's rmse: 0.0722655\tvalid_1's rmse: 0.0757075\n",
      "[1800]\ttraining's rmse: 0.072262\tvalid_1's rmse: 0.0757064\n",
      "[1825]\ttraining's rmse: 0.0722586\tvalid_1's rmse: 0.075705\n",
      "[1850]\ttraining's rmse: 0.0722546\tvalid_1's rmse: 0.0757026\n",
      "[1875]\ttraining's rmse: 0.0722514\tvalid_1's rmse: 0.0757016\n",
      "[1900]\ttraining's rmse: 0.0722471\tvalid_1's rmse: 0.0757007\n",
      "[1925]\ttraining's rmse: 0.0722436\tvalid_1's rmse: 0.0757004\n",
      "[1950]\ttraining's rmse: 0.072241\tvalid_1's rmse: 0.0756996\n",
      "[1975]\ttraining's rmse: 0.0722385\tvalid_1's rmse: 0.0756985\n",
      "[2000]\ttraining's rmse: 0.0722362\tvalid_1's rmse: 0.0756982\n",
      "[2025]\ttraining's rmse: 0.0722346\tvalid_1's rmse: 0.075697\n",
      "[2050]\ttraining's rmse: 0.0722317\tvalid_1's rmse: 0.0756958\n",
      "[2075]\ttraining's rmse: 0.0722295\tvalid_1's rmse: 0.0756947\n",
      "[2100]\ttraining's rmse: 0.0722275\tvalid_1's rmse: 0.075694\n",
      "[2125]\ttraining's rmse: 0.0722259\tvalid_1's rmse: 0.0756934\n",
      "[2150]\ttraining's rmse: 0.0722236\tvalid_1's rmse: 0.0756926\n",
      "[2175]\ttraining's rmse: 0.072222\tvalid_1's rmse: 0.0756924\n",
      "[2200]\ttraining's rmse: 0.0722189\tvalid_1's rmse: 0.0756914\n",
      "[2225]\ttraining's rmse: 0.0722169\tvalid_1's rmse: 0.0756903\n",
      "[2250]\ttraining's rmse: 0.0722136\tvalid_1's rmse: 0.0756895\n",
      "[2275]\ttraining's rmse: 0.0722114\tvalid_1's rmse: 0.0756887\n",
      "[2300]\ttraining's rmse: 0.0722099\tvalid_1's rmse: 0.0756884\n",
      "[2325]\ttraining's rmse: 0.0722078\tvalid_1's rmse: 0.0756879\n",
      "[2350]\ttraining's rmse: 0.0722058\tvalid_1's rmse: 0.0756878\n",
      "[2375]\ttraining's rmse: 0.0722032\tvalid_1's rmse: 0.0756878\n",
      "Early stopping, best iteration is:\n",
      "[2340]\ttraining's rmse: 0.0722069\tvalid_1's rmse: 0.0756877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.074623\tvalid_1's rmse: 0.0759488\n",
      "[50]\ttraining's rmse: 0.0745323\tvalid_1's rmse: 0.0759003\n",
      "[75]\ttraining's rmse: 0.0744399\tvalid_1's rmse: 0.0758531\n",
      "[100]\ttraining's rmse: 0.0743553\tvalid_1's rmse: 0.0758113\n",
      "[125]\ttraining's rmse: 0.0742668\tvalid_1's rmse: 0.0757685\n",
      "[150]\ttraining's rmse: 0.0741857\tvalid_1's rmse: 0.0757298\n",
      "[175]\ttraining's rmse: 0.0741195\tvalid_1's rmse: 0.0756971\n",
      "[200]\ttraining's rmse: 0.0740436\tvalid_1's rmse: 0.075663\n",
      "[225]\ttraining's rmse: 0.0739703\tvalid_1's rmse: 0.0756316\n",
      "[250]\ttraining's rmse: 0.0739102\tvalid_1's rmse: 0.0756035\n",
      "[275]\ttraining's rmse: 0.073854\tvalid_1's rmse: 0.0755771\n",
      "[300]\ttraining's rmse: 0.0737979\tvalid_1's rmse: 0.0755524\n",
      "[325]\ttraining's rmse: 0.0737403\tvalid_1's rmse: 0.0755277\n",
      "[350]\ttraining's rmse: 0.0736843\tvalid_1's rmse: 0.0755048\n",
      "[375]\ttraining's rmse: 0.0736391\tvalid_1's rmse: 0.0754851\n",
      "[400]\ttraining's rmse: 0.0735887\tvalid_1's rmse: 0.0754658\n",
      "[425]\ttraining's rmse: 0.0735455\tvalid_1's rmse: 0.0754473\n",
      "[450]\ttraining's rmse: 0.0735038\tvalid_1's rmse: 0.0754302\n",
      "[475]\ttraining's rmse: 0.0734663\tvalid_1's rmse: 0.0754142\n",
      "[500]\ttraining's rmse: 0.0734326\tvalid_1's rmse: 0.0753983\n",
      "[525]\ttraining's rmse: 0.0733899\tvalid_1's rmse: 0.0753836\n",
      "[550]\ttraining's rmse: 0.0733503\tvalid_1's rmse: 0.0753702\n",
      "[575]\ttraining's rmse: 0.0733151\tvalid_1's rmse: 0.0753574\n",
      "[600]\ttraining's rmse: 0.0732803\tvalid_1's rmse: 0.0753456\n",
      "[625]\ttraining's rmse: 0.0732525\tvalid_1's rmse: 0.0753345\n",
      "[650]\ttraining's rmse: 0.0732196\tvalid_1's rmse: 0.0753231\n",
      "[675]\ttraining's rmse: 0.0731843\tvalid_1's rmse: 0.0753124\n",
      "[700]\ttraining's rmse: 0.0731548\tvalid_1's rmse: 0.0753019\n",
      "[725]\ttraining's rmse: 0.0731276\tvalid_1's rmse: 0.0752934\n",
      "[750]\ttraining's rmse: 0.0731019\tvalid_1's rmse: 0.075285\n",
      "[775]\ttraining's rmse: 0.0730815\tvalid_1's rmse: 0.0752772\n",
      "[800]\ttraining's rmse: 0.0730544\tvalid_1's rmse: 0.0752694\n",
      "[825]\ttraining's rmse: 0.0730314\tvalid_1's rmse: 0.0752618\n",
      "[850]\ttraining's rmse: 0.0730078\tvalid_1's rmse: 0.0752552\n",
      "[875]\ttraining's rmse: 0.0729863\tvalid_1's rmse: 0.0752485\n",
      "[900]\ttraining's rmse: 0.0729643\tvalid_1's rmse: 0.0752421\n",
      "[925]\ttraining's rmse: 0.0729441\tvalid_1's rmse: 0.0752361\n",
      "[950]\ttraining's rmse: 0.0729243\tvalid_1's rmse: 0.0752304\n",
      "[975]\ttraining's rmse: 0.0729063\tvalid_1's rmse: 0.0752251\n",
      "[1000]\ttraining's rmse: 0.0728896\tvalid_1's rmse: 0.07522\n",
      "[1025]\ttraining's rmse: 0.0728698\tvalid_1's rmse: 0.0752151\n",
      "[1050]\ttraining's rmse: 0.0728535\tvalid_1's rmse: 0.0752104\n",
      "[1075]\ttraining's rmse: 0.0728391\tvalid_1's rmse: 0.0752068\n",
      "[1100]\ttraining's rmse: 0.0728248\tvalid_1's rmse: 0.0752026\n",
      "[1125]\ttraining's rmse: 0.0728099\tvalid_1's rmse: 0.075199\n",
      "[1150]\ttraining's rmse: 0.0727941\tvalid_1's rmse: 0.0751949\n",
      "[1175]\ttraining's rmse: 0.0727818\tvalid_1's rmse: 0.0751921\n",
      "[1200]\ttraining's rmse: 0.0727689\tvalid_1's rmse: 0.0751891\n",
      "[1225]\ttraining's rmse: 0.0727567\tvalid_1's rmse: 0.0751861\n",
      "[1250]\ttraining's rmse: 0.0727445\tvalid_1's rmse: 0.075183\n",
      "[1275]\ttraining's rmse: 0.0727302\tvalid_1's rmse: 0.0751809\n",
      "[1300]\ttraining's rmse: 0.0727196\tvalid_1's rmse: 0.0751784\n",
      "[1325]\ttraining's rmse: 0.0727086\tvalid_1's rmse: 0.0751763\n",
      "[1350]\ttraining's rmse: 0.0726983\tvalid_1's rmse: 0.0751739\n",
      "[1375]\ttraining's rmse: 0.0726869\tvalid_1's rmse: 0.0751724\n",
      "[1400]\ttraining's rmse: 0.0726783\tvalid_1's rmse: 0.0751702\n",
      "[1425]\ttraining's rmse: 0.0726688\tvalid_1's rmse: 0.0751686\n",
      "[1450]\ttraining's rmse: 0.0726609\tvalid_1's rmse: 0.0751671\n",
      "[1475]\ttraining's rmse: 0.072655\tvalid_1's rmse: 0.0751655\n",
      "[1500]\ttraining's rmse: 0.0726493\tvalid_1's rmse: 0.0751639\n",
      "[1525]\ttraining's rmse: 0.0726424\tvalid_1's rmse: 0.0751623\n",
      "[1550]\ttraining's rmse: 0.0726356\tvalid_1's rmse: 0.0751612\n",
      "[1575]\ttraining's rmse: 0.07263\tvalid_1's rmse: 0.0751596\n",
      "[1600]\ttraining's rmse: 0.072626\tvalid_1's rmse: 0.0751589\n",
      "[1625]\ttraining's rmse: 0.0726207\tvalid_1's rmse: 0.0751572\n",
      "[1650]\ttraining's rmse: 0.0726135\tvalid_1's rmse: 0.0751562\n",
      "[1675]\ttraining's rmse: 0.0726092\tvalid_1's rmse: 0.0751553\n",
      "[1700]\ttraining's rmse: 0.0726047\tvalid_1's rmse: 0.0751544\n",
      "[1725]\ttraining's rmse: 0.0726005\tvalid_1's rmse: 0.0751535\n",
      "[1750]\ttraining's rmse: 0.0725952\tvalid_1's rmse: 0.0751526\n",
      "[1775]\ttraining's rmse: 0.0725919\tvalid_1's rmse: 0.0751521\n",
      "[1800]\ttraining's rmse: 0.0725878\tvalid_1's rmse: 0.0751515\n",
      "[1825]\ttraining's rmse: 0.0725831\tvalid_1's rmse: 0.075151\n",
      "[1850]\ttraining's rmse: 0.0725794\tvalid_1's rmse: 0.0751501\n",
      "[1875]\ttraining's rmse: 0.0725758\tvalid_1's rmse: 0.0751496\n",
      "[1900]\ttraining's rmse: 0.0725725\tvalid_1's rmse: 0.0751494\n",
      "[1925]\ttraining's rmse: 0.0725695\tvalid_1's rmse: 0.075149\n",
      "[1950]\ttraining's rmse: 0.0725658\tvalid_1's rmse: 0.075148\n",
      "[1975]\ttraining's rmse: 0.0725632\tvalid_1's rmse: 0.0751474\n",
      "[2000]\ttraining's rmse: 0.0725606\tvalid_1's rmse: 0.0751472\n",
      "[2025]\ttraining's rmse: 0.0725574\tvalid_1's rmse: 0.0751466\n",
      "[2050]\ttraining's rmse: 0.0725547\tvalid_1's rmse: 0.0751463\n",
      "[2075]\ttraining's rmse: 0.0725525\tvalid_1's rmse: 0.075146\n",
      "[2100]\ttraining's rmse: 0.0725488\tvalid_1's rmse: 0.0751459\n",
      "[2125]\ttraining's rmse: 0.0725472\tvalid_1's rmse: 0.0751454\n",
      "[2150]\ttraining's rmse: 0.0725444\tvalid_1's rmse: 0.0751453\n",
      "[2175]\ttraining's rmse: 0.0725417\tvalid_1's rmse: 0.0751453\n",
      "[2200]\ttraining's rmse: 0.072539\tvalid_1's rmse: 0.0751449\n",
      "[2225]\ttraining's rmse: 0.0725363\tvalid_1's rmse: 0.0751445\n",
      "[2250]\ttraining's rmse: 0.0725345\tvalid_1's rmse: 0.0751441\n",
      "[2275]\ttraining's rmse: 0.0725325\tvalid_1's rmse: 0.0751437\n",
      "[2300]\ttraining's rmse: 0.0725312\tvalid_1's rmse: 0.0751435\n",
      "[2325]\ttraining's rmse: 0.0725279\tvalid_1's rmse: 0.0751432\n",
      "[2350]\ttraining's rmse: 0.0725262\tvalid_1's rmse: 0.0751431\n",
      "[2375]\ttraining's rmse: 0.0725247\tvalid_1's rmse: 0.0751432\n",
      "[2400]\ttraining's rmse: 0.0725234\tvalid_1's rmse: 0.0751431\n",
      "[2425]\ttraining's rmse: 0.0725209\tvalid_1's rmse: 0.0751432\n",
      "Early stopping, best iteration is:\n",
      "[2384]\ttraining's rmse: 0.0725242\tvalid_1's rmse: 0.0751429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0760853\tvalid_1's rmse: 0.0729655\n",
      "[50]\ttraining's rmse: 0.075994\tvalid_1's rmse: 0.0729207\n",
      "[75]\ttraining's rmse: 0.0758984\tvalid_1's rmse: 0.0728777\n",
      "[100]\ttraining's rmse: 0.0758118\tvalid_1's rmse: 0.0728379\n",
      "[125]\ttraining's rmse: 0.0757254\tvalid_1's rmse: 0.072801\n",
      "[150]\ttraining's rmse: 0.0756425\tvalid_1's rmse: 0.0727648\n",
      "[175]\ttraining's rmse: 0.0755762\tvalid_1's rmse: 0.0727364\n",
      "[200]\ttraining's rmse: 0.0755021\tvalid_1's rmse: 0.0727066\n",
      "[225]\ttraining's rmse: 0.0754291\tvalid_1's rmse: 0.0726776\n",
      "[250]\ttraining's rmse: 0.0753719\tvalid_1's rmse: 0.0726534\n",
      "[275]\ttraining's rmse: 0.0753189\tvalid_1's rmse: 0.0726306\n",
      "[300]\ttraining's rmse: 0.0752641\tvalid_1's rmse: 0.0726092\n",
      "[325]\ttraining's rmse: 0.0752074\tvalid_1's rmse: 0.0725894\n",
      "[350]\ttraining's rmse: 0.075154\tvalid_1's rmse: 0.0725699\n",
      "[375]\ttraining's rmse: 0.075109\tvalid_1's rmse: 0.0725534\n",
      "[400]\ttraining's rmse: 0.0750601\tvalid_1's rmse: 0.0725439\n",
      "[425]\ttraining's rmse: 0.075016\tvalid_1's rmse: 0.0725288\n",
      "[450]\ttraining's rmse: 0.0749762\tvalid_1's rmse: 0.072516\n",
      "[475]\ttraining's rmse: 0.0749381\tvalid_1's rmse: 0.0725073\n",
      "[500]\ttraining's rmse: 0.0749063\tvalid_1's rmse: 0.0724942\n",
      "[525]\ttraining's rmse: 0.0748645\tvalid_1's rmse: 0.0724878\n",
      "[550]\ttraining's rmse: 0.0748272\tvalid_1's rmse: 0.0724764\n",
      "[575]\ttraining's rmse: 0.0747906\tvalid_1's rmse: 0.0724687\n",
      "[600]\ttraining's rmse: 0.0747574\tvalid_1's rmse: 0.0724598\n",
      "[625]\ttraining's rmse: 0.0747313\tvalid_1's rmse: 0.0724569\n",
      "[650]\ttraining's rmse: 0.0746974\tvalid_1's rmse: 0.0724484\n",
      "[675]\ttraining's rmse: 0.074662\tvalid_1's rmse: 0.0724406\n",
      "[700]\ttraining's rmse: 0.0746323\tvalid_1's rmse: 0.0724339\n",
      "[725]\ttraining's rmse: 0.0746056\tvalid_1's rmse: 0.0724313\n",
      "[750]\ttraining's rmse: 0.0745806\tvalid_1's rmse: 0.0724254\n",
      "[775]\ttraining's rmse: 0.07456\tvalid_1's rmse: 0.0724295\n",
      "[800]\ttraining's rmse: 0.0745325\tvalid_1's rmse: 0.0724279\n",
      "Early stopping, best iteration is:\n",
      "[766]\ttraining's rmse: 0.0745661\tvalid_1's rmse: 0.0724222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0763841\tvalid_1's rmse: 0.0784612\n",
      "[50]\ttraining's rmse: 0.0762742\tvalid_1's rmse: 0.0784147\n",
      "[75]\ttraining's rmse: 0.0761673\tvalid_1's rmse: 0.0783687\n",
      "[100]\ttraining's rmse: 0.0760679\tvalid_1's rmse: 0.0783285\n",
      "[125]\ttraining's rmse: 0.0759666\tvalid_1's rmse: 0.0782882\n",
      "[150]\ttraining's rmse: 0.0758766\tvalid_1's rmse: 0.0782517\n",
      "[175]\ttraining's rmse: 0.0758024\tvalid_1's rmse: 0.0782193\n",
      "[200]\ttraining's rmse: 0.0757204\tvalid_1's rmse: 0.0781874\n",
      "[225]\ttraining's rmse: 0.0756394\tvalid_1's rmse: 0.0781582\n",
      "[250]\ttraining's rmse: 0.0755705\tvalid_1's rmse: 0.0781297\n",
      "[275]\ttraining's rmse: 0.0755075\tvalid_1's rmse: 0.0781056\n",
      "[300]\ttraining's rmse: 0.0754453\tvalid_1's rmse: 0.0780827\n",
      "[325]\ttraining's rmse: 0.0753837\tvalid_1's rmse: 0.0780607\n",
      "[350]\ttraining's rmse: 0.075323\tvalid_1's rmse: 0.0780391\n",
      "[375]\ttraining's rmse: 0.0752743\tvalid_1's rmse: 0.0780204\n",
      "[400]\ttraining's rmse: 0.0752184\tvalid_1's rmse: 0.0780028\n",
      "[425]\ttraining's rmse: 0.0751689\tvalid_1's rmse: 0.0779872\n",
      "[450]\ttraining's rmse: 0.0751234\tvalid_1's rmse: 0.0779706\n",
      "[475]\ttraining's rmse: 0.0750844\tvalid_1's rmse: 0.0779564\n",
      "[500]\ttraining's rmse: 0.0750503\tvalid_1's rmse: 0.0779402\n",
      "[525]\ttraining's rmse: 0.0750066\tvalid_1's rmse: 0.077926\n",
      "[550]\ttraining's rmse: 0.0749672\tvalid_1's rmse: 0.0779146\n",
      "[575]\ttraining's rmse: 0.07493\tvalid_1's rmse: 0.0779027\n",
      "[600]\ttraining's rmse: 0.0748924\tvalid_1's rmse: 0.077892\n",
      "[625]\ttraining's rmse: 0.0748648\tvalid_1's rmse: 0.077882\n",
      "[650]\ttraining's rmse: 0.0748278\tvalid_1's rmse: 0.0778719\n",
      "[675]\ttraining's rmse: 0.074794\tvalid_1's rmse: 0.077862\n",
      "[700]\ttraining's rmse: 0.0747624\tvalid_1's rmse: 0.0778534\n",
      "[725]\ttraining's rmse: 0.074732\tvalid_1's rmse: 0.0778455\n",
      "[750]\ttraining's rmse: 0.0747022\tvalid_1's rmse: 0.0778371\n",
      "[775]\ttraining's rmse: 0.074682\tvalid_1's rmse: 0.0778296\n",
      "[800]\ttraining's rmse: 0.0746516\tvalid_1's rmse: 0.0778225\n",
      "[825]\ttraining's rmse: 0.0746277\tvalid_1's rmse: 0.0778161\n",
      "[850]\ttraining's rmse: 0.0746009\tvalid_1's rmse: 0.0778101\n",
      "[875]\ttraining's rmse: 0.0745796\tvalid_1's rmse: 0.0778034\n",
      "[900]\ttraining's rmse: 0.0745559\tvalid_1's rmse: 0.0777982\n",
      "[925]\ttraining's rmse: 0.074534\tvalid_1's rmse: 0.0777925\n",
      "[950]\ttraining's rmse: 0.0745132\tvalid_1's rmse: 0.0777868\n",
      "[975]\ttraining's rmse: 0.0744939\tvalid_1's rmse: 0.0777812\n",
      "[1000]\ttraining's rmse: 0.0744747\tvalid_1's rmse: 0.0777757\n",
      "[1025]\ttraining's rmse: 0.0744542\tvalid_1's rmse: 0.0777704\n",
      "[1050]\ttraining's rmse: 0.0744386\tvalid_1's rmse: 0.0777644\n",
      "[1075]\ttraining's rmse: 0.0744222\tvalid_1's rmse: 0.0777616\n",
      "[1100]\ttraining's rmse: 0.0744091\tvalid_1's rmse: 0.0777578\n",
      "[1125]\ttraining's rmse: 0.0743945\tvalid_1's rmse: 0.0777534\n",
      "[1150]\ttraining's rmse: 0.0743798\tvalid_1's rmse: 0.0777496\n",
      "[1175]\ttraining's rmse: 0.0743692\tvalid_1's rmse: 0.0777474\n",
      "[1200]\ttraining's rmse: 0.0743583\tvalid_1's rmse: 0.077744\n",
      "[1225]\ttraining's rmse: 0.0743465\tvalid_1's rmse: 0.0777409\n",
      "[1250]\ttraining's rmse: 0.0743346\tvalid_1's rmse: 0.0777363\n",
      "[1275]\ttraining's rmse: 0.0743202\tvalid_1's rmse: 0.0777327\n",
      "[1300]\ttraining's rmse: 0.0743106\tvalid_1's rmse: 0.077729\n",
      "[1325]\ttraining's rmse: 0.0742994\tvalid_1's rmse: 0.0777264\n",
      "[1350]\ttraining's rmse: 0.0742868\tvalid_1's rmse: 0.0777235\n",
      "[1375]\ttraining's rmse: 0.0742774\tvalid_1's rmse: 0.0777215\n",
      "[1400]\ttraining's rmse: 0.0742681\tvalid_1's rmse: 0.0777188\n",
      "[1425]\ttraining's rmse: 0.0742565\tvalid_1's rmse: 0.0777176\n",
      "[1450]\ttraining's rmse: 0.0742457\tvalid_1's rmse: 0.0777155\n",
      "[1475]\ttraining's rmse: 0.0742376\tvalid_1's rmse: 0.0777131\n",
      "[1500]\ttraining's rmse: 0.0742296\tvalid_1's rmse: 0.0777115\n",
      "[1525]\ttraining's rmse: 0.0742238\tvalid_1's rmse: 0.0777097\n",
      "[1550]\ttraining's rmse: 0.074215\tvalid_1's rmse: 0.0777084\n",
      "[1575]\ttraining's rmse: 0.0742083\tvalid_1's rmse: 0.0777067\n",
      "[1600]\ttraining's rmse: 0.0742028\tvalid_1's rmse: 0.0777053\n",
      "[1625]\ttraining's rmse: 0.0741978\tvalid_1's rmse: 0.0777036\n",
      "[1650]\ttraining's rmse: 0.0741931\tvalid_1's rmse: 0.0777013\n",
      "[1675]\ttraining's rmse: 0.0741875\tvalid_1's rmse: 0.0777\n",
      "[1700]\ttraining's rmse: 0.0741841\tvalid_1's rmse: 0.0776985\n",
      "[1725]\ttraining's rmse: 0.0741769\tvalid_1's rmse: 0.0776972\n",
      "[1750]\ttraining's rmse: 0.0741711\tvalid_1's rmse: 0.0776964\n",
      "[1775]\ttraining's rmse: 0.0741665\tvalid_1's rmse: 0.0776952\n",
      "[1800]\ttraining's rmse: 0.0741624\tvalid_1's rmse: 0.0776943\n",
      "[1825]\ttraining's rmse: 0.0741581\tvalid_1's rmse: 0.0776926\n",
      "[1850]\ttraining's rmse: 0.0741547\tvalid_1's rmse: 0.0776912\n",
      "[1875]\ttraining's rmse: 0.0741503\tvalid_1's rmse: 0.0776906\n",
      "[1900]\ttraining's rmse: 0.0741452\tvalid_1's rmse: 0.0776897\n",
      "[1925]\ttraining's rmse: 0.0741422\tvalid_1's rmse: 0.0776892\n",
      "[1950]\ttraining's rmse: 0.074139\tvalid_1's rmse: 0.0776883\n",
      "[1975]\ttraining's rmse: 0.0741367\tvalid_1's rmse: 0.077688\n",
      "[2000]\ttraining's rmse: 0.0741349\tvalid_1's rmse: 0.0776879\n",
      "[2025]\ttraining's rmse: 0.0741316\tvalid_1's rmse: 0.0776871\n",
      "[2050]\ttraining's rmse: 0.0741296\tvalid_1's rmse: 0.0776867\n",
      "[2075]\ttraining's rmse: 0.0741268\tvalid_1's rmse: 0.077686\n",
      "[2100]\ttraining's rmse: 0.0741252\tvalid_1's rmse: 0.0776848\n",
      "[2125]\ttraining's rmse: 0.0741219\tvalid_1's rmse: 0.0776844\n",
      "[2150]\ttraining's rmse: 0.0741173\tvalid_1's rmse: 0.0776838\n",
      "[2175]\ttraining's rmse: 0.0741151\tvalid_1's rmse: 0.077683\n",
      "[2200]\ttraining's rmse: 0.0741126\tvalid_1's rmse: 0.0776827\n",
      "[2225]\ttraining's rmse: 0.0741104\tvalid_1's rmse: 0.0776822\n",
      "[2250]\ttraining's rmse: 0.0741073\tvalid_1's rmse: 0.0776813\n",
      "[2275]\ttraining's rmse: 0.0741042\tvalid_1's rmse: 0.0776814\n",
      "[2300]\ttraining's rmse: 0.0741009\tvalid_1's rmse: 0.0776804\n",
      "[2325]\ttraining's rmse: 0.0740988\tvalid_1's rmse: 0.0776801\n",
      "[2350]\ttraining's rmse: 0.0740968\tvalid_1's rmse: 0.0776792\n",
      "[2375]\ttraining's rmse: 0.0740951\tvalid_1's rmse: 0.077678\n",
      "[2400]\ttraining's rmse: 0.0740931\tvalid_1's rmse: 0.0776772\n",
      "[2425]\ttraining's rmse: 0.0740911\tvalid_1's rmse: 0.077677\n",
      "[2450]\ttraining's rmse: 0.0740888\tvalid_1's rmse: 0.0776766\n",
      "[2475]\ttraining's rmse: 0.0740864\tvalid_1's rmse: 0.0776763\n",
      "[2500]\ttraining's rmse: 0.0740847\tvalid_1's rmse: 0.0776759\n",
      "[2525]\ttraining's rmse: 0.0740829\tvalid_1's rmse: 0.0776743\n",
      "[2550]\ttraining's rmse: 0.0740812\tvalid_1's rmse: 0.0776736\n",
      "[2575]\ttraining's rmse: 0.0740803\tvalid_1's rmse: 0.0776736\n",
      "[2600]\ttraining's rmse: 0.0740791\tvalid_1's rmse: 0.0776727\n",
      "[2625]\ttraining's rmse: 0.0740778\tvalid_1's rmse: 0.0776725\n",
      "[2650]\ttraining's rmse: 0.0740768\tvalid_1's rmse: 0.0776721\n",
      "[2675]\ttraining's rmse: 0.0740749\tvalid_1's rmse: 0.0776713\n",
      "[2700]\ttraining's rmse: 0.074073\tvalid_1's rmse: 0.0776707\n",
      "[2725]\ttraining's rmse: 0.0740715\tvalid_1's rmse: 0.0776706\n",
      "[2750]\ttraining's rmse: 0.0740693\tvalid_1's rmse: 0.0776702\n",
      "[2775]\ttraining's rmse: 0.0740671\tvalid_1's rmse: 0.07767\n",
      "[2800]\ttraining's rmse: 0.0740665\tvalid_1's rmse: 0.0776702\n",
      "[2825]\ttraining's rmse: 0.0740644\tvalid_1's rmse: 0.0776697\n",
      "[2850]\ttraining's rmse: 0.0740635\tvalid_1's rmse: 0.0776698\n",
      "[2875]\ttraining's rmse: 0.0740626\tvalid_1's rmse: 0.0776699\n",
      "Early stopping, best iteration is:\n",
      "[2830]\ttraining's rmse: 0.0740642\tvalid_1's rmse: 0.0776696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0766615\tvalid_1's rmse: 0.077933\n",
      "[50]\ttraining's rmse: 0.076563\tvalid_1's rmse: 0.0778842\n",
      "[75]\ttraining's rmse: 0.0764619\tvalid_1's rmse: 0.0778369\n",
      "[100]\ttraining's rmse: 0.0763707\tvalid_1's rmse: 0.077794\n",
      "[125]\ttraining's rmse: 0.0762752\tvalid_1's rmse: 0.0777512\n",
      "[150]\ttraining's rmse: 0.0761878\tvalid_1's rmse: 0.0777117\n",
      "[175]\ttraining's rmse: 0.0761169\tvalid_1's rmse: 0.0776789\n",
      "[200]\ttraining's rmse: 0.076038\tvalid_1's rmse: 0.0776451\n",
      "[225]\ttraining's rmse: 0.0759634\tvalid_1's rmse: 0.077614\n",
      "[250]\ttraining's rmse: 0.0758982\tvalid_1's rmse: 0.0775847\n",
      "[275]\ttraining's rmse: 0.075839\tvalid_1's rmse: 0.0775578\n",
      "[300]\ttraining's rmse: 0.0757793\tvalid_1's rmse: 0.0775342\n",
      "[325]\ttraining's rmse: 0.0757167\tvalid_1's rmse: 0.0775094\n",
      "[350]\ttraining's rmse: 0.0756565\tvalid_1's rmse: 0.0774863\n",
      "[375]\ttraining's rmse: 0.0756073\tvalid_1's rmse: 0.077467\n",
      "[400]\ttraining's rmse: 0.0755551\tvalid_1's rmse: 0.0774489\n",
      "[425]\ttraining's rmse: 0.0755077\tvalid_1's rmse: 0.0774305\n",
      "[450]\ttraining's rmse: 0.075464\tvalid_1's rmse: 0.0774136\n",
      "[475]\ttraining's rmse: 0.0754225\tvalid_1's rmse: 0.0773976\n",
      "[500]\ttraining's rmse: 0.0753867\tvalid_1's rmse: 0.0773824\n",
      "[525]\ttraining's rmse: 0.0753421\tvalid_1's rmse: 0.0773676\n",
      "[550]\ttraining's rmse: 0.0753007\tvalid_1's rmse: 0.0773539\n",
      "[575]\ttraining's rmse: 0.0752636\tvalid_1's rmse: 0.0773431\n",
      "[600]\ttraining's rmse: 0.0752261\tvalid_1's rmse: 0.0773313\n",
      "[625]\ttraining's rmse: 0.075199\tvalid_1's rmse: 0.0773209\n",
      "[650]\ttraining's rmse: 0.0751645\tvalid_1's rmse: 0.0773109\n",
      "[675]\ttraining's rmse: 0.0751287\tvalid_1's rmse: 0.0773009\n",
      "[700]\ttraining's rmse: 0.0750989\tvalid_1's rmse: 0.0772916\n",
      "[725]\ttraining's rmse: 0.0750701\tvalid_1's rmse: 0.0772832\n",
      "[750]\ttraining's rmse: 0.0750429\tvalid_1's rmse: 0.0772752\n",
      "[775]\ttraining's rmse: 0.0750192\tvalid_1's rmse: 0.0772671\n",
      "[800]\ttraining's rmse: 0.0749893\tvalid_1's rmse: 0.0772596\n",
      "[825]\ttraining's rmse: 0.0749648\tvalid_1's rmse: 0.0772521\n",
      "[850]\ttraining's rmse: 0.0749412\tvalid_1's rmse: 0.0772466\n",
      "[875]\ttraining's rmse: 0.0749193\tvalid_1's rmse: 0.0772403\n",
      "[900]\ttraining's rmse: 0.074896\tvalid_1's rmse: 0.0772342\n",
      "[925]\ttraining's rmse: 0.0748731\tvalid_1's rmse: 0.0772289\n",
      "[950]\ttraining's rmse: 0.0748521\tvalid_1's rmse: 0.0772235\n",
      "[975]\ttraining's rmse: 0.0748331\tvalid_1's rmse: 0.0772185\n",
      "[1000]\ttraining's rmse: 0.0748142\tvalid_1's rmse: 0.0772133\n",
      "[1025]\ttraining's rmse: 0.0747934\tvalid_1's rmse: 0.0772088\n",
      "[1050]\ttraining's rmse: 0.0747766\tvalid_1's rmse: 0.0772043\n",
      "[1075]\ttraining's rmse: 0.0747604\tvalid_1's rmse: 0.077201\n",
      "[1100]\ttraining's rmse: 0.0747472\tvalid_1's rmse: 0.077197\n",
      "[1125]\ttraining's rmse: 0.0747303\tvalid_1's rmse: 0.0771933\n",
      "[1150]\ttraining's rmse: 0.0747157\tvalid_1's rmse: 0.0771903\n",
      "[1175]\ttraining's rmse: 0.074702\tvalid_1's rmse: 0.0771876\n",
      "[1200]\ttraining's rmse: 0.074689\tvalid_1's rmse: 0.0771847\n",
      "[1225]\ttraining's rmse: 0.0746743\tvalid_1's rmse: 0.077182\n",
      "[1250]\ttraining's rmse: 0.074662\tvalid_1's rmse: 0.0771793\n",
      "[1275]\ttraining's rmse: 0.074648\tvalid_1's rmse: 0.0771771\n",
      "[1300]\ttraining's rmse: 0.074637\tvalid_1's rmse: 0.0771746\n",
      "[1325]\ttraining's rmse: 0.0746273\tvalid_1's rmse: 0.0771722\n",
      "[1350]\ttraining's rmse: 0.0746158\tvalid_1's rmse: 0.0771703\n",
      "[1375]\ttraining's rmse: 0.0746044\tvalid_1's rmse: 0.0771685\n",
      "[1400]\ttraining's rmse: 0.0745966\tvalid_1's rmse: 0.0771665\n",
      "[1425]\ttraining's rmse: 0.0745866\tvalid_1's rmse: 0.0771653\n",
      "[1450]\ttraining's rmse: 0.0745759\tvalid_1's rmse: 0.0771639\n",
      "[1475]\ttraining's rmse: 0.0745672\tvalid_1's rmse: 0.0771622\n",
      "[1500]\ttraining's rmse: 0.0745583\tvalid_1's rmse: 0.0771611\n",
      "[1525]\ttraining's rmse: 0.0745511\tvalid_1's rmse: 0.0771596\n",
      "[1550]\ttraining's rmse: 0.0745431\tvalid_1's rmse: 0.0771581\n",
      "[1575]\ttraining's rmse: 0.0745358\tvalid_1's rmse: 0.0771564\n",
      "[1600]\ttraining's rmse: 0.0745302\tvalid_1's rmse: 0.0771555\n",
      "[1625]\ttraining's rmse: 0.0745225\tvalid_1's rmse: 0.077154\n",
      "[1650]\ttraining's rmse: 0.0745166\tvalid_1's rmse: 0.0771537\n",
      "[1675]\ttraining's rmse: 0.0745128\tvalid_1's rmse: 0.0771522\n",
      "[1700]\ttraining's rmse: 0.0745089\tvalid_1's rmse: 0.0771511\n",
      "[1725]\ttraining's rmse: 0.0745042\tvalid_1's rmse: 0.0771498\n",
      "[1750]\ttraining's rmse: 0.0744987\tvalid_1's rmse: 0.0771493\n",
      "[1775]\ttraining's rmse: 0.0744952\tvalid_1's rmse: 0.0771486\n",
      "[1800]\ttraining's rmse: 0.0744898\tvalid_1's rmse: 0.0771477\n",
      "[1825]\ttraining's rmse: 0.0744851\tvalid_1's rmse: 0.077147\n",
      "[1850]\ttraining's rmse: 0.0744809\tvalid_1's rmse: 0.0771463\n",
      "[1875]\ttraining's rmse: 0.0744775\tvalid_1's rmse: 0.0771465\n",
      "[1900]\ttraining's rmse: 0.0744744\tvalid_1's rmse: 0.0771465\n",
      "[1925]\ttraining's rmse: 0.074471\tvalid_1's rmse: 0.077146\n",
      "[1950]\ttraining's rmse: 0.0744675\tvalid_1's rmse: 0.0771454\n",
      "[1975]\ttraining's rmse: 0.0744651\tvalid_1's rmse: 0.0771448\n",
      "[2000]\ttraining's rmse: 0.074461\tvalid_1's rmse: 0.0771447\n",
      "[2025]\ttraining's rmse: 0.074458\tvalid_1's rmse: 0.0771442\n",
      "[2050]\ttraining's rmse: 0.0744529\tvalid_1's rmse: 0.0771435\n",
      "[2075]\ttraining's rmse: 0.07445\tvalid_1's rmse: 0.0771435\n",
      "[2100]\ttraining's rmse: 0.0744467\tvalid_1's rmse: 0.0771432\n",
      "[2125]\ttraining's rmse: 0.0744443\tvalid_1's rmse: 0.0771428\n",
      "[2150]\ttraining's rmse: 0.0744419\tvalid_1's rmse: 0.077143\n",
      "Early stopping, best iteration is:\n",
      "[2123]\ttraining's rmse: 0.0744444\tvalid_1's rmse: 0.0771428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0780904\tvalid_1's rmse: 0.0750236\n",
      "[50]\ttraining's rmse: 0.0779954\tvalid_1's rmse: 0.0749833\n",
      "[75]\ttraining's rmse: 0.0778963\tvalid_1's rmse: 0.0749391\n",
      "[100]\ttraining's rmse: 0.077809\tvalid_1's rmse: 0.0749011\n",
      "[125]\ttraining's rmse: 0.0777177\tvalid_1's rmse: 0.0748615\n",
      "[150]\ttraining's rmse: 0.0776323\tvalid_1's rmse: 0.0748263\n",
      "[175]\ttraining's rmse: 0.0775626\tvalid_1's rmse: 0.0747991\n",
      "[200]\ttraining's rmse: 0.0774845\tvalid_1's rmse: 0.0747698\n",
      "[225]\ttraining's rmse: 0.0774089\tvalid_1's rmse: 0.07474\n",
      "[250]\ttraining's rmse: 0.0773473\tvalid_1's rmse: 0.0747137\n",
      "[275]\ttraining's rmse: 0.0772897\tvalid_1's rmse: 0.07469\n",
      "[300]\ttraining's rmse: 0.0772332\tvalid_1's rmse: 0.074668\n",
      "[325]\ttraining's rmse: 0.0771754\tvalid_1's rmse: 0.0746483\n",
      "[350]\ttraining's rmse: 0.0771192\tvalid_1's rmse: 0.0746287\n",
      "[375]\ttraining's rmse: 0.0770732\tvalid_1's rmse: 0.0746111\n",
      "[400]\ttraining's rmse: 0.0770222\tvalid_1's rmse: 0.0745993\n",
      "[425]\ttraining's rmse: 0.0769759\tvalid_1's rmse: 0.074584\n",
      "[450]\ttraining's rmse: 0.0769342\tvalid_1's rmse: 0.0745731\n",
      "[475]\ttraining's rmse: 0.0768968\tvalid_1's rmse: 0.0745648\n",
      "[500]\ttraining's rmse: 0.0768644\tvalid_1's rmse: 0.0745522\n",
      "[525]\ttraining's rmse: 0.0768219\tvalid_1's rmse: 0.0745396\n",
      "[550]\ttraining's rmse: 0.0767837\tvalid_1's rmse: 0.0745276\n",
      "[575]\ttraining's rmse: 0.0767474\tvalid_1's rmse: 0.074521\n",
      "[600]\ttraining's rmse: 0.0767121\tvalid_1's rmse: 0.0745144\n",
      "[625]\ttraining's rmse: 0.0766858\tvalid_1's rmse: 0.0745128\n",
      "[650]\ttraining's rmse: 0.0766508\tvalid_1's rmse: 0.0745045\n",
      "[675]\ttraining's rmse: 0.0766144\tvalid_1's rmse: 0.0745034\n",
      "[700]\ttraining's rmse: 0.0765832\tvalid_1's rmse: 0.0745001\n",
      "[725]\ttraining's rmse: 0.0765532\tvalid_1's rmse: 0.0745041\n",
      "Early stopping, best iteration is:\n",
      "[692]\ttraining's rmse: 0.0765929\tvalid_1's rmse: 0.0744979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.07894\tvalid_1's rmse: 0.0811399\n",
      "[50]\ttraining's rmse: 0.0788206\tvalid_1's rmse: 0.0810909\n",
      "[75]\ttraining's rmse: 0.0787006\tvalid_1's rmse: 0.0810434\n",
      "[100]\ttraining's rmse: 0.0785902\tvalid_1's rmse: 0.0810003\n",
      "[125]\ttraining's rmse: 0.0784781\tvalid_1's rmse: 0.0809578\n",
      "[150]\ttraining's rmse: 0.0783725\tvalid_1's rmse: 0.080918\n",
      "[175]\ttraining's rmse: 0.0782887\tvalid_1's rmse: 0.0808843\n",
      "[200]\ttraining's rmse: 0.0781978\tvalid_1's rmse: 0.0808507\n",
      "[225]\ttraining's rmse: 0.078107\tvalid_1's rmse: 0.0808192\n",
      "[250]\ttraining's rmse: 0.0780313\tvalid_1's rmse: 0.0807896\n",
      "[275]\ttraining's rmse: 0.0779625\tvalid_1's rmse: 0.080764\n",
      "[300]\ttraining's rmse: 0.0778908\tvalid_1's rmse: 0.0807402\n",
      "[325]\ttraining's rmse: 0.0778208\tvalid_1's rmse: 0.0807175\n",
      "[350]\ttraining's rmse: 0.077753\tvalid_1's rmse: 0.0806944\n",
      "[375]\ttraining's rmse: 0.0776956\tvalid_1's rmse: 0.0806744\n",
      "[400]\ttraining's rmse: 0.0776349\tvalid_1's rmse: 0.0806554\n",
      "[425]\ttraining's rmse: 0.0775815\tvalid_1's rmse: 0.0806386\n",
      "[450]\ttraining's rmse: 0.0775309\tvalid_1's rmse: 0.0806202\n",
      "[475]\ttraining's rmse: 0.0774835\tvalid_1's rmse: 0.0806039\n",
      "[500]\ttraining's rmse: 0.0774427\tvalid_1's rmse: 0.0805897\n",
      "[525]\ttraining's rmse: 0.0773913\tvalid_1's rmse: 0.0805748\n",
      "[550]\ttraining's rmse: 0.0773463\tvalid_1's rmse: 0.0805612\n",
      "[575]\ttraining's rmse: 0.0773025\tvalid_1's rmse: 0.080549\n",
      "[600]\ttraining's rmse: 0.0772618\tvalid_1's rmse: 0.080537\n",
      "[625]\ttraining's rmse: 0.0772299\tvalid_1's rmse: 0.0805255\n",
      "[650]\ttraining's rmse: 0.0771898\tvalid_1's rmse: 0.0805135\n",
      "[675]\ttraining's rmse: 0.0771509\tvalid_1's rmse: 0.0805026\n",
      "[700]\ttraining's rmse: 0.0771139\tvalid_1's rmse: 0.0804931\n",
      "[725]\ttraining's rmse: 0.07708\tvalid_1's rmse: 0.0804844\n",
      "[750]\ttraining's rmse: 0.0770511\tvalid_1's rmse: 0.0804759\n",
      "[775]\ttraining's rmse: 0.0770253\tvalid_1's rmse: 0.0804674\n",
      "[800]\ttraining's rmse: 0.0769945\tvalid_1's rmse: 0.0804598\n",
      "[825]\ttraining's rmse: 0.0769678\tvalid_1's rmse: 0.0804523\n",
      "[850]\ttraining's rmse: 0.0769385\tvalid_1's rmse: 0.0804465\n",
      "[875]\ttraining's rmse: 0.0769164\tvalid_1's rmse: 0.0804391\n",
      "[900]\ttraining's rmse: 0.0768899\tvalid_1's rmse: 0.0804332\n",
      "[925]\ttraining's rmse: 0.0768661\tvalid_1's rmse: 0.0804265\n",
      "[950]\ttraining's rmse: 0.0768435\tvalid_1's rmse: 0.0804204\n",
      "[975]\ttraining's rmse: 0.0768228\tvalid_1's rmse: 0.0804158\n",
      "[1000]\ttraining's rmse: 0.0768004\tvalid_1's rmse: 0.0804112\n",
      "[1025]\ttraining's rmse: 0.0767782\tvalid_1's rmse: 0.0804058\n",
      "[1050]\ttraining's rmse: 0.0767562\tvalid_1's rmse: 0.0804001\n",
      "[1075]\ttraining's rmse: 0.0767372\tvalid_1's rmse: 0.0803975\n",
      "[1100]\ttraining's rmse: 0.0767212\tvalid_1's rmse: 0.0803945\n",
      "[1125]\ttraining's rmse: 0.0767047\tvalid_1's rmse: 0.0803899\n",
      "[1150]\ttraining's rmse: 0.0766863\tvalid_1's rmse: 0.0803875\n",
      "[1175]\ttraining's rmse: 0.076671\tvalid_1's rmse: 0.080385\n",
      "[1200]\ttraining's rmse: 0.0766581\tvalid_1's rmse: 0.0803808\n",
      "[1225]\ttraining's rmse: 0.0766436\tvalid_1's rmse: 0.0803779\n",
      "[1250]\ttraining's rmse: 0.0766327\tvalid_1's rmse: 0.0803751\n",
      "[1275]\ttraining's rmse: 0.0766162\tvalid_1's rmse: 0.0803721\n",
      "[1300]\ttraining's rmse: 0.0766045\tvalid_1's rmse: 0.0803681\n",
      "[1325]\ttraining's rmse: 0.0765919\tvalid_1's rmse: 0.080366\n",
      "[1350]\ttraining's rmse: 0.0765791\tvalid_1's rmse: 0.0803631\n",
      "[1375]\ttraining's rmse: 0.0765669\tvalid_1's rmse: 0.0803617\n",
      "[1400]\ttraining's rmse: 0.0765571\tvalid_1's rmse: 0.0803579\n",
      "[1425]\ttraining's rmse: 0.0765465\tvalid_1's rmse: 0.0803555\n",
      "[1450]\ttraining's rmse: 0.0765353\tvalid_1's rmse: 0.0803533\n",
      "[1475]\ttraining's rmse: 0.0765258\tvalid_1's rmse: 0.080351\n",
      "[1500]\ttraining's rmse: 0.0765174\tvalid_1's rmse: 0.0803497\n",
      "[1525]\ttraining's rmse: 0.0765094\tvalid_1's rmse: 0.0803472\n",
      "[1550]\ttraining's rmse: 0.0765008\tvalid_1's rmse: 0.080347\n",
      "[1575]\ttraining's rmse: 0.0764931\tvalid_1's rmse: 0.0803442\n",
      "[1600]\ttraining's rmse: 0.0764867\tvalid_1's rmse: 0.0803426\n",
      "[1625]\ttraining's rmse: 0.0764791\tvalid_1's rmse: 0.0803398\n",
      "[1650]\ttraining's rmse: 0.0764719\tvalid_1's rmse: 0.080338\n",
      "[1675]\ttraining's rmse: 0.0764673\tvalid_1's rmse: 0.0803371\n",
      "[1700]\ttraining's rmse: 0.076461\tvalid_1's rmse: 0.0803347\n",
      "[1725]\ttraining's rmse: 0.0764572\tvalid_1's rmse: 0.0803337\n",
      "[1750]\ttraining's rmse: 0.076451\tvalid_1's rmse: 0.0803315\n",
      "[1775]\ttraining's rmse: 0.0764457\tvalid_1's rmse: 0.0803296\n",
      "[1800]\ttraining's rmse: 0.0764405\tvalid_1's rmse: 0.0803283\n",
      "[1825]\ttraining's rmse: 0.0764357\tvalid_1's rmse: 0.080327\n",
      "[1850]\ttraining's rmse: 0.0764317\tvalid_1's rmse: 0.0803258\n",
      "[1875]\ttraining's rmse: 0.0764286\tvalid_1's rmse: 0.080325\n",
      "[1900]\ttraining's rmse: 0.0764251\tvalid_1's rmse: 0.0803244\n",
      "[1925]\ttraining's rmse: 0.0764216\tvalid_1's rmse: 0.0803238\n",
      "[1950]\ttraining's rmse: 0.0764194\tvalid_1's rmse: 0.0803225\n",
      "[1975]\ttraining's rmse: 0.0764161\tvalid_1's rmse: 0.0803211\n",
      "[2000]\ttraining's rmse: 0.0764121\tvalid_1's rmse: 0.0803208\n",
      "[2025]\ttraining's rmse: 0.0764087\tvalid_1's rmse: 0.0803191\n",
      "[2050]\ttraining's rmse: 0.0764043\tvalid_1's rmse: 0.0803184\n",
      "[2075]\ttraining's rmse: 0.0764015\tvalid_1's rmse: 0.0803175\n",
      "[2100]\ttraining's rmse: 0.0763986\tvalid_1's rmse: 0.0803176\n",
      "[2125]\ttraining's rmse: 0.0763962\tvalid_1's rmse: 0.080317\n",
      "[2150]\ttraining's rmse: 0.0763928\tvalid_1's rmse: 0.0803168\n",
      "[2175]\ttraining's rmse: 0.0763897\tvalid_1's rmse: 0.0803159\n",
      "[2200]\ttraining's rmse: 0.0763871\tvalid_1's rmse: 0.080316\n",
      "[2225]\ttraining's rmse: 0.0763848\tvalid_1's rmse: 0.0803156\n",
      "[2250]\ttraining's rmse: 0.0763822\tvalid_1's rmse: 0.0803151\n",
      "[2275]\ttraining's rmse: 0.0763802\tvalid_1's rmse: 0.0803147\n",
      "[2300]\ttraining's rmse: 0.0763783\tvalid_1's rmse: 0.0803135\n",
      "[2325]\ttraining's rmse: 0.0763762\tvalid_1's rmse: 0.080313\n",
      "[2350]\ttraining's rmse: 0.0763732\tvalid_1's rmse: 0.0803116\n",
      "[2375]\ttraining's rmse: 0.0763708\tvalid_1's rmse: 0.0803104\n",
      "[2400]\ttraining's rmse: 0.0763682\tvalid_1's rmse: 0.0803106\n",
      "[2425]\ttraining's rmse: 0.0763671\tvalid_1's rmse: 0.0803106\n",
      "Early stopping, best iteration is:\n",
      "[2384]\ttraining's rmse: 0.0763699\tvalid_1's rmse: 0.0803102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0792144\tvalid_1's rmse: 0.0806242\n",
      "[50]\ttraining's rmse: 0.0791094\tvalid_1's rmse: 0.0805736\n",
      "[75]\ttraining's rmse: 0.0790026\tvalid_1's rmse: 0.0805233\n",
      "[100]\ttraining's rmse: 0.0789068\tvalid_1's rmse: 0.0804777\n",
      "[125]\ttraining's rmse: 0.0788056\tvalid_1's rmse: 0.0804325\n",
      "[150]\ttraining's rmse: 0.078715\tvalid_1's rmse: 0.0803909\n",
      "[175]\ttraining's rmse: 0.0786393\tvalid_1's rmse: 0.0803569\n",
      "[200]\ttraining's rmse: 0.0785568\tvalid_1's rmse: 0.0803221\n",
      "[225]\ttraining's rmse: 0.0784768\tvalid_1's rmse: 0.0802891\n",
      "[250]\ttraining's rmse: 0.0784082\tvalid_1's rmse: 0.0802602\n",
      "[275]\ttraining's rmse: 0.0783441\tvalid_1's rmse: 0.0802328\n",
      "[300]\ttraining's rmse: 0.078281\tvalid_1's rmse: 0.0802077\n",
      "[325]\ttraining's rmse: 0.0782153\tvalid_1's rmse: 0.080182\n",
      "[350]\ttraining's rmse: 0.0781524\tvalid_1's rmse: 0.0801584\n",
      "[375]\ttraining's rmse: 0.0781012\tvalid_1's rmse: 0.0801373\n",
      "[400]\ttraining's rmse: 0.0780457\tvalid_1's rmse: 0.0801183\n",
      "[425]\ttraining's rmse: 0.077996\tvalid_1's rmse: 0.0800987\n",
      "[450]\ttraining's rmse: 0.0779482\tvalid_1's rmse: 0.0800805\n",
      "[475]\ttraining's rmse: 0.0779041\tvalid_1's rmse: 0.0800641\n",
      "[500]\ttraining's rmse: 0.0778671\tvalid_1's rmse: 0.0800485\n",
      "[525]\ttraining's rmse: 0.0778207\tvalid_1's rmse: 0.0800329\n",
      "[550]\ttraining's rmse: 0.0777766\tvalid_1's rmse: 0.0800176\n",
      "[575]\ttraining's rmse: 0.0777365\tvalid_1's rmse: 0.0800051\n",
      "[600]\ttraining's rmse: 0.0776978\tvalid_1's rmse: 0.0799921\n",
      "[625]\ttraining's rmse: 0.0776683\tvalid_1's rmse: 0.0799808\n",
      "[650]\ttraining's rmse: 0.0776276\tvalid_1's rmse: 0.0799682\n",
      "[675]\ttraining's rmse: 0.0775889\tvalid_1's rmse: 0.079957\n",
      "[700]\ttraining's rmse: 0.0775557\tvalid_1's rmse: 0.0799466\n",
      "[725]\ttraining's rmse: 0.0775216\tvalid_1's rmse: 0.0799362\n",
      "[750]\ttraining's rmse: 0.0774932\tvalid_1's rmse: 0.0799277\n",
      "[775]\ttraining's rmse: 0.0774693\tvalid_1's rmse: 0.07992\n",
      "[800]\ttraining's rmse: 0.0774377\tvalid_1's rmse: 0.0799114\n",
      "[825]\ttraining's rmse: 0.0774108\tvalid_1's rmse: 0.079903\n",
      "[850]\ttraining's rmse: 0.0773831\tvalid_1's rmse: 0.0798964\n",
      "[875]\ttraining's rmse: 0.0773601\tvalid_1's rmse: 0.0798893\n",
      "[900]\ttraining's rmse: 0.0773348\tvalid_1's rmse: 0.079882\n",
      "[925]\ttraining's rmse: 0.0773125\tvalid_1's rmse: 0.0798764\n",
      "[950]\ttraining's rmse: 0.0772913\tvalid_1's rmse: 0.0798709\n",
      "[975]\ttraining's rmse: 0.0772707\tvalid_1's rmse: 0.0798647\n",
      "[1000]\ttraining's rmse: 0.0772503\tvalid_1's rmse: 0.0798596\n",
      "[1025]\ttraining's rmse: 0.0772287\tvalid_1's rmse: 0.0798548\n",
      "[1050]\ttraining's rmse: 0.077211\tvalid_1's rmse: 0.0798496\n",
      "[1075]\ttraining's rmse: 0.0771905\tvalid_1's rmse: 0.0798456\n",
      "[1100]\ttraining's rmse: 0.0771783\tvalid_1's rmse: 0.0798419\n",
      "[1125]\ttraining's rmse: 0.0771612\tvalid_1's rmse: 0.0798372\n",
      "[1150]\ttraining's rmse: 0.0771426\tvalid_1's rmse: 0.0798336\n",
      "[1175]\ttraining's rmse: 0.0771286\tvalid_1's rmse: 0.0798303\n",
      "[1200]\ttraining's rmse: 0.0771136\tvalid_1's rmse: 0.0798269\n",
      "[1225]\ttraining's rmse: 0.0771003\tvalid_1's rmse: 0.0798239\n",
      "[1250]\ttraining's rmse: 0.0770875\tvalid_1's rmse: 0.0798201\n",
      "[1275]\ttraining's rmse: 0.0770736\tvalid_1's rmse: 0.0798169\n",
      "[1300]\ttraining's rmse: 0.0770631\tvalid_1's rmse: 0.0798141\n",
      "[1325]\ttraining's rmse: 0.0770511\tvalid_1's rmse: 0.0798118\n",
      "[1350]\ttraining's rmse: 0.0770395\tvalid_1's rmse: 0.0798092\n",
      "[1375]\ttraining's rmse: 0.0770289\tvalid_1's rmse: 0.0798067\n",
      "[1400]\ttraining's rmse: 0.0770193\tvalid_1's rmse: 0.0798041\n",
      "[1425]\ttraining's rmse: 0.0770077\tvalid_1's rmse: 0.0798017\n",
      "[1450]\ttraining's rmse: 0.0769979\tvalid_1's rmse: 0.0798001\n",
      "[1475]\ttraining's rmse: 0.0769863\tvalid_1's rmse: 0.0797978\n",
      "[1500]\ttraining's rmse: 0.07698\tvalid_1's rmse: 0.0797955\n",
      "[1525]\ttraining's rmse: 0.0769722\tvalid_1's rmse: 0.0797935\n",
      "[1550]\ttraining's rmse: 0.0769654\tvalid_1's rmse: 0.0797928\n",
      "[1575]\ttraining's rmse: 0.076956\tvalid_1's rmse: 0.0797913\n",
      "[1600]\ttraining's rmse: 0.0769508\tvalid_1's rmse: 0.0797901\n",
      "[1625]\ttraining's rmse: 0.0769433\tvalid_1's rmse: 0.0797883\n",
      "[1650]\ttraining's rmse: 0.0769368\tvalid_1's rmse: 0.0797874\n",
      "[1675]\ttraining's rmse: 0.0769313\tvalid_1's rmse: 0.0797865\n",
      "[1700]\ttraining's rmse: 0.076926\tvalid_1's rmse: 0.0797853\n",
      "[1725]\ttraining's rmse: 0.0769205\tvalid_1's rmse: 0.0797841\n",
      "[1750]\ttraining's rmse: 0.0769142\tvalid_1's rmse: 0.0797836\n",
      "[1775]\ttraining's rmse: 0.0769087\tvalid_1's rmse: 0.079783\n",
      "[1800]\ttraining's rmse: 0.0769041\tvalid_1's rmse: 0.0797822\n",
      "[1825]\ttraining's rmse: 0.0768981\tvalid_1's rmse: 0.0797808\n",
      "[1850]\ttraining's rmse: 0.0768943\tvalid_1's rmse: 0.0797798\n",
      "[1875]\ttraining's rmse: 0.0768904\tvalid_1's rmse: 0.0797792\n",
      "[1900]\ttraining's rmse: 0.076886\tvalid_1's rmse: 0.0797791\n",
      "[1925]\ttraining's rmse: 0.076882\tvalid_1's rmse: 0.0797781\n",
      "[1950]\ttraining's rmse: 0.0768797\tvalid_1's rmse: 0.0797774\n",
      "[1975]\ttraining's rmse: 0.0768758\tvalid_1's rmse: 0.0797761\n",
      "[2000]\ttraining's rmse: 0.0768721\tvalid_1's rmse: 0.0797757\n",
      "[2025]\ttraining's rmse: 0.0768682\tvalid_1's rmse: 0.0797747\n",
      "[2050]\ttraining's rmse: 0.0768651\tvalid_1's rmse: 0.0797745\n",
      "[2075]\ttraining's rmse: 0.0768612\tvalid_1's rmse: 0.0797739\n",
      "[2100]\ttraining's rmse: 0.0768581\tvalid_1's rmse: 0.0797731\n",
      "[2125]\ttraining's rmse: 0.0768563\tvalid_1's rmse: 0.0797729\n",
      "[2150]\ttraining's rmse: 0.0768537\tvalid_1's rmse: 0.0797731\n",
      "[2175]\ttraining's rmse: 0.076851\tvalid_1's rmse: 0.0797728\n",
      "[2200]\ttraining's rmse: 0.0768485\tvalid_1's rmse: 0.0797722\n",
      "[2225]\ttraining's rmse: 0.076846\tvalid_1's rmse: 0.0797721\n",
      "[2250]\ttraining's rmse: 0.0768434\tvalid_1's rmse: 0.0797718\n",
      "[2275]\ttraining's rmse: 0.0768412\tvalid_1's rmse: 0.0797717\n",
      "[2300]\ttraining's rmse: 0.076839\tvalid_1's rmse: 0.0797712\n",
      "[2325]\ttraining's rmse: 0.076836\tvalid_1's rmse: 0.0797709\n",
      "[2350]\ttraining's rmse: 0.076834\tvalid_1's rmse: 0.0797704\n",
      "[2375]\ttraining's rmse: 0.076832\tvalid_1's rmse: 0.07977\n",
      "[2400]\ttraining's rmse: 0.0768306\tvalid_1's rmse: 0.0797696\n",
      "[2425]\ttraining's rmse: 0.0768281\tvalid_1's rmse: 0.0797695\n",
      "[2450]\ttraining's rmse: 0.0768259\tvalid_1's rmse: 0.0797694\n",
      "[2475]\ttraining's rmse: 0.0768221\tvalid_1's rmse: 0.0797693\n",
      "[2500]\ttraining's rmse: 0.0768198\tvalid_1's rmse: 0.0797687\n",
      "[2525]\ttraining's rmse: 0.0768177\tvalid_1's rmse: 0.0797684\n",
      "[2550]\ttraining's rmse: 0.0768156\tvalid_1's rmse: 0.0797683\n",
      "[2575]\ttraining's rmse: 0.0768126\tvalid_1's rmse: 0.0797678\n",
      "[2600]\ttraining's rmse: 0.0768105\tvalid_1's rmse: 0.0797674\n",
      "[2625]\ttraining's rmse: 0.076809\tvalid_1's rmse: 0.0797669\n",
      "[2650]\ttraining's rmse: 0.0768081\tvalid_1's rmse: 0.0797667\n",
      "[2675]\ttraining's rmse: 0.0768059\tvalid_1's rmse: 0.0797661\n",
      "[2700]\ttraining's rmse: 0.0768051\tvalid_1's rmse: 0.0797658\n",
      "[2725]\ttraining's rmse: 0.0768041\tvalid_1's rmse: 0.0797659\n",
      "[2750]\ttraining's rmse: 0.0768027\tvalid_1's rmse: 0.0797658\n",
      "[2775]\ttraining's rmse: 0.0768011\tvalid_1's rmse: 0.0797656\n",
      "[2800]\ttraining's rmse: 0.0767999\tvalid_1's rmse: 0.0797657\n",
      "[2825]\ttraining's rmse: 0.0767975\tvalid_1's rmse: 0.0797659\n",
      "[2850]\ttraining's rmse: 0.0767961\tvalid_1's rmse: 0.0797658\n",
      "[2875]\ttraining's rmse: 0.0767952\tvalid_1's rmse: 0.0797659\n",
      "[2900]\ttraining's rmse: 0.0767934\tvalid_1's rmse: 0.0797662\n",
      "Early stopping, best iteration is:\n",
      "[2857]\ttraining's rmse: 0.0767959\tvalid_1's rmse: 0.0797656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0807656\tvalid_1's rmse: 0.0774671\n",
      "[50]\ttraining's rmse: 0.0806631\tvalid_1's rmse: 0.0774234\n",
      "[75]\ttraining's rmse: 0.0805553\tvalid_1's rmse: 0.0773786\n",
      "[100]\ttraining's rmse: 0.0804617\tvalid_1's rmse: 0.0773391\n",
      "[125]\ttraining's rmse: 0.0803654\tvalid_1's rmse: 0.0773004\n",
      "[150]\ttraining's rmse: 0.0802766\tvalid_1's rmse: 0.0772639\n",
      "[175]\ttraining's rmse: 0.0802011\tvalid_1's rmse: 0.0772341\n",
      "[200]\ttraining's rmse: 0.0801182\tvalid_1's rmse: 0.0772031\n",
      "[225]\ttraining's rmse: 0.0800392\tvalid_1's rmse: 0.0771727\n",
      "[250]\ttraining's rmse: 0.0799732\tvalid_1's rmse: 0.0771467\n",
      "[275]\ttraining's rmse: 0.07991\tvalid_1's rmse: 0.0771224\n",
      "[300]\ttraining's rmse: 0.0798495\tvalid_1's rmse: 0.0770994\n",
      "[325]\ttraining's rmse: 0.0797864\tvalid_1's rmse: 0.0770776\n",
      "[350]\ttraining's rmse: 0.0797254\tvalid_1's rmse: 0.0770557\n",
      "[375]\ttraining's rmse: 0.0796749\tvalid_1's rmse: 0.0770393\n",
      "[400]\ttraining's rmse: 0.0796222\tvalid_1's rmse: 0.0770324\n",
      "[425]\ttraining's rmse: 0.0795725\tvalid_1's rmse: 0.0770209\n",
      "[450]\ttraining's rmse: 0.0795266\tvalid_1's rmse: 0.0770042\n",
      "[475]\ttraining's rmse: 0.0794841\tvalid_1's rmse: 0.076995\n",
      "[500]\ttraining's rmse: 0.0794488\tvalid_1's rmse: 0.0769818\n",
      "[525]\ttraining's rmse: 0.0794003\tvalid_1's rmse: 0.0769731\n",
      "[550]\ttraining's rmse: 0.0793577\tvalid_1's rmse: 0.076967\n",
      "[575]\ttraining's rmse: 0.0793169\tvalid_1's rmse: 0.0769567\n",
      "[600]\ttraining's rmse: 0.0792773\tvalid_1's rmse: 0.0769492\n",
      "[625]\ttraining's rmse: 0.0792467\tvalid_1's rmse: 0.0769528\n",
      "[650]\ttraining's rmse: 0.0792071\tvalid_1's rmse: 0.0769421\n",
      "[675]\ttraining's rmse: 0.0791686\tvalid_1's rmse: 0.0769334\n",
      "[700]\ttraining's rmse: 0.0791364\tvalid_1's rmse: 0.0769262\n",
      "[725]\ttraining's rmse: 0.0791044\tvalid_1's rmse: 0.0769314\n",
      "[750]\ttraining's rmse: 0.079073\tvalid_1's rmse: 0.0769302\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 0.0791235\tvalid_1's rmse: 0.0769237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0806374\tvalid_1's rmse: 0.082837\n",
      "[50]\ttraining's rmse: 0.0805156\tvalid_1's rmse: 0.0827885\n",
      "[75]\ttraining's rmse: 0.0803965\tvalid_1's rmse: 0.0827415\n",
      "[100]\ttraining's rmse: 0.0802865\tvalid_1's rmse: 0.0827\n",
      "[125]\ttraining's rmse: 0.0801723\tvalid_1's rmse: 0.0826598\n",
      "[150]\ttraining's rmse: 0.0800673\tvalid_1's rmse: 0.0826225\n",
      "[175]\ttraining's rmse: 0.0799832\tvalid_1's rmse: 0.0825891\n",
      "[200]\ttraining's rmse: 0.0798906\tvalid_1's rmse: 0.0825557\n",
      "[225]\ttraining's rmse: 0.0798021\tvalid_1's rmse: 0.0825244\n",
      "[250]\ttraining's rmse: 0.0797265\tvalid_1's rmse: 0.0824945\n",
      "[275]\ttraining's rmse: 0.0796544\tvalid_1's rmse: 0.0824684\n",
      "[300]\ttraining's rmse: 0.0795845\tvalid_1's rmse: 0.0824434\n",
      "[325]\ttraining's rmse: 0.0795122\tvalid_1's rmse: 0.0824206\n",
      "[350]\ttraining's rmse: 0.0794458\tvalid_1's rmse: 0.082398\n",
      "[375]\ttraining's rmse: 0.0793898\tvalid_1's rmse: 0.0823786\n",
      "[400]\ttraining's rmse: 0.0793284\tvalid_1's rmse: 0.0823595\n",
      "[425]\ttraining's rmse: 0.0792726\tvalid_1's rmse: 0.082342\n",
      "[450]\ttraining's rmse: 0.0792231\tvalid_1's rmse: 0.0823233\n",
      "[475]\ttraining's rmse: 0.0791767\tvalid_1's rmse: 0.0823075\n",
      "[500]\ttraining's rmse: 0.0791368\tvalid_1's rmse: 0.0822923\n",
      "[525]\ttraining's rmse: 0.0790876\tvalid_1's rmse: 0.0822769\n",
      "[550]\ttraining's rmse: 0.0790412\tvalid_1's rmse: 0.0822618\n",
      "[575]\ttraining's rmse: 0.0789988\tvalid_1's rmse: 0.0822498\n",
      "[600]\ttraining's rmse: 0.0789586\tvalid_1's rmse: 0.0822376\n",
      "[625]\ttraining's rmse: 0.0789268\tvalid_1's rmse: 0.0822274\n",
      "[650]\ttraining's rmse: 0.0788848\tvalid_1's rmse: 0.0822164\n",
      "[675]\ttraining's rmse: 0.0788458\tvalid_1's rmse: 0.0822045\n",
      "[700]\ttraining's rmse: 0.078811\tvalid_1's rmse: 0.0821939\n",
      "[725]\ttraining's rmse: 0.0787754\tvalid_1's rmse: 0.0821837\n",
      "[750]\ttraining's rmse: 0.0787408\tvalid_1's rmse: 0.0821747\n",
      "[775]\ttraining's rmse: 0.0787161\tvalid_1's rmse: 0.0821673\n",
      "[800]\ttraining's rmse: 0.0786844\tvalid_1's rmse: 0.08216\n",
      "[825]\ttraining's rmse: 0.0786549\tvalid_1's rmse: 0.0821511\n",
      "[850]\ttraining's rmse: 0.0786247\tvalid_1's rmse: 0.0821445\n",
      "[875]\ttraining's rmse: 0.0786014\tvalid_1's rmse: 0.0821384\n",
      "[900]\ttraining's rmse: 0.0785739\tvalid_1's rmse: 0.082132\n",
      "[925]\ttraining's rmse: 0.0785491\tvalid_1's rmse: 0.0821259\n",
      "[950]\ttraining's rmse: 0.0785246\tvalid_1's rmse: 0.0821199\n",
      "[975]\ttraining's rmse: 0.0785023\tvalid_1's rmse: 0.0821143\n",
      "[1000]\ttraining's rmse: 0.078482\tvalid_1's rmse: 0.0821088\n",
      "[1025]\ttraining's rmse: 0.078458\tvalid_1's rmse: 0.0821037\n",
      "[1050]\ttraining's rmse: 0.0784378\tvalid_1's rmse: 0.0820969\n",
      "[1075]\ttraining's rmse: 0.0784177\tvalid_1's rmse: 0.0820931\n",
      "[1100]\ttraining's rmse: 0.0784015\tvalid_1's rmse: 0.0820873\n",
      "[1125]\ttraining's rmse: 0.0783849\tvalid_1's rmse: 0.0820816\n",
      "[1150]\ttraining's rmse: 0.078366\tvalid_1's rmse: 0.0820777\n",
      "[1175]\ttraining's rmse: 0.0783505\tvalid_1's rmse: 0.082075\n",
      "[1200]\ttraining's rmse: 0.0783338\tvalid_1's rmse: 0.0820714\n",
      "[1225]\ttraining's rmse: 0.0783173\tvalid_1's rmse: 0.0820667\n",
      "[1250]\ttraining's rmse: 0.0783077\tvalid_1's rmse: 0.0820634\n",
      "[1275]\ttraining's rmse: 0.0782925\tvalid_1's rmse: 0.0820599\n",
      "[1300]\ttraining's rmse: 0.0782807\tvalid_1's rmse: 0.0820569\n",
      "[1325]\ttraining's rmse: 0.0782693\tvalid_1's rmse: 0.0820536\n",
      "[1350]\ttraining's rmse: 0.0782531\tvalid_1's rmse: 0.0820503\n",
      "[1375]\ttraining's rmse: 0.0782425\tvalid_1's rmse: 0.0820469\n",
      "[1400]\ttraining's rmse: 0.0782318\tvalid_1's rmse: 0.0820442\n",
      "[1425]\ttraining's rmse: 0.0782226\tvalid_1's rmse: 0.0820414\n",
      "[1450]\ttraining's rmse: 0.0782101\tvalid_1's rmse: 0.0820397\n",
      "[1475]\ttraining's rmse: 0.0782014\tvalid_1's rmse: 0.0820366\n",
      "[1500]\ttraining's rmse: 0.0781937\tvalid_1's rmse: 0.0820333\n",
      "[1525]\ttraining's rmse: 0.0781832\tvalid_1's rmse: 0.0820315\n",
      "[1550]\ttraining's rmse: 0.0781752\tvalid_1's rmse: 0.0820298\n",
      "[1575]\ttraining's rmse: 0.0781675\tvalid_1's rmse: 0.0820274\n",
      "[1600]\ttraining's rmse: 0.0781621\tvalid_1's rmse: 0.0820255\n",
      "[1625]\ttraining's rmse: 0.0781555\tvalid_1's rmse: 0.0820229\n",
      "[1650]\ttraining's rmse: 0.0781491\tvalid_1's rmse: 0.0820214\n",
      "[1675]\ttraining's rmse: 0.0781444\tvalid_1's rmse: 0.0820198\n",
      "[1700]\ttraining's rmse: 0.0781361\tvalid_1's rmse: 0.0820185\n",
      "[1725]\ttraining's rmse: 0.0781304\tvalid_1's rmse: 0.0820164\n",
      "[1750]\ttraining's rmse: 0.0781239\tvalid_1's rmse: 0.0820138\n",
      "[1775]\ttraining's rmse: 0.0781182\tvalid_1's rmse: 0.0820124\n",
      "[1800]\ttraining's rmse: 0.0781145\tvalid_1's rmse: 0.0820093\n",
      "[1825]\ttraining's rmse: 0.0781088\tvalid_1's rmse: 0.0820081\n",
      "[1850]\ttraining's rmse: 0.0781046\tvalid_1's rmse: 0.0820064\n",
      "[1875]\ttraining's rmse: 0.0780989\tvalid_1's rmse: 0.0820055\n",
      "[1900]\ttraining's rmse: 0.078096\tvalid_1's rmse: 0.082004\n",
      "[1925]\ttraining's rmse: 0.0780918\tvalid_1's rmse: 0.0820036\n",
      "[1950]\ttraining's rmse: 0.0780886\tvalid_1's rmse: 0.0820013\n",
      "[1975]\ttraining's rmse: 0.0780853\tvalid_1's rmse: 0.0820006\n",
      "[2000]\ttraining's rmse: 0.0780812\tvalid_1's rmse: 0.0819993\n",
      "[2025]\ttraining's rmse: 0.0780783\tvalid_1's rmse: 0.0819982\n",
      "[2050]\ttraining's rmse: 0.0780748\tvalid_1's rmse: 0.0819974\n",
      "[2075]\ttraining's rmse: 0.0780713\tvalid_1's rmse: 0.0819962\n",
      "[2100]\ttraining's rmse: 0.0780691\tvalid_1's rmse: 0.0819957\n",
      "[2125]\ttraining's rmse: 0.0780652\tvalid_1's rmse: 0.0819958\n",
      "[2150]\ttraining's rmse: 0.0780613\tvalid_1's rmse: 0.081995\n",
      "[2175]\ttraining's rmse: 0.0780586\tvalid_1's rmse: 0.0819939\n",
      "[2200]\ttraining's rmse: 0.0780563\tvalid_1's rmse: 0.0819935\n",
      "[2225]\ttraining's rmse: 0.0780535\tvalid_1's rmse: 0.0819927\n",
      "[2250]\ttraining's rmse: 0.0780498\tvalid_1's rmse: 0.0819926\n",
      "[2275]\ttraining's rmse: 0.0780471\tvalid_1's rmse: 0.0819915\n",
      "[2300]\ttraining's rmse: 0.0780436\tvalid_1's rmse: 0.0819915\n",
      "[2325]\ttraining's rmse: 0.0780419\tvalid_1's rmse: 0.0819916\n",
      "Early stopping, best iteration is:\n",
      "[2293]\ttraining's rmse: 0.078044\tvalid_1's rmse: 0.0819913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0808419\tvalid_1's rmse: 0.0824542\n",
      "[50]\ttraining's rmse: 0.0807369\tvalid_1's rmse: 0.0824033\n",
      "[75]\ttraining's rmse: 0.0806251\tvalid_1's rmse: 0.0823531\n",
      "[100]\ttraining's rmse: 0.0805243\tvalid_1's rmse: 0.0823092\n",
      "[125]\ttraining's rmse: 0.0804233\tvalid_1's rmse: 0.0822651\n",
      "[150]\ttraining's rmse: 0.080328\tvalid_1's rmse: 0.0822229\n",
      "[175]\ttraining's rmse: 0.080252\tvalid_1's rmse: 0.082189\n",
      "[200]\ttraining's rmse: 0.0801671\tvalid_1's rmse: 0.0821547\n",
      "[225]\ttraining's rmse: 0.080083\tvalid_1's rmse: 0.0821212\n",
      "[250]\ttraining's rmse: 0.0800126\tvalid_1's rmse: 0.0820912\n",
      "[275]\ttraining's rmse: 0.0799451\tvalid_1's rmse: 0.0820635\n",
      "[300]\ttraining's rmse: 0.0798813\tvalid_1's rmse: 0.0820384\n",
      "[325]\ttraining's rmse: 0.0798115\tvalid_1's rmse: 0.0820125\n",
      "[350]\ttraining's rmse: 0.0797468\tvalid_1's rmse: 0.0819895\n",
      "[375]\ttraining's rmse: 0.0796961\tvalid_1's rmse: 0.0819693\n",
      "[400]\ttraining's rmse: 0.0796384\tvalid_1's rmse: 0.08195\n",
      "[425]\ttraining's rmse: 0.0795873\tvalid_1's rmse: 0.0819317\n",
      "[450]\ttraining's rmse: 0.0795381\tvalid_1's rmse: 0.0819132\n",
      "[475]\ttraining's rmse: 0.0794935\tvalid_1's rmse: 0.0818969\n",
      "[500]\ttraining's rmse: 0.0794553\tvalid_1's rmse: 0.0818814\n",
      "[525]\ttraining's rmse: 0.079408\tvalid_1's rmse: 0.0818657\n",
      "[550]\ttraining's rmse: 0.0793636\tvalid_1's rmse: 0.0818514\n",
      "[575]\ttraining's rmse: 0.0793238\tvalid_1's rmse: 0.0818375\n",
      "[600]\ttraining's rmse: 0.079287\tvalid_1's rmse: 0.0818252\n",
      "[625]\ttraining's rmse: 0.0792571\tvalid_1's rmse: 0.0818142\n",
      "[650]\ttraining's rmse: 0.0792168\tvalid_1's rmse: 0.0818016\n",
      "[675]\ttraining's rmse: 0.079177\tvalid_1's rmse: 0.08179\n",
      "[700]\ttraining's rmse: 0.0791437\tvalid_1's rmse: 0.0817797\n",
      "[725]\ttraining's rmse: 0.0791097\tvalid_1's rmse: 0.08177\n",
      "[750]\ttraining's rmse: 0.0790808\tvalid_1's rmse: 0.0817609\n",
      "[775]\ttraining's rmse: 0.0790566\tvalid_1's rmse: 0.0817527\n",
      "[800]\ttraining's rmse: 0.0790258\tvalid_1's rmse: 0.0817446\n",
      "[825]\ttraining's rmse: 0.0790002\tvalid_1's rmse: 0.0817369\n",
      "[850]\ttraining's rmse: 0.0789738\tvalid_1's rmse: 0.081731\n",
      "[875]\ttraining's rmse: 0.0789501\tvalid_1's rmse: 0.0817246\n",
      "[900]\ttraining's rmse: 0.078925\tvalid_1's rmse: 0.0817189\n",
      "[925]\ttraining's rmse: 0.0789016\tvalid_1's rmse: 0.0817132\n",
      "[950]\ttraining's rmse: 0.0788777\tvalid_1's rmse: 0.0817081\n",
      "[975]\ttraining's rmse: 0.0788552\tvalid_1's rmse: 0.0817022\n",
      "[1000]\ttraining's rmse: 0.0788345\tvalid_1's rmse: 0.0816977\n",
      "[1025]\ttraining's rmse: 0.0788118\tvalid_1's rmse: 0.0816933\n",
      "[1050]\ttraining's rmse: 0.078792\tvalid_1's rmse: 0.0816883\n",
      "[1075]\ttraining's rmse: 0.0787731\tvalid_1's rmse: 0.0816848\n",
      "[1100]\ttraining's rmse: 0.0787587\tvalid_1's rmse: 0.0816814\n",
      "[1125]\ttraining's rmse: 0.0787419\tvalid_1's rmse: 0.0816773\n",
      "[1150]\ttraining's rmse: 0.0787241\tvalid_1's rmse: 0.081674\n",
      "[1175]\ttraining's rmse: 0.0787092\tvalid_1's rmse: 0.0816704\n",
      "[1200]\ttraining's rmse: 0.0786951\tvalid_1's rmse: 0.0816671\n",
      "[1225]\ttraining's rmse: 0.0786792\tvalid_1's rmse: 0.081664\n",
      "[1250]\ttraining's rmse: 0.0786648\tvalid_1's rmse: 0.0816605\n",
      "[1275]\ttraining's rmse: 0.0786494\tvalid_1's rmse: 0.0816578\n",
      "[1300]\ttraining's rmse: 0.0786362\tvalid_1's rmse: 0.0816548\n",
      "[1325]\ttraining's rmse: 0.0786214\tvalid_1's rmse: 0.0816517\n",
      "[1350]\ttraining's rmse: 0.0786083\tvalid_1's rmse: 0.0816501\n",
      "[1375]\ttraining's rmse: 0.0785956\tvalid_1's rmse: 0.0816481\n",
      "[1400]\ttraining's rmse: 0.0785895\tvalid_1's rmse: 0.081646\n",
      "[1425]\ttraining's rmse: 0.0785782\tvalid_1's rmse: 0.0816444\n",
      "[1450]\ttraining's rmse: 0.0785666\tvalid_1's rmse: 0.0816425\n",
      "[1475]\ttraining's rmse: 0.0785577\tvalid_1's rmse: 0.0816409\n",
      "[1500]\ttraining's rmse: 0.0785499\tvalid_1's rmse: 0.0816394\n",
      "[1525]\ttraining's rmse: 0.0785405\tvalid_1's rmse: 0.0816374\n",
      "[1550]\ttraining's rmse: 0.078531\tvalid_1's rmse: 0.0816366\n",
      "[1575]\ttraining's rmse: 0.0785229\tvalid_1's rmse: 0.0816348\n",
      "[1600]\ttraining's rmse: 0.0785163\tvalid_1's rmse: 0.0816343\n",
      "[1625]\ttraining's rmse: 0.0785089\tvalid_1's rmse: 0.081633\n",
      "[1650]\ttraining's rmse: 0.0785019\tvalid_1's rmse: 0.0816319\n",
      "[1675]\ttraining's rmse: 0.078496\tvalid_1's rmse: 0.0816308\n",
      "[1700]\ttraining's rmse: 0.0784906\tvalid_1's rmse: 0.0816294\n",
      "[1725]\ttraining's rmse: 0.0784855\tvalid_1's rmse: 0.0816287\n",
      "[1750]\ttraining's rmse: 0.0784789\tvalid_1's rmse: 0.0816279\n",
      "[1775]\ttraining's rmse: 0.0784731\tvalid_1's rmse: 0.081627\n",
      "[1800]\ttraining's rmse: 0.0784666\tvalid_1's rmse: 0.0816255\n",
      "[1825]\ttraining's rmse: 0.0784619\tvalid_1's rmse: 0.0816243\n",
      "[1850]\ttraining's rmse: 0.0784566\tvalid_1's rmse: 0.081623\n",
      "[1875]\ttraining's rmse: 0.0784522\tvalid_1's rmse: 0.0816222\n",
      "[1900]\ttraining's rmse: 0.0784478\tvalid_1's rmse: 0.0816219\n",
      "[1925]\ttraining's rmse: 0.0784441\tvalid_1's rmse: 0.081621\n",
      "[1950]\ttraining's rmse: 0.0784395\tvalid_1's rmse: 0.0816195\n",
      "[1975]\ttraining's rmse: 0.0784355\tvalid_1's rmse: 0.0816188\n",
      "[2000]\ttraining's rmse: 0.0784313\tvalid_1's rmse: 0.0816184\n",
      "[2025]\ttraining's rmse: 0.0784272\tvalid_1's rmse: 0.0816175\n",
      "[2050]\ttraining's rmse: 0.0784236\tvalid_1's rmse: 0.0816171\n",
      "[2075]\ttraining's rmse: 0.0784196\tvalid_1's rmse: 0.0816166\n",
      "[2100]\ttraining's rmse: 0.0784169\tvalid_1's rmse: 0.0816161\n",
      "[2125]\ttraining's rmse: 0.0784136\tvalid_1's rmse: 0.0816158\n",
      "[2150]\ttraining's rmse: 0.0784111\tvalid_1's rmse: 0.0816159\n",
      "[2175]\ttraining's rmse: 0.0784092\tvalid_1's rmse: 0.0816157\n",
      "[2200]\ttraining's rmse: 0.0784066\tvalid_1's rmse: 0.0816154\n",
      "[2225]\ttraining's rmse: 0.0784045\tvalid_1's rmse: 0.0816153\n",
      "[2250]\ttraining's rmse: 0.078402\tvalid_1's rmse: 0.0816152\n",
      "[2275]\ttraining's rmse: 0.0783989\tvalid_1's rmse: 0.0816147\n",
      "[2300]\ttraining's rmse: 0.0783949\tvalid_1's rmse: 0.0816141\n",
      "[2325]\ttraining's rmse: 0.0783916\tvalid_1's rmse: 0.0816136\n",
      "[2350]\ttraining's rmse: 0.0783902\tvalid_1's rmse: 0.0816134\n",
      "[2375]\ttraining's rmse: 0.0783885\tvalid_1's rmse: 0.0816128\n",
      "[2400]\ttraining's rmse: 0.0783857\tvalid_1's rmse: 0.0816125\n",
      "[2425]\ttraining's rmse: 0.0783828\tvalid_1's rmse: 0.0816123\n",
      "[2450]\ttraining's rmse: 0.0783812\tvalid_1's rmse: 0.0816123\n",
      "[2475]\ttraining's rmse: 0.0783787\tvalid_1's rmse: 0.0816124\n",
      "Early stopping, best iteration is:\n",
      "[2441]\ttraining's rmse: 0.0783821\tvalid_1's rmse: 0.0816121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0825331\tvalid_1's rmse: 0.0790181\n",
      "[50]\ttraining's rmse: 0.0824295\tvalid_1's rmse: 0.0789723\n",
      "[75]\ttraining's rmse: 0.0823236\tvalid_1's rmse: 0.0789272\n",
      "[100]\ttraining's rmse: 0.0822269\tvalid_1's rmse: 0.0788863\n",
      "[125]\ttraining's rmse: 0.0821246\tvalid_1's rmse: 0.0788467\n",
      "[150]\ttraining's rmse: 0.0820324\tvalid_1's rmse: 0.0788092\n",
      "[175]\ttraining's rmse: 0.081958\tvalid_1's rmse: 0.0787795\n",
      "[200]\ttraining's rmse: 0.0818759\tvalid_1's rmse: 0.0787501\n",
      "[225]\ttraining's rmse: 0.0817958\tvalid_1's rmse: 0.0787236\n",
      "[250]\ttraining's rmse: 0.0817283\tvalid_1's rmse: 0.0786969\n",
      "[275]\ttraining's rmse: 0.081666\tvalid_1's rmse: 0.0786737\n",
      "[300]\ttraining's rmse: 0.0816039\tvalid_1's rmse: 0.078652\n",
      "[325]\ttraining's rmse: 0.0815408\tvalid_1's rmse: 0.0786298\n",
      "[350]\ttraining's rmse: 0.0814793\tvalid_1's rmse: 0.0786096\n",
      "[375]\ttraining's rmse: 0.08143\tvalid_1's rmse: 0.0785912\n",
      "[400]\ttraining's rmse: 0.0813728\tvalid_1's rmse: 0.0785794\n",
      "[425]\ttraining's rmse: 0.0813231\tvalid_1's rmse: 0.078572\n",
      "[450]\ttraining's rmse: 0.0812773\tvalid_1's rmse: 0.0785597\n",
      "[475]\ttraining's rmse: 0.0812345\tvalid_1's rmse: 0.078557\n",
      "[500]\ttraining's rmse: 0.0811972\tvalid_1's rmse: 0.078545\n",
      "[525]\ttraining's rmse: 0.0811483\tvalid_1's rmse: 0.0785304\n",
      "[550]\ttraining's rmse: 0.0811046\tvalid_1's rmse: 0.0785178\n",
      "[575]\ttraining's rmse: 0.081064\tvalid_1's rmse: 0.0785076\n",
      "[600]\ttraining's rmse: 0.0810239\tvalid_1's rmse: 0.0785044\n",
      "[625]\ttraining's rmse: 0.0809941\tvalid_1's rmse: 0.0785059\n",
      "[650]\ttraining's rmse: 0.0809539\tvalid_1's rmse: 0.0785023\n",
      "[675]\ttraining's rmse: 0.0809125\tvalid_1's rmse: 0.0785059\n",
      "[700]\ttraining's rmse: 0.0808781\tvalid_1's rmse: 0.0784975\n",
      "Early stopping, best iteration is:\n",
      "[670]\ttraining's rmse: 0.0809232\tvalid_1's rmse: 0.0784955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0821672\tvalid_1's rmse: 0.0847222\n",
      "[50]\ttraining's rmse: 0.082041\tvalid_1's rmse: 0.0846729\n",
      "[75]\ttraining's rmse: 0.0819149\tvalid_1's rmse: 0.0846224\n",
      "[100]\ttraining's rmse: 0.0818001\tvalid_1's rmse: 0.0845797\n",
      "[125]\ttraining's rmse: 0.0816829\tvalid_1's rmse: 0.0845364\n",
      "[150]\ttraining's rmse: 0.0815774\tvalid_1's rmse: 0.0844964\n",
      "[175]\ttraining's rmse: 0.0814879\tvalid_1's rmse: 0.0844611\n",
      "[200]\ttraining's rmse: 0.0813949\tvalid_1's rmse: 0.0844272\n",
      "[225]\ttraining's rmse: 0.0813016\tvalid_1's rmse: 0.0843954\n",
      "[250]\ttraining's rmse: 0.0812251\tvalid_1's rmse: 0.0843665\n",
      "[275]\ttraining's rmse: 0.0811517\tvalid_1's rmse: 0.0843399\n",
      "[300]\ttraining's rmse: 0.0810785\tvalid_1's rmse: 0.0843142\n",
      "[325]\ttraining's rmse: 0.0810066\tvalid_1's rmse: 0.0842893\n",
      "[350]\ttraining's rmse: 0.0809383\tvalid_1's rmse: 0.0842664\n",
      "[375]\ttraining's rmse: 0.0808782\tvalid_1's rmse: 0.084247\n",
      "[400]\ttraining's rmse: 0.080812\tvalid_1's rmse: 0.0842264\n",
      "[425]\ttraining's rmse: 0.0807561\tvalid_1's rmse: 0.0842071\n",
      "[450]\ttraining's rmse: 0.0807055\tvalid_1's rmse: 0.0841883\n",
      "[475]\ttraining's rmse: 0.0806594\tvalid_1's rmse: 0.0841718\n",
      "[500]\ttraining's rmse: 0.080618\tvalid_1's rmse: 0.0841562\n",
      "[525]\ttraining's rmse: 0.0805675\tvalid_1's rmse: 0.0841407\n",
      "[550]\ttraining's rmse: 0.0805208\tvalid_1's rmse: 0.084126\n",
      "[575]\ttraining's rmse: 0.0804769\tvalid_1's rmse: 0.084113\n",
      "[600]\ttraining's rmse: 0.080436\tvalid_1's rmse: 0.0841015\n",
      "[625]\ttraining's rmse: 0.080401\tvalid_1's rmse: 0.0840912\n",
      "[650]\ttraining's rmse: 0.0803618\tvalid_1's rmse: 0.0840798\n",
      "[675]\ttraining's rmse: 0.0803214\tvalid_1's rmse: 0.0840684\n",
      "[700]\ttraining's rmse: 0.0802875\tvalid_1's rmse: 0.0840582\n",
      "[725]\ttraining's rmse: 0.0802508\tvalid_1's rmse: 0.0840476\n",
      "[750]\ttraining's rmse: 0.080217\tvalid_1's rmse: 0.0840382\n",
      "[775]\ttraining's rmse: 0.0801914\tvalid_1's rmse: 0.0840289\n",
      "[800]\ttraining's rmse: 0.0801574\tvalid_1's rmse: 0.0840199\n",
      "[825]\ttraining's rmse: 0.0801275\tvalid_1's rmse: 0.084011\n",
      "[850]\ttraining's rmse: 0.0800966\tvalid_1's rmse: 0.0840043\n",
      "[875]\ttraining's rmse: 0.0800708\tvalid_1's rmse: 0.0839972\n",
      "[900]\ttraining's rmse: 0.0800411\tvalid_1's rmse: 0.0839893\n",
      "[925]\ttraining's rmse: 0.0800165\tvalid_1's rmse: 0.0839828\n",
      "[950]\ttraining's rmse: 0.0799952\tvalid_1's rmse: 0.0839763\n",
      "[975]\ttraining's rmse: 0.0799708\tvalid_1's rmse: 0.0839703\n",
      "[1000]\ttraining's rmse: 0.0799481\tvalid_1's rmse: 0.0839644\n",
      "[1025]\ttraining's rmse: 0.0799242\tvalid_1's rmse: 0.0839596\n",
      "[1050]\ttraining's rmse: 0.079904\tvalid_1's rmse: 0.0839534\n",
      "[1075]\ttraining's rmse: 0.0798837\tvalid_1's rmse: 0.0839493\n",
      "[1100]\ttraining's rmse: 0.0798664\tvalid_1's rmse: 0.0839442\n",
      "[1125]\ttraining's rmse: 0.079848\tvalid_1's rmse: 0.0839378\n",
      "[1150]\ttraining's rmse: 0.0798318\tvalid_1's rmse: 0.0839341\n",
      "[1175]\ttraining's rmse: 0.0798149\tvalid_1's rmse: 0.0839306\n",
      "[1200]\ttraining's rmse: 0.0798007\tvalid_1's rmse: 0.0839258\n",
      "[1225]\ttraining's rmse: 0.0797843\tvalid_1's rmse: 0.0839213\n",
      "[1250]\ttraining's rmse: 0.0797714\tvalid_1's rmse: 0.0839171\n",
      "[1275]\ttraining's rmse: 0.0797528\tvalid_1's rmse: 0.083913\n",
      "[1300]\ttraining's rmse: 0.0797393\tvalid_1's rmse: 0.0839073\n",
      "[1325]\ttraining's rmse: 0.0797259\tvalid_1's rmse: 0.083904\n",
      "[1350]\ttraining's rmse: 0.0797117\tvalid_1's rmse: 0.0838999\n",
      "[1375]\ttraining's rmse: 0.0796987\tvalid_1's rmse: 0.0838975\n",
      "[1400]\ttraining's rmse: 0.079687\tvalid_1's rmse: 0.083894\n",
      "[1425]\ttraining's rmse: 0.0796743\tvalid_1's rmse: 0.0838914\n",
      "[1450]\ttraining's rmse: 0.0796615\tvalid_1's rmse: 0.0838896\n",
      "[1475]\ttraining's rmse: 0.0796512\tvalid_1's rmse: 0.083887\n",
      "[1500]\ttraining's rmse: 0.0796434\tvalid_1's rmse: 0.0838841\n",
      "[1525]\ttraining's rmse: 0.0796321\tvalid_1's rmse: 0.0838815\n",
      "[1550]\ttraining's rmse: 0.0796227\tvalid_1's rmse: 0.0838795\n",
      "[1575]\ttraining's rmse: 0.0796159\tvalid_1's rmse: 0.0838771\n",
      "[1600]\ttraining's rmse: 0.0796099\tvalid_1's rmse: 0.0838752\n",
      "[1625]\ttraining's rmse: 0.0796008\tvalid_1's rmse: 0.0838718\n",
      "[1650]\ttraining's rmse: 0.0795941\tvalid_1's rmse: 0.0838685\n",
      "[1675]\ttraining's rmse: 0.0795904\tvalid_1's rmse: 0.0838662\n",
      "[1700]\ttraining's rmse: 0.0795857\tvalid_1's rmse: 0.0838645\n",
      "[1725]\ttraining's rmse: 0.0795807\tvalid_1's rmse: 0.0838628\n",
      "[1750]\ttraining's rmse: 0.0795736\tvalid_1's rmse: 0.0838602\n",
      "[1775]\ttraining's rmse: 0.0795663\tvalid_1's rmse: 0.083859\n",
      "[1800]\ttraining's rmse: 0.0795617\tvalid_1's rmse: 0.0838573\n",
      "[1825]\ttraining's rmse: 0.0795546\tvalid_1's rmse: 0.0838558\n",
      "[1850]\ttraining's rmse: 0.0795503\tvalid_1's rmse: 0.0838542\n",
      "[1875]\ttraining's rmse: 0.0795446\tvalid_1's rmse: 0.0838526\n",
      "[1900]\ttraining's rmse: 0.0795402\tvalid_1's rmse: 0.083851\n",
      "[1925]\ttraining's rmse: 0.0795359\tvalid_1's rmse: 0.0838498\n",
      "[1950]\ttraining's rmse: 0.0795312\tvalid_1's rmse: 0.0838489\n",
      "[1975]\ttraining's rmse: 0.0795276\tvalid_1's rmse: 0.0838475\n",
      "[2000]\ttraining's rmse: 0.0795248\tvalid_1's rmse: 0.0838469\n",
      "[2025]\ttraining's rmse: 0.0795216\tvalid_1's rmse: 0.0838453\n",
      "[2050]\ttraining's rmse: 0.0795168\tvalid_1's rmse: 0.0838447\n",
      "[2075]\ttraining's rmse: 0.0795142\tvalid_1's rmse: 0.0838436\n",
      "[2100]\ttraining's rmse: 0.0795103\tvalid_1's rmse: 0.0838429\n",
      "[2125]\ttraining's rmse: 0.079508\tvalid_1's rmse: 0.0838421\n",
      "[2150]\ttraining's rmse: 0.0795041\tvalid_1's rmse: 0.0838414\n",
      "[2175]\ttraining's rmse: 0.0795012\tvalid_1's rmse: 0.0838407\n",
      "[2200]\ttraining's rmse: 0.0794976\tvalid_1's rmse: 0.0838399\n",
      "[2225]\ttraining's rmse: 0.0794953\tvalid_1's rmse: 0.0838389\n",
      "[2250]\ttraining's rmse: 0.079493\tvalid_1's rmse: 0.0838382\n",
      "[2275]\ttraining's rmse: 0.0794899\tvalid_1's rmse: 0.0838378\n",
      "[2300]\ttraining's rmse: 0.0794878\tvalid_1's rmse: 0.0838364\n",
      "[2325]\ttraining's rmse: 0.0794834\tvalid_1's rmse: 0.0838356\n",
      "[2350]\ttraining's rmse: 0.0794811\tvalid_1's rmse: 0.0838348\n",
      "[2375]\ttraining's rmse: 0.0794791\tvalid_1's rmse: 0.0838343\n",
      "[2400]\ttraining's rmse: 0.079476\tvalid_1's rmse: 0.0838332\n",
      "[2425]\ttraining's rmse: 0.0794742\tvalid_1's rmse: 0.083833\n",
      "[2450]\ttraining's rmse: 0.0794726\tvalid_1's rmse: 0.0838321\n",
      "[2475]\ttraining's rmse: 0.0794705\tvalid_1's rmse: 0.0838316\n",
      "[2500]\ttraining's rmse: 0.079468\tvalid_1's rmse: 0.0838307\n",
      "[2525]\ttraining's rmse: 0.0794649\tvalid_1's rmse: 0.0838304\n",
      "[2550]\ttraining's rmse: 0.0794629\tvalid_1's rmse: 0.0838305\n",
      "[2575]\ttraining's rmse: 0.0794601\tvalid_1's rmse: 0.0838304\n",
      "[2600]\ttraining's rmse: 0.0794585\tvalid_1's rmse: 0.0838303\n",
      "[2625]\ttraining's rmse: 0.0794573\tvalid_1's rmse: 0.0838292\n",
      "[2650]\ttraining's rmse: 0.079455\tvalid_1's rmse: 0.0838293\n",
      "[2675]\ttraining's rmse: 0.0794522\tvalid_1's rmse: 0.0838292\n",
      "Early stopping, best iteration is:\n",
      "[2632]\ttraining's rmse: 0.0794559\tvalid_1's rmse: 0.0838291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0825119\tvalid_1's rmse: 0.0840657\n",
      "[50]\ttraining's rmse: 0.0823983\tvalid_1's rmse: 0.084013\n",
      "[75]\ttraining's rmse: 0.0822812\tvalid_1's rmse: 0.0839603\n",
      "[100]\ttraining's rmse: 0.0821763\tvalid_1's rmse: 0.0839129\n",
      "[125]\ttraining's rmse: 0.0820672\tvalid_1's rmse: 0.0838673\n",
      "[150]\ttraining's rmse: 0.0819688\tvalid_1's rmse: 0.0838237\n",
      "[175]\ttraining's rmse: 0.0818875\tvalid_1's rmse: 0.0837888\n",
      "[200]\ttraining's rmse: 0.0817991\tvalid_1's rmse: 0.0837526\n",
      "[225]\ttraining's rmse: 0.0817137\tvalid_1's rmse: 0.0837205\n",
      "[250]\ttraining's rmse: 0.0816417\tvalid_1's rmse: 0.08369\n",
      "[275]\ttraining's rmse: 0.0815744\tvalid_1's rmse: 0.083664\n",
      "[300]\ttraining's rmse: 0.0815065\tvalid_1's rmse: 0.0836371\n",
      "[325]\ttraining's rmse: 0.0814375\tvalid_1's rmse: 0.0836107\n",
      "[350]\ttraining's rmse: 0.0813705\tvalid_1's rmse: 0.0835866\n",
      "[375]\ttraining's rmse: 0.0813155\tvalid_1's rmse: 0.0835658\n",
      "[400]\ttraining's rmse: 0.0812554\tvalid_1's rmse: 0.0835464\n",
      "[425]\ttraining's rmse: 0.0811999\tvalid_1's rmse: 0.0835266\n",
      "[450]\ttraining's rmse: 0.0811493\tvalid_1's rmse: 0.0835093\n",
      "[475]\ttraining's rmse: 0.0811027\tvalid_1's rmse: 0.083493\n",
      "[500]\ttraining's rmse: 0.0810615\tvalid_1's rmse: 0.0834767\n",
      "[525]\ttraining's rmse: 0.0810094\tvalid_1's rmse: 0.0834601\n",
      "[550]\ttraining's rmse: 0.0809637\tvalid_1's rmse: 0.0834448\n",
      "[575]\ttraining's rmse: 0.0809193\tvalid_1's rmse: 0.0834309\n",
      "[600]\ttraining's rmse: 0.0808782\tvalid_1's rmse: 0.0834184\n",
      "[625]\ttraining's rmse: 0.0808465\tvalid_1's rmse: 0.0834069\n",
      "[650]\ttraining's rmse: 0.0808052\tvalid_1's rmse: 0.0833952\n",
      "[675]\ttraining's rmse: 0.0807643\tvalid_1's rmse: 0.0833847\n",
      "[700]\ttraining's rmse: 0.0807295\tvalid_1's rmse: 0.0833738\n",
      "[725]\ttraining's rmse: 0.0806971\tvalid_1's rmse: 0.083365\n",
      "[750]\ttraining's rmse: 0.080666\tvalid_1's rmse: 0.0833559\n",
      "[775]\ttraining's rmse: 0.0806403\tvalid_1's rmse: 0.0833477\n",
      "[800]\ttraining's rmse: 0.0806066\tvalid_1's rmse: 0.08334\n",
      "[825]\ttraining's rmse: 0.0805804\tvalid_1's rmse: 0.0833317\n",
      "[850]\ttraining's rmse: 0.0805516\tvalid_1's rmse: 0.0833246\n",
      "[875]\ttraining's rmse: 0.0805262\tvalid_1's rmse: 0.083318\n",
      "[900]\ttraining's rmse: 0.0804994\tvalid_1's rmse: 0.0833113\n",
      "[925]\ttraining's rmse: 0.080474\tvalid_1's rmse: 0.0833054\n",
      "[950]\ttraining's rmse: 0.0804502\tvalid_1's rmse: 0.0832999\n",
      "[975]\ttraining's rmse: 0.0804265\tvalid_1's rmse: 0.0832945\n",
      "[1000]\ttraining's rmse: 0.0804063\tvalid_1's rmse: 0.0832888\n",
      "[1025]\ttraining's rmse: 0.0803832\tvalid_1's rmse: 0.0832843\n",
      "[1050]\ttraining's rmse: 0.0803627\tvalid_1's rmse: 0.083279\n",
      "[1075]\ttraining's rmse: 0.0803411\tvalid_1's rmse: 0.0832754\n",
      "[1100]\ttraining's rmse: 0.0803248\tvalid_1's rmse: 0.0832715\n",
      "[1125]\ttraining's rmse: 0.0803074\tvalid_1's rmse: 0.0832676\n",
      "[1150]\ttraining's rmse: 0.0802901\tvalid_1's rmse: 0.0832632\n",
      "[1175]\ttraining's rmse: 0.0802752\tvalid_1's rmse: 0.08326\n",
      "[1200]\ttraining's rmse: 0.0802582\tvalid_1's rmse: 0.0832567\n",
      "[1225]\ttraining's rmse: 0.0802414\tvalid_1's rmse: 0.0832536\n",
      "[1250]\ttraining's rmse: 0.0802261\tvalid_1's rmse: 0.0832511\n",
      "[1275]\ttraining's rmse: 0.0802102\tvalid_1's rmse: 0.083249\n",
      "[1300]\ttraining's rmse: 0.0801978\tvalid_1's rmse: 0.083246\n",
      "[1325]\ttraining's rmse: 0.080185\tvalid_1's rmse: 0.0832439\n",
      "[1350]\ttraining's rmse: 0.0801721\tvalid_1's rmse: 0.0832419\n",
      "[1375]\ttraining's rmse: 0.0801599\tvalid_1's rmse: 0.0832403\n",
      "[1400]\ttraining's rmse: 0.0801494\tvalid_1's rmse: 0.0832377\n",
      "[1425]\ttraining's rmse: 0.0801375\tvalid_1's rmse: 0.0832353\n",
      "[1450]\ttraining's rmse: 0.0801251\tvalid_1's rmse: 0.0832335\n",
      "[1475]\ttraining's rmse: 0.0801158\tvalid_1's rmse: 0.0832318\n",
      "[1500]\ttraining's rmse: 0.0801061\tvalid_1's rmse: 0.0832303\n",
      "[1525]\ttraining's rmse: 0.0800976\tvalid_1's rmse: 0.0832287\n",
      "[1550]\ttraining's rmse: 0.080089\tvalid_1's rmse: 0.0832277\n",
      "[1575]\ttraining's rmse: 0.0800786\tvalid_1's rmse: 0.0832258\n",
      "[1600]\ttraining's rmse: 0.0800699\tvalid_1's rmse: 0.0832246\n",
      "[1625]\ttraining's rmse: 0.0800618\tvalid_1's rmse: 0.0832232\n",
      "[1650]\ttraining's rmse: 0.0800546\tvalid_1's rmse: 0.0832223\n",
      "[1675]\ttraining's rmse: 0.0800489\tvalid_1's rmse: 0.0832208\n",
      "[1700]\ttraining's rmse: 0.0800433\tvalid_1's rmse: 0.0832195\n",
      "[1725]\ttraining's rmse: 0.0800365\tvalid_1's rmse: 0.0832186\n",
      "[1750]\ttraining's rmse: 0.0800308\tvalid_1's rmse: 0.0832177\n",
      "[1775]\ttraining's rmse: 0.080025\tvalid_1's rmse: 0.0832173\n",
      "[1800]\ttraining's rmse: 0.0800205\tvalid_1's rmse: 0.0832166\n",
      "[1825]\ttraining's rmse: 0.0800131\tvalid_1's rmse: 0.0832156\n",
      "[1850]\ttraining's rmse: 0.0800081\tvalid_1's rmse: 0.0832148\n",
      "[1875]\ttraining's rmse: 0.0800024\tvalid_1's rmse: 0.0832139\n",
      "[1900]\ttraining's rmse: 0.0799995\tvalid_1's rmse: 0.0832139\n",
      "[1925]\ttraining's rmse: 0.079995\tvalid_1's rmse: 0.0832136\n",
      "[1950]\ttraining's rmse: 0.0799923\tvalid_1's rmse: 0.0832129\n",
      "[1975]\ttraining's rmse: 0.0799887\tvalid_1's rmse: 0.0832126\n",
      "[2000]\ttraining's rmse: 0.0799849\tvalid_1's rmse: 0.083212\n",
      "[2025]\ttraining's rmse: 0.079981\tvalid_1's rmse: 0.0832112\n",
      "[2050]\ttraining's rmse: 0.0799767\tvalid_1's rmse: 0.0832109\n",
      "[2075]\ttraining's rmse: 0.0799743\tvalid_1's rmse: 0.0832107\n",
      "[2100]\ttraining's rmse: 0.0799708\tvalid_1's rmse: 0.0832105\n",
      "[2125]\ttraining's rmse: 0.079968\tvalid_1's rmse: 0.0832101\n",
      "[2150]\ttraining's rmse: 0.0799651\tvalid_1's rmse: 0.0832104\n",
      "[2175]\ttraining's rmse: 0.0799618\tvalid_1's rmse: 0.0832104\n",
      "Early stopping, best iteration is:\n",
      "[2128]\ttraining's rmse: 0.0799677\tvalid_1's rmse: 0.0832101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0842803\tvalid_1's rmse: 0.0804783\n",
      "[50]\ttraining's rmse: 0.0841723\tvalid_1's rmse: 0.0804326\n",
      "[75]\ttraining's rmse: 0.084061\tvalid_1's rmse: 0.080386\n",
      "[100]\ttraining's rmse: 0.08396\tvalid_1's rmse: 0.0803456\n",
      "[125]\ttraining's rmse: 0.0838587\tvalid_1's rmse: 0.0803052\n",
      "[150]\ttraining's rmse: 0.0837607\tvalid_1's rmse: 0.0802667\n",
      "[175]\ttraining's rmse: 0.0836817\tvalid_1's rmse: 0.080236\n",
      "[200]\ttraining's rmse: 0.0835968\tvalid_1's rmse: 0.0802062\n",
      "[225]\ttraining's rmse: 0.0835123\tvalid_1's rmse: 0.0801769\n",
      "[250]\ttraining's rmse: 0.0834438\tvalid_1's rmse: 0.0801526\n",
      "[275]\ttraining's rmse: 0.0833798\tvalid_1's rmse: 0.0801285\n",
      "[300]\ttraining's rmse: 0.0833155\tvalid_1's rmse: 0.0801051\n",
      "[325]\ttraining's rmse: 0.0832484\tvalid_1's rmse: 0.0800822\n",
      "[350]\ttraining's rmse: 0.0831858\tvalid_1's rmse: 0.0800613\n",
      "[375]\ttraining's rmse: 0.0831314\tvalid_1's rmse: 0.0800447\n",
      "[400]\ttraining's rmse: 0.0830737\tvalid_1's rmse: 0.0800322\n",
      "[425]\ttraining's rmse: 0.0830207\tvalid_1's rmse: 0.0800213\n",
      "[450]\ttraining's rmse: 0.0829729\tvalid_1's rmse: 0.0800087\n",
      "[475]\ttraining's rmse: 0.0829278\tvalid_1's rmse: 0.0799953\n",
      "[500]\ttraining's rmse: 0.0828898\tvalid_1's rmse: 0.0799825\n",
      "[525]\ttraining's rmse: 0.0828401\tvalid_1's rmse: 0.0799686\n",
      "[550]\ttraining's rmse: 0.0827958\tvalid_1's rmse: 0.0799602\n",
      "[575]\ttraining's rmse: 0.0827527\tvalid_1's rmse: 0.0799495\n",
      "[600]\ttraining's rmse: 0.0827117\tvalid_1's rmse: 0.0799446\n",
      "[625]\ttraining's rmse: 0.08268\tvalid_1's rmse: 0.0799359\n",
      "[650]\ttraining's rmse: 0.0826397\tvalid_1's rmse: 0.0799321\n",
      "[675]\ttraining's rmse: 0.0825993\tvalid_1's rmse: 0.0799338\n",
      "[700]\ttraining's rmse: 0.0825636\tvalid_1's rmse: 0.0799259\n",
      "[725]\ttraining's rmse: 0.0825296\tvalid_1's rmse: 0.0799455\n",
      "[750]\ttraining's rmse: 0.0824995\tvalid_1's rmse: 0.0799489\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0825574\tvalid_1's rmse: 0.0799248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0837883\tvalid_1's rmse: 0.0862195\n",
      "[50]\ttraining's rmse: 0.0836631\tvalid_1's rmse: 0.0861682\n",
      "[75]\ttraining's rmse: 0.0835377\tvalid_1's rmse: 0.0861163\n",
      "[100]\ttraining's rmse: 0.0834239\tvalid_1's rmse: 0.0860728\n",
      "[125]\ttraining's rmse: 0.0833052\tvalid_1's rmse: 0.0860271\n",
      "[150]\ttraining's rmse: 0.0831956\tvalid_1's rmse: 0.0859852\n",
      "[175]\ttraining's rmse: 0.0831078\tvalid_1's rmse: 0.0859493\n",
      "[200]\ttraining's rmse: 0.0830131\tvalid_1's rmse: 0.0859137\n",
      "[225]\ttraining's rmse: 0.0829215\tvalid_1's rmse: 0.085881\n",
      "[250]\ttraining's rmse: 0.0828393\tvalid_1's rmse: 0.0858499\n",
      "[275]\ttraining's rmse: 0.0827637\tvalid_1's rmse: 0.0858222\n",
      "[300]\ttraining's rmse: 0.0826927\tvalid_1's rmse: 0.0857937\n",
      "[325]\ttraining's rmse: 0.082624\tvalid_1's rmse: 0.0857694\n",
      "[350]\ttraining's rmse: 0.0825556\tvalid_1's rmse: 0.0857439\n",
      "[375]\ttraining's rmse: 0.0824948\tvalid_1's rmse: 0.0857238\n",
      "[400]\ttraining's rmse: 0.0824295\tvalid_1's rmse: 0.0857025\n",
      "[425]\ttraining's rmse: 0.0823733\tvalid_1's rmse: 0.0856832\n",
      "[450]\ttraining's rmse: 0.0823206\tvalid_1's rmse: 0.0856636\n",
      "[475]\ttraining's rmse: 0.0822703\tvalid_1's rmse: 0.0856469\n",
      "[500]\ttraining's rmse: 0.0822294\tvalid_1's rmse: 0.0856306\n",
      "[525]\ttraining's rmse: 0.0821768\tvalid_1's rmse: 0.085614\n",
      "[550]\ttraining's rmse: 0.0821305\tvalid_1's rmse: 0.0855994\n",
      "[575]\ttraining's rmse: 0.0820862\tvalid_1's rmse: 0.0855848\n",
      "[600]\ttraining's rmse: 0.0820443\tvalid_1's rmse: 0.0855718\n",
      "[625]\ttraining's rmse: 0.0820102\tvalid_1's rmse: 0.08556\n",
      "[650]\ttraining's rmse: 0.0819708\tvalid_1's rmse: 0.0855485\n",
      "[675]\ttraining's rmse: 0.0819299\tvalid_1's rmse: 0.085536\n",
      "[700]\ttraining's rmse: 0.081894\tvalid_1's rmse: 0.0855258\n",
      "[725]\ttraining's rmse: 0.0818585\tvalid_1's rmse: 0.0855163\n",
      "[750]\ttraining's rmse: 0.0818226\tvalid_1's rmse: 0.0855068\n",
      "[775]\ttraining's rmse: 0.0817965\tvalid_1's rmse: 0.0854974\n",
      "[800]\ttraining's rmse: 0.0817616\tvalid_1's rmse: 0.0854888\n",
      "[825]\ttraining's rmse: 0.081732\tvalid_1's rmse: 0.0854799\n",
      "[850]\ttraining's rmse: 0.0817005\tvalid_1's rmse: 0.0854725\n",
      "[875]\ttraining's rmse: 0.081673\tvalid_1's rmse: 0.0854657\n",
      "[900]\ttraining's rmse: 0.0816447\tvalid_1's rmse: 0.0854587\n",
      "[925]\ttraining's rmse: 0.0816202\tvalid_1's rmse: 0.0854523\n",
      "[950]\ttraining's rmse: 0.0815974\tvalid_1's rmse: 0.085446\n",
      "[975]\ttraining's rmse: 0.0815735\tvalid_1's rmse: 0.0854406\n",
      "[1000]\ttraining's rmse: 0.081551\tvalid_1's rmse: 0.0854349\n",
      "[1025]\ttraining's rmse: 0.0815247\tvalid_1's rmse: 0.0854273\n",
      "[1050]\ttraining's rmse: 0.0815028\tvalid_1's rmse: 0.0854209\n",
      "[1075]\ttraining's rmse: 0.0814819\tvalid_1's rmse: 0.0854175\n",
      "[1100]\ttraining's rmse: 0.0814624\tvalid_1's rmse: 0.0854125\n",
      "[1125]\ttraining's rmse: 0.0814444\tvalid_1's rmse: 0.0854062\n",
      "[1150]\ttraining's rmse: 0.0814258\tvalid_1's rmse: 0.0854007\n",
      "[1175]\ttraining's rmse: 0.0814096\tvalid_1's rmse: 0.0853967\n",
      "[1200]\ttraining's rmse: 0.0813912\tvalid_1's rmse: 0.0853917\n",
      "[1225]\ttraining's rmse: 0.0813735\tvalid_1's rmse: 0.0853877\n",
      "[1250]\ttraining's rmse: 0.0813578\tvalid_1's rmse: 0.0853848\n",
      "[1275]\ttraining's rmse: 0.0813388\tvalid_1's rmse: 0.0853822\n",
      "[1300]\ttraining's rmse: 0.0813266\tvalid_1's rmse: 0.0853779\n",
      "[1325]\ttraining's rmse: 0.0813144\tvalid_1's rmse: 0.0853751\n",
      "[1350]\ttraining's rmse: 0.0813006\tvalid_1's rmse: 0.0853715\n",
      "[1375]\ttraining's rmse: 0.0812875\tvalid_1's rmse: 0.0853695\n",
      "[1400]\ttraining's rmse: 0.081278\tvalid_1's rmse: 0.0853666\n",
      "[1425]\ttraining's rmse: 0.0812656\tvalid_1's rmse: 0.0853635\n",
      "[1450]\ttraining's rmse: 0.0812524\tvalid_1's rmse: 0.0853619\n",
      "[1475]\ttraining's rmse: 0.0812432\tvalid_1's rmse: 0.0853578\n",
      "[1500]\ttraining's rmse: 0.0812345\tvalid_1's rmse: 0.0853544\n",
      "[1525]\ttraining's rmse: 0.0812268\tvalid_1's rmse: 0.0853514\n",
      "[1550]\ttraining's rmse: 0.0812179\tvalid_1's rmse: 0.0853484\n",
      "[1575]\ttraining's rmse: 0.0812113\tvalid_1's rmse: 0.0853474\n",
      "[1600]\ttraining's rmse: 0.0812042\tvalid_1's rmse: 0.0853437\n",
      "[1625]\ttraining's rmse: 0.0811973\tvalid_1's rmse: 0.0853412\n",
      "[1650]\ttraining's rmse: 0.0811908\tvalid_1's rmse: 0.0853391\n",
      "[1675]\ttraining's rmse: 0.0811842\tvalid_1's rmse: 0.0853367\n",
      "[1700]\ttraining's rmse: 0.0811767\tvalid_1's rmse: 0.0853344\n",
      "[1725]\ttraining's rmse: 0.0811699\tvalid_1's rmse: 0.0853323\n",
      "[1750]\ttraining's rmse: 0.0811629\tvalid_1's rmse: 0.0853297\n",
      "[1775]\ttraining's rmse: 0.0811578\tvalid_1's rmse: 0.0853284\n",
      "[1800]\ttraining's rmse: 0.0811521\tvalid_1's rmse: 0.0853259\n",
      "[1825]\ttraining's rmse: 0.0811463\tvalid_1's rmse: 0.0853247\n",
      "[1850]\ttraining's rmse: 0.0811415\tvalid_1's rmse: 0.0853235\n",
      "[1875]\ttraining's rmse: 0.0811368\tvalid_1's rmse: 0.0853226\n",
      "[1900]\ttraining's rmse: 0.0811326\tvalid_1's rmse: 0.0853215\n",
      "[1925]\ttraining's rmse: 0.081128\tvalid_1's rmse: 0.0853206\n",
      "[1950]\ttraining's rmse: 0.0811242\tvalid_1's rmse: 0.0853195\n",
      "[1975]\ttraining's rmse: 0.0811194\tvalid_1's rmse: 0.0853171\n",
      "[2000]\ttraining's rmse: 0.0811145\tvalid_1's rmse: 0.085316\n",
      "[2025]\ttraining's rmse: 0.0811086\tvalid_1's rmse: 0.085314\n",
      "[2050]\ttraining's rmse: 0.0811049\tvalid_1's rmse: 0.0853123\n",
      "[2075]\ttraining's rmse: 0.0811015\tvalid_1's rmse: 0.0853111\n",
      "[2100]\ttraining's rmse: 0.0810986\tvalid_1's rmse: 0.0853106\n",
      "[2125]\ttraining's rmse: 0.0810946\tvalid_1's rmse: 0.0853091\n",
      "[2150]\ttraining's rmse: 0.0810908\tvalid_1's rmse: 0.0853087\n",
      "[2175]\ttraining's rmse: 0.0810885\tvalid_1's rmse: 0.0853073\n",
      "[2200]\ttraining's rmse: 0.0810856\tvalid_1's rmse: 0.0853069\n",
      "[2225]\ttraining's rmse: 0.0810822\tvalid_1's rmse: 0.0853064\n",
      "[2250]\ttraining's rmse: 0.0810796\tvalid_1's rmse: 0.0853061\n",
      "[2275]\ttraining's rmse: 0.0810767\tvalid_1's rmse: 0.0853056\n",
      "[2300]\ttraining's rmse: 0.0810744\tvalid_1's rmse: 0.0853045\n",
      "[2325]\ttraining's rmse: 0.0810717\tvalid_1's rmse: 0.0853036\n",
      "[2350]\ttraining's rmse: 0.0810693\tvalid_1's rmse: 0.0853027\n",
      "[2375]\ttraining's rmse: 0.0810671\tvalid_1's rmse: 0.0853019\n",
      "[2400]\ttraining's rmse: 0.0810637\tvalid_1's rmse: 0.085302\n",
      "[2425]\ttraining's rmse: 0.081061\tvalid_1's rmse: 0.0853016\n",
      "[2450]\ttraining's rmse: 0.0810579\tvalid_1's rmse: 0.0853019\n",
      "[2475]\ttraining's rmse: 0.0810553\tvalid_1's rmse: 0.0853011\n",
      "[2500]\ttraining's rmse: 0.0810533\tvalid_1's rmse: 0.0853006\n",
      "[2525]\ttraining's rmse: 0.0810508\tvalid_1's rmse: 0.0852999\n",
      "[2550]\ttraining's rmse: 0.081048\tvalid_1's rmse: 0.085299\n",
      "[2575]\ttraining's rmse: 0.0810456\tvalid_1's rmse: 0.0852987\n",
      "[2600]\ttraining's rmse: 0.0810431\tvalid_1's rmse: 0.0852982\n",
      "[2625]\ttraining's rmse: 0.0810419\tvalid_1's rmse: 0.0852974\n",
      "[2650]\ttraining's rmse: 0.0810406\tvalid_1's rmse: 0.0852966\n",
      "[2675]\ttraining's rmse: 0.081038\tvalid_1's rmse: 0.0852964\n",
      "[2700]\ttraining's rmse: 0.0810367\tvalid_1's rmse: 0.0852961\n",
      "[2725]\ttraining's rmse: 0.0810341\tvalid_1's rmse: 0.0852958\n",
      "[2750]\ttraining's rmse: 0.0810324\tvalid_1's rmse: 0.0852954\n",
      "[2775]\ttraining's rmse: 0.0810312\tvalid_1's rmse: 0.0852954\n",
      "[2800]\ttraining's rmse: 0.0810306\tvalid_1's rmse: 0.0852956\n",
      "Early stopping, best iteration is:\n",
      "[2771]\ttraining's rmse: 0.0810313\tvalid_1's rmse: 0.0852953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0838935\tvalid_1's rmse: 0.0860316\n",
      "[50]\ttraining's rmse: 0.0837777\tvalid_1's rmse: 0.0859779\n",
      "[75]\ttraining's rmse: 0.0836582\tvalid_1's rmse: 0.0859273\n",
      "[100]\ttraining's rmse: 0.0835525\tvalid_1's rmse: 0.0858829\n",
      "[125]\ttraining's rmse: 0.0834442\tvalid_1's rmse: 0.0858364\n",
      "[150]\ttraining's rmse: 0.0833412\tvalid_1's rmse: 0.0857926\n",
      "[175]\ttraining's rmse: 0.0832568\tvalid_1's rmse: 0.0857574\n",
      "[200]\ttraining's rmse: 0.0831663\tvalid_1's rmse: 0.0857207\n",
      "[225]\ttraining's rmse: 0.0830789\tvalid_1's rmse: 0.0856882\n",
      "[250]\ttraining's rmse: 0.0830018\tvalid_1's rmse: 0.0856575\n",
      "[275]\ttraining's rmse: 0.0829331\tvalid_1's rmse: 0.0856291\n",
      "[300]\ttraining's rmse: 0.0828596\tvalid_1's rmse: 0.0856031\n",
      "[325]\ttraining's rmse: 0.082789\tvalid_1's rmse: 0.0855777\n",
      "[350]\ttraining's rmse: 0.0827222\tvalid_1's rmse: 0.0855542\n",
      "[375]\ttraining's rmse: 0.0826661\tvalid_1's rmse: 0.0855337\n",
      "[400]\ttraining's rmse: 0.0826045\tvalid_1's rmse: 0.0855131\n",
      "[425]\ttraining's rmse: 0.08255\tvalid_1's rmse: 0.0854949\n",
      "[450]\ttraining's rmse: 0.0824986\tvalid_1's rmse: 0.0854763\n",
      "[475]\ttraining's rmse: 0.0824536\tvalid_1's rmse: 0.0854604\n",
      "[500]\ttraining's rmse: 0.0824129\tvalid_1's rmse: 0.0854447\n",
      "[525]\ttraining's rmse: 0.0823603\tvalid_1's rmse: 0.0854285\n",
      "[550]\ttraining's rmse: 0.0823109\tvalid_1's rmse: 0.0854131\n",
      "[575]\ttraining's rmse: 0.0822656\tvalid_1's rmse: 0.0853984\n",
      "[600]\ttraining's rmse: 0.0822213\tvalid_1's rmse: 0.0853865\n",
      "[625]\ttraining's rmse: 0.0821893\tvalid_1's rmse: 0.0853752\n",
      "[650]\ttraining's rmse: 0.0821467\tvalid_1's rmse: 0.0853636\n",
      "[675]\ttraining's rmse: 0.0821055\tvalid_1's rmse: 0.0853525\n",
      "[700]\ttraining's rmse: 0.082069\tvalid_1's rmse: 0.0853417\n",
      "[725]\ttraining's rmse: 0.0820348\tvalid_1's rmse: 0.0853322\n",
      "[750]\ttraining's rmse: 0.082001\tvalid_1's rmse: 0.0853228\n",
      "[775]\ttraining's rmse: 0.0819733\tvalid_1's rmse: 0.0853142\n",
      "[800]\ttraining's rmse: 0.0819391\tvalid_1's rmse: 0.0853064\n",
      "[825]\ttraining's rmse: 0.081909\tvalid_1's rmse: 0.0852983\n",
      "[850]\ttraining's rmse: 0.0818805\tvalid_1's rmse: 0.0852915\n",
      "[875]\ttraining's rmse: 0.0818557\tvalid_1's rmse: 0.0852849\n",
      "[900]\ttraining's rmse: 0.0818281\tvalid_1's rmse: 0.0852778\n",
      "[925]\ttraining's rmse: 0.0818025\tvalid_1's rmse: 0.0852722\n",
      "[950]\ttraining's rmse: 0.0817796\tvalid_1's rmse: 0.085267\n",
      "[975]\ttraining's rmse: 0.0817554\tvalid_1's rmse: 0.0852615\n",
      "[1000]\ttraining's rmse: 0.0817347\tvalid_1's rmse: 0.0852564\n",
      "[1025]\ttraining's rmse: 0.0817119\tvalid_1's rmse: 0.0852523\n",
      "[1050]\ttraining's rmse: 0.0816912\tvalid_1's rmse: 0.0852468\n",
      "[1075]\ttraining's rmse: 0.0816704\tvalid_1's rmse: 0.085243\n",
      "[1100]\ttraining's rmse: 0.081654\tvalid_1's rmse: 0.0852382\n",
      "[1125]\ttraining's rmse: 0.0816342\tvalid_1's rmse: 0.0852344\n",
      "[1150]\ttraining's rmse: 0.0816146\tvalid_1's rmse: 0.0852311\n",
      "[1175]\ttraining's rmse: 0.0815987\tvalid_1's rmse: 0.0852277\n",
      "[1200]\ttraining's rmse: 0.0815819\tvalid_1's rmse: 0.0852237\n",
      "[1225]\ttraining's rmse: 0.0815655\tvalid_1's rmse: 0.0852206\n",
      "[1250]\ttraining's rmse: 0.0815517\tvalid_1's rmse: 0.0852179\n",
      "[1275]\ttraining's rmse: 0.0815342\tvalid_1's rmse: 0.0852154\n",
      "[1300]\ttraining's rmse: 0.0815227\tvalid_1's rmse: 0.085213\n",
      "[1325]\ttraining's rmse: 0.0815073\tvalid_1's rmse: 0.08521\n",
      "[1350]\ttraining's rmse: 0.0814931\tvalid_1's rmse: 0.0852084\n",
      "[1375]\ttraining's rmse: 0.0814817\tvalid_1's rmse: 0.0852064\n",
      "[1400]\ttraining's rmse: 0.0814701\tvalid_1's rmse: 0.0852039\n",
      "[1425]\ttraining's rmse: 0.0814586\tvalid_1's rmse: 0.0852021\n",
      "[1450]\ttraining's rmse: 0.0814461\tvalid_1's rmse: 0.0852005\n",
      "[1475]\ttraining's rmse: 0.081434\tvalid_1's rmse: 0.0851992\n",
      "[1500]\ttraining's rmse: 0.0814262\tvalid_1's rmse: 0.0851978\n",
      "[1525]\ttraining's rmse: 0.0814155\tvalid_1's rmse: 0.0851965\n",
      "[1550]\ttraining's rmse: 0.081405\tvalid_1's rmse: 0.0851955\n",
      "[1575]\ttraining's rmse: 0.0813971\tvalid_1's rmse: 0.0851937\n",
      "[1600]\ttraining's rmse: 0.0813914\tvalid_1's rmse: 0.0851929\n",
      "[1625]\ttraining's rmse: 0.0813824\tvalid_1's rmse: 0.0851915\n",
      "[1650]\ttraining's rmse: 0.0813739\tvalid_1's rmse: 0.08519\n",
      "[1675]\ttraining's rmse: 0.0813686\tvalid_1's rmse: 0.0851886\n",
      "[1700]\ttraining's rmse: 0.0813628\tvalid_1's rmse: 0.0851881\n",
      "[1725]\ttraining's rmse: 0.0813561\tvalid_1's rmse: 0.0851868\n",
      "[1750]\ttraining's rmse: 0.0813488\tvalid_1's rmse: 0.0851856\n",
      "[1775]\ttraining's rmse: 0.0813415\tvalid_1's rmse: 0.0851854\n",
      "[1800]\ttraining's rmse: 0.0813353\tvalid_1's rmse: 0.0851851\n",
      "[1825]\ttraining's rmse: 0.0813278\tvalid_1's rmse: 0.0851844\n",
      "[1850]\ttraining's rmse: 0.0813229\tvalid_1's rmse: 0.0851835\n",
      "[1875]\ttraining's rmse: 0.0813172\tvalid_1's rmse: 0.0851823\n",
      "[1900]\ttraining's rmse: 0.0813138\tvalid_1's rmse: 0.085182\n",
      "[1925]\ttraining's rmse: 0.0813075\tvalid_1's rmse: 0.0851814\n",
      "[1950]\ttraining's rmse: 0.0813037\tvalid_1's rmse: 0.0851805\n",
      "[1975]\ttraining's rmse: 0.0813006\tvalid_1's rmse: 0.0851798\n",
      "[2000]\ttraining's rmse: 0.0812965\tvalid_1's rmse: 0.0851787\n",
      "[2025]\ttraining's rmse: 0.0812921\tvalid_1's rmse: 0.0851775\n",
      "[2050]\ttraining's rmse: 0.0812889\tvalid_1's rmse: 0.0851768\n",
      "[2075]\ttraining's rmse: 0.0812864\tvalid_1's rmse: 0.0851765\n",
      "[2100]\ttraining's rmse: 0.0812835\tvalid_1's rmse: 0.0851761\n",
      "[2125]\ttraining's rmse: 0.0812792\tvalid_1's rmse: 0.0851755\n",
      "[2150]\ttraining's rmse: 0.0812761\tvalid_1's rmse: 0.0851759\n",
      "Early stopping, best iteration is:\n",
      "[2123]\ttraining's rmse: 0.0812793\tvalid_1's rmse: 0.0851754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0860096\tvalid_1's rmse: 0.0817365\n",
      "[50]\ttraining's rmse: 0.0859008\tvalid_1's rmse: 0.081691\n",
      "[75]\ttraining's rmse: 0.0857876\tvalid_1's rmse: 0.0816456\n",
      "[100]\ttraining's rmse: 0.0856845\tvalid_1's rmse: 0.0816052\n",
      "[125]\ttraining's rmse: 0.0855803\tvalid_1's rmse: 0.0815664\n",
      "[150]\ttraining's rmse: 0.0854817\tvalid_1's rmse: 0.0815286\n",
      "[175]\ttraining's rmse: 0.0854023\tvalid_1's rmse: 0.0814981\n",
      "[200]\ttraining's rmse: 0.0853146\tvalid_1's rmse: 0.0814678\n",
      "[225]\ttraining's rmse: 0.0852299\tvalid_1's rmse: 0.0814388\n",
      "[250]\ttraining's rmse: 0.0851583\tvalid_1's rmse: 0.0814132\n",
      "[275]\ttraining's rmse: 0.0850938\tvalid_1's rmse: 0.081389\n",
      "[300]\ttraining's rmse: 0.0850289\tvalid_1's rmse: 0.0813656\n",
      "[325]\ttraining's rmse: 0.0849636\tvalid_1's rmse: 0.0813446\n",
      "[350]\ttraining's rmse: 0.084898\tvalid_1's rmse: 0.0813242\n",
      "[375]\ttraining's rmse: 0.0848465\tvalid_1's rmse: 0.0813062\n",
      "[400]\ttraining's rmse: 0.084789\tvalid_1's rmse: 0.0812888\n",
      "[425]\ttraining's rmse: 0.0847372\tvalid_1's rmse: 0.0812742\n",
      "[450]\ttraining's rmse: 0.0846889\tvalid_1's rmse: 0.0812617\n",
      "[475]\ttraining's rmse: 0.0846417\tvalid_1's rmse: 0.0812514\n",
      "[500]\ttraining's rmse: 0.0846052\tvalid_1's rmse: 0.0812391\n",
      "[525]\ttraining's rmse: 0.0845552\tvalid_1's rmse: 0.0812305\n",
      "[550]\ttraining's rmse: 0.0845079\tvalid_1's rmse: 0.0812181\n",
      "[575]\ttraining's rmse: 0.0844644\tvalid_1's rmse: 0.0812063\n",
      "[600]\ttraining's rmse: 0.0844213\tvalid_1's rmse: 0.0811966\n",
      "[625]\ttraining's rmse: 0.0843878\tvalid_1's rmse: 0.0811878\n",
      "[650]\ttraining's rmse: 0.0843465\tvalid_1's rmse: 0.0811832\n",
      "[675]\ttraining's rmse: 0.0843051\tvalid_1's rmse: 0.0811754\n",
      "[700]\ttraining's rmse: 0.0842691\tvalid_1's rmse: 0.0811706\n",
      "[725]\ttraining's rmse: 0.084234\tvalid_1's rmse: 0.081171\n",
      "[750]\ttraining's rmse: 0.0842014\tvalid_1's rmse: 0.0811739\n",
      "[775]\ttraining's rmse: 0.0841731\tvalid_1's rmse: 0.0811782\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.084219\tvalid_1's rmse: 0.0811679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0850135\tvalid_1's rmse: 0.0874835\n",
      "[50]\ttraining's rmse: 0.0848827\tvalid_1's rmse: 0.0874305\n",
      "[75]\ttraining's rmse: 0.0847543\tvalid_1's rmse: 0.0873778\n",
      "[100]\ttraining's rmse: 0.0846379\tvalid_1's rmse: 0.0873337\n",
      "[125]\ttraining's rmse: 0.0845188\tvalid_1's rmse: 0.0872881\n",
      "[150]\ttraining's rmse: 0.0844078\tvalid_1's rmse: 0.087245\n",
      "[175]\ttraining's rmse: 0.0843193\tvalid_1's rmse: 0.0872087\n",
      "[200]\ttraining's rmse: 0.0842236\tvalid_1's rmse: 0.0871715\n",
      "[225]\ttraining's rmse: 0.0841297\tvalid_1's rmse: 0.0871362\n",
      "[250]\ttraining's rmse: 0.084051\tvalid_1's rmse: 0.0871037\n",
      "[275]\ttraining's rmse: 0.0839753\tvalid_1's rmse: 0.0870761\n",
      "[300]\ttraining's rmse: 0.0839012\tvalid_1's rmse: 0.0870486\n",
      "[325]\ttraining's rmse: 0.0838291\tvalid_1's rmse: 0.0870225\n",
      "[350]\ttraining's rmse: 0.0837588\tvalid_1's rmse: 0.0869985\n",
      "[375]\ttraining's rmse: 0.0836981\tvalid_1's rmse: 0.0869781\n",
      "[400]\ttraining's rmse: 0.0836349\tvalid_1's rmse: 0.0869576\n",
      "[425]\ttraining's rmse: 0.0835776\tvalid_1's rmse: 0.0869372\n",
      "[450]\ttraining's rmse: 0.0835245\tvalid_1's rmse: 0.0869162\n",
      "[475]\ttraining's rmse: 0.0834742\tvalid_1's rmse: 0.0868989\n",
      "[500]\ttraining's rmse: 0.0834318\tvalid_1's rmse: 0.0868822\n",
      "[525]\ttraining's rmse: 0.0833801\tvalid_1's rmse: 0.0868654\n",
      "[550]\ttraining's rmse: 0.083332\tvalid_1's rmse: 0.0868496\n",
      "[575]\ttraining's rmse: 0.0832875\tvalid_1's rmse: 0.086837\n",
      "[600]\ttraining's rmse: 0.0832482\tvalid_1's rmse: 0.0868241\n",
      "[625]\ttraining's rmse: 0.0832138\tvalid_1's rmse: 0.0868113\n",
      "[650]\ttraining's rmse: 0.0831737\tvalid_1's rmse: 0.0867985\n",
      "[675]\ttraining's rmse: 0.0831357\tvalid_1's rmse: 0.0867861\n",
      "[700]\ttraining's rmse: 0.0830987\tvalid_1's rmse: 0.086774\n",
      "[725]\ttraining's rmse: 0.083064\tvalid_1's rmse: 0.0867642\n",
      "[750]\ttraining's rmse: 0.0830314\tvalid_1's rmse: 0.0867545\n",
      "[775]\ttraining's rmse: 0.0830066\tvalid_1's rmse: 0.086744\n",
      "[800]\ttraining's rmse: 0.0829713\tvalid_1's rmse: 0.0867354\n",
      "[825]\ttraining's rmse: 0.0829403\tvalid_1's rmse: 0.0867268\n",
      "[850]\ttraining's rmse: 0.0829098\tvalid_1's rmse: 0.08672\n",
      "[875]\ttraining's rmse: 0.0828836\tvalid_1's rmse: 0.0867133\n",
      "[900]\ttraining's rmse: 0.0828542\tvalid_1's rmse: 0.0867059\n",
      "[925]\ttraining's rmse: 0.0828273\tvalid_1's rmse: 0.0866973\n",
      "[950]\ttraining's rmse: 0.0828057\tvalid_1's rmse: 0.0866906\n",
      "[975]\ttraining's rmse: 0.0827827\tvalid_1's rmse: 0.086684\n",
      "[1000]\ttraining's rmse: 0.0827603\tvalid_1's rmse: 0.0866789\n",
      "[1025]\ttraining's rmse: 0.0827361\tvalid_1's rmse: 0.086671\n",
      "[1050]\ttraining's rmse: 0.0827154\tvalid_1's rmse: 0.0866629\n",
      "[1075]\ttraining's rmse: 0.0826935\tvalid_1's rmse: 0.0866588\n",
      "[1100]\ttraining's rmse: 0.0826779\tvalid_1's rmse: 0.0866533\n",
      "[1125]\ttraining's rmse: 0.082659\tvalid_1's rmse: 0.0866469\n",
      "[1150]\ttraining's rmse: 0.0826409\tvalid_1's rmse: 0.0866435\n",
      "[1175]\ttraining's rmse: 0.0826243\tvalid_1's rmse: 0.0866392\n",
      "[1200]\ttraining's rmse: 0.0826096\tvalid_1's rmse: 0.0866352\n",
      "[1225]\ttraining's rmse: 0.0825941\tvalid_1's rmse: 0.0866317\n",
      "[1250]\ttraining's rmse: 0.0825804\tvalid_1's rmse: 0.0866281\n",
      "[1275]\ttraining's rmse: 0.0825628\tvalid_1's rmse: 0.0866257\n",
      "[1300]\ttraining's rmse: 0.0825482\tvalid_1's rmse: 0.0866221\n",
      "[1325]\ttraining's rmse: 0.0825335\tvalid_1's rmse: 0.0866176\n",
      "[1350]\ttraining's rmse: 0.0825208\tvalid_1's rmse: 0.086615\n",
      "[1375]\ttraining's rmse: 0.0825069\tvalid_1's rmse: 0.0866117\n",
      "[1400]\ttraining's rmse: 0.0824935\tvalid_1's rmse: 0.0866084\n",
      "[1425]\ttraining's rmse: 0.0824811\tvalid_1's rmse: 0.0866063\n",
      "[1450]\ttraining's rmse: 0.082467\tvalid_1's rmse: 0.0866041\n",
      "[1475]\ttraining's rmse: 0.082458\tvalid_1's rmse: 0.0866005\n",
      "[1500]\ttraining's rmse: 0.0824503\tvalid_1's rmse: 0.0865991\n",
      "[1525]\ttraining's rmse: 0.0824423\tvalid_1's rmse: 0.0865967\n",
      "[1550]\ttraining's rmse: 0.0824331\tvalid_1's rmse: 0.0865946\n",
      "[1575]\ttraining's rmse: 0.0824252\tvalid_1's rmse: 0.0865914\n",
      "[1600]\ttraining's rmse: 0.0824184\tvalid_1's rmse: 0.0865883\n",
      "[1625]\ttraining's rmse: 0.0824101\tvalid_1's rmse: 0.0865854\n",
      "[1650]\ttraining's rmse: 0.0824007\tvalid_1's rmse: 0.0865831\n",
      "[1675]\ttraining's rmse: 0.0823933\tvalid_1's rmse: 0.0865798\n",
      "[1700]\ttraining's rmse: 0.0823867\tvalid_1's rmse: 0.0865771\n",
      "[1725]\ttraining's rmse: 0.0823808\tvalid_1's rmse: 0.0865747\n",
      "[1750]\ttraining's rmse: 0.0823744\tvalid_1's rmse: 0.0865729\n",
      "[1775]\ttraining's rmse: 0.0823693\tvalid_1's rmse: 0.0865721\n",
      "[1800]\ttraining's rmse: 0.0823635\tvalid_1's rmse: 0.0865695\n",
      "[1825]\ttraining's rmse: 0.0823574\tvalid_1's rmse: 0.0865682\n",
      "[1850]\ttraining's rmse: 0.0823524\tvalid_1's rmse: 0.0865658\n",
      "[1875]\ttraining's rmse: 0.0823464\tvalid_1's rmse: 0.0865649\n",
      "[1900]\ttraining's rmse: 0.0823422\tvalid_1's rmse: 0.0865634\n",
      "[1925]\ttraining's rmse: 0.0823373\tvalid_1's rmse: 0.0865623\n",
      "[1950]\ttraining's rmse: 0.0823341\tvalid_1's rmse: 0.0865613\n",
      "[1975]\ttraining's rmse: 0.08233\tvalid_1's rmse: 0.0865594\n",
      "[2000]\ttraining's rmse: 0.0823255\tvalid_1's rmse: 0.0865575\n",
      "[2025]\ttraining's rmse: 0.082321\tvalid_1's rmse: 0.0865561\n",
      "[2050]\ttraining's rmse: 0.0823165\tvalid_1's rmse: 0.0865552\n",
      "[2075]\ttraining's rmse: 0.082314\tvalid_1's rmse: 0.0865544\n",
      "[2100]\ttraining's rmse: 0.082311\tvalid_1's rmse: 0.0865525\n",
      "[2125]\ttraining's rmse: 0.0823082\tvalid_1's rmse: 0.0865522\n",
      "[2150]\ttraining's rmse: 0.0823043\tvalid_1's rmse: 0.0865516\n",
      "[2175]\ttraining's rmse: 0.0823002\tvalid_1's rmse: 0.0865512\n",
      "[2200]\ttraining's rmse: 0.0822972\tvalid_1's rmse: 0.0865498\n",
      "[2225]\ttraining's rmse: 0.0822926\tvalid_1's rmse: 0.0865481\n",
      "[2250]\ttraining's rmse: 0.0822896\tvalid_1's rmse: 0.0865471\n",
      "[2275]\ttraining's rmse: 0.0822863\tvalid_1's rmse: 0.0865461\n",
      "[2300]\ttraining's rmse: 0.0822838\tvalid_1's rmse: 0.0865452\n",
      "[2325]\ttraining's rmse: 0.0822801\tvalid_1's rmse: 0.0865444\n",
      "[2350]\ttraining's rmse: 0.0822764\tvalid_1's rmse: 0.0865439\n",
      "[2375]\ttraining's rmse: 0.0822735\tvalid_1's rmse: 0.0865427\n",
      "[2400]\ttraining's rmse: 0.0822697\tvalid_1's rmse: 0.0865413\n",
      "[2425]\ttraining's rmse: 0.0822665\tvalid_1's rmse: 0.0865408\n",
      "[2450]\ttraining's rmse: 0.0822641\tvalid_1's rmse: 0.0865408\n",
      "[2475]\ttraining's rmse: 0.0822615\tvalid_1's rmse: 0.0865398\n",
      "[2500]\ttraining's rmse: 0.0822596\tvalid_1's rmse: 0.0865395\n",
      "[2525]\ttraining's rmse: 0.0822578\tvalid_1's rmse: 0.0865388\n",
      "[2550]\ttraining's rmse: 0.0822556\tvalid_1's rmse: 0.0865384\n",
      "[2575]\ttraining's rmse: 0.0822535\tvalid_1's rmse: 0.0865376\n",
      "[2600]\ttraining's rmse: 0.0822522\tvalid_1's rmse: 0.0865373\n",
      "[2625]\ttraining's rmse: 0.0822508\tvalid_1's rmse: 0.0865367\n",
      "[2650]\ttraining's rmse: 0.0822487\tvalid_1's rmse: 0.0865355\n",
      "[2675]\ttraining's rmse: 0.082247\tvalid_1's rmse: 0.0865345\n",
      "[2700]\ttraining's rmse: 0.0822456\tvalid_1's rmse: 0.0865339\n",
      "[2725]\ttraining's rmse: 0.0822428\tvalid_1's rmse: 0.0865341\n",
      "[2750]\ttraining's rmse: 0.0822414\tvalid_1's rmse: 0.0865334\n",
      "[2775]\ttraining's rmse: 0.0822399\tvalid_1's rmse: 0.0865331\n",
      "[2800]\ttraining's rmse: 0.0822376\tvalid_1's rmse: 0.0865328\n",
      "[2825]\ttraining's rmse: 0.082236\tvalid_1's rmse: 0.0865321\n",
      "[2850]\ttraining's rmse: 0.082235\tvalid_1's rmse: 0.0865324\n",
      "[2875]\ttraining's rmse: 0.082233\tvalid_1's rmse: 0.086532\n",
      "[2900]\ttraining's rmse: 0.0822304\tvalid_1's rmse: 0.0865317\n",
      "[2925]\ttraining's rmse: 0.0822292\tvalid_1's rmse: 0.0865314\n",
      "[2950]\ttraining's rmse: 0.0822274\tvalid_1's rmse: 0.0865314\n",
      "[2975]\ttraining's rmse: 0.0822253\tvalid_1's rmse: 0.0865315\n",
      "[3000]\ttraining's rmse: 0.082224\tvalid_1's rmse: 0.0865308\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.082224\tvalid_1's rmse: 0.0865308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0850389\tvalid_1's rmse: 0.0874452\n",
      "[50]\ttraining's rmse: 0.0849229\tvalid_1's rmse: 0.0873938\n",
      "[75]\ttraining's rmse: 0.0848008\tvalid_1's rmse: 0.0873422\n",
      "[100]\ttraining's rmse: 0.0846928\tvalid_1's rmse: 0.0872959\n",
      "[125]\ttraining's rmse: 0.0845806\tvalid_1's rmse: 0.0872497\n",
      "[150]\ttraining's rmse: 0.0844769\tvalid_1's rmse: 0.0872049\n",
      "[175]\ttraining's rmse: 0.0843933\tvalid_1's rmse: 0.0871697\n",
      "[200]\ttraining's rmse: 0.0842999\tvalid_1's rmse: 0.087134\n",
      "[225]\ttraining's rmse: 0.0842089\tvalid_1's rmse: 0.0870992\n",
      "[250]\ttraining's rmse: 0.0841322\tvalid_1's rmse: 0.0870696\n",
      "[275]\ttraining's rmse: 0.0840647\tvalid_1's rmse: 0.0870431\n",
      "[300]\ttraining's rmse: 0.0839943\tvalid_1's rmse: 0.0870155\n",
      "[325]\ttraining's rmse: 0.083923\tvalid_1's rmse: 0.0869901\n",
      "[350]\ttraining's rmse: 0.0838537\tvalid_1's rmse: 0.086966\n",
      "[375]\ttraining's rmse: 0.083797\tvalid_1's rmse: 0.086944\n",
      "[400]\ttraining's rmse: 0.0837362\tvalid_1's rmse: 0.0869234\n",
      "[425]\ttraining's rmse: 0.0836782\tvalid_1's rmse: 0.0869033\n",
      "[450]\ttraining's rmse: 0.0836263\tvalid_1's rmse: 0.0868858\n",
      "[475]\ttraining's rmse: 0.0835785\tvalid_1's rmse: 0.0868693\n",
      "[500]\ttraining's rmse: 0.083537\tvalid_1's rmse: 0.0868534\n",
      "[525]\ttraining's rmse: 0.0834837\tvalid_1's rmse: 0.0868374\n",
      "[550]\ttraining's rmse: 0.0834354\tvalid_1's rmse: 0.0868229\n",
      "[575]\ttraining's rmse: 0.0833895\tvalid_1's rmse: 0.0868091\n",
      "[600]\ttraining's rmse: 0.0833481\tvalid_1's rmse: 0.0867967\n",
      "[625]\ttraining's rmse: 0.0833144\tvalid_1's rmse: 0.0867848\n",
      "[650]\ttraining's rmse: 0.0832701\tvalid_1's rmse: 0.0867729\n",
      "[675]\ttraining's rmse: 0.0832286\tvalid_1's rmse: 0.0867615\n",
      "[700]\ttraining's rmse: 0.0831909\tvalid_1's rmse: 0.0867502\n",
      "[725]\ttraining's rmse: 0.0831579\tvalid_1's rmse: 0.0867407\n",
      "[750]\ttraining's rmse: 0.0831263\tvalid_1's rmse: 0.0867322\n",
      "[775]\ttraining's rmse: 0.0831001\tvalid_1's rmse: 0.0867238\n",
      "[800]\ttraining's rmse: 0.083063\tvalid_1's rmse: 0.0867147\n",
      "[825]\ttraining's rmse: 0.083033\tvalid_1's rmse: 0.0867062\n",
      "[850]\ttraining's rmse: 0.083004\tvalid_1's rmse: 0.0866995\n",
      "[875]\ttraining's rmse: 0.0829773\tvalid_1's rmse: 0.0866928\n",
      "[900]\ttraining's rmse: 0.0829477\tvalid_1's rmse: 0.0866853\n",
      "[925]\ttraining's rmse: 0.0829205\tvalid_1's rmse: 0.08668\n",
      "[950]\ttraining's rmse: 0.0828963\tvalid_1's rmse: 0.086674\n",
      "[975]\ttraining's rmse: 0.0828751\tvalid_1's rmse: 0.0866688\n",
      "[1000]\ttraining's rmse: 0.0828537\tvalid_1's rmse: 0.086664\n",
      "[1025]\ttraining's rmse: 0.0828283\tvalid_1's rmse: 0.0866601\n",
      "[1050]\ttraining's rmse: 0.0828079\tvalid_1's rmse: 0.0866547\n",
      "[1075]\ttraining's rmse: 0.0827879\tvalid_1's rmse: 0.0866504\n",
      "[1100]\ttraining's rmse: 0.0827698\tvalid_1's rmse: 0.0866456\n",
      "[1125]\ttraining's rmse: 0.0827483\tvalid_1's rmse: 0.0866415\n",
      "[1150]\ttraining's rmse: 0.0827308\tvalid_1's rmse: 0.0866377\n",
      "[1175]\ttraining's rmse: 0.0827152\tvalid_1's rmse: 0.0866347\n",
      "[1200]\ttraining's rmse: 0.0826983\tvalid_1's rmse: 0.0866312\n",
      "[1225]\ttraining's rmse: 0.0826827\tvalid_1's rmse: 0.0866283\n",
      "[1250]\ttraining's rmse: 0.0826687\tvalid_1's rmse: 0.0866259\n",
      "[1275]\ttraining's rmse: 0.0826508\tvalid_1's rmse: 0.0866238\n",
      "[1300]\ttraining's rmse: 0.0826381\tvalid_1's rmse: 0.086621\n",
      "[1325]\ttraining's rmse: 0.0826231\tvalid_1's rmse: 0.086619\n",
      "[1350]\ttraining's rmse: 0.0826111\tvalid_1's rmse: 0.086617\n",
      "[1375]\ttraining's rmse: 0.082597\tvalid_1's rmse: 0.0866153\n",
      "[1400]\ttraining's rmse: 0.0825851\tvalid_1's rmse: 0.0866128\n",
      "[1425]\ttraining's rmse: 0.0825734\tvalid_1's rmse: 0.0866116\n",
      "[1450]\ttraining's rmse: 0.0825612\tvalid_1's rmse: 0.0866107\n",
      "[1475]\ttraining's rmse: 0.0825492\tvalid_1's rmse: 0.0866079\n",
      "[1500]\ttraining's rmse: 0.0825401\tvalid_1's rmse: 0.0866062\n",
      "[1525]\ttraining's rmse: 0.0825288\tvalid_1's rmse: 0.0866048\n",
      "[1550]\ttraining's rmse: 0.0825204\tvalid_1's rmse: 0.0866037\n",
      "[1575]\ttraining's rmse: 0.0825118\tvalid_1's rmse: 0.086602\n",
      "[1600]\ttraining's rmse: 0.0825039\tvalid_1's rmse: 0.086601\n",
      "[1625]\ttraining's rmse: 0.0824959\tvalid_1's rmse: 0.0865999\n",
      "[1650]\ttraining's rmse: 0.0824886\tvalid_1's rmse: 0.0865992\n",
      "[1675]\ttraining's rmse: 0.0824823\tvalid_1's rmse: 0.0865982\n",
      "[1700]\ttraining's rmse: 0.0824754\tvalid_1's rmse: 0.0865968\n",
      "[1725]\ttraining's rmse: 0.0824692\tvalid_1's rmse: 0.086596\n",
      "[1750]\ttraining's rmse: 0.0824619\tvalid_1's rmse: 0.086595\n",
      "[1775]\ttraining's rmse: 0.0824557\tvalid_1's rmse: 0.0865942\n",
      "[1800]\ttraining's rmse: 0.0824496\tvalid_1's rmse: 0.0865936\n",
      "[1825]\ttraining's rmse: 0.0824435\tvalid_1's rmse: 0.0865926\n",
      "[1850]\ttraining's rmse: 0.0824388\tvalid_1's rmse: 0.0865918\n",
      "[1875]\ttraining's rmse: 0.0824343\tvalid_1's rmse: 0.0865913\n",
      "[1900]\ttraining's rmse: 0.0824302\tvalid_1's rmse: 0.0865909\n",
      "[1925]\ttraining's rmse: 0.0824255\tvalid_1's rmse: 0.0865902\n",
      "[1950]\ttraining's rmse: 0.0824213\tvalid_1's rmse: 0.0865892\n",
      "[1975]\ttraining's rmse: 0.0824164\tvalid_1's rmse: 0.0865886\n",
      "[2000]\ttraining's rmse: 0.0824123\tvalid_1's rmse: 0.0865882\n",
      "[2025]\ttraining's rmse: 0.0824089\tvalid_1's rmse: 0.0865874\n",
      "[2050]\ttraining's rmse: 0.0824053\tvalid_1's rmse: 0.0865871\n",
      "[2075]\ttraining's rmse: 0.0824024\tvalid_1's rmse: 0.0865871\n",
      "[2100]\ttraining's rmse: 0.0823989\tvalid_1's rmse: 0.0865868\n",
      "[2125]\ttraining's rmse: 0.0823953\tvalid_1's rmse: 0.0865862\n",
      "[2150]\ttraining's rmse: 0.0823919\tvalid_1's rmse: 0.0865863\n",
      "[2175]\ttraining's rmse: 0.0823896\tvalid_1's rmse: 0.0865863\n",
      "Early stopping, best iteration is:\n",
      "[2135]\ttraining's rmse: 0.0823939\tvalid_1's rmse: 0.0865859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0873444\tvalid_1's rmse: 0.0827636\n",
      "[50]\ttraining's rmse: 0.0872318\tvalid_1's rmse: 0.0827156\n",
      "[75]\ttraining's rmse: 0.0871171\tvalid_1's rmse: 0.0826704\n",
      "[100]\ttraining's rmse: 0.0870124\tvalid_1's rmse: 0.0826297\n",
      "[125]\ttraining's rmse: 0.0869038\tvalid_1's rmse: 0.08259\n",
      "[150]\ttraining's rmse: 0.086805\tvalid_1's rmse: 0.0825541\n",
      "[175]\ttraining's rmse: 0.0867235\tvalid_1's rmse: 0.082524\n",
      "[200]\ttraining's rmse: 0.0866313\tvalid_1's rmse: 0.0824939\n",
      "[225]\ttraining's rmse: 0.0865452\tvalid_1's rmse: 0.0824637\n",
      "[250]\ttraining's rmse: 0.0864737\tvalid_1's rmse: 0.0824419\n",
      "[275]\ttraining's rmse: 0.086408\tvalid_1's rmse: 0.0824185\n",
      "[300]\ttraining's rmse: 0.0863415\tvalid_1's rmse: 0.0823963\n",
      "[325]\ttraining's rmse: 0.0862731\tvalid_1's rmse: 0.0823732\n",
      "[350]\ttraining's rmse: 0.0862071\tvalid_1's rmse: 0.0823526\n",
      "[375]\ttraining's rmse: 0.0861526\tvalid_1's rmse: 0.0823358\n",
      "[400]\ttraining's rmse: 0.0860933\tvalid_1's rmse: 0.0823257\n",
      "[425]\ttraining's rmse: 0.0860396\tvalid_1's rmse: 0.0823139\n",
      "[450]\ttraining's rmse: 0.0859904\tvalid_1's rmse: 0.0822999\n",
      "[475]\ttraining's rmse: 0.0859441\tvalid_1's rmse: 0.0822862\n",
      "[500]\ttraining's rmse: 0.0859059\tvalid_1's rmse: 0.0822743\n",
      "[525]\ttraining's rmse: 0.0858537\tvalid_1's rmse: 0.0822613\n",
      "[550]\ttraining's rmse: 0.085807\tvalid_1's rmse: 0.0822492\n",
      "[575]\ttraining's rmse: 0.0857625\tvalid_1's rmse: 0.0822429\n",
      "[600]\ttraining's rmse: 0.0857174\tvalid_1's rmse: 0.0822422\n",
      "[625]\ttraining's rmse: 0.0856842\tvalid_1's rmse: 0.0822345\n",
      "[650]\ttraining's rmse: 0.0856435\tvalid_1's rmse: 0.0822283\n",
      "[675]\ttraining's rmse: 0.0856007\tvalid_1's rmse: 0.0822204\n",
      "[700]\ttraining's rmse: 0.085563\tvalid_1's rmse: 0.082214\n",
      "[725]\ttraining's rmse: 0.0855283\tvalid_1's rmse: 0.0822197\n",
      "[750]\ttraining's rmse: 0.0854967\tvalid_1's rmse: 0.0822179\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0855561\tvalid_1's rmse: 0.0822131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0863327\tvalid_1's rmse: 0.0889052\n",
      "[50]\ttraining's rmse: 0.086202\tvalid_1's rmse: 0.0888535\n",
      "[75]\ttraining's rmse: 0.0860709\tvalid_1's rmse: 0.0888002\n",
      "[100]\ttraining's rmse: 0.0859515\tvalid_1's rmse: 0.088753\n",
      "[125]\ttraining's rmse: 0.0858279\tvalid_1's rmse: 0.088706\n",
      "[150]\ttraining's rmse: 0.0857163\tvalid_1's rmse: 0.0886627\n",
      "[175]\ttraining's rmse: 0.0856257\tvalid_1's rmse: 0.0886262\n",
      "[200]\ttraining's rmse: 0.0855248\tvalid_1's rmse: 0.0885888\n",
      "[225]\ttraining's rmse: 0.0854287\tvalid_1's rmse: 0.0885531\n",
      "[250]\ttraining's rmse: 0.0853458\tvalid_1's rmse: 0.0885216\n",
      "[275]\ttraining's rmse: 0.0852673\tvalid_1's rmse: 0.0884933\n",
      "[300]\ttraining's rmse: 0.085193\tvalid_1's rmse: 0.0884674\n",
      "[325]\ttraining's rmse: 0.0851168\tvalid_1's rmse: 0.0884417\n",
      "[350]\ttraining's rmse: 0.0850459\tvalid_1's rmse: 0.0884157\n",
      "[375]\ttraining's rmse: 0.0849842\tvalid_1's rmse: 0.0883952\n",
      "[400]\ttraining's rmse: 0.0849175\tvalid_1's rmse: 0.0883729\n",
      "[425]\ttraining's rmse: 0.0848567\tvalid_1's rmse: 0.0883523\n",
      "[450]\ttraining's rmse: 0.0848004\tvalid_1's rmse: 0.0883322\n",
      "[475]\ttraining's rmse: 0.0847496\tvalid_1's rmse: 0.0883139\n",
      "[500]\ttraining's rmse: 0.0847075\tvalid_1's rmse: 0.0882984\n",
      "[525]\ttraining's rmse: 0.0846541\tvalid_1's rmse: 0.0882813\n",
      "[550]\ttraining's rmse: 0.0846044\tvalid_1's rmse: 0.088265\n",
      "[575]\ttraining's rmse: 0.0845576\tvalid_1's rmse: 0.0882512\n",
      "[600]\ttraining's rmse: 0.0845114\tvalid_1's rmse: 0.0882371\n",
      "[625]\ttraining's rmse: 0.0844763\tvalid_1's rmse: 0.0882259\n",
      "[650]\ttraining's rmse: 0.084436\tvalid_1's rmse: 0.0882141\n",
      "[675]\ttraining's rmse: 0.0843928\tvalid_1's rmse: 0.088201\n",
      "[700]\ttraining's rmse: 0.0843556\tvalid_1's rmse: 0.0881889\n",
      "[725]\ttraining's rmse: 0.0843193\tvalid_1's rmse: 0.0881793\n",
      "[750]\ttraining's rmse: 0.0842828\tvalid_1's rmse: 0.0881701\n",
      "[775]\ttraining's rmse: 0.0842558\tvalid_1's rmse: 0.0881602\n",
      "[800]\ttraining's rmse: 0.0842198\tvalid_1's rmse: 0.0881524\n",
      "[825]\ttraining's rmse: 0.0841905\tvalid_1's rmse: 0.0881433\n",
      "[850]\ttraining's rmse: 0.0841589\tvalid_1's rmse: 0.0881362\n",
      "[875]\ttraining's rmse: 0.0841327\tvalid_1's rmse: 0.0881276\n",
      "[900]\ttraining's rmse: 0.0841021\tvalid_1's rmse: 0.088119\n",
      "[925]\ttraining's rmse: 0.084075\tvalid_1's rmse: 0.0881112\n",
      "[950]\ttraining's rmse: 0.0840506\tvalid_1's rmse: 0.0881048\n",
      "[975]\ttraining's rmse: 0.0840277\tvalid_1's rmse: 0.0880987\n",
      "[1000]\ttraining's rmse: 0.0840032\tvalid_1's rmse: 0.0880939\n",
      "[1025]\ttraining's rmse: 0.0839781\tvalid_1's rmse: 0.0880878\n",
      "[1050]\ttraining's rmse: 0.0839551\tvalid_1's rmse: 0.0880811\n",
      "[1075]\ttraining's rmse: 0.0839344\tvalid_1's rmse: 0.0880772\n",
      "[1100]\ttraining's rmse: 0.0839157\tvalid_1's rmse: 0.0880715\n",
      "[1125]\ttraining's rmse: 0.0838971\tvalid_1's rmse: 0.0880676\n",
      "[1150]\ttraining's rmse: 0.0838793\tvalid_1's rmse: 0.0880629\n",
      "[1175]\ttraining's rmse: 0.0838604\tvalid_1's rmse: 0.0880597\n",
      "[1200]\ttraining's rmse: 0.0838458\tvalid_1's rmse: 0.0880537\n",
      "[1225]\ttraining's rmse: 0.0838288\tvalid_1's rmse: 0.0880495\n",
      "[1250]\ttraining's rmse: 0.083813\tvalid_1's rmse: 0.0880452\n",
      "[1275]\ttraining's rmse: 0.083794\tvalid_1's rmse: 0.0880415\n",
      "[1300]\ttraining's rmse: 0.0837816\tvalid_1's rmse: 0.0880371\n",
      "[1325]\ttraining's rmse: 0.0837692\tvalid_1's rmse: 0.0880334\n",
      "[1350]\ttraining's rmse: 0.083752\tvalid_1's rmse: 0.0880301\n",
      "[1375]\ttraining's rmse: 0.0837388\tvalid_1's rmse: 0.0880275\n",
      "[1400]\ttraining's rmse: 0.0837253\tvalid_1's rmse: 0.0880227\n",
      "[1425]\ttraining's rmse: 0.0837115\tvalid_1's rmse: 0.0880201\n",
      "[1450]\ttraining's rmse: 0.0836983\tvalid_1's rmse: 0.0880174\n",
      "[1475]\ttraining's rmse: 0.0836871\tvalid_1's rmse: 0.0880139\n",
      "[1500]\ttraining's rmse: 0.0836775\tvalid_1's rmse: 0.0880114\n",
      "[1525]\ttraining's rmse: 0.0836678\tvalid_1's rmse: 0.0880093\n",
      "[1550]\ttraining's rmse: 0.0836573\tvalid_1's rmse: 0.0880066\n",
      "[1575]\ttraining's rmse: 0.0836489\tvalid_1's rmse: 0.0880033\n",
      "[1600]\ttraining's rmse: 0.0836404\tvalid_1's rmse: 0.088001\n",
      "[1625]\ttraining's rmse: 0.0836331\tvalid_1's rmse: 0.0879988\n",
      "[1650]\ttraining's rmse: 0.0836258\tvalid_1's rmse: 0.0879964\n",
      "[1675]\ttraining's rmse: 0.0836183\tvalid_1's rmse: 0.087995\n",
      "[1700]\ttraining's rmse: 0.0836132\tvalid_1's rmse: 0.0879918\n",
      "[1725]\ttraining's rmse: 0.0836072\tvalid_1's rmse: 0.0879904\n",
      "[1750]\ttraining's rmse: 0.0836007\tvalid_1's rmse: 0.0879881\n",
      "[1775]\ttraining's rmse: 0.0835957\tvalid_1's rmse: 0.0879866\n",
      "[1800]\ttraining's rmse: 0.0835905\tvalid_1's rmse: 0.087985\n",
      "[1825]\ttraining's rmse: 0.0835843\tvalid_1's rmse: 0.0879825\n",
      "[1850]\ttraining's rmse: 0.0835767\tvalid_1's rmse: 0.0879806\n",
      "[1875]\ttraining's rmse: 0.0835721\tvalid_1's rmse: 0.0879779\n",
      "[1900]\ttraining's rmse: 0.0835664\tvalid_1's rmse: 0.0879762\n",
      "[1925]\ttraining's rmse: 0.0835622\tvalid_1's rmse: 0.0879753\n",
      "[1950]\ttraining's rmse: 0.0835596\tvalid_1's rmse: 0.0879736\n",
      "[1975]\ttraining's rmse: 0.083555\tvalid_1's rmse: 0.0879721\n",
      "[2000]\ttraining's rmse: 0.0835501\tvalid_1's rmse: 0.0879703\n",
      "[2025]\ttraining's rmse: 0.0835459\tvalid_1's rmse: 0.087969\n",
      "[2050]\ttraining's rmse: 0.0835414\tvalid_1's rmse: 0.0879674\n",
      "[2075]\ttraining's rmse: 0.0835374\tvalid_1's rmse: 0.0879666\n",
      "[2100]\ttraining's rmse: 0.0835344\tvalid_1's rmse: 0.0879659\n",
      "[2125]\ttraining's rmse: 0.0835299\tvalid_1's rmse: 0.0879628\n",
      "[2150]\ttraining's rmse: 0.083527\tvalid_1's rmse: 0.0879625\n",
      "[2175]\ttraining's rmse: 0.0835239\tvalid_1's rmse: 0.0879615\n",
      "[2200]\ttraining's rmse: 0.0835209\tvalid_1's rmse: 0.08796\n",
      "[2225]\ttraining's rmse: 0.0835165\tvalid_1's rmse: 0.0879589\n",
      "[2250]\ttraining's rmse: 0.0835133\tvalid_1's rmse: 0.0879577\n",
      "[2275]\ttraining's rmse: 0.08351\tvalid_1's rmse: 0.0879568\n",
      "[2300]\ttraining's rmse: 0.0835071\tvalid_1's rmse: 0.0879561\n",
      "[2325]\ttraining's rmse: 0.0835042\tvalid_1's rmse: 0.0879552\n",
      "[2350]\ttraining's rmse: 0.0835015\tvalid_1's rmse: 0.0879543\n",
      "[2375]\ttraining's rmse: 0.0834979\tvalid_1's rmse: 0.0879533\n",
      "[2400]\ttraining's rmse: 0.0834946\tvalid_1's rmse: 0.0879522\n",
      "[2425]\ttraining's rmse: 0.0834916\tvalid_1's rmse: 0.0879513\n",
      "[2450]\ttraining's rmse: 0.0834899\tvalid_1's rmse: 0.0879497\n",
      "[2475]\ttraining's rmse: 0.0834863\tvalid_1's rmse: 0.087949\n",
      "[2500]\ttraining's rmse: 0.0834844\tvalid_1's rmse: 0.0879471\n",
      "[2525]\ttraining's rmse: 0.0834817\tvalid_1's rmse: 0.0879467\n",
      "[2550]\ttraining's rmse: 0.0834786\tvalid_1's rmse: 0.0879459\n",
      "[2575]\ttraining's rmse: 0.0834766\tvalid_1's rmse: 0.087945\n",
      "[2600]\ttraining's rmse: 0.0834744\tvalid_1's rmse: 0.0879451\n",
      "[2625]\ttraining's rmse: 0.0834725\tvalid_1's rmse: 0.0879434\n",
      "[2650]\ttraining's rmse: 0.0834704\tvalid_1's rmse: 0.0879435\n",
      "[2675]\ttraining's rmse: 0.0834675\tvalid_1's rmse: 0.0879425\n",
      "[2700]\ttraining's rmse: 0.0834667\tvalid_1's rmse: 0.0879425\n",
      "[2725]\ttraining's rmse: 0.0834655\tvalid_1's rmse: 0.0879423\n",
      "[2750]\ttraining's rmse: 0.083463\tvalid_1's rmse: 0.0879414\n",
      "[2775]\ttraining's rmse: 0.0834613\tvalid_1's rmse: 0.0879415\n",
      "[2800]\ttraining's rmse: 0.0834597\tvalid_1's rmse: 0.0879414\n",
      "[2825]\ttraining's rmse: 0.0834586\tvalid_1's rmse: 0.0879408\n",
      "[2850]\ttraining's rmse: 0.0834565\tvalid_1's rmse: 0.0879402\n",
      "[2875]\ttraining's rmse: 0.0834543\tvalid_1's rmse: 0.0879392\n",
      "[2900]\ttraining's rmse: 0.0834511\tvalid_1's rmse: 0.0879392\n",
      "[2925]\ttraining's rmse: 0.08345\tvalid_1's rmse: 0.0879387\n",
      "[2950]\ttraining's rmse: 0.0834488\tvalid_1's rmse: 0.0879384\n",
      "[2975]\ttraining's rmse: 0.0834477\tvalid_1's rmse: 0.087938\n",
      "[3000]\ttraining's rmse: 0.0834462\tvalid_1's rmse: 0.0879376\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0834462\tvalid_1's rmse: 0.0879376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0863245\tvalid_1's rmse: 0.0889299\n",
      "[50]\ttraining's rmse: 0.0862035\tvalid_1's rmse: 0.0888775\n",
      "[75]\ttraining's rmse: 0.0860742\tvalid_1's rmse: 0.0888263\n",
      "[100]\ttraining's rmse: 0.08596\tvalid_1's rmse: 0.0887798\n",
      "[125]\ttraining's rmse: 0.0858439\tvalid_1's rmse: 0.0887331\n",
      "[150]\ttraining's rmse: 0.0857335\tvalid_1's rmse: 0.0886888\n",
      "[175]\ttraining's rmse: 0.0856438\tvalid_1's rmse: 0.0886528\n",
      "[200]\ttraining's rmse: 0.0855459\tvalid_1's rmse: 0.088616\n",
      "[225]\ttraining's rmse: 0.0854508\tvalid_1's rmse: 0.0885828\n",
      "[250]\ttraining's rmse: 0.0853688\tvalid_1's rmse: 0.0885531\n",
      "[275]\ttraining's rmse: 0.0852957\tvalid_1's rmse: 0.0885259\n",
      "[300]\ttraining's rmse: 0.0852211\tvalid_1's rmse: 0.0884996\n",
      "[325]\ttraining's rmse: 0.0851465\tvalid_1's rmse: 0.0884744\n",
      "[350]\ttraining's rmse: 0.0850745\tvalid_1's rmse: 0.0884505\n",
      "[375]\ttraining's rmse: 0.0850159\tvalid_1's rmse: 0.0884302\n",
      "[400]\ttraining's rmse: 0.0849504\tvalid_1's rmse: 0.08841\n",
      "[425]\ttraining's rmse: 0.084891\tvalid_1's rmse: 0.0883908\n",
      "[450]\ttraining's rmse: 0.0848366\tvalid_1's rmse: 0.0883727\n",
      "[475]\ttraining's rmse: 0.0847849\tvalid_1's rmse: 0.0883563\n",
      "[500]\ttraining's rmse: 0.0847417\tvalid_1's rmse: 0.0883413\n",
      "[525]\ttraining's rmse: 0.0846857\tvalid_1's rmse: 0.0883256\n",
      "[550]\ttraining's rmse: 0.0846345\tvalid_1's rmse: 0.0883103\n",
      "[575]\ttraining's rmse: 0.0845874\tvalid_1's rmse: 0.0882968\n",
      "[600]\ttraining's rmse: 0.0845425\tvalid_1's rmse: 0.0882847\n",
      "[625]\ttraining's rmse: 0.084509\tvalid_1's rmse: 0.0882733\n",
      "[650]\ttraining's rmse: 0.0844633\tvalid_1's rmse: 0.0882608\n",
      "[675]\ttraining's rmse: 0.0844208\tvalid_1's rmse: 0.0882505\n",
      "[700]\ttraining's rmse: 0.0843799\tvalid_1's rmse: 0.0882395\n",
      "[725]\ttraining's rmse: 0.0843455\tvalid_1's rmse: 0.0882305\n",
      "[750]\ttraining's rmse: 0.0843099\tvalid_1's rmse: 0.0882215\n",
      "[775]\ttraining's rmse: 0.0842816\tvalid_1's rmse: 0.0882129\n",
      "[800]\ttraining's rmse: 0.0842422\tvalid_1's rmse: 0.0882054\n",
      "[825]\ttraining's rmse: 0.084211\tvalid_1's rmse: 0.0881969\n",
      "[850]\ttraining's rmse: 0.0841809\tvalid_1's rmse: 0.08819\n",
      "[875]\ttraining's rmse: 0.0841536\tvalid_1's rmse: 0.0881838\n",
      "[900]\ttraining's rmse: 0.0841224\tvalid_1's rmse: 0.0881764\n",
      "[925]\ttraining's rmse: 0.0840939\tvalid_1's rmse: 0.0881706\n",
      "[950]\ttraining's rmse: 0.084068\tvalid_1's rmse: 0.0881648\n",
      "[975]\ttraining's rmse: 0.0840452\tvalid_1's rmse: 0.0881595\n",
      "[1000]\ttraining's rmse: 0.0840225\tvalid_1's rmse: 0.0881549\n",
      "[1025]\ttraining's rmse: 0.0839961\tvalid_1's rmse: 0.0881511\n",
      "[1050]\ttraining's rmse: 0.0839723\tvalid_1's rmse: 0.0881469\n",
      "[1075]\ttraining's rmse: 0.0839513\tvalid_1's rmse: 0.0881436\n",
      "[1100]\ttraining's rmse: 0.0839337\tvalid_1's rmse: 0.0881399\n",
      "[1125]\ttraining's rmse: 0.0839123\tvalid_1's rmse: 0.0881361\n",
      "[1150]\ttraining's rmse: 0.0838917\tvalid_1's rmse: 0.088133\n",
      "[1175]\ttraining's rmse: 0.0838744\tvalid_1's rmse: 0.0881301\n",
      "[1200]\ttraining's rmse: 0.0838578\tvalid_1's rmse: 0.0881273\n",
      "[1225]\ttraining's rmse: 0.0838419\tvalid_1's rmse: 0.0881244\n",
      "[1250]\ttraining's rmse: 0.083828\tvalid_1's rmse: 0.0881215\n",
      "[1275]\ttraining's rmse: 0.0838093\tvalid_1's rmse: 0.0881194\n",
      "[1300]\ttraining's rmse: 0.0837952\tvalid_1's rmse: 0.0881169\n",
      "[1325]\ttraining's rmse: 0.0837812\tvalid_1's rmse: 0.0881149\n",
      "[1350]\ttraining's rmse: 0.0837657\tvalid_1's rmse: 0.0881137\n",
      "[1375]\ttraining's rmse: 0.0837528\tvalid_1's rmse: 0.0881122\n",
      "[1400]\ttraining's rmse: 0.0837419\tvalid_1's rmse: 0.0881105\n",
      "[1425]\ttraining's rmse: 0.0837277\tvalid_1's rmse: 0.0881095\n",
      "[1450]\ttraining's rmse: 0.0837161\tvalid_1's rmse: 0.0881084\n",
      "[1475]\ttraining's rmse: 0.083705\tvalid_1's rmse: 0.0881072\n",
      "[1500]\ttraining's rmse: 0.0836948\tvalid_1's rmse: 0.0881056\n",
      "[1525]\ttraining's rmse: 0.083683\tvalid_1's rmse: 0.0881041\n",
      "[1550]\ttraining's rmse: 0.0836731\tvalid_1's rmse: 0.0881032\n",
      "[1575]\ttraining's rmse: 0.0836629\tvalid_1's rmse: 0.0881014\n",
      "[1600]\ttraining's rmse: 0.0836553\tvalid_1's rmse: 0.0881004\n",
      "[1625]\ttraining's rmse: 0.0836461\tvalid_1's rmse: 0.0880991\n",
      "[1650]\ttraining's rmse: 0.0836382\tvalid_1's rmse: 0.0880989\n",
      "[1675]\ttraining's rmse: 0.0836326\tvalid_1's rmse: 0.0880983\n",
      "[1700]\ttraining's rmse: 0.0836268\tvalid_1's rmse: 0.0880975\n",
      "[1725]\ttraining's rmse: 0.0836191\tvalid_1's rmse: 0.0880963\n",
      "[1750]\ttraining's rmse: 0.0836113\tvalid_1's rmse: 0.0880956\n",
      "[1775]\ttraining's rmse: 0.0836045\tvalid_1's rmse: 0.088095\n",
      "[1800]\ttraining's rmse: 0.0835974\tvalid_1's rmse: 0.0880943\n",
      "[1825]\ttraining's rmse: 0.0835916\tvalid_1's rmse: 0.088094\n",
      "[1850]\ttraining's rmse: 0.083587\tvalid_1's rmse: 0.0880931\n",
      "[1875]\ttraining's rmse: 0.0835814\tvalid_1's rmse: 0.0880932\n",
      "[1900]\ttraining's rmse: 0.0835767\tvalid_1's rmse: 0.0880929\n",
      "[1925]\ttraining's rmse: 0.0835725\tvalid_1's rmse: 0.0880927\n",
      "[1950]\ttraining's rmse: 0.0835686\tvalid_1's rmse: 0.0880919\n",
      "[1975]\ttraining's rmse: 0.0835642\tvalid_1's rmse: 0.0880914\n",
      "[2000]\ttraining's rmse: 0.0835574\tvalid_1's rmse: 0.0880906\n",
      "[2025]\ttraining's rmse: 0.0835518\tvalid_1's rmse: 0.0880898\n",
      "[2050]\ttraining's rmse: 0.0835477\tvalid_1's rmse: 0.0880897\n",
      "[2075]\ttraining's rmse: 0.0835438\tvalid_1's rmse: 0.0880889\n",
      "[2100]\ttraining's rmse: 0.0835407\tvalid_1's rmse: 0.0880888\n",
      "[2125]\ttraining's rmse: 0.0835366\tvalid_1's rmse: 0.088089\n",
      "Early stopping, best iteration is:\n",
      "[2096]\ttraining's rmse: 0.083541\tvalid_1's rmse: 0.0880887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0888001\tvalid_1's rmse: 0.0839153\n",
      "[50]\ttraining's rmse: 0.0886854\tvalid_1's rmse: 0.0838658\n",
      "[75]\ttraining's rmse: 0.0885674\tvalid_1's rmse: 0.0838173\n",
      "[100]\ttraining's rmse: 0.0884624\tvalid_1's rmse: 0.0837741\n",
      "[125]\ttraining's rmse: 0.0883541\tvalid_1's rmse: 0.0837318\n",
      "[150]\ttraining's rmse: 0.088254\tvalid_1's rmse: 0.0836963\n",
      "[175]\ttraining's rmse: 0.0881718\tvalid_1's rmse: 0.0836656\n",
      "[200]\ttraining's rmse: 0.0880805\tvalid_1's rmse: 0.0836339\n",
      "[225]\ttraining's rmse: 0.087996\tvalid_1's rmse: 0.0836032\n",
      "[250]\ttraining's rmse: 0.0879211\tvalid_1's rmse: 0.0835774\n",
      "[275]\ttraining's rmse: 0.0878518\tvalid_1's rmse: 0.0835503\n",
      "[300]\ttraining's rmse: 0.0877834\tvalid_1's rmse: 0.0835251\n",
      "[325]\ttraining's rmse: 0.0877166\tvalid_1's rmse: 0.0835046\n",
      "[350]\ttraining's rmse: 0.0876483\tvalid_1's rmse: 0.0834818\n",
      "[375]\ttraining's rmse: 0.087594\tvalid_1's rmse: 0.0834689\n",
      "[400]\ttraining's rmse: 0.0875338\tvalid_1's rmse: 0.083451\n",
      "[425]\ttraining's rmse: 0.0874763\tvalid_1's rmse: 0.0834347\n",
      "[450]\ttraining's rmse: 0.0874251\tvalid_1's rmse: 0.0834193\n",
      "[475]\ttraining's rmse: 0.0873753\tvalid_1's rmse: 0.0834047\n",
      "[500]\ttraining's rmse: 0.0873337\tvalid_1's rmse: 0.0833928\n",
      "[525]\ttraining's rmse: 0.0872799\tvalid_1's rmse: 0.0833786\n",
      "[550]\ttraining's rmse: 0.0872306\tvalid_1's rmse: 0.0833704\n",
      "[575]\ttraining's rmse: 0.0871861\tvalid_1's rmse: 0.0833575\n",
      "[600]\ttraining's rmse: 0.0871432\tvalid_1's rmse: 0.0833473\n",
      "[625]\ttraining's rmse: 0.0871085\tvalid_1's rmse: 0.0833368\n",
      "[650]\ttraining's rmse: 0.0870648\tvalid_1's rmse: 0.0833375\n",
      "[675]\ttraining's rmse: 0.0870215\tvalid_1's rmse: 0.0833283\n",
      "[700]\ttraining's rmse: 0.0869818\tvalid_1's rmse: 0.0833188\n",
      "[725]\ttraining's rmse: 0.0869451\tvalid_1's rmse: 0.083319\n",
      "[750]\ttraining's rmse: 0.0869105\tvalid_1's rmse: 0.0833163\n",
      "[775]\ttraining's rmse: 0.0868827\tvalid_1's rmse: 0.0833102\n",
      "[800]\ttraining's rmse: 0.0868442\tvalid_1's rmse: 0.083304\n",
      "[825]\ttraining's rmse: 0.0868125\tvalid_1's rmse: 0.0833007\n",
      "[850]\ttraining's rmse: 0.0867805\tvalid_1's rmse: 0.0833011\n",
      "[875]\ttraining's rmse: 0.0867538\tvalid_1's rmse: 0.0832961\n",
      "[900]\ttraining's rmse: 0.0867237\tvalid_1's rmse: 0.0832955\n",
      "[925]\ttraining's rmse: 0.0866949\tvalid_1's rmse: 0.083296\n",
      "[950]\ttraining's rmse: 0.0866678\tvalid_1's rmse: 0.0832973\n",
      "[975]\ttraining's rmse: 0.0866417\tvalid_1's rmse: 0.0833011\n",
      "Early stopping, best iteration is:\n",
      "[947]\ttraining's rmse: 0.0866705\tvalid_1's rmse: 0.083291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876984\tvalid_1's rmse: 0.0903688\n",
      "[50]\ttraining's rmse: 0.0875547\tvalid_1's rmse: 0.0903132\n",
      "[75]\ttraining's rmse: 0.0874144\tvalid_1's rmse: 0.0902578\n",
      "[100]\ttraining's rmse: 0.0872799\tvalid_1's rmse: 0.0902096\n",
      "[125]\ttraining's rmse: 0.0871493\tvalid_1's rmse: 0.0901608\n",
      "[150]\ttraining's rmse: 0.0870276\tvalid_1's rmse: 0.090116\n",
      "[175]\ttraining's rmse: 0.0869258\tvalid_1's rmse: 0.0900775\n",
      "[200]\ttraining's rmse: 0.0868221\tvalid_1's rmse: 0.0900376\n",
      "[225]\ttraining's rmse: 0.0867172\tvalid_1's rmse: 0.0899998\n",
      "[250]\ttraining's rmse: 0.0866278\tvalid_1's rmse: 0.0899642\n",
      "[275]\ttraining's rmse: 0.0865458\tvalid_1's rmse: 0.0899319\n",
      "[300]\ttraining's rmse: 0.0864644\tvalid_1's rmse: 0.0899039\n",
      "[325]\ttraining's rmse: 0.0863855\tvalid_1's rmse: 0.0898758\n",
      "[350]\ttraining's rmse: 0.0863077\tvalid_1's rmse: 0.0898493\n",
      "[375]\ttraining's rmse: 0.0862443\tvalid_1's rmse: 0.0898277\n",
      "[400]\ttraining's rmse: 0.0861705\tvalid_1's rmse: 0.0898056\n",
      "[425]\ttraining's rmse: 0.0861061\tvalid_1's rmse: 0.0897833\n",
      "[450]\ttraining's rmse: 0.0860446\tvalid_1's rmse: 0.0897617\n",
      "[475]\ttraining's rmse: 0.0859889\tvalid_1's rmse: 0.0897404\n",
      "[500]\ttraining's rmse: 0.0859412\tvalid_1's rmse: 0.0897216\n",
      "[525]\ttraining's rmse: 0.0858824\tvalid_1's rmse: 0.0897047\n",
      "[550]\ttraining's rmse: 0.085829\tvalid_1's rmse: 0.0896884\n",
      "[575]\ttraining's rmse: 0.0857756\tvalid_1's rmse: 0.0896729\n",
      "[600]\ttraining's rmse: 0.0857274\tvalid_1's rmse: 0.089659\n",
      "[625]\ttraining's rmse: 0.0856864\tvalid_1's rmse: 0.0896453\n",
      "[650]\ttraining's rmse: 0.0856413\tvalid_1's rmse: 0.0896326\n",
      "[675]\ttraining's rmse: 0.0855947\tvalid_1's rmse: 0.0896198\n",
      "[700]\ttraining's rmse: 0.0855533\tvalid_1's rmse: 0.0896081\n",
      "[725]\ttraining's rmse: 0.0855158\tvalid_1's rmse: 0.0895969\n",
      "[750]\ttraining's rmse: 0.0854778\tvalid_1's rmse: 0.0895857\n",
      "[775]\ttraining's rmse: 0.0854489\tvalid_1's rmse: 0.0895744\n",
      "[800]\ttraining's rmse: 0.0854118\tvalid_1's rmse: 0.0895641\n",
      "[825]\ttraining's rmse: 0.0853803\tvalid_1's rmse: 0.0895556\n",
      "[850]\ttraining's rmse: 0.0853482\tvalid_1's rmse: 0.0895476\n",
      "[875]\ttraining's rmse: 0.0853189\tvalid_1's rmse: 0.089539\n",
      "[900]\ttraining's rmse: 0.0852871\tvalid_1's rmse: 0.0895304\n",
      "[925]\ttraining's rmse: 0.0852614\tvalid_1's rmse: 0.0895227\n",
      "[950]\ttraining's rmse: 0.0852356\tvalid_1's rmse: 0.0895154\n",
      "[975]\ttraining's rmse: 0.0852109\tvalid_1's rmse: 0.0895073\n",
      "[1000]\ttraining's rmse: 0.0851875\tvalid_1's rmse: 0.0895005\n",
      "[1025]\ttraining's rmse: 0.0851644\tvalid_1's rmse: 0.089494\n",
      "[1050]\ttraining's rmse: 0.0851432\tvalid_1's rmse: 0.0894869\n",
      "[1075]\ttraining's rmse: 0.0851195\tvalid_1's rmse: 0.0894825\n",
      "[1100]\ttraining's rmse: 0.0851002\tvalid_1's rmse: 0.0894768\n",
      "[1125]\ttraining's rmse: 0.0850817\tvalid_1's rmse: 0.0894712\n",
      "[1150]\ttraining's rmse: 0.0850621\tvalid_1's rmse: 0.0894664\n",
      "[1175]\ttraining's rmse: 0.0850455\tvalid_1's rmse: 0.0894625\n",
      "[1200]\ttraining's rmse: 0.0850287\tvalid_1's rmse: 0.0894564\n",
      "[1225]\ttraining's rmse: 0.0850126\tvalid_1's rmse: 0.089451\n",
      "[1250]\ttraining's rmse: 0.0849953\tvalid_1's rmse: 0.0894464\n",
      "[1275]\ttraining's rmse: 0.0849769\tvalid_1's rmse: 0.0894435\n",
      "[1300]\ttraining's rmse: 0.0849627\tvalid_1's rmse: 0.0894389\n",
      "[1325]\ttraining's rmse: 0.0849468\tvalid_1's rmse: 0.0894355\n",
      "[1350]\ttraining's rmse: 0.084931\tvalid_1's rmse: 0.089433\n",
      "[1375]\ttraining's rmse: 0.0849164\tvalid_1's rmse: 0.089429\n",
      "[1400]\ttraining's rmse: 0.0849038\tvalid_1's rmse: 0.0894252\n",
      "[1425]\ttraining's rmse: 0.0848884\tvalid_1's rmse: 0.0894226\n",
      "[1450]\ttraining's rmse: 0.0848748\tvalid_1's rmse: 0.089419\n",
      "[1475]\ttraining's rmse: 0.0848646\tvalid_1's rmse: 0.089416\n",
      "[1500]\ttraining's rmse: 0.084853\tvalid_1's rmse: 0.089413\n",
      "[1525]\ttraining's rmse: 0.084842\tvalid_1's rmse: 0.0894097\n",
      "[1550]\ttraining's rmse: 0.0848326\tvalid_1's rmse: 0.0894078\n",
      "[1575]\ttraining's rmse: 0.0848223\tvalid_1's rmse: 0.0894045\n",
      "[1600]\ttraining's rmse: 0.0848142\tvalid_1's rmse: 0.0894026\n",
      "[1625]\ttraining's rmse: 0.0848064\tvalid_1's rmse: 0.0894\n",
      "[1650]\ttraining's rmse: 0.0847977\tvalid_1's rmse: 0.0893979\n",
      "[1675]\ttraining's rmse: 0.0847908\tvalid_1's rmse: 0.0893954\n",
      "[1700]\ttraining's rmse: 0.0847839\tvalid_1's rmse: 0.0893923\n",
      "[1725]\ttraining's rmse: 0.0847756\tvalid_1's rmse: 0.0893914\n",
      "[1750]\ttraining's rmse: 0.0847672\tvalid_1's rmse: 0.0893873\n",
      "[1775]\ttraining's rmse: 0.0847608\tvalid_1's rmse: 0.089385\n",
      "[1800]\ttraining's rmse: 0.0847555\tvalid_1's rmse: 0.0893833\n",
      "[1825]\ttraining's rmse: 0.0847484\tvalid_1's rmse: 0.0893809\n",
      "[1850]\ttraining's rmse: 0.0847435\tvalid_1's rmse: 0.0893789\n",
      "[1875]\ttraining's rmse: 0.0847365\tvalid_1's rmse: 0.0893768\n",
      "[1900]\ttraining's rmse: 0.0847311\tvalid_1's rmse: 0.0893745\n",
      "[1925]\ttraining's rmse: 0.0847271\tvalid_1's rmse: 0.0893742\n",
      "[1950]\ttraining's rmse: 0.0847212\tvalid_1's rmse: 0.0893723\n",
      "[1975]\ttraining's rmse: 0.0847171\tvalid_1's rmse: 0.0893714\n",
      "[2000]\ttraining's rmse: 0.0847132\tvalid_1's rmse: 0.0893706\n",
      "[2025]\ttraining's rmse: 0.0847077\tvalid_1's rmse: 0.0893674\n",
      "[2050]\ttraining's rmse: 0.0847027\tvalid_1's rmse: 0.089367\n",
      "[2075]\ttraining's rmse: 0.0846984\tvalid_1's rmse: 0.0893662\n",
      "[2100]\ttraining's rmse: 0.0846947\tvalid_1's rmse: 0.0893646\n",
      "[2125]\ttraining's rmse: 0.084691\tvalid_1's rmse: 0.0893636\n",
      "[2150]\ttraining's rmse: 0.0846869\tvalid_1's rmse: 0.0893627\n",
      "[2175]\ttraining's rmse: 0.0846842\tvalid_1's rmse: 0.089362\n",
      "[2200]\ttraining's rmse: 0.0846794\tvalid_1's rmse: 0.0893612\n",
      "[2225]\ttraining's rmse: 0.0846761\tvalid_1's rmse: 0.0893593\n",
      "[2250]\ttraining's rmse: 0.0846732\tvalid_1's rmse: 0.0893576\n",
      "[2275]\ttraining's rmse: 0.0846688\tvalid_1's rmse: 0.0893568\n",
      "[2300]\ttraining's rmse: 0.084666\tvalid_1's rmse: 0.089356\n",
      "[2325]\ttraining's rmse: 0.084663\tvalid_1's rmse: 0.0893546\n",
      "[2350]\ttraining's rmse: 0.0846598\tvalid_1's rmse: 0.0893532\n",
      "[2375]\ttraining's rmse: 0.0846571\tvalid_1's rmse: 0.0893525\n",
      "[2400]\ttraining's rmse: 0.0846539\tvalid_1's rmse: 0.0893518\n",
      "[2425]\ttraining's rmse: 0.084652\tvalid_1's rmse: 0.0893513\n",
      "[2450]\ttraining's rmse: 0.0846498\tvalid_1's rmse: 0.0893507\n",
      "[2475]\ttraining's rmse: 0.0846465\tvalid_1's rmse: 0.0893499\n",
      "[2500]\ttraining's rmse: 0.084645\tvalid_1's rmse: 0.0893498\n",
      "[2525]\ttraining's rmse: 0.0846438\tvalid_1's rmse: 0.0893493\n",
      "[2550]\ttraining's rmse: 0.0846419\tvalid_1's rmse: 0.0893488\n",
      "[2575]\ttraining's rmse: 0.0846392\tvalid_1's rmse: 0.0893484\n",
      "[2600]\ttraining's rmse: 0.0846365\tvalid_1's rmse: 0.0893478\n",
      "[2625]\ttraining's rmse: 0.0846335\tvalid_1's rmse: 0.0893468\n",
      "[2650]\ttraining's rmse: 0.0846319\tvalid_1's rmse: 0.0893462\n",
      "[2675]\ttraining's rmse: 0.0846292\tvalid_1's rmse: 0.0893452\n",
      "[2700]\ttraining's rmse: 0.0846268\tvalid_1's rmse: 0.0893448\n",
      "[2725]\ttraining's rmse: 0.0846248\tvalid_1's rmse: 0.0893445\n",
      "[2750]\ttraining's rmse: 0.0846228\tvalid_1's rmse: 0.0893441\n",
      "[2775]\ttraining's rmse: 0.0846201\tvalid_1's rmse: 0.0893436\n",
      "[2800]\ttraining's rmse: 0.0846189\tvalid_1's rmse: 0.0893434\n",
      "[2825]\ttraining's rmse: 0.0846172\tvalid_1's rmse: 0.0893433\n",
      "[2850]\ttraining's rmse: 0.0846151\tvalid_1's rmse: 0.0893435\n",
      "[2875]\ttraining's rmse: 0.0846135\tvalid_1's rmse: 0.0893432\n",
      "[2900]\ttraining's rmse: 0.0846126\tvalid_1's rmse: 0.0893435\n",
      "[2925]\ttraining's rmse: 0.0846109\tvalid_1's rmse: 0.0893429\n",
      "[2950]\ttraining's rmse: 0.0846083\tvalid_1's rmse: 0.0893429\n",
      "[2975]\ttraining's rmse: 0.0846068\tvalid_1's rmse: 0.0893431\n",
      "[3000]\ttraining's rmse: 0.0846042\tvalid_1's rmse: 0.0893424\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0846042\tvalid_1's rmse: 0.0893424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876463\tvalid_1's rmse: 0.0904833\n",
      "[50]\ttraining's rmse: 0.0875178\tvalid_1's rmse: 0.0904294\n",
      "[75]\ttraining's rmse: 0.0873832\tvalid_1's rmse: 0.0903751\n",
      "[100]\ttraining's rmse: 0.0872626\tvalid_1's rmse: 0.0903271\n",
      "[125]\ttraining's rmse: 0.0871389\tvalid_1's rmse: 0.0902793\n",
      "[150]\ttraining's rmse: 0.0870229\tvalid_1's rmse: 0.090234\n",
      "[175]\ttraining's rmse: 0.0869285\tvalid_1's rmse: 0.0901995\n",
      "[200]\ttraining's rmse: 0.0868249\tvalid_1's rmse: 0.0901618\n",
      "[225]\ttraining's rmse: 0.0867246\tvalid_1's rmse: 0.0901268\n",
      "[250]\ttraining's rmse: 0.0866388\tvalid_1's rmse: 0.0900957\n",
      "[275]\ttraining's rmse: 0.0865643\tvalid_1's rmse: 0.0900683\n",
      "[300]\ttraining's rmse: 0.0864866\tvalid_1's rmse: 0.0900409\n",
      "[325]\ttraining's rmse: 0.0864062\tvalid_1's rmse: 0.090014\n",
      "[350]\ttraining's rmse: 0.0863311\tvalid_1's rmse: 0.0899894\n",
      "[375]\ttraining's rmse: 0.0862704\tvalid_1's rmse: 0.089969\n",
      "[400]\ttraining's rmse: 0.0862017\tvalid_1's rmse: 0.0899486\n",
      "[425]\ttraining's rmse: 0.0861402\tvalid_1's rmse: 0.089929\n",
      "[450]\ttraining's rmse: 0.0860856\tvalid_1's rmse: 0.0899111\n",
      "[475]\ttraining's rmse: 0.0860321\tvalid_1's rmse: 0.0898938\n",
      "[500]\ttraining's rmse: 0.0859852\tvalid_1's rmse: 0.0898783\n",
      "[525]\ttraining's rmse: 0.0859257\tvalid_1's rmse: 0.0898615\n",
      "[550]\ttraining's rmse: 0.0858729\tvalid_1's rmse: 0.0898465\n",
      "[575]\ttraining's rmse: 0.0858233\tvalid_1's rmse: 0.0898335\n",
      "[600]\ttraining's rmse: 0.0857741\tvalid_1's rmse: 0.0898197\n",
      "[625]\ttraining's rmse: 0.0857345\tvalid_1's rmse: 0.0898083\n",
      "[650]\ttraining's rmse: 0.0856873\tvalid_1's rmse: 0.089796\n",
      "[675]\ttraining's rmse: 0.0856393\tvalid_1's rmse: 0.0897837\n",
      "[700]\ttraining's rmse: 0.0855988\tvalid_1's rmse: 0.0897733\n",
      "[725]\ttraining's rmse: 0.0855623\tvalid_1's rmse: 0.0897642\n",
      "[750]\ttraining's rmse: 0.0855267\tvalid_1's rmse: 0.0897556\n",
      "[775]\ttraining's rmse: 0.0854951\tvalid_1's rmse: 0.0897462\n",
      "[800]\ttraining's rmse: 0.0854566\tvalid_1's rmse: 0.0897384\n",
      "[825]\ttraining's rmse: 0.0854232\tvalid_1's rmse: 0.0897302\n",
      "[850]\ttraining's rmse: 0.0853914\tvalid_1's rmse: 0.0897238\n",
      "[875]\ttraining's rmse: 0.0853624\tvalid_1's rmse: 0.0897175\n",
      "[900]\ttraining's rmse: 0.0853322\tvalid_1's rmse: 0.0897121\n",
      "[925]\ttraining's rmse: 0.0853025\tvalid_1's rmse: 0.089706\n",
      "[950]\ttraining's rmse: 0.085275\tvalid_1's rmse: 0.0897004\n",
      "[975]\ttraining's rmse: 0.0852503\tvalid_1's rmse: 0.0896949\n",
      "[1000]\ttraining's rmse: 0.085227\tvalid_1's rmse: 0.0896898\n",
      "[1025]\ttraining's rmse: 0.0852006\tvalid_1's rmse: 0.0896856\n",
      "[1050]\ttraining's rmse: 0.0851763\tvalid_1's rmse: 0.0896812\n",
      "[1075]\ttraining's rmse: 0.0851524\tvalid_1's rmse: 0.0896779\n",
      "[1100]\ttraining's rmse: 0.0851319\tvalid_1's rmse: 0.0896739\n",
      "[1125]\ttraining's rmse: 0.0851121\tvalid_1's rmse: 0.0896701\n",
      "[1150]\ttraining's rmse: 0.0850934\tvalid_1's rmse: 0.0896673\n",
      "[1175]\ttraining's rmse: 0.0850772\tvalid_1's rmse: 0.0896641\n",
      "[1200]\ttraining's rmse: 0.0850604\tvalid_1's rmse: 0.0896617\n",
      "[1225]\ttraining's rmse: 0.0850439\tvalid_1's rmse: 0.0896595\n",
      "[1250]\ttraining's rmse: 0.0850279\tvalid_1's rmse: 0.0896572\n",
      "[1275]\ttraining's rmse: 0.0850084\tvalid_1's rmse: 0.0896554\n",
      "[1300]\ttraining's rmse: 0.0849932\tvalid_1's rmse: 0.0896525\n",
      "[1325]\ttraining's rmse: 0.0849787\tvalid_1's rmse: 0.0896503\n",
      "[1350]\ttraining's rmse: 0.0849626\tvalid_1's rmse: 0.0896488\n",
      "[1375]\ttraining's rmse: 0.0849464\tvalid_1's rmse: 0.0896469\n",
      "[1400]\ttraining's rmse: 0.0849344\tvalid_1's rmse: 0.0896446\n",
      "[1425]\ttraining's rmse: 0.0849208\tvalid_1's rmse: 0.0896436\n",
      "[1450]\ttraining's rmse: 0.0849092\tvalid_1's rmse: 0.0896424\n",
      "[1475]\ttraining's rmse: 0.0848976\tvalid_1's rmse: 0.0896414\n",
      "[1500]\ttraining's rmse: 0.0848871\tvalid_1's rmse: 0.0896396\n",
      "[1525]\ttraining's rmse: 0.0848758\tvalid_1's rmse: 0.0896379\n",
      "[1550]\ttraining's rmse: 0.0848661\tvalid_1's rmse: 0.0896371\n",
      "[1575]\ttraining's rmse: 0.0848561\tvalid_1's rmse: 0.0896359\n",
      "[1600]\ttraining's rmse: 0.0848479\tvalid_1's rmse: 0.0896353\n",
      "[1625]\ttraining's rmse: 0.0848396\tvalid_1's rmse: 0.0896342\n",
      "[1650]\ttraining's rmse: 0.0848308\tvalid_1's rmse: 0.0896344\n",
      "[1675]\ttraining's rmse: 0.0848237\tvalid_1's rmse: 0.0896335\n",
      "[1700]\ttraining's rmse: 0.0848164\tvalid_1's rmse: 0.0896326\n",
      "[1725]\ttraining's rmse: 0.0848071\tvalid_1's rmse: 0.0896319\n",
      "[1750]\ttraining's rmse: 0.084798\tvalid_1's rmse: 0.0896306\n",
      "[1775]\ttraining's rmse: 0.0847915\tvalid_1's rmse: 0.0896305\n",
      "[1800]\ttraining's rmse: 0.0847852\tvalid_1's rmse: 0.0896299\n",
      "[1825]\ttraining's rmse: 0.084779\tvalid_1's rmse: 0.0896294\n",
      "[1850]\ttraining's rmse: 0.0847739\tvalid_1's rmse: 0.0896286\n",
      "[1875]\ttraining's rmse: 0.0847682\tvalid_1's rmse: 0.0896281\n",
      "[1900]\ttraining's rmse: 0.0847623\tvalid_1's rmse: 0.0896276\n",
      "[1925]\ttraining's rmse: 0.0847589\tvalid_1's rmse: 0.0896275\n",
      "[1950]\ttraining's rmse: 0.0847542\tvalid_1's rmse: 0.0896264\n",
      "[1975]\ttraining's rmse: 0.0847502\tvalid_1's rmse: 0.0896261\n",
      "[2000]\ttraining's rmse: 0.0847449\tvalid_1's rmse: 0.0896253\n",
      "[2025]\ttraining's rmse: 0.0847412\tvalid_1's rmse: 0.0896247\n",
      "[2050]\ttraining's rmse: 0.0847376\tvalid_1's rmse: 0.0896246\n",
      "[2075]\ttraining's rmse: 0.0847333\tvalid_1's rmse: 0.0896242\n",
      "[2100]\ttraining's rmse: 0.0847296\tvalid_1's rmse: 0.089624\n",
      "[2125]\ttraining's rmse: 0.0847254\tvalid_1's rmse: 0.089624\n",
      "[2150]\ttraining's rmse: 0.0847217\tvalid_1's rmse: 0.0896241\n",
      "[2175]\ttraining's rmse: 0.0847183\tvalid_1's rmse: 0.0896243\n",
      "Early stopping, best iteration is:\n",
      "[2132]\ttraining's rmse: 0.0847247\tvalid_1's rmse: 0.0896239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0902961\tvalid_1's rmse: 0.0850956\n",
      "[50]\ttraining's rmse: 0.0901741\tvalid_1's rmse: 0.085049\n",
      "[75]\ttraining's rmse: 0.0900464\tvalid_1's rmse: 0.0849986\n",
      "[100]\ttraining's rmse: 0.0899323\tvalid_1's rmse: 0.0849559\n",
      "[125]\ttraining's rmse: 0.0898165\tvalid_1's rmse: 0.084912\n",
      "[150]\ttraining's rmse: 0.0897094\tvalid_1's rmse: 0.0848744\n",
      "[175]\ttraining's rmse: 0.089621\tvalid_1's rmse: 0.0848436\n",
      "[200]\ttraining's rmse: 0.0895226\tvalid_1's rmse: 0.0848121\n",
      "[225]\ttraining's rmse: 0.0894287\tvalid_1's rmse: 0.0847802\n",
      "[250]\ttraining's rmse: 0.0893503\tvalid_1's rmse: 0.0847542\n",
      "[275]\ttraining's rmse: 0.0892772\tvalid_1's rmse: 0.0847306\n",
      "[300]\ttraining's rmse: 0.0892049\tvalid_1's rmse: 0.0847054\n",
      "[325]\ttraining's rmse: 0.0891311\tvalid_1's rmse: 0.0846824\n",
      "[350]\ttraining's rmse: 0.0890572\tvalid_1's rmse: 0.0846599\n",
      "[375]\ttraining's rmse: 0.0890004\tvalid_1's rmse: 0.0846477\n",
      "[400]\ttraining's rmse: 0.0889335\tvalid_1's rmse: 0.0846278\n",
      "[425]\ttraining's rmse: 0.0888735\tvalid_1's rmse: 0.0846138\n",
      "[450]\ttraining's rmse: 0.0888177\tvalid_1's rmse: 0.0845965\n",
      "[475]\ttraining's rmse: 0.0887684\tvalid_1's rmse: 0.0845861\n",
      "[500]\ttraining's rmse: 0.0887247\tvalid_1's rmse: 0.0845722\n",
      "[525]\ttraining's rmse: 0.0886678\tvalid_1's rmse: 0.08456\n",
      "[550]\ttraining's rmse: 0.0886145\tvalid_1's rmse: 0.0845499\n",
      "[575]\ttraining's rmse: 0.0885654\tvalid_1's rmse: 0.0845406\n",
      "[600]\ttraining's rmse: 0.0885182\tvalid_1's rmse: 0.0845396\n",
      "[625]\ttraining's rmse: 0.0884801\tvalid_1's rmse: 0.084528\n",
      "[650]\ttraining's rmse: 0.0884321\tvalid_1's rmse: 0.0845231\n",
      "[675]\ttraining's rmse: 0.0883831\tvalid_1's rmse: 0.0845187\n",
      "[700]\ttraining's rmse: 0.0883411\tvalid_1's rmse: 0.0845165\n",
      "[725]\ttraining's rmse: 0.088303\tvalid_1's rmse: 0.0845144\n",
      "[750]\ttraining's rmse: 0.0882665\tvalid_1's rmse: 0.0845271\n",
      "[775]\ttraining's rmse: 0.0882353\tvalid_1's rmse: 0.0845207\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0882868\tvalid_1's rmse: 0.084511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0888999\tvalid_1's rmse: 0.0916407\n",
      "[50]\ttraining's rmse: 0.0887539\tvalid_1's rmse: 0.0915869\n",
      "[75]\ttraining's rmse: 0.0886083\tvalid_1's rmse: 0.0915336\n",
      "[100]\ttraining's rmse: 0.088474\tvalid_1's rmse: 0.0914863\n",
      "[125]\ttraining's rmse: 0.0883353\tvalid_1's rmse: 0.0914406\n",
      "[150]\ttraining's rmse: 0.0882102\tvalid_1's rmse: 0.0913967\n",
      "[175]\ttraining's rmse: 0.0881046\tvalid_1's rmse: 0.0913596\n",
      "[200]\ttraining's rmse: 0.0879906\tvalid_1's rmse: 0.0913225\n",
      "[225]\ttraining's rmse: 0.087881\tvalid_1's rmse: 0.0912886\n",
      "[250]\ttraining's rmse: 0.0877872\tvalid_1's rmse: 0.0912534\n",
      "[275]\ttraining's rmse: 0.0877028\tvalid_1's rmse: 0.0912237\n",
      "[300]\ttraining's rmse: 0.0876178\tvalid_1's rmse: 0.0911956\n",
      "[325]\ttraining's rmse: 0.087533\tvalid_1's rmse: 0.0911669\n",
      "[350]\ttraining's rmse: 0.0874501\tvalid_1's rmse: 0.0911405\n",
      "[375]\ttraining's rmse: 0.0873799\tvalid_1's rmse: 0.0911186\n",
      "[400]\ttraining's rmse: 0.0873034\tvalid_1's rmse: 0.0910971\n",
      "[425]\ttraining's rmse: 0.0872361\tvalid_1's rmse: 0.0910753\n",
      "[450]\ttraining's rmse: 0.0871739\tvalid_1's rmse: 0.091055\n",
      "[475]\ttraining's rmse: 0.0871187\tvalid_1's rmse: 0.0910345\n",
      "[500]\ttraining's rmse: 0.0870711\tvalid_1's rmse: 0.0910168\n",
      "[525]\ttraining's rmse: 0.0870069\tvalid_1's rmse: 0.0909984\n",
      "[550]\ttraining's rmse: 0.0869532\tvalid_1's rmse: 0.0909823\n",
      "[575]\ttraining's rmse: 0.0869023\tvalid_1's rmse: 0.0909693\n",
      "[600]\ttraining's rmse: 0.0868551\tvalid_1's rmse: 0.090956\n",
      "[625]\ttraining's rmse: 0.0868143\tvalid_1's rmse: 0.0909438\n",
      "[650]\ttraining's rmse: 0.0867671\tvalid_1's rmse: 0.0909308\n",
      "[675]\ttraining's rmse: 0.0867212\tvalid_1's rmse: 0.0909181\n",
      "[700]\ttraining's rmse: 0.0866797\tvalid_1's rmse: 0.0909074\n",
      "[725]\ttraining's rmse: 0.0866404\tvalid_1's rmse: 0.0908972\n",
      "[750]\ttraining's rmse: 0.0866019\tvalid_1's rmse: 0.0908861\n",
      "[775]\ttraining's rmse: 0.0865719\tvalid_1's rmse: 0.0908745\n",
      "[800]\ttraining's rmse: 0.0865328\tvalid_1's rmse: 0.090865\n",
      "[825]\ttraining's rmse: 0.0864999\tvalid_1's rmse: 0.0908554\n",
      "[850]\ttraining's rmse: 0.0864655\tvalid_1's rmse: 0.0908483\n",
      "[875]\ttraining's rmse: 0.0864362\tvalid_1's rmse: 0.0908416\n",
      "[900]\ttraining's rmse: 0.0864029\tvalid_1's rmse: 0.0908345\n",
      "[925]\ttraining's rmse: 0.0863714\tvalid_1's rmse: 0.090826\n",
      "[950]\ttraining's rmse: 0.0863458\tvalid_1's rmse: 0.090819\n",
      "[975]\ttraining's rmse: 0.0863199\tvalid_1's rmse: 0.0908128\n",
      "[1000]\ttraining's rmse: 0.0862947\tvalid_1's rmse: 0.0908073\n",
      "[1025]\ttraining's rmse: 0.0862681\tvalid_1's rmse: 0.0908005\n",
      "[1050]\ttraining's rmse: 0.0862458\tvalid_1's rmse: 0.0907933\n",
      "[1075]\ttraining's rmse: 0.0862229\tvalid_1's rmse: 0.090789\n",
      "[1100]\ttraining's rmse: 0.086201\tvalid_1's rmse: 0.0907828\n",
      "[1125]\ttraining's rmse: 0.0861813\tvalid_1's rmse: 0.0907767\n",
      "[1150]\ttraining's rmse: 0.0861625\tvalid_1's rmse: 0.0907732\n",
      "[1175]\ttraining's rmse: 0.0861446\tvalid_1's rmse: 0.0907699\n",
      "[1200]\ttraining's rmse: 0.0861279\tvalid_1's rmse: 0.0907655\n",
      "[1225]\ttraining's rmse: 0.0861126\tvalid_1's rmse: 0.0907618\n",
      "[1250]\ttraining's rmse: 0.0860977\tvalid_1's rmse: 0.0907575\n",
      "[1275]\ttraining's rmse: 0.0860796\tvalid_1's rmse: 0.0907542\n",
      "[1300]\ttraining's rmse: 0.0860663\tvalid_1's rmse: 0.0907493\n",
      "[1325]\ttraining's rmse: 0.0860535\tvalid_1's rmse: 0.0907457\n",
      "[1350]\ttraining's rmse: 0.0860382\tvalid_1's rmse: 0.0907416\n",
      "[1375]\ttraining's rmse: 0.086024\tvalid_1's rmse: 0.0907389\n",
      "[1400]\ttraining's rmse: 0.0860103\tvalid_1's rmse: 0.0907344\n",
      "[1425]\ttraining's rmse: 0.0859976\tvalid_1's rmse: 0.0907322\n",
      "[1450]\ttraining's rmse: 0.0859842\tvalid_1's rmse: 0.0907286\n",
      "[1475]\ttraining's rmse: 0.0859716\tvalid_1's rmse: 0.0907254\n",
      "[1500]\ttraining's rmse: 0.0859612\tvalid_1's rmse: 0.090722\n",
      "[1525]\ttraining's rmse: 0.0859479\tvalid_1's rmse: 0.090719\n",
      "[1550]\ttraining's rmse: 0.085936\tvalid_1's rmse: 0.0907154\n",
      "[1575]\ttraining's rmse: 0.0859243\tvalid_1's rmse: 0.0907129\n",
      "[1600]\ttraining's rmse: 0.0859166\tvalid_1's rmse: 0.0907103\n",
      "[1625]\ttraining's rmse: 0.085908\tvalid_1's rmse: 0.0907078\n",
      "[1650]\ttraining's rmse: 0.0859002\tvalid_1's rmse: 0.0907055\n",
      "[1675]\ttraining's rmse: 0.0858941\tvalid_1's rmse: 0.0907029\n",
      "[1700]\ttraining's rmse: 0.0858856\tvalid_1's rmse: 0.0907015\n",
      "[1725]\ttraining's rmse: 0.085879\tvalid_1's rmse: 0.0906999\n",
      "[1750]\ttraining's rmse: 0.0858707\tvalid_1's rmse: 0.0906977\n",
      "[1775]\ttraining's rmse: 0.085864\tvalid_1's rmse: 0.0906969\n",
      "[1800]\ttraining's rmse: 0.0858565\tvalid_1's rmse: 0.0906951\n",
      "[1825]\ttraining's rmse: 0.0858482\tvalid_1's rmse: 0.0906928\n",
      "[1850]\ttraining's rmse: 0.0858408\tvalid_1's rmse: 0.0906901\n",
      "[1875]\ttraining's rmse: 0.0858354\tvalid_1's rmse: 0.090688\n",
      "[1900]\ttraining's rmse: 0.0858292\tvalid_1's rmse: 0.0906859\n",
      "[1925]\ttraining's rmse: 0.0858246\tvalid_1's rmse: 0.0906838\n",
      "[1950]\ttraining's rmse: 0.0858199\tvalid_1's rmse: 0.0906812\n",
      "[1975]\ttraining's rmse: 0.0858143\tvalid_1's rmse: 0.0906794\n",
      "[2000]\ttraining's rmse: 0.0858111\tvalid_1's rmse: 0.0906786\n",
      "[2025]\ttraining's rmse: 0.0858035\tvalid_1's rmse: 0.0906758\n",
      "[2050]\ttraining's rmse: 0.085798\tvalid_1's rmse: 0.0906755\n",
      "[2075]\ttraining's rmse: 0.0857948\tvalid_1's rmse: 0.0906745\n",
      "[2100]\ttraining's rmse: 0.0857913\tvalid_1's rmse: 0.0906737\n",
      "[2125]\ttraining's rmse: 0.0857875\tvalid_1's rmse: 0.0906725\n",
      "[2150]\ttraining's rmse: 0.0857838\tvalid_1's rmse: 0.0906723\n",
      "[2175]\ttraining's rmse: 0.0857814\tvalid_1's rmse: 0.0906719\n",
      "[2200]\ttraining's rmse: 0.0857784\tvalid_1's rmse: 0.0906707\n",
      "[2225]\ttraining's rmse: 0.0857761\tvalid_1's rmse: 0.09067\n",
      "[2250]\ttraining's rmse: 0.085773\tvalid_1's rmse: 0.0906691\n",
      "[2275]\ttraining's rmse: 0.0857693\tvalid_1's rmse: 0.0906684\n",
      "[2300]\ttraining's rmse: 0.0857667\tvalid_1's rmse: 0.0906668\n",
      "[2325]\ttraining's rmse: 0.0857625\tvalid_1's rmse: 0.0906655\n",
      "[2350]\ttraining's rmse: 0.0857601\tvalid_1's rmse: 0.090665\n",
      "[2375]\ttraining's rmse: 0.0857563\tvalid_1's rmse: 0.0906644\n",
      "[2400]\ttraining's rmse: 0.0857537\tvalid_1's rmse: 0.0906633\n",
      "[2425]\ttraining's rmse: 0.0857499\tvalid_1's rmse: 0.0906624\n",
      "[2450]\ttraining's rmse: 0.0857484\tvalid_1's rmse: 0.0906618\n",
      "[2475]\ttraining's rmse: 0.0857457\tvalid_1's rmse: 0.0906614\n",
      "[2500]\ttraining's rmse: 0.0857426\tvalid_1's rmse: 0.0906607\n",
      "[2525]\ttraining's rmse: 0.0857399\tvalid_1's rmse: 0.0906598\n",
      "[2550]\ttraining's rmse: 0.0857366\tvalid_1's rmse: 0.0906594\n",
      "[2575]\ttraining's rmse: 0.0857345\tvalid_1's rmse: 0.0906594\n",
      "[2600]\ttraining's rmse: 0.0857331\tvalid_1's rmse: 0.0906592\n",
      "[2625]\ttraining's rmse: 0.0857305\tvalid_1's rmse: 0.0906578\n",
      "[2650]\ttraining's rmse: 0.0857289\tvalid_1's rmse: 0.0906575\n",
      "[2675]\ttraining's rmse: 0.0857264\tvalid_1's rmse: 0.0906567\n",
      "[2700]\ttraining's rmse: 0.0857242\tvalid_1's rmse: 0.0906562\n",
      "[2725]\ttraining's rmse: 0.0857218\tvalid_1's rmse: 0.0906563\n",
      "[2750]\ttraining's rmse: 0.0857203\tvalid_1's rmse: 0.0906567\n",
      "[2775]\ttraining's rmse: 0.0857178\tvalid_1's rmse: 0.0906566\n",
      "Early stopping, best iteration is:\n",
      "[2728]\ttraining's rmse: 0.0857217\tvalid_1's rmse: 0.0906562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0888913\tvalid_1's rmse: 0.0916831\n",
      "[50]\ttraining's rmse: 0.088762\tvalid_1's rmse: 0.0916287\n",
      "[75]\ttraining's rmse: 0.0886233\tvalid_1's rmse: 0.0915737\n",
      "[100]\ttraining's rmse: 0.0885002\tvalid_1's rmse: 0.0915264\n",
      "[125]\ttraining's rmse: 0.0883721\tvalid_1's rmse: 0.0914777\n",
      "[150]\ttraining's rmse: 0.0882552\tvalid_1's rmse: 0.0914333\n",
      "[175]\ttraining's rmse: 0.0881579\tvalid_1's rmse: 0.0913967\n",
      "[200]\ttraining's rmse: 0.0880527\tvalid_1's rmse: 0.09136\n",
      "[225]\ttraining's rmse: 0.0879511\tvalid_1's rmse: 0.0913257\n",
      "[250]\ttraining's rmse: 0.0878631\tvalid_1's rmse: 0.0912938\n",
      "[275]\ttraining's rmse: 0.0877842\tvalid_1's rmse: 0.0912654\n",
      "[300]\ttraining's rmse: 0.0877026\tvalid_1's rmse: 0.0912378\n",
      "[325]\ttraining's rmse: 0.0876218\tvalid_1's rmse: 0.0912126\n",
      "[350]\ttraining's rmse: 0.0875437\tvalid_1's rmse: 0.0911885\n",
      "[375]\ttraining's rmse: 0.08748\tvalid_1's rmse: 0.0911684\n",
      "[400]\ttraining's rmse: 0.0874103\tvalid_1's rmse: 0.0911486\n",
      "[425]\ttraining's rmse: 0.0873473\tvalid_1's rmse: 0.0911288\n",
      "[450]\ttraining's rmse: 0.0872898\tvalid_1's rmse: 0.0911098\n",
      "[475]\ttraining's rmse: 0.0872363\tvalid_1's rmse: 0.0910939\n",
      "[500]\ttraining's rmse: 0.0871884\tvalid_1's rmse: 0.0910796\n",
      "[525]\ttraining's rmse: 0.0871287\tvalid_1's rmse: 0.0910634\n",
      "[550]\ttraining's rmse: 0.0870713\tvalid_1's rmse: 0.091049\n",
      "[575]\ttraining's rmse: 0.0870217\tvalid_1's rmse: 0.0910349\n",
      "[600]\ttraining's rmse: 0.0869711\tvalid_1's rmse: 0.0910218\n",
      "[625]\ttraining's rmse: 0.0869312\tvalid_1's rmse: 0.0910096\n",
      "[650]\ttraining's rmse: 0.0868841\tvalid_1's rmse: 0.0909985\n",
      "[675]\ttraining's rmse: 0.0868355\tvalid_1's rmse: 0.090988\n",
      "[700]\ttraining's rmse: 0.0867916\tvalid_1's rmse: 0.0909767\n",
      "[725]\ttraining's rmse: 0.0867536\tvalid_1's rmse: 0.0909681\n",
      "[750]\ttraining's rmse: 0.0867155\tvalid_1's rmse: 0.0909593\n",
      "[775]\ttraining's rmse: 0.086683\tvalid_1's rmse: 0.0909505\n",
      "[800]\ttraining's rmse: 0.0866418\tvalid_1's rmse: 0.0909431\n",
      "[825]\ttraining's rmse: 0.0866079\tvalid_1's rmse: 0.0909355\n",
      "[850]\ttraining's rmse: 0.086576\tvalid_1's rmse: 0.0909306\n",
      "[875]\ttraining's rmse: 0.0865471\tvalid_1's rmse: 0.0909243\n",
      "[900]\ttraining's rmse: 0.0865177\tvalid_1's rmse: 0.090918\n",
      "[925]\ttraining's rmse: 0.0864859\tvalid_1's rmse: 0.0909122\n",
      "[950]\ttraining's rmse: 0.0864563\tvalid_1's rmse: 0.0909074\n",
      "[975]\ttraining's rmse: 0.086431\tvalid_1's rmse: 0.0909019\n",
      "[1000]\ttraining's rmse: 0.0864064\tvalid_1's rmse: 0.0908971\n",
      "[1025]\ttraining's rmse: 0.0863778\tvalid_1's rmse: 0.0908928\n",
      "[1050]\ttraining's rmse: 0.0863555\tvalid_1's rmse: 0.0908891\n",
      "[1075]\ttraining's rmse: 0.0863324\tvalid_1's rmse: 0.0908857\n",
      "[1100]\ttraining's rmse: 0.0863133\tvalid_1's rmse: 0.0908824\n",
      "[1125]\ttraining's rmse: 0.086292\tvalid_1's rmse: 0.0908792\n",
      "[1150]\ttraining's rmse: 0.086271\tvalid_1's rmse: 0.090876\n",
      "[1175]\ttraining's rmse: 0.0862535\tvalid_1's rmse: 0.0908732\n",
      "[1200]\ttraining's rmse: 0.086234\tvalid_1's rmse: 0.0908696\n",
      "[1225]\ttraining's rmse: 0.0862175\tvalid_1's rmse: 0.0908669\n",
      "[1250]\ttraining's rmse: 0.0862038\tvalid_1's rmse: 0.090865\n",
      "[1275]\ttraining's rmse: 0.0861853\tvalid_1's rmse: 0.0908638\n",
      "[1300]\ttraining's rmse: 0.0861705\tvalid_1's rmse: 0.0908611\n",
      "[1325]\ttraining's rmse: 0.0861569\tvalid_1's rmse: 0.0908595\n",
      "[1350]\ttraining's rmse: 0.0861403\tvalid_1's rmse: 0.0908579\n",
      "[1375]\ttraining's rmse: 0.0861259\tvalid_1's rmse: 0.0908571\n",
      "[1400]\ttraining's rmse: 0.0861133\tvalid_1's rmse: 0.0908554\n",
      "[1425]\ttraining's rmse: 0.086097\tvalid_1's rmse: 0.0908536\n",
      "[1450]\ttraining's rmse: 0.0860835\tvalid_1's rmse: 0.0908527\n",
      "[1475]\ttraining's rmse: 0.0860718\tvalid_1's rmse: 0.0908508\n",
      "[1500]\ttraining's rmse: 0.0860599\tvalid_1's rmse: 0.0908499\n",
      "[1525]\ttraining's rmse: 0.0860455\tvalid_1's rmse: 0.0908488\n",
      "[1550]\ttraining's rmse: 0.0860347\tvalid_1's rmse: 0.090848\n",
      "[1575]\ttraining's rmse: 0.0860247\tvalid_1's rmse: 0.0908471\n",
      "[1600]\ttraining's rmse: 0.0860156\tvalid_1's rmse: 0.0908468\n",
      "[1625]\ttraining's rmse: 0.0860051\tvalid_1's rmse: 0.0908454\n",
      "[1650]\ttraining's rmse: 0.0859963\tvalid_1's rmse: 0.0908446\n",
      "[1675]\ttraining's rmse: 0.085989\tvalid_1's rmse: 0.0908436\n",
      "[1700]\ttraining's rmse: 0.0859808\tvalid_1's rmse: 0.0908427\n",
      "[1725]\ttraining's rmse: 0.0859739\tvalid_1's rmse: 0.0908419\n",
      "[1750]\ttraining's rmse: 0.085965\tvalid_1's rmse: 0.090841\n",
      "[1775]\ttraining's rmse: 0.0859572\tvalid_1's rmse: 0.0908403\n",
      "[1800]\ttraining's rmse: 0.0859516\tvalid_1's rmse: 0.0908401\n",
      "[1825]\ttraining's rmse: 0.0859448\tvalid_1's rmse: 0.0908396\n",
      "[1850]\ttraining's rmse: 0.0859383\tvalid_1's rmse: 0.0908389\n",
      "[1875]\ttraining's rmse: 0.0859306\tvalid_1's rmse: 0.0908383\n",
      "[1900]\ttraining's rmse: 0.0859247\tvalid_1's rmse: 0.0908386\n",
      "Early stopping, best iteration is:\n",
      "[1873]\ttraining's rmse: 0.085931\tvalid_1's rmse: 0.090838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.09152\tvalid_1's rmse: 0.0863238\n",
      "[50]\ttraining's rmse: 0.09139\tvalid_1's rmse: 0.0862748\n",
      "[75]\ttraining's rmse: 0.0912535\tvalid_1's rmse: 0.0862231\n",
      "[100]\ttraining's rmse: 0.0911316\tvalid_1's rmse: 0.0861812\n",
      "[125]\ttraining's rmse: 0.0910087\tvalid_1's rmse: 0.0861379\n",
      "[150]\ttraining's rmse: 0.0908932\tvalid_1's rmse: 0.0861001\n",
      "[175]\ttraining's rmse: 0.0907958\tvalid_1's rmse: 0.0860675\n",
      "[200]\ttraining's rmse: 0.090691\tvalid_1's rmse: 0.086037\n",
      "[225]\ttraining's rmse: 0.0905896\tvalid_1's rmse: 0.0860054\n",
      "[250]\ttraining's rmse: 0.0905037\tvalid_1's rmse: 0.0859794\n",
      "[275]\ttraining's rmse: 0.0904249\tvalid_1's rmse: 0.0859533\n",
      "[300]\ttraining's rmse: 0.0903441\tvalid_1's rmse: 0.0859284\n",
      "[325]\ttraining's rmse: 0.090267\tvalid_1's rmse: 0.0859051\n",
      "[350]\ttraining's rmse: 0.0901893\tvalid_1's rmse: 0.0858824\n",
      "[375]\ttraining's rmse: 0.0901258\tvalid_1's rmse: 0.085867\n",
      "[400]\ttraining's rmse: 0.0900581\tvalid_1's rmse: 0.0858533\n",
      "[425]\ttraining's rmse: 0.0899949\tvalid_1's rmse: 0.0858373\n",
      "[450]\ttraining's rmse: 0.0899369\tvalid_1's rmse: 0.0858208\n",
      "[475]\ttraining's rmse: 0.0898832\tvalid_1's rmse: 0.0858125\n",
      "[500]\ttraining's rmse: 0.0898379\tvalid_1's rmse: 0.0858043\n",
      "[525]\ttraining's rmse: 0.0897787\tvalid_1's rmse: 0.0857902\n",
      "[550]\ttraining's rmse: 0.0897229\tvalid_1's rmse: 0.0857761\n",
      "[575]\ttraining's rmse: 0.0896729\tvalid_1's rmse: 0.0857638\n",
      "[600]\ttraining's rmse: 0.089622\tvalid_1's rmse: 0.0857538\n",
      "[625]\ttraining's rmse: 0.0895822\tvalid_1's rmse: 0.0857458\n",
      "[650]\ttraining's rmse: 0.0895327\tvalid_1's rmse: 0.0857387\n",
      "[675]\ttraining's rmse: 0.0894838\tvalid_1's rmse: 0.0857354\n",
      "[700]\ttraining's rmse: 0.0894388\tvalid_1's rmse: 0.0857312\n",
      "[725]\ttraining's rmse: 0.0893981\tvalid_1's rmse: 0.0857296\n",
      "[750]\ttraining's rmse: 0.0893578\tvalid_1's rmse: 0.0857263\n",
      "[775]\ttraining's rmse: 0.0893255\tvalid_1's rmse: 0.0857193\n",
      "[800]\ttraining's rmse: 0.089284\tvalid_1's rmse: 0.085714\n",
      "[825]\ttraining's rmse: 0.0892517\tvalid_1's rmse: 0.0857215\n",
      "[850]\ttraining's rmse: 0.0892161\tvalid_1's rmse: 0.0857232\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's rmse: 0.089272\tvalid_1's rmse: 0.0857125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0904217\tvalid_1's rmse: 0.0928016\n",
      "[50]\ttraining's rmse: 0.0902674\tvalid_1's rmse: 0.0927469\n",
      "[75]\ttraining's rmse: 0.090114\tvalid_1's rmse: 0.0926897\n",
      "[100]\ttraining's rmse: 0.0899741\tvalid_1's rmse: 0.0926442\n",
      "[125]\ttraining's rmse: 0.089832\tvalid_1's rmse: 0.0925959\n",
      "[150]\ttraining's rmse: 0.0897013\tvalid_1's rmse: 0.0925501\n",
      "[175]\ttraining's rmse: 0.0895931\tvalid_1's rmse: 0.0925115\n",
      "[200]\ttraining's rmse: 0.0894779\tvalid_1's rmse: 0.0924731\n",
      "[225]\ttraining's rmse: 0.0893606\tvalid_1's rmse: 0.092439\n",
      "[250]\ttraining's rmse: 0.089267\tvalid_1's rmse: 0.0924054\n",
      "[275]\ttraining's rmse: 0.089174\tvalid_1's rmse: 0.0923752\n",
      "[300]\ttraining's rmse: 0.0890868\tvalid_1's rmse: 0.0923452\n",
      "[325]\ttraining's rmse: 0.0889983\tvalid_1's rmse: 0.0923177\n",
      "[350]\ttraining's rmse: 0.0889139\tvalid_1's rmse: 0.0922918\n",
      "[375]\ttraining's rmse: 0.0888426\tvalid_1's rmse: 0.0922711\n",
      "[400]\ttraining's rmse: 0.0887667\tvalid_1's rmse: 0.0922481\n",
      "[425]\ttraining's rmse: 0.0886983\tvalid_1's rmse: 0.0922257\n",
      "[450]\ttraining's rmse: 0.0886321\tvalid_1's rmse: 0.092205\n",
      "[475]\ttraining's rmse: 0.0885715\tvalid_1's rmse: 0.0921845\n",
      "[500]\ttraining's rmse: 0.0885218\tvalid_1's rmse: 0.0921667\n",
      "[525]\ttraining's rmse: 0.0884589\tvalid_1's rmse: 0.0921499\n",
      "[550]\ttraining's rmse: 0.0883998\tvalid_1's rmse: 0.0921333\n",
      "[575]\ttraining's rmse: 0.0883448\tvalid_1's rmse: 0.0921207\n",
      "[600]\ttraining's rmse: 0.0882932\tvalid_1's rmse: 0.092107\n",
      "[625]\ttraining's rmse: 0.0882527\tvalid_1's rmse: 0.0920931\n",
      "[650]\ttraining's rmse: 0.0882033\tvalid_1's rmse: 0.0920795\n",
      "[675]\ttraining's rmse: 0.0881544\tvalid_1's rmse: 0.0920659\n",
      "[700]\ttraining's rmse: 0.0881114\tvalid_1's rmse: 0.0920543\n",
      "[725]\ttraining's rmse: 0.0880702\tvalid_1's rmse: 0.0920446\n",
      "[750]\ttraining's rmse: 0.0880332\tvalid_1's rmse: 0.0920358\n",
      "[775]\ttraining's rmse: 0.0880036\tvalid_1's rmse: 0.0920255\n",
      "[800]\ttraining's rmse: 0.0879648\tvalid_1's rmse: 0.0920174\n",
      "[825]\ttraining's rmse: 0.0879326\tvalid_1's rmse: 0.0920082\n",
      "[850]\ttraining's rmse: 0.0878954\tvalid_1's rmse: 0.0920017\n",
      "[875]\ttraining's rmse: 0.0878639\tvalid_1's rmse: 0.0919942\n",
      "[900]\ttraining's rmse: 0.0878309\tvalid_1's rmse: 0.0919854\n",
      "[925]\ttraining's rmse: 0.087801\tvalid_1's rmse: 0.0919777\n",
      "[950]\ttraining's rmse: 0.0877708\tvalid_1's rmse: 0.0919708\n",
      "[975]\ttraining's rmse: 0.0877413\tvalid_1's rmse: 0.091964\n",
      "[1000]\ttraining's rmse: 0.0877116\tvalid_1's rmse: 0.0919588\n",
      "[1025]\ttraining's rmse: 0.0876854\tvalid_1's rmse: 0.0919506\n",
      "[1050]\ttraining's rmse: 0.0876604\tvalid_1's rmse: 0.0919447\n",
      "[1075]\ttraining's rmse: 0.0876367\tvalid_1's rmse: 0.0919398\n",
      "[1100]\ttraining's rmse: 0.0876154\tvalid_1's rmse: 0.0919353\n",
      "[1125]\ttraining's rmse: 0.0875945\tvalid_1's rmse: 0.0919299\n",
      "[1150]\ttraining's rmse: 0.087574\tvalid_1's rmse: 0.0919255\n",
      "[1175]\ttraining's rmse: 0.0875518\tvalid_1's rmse: 0.0919223\n",
      "[1200]\ttraining's rmse: 0.0875309\tvalid_1's rmse: 0.0919169\n",
      "[1225]\ttraining's rmse: 0.087514\tvalid_1's rmse: 0.091912\n",
      "[1250]\ttraining's rmse: 0.0874982\tvalid_1's rmse: 0.0919071\n",
      "[1275]\ttraining's rmse: 0.0874803\tvalid_1's rmse: 0.0919043\n",
      "[1300]\ttraining's rmse: 0.0874654\tvalid_1's rmse: 0.0918994\n",
      "[1325]\ttraining's rmse: 0.08745\tvalid_1's rmse: 0.0918959\n",
      "[1350]\ttraining's rmse: 0.0874369\tvalid_1's rmse: 0.091893\n",
      "[1375]\ttraining's rmse: 0.0874237\tvalid_1's rmse: 0.0918898\n",
      "[1400]\ttraining's rmse: 0.0874106\tvalid_1's rmse: 0.0918858\n",
      "[1425]\ttraining's rmse: 0.0873933\tvalid_1's rmse: 0.0918832\n",
      "[1450]\ttraining's rmse: 0.0873763\tvalid_1's rmse: 0.0918804\n",
      "[1475]\ttraining's rmse: 0.0873656\tvalid_1's rmse: 0.0918783\n",
      "[1500]\ttraining's rmse: 0.087355\tvalid_1's rmse: 0.0918749\n",
      "[1525]\ttraining's rmse: 0.0873443\tvalid_1's rmse: 0.0918719\n",
      "[1550]\ttraining's rmse: 0.087333\tvalid_1's rmse: 0.0918687\n",
      "[1575]\ttraining's rmse: 0.0873226\tvalid_1's rmse: 0.0918669\n",
      "[1600]\ttraining's rmse: 0.0873119\tvalid_1's rmse: 0.0918633\n",
      "[1625]\ttraining's rmse: 0.0873013\tvalid_1's rmse: 0.0918606\n",
      "[1650]\ttraining's rmse: 0.0872918\tvalid_1's rmse: 0.0918582\n",
      "[1675]\ttraining's rmse: 0.0872831\tvalid_1's rmse: 0.0918561\n",
      "[1700]\ttraining's rmse: 0.0872733\tvalid_1's rmse: 0.0918545\n",
      "[1725]\ttraining's rmse: 0.0872626\tvalid_1's rmse: 0.0918525\n",
      "[1750]\ttraining's rmse: 0.0872497\tvalid_1's rmse: 0.0918498\n",
      "[1775]\ttraining's rmse: 0.087244\tvalid_1's rmse: 0.0918485\n",
      "[1800]\ttraining's rmse: 0.0872347\tvalid_1's rmse: 0.0918456\n",
      "[1825]\ttraining's rmse: 0.0872293\tvalid_1's rmse: 0.0918443\n",
      "[1850]\ttraining's rmse: 0.0872225\tvalid_1's rmse: 0.0918413\n",
      "[1875]\ttraining's rmse: 0.0872158\tvalid_1's rmse: 0.0918397\n",
      "[1900]\ttraining's rmse: 0.0872097\tvalid_1's rmse: 0.0918391\n",
      "[1925]\ttraining's rmse: 0.0872037\tvalid_1's rmse: 0.091838\n",
      "[1950]\ttraining's rmse: 0.0872\tvalid_1's rmse: 0.0918363\n",
      "[1975]\ttraining's rmse: 0.0871966\tvalid_1's rmse: 0.0918358\n",
      "[2000]\ttraining's rmse: 0.0871924\tvalid_1's rmse: 0.0918351\n",
      "[2025]\ttraining's rmse: 0.0871877\tvalid_1's rmse: 0.0918335\n",
      "[2050]\ttraining's rmse: 0.0871838\tvalid_1's rmse: 0.0918314\n",
      "[2075]\ttraining's rmse: 0.0871808\tvalid_1's rmse: 0.0918303\n",
      "[2100]\ttraining's rmse: 0.0871768\tvalid_1's rmse: 0.0918299\n",
      "[2125]\ttraining's rmse: 0.0871724\tvalid_1's rmse: 0.0918284\n",
      "[2150]\ttraining's rmse: 0.0871678\tvalid_1's rmse: 0.0918262\n",
      "[2175]\ttraining's rmse: 0.0871644\tvalid_1's rmse: 0.0918247\n",
      "[2200]\ttraining's rmse: 0.0871613\tvalid_1's rmse: 0.0918231\n",
      "[2225]\ttraining's rmse: 0.087157\tvalid_1's rmse: 0.0918222\n",
      "[2250]\ttraining's rmse: 0.0871545\tvalid_1's rmse: 0.0918211\n",
      "[2275]\ttraining's rmse: 0.0871501\tvalid_1's rmse: 0.0918208\n",
      "[2300]\ttraining's rmse: 0.0871475\tvalid_1's rmse: 0.0918204\n",
      "[2325]\ttraining's rmse: 0.0871434\tvalid_1's rmse: 0.0918192\n",
      "[2350]\ttraining's rmse: 0.08714\tvalid_1's rmse: 0.0918175\n",
      "[2375]\ttraining's rmse: 0.0871373\tvalid_1's rmse: 0.0918168\n",
      "[2400]\ttraining's rmse: 0.0871336\tvalid_1's rmse: 0.0918162\n",
      "[2425]\ttraining's rmse: 0.0871304\tvalid_1's rmse: 0.0918155\n",
      "[2450]\ttraining's rmse: 0.0871269\tvalid_1's rmse: 0.0918153\n",
      "[2475]\ttraining's rmse: 0.087124\tvalid_1's rmse: 0.0918148\n",
      "[2500]\ttraining's rmse: 0.0871216\tvalid_1's rmse: 0.0918145\n",
      "[2525]\ttraining's rmse: 0.0871187\tvalid_1's rmse: 0.0918142\n",
      "[2550]\ttraining's rmse: 0.0871151\tvalid_1's rmse: 0.0918139\n",
      "[2575]\ttraining's rmse: 0.0871118\tvalid_1's rmse: 0.0918139\n",
      "[2600]\ttraining's rmse: 0.087109\tvalid_1's rmse: 0.0918132\n",
      "[2625]\ttraining's rmse: 0.0871061\tvalid_1's rmse: 0.0918116\n",
      "[2650]\ttraining's rmse: 0.087104\tvalid_1's rmse: 0.0918106\n",
      "[2675]\ttraining's rmse: 0.0871019\tvalid_1's rmse: 0.0918096\n",
      "[2700]\ttraining's rmse: 0.0871003\tvalid_1's rmse: 0.0918094\n",
      "[2725]\ttraining's rmse: 0.0870975\tvalid_1's rmse: 0.0918089\n",
      "[2750]\ttraining's rmse: 0.0870954\tvalid_1's rmse: 0.0918081\n",
      "[2775]\ttraining's rmse: 0.0870937\tvalid_1's rmse: 0.0918081\n",
      "[2800]\ttraining's rmse: 0.0870915\tvalid_1's rmse: 0.0918075\n",
      "[2825]\ttraining's rmse: 0.08709\tvalid_1's rmse: 0.0918076\n",
      "[2850]\ttraining's rmse: 0.0870874\tvalid_1's rmse: 0.0918075\n",
      "Early stopping, best iteration is:\n",
      "[2811]\ttraining's rmse: 0.087091\tvalid_1's rmse: 0.0918072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0903842\tvalid_1's rmse: 0.0928958\n",
      "[50]\ttraining's rmse: 0.090247\tvalid_1's rmse: 0.0928392\n",
      "[75]\ttraining's rmse: 0.0901038\tvalid_1's rmse: 0.0927849\n",
      "[100]\ttraining's rmse: 0.0899772\tvalid_1's rmse: 0.0927369\n",
      "[125]\ttraining's rmse: 0.0898422\tvalid_1's rmse: 0.092687\n",
      "[150]\ttraining's rmse: 0.0897183\tvalid_1's rmse: 0.0926426\n",
      "[175]\ttraining's rmse: 0.0896184\tvalid_1's rmse: 0.0926054\n",
      "[200]\ttraining's rmse: 0.0895087\tvalid_1's rmse: 0.0925671\n",
      "[225]\ttraining's rmse: 0.0894039\tvalid_1's rmse: 0.092532\n",
      "[250]\ttraining's rmse: 0.0893149\tvalid_1's rmse: 0.0924999\n",
      "[275]\ttraining's rmse: 0.0892303\tvalid_1's rmse: 0.092472\n",
      "[300]\ttraining's rmse: 0.0891495\tvalid_1's rmse: 0.0924461\n",
      "[325]\ttraining's rmse: 0.0890657\tvalid_1's rmse: 0.09242\n",
      "[350]\ttraining's rmse: 0.0889846\tvalid_1's rmse: 0.0923965\n",
      "[375]\ttraining's rmse: 0.0889199\tvalid_1's rmse: 0.0923756\n",
      "[400]\ttraining's rmse: 0.0888479\tvalid_1's rmse: 0.0923539\n",
      "[425]\ttraining's rmse: 0.0887831\tvalid_1's rmse: 0.0923346\n",
      "[450]\ttraining's rmse: 0.0887246\tvalid_1's rmse: 0.0923171\n",
      "[475]\ttraining's rmse: 0.0886694\tvalid_1's rmse: 0.0923\n",
      "[500]\ttraining's rmse: 0.0886221\tvalid_1's rmse: 0.0922849\n",
      "[525]\ttraining's rmse: 0.0885601\tvalid_1's rmse: 0.0922694\n",
      "[550]\ttraining's rmse: 0.0885037\tvalid_1's rmse: 0.0922545\n",
      "[575]\ttraining's rmse: 0.0884486\tvalid_1's rmse: 0.0922397\n",
      "[600]\ttraining's rmse: 0.0883968\tvalid_1's rmse: 0.092227\n",
      "[625]\ttraining's rmse: 0.0883553\tvalid_1's rmse: 0.0922155\n",
      "[650]\ttraining's rmse: 0.0883044\tvalid_1's rmse: 0.092202\n",
      "[675]\ttraining's rmse: 0.0882535\tvalid_1's rmse: 0.0921902\n",
      "[700]\ttraining's rmse: 0.0882098\tvalid_1's rmse: 0.0921804\n",
      "[725]\ttraining's rmse: 0.0881672\tvalid_1's rmse: 0.0921712\n",
      "[750]\ttraining's rmse: 0.0881281\tvalid_1's rmse: 0.0921627\n",
      "[775]\ttraining's rmse: 0.088095\tvalid_1's rmse: 0.0921538\n",
      "[800]\ttraining's rmse: 0.0880538\tvalid_1's rmse: 0.0921474\n",
      "[825]\ttraining's rmse: 0.0880192\tvalid_1's rmse: 0.0921385\n",
      "[850]\ttraining's rmse: 0.0879832\tvalid_1's rmse: 0.092133\n",
      "[875]\ttraining's rmse: 0.0879516\tvalid_1's rmse: 0.0921269\n",
      "[900]\ttraining's rmse: 0.0879169\tvalid_1's rmse: 0.0921211\n",
      "[925]\ttraining's rmse: 0.0878844\tvalid_1's rmse: 0.0921159\n",
      "[950]\ttraining's rmse: 0.0878552\tvalid_1's rmse: 0.0921096\n",
      "[975]\ttraining's rmse: 0.0878275\tvalid_1's rmse: 0.0921039\n",
      "[1000]\ttraining's rmse: 0.0878018\tvalid_1's rmse: 0.0920983\n",
      "[1025]\ttraining's rmse: 0.0877711\tvalid_1's rmse: 0.0920948\n",
      "[1050]\ttraining's rmse: 0.0877471\tvalid_1's rmse: 0.0920912\n",
      "[1075]\ttraining's rmse: 0.0877208\tvalid_1's rmse: 0.0920879\n",
      "[1100]\ttraining's rmse: 0.0876997\tvalid_1's rmse: 0.0920847\n",
      "[1125]\ttraining's rmse: 0.0876771\tvalid_1's rmse: 0.0920813\n",
      "[1150]\ttraining's rmse: 0.087654\tvalid_1's rmse: 0.0920779\n",
      "[1175]\ttraining's rmse: 0.0876326\tvalid_1's rmse: 0.0920755\n",
      "[1200]\ttraining's rmse: 0.0876086\tvalid_1's rmse: 0.0920725\n",
      "[1225]\ttraining's rmse: 0.0875908\tvalid_1's rmse: 0.0920701\n",
      "[1250]\ttraining's rmse: 0.0875757\tvalid_1's rmse: 0.0920685\n",
      "[1275]\ttraining's rmse: 0.0875567\tvalid_1's rmse: 0.0920663\n",
      "[1300]\ttraining's rmse: 0.0875407\tvalid_1's rmse: 0.0920637\n",
      "[1325]\ttraining's rmse: 0.0875214\tvalid_1's rmse: 0.0920619\n",
      "[1350]\ttraining's rmse: 0.0875056\tvalid_1's rmse: 0.092061\n",
      "[1375]\ttraining's rmse: 0.0874894\tvalid_1's rmse: 0.092059\n",
      "[1400]\ttraining's rmse: 0.0874773\tvalid_1's rmse: 0.0920576\n",
      "[1425]\ttraining's rmse: 0.0874625\tvalid_1's rmse: 0.092057\n",
      "[1450]\ttraining's rmse: 0.0874476\tvalid_1's rmse: 0.0920555\n",
      "[1475]\ttraining's rmse: 0.0874343\tvalid_1's rmse: 0.0920537\n",
      "[1500]\ttraining's rmse: 0.0874196\tvalid_1's rmse: 0.092052\n",
      "[1525]\ttraining's rmse: 0.0874084\tvalid_1's rmse: 0.0920506\n",
      "[1550]\ttraining's rmse: 0.0873961\tvalid_1's rmse: 0.0920496\n",
      "[1575]\ttraining's rmse: 0.0873848\tvalid_1's rmse: 0.0920488\n",
      "[1600]\ttraining's rmse: 0.0873745\tvalid_1's rmse: 0.0920486\n",
      "[1625]\ttraining's rmse: 0.0873631\tvalid_1's rmse: 0.0920477\n",
      "[1650]\ttraining's rmse: 0.0873543\tvalid_1's rmse: 0.0920473\n",
      "[1675]\ttraining's rmse: 0.0873454\tvalid_1's rmse: 0.0920464\n",
      "[1700]\ttraining's rmse: 0.0873381\tvalid_1's rmse: 0.0920448\n",
      "[1725]\ttraining's rmse: 0.0873277\tvalid_1's rmse: 0.0920438\n",
      "[1750]\ttraining's rmse: 0.0873169\tvalid_1's rmse: 0.0920436\n",
      "[1775]\ttraining's rmse: 0.0873081\tvalid_1's rmse: 0.0920434\n",
      "[1800]\ttraining's rmse: 0.0873008\tvalid_1's rmse: 0.0920429\n",
      "[1825]\ttraining's rmse: 0.0872937\tvalid_1's rmse: 0.092042\n",
      "[1850]\ttraining's rmse: 0.0872881\tvalid_1's rmse: 0.0920412\n",
      "[1875]\ttraining's rmse: 0.0872813\tvalid_1's rmse: 0.0920404\n",
      "[1900]\ttraining's rmse: 0.0872752\tvalid_1's rmse: 0.0920397\n",
      "[1925]\ttraining's rmse: 0.0872683\tvalid_1's rmse: 0.0920396\n",
      "[1950]\ttraining's rmse: 0.0872636\tvalid_1's rmse: 0.0920392\n",
      "[1975]\ttraining's rmse: 0.0872591\tvalid_1's rmse: 0.0920387\n",
      "[2000]\ttraining's rmse: 0.0872538\tvalid_1's rmse: 0.092038\n",
      "[2025]\ttraining's rmse: 0.0872483\tvalid_1's rmse: 0.0920368\n",
      "[2050]\ttraining's rmse: 0.0872435\tvalid_1's rmse: 0.0920373\n",
      "[2075]\ttraining's rmse: 0.0872397\tvalid_1's rmse: 0.0920368\n",
      "Early stopping, best iteration is:\n",
      "[2025]\ttraining's rmse: 0.0872483\tvalid_1's rmse: 0.0920368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0927068\tvalid_1's rmse: 0.0881882\n",
      "[50]\ttraining's rmse: 0.0925743\tvalid_1's rmse: 0.088139\n",
      "[75]\ttraining's rmse: 0.0924385\tvalid_1's rmse: 0.0880901\n",
      "[100]\ttraining's rmse: 0.0923165\tvalid_1's rmse: 0.088048\n",
      "[125]\ttraining's rmse: 0.0921866\tvalid_1's rmse: 0.0880025\n",
      "[150]\ttraining's rmse: 0.0920695\tvalid_1's rmse: 0.0879637\n",
      "[175]\ttraining's rmse: 0.0919716\tvalid_1's rmse: 0.0879347\n",
      "[200]\ttraining's rmse: 0.0918665\tvalid_1's rmse: 0.0879012\n",
      "[225]\ttraining's rmse: 0.0917632\tvalid_1's rmse: 0.0878681\n",
      "[250]\ttraining's rmse: 0.0916742\tvalid_1's rmse: 0.0878402\n",
      "[275]\ttraining's rmse: 0.0915954\tvalid_1's rmse: 0.0878146\n",
      "[300]\ttraining's rmse: 0.0915147\tvalid_1's rmse: 0.0877913\n",
      "[325]\ttraining's rmse: 0.0914323\tvalid_1's rmse: 0.0877667\n",
      "[350]\ttraining's rmse: 0.0913515\tvalid_1's rmse: 0.0877439\n",
      "[375]\ttraining's rmse: 0.091287\tvalid_1's rmse: 0.0877284\n",
      "[400]\ttraining's rmse: 0.0912173\tvalid_1's rmse: 0.0877139\n",
      "[425]\ttraining's rmse: 0.091152\tvalid_1's rmse: 0.087697\n",
      "[450]\ttraining's rmse: 0.0910922\tvalid_1's rmse: 0.0876815\n",
      "[475]\ttraining's rmse: 0.0910359\tvalid_1's rmse: 0.0876673\n",
      "[500]\ttraining's rmse: 0.09099\tvalid_1's rmse: 0.0876564\n",
      "[525]\ttraining's rmse: 0.0909301\tvalid_1's rmse: 0.0876544\n",
      "[550]\ttraining's rmse: 0.0908741\tvalid_1's rmse: 0.0876405\n",
      "[575]\ttraining's rmse: 0.0908208\tvalid_1's rmse: 0.0876334\n",
      "[600]\ttraining's rmse: 0.0907696\tvalid_1's rmse: 0.0876289\n",
      "[625]\ttraining's rmse: 0.0907287\tvalid_1's rmse: 0.0876199\n",
      "[650]\ttraining's rmse: 0.0906759\tvalid_1's rmse: 0.0876101\n",
      "[675]\ttraining's rmse: 0.0906235\tvalid_1's rmse: 0.087605\n",
      "[700]\ttraining's rmse: 0.0905797\tvalid_1's rmse: 0.0876007\n",
      "[725]\ttraining's rmse: 0.0905384\tvalid_1's rmse: 0.0875938\n",
      "[750]\ttraining's rmse: 0.0904994\tvalid_1's rmse: 0.0875871\n",
      "[775]\ttraining's rmse: 0.0904657\tvalid_1's rmse: 0.0875795\n",
      "[800]\ttraining's rmse: 0.0904229\tvalid_1's rmse: 0.0875803\n",
      "[825]\ttraining's rmse: 0.0903872\tvalid_1's rmse: 0.0875764\n",
      "[850]\ttraining's rmse: 0.0903508\tvalid_1's rmse: 0.0875719\n",
      "[875]\ttraining's rmse: 0.0903197\tvalid_1's rmse: 0.087576\n",
      "[900]\ttraining's rmse: 0.0902832\tvalid_1's rmse: 0.08759\n",
      "Early stopping, best iteration is:\n",
      "[872]\ttraining's rmse: 0.0903219\tvalid_1's rmse: 0.0875674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0919611\tvalid_1's rmse: 0.0938527\n",
      "[50]\ttraining's rmse: 0.0917656\tvalid_1's rmse: 0.0937961\n",
      "[75]\ttraining's rmse: 0.0915739\tvalid_1's rmse: 0.0937391\n",
      "[100]\ttraining's rmse: 0.0913992\tvalid_1's rmse: 0.0936918\n",
      "[125]\ttraining's rmse: 0.0912271\tvalid_1's rmse: 0.0936423\n",
      "[150]\ttraining's rmse: 0.091071\tvalid_1's rmse: 0.0935976\n",
      "[175]\ttraining's rmse: 0.0909375\tvalid_1's rmse: 0.0935594\n",
      "[200]\ttraining's rmse: 0.0907956\tvalid_1's rmse: 0.0935231\n",
      "[225]\ttraining's rmse: 0.0906626\tvalid_1's rmse: 0.0934873\n",
      "[250]\ttraining's rmse: 0.0905434\tvalid_1's rmse: 0.0934525\n",
      "[275]\ttraining's rmse: 0.0904339\tvalid_1's rmse: 0.0934239\n",
      "[300]\ttraining's rmse: 0.090328\tvalid_1's rmse: 0.0933948\n",
      "[325]\ttraining's rmse: 0.0902247\tvalid_1's rmse: 0.0933661\n",
      "[350]\ttraining's rmse: 0.0901249\tvalid_1's rmse: 0.0933399\n",
      "[375]\ttraining's rmse: 0.0900385\tvalid_1's rmse: 0.0933164\n",
      "[400]\ttraining's rmse: 0.0899482\tvalid_1's rmse: 0.0932946\n",
      "[425]\ttraining's rmse: 0.0898693\tvalid_1's rmse: 0.0932723\n",
      "[450]\ttraining's rmse: 0.0897986\tvalid_1's rmse: 0.0932498\n",
      "[475]\ttraining's rmse: 0.0897314\tvalid_1's rmse: 0.0932287\n",
      "[500]\ttraining's rmse: 0.0896705\tvalid_1's rmse: 0.0932107\n",
      "[525]\ttraining's rmse: 0.0895935\tvalid_1's rmse: 0.093194\n",
      "[550]\ttraining's rmse: 0.0895263\tvalid_1's rmse: 0.0931776\n",
      "[575]\ttraining's rmse: 0.0894669\tvalid_1's rmse: 0.0931625\n",
      "[600]\ttraining's rmse: 0.0894057\tvalid_1's rmse: 0.0931472\n",
      "[625]\ttraining's rmse: 0.0893558\tvalid_1's rmse: 0.0931354\n",
      "[650]\ttraining's rmse: 0.0893021\tvalid_1's rmse: 0.0931214\n",
      "[675]\ttraining's rmse: 0.0892501\tvalid_1's rmse: 0.0931071\n",
      "[700]\ttraining's rmse: 0.0892001\tvalid_1's rmse: 0.0930935\n",
      "[725]\ttraining's rmse: 0.0891556\tvalid_1's rmse: 0.0930833\n",
      "[750]\ttraining's rmse: 0.0891143\tvalid_1's rmse: 0.0930746\n",
      "[775]\ttraining's rmse: 0.0890781\tvalid_1's rmse: 0.0930643\n",
      "[800]\ttraining's rmse: 0.0890314\tvalid_1's rmse: 0.0930546\n",
      "[825]\ttraining's rmse: 0.0889937\tvalid_1's rmse: 0.0930453\n",
      "[850]\ttraining's rmse: 0.0889508\tvalid_1's rmse: 0.0930355\n",
      "[875]\ttraining's rmse: 0.0889191\tvalid_1's rmse: 0.0930286\n",
      "[900]\ttraining's rmse: 0.0888833\tvalid_1's rmse: 0.0930193\n",
      "[925]\ttraining's rmse: 0.08885\tvalid_1's rmse: 0.0930113\n",
      "[950]\ttraining's rmse: 0.088819\tvalid_1's rmse: 0.0930031\n",
      "[975]\ttraining's rmse: 0.0887902\tvalid_1's rmse: 0.0929956\n",
      "[1000]\ttraining's rmse: 0.0887585\tvalid_1's rmse: 0.092988\n",
      "[1025]\ttraining's rmse: 0.0887269\tvalid_1's rmse: 0.0929818\n",
      "[1050]\ttraining's rmse: 0.0887006\tvalid_1's rmse: 0.0929744\n",
      "[1075]\ttraining's rmse: 0.088674\tvalid_1's rmse: 0.0929688\n",
      "[1100]\ttraining's rmse: 0.0886517\tvalid_1's rmse: 0.0929623\n",
      "[1125]\ttraining's rmse: 0.0886296\tvalid_1's rmse: 0.0929563\n",
      "[1150]\ttraining's rmse: 0.088606\tvalid_1's rmse: 0.0929512\n",
      "[1175]\ttraining's rmse: 0.0885856\tvalid_1's rmse: 0.0929463\n",
      "[1200]\ttraining's rmse: 0.0885683\tvalid_1's rmse: 0.0929408\n",
      "[1225]\ttraining's rmse: 0.0885501\tvalid_1's rmse: 0.0929372\n",
      "[1250]\ttraining's rmse: 0.0885322\tvalid_1's rmse: 0.0929326\n",
      "[1275]\ttraining's rmse: 0.0885101\tvalid_1's rmse: 0.0929291\n",
      "[1300]\ttraining's rmse: 0.0884956\tvalid_1's rmse: 0.0929256\n",
      "[1325]\ttraining's rmse: 0.0884792\tvalid_1's rmse: 0.0929219\n",
      "[1350]\ttraining's rmse: 0.0884616\tvalid_1's rmse: 0.0929192\n",
      "[1375]\ttraining's rmse: 0.0884458\tvalid_1's rmse: 0.0929165\n",
      "[1400]\ttraining's rmse: 0.0884327\tvalid_1's rmse: 0.0929125\n",
      "[1425]\ttraining's rmse: 0.0884147\tvalid_1's rmse: 0.0929097\n",
      "[1450]\ttraining's rmse: 0.0883988\tvalid_1's rmse: 0.0929059\n",
      "[1475]\ttraining's rmse: 0.0883878\tvalid_1's rmse: 0.0929042\n",
      "[1500]\ttraining's rmse: 0.0883761\tvalid_1's rmse: 0.0929022\n",
      "[1525]\ttraining's rmse: 0.0883628\tvalid_1's rmse: 0.0929\n",
      "[1550]\ttraining's rmse: 0.0883482\tvalid_1's rmse: 0.0928988\n",
      "[1575]\ttraining's rmse: 0.088338\tvalid_1's rmse: 0.092896\n",
      "[1600]\ttraining's rmse: 0.0883281\tvalid_1's rmse: 0.0928938\n",
      "[1625]\ttraining's rmse: 0.088318\tvalid_1's rmse: 0.0928896\n",
      "[1650]\ttraining's rmse: 0.0883091\tvalid_1's rmse: 0.0928869\n",
      "[1675]\ttraining's rmse: 0.0883029\tvalid_1's rmse: 0.0928848\n",
      "[1700]\ttraining's rmse: 0.088293\tvalid_1's rmse: 0.0928829\n",
      "[1725]\ttraining's rmse: 0.0882834\tvalid_1's rmse: 0.0928802\n",
      "[1750]\ttraining's rmse: 0.0882743\tvalid_1's rmse: 0.0928769\n",
      "[1775]\ttraining's rmse: 0.0882666\tvalid_1's rmse: 0.0928756\n",
      "[1800]\ttraining's rmse: 0.0882595\tvalid_1's rmse: 0.0928738\n",
      "[1825]\ttraining's rmse: 0.0882522\tvalid_1's rmse: 0.0928713\n",
      "[1850]\ttraining's rmse: 0.0882446\tvalid_1's rmse: 0.0928682\n",
      "[1875]\ttraining's rmse: 0.0882374\tvalid_1's rmse: 0.0928666\n",
      "[1900]\ttraining's rmse: 0.0882324\tvalid_1's rmse: 0.0928651\n",
      "[1925]\ttraining's rmse: 0.0882262\tvalid_1's rmse: 0.0928642\n",
      "[1950]\ttraining's rmse: 0.0882214\tvalid_1's rmse: 0.0928624\n",
      "[1975]\ttraining's rmse: 0.0882158\tvalid_1's rmse: 0.0928599\n",
      "[2000]\ttraining's rmse: 0.0882094\tvalid_1's rmse: 0.0928589\n",
      "[2025]\ttraining's rmse: 0.0882044\tvalid_1's rmse: 0.0928575\n",
      "[2050]\ttraining's rmse: 0.0881998\tvalid_1's rmse: 0.0928556\n",
      "[2075]\ttraining's rmse: 0.0881962\tvalid_1's rmse: 0.092855\n",
      "[2100]\ttraining's rmse: 0.0881923\tvalid_1's rmse: 0.0928537\n",
      "[2125]\ttraining's rmse: 0.0881885\tvalid_1's rmse: 0.0928518\n",
      "[2150]\ttraining's rmse: 0.0881835\tvalid_1's rmse: 0.0928506\n",
      "[2175]\ttraining's rmse: 0.0881789\tvalid_1's rmse: 0.0928501\n",
      "[2200]\ttraining's rmse: 0.0881753\tvalid_1's rmse: 0.0928488\n",
      "[2225]\ttraining's rmse: 0.0881712\tvalid_1's rmse: 0.0928476\n",
      "[2250]\ttraining's rmse: 0.088168\tvalid_1's rmse: 0.0928466\n",
      "[2275]\ttraining's rmse: 0.0881629\tvalid_1's rmse: 0.0928457\n",
      "[2300]\ttraining's rmse: 0.0881596\tvalid_1's rmse: 0.0928437\n",
      "[2325]\ttraining's rmse: 0.0881551\tvalid_1's rmse: 0.092843\n",
      "[2350]\ttraining's rmse: 0.0881521\tvalid_1's rmse: 0.0928426\n",
      "[2375]\ttraining's rmse: 0.0881494\tvalid_1's rmse: 0.0928421\n",
      "[2400]\ttraining's rmse: 0.0881454\tvalid_1's rmse: 0.0928408\n",
      "[2425]\ttraining's rmse: 0.0881409\tvalid_1's rmse: 0.09284\n",
      "[2450]\ttraining's rmse: 0.0881393\tvalid_1's rmse: 0.0928394\n",
      "[2475]\ttraining's rmse: 0.0881355\tvalid_1's rmse: 0.0928387\n",
      "[2500]\ttraining's rmse: 0.0881322\tvalid_1's rmse: 0.0928379\n",
      "[2525]\ttraining's rmse: 0.08813\tvalid_1's rmse: 0.092837\n",
      "[2550]\ttraining's rmse: 0.0881259\tvalid_1's rmse: 0.092836\n",
      "[2575]\ttraining's rmse: 0.0881226\tvalid_1's rmse: 0.0928355\n",
      "[2600]\ttraining's rmse: 0.0881186\tvalid_1's rmse: 0.0928346\n",
      "[2625]\ttraining's rmse: 0.0881161\tvalid_1's rmse: 0.0928339\n",
      "[2650]\ttraining's rmse: 0.0881136\tvalid_1's rmse: 0.0928336\n",
      "[2675]\ttraining's rmse: 0.0881115\tvalid_1's rmse: 0.0928337\n",
      "Early stopping, best iteration is:\n",
      "[2635]\ttraining's rmse: 0.0881151\tvalid_1's rmse: 0.0928335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0918675\tvalid_1's rmse: 0.0940502\n",
      "[50]\ttraining's rmse: 0.09169\tvalid_1's rmse: 0.0939929\n",
      "[75]\ttraining's rmse: 0.0915112\tvalid_1's rmse: 0.0939362\n",
      "[100]\ttraining's rmse: 0.0913502\tvalid_1's rmse: 0.0938869\n",
      "[125]\ttraining's rmse: 0.0911865\tvalid_1's rmse: 0.0938382\n",
      "[150]\ttraining's rmse: 0.0910395\tvalid_1's rmse: 0.0937927\n",
      "[175]\ttraining's rmse: 0.0909137\tvalid_1's rmse: 0.0937558\n",
      "[200]\ttraining's rmse: 0.09078\tvalid_1's rmse: 0.0937178\n",
      "[225]\ttraining's rmse: 0.0906563\tvalid_1's rmse: 0.0936829\n",
      "[250]\ttraining's rmse: 0.0905474\tvalid_1's rmse: 0.0936505\n",
      "[275]\ttraining's rmse: 0.0904446\tvalid_1's rmse: 0.0936218\n",
      "[300]\ttraining's rmse: 0.0903404\tvalid_1's rmse: 0.0935923\n",
      "[325]\ttraining's rmse: 0.0902443\tvalid_1's rmse: 0.0935653\n",
      "[350]\ttraining's rmse: 0.0901474\tvalid_1's rmse: 0.0935404\n",
      "[375]\ttraining's rmse: 0.0900701\tvalid_1's rmse: 0.0935185\n",
      "[400]\ttraining's rmse: 0.0899872\tvalid_1's rmse: 0.093497\n",
      "[425]\ttraining's rmse: 0.0899082\tvalid_1's rmse: 0.0934761\n",
      "[450]\ttraining's rmse: 0.0898369\tvalid_1's rmse: 0.0934579\n",
      "[475]\ttraining's rmse: 0.0897714\tvalid_1's rmse: 0.0934402\n",
      "[500]\ttraining's rmse: 0.0897147\tvalid_1's rmse: 0.0934234\n",
      "[525]\ttraining's rmse: 0.0896451\tvalid_1's rmse: 0.0934068\n",
      "[550]\ttraining's rmse: 0.089578\tvalid_1's rmse: 0.0933911\n",
      "[575]\ttraining's rmse: 0.0895184\tvalid_1's rmse: 0.0933773\n",
      "[600]\ttraining's rmse: 0.0894617\tvalid_1's rmse: 0.0933646\n",
      "[625]\ttraining's rmse: 0.0894141\tvalid_1's rmse: 0.0933529\n",
      "[650]\ttraining's rmse: 0.0893588\tvalid_1's rmse: 0.0933405\n",
      "[675]\ttraining's rmse: 0.0893084\tvalid_1's rmse: 0.0933294\n",
      "[700]\ttraining's rmse: 0.0892582\tvalid_1's rmse: 0.0933176\n",
      "[725]\ttraining's rmse: 0.0892138\tvalid_1's rmse: 0.0933082\n",
      "[750]\ttraining's rmse: 0.0891711\tvalid_1's rmse: 0.0932979\n",
      "[775]\ttraining's rmse: 0.0891359\tvalid_1's rmse: 0.0932886\n",
      "[800]\ttraining's rmse: 0.0890922\tvalid_1's rmse: 0.0932814\n",
      "[825]\ttraining's rmse: 0.089056\tvalid_1's rmse: 0.093273\n",
      "[850]\ttraining's rmse: 0.089019\tvalid_1's rmse: 0.093267\n",
      "[875]\ttraining's rmse: 0.0889873\tvalid_1's rmse: 0.0932606\n",
      "[900]\ttraining's rmse: 0.0889511\tvalid_1's rmse: 0.0932535\n",
      "[925]\ttraining's rmse: 0.0889168\tvalid_1's rmse: 0.0932466\n",
      "[950]\ttraining's rmse: 0.0888868\tvalid_1's rmse: 0.0932407\n",
      "[975]\ttraining's rmse: 0.0888579\tvalid_1's rmse: 0.0932357\n",
      "[1000]\ttraining's rmse: 0.0888296\tvalid_1's rmse: 0.0932311\n",
      "[1025]\ttraining's rmse: 0.0887975\tvalid_1's rmse: 0.093226\n",
      "[1050]\ttraining's rmse: 0.0887709\tvalid_1's rmse: 0.0932215\n",
      "[1075]\ttraining's rmse: 0.088743\tvalid_1's rmse: 0.0932186\n",
      "[1100]\ttraining's rmse: 0.0887209\tvalid_1's rmse: 0.0932139\n",
      "[1125]\ttraining's rmse: 0.0886972\tvalid_1's rmse: 0.0932096\n",
      "[1150]\ttraining's rmse: 0.088675\tvalid_1's rmse: 0.0932063\n",
      "[1175]\ttraining's rmse: 0.0886548\tvalid_1's rmse: 0.0932045\n",
      "[1200]\ttraining's rmse: 0.0886332\tvalid_1's rmse: 0.0932017\n",
      "[1225]\ttraining's rmse: 0.0886149\tvalid_1's rmse: 0.0931993\n",
      "[1250]\ttraining's rmse: 0.0885992\tvalid_1's rmse: 0.0931974\n",
      "[1275]\ttraining's rmse: 0.0885777\tvalid_1's rmse: 0.0931962\n",
      "[1300]\ttraining's rmse: 0.0885619\tvalid_1's rmse: 0.0931938\n",
      "[1325]\ttraining's rmse: 0.0885449\tvalid_1's rmse: 0.0931917\n",
      "[1350]\ttraining's rmse: 0.0885271\tvalid_1's rmse: 0.0931903\n",
      "[1375]\ttraining's rmse: 0.0885116\tvalid_1's rmse: 0.0931885\n",
      "[1400]\ttraining's rmse: 0.0884984\tvalid_1's rmse: 0.0931867\n",
      "[1425]\ttraining's rmse: 0.0884829\tvalid_1's rmse: 0.0931849\n",
      "[1450]\ttraining's rmse: 0.088465\tvalid_1's rmse: 0.0931836\n",
      "[1475]\ttraining's rmse: 0.08845\tvalid_1's rmse: 0.0931821\n",
      "[1500]\ttraining's rmse: 0.0884375\tvalid_1's rmse: 0.0931807\n",
      "[1525]\ttraining's rmse: 0.0884241\tvalid_1's rmse: 0.0931796\n",
      "[1550]\ttraining's rmse: 0.0884134\tvalid_1's rmse: 0.0931787\n",
      "[1575]\ttraining's rmse: 0.0884009\tvalid_1's rmse: 0.0931777\n",
      "[1600]\ttraining's rmse: 0.0883904\tvalid_1's rmse: 0.0931769\n",
      "[1625]\ttraining's rmse: 0.0883778\tvalid_1's rmse: 0.0931748\n",
      "[1650]\ttraining's rmse: 0.0883672\tvalid_1's rmse: 0.0931737\n",
      "[1675]\ttraining's rmse: 0.0883597\tvalid_1's rmse: 0.0931727\n",
      "[1700]\ttraining's rmse: 0.0883506\tvalid_1's rmse: 0.0931718\n",
      "[1725]\ttraining's rmse: 0.0883383\tvalid_1's rmse: 0.0931698\n",
      "[1750]\ttraining's rmse: 0.0883295\tvalid_1's rmse: 0.093169\n",
      "[1775]\ttraining's rmse: 0.088322\tvalid_1's rmse: 0.0931686\n",
      "[1800]\ttraining's rmse: 0.0883143\tvalid_1's rmse: 0.0931683\n",
      "[1825]\ttraining's rmse: 0.0883068\tvalid_1's rmse: 0.0931679\n",
      "[1850]\ttraining's rmse: 0.0882967\tvalid_1's rmse: 0.093167\n",
      "[1875]\ttraining's rmse: 0.0882873\tvalid_1's rmse: 0.0931659\n",
      "[1900]\ttraining's rmse: 0.0882815\tvalid_1's rmse: 0.093165\n",
      "[1925]\ttraining's rmse: 0.088276\tvalid_1's rmse: 0.0931645\n",
      "[1950]\ttraining's rmse: 0.0882708\tvalid_1's rmse: 0.093164\n",
      "[1975]\ttraining's rmse: 0.0882662\tvalid_1's rmse: 0.0931636\n",
      "[2000]\ttraining's rmse: 0.0882595\tvalid_1's rmse: 0.0931627\n",
      "[2025]\ttraining's rmse: 0.0882553\tvalid_1's rmse: 0.0931621\n",
      "[2050]\ttraining's rmse: 0.0882506\tvalid_1's rmse: 0.093162\n",
      "[2075]\ttraining's rmse: 0.088246\tvalid_1's rmse: 0.0931614\n",
      "[2100]\ttraining's rmse: 0.0882415\tvalid_1's rmse: 0.093161\n",
      "[2125]\ttraining's rmse: 0.0882363\tvalid_1's rmse: 0.0931606\n",
      "[2150]\ttraining's rmse: 0.0882316\tvalid_1's rmse: 0.0931607\n",
      "Early stopping, best iteration is:\n",
      "[2116]\ttraining's rmse: 0.0882382\tvalid_1's rmse: 0.0931605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0938091\tvalid_1's rmse: 0.0902071\n",
      "[50]\ttraining's rmse: 0.0936748\tvalid_1's rmse: 0.0901583\n",
      "[75]\ttraining's rmse: 0.0935317\tvalid_1's rmse: 0.0901077\n",
      "[100]\ttraining's rmse: 0.0934031\tvalid_1's rmse: 0.0900657\n",
      "[125]\ttraining's rmse: 0.0932719\tvalid_1's rmse: 0.0900243\n",
      "[150]\ttraining's rmse: 0.0931493\tvalid_1's rmse: 0.0899848\n",
      "[175]\ttraining's rmse: 0.0930471\tvalid_1's rmse: 0.0899535\n",
      "[200]\ttraining's rmse: 0.0929369\tvalid_1's rmse: 0.0899199\n",
      "[225]\ttraining's rmse: 0.0928286\tvalid_1's rmse: 0.0898875\n",
      "[250]\ttraining's rmse: 0.092737\tvalid_1's rmse: 0.0898606\n",
      "[275]\ttraining's rmse: 0.0926543\tvalid_1's rmse: 0.0898397\n",
      "[300]\ttraining's rmse: 0.0925709\tvalid_1's rmse: 0.0898166\n",
      "[325]\ttraining's rmse: 0.0924837\tvalid_1's rmse: 0.0897945\n",
      "[350]\ttraining's rmse: 0.0924008\tvalid_1's rmse: 0.089771\n",
      "[375]\ttraining's rmse: 0.0923333\tvalid_1's rmse: 0.0897574\n",
      "[400]\ttraining's rmse: 0.0922606\tvalid_1's rmse: 0.0897378\n",
      "[425]\ttraining's rmse: 0.0921894\tvalid_1's rmse: 0.0897232\n",
      "[450]\ttraining's rmse: 0.0921235\tvalid_1's rmse: 0.0897121\n",
      "[475]\ttraining's rmse: 0.0920628\tvalid_1's rmse: 0.0896972\n",
      "[500]\ttraining's rmse: 0.0920135\tvalid_1's rmse: 0.089689\n",
      "[525]\ttraining's rmse: 0.091948\tvalid_1's rmse: 0.0896742\n",
      "[550]\ttraining's rmse: 0.091888\tvalid_1's rmse: 0.0896615\n",
      "[575]\ttraining's rmse: 0.0918329\tvalid_1's rmse: 0.089656\n",
      "[600]\ttraining's rmse: 0.091779\tvalid_1's rmse: 0.089647\n",
      "[625]\ttraining's rmse: 0.091736\tvalid_1's rmse: 0.0896371\n",
      "[650]\ttraining's rmse: 0.0916825\tvalid_1's rmse: 0.0896402\n",
      "[675]\ttraining's rmse: 0.0916308\tvalid_1's rmse: 0.0896386\n",
      "Early stopping, best iteration is:\n",
      "[641]\ttraining's rmse: 0.0917032\tvalid_1's rmse: 0.0896314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0928511\tvalid_1's rmse: 0.0946835\n",
      "[50]\ttraining's rmse: 0.092653\tvalid_1's rmse: 0.0946249\n",
      "[75]\ttraining's rmse: 0.0924564\tvalid_1's rmse: 0.0945695\n",
      "[100]\ttraining's rmse: 0.0922775\tvalid_1's rmse: 0.0945185\n",
      "[125]\ttraining's rmse: 0.092101\tvalid_1's rmse: 0.094471\n",
      "[150]\ttraining's rmse: 0.0919372\tvalid_1's rmse: 0.0944234\n",
      "[175]\ttraining's rmse: 0.0917985\tvalid_1's rmse: 0.0943831\n",
      "[200]\ttraining's rmse: 0.0916586\tvalid_1's rmse: 0.0943435\n",
      "[225]\ttraining's rmse: 0.0915188\tvalid_1's rmse: 0.0943054\n",
      "[250]\ttraining's rmse: 0.0914022\tvalid_1's rmse: 0.0942725\n",
      "[275]\ttraining's rmse: 0.0912886\tvalid_1's rmse: 0.0942416\n",
      "[300]\ttraining's rmse: 0.0911787\tvalid_1's rmse: 0.094211\n",
      "[325]\ttraining's rmse: 0.0910718\tvalid_1's rmse: 0.0941829\n",
      "[350]\ttraining's rmse: 0.0909671\tvalid_1's rmse: 0.0941547\n",
      "[375]\ttraining's rmse: 0.0908763\tvalid_1's rmse: 0.0941322\n",
      "[400]\ttraining's rmse: 0.090782\tvalid_1's rmse: 0.0941089\n",
      "[425]\ttraining's rmse: 0.0906941\tvalid_1's rmse: 0.0940858\n",
      "[450]\ttraining's rmse: 0.0906177\tvalid_1's rmse: 0.0940641\n",
      "[475]\ttraining's rmse: 0.0905453\tvalid_1's rmse: 0.0940432\n",
      "[500]\ttraining's rmse: 0.0904821\tvalid_1's rmse: 0.0940245\n",
      "[525]\ttraining's rmse: 0.0904085\tvalid_1's rmse: 0.0940052\n",
      "[550]\ttraining's rmse: 0.0903404\tvalid_1's rmse: 0.0939894\n",
      "[575]\ttraining's rmse: 0.0902778\tvalid_1's rmse: 0.0939767\n",
      "[600]\ttraining's rmse: 0.0902164\tvalid_1's rmse: 0.0939613\n",
      "[625]\ttraining's rmse: 0.0901655\tvalid_1's rmse: 0.0939477\n",
      "[650]\ttraining's rmse: 0.0901067\tvalid_1's rmse: 0.0939339\n",
      "[675]\ttraining's rmse: 0.090049\tvalid_1's rmse: 0.0939207\n",
      "[700]\ttraining's rmse: 0.0900004\tvalid_1's rmse: 0.0939102\n",
      "[725]\ttraining's rmse: 0.0899545\tvalid_1's rmse: 0.0938994\n",
      "[750]\ttraining's rmse: 0.089911\tvalid_1's rmse: 0.0938893\n",
      "[775]\ttraining's rmse: 0.089872\tvalid_1's rmse: 0.0938783\n",
      "[800]\ttraining's rmse: 0.089826\tvalid_1's rmse: 0.0938692\n",
      "[825]\ttraining's rmse: 0.089787\tvalid_1's rmse: 0.0938581\n",
      "[850]\ttraining's rmse: 0.0897496\tvalid_1's rmse: 0.0938505\n",
      "[875]\ttraining's rmse: 0.0897158\tvalid_1's rmse: 0.0938425\n",
      "[900]\ttraining's rmse: 0.0896772\tvalid_1's rmse: 0.0938326\n",
      "[925]\ttraining's rmse: 0.0896426\tvalid_1's rmse: 0.0938244\n",
      "[950]\ttraining's rmse: 0.0896117\tvalid_1's rmse: 0.0938153\n",
      "[975]\ttraining's rmse: 0.08958\tvalid_1's rmse: 0.0938071\n",
      "[1000]\ttraining's rmse: 0.0895515\tvalid_1's rmse: 0.0938016\n",
      "[1025]\ttraining's rmse: 0.0895225\tvalid_1's rmse: 0.0937964\n",
      "[1050]\ttraining's rmse: 0.0894968\tvalid_1's rmse: 0.0937891\n",
      "[1075]\ttraining's rmse: 0.0894731\tvalid_1's rmse: 0.0937844\n",
      "[1100]\ttraining's rmse: 0.0894499\tvalid_1's rmse: 0.0937788\n",
      "[1125]\ttraining's rmse: 0.0894276\tvalid_1's rmse: 0.0937736\n",
      "[1150]\ttraining's rmse: 0.0894042\tvalid_1's rmse: 0.0937673\n",
      "[1175]\ttraining's rmse: 0.0893799\tvalid_1's rmse: 0.0937614\n",
      "[1200]\ttraining's rmse: 0.0893591\tvalid_1's rmse: 0.0937567\n",
      "[1225]\ttraining's rmse: 0.0893387\tvalid_1's rmse: 0.0937507\n",
      "[1250]\ttraining's rmse: 0.0893203\tvalid_1's rmse: 0.0937467\n",
      "[1275]\ttraining's rmse: 0.0892998\tvalid_1's rmse: 0.0937429\n",
      "[1300]\ttraining's rmse: 0.0892854\tvalid_1's rmse: 0.0937387\n",
      "[1325]\ttraining's rmse: 0.0892696\tvalid_1's rmse: 0.0937359\n",
      "[1350]\ttraining's rmse: 0.0892491\tvalid_1's rmse: 0.0937308\n",
      "[1375]\ttraining's rmse: 0.0892315\tvalid_1's rmse: 0.0937264\n",
      "[1400]\ttraining's rmse: 0.0892171\tvalid_1's rmse: 0.0937223\n",
      "[1425]\ttraining's rmse: 0.0892004\tvalid_1's rmse: 0.0937193\n",
      "[1450]\ttraining's rmse: 0.0891844\tvalid_1's rmse: 0.0937161\n",
      "[1475]\ttraining's rmse: 0.089169\tvalid_1's rmse: 0.0937126\n",
      "[1500]\ttraining's rmse: 0.0891562\tvalid_1's rmse: 0.0937094\n",
      "[1525]\ttraining's rmse: 0.0891465\tvalid_1's rmse: 0.0937066\n",
      "[1550]\ttraining's rmse: 0.089132\tvalid_1's rmse: 0.0937053\n",
      "[1575]\ttraining's rmse: 0.0891203\tvalid_1's rmse: 0.0937023\n",
      "[1600]\ttraining's rmse: 0.0891106\tvalid_1's rmse: 0.093701\n",
      "[1625]\ttraining's rmse: 0.0890966\tvalid_1's rmse: 0.0936983\n",
      "[1650]\ttraining's rmse: 0.0890854\tvalid_1's rmse: 0.0936952\n",
      "[1675]\ttraining's rmse: 0.0890776\tvalid_1's rmse: 0.0936929\n",
      "[1700]\ttraining's rmse: 0.089069\tvalid_1's rmse: 0.0936898\n",
      "[1725]\ttraining's rmse: 0.0890601\tvalid_1's rmse: 0.0936876\n",
      "[1750]\ttraining's rmse: 0.0890501\tvalid_1's rmse: 0.093685\n",
      "[1775]\ttraining's rmse: 0.0890421\tvalid_1's rmse: 0.0936841\n",
      "[1800]\ttraining's rmse: 0.0890354\tvalid_1's rmse: 0.0936821\n",
      "[1825]\ttraining's rmse: 0.0890277\tvalid_1's rmse: 0.0936807\n",
      "[1850]\ttraining's rmse: 0.0890211\tvalid_1's rmse: 0.0936797\n",
      "[1875]\ttraining's rmse: 0.0890133\tvalid_1's rmse: 0.0936789\n",
      "[1900]\ttraining's rmse: 0.0890075\tvalid_1's rmse: 0.0936781\n",
      "[1925]\ttraining's rmse: 0.0890004\tvalid_1's rmse: 0.0936759\n",
      "[1950]\ttraining's rmse: 0.0889956\tvalid_1's rmse: 0.0936742\n",
      "[1975]\ttraining's rmse: 0.0889906\tvalid_1's rmse: 0.0936725\n",
      "[2000]\ttraining's rmse: 0.0889865\tvalid_1's rmse: 0.0936716\n",
      "[2025]\ttraining's rmse: 0.0889815\tvalid_1's rmse: 0.0936708\n",
      "[2050]\ttraining's rmse: 0.0889754\tvalid_1's rmse: 0.0936693\n",
      "[2075]\ttraining's rmse: 0.0889697\tvalid_1's rmse: 0.0936677\n",
      "[2100]\ttraining's rmse: 0.088965\tvalid_1's rmse: 0.0936663\n",
      "[2125]\ttraining's rmse: 0.0889603\tvalid_1's rmse: 0.0936651\n",
      "[2150]\ttraining's rmse: 0.0889563\tvalid_1's rmse: 0.0936637\n",
      "[2175]\ttraining's rmse: 0.0889533\tvalid_1's rmse: 0.0936623\n",
      "[2200]\ttraining's rmse: 0.0889499\tvalid_1's rmse: 0.0936612\n",
      "[2225]\ttraining's rmse: 0.0889473\tvalid_1's rmse: 0.0936599\n",
      "[2250]\ttraining's rmse: 0.0889427\tvalid_1's rmse: 0.0936596\n",
      "[2275]\ttraining's rmse: 0.0889378\tvalid_1's rmse: 0.0936582\n",
      "[2300]\ttraining's rmse: 0.0889344\tvalid_1's rmse: 0.0936569\n",
      "[2325]\ttraining's rmse: 0.0889309\tvalid_1's rmse: 0.0936556\n",
      "[2350]\ttraining's rmse: 0.0889277\tvalid_1's rmse: 0.0936544\n",
      "[2375]\ttraining's rmse: 0.0889243\tvalid_1's rmse: 0.0936536\n",
      "[2400]\ttraining's rmse: 0.0889202\tvalid_1's rmse: 0.0936528\n",
      "[2425]\ttraining's rmse: 0.0889166\tvalid_1's rmse: 0.093652\n",
      "[2450]\ttraining's rmse: 0.088914\tvalid_1's rmse: 0.0936516\n",
      "[2475]\ttraining's rmse: 0.08891\tvalid_1's rmse: 0.0936509\n",
      "[2500]\ttraining's rmse: 0.0889063\tvalid_1's rmse: 0.0936506\n",
      "[2525]\ttraining's rmse: 0.0889033\tvalid_1's rmse: 0.09365\n",
      "[2550]\ttraining's rmse: 0.0889001\tvalid_1's rmse: 0.0936494\n",
      "[2575]\ttraining's rmse: 0.0888967\tvalid_1's rmse: 0.0936485\n",
      "[2600]\ttraining's rmse: 0.0888939\tvalid_1's rmse: 0.0936482\n",
      "[2625]\ttraining's rmse: 0.0888911\tvalid_1's rmse: 0.0936466\n",
      "[2650]\ttraining's rmse: 0.0888869\tvalid_1's rmse: 0.0936452\n",
      "[2675]\ttraining's rmse: 0.0888847\tvalid_1's rmse: 0.0936442\n",
      "[2700]\ttraining's rmse: 0.0888828\tvalid_1's rmse: 0.0936431\n",
      "[2725]\ttraining's rmse: 0.0888789\tvalid_1's rmse: 0.093643\n",
      "[2750]\ttraining's rmse: 0.0888767\tvalid_1's rmse: 0.0936429\n",
      "[2775]\ttraining's rmse: 0.0888749\tvalid_1's rmse: 0.093643\n",
      "[2800]\ttraining's rmse: 0.0888727\tvalid_1's rmse: 0.0936425\n",
      "[2825]\ttraining's rmse: 0.0888701\tvalid_1's rmse: 0.0936426\n",
      "[2850]\ttraining's rmse: 0.0888688\tvalid_1's rmse: 0.0936423\n",
      "[2875]\ttraining's rmse: 0.0888671\tvalid_1's rmse: 0.093642\n",
      "[2900]\ttraining's rmse: 0.088865\tvalid_1's rmse: 0.093641\n",
      "[2925]\ttraining's rmse: 0.0888635\tvalid_1's rmse: 0.0936405\n",
      "[2950]\ttraining's rmse: 0.0888606\tvalid_1's rmse: 0.0936405\n",
      "[2975]\ttraining's rmse: 0.0888588\tvalid_1's rmse: 0.0936406\n",
      "Early stopping, best iteration is:\n",
      "[2932]\ttraining's rmse: 0.088863\tvalid_1's rmse: 0.0936403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0926782\tvalid_1's rmse: 0.0950472\n",
      "[50]\ttraining's rmse: 0.0924994\tvalid_1's rmse: 0.0949882\n",
      "[75]\ttraining's rmse: 0.0923168\tvalid_1's rmse: 0.0949331\n",
      "[100]\ttraining's rmse: 0.0921529\tvalid_1's rmse: 0.0948821\n",
      "[125]\ttraining's rmse: 0.0919906\tvalid_1's rmse: 0.0948317\n",
      "[150]\ttraining's rmse: 0.0918438\tvalid_1's rmse: 0.0947867\n",
      "[175]\ttraining's rmse: 0.0917142\tvalid_1's rmse: 0.0947483\n",
      "[200]\ttraining's rmse: 0.0915827\tvalid_1's rmse: 0.0947116\n",
      "[225]\ttraining's rmse: 0.0914597\tvalid_1's rmse: 0.0946773\n",
      "[250]\ttraining's rmse: 0.0913521\tvalid_1's rmse: 0.0946438\n",
      "[275]\ttraining's rmse: 0.0912489\tvalid_1's rmse: 0.094614\n",
      "[300]\ttraining's rmse: 0.0911486\tvalid_1's rmse: 0.0945857\n",
      "[325]\ttraining's rmse: 0.0910518\tvalid_1's rmse: 0.094559\n",
      "[350]\ttraining's rmse: 0.090957\tvalid_1's rmse: 0.0945352\n",
      "[375]\ttraining's rmse: 0.0908805\tvalid_1's rmse: 0.0945136\n",
      "[400]\ttraining's rmse: 0.0907957\tvalid_1's rmse: 0.0944922\n",
      "[425]\ttraining's rmse: 0.090715\tvalid_1's rmse: 0.0944708\n",
      "[450]\ttraining's rmse: 0.0906419\tvalid_1's rmse: 0.0944514\n",
      "[475]\ttraining's rmse: 0.0905756\tvalid_1's rmse: 0.0944326\n",
      "[500]\ttraining's rmse: 0.0905192\tvalid_1's rmse: 0.094417\n",
      "[525]\ttraining's rmse: 0.090451\tvalid_1's rmse: 0.0944005\n",
      "[550]\ttraining's rmse: 0.0903839\tvalid_1's rmse: 0.0943846\n",
      "[575]\ttraining's rmse: 0.0903267\tvalid_1's rmse: 0.0943716\n",
      "[600]\ttraining's rmse: 0.0902679\tvalid_1's rmse: 0.0943583\n",
      "[625]\ttraining's rmse: 0.0902197\tvalid_1's rmse: 0.0943459\n",
      "[650]\ttraining's rmse: 0.0901617\tvalid_1's rmse: 0.0943325\n",
      "[675]\ttraining's rmse: 0.0901099\tvalid_1's rmse: 0.0943203\n",
      "[700]\ttraining's rmse: 0.0900631\tvalid_1's rmse: 0.0943095\n",
      "[725]\ttraining's rmse: 0.0900197\tvalid_1's rmse: 0.0943007\n",
      "[750]\ttraining's rmse: 0.0899788\tvalid_1's rmse: 0.0942911\n",
      "[775]\ttraining's rmse: 0.0899438\tvalid_1's rmse: 0.0942828\n",
      "[800]\ttraining's rmse: 0.0898993\tvalid_1's rmse: 0.0942751\n",
      "[825]\ttraining's rmse: 0.0898637\tvalid_1's rmse: 0.0942681\n",
      "[850]\ttraining's rmse: 0.0898274\tvalid_1's rmse: 0.0942614\n",
      "[875]\ttraining's rmse: 0.089795\tvalid_1's rmse: 0.0942548\n",
      "[900]\ttraining's rmse: 0.0897591\tvalid_1's rmse: 0.094248\n",
      "[925]\ttraining's rmse: 0.0897245\tvalid_1's rmse: 0.0942425\n",
      "[950]\ttraining's rmse: 0.0896932\tvalid_1's rmse: 0.0942375\n",
      "[975]\ttraining's rmse: 0.0896617\tvalid_1's rmse: 0.0942316\n",
      "[1000]\ttraining's rmse: 0.089633\tvalid_1's rmse: 0.0942259\n",
      "[1025]\ttraining's rmse: 0.0896025\tvalid_1's rmse: 0.0942213\n",
      "[1050]\ttraining's rmse: 0.0895775\tvalid_1's rmse: 0.0942175\n",
      "[1075]\ttraining's rmse: 0.0895507\tvalid_1's rmse: 0.0942135\n",
      "[1100]\ttraining's rmse: 0.0895276\tvalid_1's rmse: 0.0942091\n",
      "[1125]\ttraining's rmse: 0.0895039\tvalid_1's rmse: 0.0942053\n",
      "[1150]\ttraining's rmse: 0.0894797\tvalid_1's rmse: 0.0942023\n",
      "[1175]\ttraining's rmse: 0.08946\tvalid_1's rmse: 0.0941998\n",
      "[1200]\ttraining's rmse: 0.0894394\tvalid_1's rmse: 0.0941963\n",
      "[1225]\ttraining's rmse: 0.0894199\tvalid_1's rmse: 0.0941936\n",
      "[1250]\ttraining's rmse: 0.0894013\tvalid_1's rmse: 0.0941905\n",
      "[1275]\ttraining's rmse: 0.0893807\tvalid_1's rmse: 0.094188\n",
      "[1300]\ttraining's rmse: 0.089364\tvalid_1's rmse: 0.0941853\n",
      "[1325]\ttraining's rmse: 0.089347\tvalid_1's rmse: 0.0941834\n",
      "[1350]\ttraining's rmse: 0.0893291\tvalid_1's rmse: 0.0941814\n",
      "[1375]\ttraining's rmse: 0.0893138\tvalid_1's rmse: 0.0941796\n",
      "[1400]\ttraining's rmse: 0.0892999\tvalid_1's rmse: 0.0941775\n",
      "[1425]\ttraining's rmse: 0.0892826\tvalid_1's rmse: 0.0941761\n",
      "[1450]\ttraining's rmse: 0.0892631\tvalid_1's rmse: 0.0941743\n",
      "[1475]\ttraining's rmse: 0.089249\tvalid_1's rmse: 0.094173\n",
      "[1500]\ttraining's rmse: 0.0892332\tvalid_1's rmse: 0.0941717\n",
      "[1525]\ttraining's rmse: 0.0892183\tvalid_1's rmse: 0.0941706\n",
      "[1550]\ttraining's rmse: 0.0892046\tvalid_1's rmse: 0.0941697\n",
      "[1575]\ttraining's rmse: 0.089192\tvalid_1's rmse: 0.0941693\n",
      "[1600]\ttraining's rmse: 0.0891812\tvalid_1's rmse: 0.0941688\n",
      "[1625]\ttraining's rmse: 0.0891688\tvalid_1's rmse: 0.0941683\n",
      "[1650]\ttraining's rmse: 0.0891595\tvalid_1's rmse: 0.0941675\n",
      "[1675]\ttraining's rmse: 0.0891517\tvalid_1's rmse: 0.0941665\n",
      "[1700]\ttraining's rmse: 0.0891422\tvalid_1's rmse: 0.0941655\n",
      "[1725]\ttraining's rmse: 0.0891332\tvalid_1's rmse: 0.0941642\n",
      "[1750]\ttraining's rmse: 0.0891246\tvalid_1's rmse: 0.0941644\n",
      "[1775]\ttraining's rmse: 0.0891161\tvalid_1's rmse: 0.0941641\n",
      "[1800]\ttraining's rmse: 0.0891068\tvalid_1's rmse: 0.0941638\n",
      "[1825]\ttraining's rmse: 0.0890974\tvalid_1's rmse: 0.0941629\n",
      "[1850]\ttraining's rmse: 0.0890917\tvalid_1's rmse: 0.0941622\n",
      "[1875]\ttraining's rmse: 0.0890845\tvalid_1's rmse: 0.0941622\n",
      "[1900]\ttraining's rmse: 0.0890785\tvalid_1's rmse: 0.0941623\n",
      "[1925]\ttraining's rmse: 0.0890722\tvalid_1's rmse: 0.0941614\n",
      "[1950]\ttraining's rmse: 0.0890671\tvalid_1's rmse: 0.0941607\n",
      "[1975]\ttraining's rmse: 0.0890627\tvalid_1's rmse: 0.0941602\n",
      "[2000]\ttraining's rmse: 0.0890565\tvalid_1's rmse: 0.0941597\n",
      "[2025]\ttraining's rmse: 0.0890515\tvalid_1's rmse: 0.0941594\n",
      "[2050]\ttraining's rmse: 0.0890462\tvalid_1's rmse: 0.0941595\n",
      "[2075]\ttraining's rmse: 0.0890423\tvalid_1's rmse: 0.0941593\n",
      "[2100]\ttraining's rmse: 0.0890376\tvalid_1's rmse: 0.0941592\n",
      "[2125]\ttraining's rmse: 0.0890325\tvalid_1's rmse: 0.0941594\n",
      "[2150]\ttraining's rmse: 0.0890279\tvalid_1's rmse: 0.0941592\n",
      "Early stopping, best iteration is:\n",
      "[2108]\ttraining's rmse: 0.089036\tvalid_1's rmse: 0.0941591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0947132\tvalid_1's rmse: 0.0910048\n",
      "[50]\ttraining's rmse: 0.09457\tvalid_1's rmse: 0.0909547\n",
      "[75]\ttraining's rmse: 0.094421\tvalid_1's rmse: 0.0909037\n",
      "[100]\ttraining's rmse: 0.0942895\tvalid_1's rmse: 0.090863\n",
      "[125]\ttraining's rmse: 0.0941524\tvalid_1's rmse: 0.0908175\n",
      "[150]\ttraining's rmse: 0.0940253\tvalid_1's rmse: 0.090779\n",
      "[175]\ttraining's rmse: 0.0939197\tvalid_1's rmse: 0.0907502\n",
      "[200]\ttraining's rmse: 0.0938053\tvalid_1's rmse: 0.0907186\n",
      "[225]\ttraining's rmse: 0.0936953\tvalid_1's rmse: 0.0906851\n",
      "[250]\ttraining's rmse: 0.0935986\tvalid_1's rmse: 0.0906563\n",
      "[275]\ttraining's rmse: 0.0935111\tvalid_1's rmse: 0.0906303\n",
      "[300]\ttraining's rmse: 0.0934228\tvalid_1's rmse: 0.0906061\n",
      "[325]\ttraining's rmse: 0.0933372\tvalid_1's rmse: 0.0905826\n",
      "[350]\ttraining's rmse: 0.0932523\tvalid_1's rmse: 0.0905613\n",
      "[375]\ttraining's rmse: 0.0931813\tvalid_1's rmse: 0.09055\n",
      "[400]\ttraining's rmse: 0.093105\tvalid_1's rmse: 0.0905355\n",
      "[425]\ttraining's rmse: 0.0930326\tvalid_1's rmse: 0.0905221\n",
      "[450]\ttraining's rmse: 0.092968\tvalid_1's rmse: 0.0905098\n",
      "[475]\ttraining's rmse: 0.0929025\tvalid_1's rmse: 0.0904949\n",
      "[500]\ttraining's rmse: 0.0928493\tvalid_1's rmse: 0.090481\n",
      "[525]\ttraining's rmse: 0.0927782\tvalid_1's rmse: 0.0904679\n",
      "[550]\ttraining's rmse: 0.092717\tvalid_1's rmse: 0.0904551\n",
      "[575]\ttraining's rmse: 0.0926617\tvalid_1's rmse: 0.0904454\n",
      "[600]\ttraining's rmse: 0.092605\tvalid_1's rmse: 0.0904415\n",
      "[625]\ttraining's rmse: 0.0925595\tvalid_1's rmse: 0.0904405\n",
      "[650]\ttraining's rmse: 0.0925004\tvalid_1's rmse: 0.0904324\n",
      "[675]\ttraining's rmse: 0.0924429\tvalid_1's rmse: 0.0904253\n",
      "[700]\ttraining's rmse: 0.0923942\tvalid_1's rmse: 0.0904245\n",
      "[725]\ttraining's rmse: 0.0923513\tvalid_1's rmse: 0.0904197\n",
      "[750]\ttraining's rmse: 0.0923095\tvalid_1's rmse: 0.0904139\n",
      "[775]\ttraining's rmse: 0.0922721\tvalid_1's rmse: 0.0904147\n",
      "[800]\ttraining's rmse: 0.0922258\tvalid_1's rmse: 0.0904111\n",
      "[825]\ttraining's rmse: 0.0921868\tvalid_1's rmse: 0.090414\n",
      "[850]\ttraining's rmse: 0.0921482\tvalid_1's rmse: 0.0904093\n",
      "[875]\ttraining's rmse: 0.0921146\tvalid_1's rmse: 0.0904127\n",
      "[900]\ttraining's rmse: 0.0920761\tvalid_1's rmse: 0.0904084\n",
      "[925]\ttraining's rmse: 0.0920415\tvalid_1's rmse: 0.0904113\n",
      "[950]\ttraining's rmse: 0.0920071\tvalid_1's rmse: 0.0904069\n",
      "[975]\ttraining's rmse: 0.0919757\tvalid_1's rmse: 0.0904295\n",
      "[1000]\ttraining's rmse: 0.0919461\tvalid_1's rmse: 0.0904267\n",
      "Early stopping, best iteration is:\n",
      "[958]\ttraining's rmse: 0.0919968\tvalid_1's rmse: 0.0904052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0938779\tvalid_1's rmse: 0.0960039\n",
      "[50]\ttraining's rmse: 0.0936772\tvalid_1's rmse: 0.0959477\n",
      "[75]\ttraining's rmse: 0.0934769\tvalid_1's rmse: 0.0958915\n",
      "[100]\ttraining's rmse: 0.0932949\tvalid_1's rmse: 0.095841\n",
      "[125]\ttraining's rmse: 0.093114\tvalid_1's rmse: 0.0957927\n",
      "[150]\ttraining's rmse: 0.0929488\tvalid_1's rmse: 0.0957471\n",
      "[175]\ttraining's rmse: 0.0928089\tvalid_1's rmse: 0.0957081\n",
      "[200]\ttraining's rmse: 0.0926629\tvalid_1's rmse: 0.0956694\n",
      "[225]\ttraining's rmse: 0.0925194\tvalid_1's rmse: 0.0956326\n",
      "[250]\ttraining's rmse: 0.0923974\tvalid_1's rmse: 0.0956002\n",
      "[275]\ttraining's rmse: 0.0922834\tvalid_1's rmse: 0.0955712\n",
      "[300]\ttraining's rmse: 0.0921641\tvalid_1's rmse: 0.0955414\n",
      "[325]\ttraining's rmse: 0.0920531\tvalid_1's rmse: 0.0955147\n",
      "[350]\ttraining's rmse: 0.0919455\tvalid_1's rmse: 0.0954894\n",
      "[375]\ttraining's rmse: 0.0918539\tvalid_1's rmse: 0.095467\n",
      "[400]\ttraining's rmse: 0.0917591\tvalid_1's rmse: 0.0954467\n",
      "[425]\ttraining's rmse: 0.0916705\tvalid_1's rmse: 0.0954247\n",
      "[450]\ttraining's rmse: 0.091593\tvalid_1's rmse: 0.0954042\n",
      "[475]\ttraining's rmse: 0.0915164\tvalid_1's rmse: 0.0953841\n",
      "[500]\ttraining's rmse: 0.0914506\tvalid_1's rmse: 0.0953658\n",
      "[525]\ttraining's rmse: 0.0913737\tvalid_1's rmse: 0.0953493\n",
      "[550]\ttraining's rmse: 0.0913079\tvalid_1's rmse: 0.0953344\n",
      "[575]\ttraining's rmse: 0.0912427\tvalid_1's rmse: 0.0953205\n",
      "[600]\ttraining's rmse: 0.0911793\tvalid_1's rmse: 0.0953049\n",
      "[625]\ttraining's rmse: 0.0911287\tvalid_1's rmse: 0.0952923\n",
      "[650]\ttraining's rmse: 0.0910717\tvalid_1's rmse: 0.0952785\n",
      "[675]\ttraining's rmse: 0.0910115\tvalid_1's rmse: 0.0952633\n",
      "[700]\ttraining's rmse: 0.0909603\tvalid_1's rmse: 0.0952517\n",
      "[725]\ttraining's rmse: 0.0909128\tvalid_1's rmse: 0.0952401\n",
      "[750]\ttraining's rmse: 0.0908688\tvalid_1's rmse: 0.0952282\n",
      "[775]\ttraining's rmse: 0.0908299\tvalid_1's rmse: 0.0952155\n",
      "[800]\ttraining's rmse: 0.0907846\tvalid_1's rmse: 0.0952075\n",
      "[825]\ttraining's rmse: 0.0907464\tvalid_1's rmse: 0.0951987\n",
      "[850]\ttraining's rmse: 0.0907063\tvalid_1's rmse: 0.0951902\n",
      "[875]\ttraining's rmse: 0.0906744\tvalid_1's rmse: 0.0951814\n",
      "[900]\ttraining's rmse: 0.0906355\tvalid_1's rmse: 0.0951729\n",
      "[925]\ttraining's rmse: 0.0906035\tvalid_1's rmse: 0.0951651\n",
      "[950]\ttraining's rmse: 0.0905701\tvalid_1's rmse: 0.0951567\n",
      "[975]\ttraining's rmse: 0.0905383\tvalid_1's rmse: 0.0951491\n",
      "[1000]\ttraining's rmse: 0.090507\tvalid_1's rmse: 0.0951433\n",
      "[1025]\ttraining's rmse: 0.0904773\tvalid_1's rmse: 0.0951372\n",
      "[1050]\ttraining's rmse: 0.0904494\tvalid_1's rmse: 0.0951289\n",
      "[1075]\ttraining's rmse: 0.0904253\tvalid_1's rmse: 0.0951238\n",
      "[1100]\ttraining's rmse: 0.0904023\tvalid_1's rmse: 0.0951175\n",
      "[1125]\ttraining's rmse: 0.0903782\tvalid_1's rmse: 0.0951117\n",
      "[1150]\ttraining's rmse: 0.0903546\tvalid_1's rmse: 0.0951076\n",
      "[1175]\ttraining's rmse: 0.0903349\tvalid_1's rmse: 0.0951047\n",
      "[1200]\ttraining's rmse: 0.0903137\tvalid_1's rmse: 0.0950979\n",
      "[1225]\ttraining's rmse: 0.0902946\tvalid_1's rmse: 0.0950937\n",
      "[1250]\ttraining's rmse: 0.0902732\tvalid_1's rmse: 0.0950893\n",
      "[1275]\ttraining's rmse: 0.0902514\tvalid_1's rmse: 0.0950851\n",
      "[1300]\ttraining's rmse: 0.0902378\tvalid_1's rmse: 0.0950814\n",
      "[1325]\ttraining's rmse: 0.090223\tvalid_1's rmse: 0.0950784\n",
      "[1350]\ttraining's rmse: 0.0902062\tvalid_1's rmse: 0.0950751\n",
      "[1375]\ttraining's rmse: 0.0901878\tvalid_1's rmse: 0.0950729\n",
      "[1400]\ttraining's rmse: 0.0901754\tvalid_1's rmse: 0.0950686\n",
      "[1425]\ttraining's rmse: 0.0901577\tvalid_1's rmse: 0.0950674\n",
      "[1450]\ttraining's rmse: 0.0901391\tvalid_1's rmse: 0.0950633\n",
      "[1475]\ttraining's rmse: 0.0901252\tvalid_1's rmse: 0.0950609\n",
      "[1500]\ttraining's rmse: 0.0901094\tvalid_1's rmse: 0.0950588\n",
      "[1525]\ttraining's rmse: 0.0901003\tvalid_1's rmse: 0.0950557\n",
      "[1550]\ttraining's rmse: 0.0900867\tvalid_1's rmse: 0.0950529\n",
      "[1575]\ttraining's rmse: 0.0900742\tvalid_1's rmse: 0.0950498\n",
      "[1600]\ttraining's rmse: 0.0900615\tvalid_1's rmse: 0.0950479\n",
      "[1625]\ttraining's rmse: 0.0900498\tvalid_1's rmse: 0.0950465\n",
      "[1650]\ttraining's rmse: 0.0900402\tvalid_1's rmse: 0.0950434\n",
      "[1675]\ttraining's rmse: 0.0900308\tvalid_1's rmse: 0.0950406\n",
      "[1700]\ttraining's rmse: 0.0900222\tvalid_1's rmse: 0.0950381\n",
      "[1725]\ttraining's rmse: 0.0900111\tvalid_1's rmse: 0.0950364\n",
      "[1750]\ttraining's rmse: 0.0900009\tvalid_1's rmse: 0.0950338\n",
      "[1775]\ttraining's rmse: 0.0899905\tvalid_1's rmse: 0.0950317\n",
      "[1800]\ttraining's rmse: 0.0899823\tvalid_1's rmse: 0.0950286\n",
      "[1825]\ttraining's rmse: 0.0899744\tvalid_1's rmse: 0.0950259\n",
      "[1850]\ttraining's rmse: 0.0899673\tvalid_1's rmse: 0.0950226\n",
      "[1875]\ttraining's rmse: 0.0899596\tvalid_1's rmse: 0.0950215\n",
      "[1900]\ttraining's rmse: 0.0899544\tvalid_1's rmse: 0.0950205\n",
      "[1925]\ttraining's rmse: 0.0899487\tvalid_1's rmse: 0.0950197\n",
      "[1950]\ttraining's rmse: 0.0899445\tvalid_1's rmse: 0.0950175\n",
      "[1975]\ttraining's rmse: 0.08994\tvalid_1's rmse: 0.095015\n",
      "[2000]\ttraining's rmse: 0.0899339\tvalid_1's rmse: 0.0950138\n",
      "[2025]\ttraining's rmse: 0.0899288\tvalid_1's rmse: 0.0950119\n",
      "[2050]\ttraining's rmse: 0.0899242\tvalid_1's rmse: 0.0950101\n",
      "[2075]\ttraining's rmse: 0.0899196\tvalid_1's rmse: 0.0950088\n",
      "[2100]\ttraining's rmse: 0.0899162\tvalid_1's rmse: 0.0950081\n",
      "[2125]\ttraining's rmse: 0.0899114\tvalid_1's rmse: 0.0950056\n",
      "[2150]\ttraining's rmse: 0.0899078\tvalid_1's rmse: 0.0950039\n",
      "[2175]\ttraining's rmse: 0.0899014\tvalid_1's rmse: 0.0950025\n",
      "[2200]\ttraining's rmse: 0.0898963\tvalid_1's rmse: 0.0950018\n",
      "[2225]\ttraining's rmse: 0.089892\tvalid_1's rmse: 0.0950003\n",
      "[2250]\ttraining's rmse: 0.0898868\tvalid_1's rmse: 0.0949996\n",
      "[2275]\ttraining's rmse: 0.0898809\tvalid_1's rmse: 0.0949993\n",
      "[2300]\ttraining's rmse: 0.0898765\tvalid_1's rmse: 0.094998\n",
      "[2325]\ttraining's rmse: 0.0898714\tvalid_1's rmse: 0.0949969\n",
      "[2350]\ttraining's rmse: 0.0898682\tvalid_1's rmse: 0.0949965\n",
      "[2375]\ttraining's rmse: 0.089865\tvalid_1's rmse: 0.0949949\n",
      "[2400]\ttraining's rmse: 0.0898616\tvalid_1's rmse: 0.0949945\n",
      "[2425]\ttraining's rmse: 0.0898592\tvalid_1's rmse: 0.0949939\n",
      "[2450]\ttraining's rmse: 0.089857\tvalid_1's rmse: 0.0949937\n",
      "[2475]\ttraining's rmse: 0.0898536\tvalid_1's rmse: 0.0949935\n",
      "[2500]\ttraining's rmse: 0.08985\tvalid_1's rmse: 0.0949922\n",
      "[2525]\ttraining's rmse: 0.0898458\tvalid_1's rmse: 0.0949917\n",
      "[2550]\ttraining's rmse: 0.0898411\tvalid_1's rmse: 0.0949916\n",
      "[2575]\ttraining's rmse: 0.0898379\tvalid_1's rmse: 0.0949909\n",
      "[2600]\ttraining's rmse: 0.0898358\tvalid_1's rmse: 0.0949908\n",
      "[2625]\ttraining's rmse: 0.0898332\tvalid_1's rmse: 0.0949899\n",
      "[2650]\ttraining's rmse: 0.0898302\tvalid_1's rmse: 0.0949893\n",
      "[2675]\ttraining's rmse: 0.0898265\tvalid_1's rmse: 0.0949872\n",
      "[2700]\ttraining's rmse: 0.0898234\tvalid_1's rmse: 0.0949858\n",
      "[2725]\ttraining's rmse: 0.0898203\tvalid_1's rmse: 0.0949849\n",
      "[2750]\ttraining's rmse: 0.0898176\tvalid_1's rmse: 0.094984\n",
      "[2775]\ttraining's rmse: 0.0898149\tvalid_1's rmse: 0.0949836\n",
      "[2800]\ttraining's rmse: 0.0898136\tvalid_1's rmse: 0.0949828\n",
      "[2825]\ttraining's rmse: 0.0898106\tvalid_1's rmse: 0.094983\n",
      "[2850]\ttraining's rmse: 0.0898084\tvalid_1's rmse: 0.0949831\n",
      "Early stopping, best iteration is:\n",
      "[2808]\ttraining's rmse: 0.089813\tvalid_1's rmse: 0.0949825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0940277\tvalid_1's rmse: 0.095733\n",
      "[50]\ttraining's rmse: 0.0938425\tvalid_1's rmse: 0.0956759\n",
      "[75]\ttraining's rmse: 0.0936538\tvalid_1's rmse: 0.0956178\n",
      "[100]\ttraining's rmse: 0.093485\tvalid_1's rmse: 0.0955683\n",
      "[125]\ttraining's rmse: 0.0933159\tvalid_1's rmse: 0.0955176\n",
      "[150]\ttraining's rmse: 0.0931605\tvalid_1's rmse: 0.0954717\n",
      "[175]\ttraining's rmse: 0.0930298\tvalid_1's rmse: 0.0954341\n",
      "[200]\ttraining's rmse: 0.0928912\tvalid_1's rmse: 0.0953945\n",
      "[225]\ttraining's rmse: 0.0927645\tvalid_1's rmse: 0.0953604\n",
      "[250]\ttraining's rmse: 0.0926527\tvalid_1's rmse: 0.0953277\n",
      "[275]\ttraining's rmse: 0.0925477\tvalid_1's rmse: 0.0952987\n",
      "[300]\ttraining's rmse: 0.0924442\tvalid_1's rmse: 0.0952707\n",
      "[325]\ttraining's rmse: 0.0923385\tvalid_1's rmse: 0.0952443\n",
      "[350]\ttraining's rmse: 0.0922401\tvalid_1's rmse: 0.095219\n",
      "[375]\ttraining's rmse: 0.0921588\tvalid_1's rmse: 0.0951962\n",
      "[400]\ttraining's rmse: 0.0920711\tvalid_1's rmse: 0.0951758\n",
      "[425]\ttraining's rmse: 0.0919914\tvalid_1's rmse: 0.0951552\n",
      "[450]\ttraining's rmse: 0.0919176\tvalid_1's rmse: 0.0951356\n",
      "[475]\ttraining's rmse: 0.0918497\tvalid_1's rmse: 0.0951186\n",
      "[500]\ttraining's rmse: 0.0917909\tvalid_1's rmse: 0.0951023\n",
      "[525]\ttraining's rmse: 0.091717\tvalid_1's rmse: 0.095084\n",
      "[550]\ttraining's rmse: 0.0916497\tvalid_1's rmse: 0.0950694\n",
      "[575]\ttraining's rmse: 0.0915874\tvalid_1's rmse: 0.0950563\n",
      "[600]\ttraining's rmse: 0.091528\tvalid_1's rmse: 0.0950433\n",
      "[625]\ttraining's rmse: 0.0914791\tvalid_1's rmse: 0.0950309\n",
      "[650]\ttraining's rmse: 0.0914228\tvalid_1's rmse: 0.0950179\n",
      "[675]\ttraining's rmse: 0.0913667\tvalid_1's rmse: 0.0950059\n",
      "[700]\ttraining's rmse: 0.0913151\tvalid_1's rmse: 0.0949943\n",
      "[725]\ttraining's rmse: 0.0912695\tvalid_1's rmse: 0.0949851\n",
      "[750]\ttraining's rmse: 0.0912283\tvalid_1's rmse: 0.0949764\n",
      "[775]\ttraining's rmse: 0.0911904\tvalid_1's rmse: 0.0949661\n",
      "[800]\ttraining's rmse: 0.0911439\tvalid_1's rmse: 0.0949579\n",
      "[825]\ttraining's rmse: 0.0911045\tvalid_1's rmse: 0.0949502\n",
      "[850]\ttraining's rmse: 0.0910672\tvalid_1's rmse: 0.0949436\n",
      "[875]\ttraining's rmse: 0.0910345\tvalid_1's rmse: 0.0949385\n",
      "[900]\ttraining's rmse: 0.0909974\tvalid_1's rmse: 0.0949308\n",
      "[925]\ttraining's rmse: 0.0909637\tvalid_1's rmse: 0.0949256\n",
      "[950]\ttraining's rmse: 0.0909313\tvalid_1's rmse: 0.0949209\n",
      "[975]\ttraining's rmse: 0.0909018\tvalid_1's rmse: 0.0949161\n",
      "[1000]\ttraining's rmse: 0.0908709\tvalid_1's rmse: 0.0949115\n",
      "[1025]\ttraining's rmse: 0.0908392\tvalid_1's rmse: 0.0949072\n",
      "[1050]\ttraining's rmse: 0.0908097\tvalid_1's rmse: 0.0949021\n",
      "[1075]\ttraining's rmse: 0.0907846\tvalid_1's rmse: 0.0948991\n",
      "[1100]\ttraining's rmse: 0.0907623\tvalid_1's rmse: 0.0948956\n",
      "[1125]\ttraining's rmse: 0.0907351\tvalid_1's rmse: 0.0948916\n",
      "[1150]\ttraining's rmse: 0.0907112\tvalid_1's rmse: 0.0948887\n",
      "[1175]\ttraining's rmse: 0.0906901\tvalid_1's rmse: 0.0948865\n",
      "[1200]\ttraining's rmse: 0.0906668\tvalid_1's rmse: 0.0948832\n",
      "[1225]\ttraining's rmse: 0.0906455\tvalid_1's rmse: 0.0948811\n",
      "[1250]\ttraining's rmse: 0.0906248\tvalid_1's rmse: 0.0948783\n",
      "[1275]\ttraining's rmse: 0.0906041\tvalid_1's rmse: 0.0948758\n",
      "[1300]\ttraining's rmse: 0.0905874\tvalid_1's rmse: 0.0948741\n",
      "[1325]\ttraining's rmse: 0.0905706\tvalid_1's rmse: 0.0948723\n",
      "[1350]\ttraining's rmse: 0.0905513\tvalid_1's rmse: 0.0948706\n",
      "[1375]\ttraining's rmse: 0.0905326\tvalid_1's rmse: 0.0948696\n",
      "[1400]\ttraining's rmse: 0.0905176\tvalid_1's rmse: 0.0948675\n",
      "[1425]\ttraining's rmse: 0.0905017\tvalid_1's rmse: 0.0948668\n",
      "[1450]\ttraining's rmse: 0.090481\tvalid_1's rmse: 0.0948649\n",
      "[1475]\ttraining's rmse: 0.0904639\tvalid_1's rmse: 0.0948637\n",
      "[1500]\ttraining's rmse: 0.0904503\tvalid_1's rmse: 0.0948634\n",
      "[1525]\ttraining's rmse: 0.0904376\tvalid_1's rmse: 0.0948636\n",
      "[1550]\ttraining's rmse: 0.0904243\tvalid_1's rmse: 0.0948628\n",
      "[1575]\ttraining's rmse: 0.0904119\tvalid_1's rmse: 0.0948614\n",
      "[1600]\ttraining's rmse: 0.0904007\tvalid_1's rmse: 0.0948606\n",
      "[1625]\ttraining's rmse: 0.0903877\tvalid_1's rmse: 0.0948597\n",
      "[1650]\ttraining's rmse: 0.0903757\tvalid_1's rmse: 0.0948587\n",
      "[1675]\ttraining's rmse: 0.0903674\tvalid_1's rmse: 0.0948581\n",
      "[1700]\ttraining's rmse: 0.0903588\tvalid_1's rmse: 0.0948573\n",
      "[1725]\ttraining's rmse: 0.0903483\tvalid_1's rmse: 0.0948563\n",
      "[1750]\ttraining's rmse: 0.0903375\tvalid_1's rmse: 0.0948558\n",
      "[1775]\ttraining's rmse: 0.0903298\tvalid_1's rmse: 0.0948559\n",
      "[1800]\ttraining's rmse: 0.0903228\tvalid_1's rmse: 0.0948557\n",
      "Early stopping, best iteration is:\n",
      "[1765]\ttraining's rmse: 0.0903336\tvalid_1's rmse: 0.0948554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0957118\tvalid_1's rmse: 0.0923912\n",
      "[50]\ttraining's rmse: 0.0955682\tvalid_1's rmse: 0.0923385\n",
      "[75]\ttraining's rmse: 0.0954161\tvalid_1's rmse: 0.0922849\n",
      "[100]\ttraining's rmse: 0.0952761\tvalid_1's rmse: 0.0922389\n",
      "[125]\ttraining's rmse: 0.0951359\tvalid_1's rmse: 0.0921939\n",
      "[150]\ttraining's rmse: 0.095007\tvalid_1's rmse: 0.0921549\n",
      "[175]\ttraining's rmse: 0.0948992\tvalid_1's rmse: 0.0921266\n",
      "[200]\ttraining's rmse: 0.0947809\tvalid_1's rmse: 0.0920902\n",
      "[225]\ttraining's rmse: 0.0946692\tvalid_1's rmse: 0.092059\n",
      "[250]\ttraining's rmse: 0.0945695\tvalid_1's rmse: 0.0920315\n",
      "[275]\ttraining's rmse: 0.0944807\tvalid_1's rmse: 0.0920068\n",
      "[300]\ttraining's rmse: 0.0943899\tvalid_1's rmse: 0.0919818\n",
      "[325]\ttraining's rmse: 0.0943015\tvalid_1's rmse: 0.0919593\n",
      "[350]\ttraining's rmse: 0.0942155\tvalid_1's rmse: 0.0919366\n",
      "[375]\ttraining's rmse: 0.0941418\tvalid_1's rmse: 0.0919186\n",
      "[400]\ttraining's rmse: 0.0940648\tvalid_1's rmse: 0.0919004\n",
      "[425]\ttraining's rmse: 0.0939908\tvalid_1's rmse: 0.0918856\n",
      "[450]\ttraining's rmse: 0.0939248\tvalid_1's rmse: 0.0918698\n",
      "[475]\ttraining's rmse: 0.0938616\tvalid_1's rmse: 0.0918537\n",
      "[500]\ttraining's rmse: 0.0938086\tvalid_1's rmse: 0.0918395\n",
      "[525]\ttraining's rmse: 0.0937365\tvalid_1's rmse: 0.0918251\n",
      "[550]\ttraining's rmse: 0.0936747\tvalid_1's rmse: 0.0918139\n",
      "[575]\ttraining's rmse: 0.0936144\tvalid_1's rmse: 0.0918073\n",
      "[600]\ttraining's rmse: 0.0935574\tvalid_1's rmse: 0.0918032\n",
      "[625]\ttraining's rmse: 0.0935111\tvalid_1's rmse: 0.0917951\n",
      "[650]\ttraining's rmse: 0.0934516\tvalid_1's rmse: 0.0917869\n",
      "[675]\ttraining's rmse: 0.093395\tvalid_1's rmse: 0.0917793\n",
      "[700]\ttraining's rmse: 0.0933447\tvalid_1's rmse: 0.0917774\n",
      "[725]\ttraining's rmse: 0.0932988\tvalid_1's rmse: 0.0917789\n",
      "[750]\ttraining's rmse: 0.0932552\tvalid_1's rmse: 0.0917786\n",
      "[775]\ttraining's rmse: 0.093219\tvalid_1's rmse: 0.0917733\n",
      "[800]\ttraining's rmse: 0.0931735\tvalid_1's rmse: 0.0917751\n",
      "[825]\ttraining's rmse: 0.0931346\tvalid_1's rmse: 0.0917758\n",
      "Early stopping, best iteration is:\n",
      "[797]\ttraining's rmse: 0.0931784\tvalid_1's rmse: 0.0917697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0757051\tvalid_1's rmse: 0.0776661\n",
      "[50]\ttraining's rmse: 0.0755927\tvalid_1's rmse: 0.0776215\n",
      "[75]\ttraining's rmse: 0.0754832\tvalid_1's rmse: 0.0775774\n",
      "[100]\ttraining's rmse: 0.0753831\tvalid_1's rmse: 0.0775376\n",
      "[125]\ttraining's rmse: 0.0752813\tvalid_1's rmse: 0.0774971\n",
      "[150]\ttraining's rmse: 0.0751916\tvalid_1's rmse: 0.0774614\n",
      "[175]\ttraining's rmse: 0.0751152\tvalid_1's rmse: 0.0774303\n",
      "[200]\ttraining's rmse: 0.0750342\tvalid_1's rmse: 0.0774004\n",
      "[225]\ttraining's rmse: 0.0749517\tvalid_1's rmse: 0.0773721\n",
      "[250]\ttraining's rmse: 0.0748827\tvalid_1's rmse: 0.0773448\n",
      "[275]\ttraining's rmse: 0.0748187\tvalid_1's rmse: 0.0773212\n",
      "[300]\ttraining's rmse: 0.074756\tvalid_1's rmse: 0.0772985\n",
      "[325]\ttraining's rmse: 0.0746957\tvalid_1's rmse: 0.0772765\n",
      "[350]\ttraining's rmse: 0.0746346\tvalid_1's rmse: 0.077256\n",
      "[375]\ttraining's rmse: 0.074584\tvalid_1's rmse: 0.0772386\n",
      "[400]\ttraining's rmse: 0.0745283\tvalid_1's rmse: 0.0772211\n",
      "[425]\ttraining's rmse: 0.0744801\tvalid_1's rmse: 0.0772037\n",
      "[450]\ttraining's rmse: 0.0744321\tvalid_1's rmse: 0.0771876\n",
      "[475]\ttraining's rmse: 0.0743913\tvalid_1's rmse: 0.0771736\n",
      "[500]\ttraining's rmse: 0.074358\tvalid_1's rmse: 0.0771603\n",
      "[525]\ttraining's rmse: 0.0743146\tvalid_1's rmse: 0.0771487\n",
      "[550]\ttraining's rmse: 0.0742741\tvalid_1's rmse: 0.077136\n",
      "[575]\ttraining's rmse: 0.074237\tvalid_1's rmse: 0.0771249\n",
      "[600]\ttraining's rmse: 0.0742003\tvalid_1's rmse: 0.0771146\n",
      "[625]\ttraining's rmse: 0.074173\tvalid_1's rmse: 0.0771047\n",
      "[650]\ttraining's rmse: 0.0741398\tvalid_1's rmse: 0.0770956\n",
      "[675]\ttraining's rmse: 0.0741042\tvalid_1's rmse: 0.0770869\n",
      "[700]\ttraining's rmse: 0.0740745\tvalid_1's rmse: 0.0770793\n",
      "[725]\ttraining's rmse: 0.0740446\tvalid_1's rmse: 0.0770711\n",
      "[750]\ttraining's rmse: 0.0740174\tvalid_1's rmse: 0.0770637\n",
      "[775]\ttraining's rmse: 0.0739965\tvalid_1's rmse: 0.0770578\n",
      "[800]\ttraining's rmse: 0.0739715\tvalid_1's rmse: 0.0770513\n",
      "[825]\ttraining's rmse: 0.0739494\tvalid_1's rmse: 0.0770449\n",
      "[850]\ttraining's rmse: 0.0739235\tvalid_1's rmse: 0.0770395\n",
      "[875]\ttraining's rmse: 0.0739037\tvalid_1's rmse: 0.0770344\n",
      "[900]\ttraining's rmse: 0.0738814\tvalid_1's rmse: 0.0770291\n",
      "[925]\ttraining's rmse: 0.0738607\tvalid_1's rmse: 0.0770235\n",
      "[950]\ttraining's rmse: 0.0738422\tvalid_1's rmse: 0.0770192\n",
      "[975]\ttraining's rmse: 0.0738241\tvalid_1's rmse: 0.077014\n",
      "[1000]\ttraining's rmse: 0.073807\tvalid_1's rmse: 0.0770099\n",
      "[1025]\ttraining's rmse: 0.0737881\tvalid_1's rmse: 0.0770051\n",
      "[1050]\ttraining's rmse: 0.0737721\tvalid_1's rmse: 0.0770002\n",
      "[1075]\ttraining's rmse: 0.0737568\tvalid_1's rmse: 0.0769979\n",
      "[1100]\ttraining's rmse: 0.0737422\tvalid_1's rmse: 0.0769939\n",
      "[1125]\ttraining's rmse: 0.0737271\tvalid_1's rmse: 0.0769903\n",
      "[1150]\ttraining's rmse: 0.0737134\tvalid_1's rmse: 0.0769864\n",
      "[1175]\ttraining's rmse: 0.0737002\tvalid_1's rmse: 0.0769837\n",
      "[1200]\ttraining's rmse: 0.0736865\tvalid_1's rmse: 0.0769808\n",
      "[1225]\ttraining's rmse: 0.0736739\tvalid_1's rmse: 0.0769772\n",
      "[1250]\ttraining's rmse: 0.0736623\tvalid_1's rmse: 0.0769746\n",
      "[1275]\ttraining's rmse: 0.0736489\tvalid_1's rmse: 0.0769721\n",
      "[1300]\ttraining's rmse: 0.0736383\tvalid_1's rmse: 0.0769692\n",
      "[1325]\ttraining's rmse: 0.0736263\tvalid_1's rmse: 0.0769671\n",
      "[1350]\ttraining's rmse: 0.0736148\tvalid_1's rmse: 0.0769652\n",
      "[1375]\ttraining's rmse: 0.0736048\tvalid_1's rmse: 0.0769635\n",
      "[1400]\ttraining's rmse: 0.0735968\tvalid_1's rmse: 0.0769598\n",
      "[1425]\ttraining's rmse: 0.0735886\tvalid_1's rmse: 0.0769583\n",
      "[1450]\ttraining's rmse: 0.0735797\tvalid_1's rmse: 0.0769562\n",
      "[1475]\ttraining's rmse: 0.0735724\tvalid_1's rmse: 0.0769531\n",
      "[1500]\ttraining's rmse: 0.073566\tvalid_1's rmse: 0.0769518\n",
      "[1525]\ttraining's rmse: 0.0735586\tvalid_1's rmse: 0.0769497\n",
      "[1550]\ttraining's rmse: 0.0735518\tvalid_1's rmse: 0.0769481\n",
      "[1575]\ttraining's rmse: 0.0735463\tvalid_1's rmse: 0.0769459\n",
      "[1600]\ttraining's rmse: 0.0735411\tvalid_1's rmse: 0.0769447\n",
      "[1625]\ttraining's rmse: 0.0735354\tvalid_1's rmse: 0.0769435\n",
      "[1650]\ttraining's rmse: 0.0735302\tvalid_1's rmse: 0.0769426\n",
      "[1675]\ttraining's rmse: 0.0735263\tvalid_1's rmse: 0.0769417\n",
      "[1700]\ttraining's rmse: 0.073522\tvalid_1's rmse: 0.0769399\n",
      "[1725]\ttraining's rmse: 0.0735176\tvalid_1's rmse: 0.0769386\n",
      "[1750]\ttraining's rmse: 0.0735116\tvalid_1's rmse: 0.0769365\n",
      "[1775]\ttraining's rmse: 0.0735058\tvalid_1's rmse: 0.0769354\n",
      "[1800]\ttraining's rmse: 0.0735004\tvalid_1's rmse: 0.0769327\n",
      "[1825]\ttraining's rmse: 0.0734973\tvalid_1's rmse: 0.0769311\n",
      "[1850]\ttraining's rmse: 0.0734934\tvalid_1's rmse: 0.0769299\n",
      "[1875]\ttraining's rmse: 0.0734899\tvalid_1's rmse: 0.0769291\n",
      "[1900]\ttraining's rmse: 0.073487\tvalid_1's rmse: 0.0769282\n",
      "[1925]\ttraining's rmse: 0.0734834\tvalid_1's rmse: 0.0769271\n",
      "[1950]\ttraining's rmse: 0.0734801\tvalid_1's rmse: 0.0769264\n",
      "[1975]\ttraining's rmse: 0.0734783\tvalid_1's rmse: 0.0769257\n",
      "[2000]\ttraining's rmse: 0.0734751\tvalid_1's rmse: 0.076925\n",
      "[2025]\ttraining's rmse: 0.073472\tvalid_1's rmse: 0.076924\n",
      "[2050]\ttraining's rmse: 0.0734687\tvalid_1's rmse: 0.0769233\n",
      "[2075]\ttraining's rmse: 0.0734653\tvalid_1's rmse: 0.0769223\n",
      "[2100]\ttraining's rmse: 0.0734632\tvalid_1's rmse: 0.0769224\n",
      "[2125]\ttraining's rmse: 0.0734612\tvalid_1's rmse: 0.0769225\n",
      "[2150]\ttraining's rmse: 0.0734585\tvalid_1's rmse: 0.0769221\n",
      "[2175]\ttraining's rmse: 0.0734559\tvalid_1's rmse: 0.0769218\n",
      "[2200]\ttraining's rmse: 0.0734533\tvalid_1's rmse: 0.0769211\n",
      "[2225]\ttraining's rmse: 0.0734511\tvalid_1's rmse: 0.0769203\n",
      "[2250]\ttraining's rmse: 0.0734486\tvalid_1's rmse: 0.0769192\n",
      "[2275]\ttraining's rmse: 0.0734466\tvalid_1's rmse: 0.0769188\n",
      "[2300]\ttraining's rmse: 0.0734452\tvalid_1's rmse: 0.0769186\n",
      "[2325]\ttraining's rmse: 0.0734426\tvalid_1's rmse: 0.0769178\n",
      "[2350]\ttraining's rmse: 0.0734415\tvalid_1's rmse: 0.0769169\n",
      "[2375]\ttraining's rmse: 0.0734401\tvalid_1's rmse: 0.0769165\n",
      "[2400]\ttraining's rmse: 0.0734372\tvalid_1's rmse: 0.0769163\n",
      "[2425]\ttraining's rmse: 0.0734356\tvalid_1's rmse: 0.0769164\n",
      "[2450]\ttraining's rmse: 0.073433\tvalid_1's rmse: 0.0769163\n",
      "Early stopping, best iteration is:\n",
      "[2419]\ttraining's rmse: 0.0734362\tvalid_1's rmse: 0.0769161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0759239\tvalid_1's rmse: 0.0772451\n",
      "[50]\ttraining's rmse: 0.0758272\tvalid_1's rmse: 0.0771974\n",
      "[75]\ttraining's rmse: 0.0757275\tvalid_1's rmse: 0.077149\n",
      "[100]\ttraining's rmse: 0.0756356\tvalid_1's rmse: 0.0771064\n",
      "[125]\ttraining's rmse: 0.0755416\tvalid_1's rmse: 0.0770622\n",
      "[150]\ttraining's rmse: 0.0754574\tvalid_1's rmse: 0.0770234\n",
      "[175]\ttraining's rmse: 0.0753877\tvalid_1's rmse: 0.0769902\n",
      "[200]\ttraining's rmse: 0.0753104\tvalid_1's rmse: 0.0769558\n",
      "[225]\ttraining's rmse: 0.0752347\tvalid_1's rmse: 0.0769245\n",
      "[250]\ttraining's rmse: 0.0751703\tvalid_1's rmse: 0.0768947\n",
      "[275]\ttraining's rmse: 0.0751123\tvalid_1's rmse: 0.0768681\n",
      "[300]\ttraining's rmse: 0.0750541\tvalid_1's rmse: 0.0768436\n",
      "[325]\ttraining's rmse: 0.0749925\tvalid_1's rmse: 0.0768183\n",
      "[350]\ttraining's rmse: 0.0749368\tvalid_1's rmse: 0.0767958\n",
      "[375]\ttraining's rmse: 0.0748888\tvalid_1's rmse: 0.0767765\n",
      "[400]\ttraining's rmse: 0.074838\tvalid_1's rmse: 0.0767587\n",
      "[425]\ttraining's rmse: 0.0747913\tvalid_1's rmse: 0.0767402\n",
      "[450]\ttraining's rmse: 0.0747491\tvalid_1's rmse: 0.0767237\n",
      "[475]\ttraining's rmse: 0.074711\tvalid_1's rmse: 0.0767093\n",
      "[500]\ttraining's rmse: 0.0746764\tvalid_1's rmse: 0.0766944\n",
      "[525]\ttraining's rmse: 0.0746334\tvalid_1's rmse: 0.0766801\n",
      "[550]\ttraining's rmse: 0.0745922\tvalid_1's rmse: 0.0766661\n",
      "[575]\ttraining's rmse: 0.0745538\tvalid_1's rmse: 0.0766535\n",
      "[600]\ttraining's rmse: 0.0745184\tvalid_1's rmse: 0.0766416\n",
      "[625]\ttraining's rmse: 0.0744893\tvalid_1's rmse: 0.0766306\n",
      "[650]\ttraining's rmse: 0.0744559\tvalid_1's rmse: 0.0766201\n",
      "[675]\ttraining's rmse: 0.0744213\tvalid_1's rmse: 0.0766096\n",
      "[700]\ttraining's rmse: 0.0743897\tvalid_1's rmse: 0.0766002\n",
      "[725]\ttraining's rmse: 0.0743602\tvalid_1's rmse: 0.0765911\n",
      "[750]\ttraining's rmse: 0.0743324\tvalid_1's rmse: 0.076583\n",
      "[775]\ttraining's rmse: 0.0743115\tvalid_1's rmse: 0.0765753\n",
      "[800]\ttraining's rmse: 0.0742804\tvalid_1's rmse: 0.0765679\n",
      "[825]\ttraining's rmse: 0.0742576\tvalid_1's rmse: 0.0765602\n",
      "[850]\ttraining's rmse: 0.0742334\tvalid_1's rmse: 0.0765537\n",
      "[875]\ttraining's rmse: 0.0742112\tvalid_1's rmse: 0.0765472\n",
      "[900]\ttraining's rmse: 0.0741882\tvalid_1's rmse: 0.0765412\n",
      "[925]\ttraining's rmse: 0.0741658\tvalid_1's rmse: 0.0765355\n",
      "[950]\ttraining's rmse: 0.0741453\tvalid_1's rmse: 0.07653\n",
      "[975]\ttraining's rmse: 0.0741253\tvalid_1's rmse: 0.0765245\n",
      "[1000]\ttraining's rmse: 0.0741081\tvalid_1's rmse: 0.0765199\n",
      "[1025]\ttraining's rmse: 0.0740886\tvalid_1's rmse: 0.0765158\n",
      "[1050]\ttraining's rmse: 0.0740728\tvalid_1's rmse: 0.0765109\n",
      "[1075]\ttraining's rmse: 0.0740564\tvalid_1's rmse: 0.076507\n",
      "[1100]\ttraining's rmse: 0.0740439\tvalid_1's rmse: 0.0765028\n",
      "[1125]\ttraining's rmse: 0.0740288\tvalid_1's rmse: 0.0764994\n",
      "[1150]\ttraining's rmse: 0.0740127\tvalid_1's rmse: 0.0764958\n",
      "[1175]\ttraining's rmse: 0.073997\tvalid_1's rmse: 0.0764928\n",
      "[1200]\ttraining's rmse: 0.0739839\tvalid_1's rmse: 0.0764896\n",
      "[1225]\ttraining's rmse: 0.0739721\tvalid_1's rmse: 0.0764868\n",
      "[1250]\ttraining's rmse: 0.0739606\tvalid_1's rmse: 0.0764843\n",
      "[1275]\ttraining's rmse: 0.0739465\tvalid_1's rmse: 0.0764821\n",
      "[1300]\ttraining's rmse: 0.0739365\tvalid_1's rmse: 0.0764794\n",
      "[1325]\ttraining's rmse: 0.073926\tvalid_1's rmse: 0.0764768\n",
      "[1350]\ttraining's rmse: 0.0739148\tvalid_1's rmse: 0.0764746\n",
      "[1375]\ttraining's rmse: 0.0739057\tvalid_1's rmse: 0.0764731\n",
      "[1400]\ttraining's rmse: 0.0738982\tvalid_1's rmse: 0.0764712\n",
      "[1425]\ttraining's rmse: 0.0738897\tvalid_1's rmse: 0.0764695\n",
      "[1450]\ttraining's rmse: 0.073881\tvalid_1's rmse: 0.076468\n",
      "[1475]\ttraining's rmse: 0.0738712\tvalid_1's rmse: 0.0764664\n",
      "[1500]\ttraining's rmse: 0.073865\tvalid_1's rmse: 0.0764647\n",
      "[1525]\ttraining's rmse: 0.0738577\tvalid_1's rmse: 0.0764631\n",
      "[1550]\ttraining's rmse: 0.0738496\tvalid_1's rmse: 0.0764618\n",
      "[1575]\ttraining's rmse: 0.0738416\tvalid_1's rmse: 0.0764604\n",
      "[1600]\ttraining's rmse: 0.073833\tvalid_1's rmse: 0.076459\n",
      "[1625]\ttraining's rmse: 0.0738281\tvalid_1's rmse: 0.0764579\n",
      "[1650]\ttraining's rmse: 0.073823\tvalid_1's rmse: 0.0764574\n",
      "[1675]\ttraining's rmse: 0.0738176\tvalid_1's rmse: 0.0764553\n",
      "[1700]\ttraining's rmse: 0.073813\tvalid_1's rmse: 0.0764543\n",
      "[1725]\ttraining's rmse: 0.0738086\tvalid_1's rmse: 0.0764532\n",
      "[1750]\ttraining's rmse: 0.0738002\tvalid_1's rmse: 0.076452\n",
      "[1775]\ttraining's rmse: 0.0737961\tvalid_1's rmse: 0.0764514\n",
      "[1800]\ttraining's rmse: 0.0737911\tvalid_1's rmse: 0.0764508\n",
      "[1825]\ttraining's rmse: 0.0737867\tvalid_1's rmse: 0.07645\n",
      "[1850]\ttraining's rmse: 0.073782\tvalid_1's rmse: 0.0764493\n",
      "[1875]\ttraining's rmse: 0.0737784\tvalid_1's rmse: 0.076449\n",
      "[1900]\ttraining's rmse: 0.0737757\tvalid_1's rmse: 0.0764484\n",
      "[1925]\ttraining's rmse: 0.0737713\tvalid_1's rmse: 0.0764478\n",
      "[1950]\ttraining's rmse: 0.0737682\tvalid_1's rmse: 0.0764472\n",
      "[1975]\ttraining's rmse: 0.0737657\tvalid_1's rmse: 0.0764468\n",
      "[2000]\ttraining's rmse: 0.0737623\tvalid_1's rmse: 0.0764462\n",
      "[2025]\ttraining's rmse: 0.0737591\tvalid_1's rmse: 0.0764464\n",
      "[2050]\ttraining's rmse: 0.0737565\tvalid_1's rmse: 0.0764459\n",
      "[2075]\ttraining's rmse: 0.0737543\tvalid_1's rmse: 0.0764457\n",
      "[2100]\ttraining's rmse: 0.0737525\tvalid_1's rmse: 0.0764454\n",
      "[2125]\ttraining's rmse: 0.0737497\tvalid_1's rmse: 0.0764452\n",
      "[2150]\ttraining's rmse: 0.073747\tvalid_1's rmse: 0.0764452\n",
      "[2175]\ttraining's rmse: 0.0737441\tvalid_1's rmse: 0.0764453\n",
      "[2200]\ttraining's rmse: 0.0737418\tvalid_1's rmse: 0.0764448\n",
      "[2225]\ttraining's rmse: 0.0737385\tvalid_1's rmse: 0.0764448\n",
      "[2250]\ttraining's rmse: 0.0737366\tvalid_1's rmse: 0.0764449\n",
      "Early stopping, best iteration is:\n",
      "[2202]\ttraining's rmse: 0.0737415\tvalid_1's rmse: 0.0764448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0773501\tvalid_1's rmse: 0.0743421\n",
      "[50]\ttraining's rmse: 0.0772572\tvalid_1's rmse: 0.0743003\n",
      "[75]\ttraining's rmse: 0.0771595\tvalid_1's rmse: 0.0742562\n",
      "[100]\ttraining's rmse: 0.0770718\tvalid_1's rmse: 0.0742161\n",
      "[125]\ttraining's rmse: 0.0769819\tvalid_1's rmse: 0.0741767\n",
      "[150]\ttraining's rmse: 0.0768983\tvalid_1's rmse: 0.0741406\n",
      "[175]\ttraining's rmse: 0.0768278\tvalid_1's rmse: 0.0741107\n",
      "[200]\ttraining's rmse: 0.0767538\tvalid_1's rmse: 0.0740813\n",
      "[225]\ttraining's rmse: 0.0766787\tvalid_1's rmse: 0.0740542\n",
      "[250]\ttraining's rmse: 0.0766184\tvalid_1's rmse: 0.0740302\n",
      "[275]\ttraining's rmse: 0.076561\tvalid_1's rmse: 0.0740067\n",
      "[300]\ttraining's rmse: 0.0765049\tvalid_1's rmse: 0.073984\n",
      "[325]\ttraining's rmse: 0.0764469\tvalid_1's rmse: 0.0739639\n",
      "[350]\ttraining's rmse: 0.0763893\tvalid_1's rmse: 0.0739443\n",
      "[375]\ttraining's rmse: 0.0763423\tvalid_1's rmse: 0.0739261\n",
      "[400]\ttraining's rmse: 0.0762917\tvalid_1's rmse: 0.073923\n",
      "[425]\ttraining's rmse: 0.0762484\tvalid_1's rmse: 0.0739075\n",
      "[450]\ttraining's rmse: 0.0762088\tvalid_1's rmse: 0.0738957\n",
      "[475]\ttraining's rmse: 0.07617\tvalid_1's rmse: 0.0738872\n",
      "[500]\ttraining's rmse: 0.0761383\tvalid_1's rmse: 0.0738754\n",
      "[525]\ttraining's rmse: 0.076095\tvalid_1's rmse: 0.0738735\n",
      "[550]\ttraining's rmse: 0.0760563\tvalid_1's rmse: 0.0738624\n",
      "[575]\ttraining's rmse: 0.07602\tvalid_1's rmse: 0.0738582\n",
      "[600]\ttraining's rmse: 0.0759858\tvalid_1's rmse: 0.0738498\n",
      "[625]\ttraining's rmse: 0.0759574\tvalid_1's rmse: 0.0738462\n",
      "[650]\ttraining's rmse: 0.0759234\tvalid_1's rmse: 0.0738418\n",
      "[675]\ttraining's rmse: 0.0758883\tvalid_1's rmse: 0.073834\n",
      "[700]\ttraining's rmse: 0.0758571\tvalid_1's rmse: 0.0738353\n",
      "[725]\ttraining's rmse: 0.0758304\tvalid_1's rmse: 0.0738398\n",
      "Early stopping, best iteration is:\n",
      "[681]\ttraining's rmse: 0.0758804\tvalid_1's rmse: 0.0738321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0750681\tvalid_1's rmse: 0.0772302\n",
      "[50]\ttraining's rmse: 0.0749613\tvalid_1's rmse: 0.0771843\n",
      "[75]\ttraining's rmse: 0.0748565\tvalid_1's rmse: 0.077141\n",
      "[100]\ttraining's rmse: 0.0747603\tvalid_1's rmse: 0.0771014\n",
      "[125]\ttraining's rmse: 0.0746603\tvalid_1's rmse: 0.0770607\n",
      "[150]\ttraining's rmse: 0.0745707\tvalid_1's rmse: 0.0770256\n",
      "[175]\ttraining's rmse: 0.0744989\tvalid_1's rmse: 0.0769942\n",
      "[200]\ttraining's rmse: 0.0744188\tvalid_1's rmse: 0.0769645\n",
      "[225]\ttraining's rmse: 0.0743426\tvalid_1's rmse: 0.076936\n",
      "[250]\ttraining's rmse: 0.0742762\tvalid_1's rmse: 0.0769089\n",
      "[275]\ttraining's rmse: 0.0742157\tvalid_1's rmse: 0.0768835\n",
      "[300]\ttraining's rmse: 0.0741556\tvalid_1's rmse: 0.0768607\n",
      "[325]\ttraining's rmse: 0.0740946\tvalid_1's rmse: 0.0768391\n",
      "[350]\ttraining's rmse: 0.0740353\tvalid_1's rmse: 0.0768189\n",
      "[375]\ttraining's rmse: 0.0739875\tvalid_1's rmse: 0.0768012\n",
      "[400]\ttraining's rmse: 0.0739343\tvalid_1's rmse: 0.0767845\n",
      "[425]\ttraining's rmse: 0.0738866\tvalid_1's rmse: 0.0767683\n",
      "[450]\ttraining's rmse: 0.0738424\tvalid_1's rmse: 0.0767506\n",
      "[475]\ttraining's rmse: 0.0738054\tvalid_1's rmse: 0.0767372\n",
      "[500]\ttraining's rmse: 0.0737715\tvalid_1's rmse: 0.0767243\n",
      "[525]\ttraining's rmse: 0.0737313\tvalid_1's rmse: 0.0767111\n",
      "[550]\ttraining's rmse: 0.0736904\tvalid_1's rmse: 0.0766979\n",
      "[575]\ttraining's rmse: 0.073653\tvalid_1's rmse: 0.0766865\n",
      "[600]\ttraining's rmse: 0.0736183\tvalid_1's rmse: 0.0766739\n",
      "[625]\ttraining's rmse: 0.0735901\tvalid_1's rmse: 0.0766639\n",
      "[650]\ttraining's rmse: 0.073557\tvalid_1's rmse: 0.0766529\n",
      "[675]\ttraining's rmse: 0.0735218\tvalid_1's rmse: 0.0766435\n",
      "[700]\ttraining's rmse: 0.0734937\tvalid_1's rmse: 0.0766339\n",
      "[725]\ttraining's rmse: 0.0734657\tvalid_1's rmse: 0.0766256\n",
      "[750]\ttraining's rmse: 0.0734396\tvalid_1's rmse: 0.0766175\n",
      "[775]\ttraining's rmse: 0.0734191\tvalid_1's rmse: 0.0766102\n",
      "[800]\ttraining's rmse: 0.0733939\tvalid_1's rmse: 0.0766036\n",
      "[825]\ttraining's rmse: 0.0733728\tvalid_1's rmse: 0.076595\n",
      "[850]\ttraining's rmse: 0.0733491\tvalid_1's rmse: 0.0765898\n",
      "[875]\ttraining's rmse: 0.0733279\tvalid_1's rmse: 0.076584\n",
      "[900]\ttraining's rmse: 0.0733025\tvalid_1's rmse: 0.0765779\n",
      "[925]\ttraining's rmse: 0.0732833\tvalid_1's rmse: 0.0765715\n",
      "[950]\ttraining's rmse: 0.0732653\tvalid_1's rmse: 0.0765663\n",
      "[975]\ttraining's rmse: 0.0732475\tvalid_1's rmse: 0.0765616\n",
      "[1000]\ttraining's rmse: 0.0732281\tvalid_1's rmse: 0.0765561\n",
      "[1025]\ttraining's rmse: 0.0732109\tvalid_1's rmse: 0.0765509\n",
      "[1050]\ttraining's rmse: 0.0731945\tvalid_1's rmse: 0.0765465\n",
      "[1075]\ttraining's rmse: 0.0731801\tvalid_1's rmse: 0.0765425\n",
      "[1100]\ttraining's rmse: 0.0731674\tvalid_1's rmse: 0.0765374\n",
      "[1125]\ttraining's rmse: 0.0731538\tvalid_1's rmse: 0.0765326\n",
      "[1150]\ttraining's rmse: 0.073141\tvalid_1's rmse: 0.0765294\n",
      "[1175]\ttraining's rmse: 0.073129\tvalid_1's rmse: 0.0765257\n",
      "[1200]\ttraining's rmse: 0.0731165\tvalid_1's rmse: 0.0765217\n",
      "[1225]\ttraining's rmse: 0.0731045\tvalid_1's rmse: 0.0765186\n",
      "[1250]\ttraining's rmse: 0.0730945\tvalid_1's rmse: 0.0765154\n",
      "[1275]\ttraining's rmse: 0.0730812\tvalid_1's rmse: 0.0765121\n",
      "[1300]\ttraining's rmse: 0.0730711\tvalid_1's rmse: 0.0765092\n",
      "[1325]\ttraining's rmse: 0.0730617\tvalid_1's rmse: 0.0765068\n",
      "[1350]\ttraining's rmse: 0.0730509\tvalid_1's rmse: 0.0765029\n",
      "[1375]\ttraining's rmse: 0.0730406\tvalid_1's rmse: 0.0765009\n",
      "[1400]\ttraining's rmse: 0.0730338\tvalid_1's rmse: 0.0764984\n",
      "[1425]\ttraining's rmse: 0.0730225\tvalid_1's rmse: 0.0764967\n",
      "[1450]\ttraining's rmse: 0.0730141\tvalid_1's rmse: 0.0764947\n",
      "[1475]\ttraining's rmse: 0.073007\tvalid_1's rmse: 0.0764923\n",
      "[1500]\ttraining's rmse: 0.0730003\tvalid_1's rmse: 0.0764902\n",
      "[1525]\ttraining's rmse: 0.0729947\tvalid_1's rmse: 0.076488\n",
      "[1550]\ttraining's rmse: 0.0729873\tvalid_1's rmse: 0.0764857\n",
      "[1575]\ttraining's rmse: 0.0729825\tvalid_1's rmse: 0.0764842\n",
      "[1600]\ttraining's rmse: 0.072977\tvalid_1's rmse: 0.0764816\n",
      "[1625]\ttraining's rmse: 0.0729713\tvalid_1's rmse: 0.0764792\n",
      "[1650]\ttraining's rmse: 0.0729654\tvalid_1's rmse: 0.0764777\n",
      "[1675]\ttraining's rmse: 0.0729613\tvalid_1's rmse: 0.076476\n",
      "[1700]\ttraining's rmse: 0.0729574\tvalid_1's rmse: 0.0764738\n",
      "[1725]\ttraining's rmse: 0.072953\tvalid_1's rmse: 0.0764734\n",
      "[1750]\ttraining's rmse: 0.0729467\tvalid_1's rmse: 0.0764713\n",
      "[1775]\ttraining's rmse: 0.0729429\tvalid_1's rmse: 0.0764706\n",
      "[1800]\ttraining's rmse: 0.0729395\tvalid_1's rmse: 0.0764699\n",
      "[1825]\ttraining's rmse: 0.0729344\tvalid_1's rmse: 0.0764687\n",
      "[1850]\ttraining's rmse: 0.0729302\tvalid_1's rmse: 0.0764672\n",
      "[1875]\ttraining's rmse: 0.0729261\tvalid_1's rmse: 0.0764667\n",
      "[1900]\ttraining's rmse: 0.0729219\tvalid_1's rmse: 0.076466\n",
      "[1925]\ttraining's rmse: 0.0729176\tvalid_1's rmse: 0.0764653\n",
      "[1950]\ttraining's rmse: 0.0729149\tvalid_1's rmse: 0.076464\n",
      "[1975]\ttraining's rmse: 0.0729125\tvalid_1's rmse: 0.0764625\n",
      "[2000]\ttraining's rmse: 0.07291\tvalid_1's rmse: 0.0764617\n",
      "[2025]\ttraining's rmse: 0.0729079\tvalid_1's rmse: 0.0764613\n",
      "[2050]\ttraining's rmse: 0.0729053\tvalid_1's rmse: 0.0764601\n",
      "[2075]\ttraining's rmse: 0.0729024\tvalid_1's rmse: 0.076458\n",
      "[2100]\ttraining's rmse: 0.0729001\tvalid_1's rmse: 0.0764574\n",
      "[2125]\ttraining's rmse: 0.0728976\tvalid_1's rmse: 0.0764564\n",
      "[2150]\ttraining's rmse: 0.0728944\tvalid_1's rmse: 0.0764562\n",
      "[2175]\ttraining's rmse: 0.0728923\tvalid_1's rmse: 0.0764556\n",
      "[2200]\ttraining's rmse: 0.0728903\tvalid_1's rmse: 0.076455\n",
      "[2225]\ttraining's rmse: 0.0728884\tvalid_1's rmse: 0.0764547\n",
      "[2250]\ttraining's rmse: 0.0728857\tvalid_1's rmse: 0.0764535\n",
      "[2275]\ttraining's rmse: 0.0728832\tvalid_1's rmse: 0.0764534\n",
      "[2300]\ttraining's rmse: 0.0728812\tvalid_1's rmse: 0.0764524\n",
      "[2325]\ttraining's rmse: 0.0728798\tvalid_1's rmse: 0.0764519\n",
      "[2350]\ttraining's rmse: 0.0728787\tvalid_1's rmse: 0.0764515\n",
      "[2375]\ttraining's rmse: 0.0728761\tvalid_1's rmse: 0.0764504\n",
      "[2400]\ttraining's rmse: 0.0728746\tvalid_1's rmse: 0.0764506\n",
      "[2425]\ttraining's rmse: 0.0728734\tvalid_1's rmse: 0.0764504\n",
      "[2450]\ttraining's rmse: 0.0728722\tvalid_1's rmse: 0.0764501\n",
      "[2475]\ttraining's rmse: 0.07287\tvalid_1's rmse: 0.0764495\n",
      "[2500]\ttraining's rmse: 0.0728683\tvalid_1's rmse: 0.0764488\n",
      "[2525]\ttraining's rmse: 0.0728666\tvalid_1's rmse: 0.0764483\n",
      "[2550]\ttraining's rmse: 0.0728645\tvalid_1's rmse: 0.0764472\n",
      "[2575]\ttraining's rmse: 0.0728621\tvalid_1's rmse: 0.076447\n",
      "[2600]\ttraining's rmse: 0.0728608\tvalid_1's rmse: 0.0764466\n",
      "[2625]\ttraining's rmse: 0.0728601\tvalid_1's rmse: 0.0764464\n",
      "Early stopping, best iteration is:\n",
      "[2584]\ttraining's rmse: 0.0728618\tvalid_1's rmse: 0.0764463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0753715\tvalid_1's rmse: 0.0766508\n",
      "[50]\ttraining's rmse: 0.0752792\tvalid_1's rmse: 0.076602\n",
      "[75]\ttraining's rmse: 0.0751821\tvalid_1's rmse: 0.0765546\n",
      "[100]\ttraining's rmse: 0.0750931\tvalid_1's rmse: 0.0765117\n",
      "[125]\ttraining's rmse: 0.0750026\tvalid_1's rmse: 0.076469\n",
      "[150]\ttraining's rmse: 0.0749213\tvalid_1's rmse: 0.076429\n",
      "[175]\ttraining's rmse: 0.0748528\tvalid_1's rmse: 0.0763957\n",
      "[200]\ttraining's rmse: 0.074779\tvalid_1's rmse: 0.0763621\n",
      "[225]\ttraining's rmse: 0.0747088\tvalid_1's rmse: 0.0763312\n",
      "[250]\ttraining's rmse: 0.0746456\tvalid_1's rmse: 0.0763031\n",
      "[275]\ttraining's rmse: 0.0745878\tvalid_1's rmse: 0.0762762\n",
      "[300]\ttraining's rmse: 0.0745304\tvalid_1's rmse: 0.0762513\n",
      "[325]\ttraining's rmse: 0.0744713\tvalid_1's rmse: 0.0762277\n",
      "[350]\ttraining's rmse: 0.0744161\tvalid_1's rmse: 0.0762059\n",
      "[375]\ttraining's rmse: 0.0743702\tvalid_1's rmse: 0.0761865\n",
      "[400]\ttraining's rmse: 0.0743192\tvalid_1's rmse: 0.0761674\n",
      "[425]\ttraining's rmse: 0.0742738\tvalid_1's rmse: 0.0761489\n",
      "[450]\ttraining's rmse: 0.0742312\tvalid_1's rmse: 0.0761317\n",
      "[475]\ttraining's rmse: 0.074192\tvalid_1's rmse: 0.0761159\n",
      "[500]\ttraining's rmse: 0.0741578\tvalid_1's rmse: 0.0761005\n",
      "[525]\ttraining's rmse: 0.0741152\tvalid_1's rmse: 0.076085\n",
      "[550]\ttraining's rmse: 0.074073\tvalid_1's rmse: 0.0760705\n",
      "[575]\ttraining's rmse: 0.0740378\tvalid_1's rmse: 0.0760577\n",
      "[600]\ttraining's rmse: 0.074003\tvalid_1's rmse: 0.076046\n",
      "[625]\ttraining's rmse: 0.0739751\tvalid_1's rmse: 0.0760347\n",
      "[650]\ttraining's rmse: 0.073942\tvalid_1's rmse: 0.076024\n",
      "[675]\ttraining's rmse: 0.0739081\tvalid_1's rmse: 0.0760143\n",
      "[700]\ttraining's rmse: 0.0738776\tvalid_1's rmse: 0.076005\n",
      "[725]\ttraining's rmse: 0.0738489\tvalid_1's rmse: 0.075997\n",
      "[750]\ttraining's rmse: 0.0738233\tvalid_1's rmse: 0.0759895\n",
      "[775]\ttraining's rmse: 0.0738009\tvalid_1's rmse: 0.0759815\n",
      "[800]\ttraining's rmse: 0.0737743\tvalid_1's rmse: 0.0759739\n",
      "[825]\ttraining's rmse: 0.0737517\tvalid_1's rmse: 0.0759667\n",
      "[850]\ttraining's rmse: 0.0737284\tvalid_1's rmse: 0.0759606\n",
      "[875]\ttraining's rmse: 0.0737087\tvalid_1's rmse: 0.0759545\n",
      "[900]\ttraining's rmse: 0.0736884\tvalid_1's rmse: 0.0759485\n",
      "[925]\ttraining's rmse: 0.0736694\tvalid_1's rmse: 0.0759436\n",
      "[950]\ttraining's rmse: 0.0736495\tvalid_1's rmse: 0.0759377\n",
      "[975]\ttraining's rmse: 0.0736295\tvalid_1's rmse: 0.0759322\n",
      "[1000]\ttraining's rmse: 0.0736107\tvalid_1's rmse: 0.0759276\n",
      "[1025]\ttraining's rmse: 0.0735914\tvalid_1's rmse: 0.075923\n",
      "[1050]\ttraining's rmse: 0.0735754\tvalid_1's rmse: 0.0759184\n",
      "[1075]\ttraining's rmse: 0.0735582\tvalid_1's rmse: 0.075915\n",
      "[1100]\ttraining's rmse: 0.073546\tvalid_1's rmse: 0.0759111\n",
      "[1125]\ttraining's rmse: 0.0735315\tvalid_1's rmse: 0.0759071\n",
      "[1150]\ttraining's rmse: 0.0735166\tvalid_1's rmse: 0.0759039\n",
      "[1175]\ttraining's rmse: 0.0735023\tvalid_1's rmse: 0.0759004\n",
      "[1200]\ttraining's rmse: 0.0734896\tvalid_1's rmse: 0.0758973\n",
      "[1225]\ttraining's rmse: 0.0734785\tvalid_1's rmse: 0.0758943\n",
      "[1250]\ttraining's rmse: 0.0734678\tvalid_1's rmse: 0.0758918\n",
      "[1275]\ttraining's rmse: 0.0734534\tvalid_1's rmse: 0.075889\n",
      "[1300]\ttraining's rmse: 0.0734436\tvalid_1's rmse: 0.0758864\n",
      "[1325]\ttraining's rmse: 0.0734353\tvalid_1's rmse: 0.0758842\n",
      "[1350]\ttraining's rmse: 0.0734234\tvalid_1's rmse: 0.0758819\n",
      "[1375]\ttraining's rmse: 0.0734123\tvalid_1's rmse: 0.0758798\n",
      "[1400]\ttraining's rmse: 0.0734039\tvalid_1's rmse: 0.0758771\n",
      "[1425]\ttraining's rmse: 0.0733958\tvalid_1's rmse: 0.0758756\n",
      "[1450]\ttraining's rmse: 0.0733853\tvalid_1's rmse: 0.0758745\n",
      "[1475]\ttraining's rmse: 0.0733774\tvalid_1's rmse: 0.075873\n",
      "[1500]\ttraining's rmse: 0.0733701\tvalid_1's rmse: 0.0758712\n",
      "[1525]\ttraining's rmse: 0.0733636\tvalid_1's rmse: 0.0758696\n",
      "[1550]\ttraining's rmse: 0.0733554\tvalid_1's rmse: 0.0758681\n",
      "[1575]\ttraining's rmse: 0.0733491\tvalid_1's rmse: 0.0758669\n",
      "[1600]\ttraining's rmse: 0.0733438\tvalid_1's rmse: 0.0758661\n",
      "[1625]\ttraining's rmse: 0.0733355\tvalid_1's rmse: 0.0758651\n",
      "[1650]\ttraining's rmse: 0.0733286\tvalid_1's rmse: 0.0758643\n",
      "[1675]\ttraining's rmse: 0.0733241\tvalid_1's rmse: 0.0758629\n",
      "[1700]\ttraining's rmse: 0.0733188\tvalid_1's rmse: 0.0758612\n",
      "[1725]\ttraining's rmse: 0.0733139\tvalid_1's rmse: 0.0758604\n",
      "[1750]\ttraining's rmse: 0.0733084\tvalid_1's rmse: 0.0758598\n",
      "[1775]\ttraining's rmse: 0.0733041\tvalid_1's rmse: 0.0758587\n",
      "[1800]\ttraining's rmse: 0.0732994\tvalid_1's rmse: 0.0758583\n",
      "[1825]\ttraining's rmse: 0.0732941\tvalid_1's rmse: 0.0758579\n",
      "[1850]\ttraining's rmse: 0.0732899\tvalid_1's rmse: 0.0758564\n",
      "[1875]\ttraining's rmse: 0.0732851\tvalid_1's rmse: 0.0758557\n",
      "[1900]\ttraining's rmse: 0.0732804\tvalid_1's rmse: 0.075855\n",
      "[1925]\ttraining's rmse: 0.0732756\tvalid_1's rmse: 0.0758545\n",
      "[1950]\ttraining's rmse: 0.0732734\tvalid_1's rmse: 0.075854\n",
      "[1975]\ttraining's rmse: 0.0732706\tvalid_1's rmse: 0.0758536\n",
      "[2000]\ttraining's rmse: 0.0732682\tvalid_1's rmse: 0.0758535\n",
      "[2025]\ttraining's rmse: 0.0732659\tvalid_1's rmse: 0.075853\n",
      "[2050]\ttraining's rmse: 0.0732627\tvalid_1's rmse: 0.0758526\n",
      "[2075]\ttraining's rmse: 0.0732605\tvalid_1's rmse: 0.0758524\n",
      "[2100]\ttraining's rmse: 0.0732577\tvalid_1's rmse: 0.0758522\n",
      "[2125]\ttraining's rmse: 0.0732555\tvalid_1's rmse: 0.075852\n",
      "[2150]\ttraining's rmse: 0.0732527\tvalid_1's rmse: 0.075852\n",
      "[2175]\ttraining's rmse: 0.0732505\tvalid_1's rmse: 0.0758519\n",
      "[2200]\ttraining's rmse: 0.0732479\tvalid_1's rmse: 0.0758515\n",
      "[2225]\ttraining's rmse: 0.0732461\tvalid_1's rmse: 0.0758514\n",
      "[2250]\ttraining's rmse: 0.073244\tvalid_1's rmse: 0.0758513\n",
      "[2275]\ttraining's rmse: 0.0732416\tvalid_1's rmse: 0.075851\n",
      "[2300]\ttraining's rmse: 0.0732387\tvalid_1's rmse: 0.0758509\n",
      "[2325]\ttraining's rmse: 0.0732371\tvalid_1's rmse: 0.0758509\n",
      "[2350]\ttraining's rmse: 0.0732355\tvalid_1's rmse: 0.0758506\n",
      "[2375]\ttraining's rmse: 0.0732334\tvalid_1's rmse: 0.0758504\n",
      "[2400]\ttraining's rmse: 0.0732312\tvalid_1's rmse: 0.0758506\n",
      "Early stopping, best iteration is:\n",
      "[2366]\ttraining's rmse: 0.073234\tvalid_1's rmse: 0.0758503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.076837\tvalid_1's rmse: 0.0736587\n",
      "[50]\ttraining's rmse: 0.0767424\tvalid_1's rmse: 0.0736154\n",
      "[75]\ttraining's rmse: 0.0766467\tvalid_1's rmse: 0.073571\n",
      "[100]\ttraining's rmse: 0.0765619\tvalid_1's rmse: 0.0735337\n",
      "[125]\ttraining's rmse: 0.0764735\tvalid_1's rmse: 0.0734957\n",
      "[150]\ttraining's rmse: 0.0763894\tvalid_1's rmse: 0.0734611\n",
      "[175]\ttraining's rmse: 0.0763226\tvalid_1's rmse: 0.0734335\n",
      "[200]\ttraining's rmse: 0.0762495\tvalid_1's rmse: 0.073406\n",
      "[225]\ttraining's rmse: 0.0761789\tvalid_1's rmse: 0.0733778\n",
      "[250]\ttraining's rmse: 0.0761182\tvalid_1's rmse: 0.0733524\n",
      "[275]\ttraining's rmse: 0.0760618\tvalid_1's rmse: 0.0733286\n",
      "[300]\ttraining's rmse: 0.0760047\tvalid_1's rmse: 0.0733068\n",
      "[325]\ttraining's rmse: 0.0759476\tvalid_1's rmse: 0.073286\n",
      "[350]\ttraining's rmse: 0.0758911\tvalid_1's rmse: 0.0732656\n",
      "[375]\ttraining's rmse: 0.0758455\tvalid_1's rmse: 0.0732495\n",
      "[400]\ttraining's rmse: 0.0757962\tvalid_1's rmse: 0.0732448\n",
      "[425]\ttraining's rmse: 0.0757525\tvalid_1's rmse: 0.0732299\n",
      "[450]\ttraining's rmse: 0.0757115\tvalid_1's rmse: 0.0732149\n",
      "[475]\ttraining's rmse: 0.0756732\tvalid_1's rmse: 0.073202\n",
      "[500]\ttraining's rmse: 0.0756413\tvalid_1's rmse: 0.0731887\n",
      "[525]\ttraining's rmse: 0.0755977\tvalid_1's rmse: 0.073185\n",
      "[550]\ttraining's rmse: 0.0755577\tvalid_1's rmse: 0.0731725\n",
      "[575]\ttraining's rmse: 0.0755205\tvalid_1's rmse: 0.0731617\n",
      "[600]\ttraining's rmse: 0.0754856\tvalid_1's rmse: 0.0731538\n",
      "[625]\ttraining's rmse: 0.0754599\tvalid_1's rmse: 0.0731468\n",
      "[650]\ttraining's rmse: 0.0754249\tvalid_1's rmse: 0.0731382\n",
      "[675]\ttraining's rmse: 0.0753906\tvalid_1's rmse: 0.0731305\n",
      "[700]\ttraining's rmse: 0.0753609\tvalid_1's rmse: 0.073124\n",
      "[725]\ttraining's rmse: 0.0753302\tvalid_1's rmse: 0.0731223\n",
      "[750]\ttraining's rmse: 0.0753022\tvalid_1's rmse: 0.0731195\n",
      "[775]\ttraining's rmse: 0.0752807\tvalid_1's rmse: 0.0731154\n",
      "[800]\ttraining's rmse: 0.0752523\tvalid_1's rmse: 0.0731105\n",
      "[825]\ttraining's rmse: 0.0752274\tvalid_1's rmse: 0.0731155\n",
      "[850]\ttraining's rmse: 0.0752034\tvalid_1's rmse: 0.0731107\n",
      "[875]\ttraining's rmse: 0.0751803\tvalid_1's rmse: 0.0731099\n",
      "[900]\ttraining's rmse: 0.075155\tvalid_1's rmse: 0.0731184\n",
      "Early stopping, best iteration is:\n",
      "[873]\ttraining's rmse: 0.0751814\tvalid_1's rmse: 0.073106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0773603\tvalid_1's rmse: 0.0792022\n",
      "[50]\ttraining's rmse: 0.0772418\tvalid_1's rmse: 0.0791577\n",
      "[75]\ttraining's rmse: 0.077124\tvalid_1's rmse: 0.0791119\n",
      "[100]\ttraining's rmse: 0.0770171\tvalid_1's rmse: 0.0790738\n",
      "[125]\ttraining's rmse: 0.0769058\tvalid_1's rmse: 0.0790322\n",
      "[150]\ttraining's rmse: 0.0768059\tvalid_1's rmse: 0.0789952\n",
      "[175]\ttraining's rmse: 0.0767255\tvalid_1's rmse: 0.0789639\n",
      "[200]\ttraining's rmse: 0.0766377\tvalid_1's rmse: 0.078933\n",
      "[225]\ttraining's rmse: 0.0765472\tvalid_1's rmse: 0.0789032\n",
      "[250]\ttraining's rmse: 0.0764748\tvalid_1's rmse: 0.078876\n",
      "[275]\ttraining's rmse: 0.0764091\tvalid_1's rmse: 0.0788524\n",
      "[300]\ttraining's rmse: 0.0763398\tvalid_1's rmse: 0.07883\n",
      "[325]\ttraining's rmse: 0.0762714\tvalid_1's rmse: 0.0788083\n",
      "[350]\ttraining's rmse: 0.0762082\tvalid_1's rmse: 0.0787875\n",
      "[375]\ttraining's rmse: 0.0761525\tvalid_1's rmse: 0.0787687\n",
      "[400]\ttraining's rmse: 0.0760932\tvalid_1's rmse: 0.0787497\n",
      "[425]\ttraining's rmse: 0.0760398\tvalid_1's rmse: 0.0787346\n",
      "[450]\ttraining's rmse: 0.0759915\tvalid_1's rmse: 0.0787177\n",
      "[475]\ttraining's rmse: 0.0759486\tvalid_1's rmse: 0.0787049\n",
      "[500]\ttraining's rmse: 0.0759106\tvalid_1's rmse: 0.0786912\n",
      "[525]\ttraining's rmse: 0.0758632\tvalid_1's rmse: 0.0786772\n",
      "[550]\ttraining's rmse: 0.0758193\tvalid_1's rmse: 0.0786647\n",
      "[575]\ttraining's rmse: 0.0757789\tvalid_1's rmse: 0.0786526\n",
      "[600]\ttraining's rmse: 0.0757413\tvalid_1's rmse: 0.0786429\n",
      "[625]\ttraining's rmse: 0.0757097\tvalid_1's rmse: 0.0786333\n",
      "[650]\ttraining's rmse: 0.0756711\tvalid_1's rmse: 0.0786235\n",
      "[675]\ttraining's rmse: 0.0756324\tvalid_1's rmse: 0.0786137\n",
      "[700]\ttraining's rmse: 0.0755982\tvalid_1's rmse: 0.0786047\n",
      "[725]\ttraining's rmse: 0.0755652\tvalid_1's rmse: 0.0785968\n",
      "[750]\ttraining's rmse: 0.0755353\tvalid_1's rmse: 0.0785884\n",
      "[775]\ttraining's rmse: 0.0755125\tvalid_1's rmse: 0.0785805\n",
      "[800]\ttraining's rmse: 0.0754829\tvalid_1's rmse: 0.0785729\n",
      "[825]\ttraining's rmse: 0.0754559\tvalid_1's rmse: 0.0785662\n",
      "[850]\ttraining's rmse: 0.0754288\tvalid_1's rmse: 0.078561\n",
      "[875]\ttraining's rmse: 0.0754054\tvalid_1's rmse: 0.0785537\n",
      "[900]\ttraining's rmse: 0.075379\tvalid_1's rmse: 0.0785477\n",
      "[925]\ttraining's rmse: 0.0753589\tvalid_1's rmse: 0.0785433\n",
      "[950]\ttraining's rmse: 0.075337\tvalid_1's rmse: 0.0785386\n",
      "[975]\ttraining's rmse: 0.075318\tvalid_1's rmse: 0.0785345\n",
      "[1000]\ttraining's rmse: 0.0752963\tvalid_1's rmse: 0.0785308\n",
      "[1025]\ttraining's rmse: 0.0752762\tvalid_1's rmse: 0.0785252\n",
      "[1050]\ttraining's rmse: 0.0752558\tvalid_1's rmse: 0.0785201\n",
      "[1075]\ttraining's rmse: 0.0752389\tvalid_1's rmse: 0.0785172\n",
      "[1100]\ttraining's rmse: 0.0752247\tvalid_1's rmse: 0.0785135\n",
      "[1125]\ttraining's rmse: 0.0752082\tvalid_1's rmse: 0.0785091\n",
      "[1150]\ttraining's rmse: 0.0751893\tvalid_1's rmse: 0.078505\n",
      "[1175]\ttraining's rmse: 0.0751779\tvalid_1's rmse: 0.0785031\n",
      "[1200]\ttraining's rmse: 0.0751628\tvalid_1's rmse: 0.0784994\n",
      "[1225]\ttraining's rmse: 0.0751502\tvalid_1's rmse: 0.0784964\n",
      "[1250]\ttraining's rmse: 0.0751375\tvalid_1's rmse: 0.0784944\n",
      "[1275]\ttraining's rmse: 0.075123\tvalid_1's rmse: 0.0784914\n",
      "[1300]\ttraining's rmse: 0.0751129\tvalid_1's rmse: 0.0784885\n",
      "[1325]\ttraining's rmse: 0.0751003\tvalid_1's rmse: 0.0784859\n",
      "[1350]\ttraining's rmse: 0.0750887\tvalid_1's rmse: 0.0784842\n",
      "[1375]\ttraining's rmse: 0.0750786\tvalid_1's rmse: 0.078482\n",
      "[1400]\ttraining's rmse: 0.0750707\tvalid_1's rmse: 0.0784793\n",
      "[1425]\ttraining's rmse: 0.0750596\tvalid_1's rmse: 0.0784767\n",
      "[1450]\ttraining's rmse: 0.0750523\tvalid_1's rmse: 0.0784748\n",
      "[1475]\ttraining's rmse: 0.0750432\tvalid_1's rmse: 0.0784729\n",
      "[1500]\ttraining's rmse: 0.0750365\tvalid_1's rmse: 0.0784709\n",
      "[1525]\ttraining's rmse: 0.0750268\tvalid_1's rmse: 0.0784681\n",
      "[1550]\ttraining's rmse: 0.075019\tvalid_1's rmse: 0.0784673\n",
      "[1575]\ttraining's rmse: 0.0750127\tvalid_1's rmse: 0.0784652\n",
      "[1600]\ttraining's rmse: 0.0750062\tvalid_1's rmse: 0.0784641\n",
      "[1625]\ttraining's rmse: 0.0749997\tvalid_1's rmse: 0.0784617\n",
      "[1650]\ttraining's rmse: 0.0749957\tvalid_1's rmse: 0.078461\n",
      "[1675]\ttraining's rmse: 0.0749916\tvalid_1's rmse: 0.0784596\n",
      "[1700]\ttraining's rmse: 0.0749872\tvalid_1's rmse: 0.0784582\n",
      "[1725]\ttraining's rmse: 0.0749814\tvalid_1's rmse: 0.0784572\n",
      "[1750]\ttraining's rmse: 0.0749762\tvalid_1's rmse: 0.0784563\n",
      "[1775]\ttraining's rmse: 0.0749716\tvalid_1's rmse: 0.0784557\n",
      "[1800]\ttraining's rmse: 0.0749665\tvalid_1's rmse: 0.0784545\n",
      "[1825]\ttraining's rmse: 0.0749617\tvalid_1's rmse: 0.0784528\n",
      "[1850]\ttraining's rmse: 0.0749585\tvalid_1's rmse: 0.0784515\n",
      "[1875]\ttraining's rmse: 0.0749542\tvalid_1's rmse: 0.0784508\n",
      "[1900]\ttraining's rmse: 0.074951\tvalid_1's rmse: 0.0784513\n",
      "[1925]\ttraining's rmse: 0.0749479\tvalid_1's rmse: 0.0784504\n",
      "[1950]\ttraining's rmse: 0.0749445\tvalid_1's rmse: 0.0784485\n",
      "[1975]\ttraining's rmse: 0.074942\tvalid_1's rmse: 0.0784474\n",
      "[2000]\ttraining's rmse: 0.0749387\tvalid_1's rmse: 0.0784461\n",
      "[2025]\ttraining's rmse: 0.0749358\tvalid_1's rmse: 0.0784455\n",
      "[2050]\ttraining's rmse: 0.0749329\tvalid_1's rmse: 0.0784453\n",
      "[2075]\ttraining's rmse: 0.0749293\tvalid_1's rmse: 0.0784437\n",
      "[2100]\ttraining's rmse: 0.0749268\tvalid_1's rmse: 0.0784433\n",
      "[2125]\ttraining's rmse: 0.0749256\tvalid_1's rmse: 0.0784423\n",
      "[2150]\ttraining's rmse: 0.0749211\tvalid_1's rmse: 0.0784415\n",
      "[2175]\ttraining's rmse: 0.074919\tvalid_1's rmse: 0.0784411\n",
      "[2200]\ttraining's rmse: 0.0749165\tvalid_1's rmse: 0.0784407\n",
      "[2225]\ttraining's rmse: 0.0749145\tvalid_1's rmse: 0.0784402\n",
      "[2250]\ttraining's rmse: 0.0749123\tvalid_1's rmse: 0.0784398\n",
      "[2275]\ttraining's rmse: 0.0749096\tvalid_1's rmse: 0.0784379\n",
      "[2300]\ttraining's rmse: 0.074908\tvalid_1's rmse: 0.0784372\n",
      "[2325]\ttraining's rmse: 0.0749062\tvalid_1's rmse: 0.0784362\n",
      "[2350]\ttraining's rmse: 0.0749046\tvalid_1's rmse: 0.0784363\n",
      "[2375]\ttraining's rmse: 0.074902\tvalid_1's rmse: 0.0784362\n",
      "[2400]\ttraining's rmse: 0.0749007\tvalid_1's rmse: 0.078436\n",
      "[2425]\ttraining's rmse: 0.0748975\tvalid_1's rmse: 0.0784359\n",
      "[2450]\ttraining's rmse: 0.0748965\tvalid_1's rmse: 0.078436\n",
      "Early stopping, best iteration is:\n",
      "[2411]\ttraining's rmse: 0.0748995\tvalid_1's rmse: 0.0784357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0774461\tvalid_1's rmse: 0.0790612\n",
      "[50]\ttraining's rmse: 0.0773454\tvalid_1's rmse: 0.0790127\n",
      "[75]\ttraining's rmse: 0.0772434\tvalid_1's rmse: 0.078964\n",
      "[100]\ttraining's rmse: 0.0771519\tvalid_1's rmse: 0.0789208\n",
      "[125]\ttraining's rmse: 0.077055\tvalid_1's rmse: 0.0788776\n",
      "[150]\ttraining's rmse: 0.0769678\tvalid_1's rmse: 0.078837\n",
      "[175]\ttraining's rmse: 0.0768961\tvalid_1's rmse: 0.0788031\n",
      "[200]\ttraining's rmse: 0.076817\tvalid_1's rmse: 0.078768\n",
      "[225]\ttraining's rmse: 0.0767408\tvalid_1's rmse: 0.078736\n",
      "[250]\ttraining's rmse: 0.0766751\tvalid_1's rmse: 0.0787068\n",
      "[275]\ttraining's rmse: 0.0766128\tvalid_1's rmse: 0.0786809\n",
      "[300]\ttraining's rmse: 0.0765515\tvalid_1's rmse: 0.078655\n",
      "[325]\ttraining's rmse: 0.0764895\tvalid_1's rmse: 0.0786287\n",
      "[350]\ttraining's rmse: 0.0764296\tvalid_1's rmse: 0.0786056\n",
      "[375]\ttraining's rmse: 0.0763806\tvalid_1's rmse: 0.0785849\n",
      "[400]\ttraining's rmse: 0.0763282\tvalid_1's rmse: 0.0785652\n",
      "[425]\ttraining's rmse: 0.0762816\tvalid_1's rmse: 0.0785476\n",
      "[450]\ttraining's rmse: 0.0762328\tvalid_1's rmse: 0.0785288\n",
      "[475]\ttraining's rmse: 0.0761921\tvalid_1's rmse: 0.0785131\n",
      "[500]\ttraining's rmse: 0.0761549\tvalid_1's rmse: 0.0784971\n",
      "[525]\ttraining's rmse: 0.0761097\tvalid_1's rmse: 0.0784831\n",
      "[550]\ttraining's rmse: 0.0760679\tvalid_1's rmse: 0.0784697\n",
      "[575]\ttraining's rmse: 0.0760279\tvalid_1's rmse: 0.0784565\n",
      "[600]\ttraining's rmse: 0.0759915\tvalid_1's rmse: 0.0784442\n",
      "[625]\ttraining's rmse: 0.0759628\tvalid_1's rmse: 0.0784324\n",
      "[650]\ttraining's rmse: 0.0759282\tvalid_1's rmse: 0.0784204\n",
      "[675]\ttraining's rmse: 0.0758922\tvalid_1's rmse: 0.0784098\n",
      "[700]\ttraining's rmse: 0.0758607\tvalid_1's rmse: 0.0783994\n",
      "[725]\ttraining's rmse: 0.075831\tvalid_1's rmse: 0.0783904\n",
      "[750]\ttraining's rmse: 0.0758017\tvalid_1's rmse: 0.0783816\n",
      "[775]\ttraining's rmse: 0.0757778\tvalid_1's rmse: 0.0783724\n",
      "[800]\ttraining's rmse: 0.075749\tvalid_1's rmse: 0.0783646\n",
      "[825]\ttraining's rmse: 0.0757248\tvalid_1's rmse: 0.0783565\n",
      "[850]\ttraining's rmse: 0.0756984\tvalid_1's rmse: 0.0783496\n",
      "[875]\ttraining's rmse: 0.075677\tvalid_1's rmse: 0.0783427\n",
      "[900]\ttraining's rmse: 0.0756517\tvalid_1's rmse: 0.0783355\n",
      "[925]\ttraining's rmse: 0.0756292\tvalid_1's rmse: 0.07833\n",
      "[950]\ttraining's rmse: 0.0756085\tvalid_1's rmse: 0.0783245\n",
      "[975]\ttraining's rmse: 0.075588\tvalid_1's rmse: 0.0783188\n",
      "[1000]\ttraining's rmse: 0.0755684\tvalid_1's rmse: 0.0783135\n",
      "[1025]\ttraining's rmse: 0.0755492\tvalid_1's rmse: 0.0783088\n",
      "[1050]\ttraining's rmse: 0.0755314\tvalid_1's rmse: 0.0783038\n",
      "[1075]\ttraining's rmse: 0.0755121\tvalid_1's rmse: 0.0783003\n",
      "[1100]\ttraining's rmse: 0.0754978\tvalid_1's rmse: 0.078296\n",
      "[1125]\ttraining's rmse: 0.0754837\tvalid_1's rmse: 0.0782923\n",
      "[1150]\ttraining's rmse: 0.0754675\tvalid_1's rmse: 0.0782887\n",
      "[1175]\ttraining's rmse: 0.0754524\tvalid_1's rmse: 0.0782849\n",
      "[1200]\ttraining's rmse: 0.075438\tvalid_1's rmse: 0.0782808\n",
      "[1225]\ttraining's rmse: 0.0754236\tvalid_1's rmse: 0.078277\n",
      "[1250]\ttraining's rmse: 0.0754119\tvalid_1's rmse: 0.0782743\n",
      "[1275]\ttraining's rmse: 0.0753972\tvalid_1's rmse: 0.0782717\n",
      "[1300]\ttraining's rmse: 0.075386\tvalid_1's rmse: 0.0782684\n",
      "[1325]\ttraining's rmse: 0.075375\tvalid_1's rmse: 0.0782655\n",
      "[1350]\ttraining's rmse: 0.0753624\tvalid_1's rmse: 0.0782634\n",
      "[1375]\ttraining's rmse: 0.0753535\tvalid_1's rmse: 0.0782613\n",
      "[1400]\ttraining's rmse: 0.0753463\tvalid_1's rmse: 0.0782592\n",
      "[1425]\ttraining's rmse: 0.0753369\tvalid_1's rmse: 0.0782578\n",
      "[1450]\ttraining's rmse: 0.0753268\tvalid_1's rmse: 0.0782557\n",
      "[1475]\ttraining's rmse: 0.0753163\tvalid_1's rmse: 0.0782542\n",
      "[1500]\ttraining's rmse: 0.0753079\tvalid_1's rmse: 0.0782531\n",
      "[1525]\ttraining's rmse: 0.0752997\tvalid_1's rmse: 0.078251\n",
      "[1550]\ttraining's rmse: 0.0752935\tvalid_1's rmse: 0.0782495\n",
      "[1575]\ttraining's rmse: 0.0752863\tvalid_1's rmse: 0.0782478\n",
      "[1600]\ttraining's rmse: 0.0752811\tvalid_1's rmse: 0.0782472\n",
      "[1625]\ttraining's rmse: 0.0752748\tvalid_1's rmse: 0.0782455\n",
      "[1650]\ttraining's rmse: 0.0752675\tvalid_1's rmse: 0.0782445\n",
      "[1675]\ttraining's rmse: 0.0752617\tvalid_1's rmse: 0.0782428\n",
      "[1700]\ttraining's rmse: 0.0752565\tvalid_1's rmse: 0.0782414\n",
      "[1725]\ttraining's rmse: 0.0752506\tvalid_1's rmse: 0.0782399\n",
      "[1750]\ttraining's rmse: 0.0752452\tvalid_1's rmse: 0.0782396\n",
      "[1775]\ttraining's rmse: 0.0752399\tvalid_1's rmse: 0.0782389\n",
      "[1800]\ttraining's rmse: 0.0752358\tvalid_1's rmse: 0.0782381\n",
      "[1825]\ttraining's rmse: 0.0752317\tvalid_1's rmse: 0.0782371\n",
      "[1850]\ttraining's rmse: 0.0752275\tvalid_1's rmse: 0.0782363\n",
      "[1875]\ttraining's rmse: 0.0752232\tvalid_1's rmse: 0.0782352\n",
      "[1900]\ttraining's rmse: 0.0752198\tvalid_1's rmse: 0.0782345\n",
      "[1925]\ttraining's rmse: 0.0752153\tvalid_1's rmse: 0.078234\n",
      "[1950]\ttraining's rmse: 0.0752125\tvalid_1's rmse: 0.0782331\n",
      "[1975]\ttraining's rmse: 0.07521\tvalid_1's rmse: 0.0782328\n",
      "[2000]\ttraining's rmse: 0.0752052\tvalid_1's rmse: 0.0782317\n",
      "[2025]\ttraining's rmse: 0.0752035\tvalid_1's rmse: 0.0782314\n",
      "[2050]\ttraining's rmse: 0.0751998\tvalid_1's rmse: 0.078231\n",
      "[2075]\ttraining's rmse: 0.0751974\tvalid_1's rmse: 0.0782304\n",
      "[2100]\ttraining's rmse: 0.0751953\tvalid_1's rmse: 0.0782303\n",
      "[2125]\ttraining's rmse: 0.0751922\tvalid_1's rmse: 0.07823\n",
      "[2150]\ttraining's rmse: 0.0751899\tvalid_1's rmse: 0.0782298\n",
      "[2175]\ttraining's rmse: 0.0751857\tvalid_1's rmse: 0.0782298\n",
      "[2200]\ttraining's rmse: 0.0751831\tvalid_1's rmse: 0.0782297\n",
      "[2225]\ttraining's rmse: 0.0751806\tvalid_1's rmse: 0.0782294\n",
      "[2250]\ttraining's rmse: 0.0751784\tvalid_1's rmse: 0.0782291\n",
      "[2275]\ttraining's rmse: 0.0751747\tvalid_1's rmse: 0.0782285\n",
      "[2300]\ttraining's rmse: 0.0751726\tvalid_1's rmse: 0.0782281\n",
      "[2325]\ttraining's rmse: 0.0751714\tvalid_1's rmse: 0.078228\n",
      "[2350]\ttraining's rmse: 0.0751698\tvalid_1's rmse: 0.0782277\n",
      "[2375]\ttraining's rmse: 0.0751677\tvalid_1's rmse: 0.0782273\n",
      "[2400]\ttraining's rmse: 0.0751655\tvalid_1's rmse: 0.0782272\n",
      "[2425]\ttraining's rmse: 0.075164\tvalid_1's rmse: 0.0782271\n",
      "Early stopping, best iteration is:\n",
      "[2386]\ttraining's rmse: 0.0751667\tvalid_1's rmse: 0.0782269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0790206\tvalid_1's rmse: 0.0758587\n",
      "[50]\ttraining's rmse: 0.078922\tvalid_1's rmse: 0.0758124\n",
      "[75]\ttraining's rmse: 0.0788198\tvalid_1's rmse: 0.0757664\n",
      "[100]\ttraining's rmse: 0.0787314\tvalid_1's rmse: 0.0757275\n",
      "[125]\ttraining's rmse: 0.0786367\tvalid_1's rmse: 0.0756881\n",
      "[150]\ttraining's rmse: 0.078548\tvalid_1's rmse: 0.0756518\n",
      "[175]\ttraining's rmse: 0.0784774\tvalid_1's rmse: 0.0756237\n",
      "[200]\ttraining's rmse: 0.0783973\tvalid_1's rmse: 0.0755928\n",
      "[225]\ttraining's rmse: 0.0783204\tvalid_1's rmse: 0.0755639\n",
      "[250]\ttraining's rmse: 0.0782567\tvalid_1's rmse: 0.0755383\n",
      "[275]\ttraining's rmse: 0.0781965\tvalid_1's rmse: 0.0755156\n",
      "[300]\ttraining's rmse: 0.0781375\tvalid_1's rmse: 0.0754925\n",
      "[325]\ttraining's rmse: 0.0780772\tvalid_1's rmse: 0.0754727\n",
      "[350]\ttraining's rmse: 0.0780196\tvalid_1's rmse: 0.0754518\n",
      "[375]\ttraining's rmse: 0.0779731\tvalid_1's rmse: 0.0754336\n",
      "[400]\ttraining's rmse: 0.0779223\tvalid_1's rmse: 0.0754191\n",
      "[425]\ttraining's rmse: 0.0778765\tvalid_1's rmse: 0.0754063\n",
      "[450]\ttraining's rmse: 0.0778318\tvalid_1's rmse: 0.0753911\n",
      "[475]\ttraining's rmse: 0.0777906\tvalid_1's rmse: 0.0753811\n",
      "[500]\ttraining's rmse: 0.0777549\tvalid_1's rmse: 0.0753682\n",
      "[525]\ttraining's rmse: 0.0777082\tvalid_1's rmse: 0.0753632\n",
      "[550]\ttraining's rmse: 0.0776675\tvalid_1's rmse: 0.0753601\n",
      "[575]\ttraining's rmse: 0.0776298\tvalid_1's rmse: 0.0753531\n",
      "[600]\ttraining's rmse: 0.0775935\tvalid_1's rmse: 0.0753429\n",
      "[625]\ttraining's rmse: 0.0775644\tvalid_1's rmse: 0.0753435\n",
      "[650]\ttraining's rmse: 0.0775276\tvalid_1's rmse: 0.0753454\n",
      "[675]\ttraining's rmse: 0.0774911\tvalid_1's rmse: 0.0753415\n",
      "[700]\ttraining's rmse: 0.0774605\tvalid_1's rmse: 0.0753415\n",
      "[725]\ttraining's rmse: 0.0774291\tvalid_1's rmse: 0.0753412\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0774692\tvalid_1's rmse: 0.0753364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0760157\tvalid_1's rmse: 0.0784269\n",
      "[50]\ttraining's rmse: 0.0759053\tvalid_1's rmse: 0.0783794\n",
      "[75]\ttraining's rmse: 0.0757972\tvalid_1's rmse: 0.0783333\n",
      "[100]\ttraining's rmse: 0.0756963\tvalid_1's rmse: 0.0782921\n",
      "[125]\ttraining's rmse: 0.0755944\tvalid_1's rmse: 0.0782512\n",
      "[150]\ttraining's rmse: 0.0755022\tvalid_1's rmse: 0.0782144\n",
      "[175]\ttraining's rmse: 0.0754293\tvalid_1's rmse: 0.0781833\n",
      "[200]\ttraining's rmse: 0.0753457\tvalid_1's rmse: 0.0781499\n",
      "[225]\ttraining's rmse: 0.0752632\tvalid_1's rmse: 0.0781192\n",
      "[250]\ttraining's rmse: 0.0751938\tvalid_1's rmse: 0.0780911\n",
      "[275]\ttraining's rmse: 0.0751282\tvalid_1's rmse: 0.0780657\n",
      "[300]\ttraining's rmse: 0.0750668\tvalid_1's rmse: 0.0780427\n",
      "[325]\ttraining's rmse: 0.0750034\tvalid_1's rmse: 0.0780196\n",
      "[350]\ttraining's rmse: 0.0749415\tvalid_1's rmse: 0.0779967\n",
      "[375]\ttraining's rmse: 0.0748901\tvalid_1's rmse: 0.0779784\n",
      "[400]\ttraining's rmse: 0.0748347\tvalid_1's rmse: 0.07796\n",
      "[425]\ttraining's rmse: 0.0747853\tvalid_1's rmse: 0.077943\n",
      "[450]\ttraining's rmse: 0.0747397\tvalid_1's rmse: 0.077926\n",
      "[475]\ttraining's rmse: 0.0746985\tvalid_1's rmse: 0.0779107\n",
      "[500]\ttraining's rmse: 0.0746621\tvalid_1's rmse: 0.0778958\n",
      "[525]\ttraining's rmse: 0.0746184\tvalid_1's rmse: 0.0778822\n",
      "[550]\ttraining's rmse: 0.0745798\tvalid_1's rmse: 0.0778695\n",
      "[575]\ttraining's rmse: 0.0745416\tvalid_1's rmse: 0.0778566\n",
      "[600]\ttraining's rmse: 0.0745065\tvalid_1's rmse: 0.077845\n",
      "[625]\ttraining's rmse: 0.0744777\tvalid_1's rmse: 0.0778343\n",
      "[650]\ttraining's rmse: 0.0744444\tvalid_1's rmse: 0.0778243\n",
      "[675]\ttraining's rmse: 0.074411\tvalid_1's rmse: 0.0778142\n",
      "[700]\ttraining's rmse: 0.0743792\tvalid_1's rmse: 0.0778044\n",
      "[725]\ttraining's rmse: 0.0743482\tvalid_1's rmse: 0.0777957\n",
      "[750]\ttraining's rmse: 0.0743204\tvalid_1's rmse: 0.0777868\n",
      "[775]\ttraining's rmse: 0.0742987\tvalid_1's rmse: 0.0777783\n",
      "[800]\ttraining's rmse: 0.0742695\tvalid_1's rmse: 0.0777706\n",
      "[825]\ttraining's rmse: 0.0742471\tvalid_1's rmse: 0.0777626\n",
      "[850]\ttraining's rmse: 0.0742197\tvalid_1's rmse: 0.0777557\n",
      "[875]\ttraining's rmse: 0.0741986\tvalid_1's rmse: 0.0777487\n",
      "[900]\ttraining's rmse: 0.0741735\tvalid_1's rmse: 0.0777411\n",
      "[925]\ttraining's rmse: 0.0741508\tvalid_1's rmse: 0.0777346\n",
      "[950]\ttraining's rmse: 0.0741296\tvalid_1's rmse: 0.0777291\n",
      "[975]\ttraining's rmse: 0.0741093\tvalid_1's rmse: 0.0777227\n",
      "[1000]\ttraining's rmse: 0.0740898\tvalid_1's rmse: 0.0777172\n",
      "[1025]\ttraining's rmse: 0.0740716\tvalid_1's rmse: 0.0777121\n",
      "[1050]\ttraining's rmse: 0.0740553\tvalid_1's rmse: 0.0777065\n",
      "[1075]\ttraining's rmse: 0.0740392\tvalid_1's rmse: 0.0777027\n",
      "[1100]\ttraining's rmse: 0.074025\tvalid_1's rmse: 0.0776985\n",
      "[1125]\ttraining's rmse: 0.0740116\tvalid_1's rmse: 0.0776945\n",
      "[1150]\ttraining's rmse: 0.073998\tvalid_1's rmse: 0.0776901\n",
      "[1175]\ttraining's rmse: 0.0739841\tvalid_1's rmse: 0.0776871\n",
      "[1200]\ttraining's rmse: 0.0739724\tvalid_1's rmse: 0.0776832\n",
      "[1225]\ttraining's rmse: 0.0739579\tvalid_1's rmse: 0.0776794\n",
      "[1250]\ttraining's rmse: 0.0739461\tvalid_1's rmse: 0.0776757\n",
      "[1275]\ttraining's rmse: 0.073934\tvalid_1's rmse: 0.0776726\n",
      "[1300]\ttraining's rmse: 0.0739226\tvalid_1's rmse: 0.0776683\n",
      "[1325]\ttraining's rmse: 0.0739124\tvalid_1's rmse: 0.0776654\n",
      "[1350]\ttraining's rmse: 0.073902\tvalid_1's rmse: 0.0776624\n",
      "[1375]\ttraining's rmse: 0.0738913\tvalid_1's rmse: 0.0776603\n",
      "[1400]\ttraining's rmse: 0.0738829\tvalid_1's rmse: 0.0776573\n",
      "[1425]\ttraining's rmse: 0.0738719\tvalid_1's rmse: 0.0776546\n",
      "[1450]\ttraining's rmse: 0.0738618\tvalid_1's rmse: 0.0776515\n",
      "[1475]\ttraining's rmse: 0.0738544\tvalid_1's rmse: 0.077649\n",
      "[1500]\ttraining's rmse: 0.0738458\tvalid_1's rmse: 0.0776457\n",
      "[1525]\ttraining's rmse: 0.0738384\tvalid_1's rmse: 0.077644\n",
      "[1550]\ttraining's rmse: 0.0738302\tvalid_1's rmse: 0.0776414\n",
      "[1575]\ttraining's rmse: 0.0738245\tvalid_1's rmse: 0.0776396\n",
      "[1600]\ttraining's rmse: 0.0738185\tvalid_1's rmse: 0.0776375\n",
      "[1625]\ttraining's rmse: 0.0738118\tvalid_1's rmse: 0.0776366\n",
      "[1650]\ttraining's rmse: 0.0738064\tvalid_1's rmse: 0.077636\n",
      "[1675]\ttraining's rmse: 0.0738004\tvalid_1's rmse: 0.0776351\n",
      "[1700]\ttraining's rmse: 0.0737965\tvalid_1's rmse: 0.0776327\n",
      "[1725]\ttraining's rmse: 0.0737899\tvalid_1's rmse: 0.0776305\n",
      "[1750]\ttraining's rmse: 0.0737843\tvalid_1's rmse: 0.0776294\n",
      "[1775]\ttraining's rmse: 0.0737791\tvalid_1's rmse: 0.0776275\n",
      "[1800]\ttraining's rmse: 0.0737741\tvalid_1's rmse: 0.0776263\n",
      "[1825]\ttraining's rmse: 0.0737703\tvalid_1's rmse: 0.0776254\n",
      "[1850]\ttraining's rmse: 0.0737656\tvalid_1's rmse: 0.0776232\n",
      "[1875]\ttraining's rmse: 0.0737614\tvalid_1's rmse: 0.0776225\n",
      "[1900]\ttraining's rmse: 0.0737584\tvalid_1's rmse: 0.0776221\n",
      "[1925]\ttraining's rmse: 0.0737548\tvalid_1's rmse: 0.0776211\n",
      "[1950]\ttraining's rmse: 0.0737521\tvalid_1's rmse: 0.0776199\n",
      "[1975]\ttraining's rmse: 0.0737506\tvalid_1's rmse: 0.0776196\n",
      "[2000]\ttraining's rmse: 0.073748\tvalid_1's rmse: 0.0776192\n",
      "[2025]\ttraining's rmse: 0.0737458\tvalid_1's rmse: 0.0776178\n",
      "[2050]\ttraining's rmse: 0.0737438\tvalid_1's rmse: 0.0776171\n",
      "[2075]\ttraining's rmse: 0.0737415\tvalid_1's rmse: 0.0776163\n",
      "[2100]\ttraining's rmse: 0.0737382\tvalid_1's rmse: 0.0776152\n",
      "[2125]\ttraining's rmse: 0.0737355\tvalid_1's rmse: 0.0776147\n",
      "[2150]\ttraining's rmse: 0.0737333\tvalid_1's rmse: 0.0776143\n",
      "[2175]\ttraining's rmse: 0.0737319\tvalid_1's rmse: 0.0776136\n",
      "[2200]\ttraining's rmse: 0.0737292\tvalid_1's rmse: 0.077613\n",
      "[2225]\ttraining's rmse: 0.0737275\tvalid_1's rmse: 0.0776129\n",
      "[2250]\ttraining's rmse: 0.0737259\tvalid_1's rmse: 0.0776117\n",
      "[2275]\ttraining's rmse: 0.0737236\tvalid_1's rmse: 0.0776112\n",
      "[2300]\ttraining's rmse: 0.0737203\tvalid_1's rmse: 0.0776107\n",
      "[2325]\ttraining's rmse: 0.0737171\tvalid_1's rmse: 0.0776102\n",
      "[2350]\ttraining's rmse: 0.0737151\tvalid_1's rmse: 0.0776096\n",
      "[2375]\ttraining's rmse: 0.0737129\tvalid_1's rmse: 0.0776087\n",
      "[2400]\ttraining's rmse: 0.0737102\tvalid_1's rmse: 0.0776081\n",
      "[2425]\ttraining's rmse: 0.0737074\tvalid_1's rmse: 0.077608\n",
      "[2450]\ttraining's rmse: 0.0737062\tvalid_1's rmse: 0.0776075\n",
      "[2475]\ttraining's rmse: 0.0737034\tvalid_1's rmse: 0.0776069\n",
      "[2500]\ttraining's rmse: 0.0737025\tvalid_1's rmse: 0.0776067\n",
      "[2525]\ttraining's rmse: 0.0736999\tvalid_1's rmse: 0.0776058\n",
      "[2550]\ttraining's rmse: 0.0736974\tvalid_1's rmse: 0.0776052\n",
      "[2575]\ttraining's rmse: 0.0736955\tvalid_1's rmse: 0.0776044\n",
      "[2600]\ttraining's rmse: 0.0736946\tvalid_1's rmse: 0.0776044\n",
      "[2625]\ttraining's rmse: 0.0736937\tvalid_1's rmse: 0.0776043\n",
      "[2650]\ttraining's rmse: 0.0736926\tvalid_1's rmse: 0.0776041\n",
      "[2675]\ttraining's rmse: 0.0736916\tvalid_1's rmse: 0.077604\n",
      "Early stopping, best iteration is:\n",
      "[2635]\ttraining's rmse: 0.0736934\tvalid_1's rmse: 0.0776039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0764565\tvalid_1's rmse: 0.077577\n",
      "[50]\ttraining's rmse: 0.0763599\tvalid_1's rmse: 0.0775256\n",
      "[75]\ttraining's rmse: 0.076259\tvalid_1's rmse: 0.0774752\n",
      "[100]\ttraining's rmse: 0.0761675\tvalid_1's rmse: 0.0774306\n",
      "[125]\ttraining's rmse: 0.0760747\tvalid_1's rmse: 0.0773852\n",
      "[150]\ttraining's rmse: 0.0759898\tvalid_1's rmse: 0.0773447\n",
      "[175]\ttraining's rmse: 0.0759184\tvalid_1's rmse: 0.0773096\n",
      "[200]\ttraining's rmse: 0.0758413\tvalid_1's rmse: 0.0772757\n",
      "[225]\ttraining's rmse: 0.0757672\tvalid_1's rmse: 0.0772435\n",
      "[250]\ttraining's rmse: 0.0757048\tvalid_1's rmse: 0.0772145\n",
      "[275]\ttraining's rmse: 0.0756445\tvalid_1's rmse: 0.0771866\n",
      "[300]\ttraining's rmse: 0.0755844\tvalid_1's rmse: 0.0771607\n",
      "[325]\ttraining's rmse: 0.0755233\tvalid_1's rmse: 0.0771363\n",
      "[350]\ttraining's rmse: 0.0754661\tvalid_1's rmse: 0.077113\n",
      "[375]\ttraining's rmse: 0.0754199\tvalid_1's rmse: 0.0770933\n",
      "[400]\ttraining's rmse: 0.0753665\tvalid_1's rmse: 0.0770737\n",
      "[425]\ttraining's rmse: 0.0753181\tvalid_1's rmse: 0.0770544\n",
      "[450]\ttraining's rmse: 0.075274\tvalid_1's rmse: 0.0770366\n",
      "[475]\ttraining's rmse: 0.075233\tvalid_1's rmse: 0.0770197\n",
      "[500]\ttraining's rmse: 0.0751984\tvalid_1's rmse: 0.0770042\n",
      "[525]\ttraining's rmse: 0.0751543\tvalid_1's rmse: 0.0769882\n",
      "[550]\ttraining's rmse: 0.0751117\tvalid_1's rmse: 0.0769733\n",
      "[575]\ttraining's rmse: 0.075073\tvalid_1's rmse: 0.0769603\n",
      "[600]\ttraining's rmse: 0.0750345\tvalid_1's rmse: 0.0769477\n",
      "[625]\ttraining's rmse: 0.0750067\tvalid_1's rmse: 0.0769366\n",
      "[650]\ttraining's rmse: 0.0749722\tvalid_1's rmse: 0.076925\n",
      "[675]\ttraining's rmse: 0.0749376\tvalid_1's rmse: 0.0769142\n",
      "[700]\ttraining's rmse: 0.0749071\tvalid_1's rmse: 0.0769033\n",
      "[725]\ttraining's rmse: 0.0748761\tvalid_1's rmse: 0.0768943\n",
      "[750]\ttraining's rmse: 0.0748482\tvalid_1's rmse: 0.0768855\n",
      "[775]\ttraining's rmse: 0.0748246\tvalid_1's rmse: 0.0768775\n",
      "[800]\ttraining's rmse: 0.0747968\tvalid_1's rmse: 0.0768698\n",
      "[825]\ttraining's rmse: 0.0747734\tvalid_1's rmse: 0.0768619\n",
      "[850]\ttraining's rmse: 0.0747496\tvalid_1's rmse: 0.0768558\n",
      "[875]\ttraining's rmse: 0.0747285\tvalid_1's rmse: 0.0768497\n",
      "[900]\ttraining's rmse: 0.0747043\tvalid_1's rmse: 0.0768425\n",
      "[925]\ttraining's rmse: 0.0746822\tvalid_1's rmse: 0.0768364\n",
      "[950]\ttraining's rmse: 0.0746632\tvalid_1's rmse: 0.0768312\n",
      "[975]\ttraining's rmse: 0.0746444\tvalid_1's rmse: 0.0768264\n",
      "[1000]\ttraining's rmse: 0.0746262\tvalid_1's rmse: 0.0768211\n",
      "[1025]\ttraining's rmse: 0.0746061\tvalid_1's rmse: 0.0768171\n",
      "[1050]\ttraining's rmse: 0.0745887\tvalid_1's rmse: 0.0768125\n",
      "[1075]\ttraining's rmse: 0.0745705\tvalid_1's rmse: 0.0768087\n",
      "[1100]\ttraining's rmse: 0.074557\tvalid_1's rmse: 0.0768049\n",
      "[1125]\ttraining's rmse: 0.0745421\tvalid_1's rmse: 0.076801\n",
      "[1150]\ttraining's rmse: 0.0745265\tvalid_1's rmse: 0.0767974\n",
      "[1175]\ttraining's rmse: 0.074513\tvalid_1's rmse: 0.0767946\n",
      "[1200]\ttraining's rmse: 0.0744991\tvalid_1's rmse: 0.0767909\n",
      "[1225]\ttraining's rmse: 0.0744851\tvalid_1's rmse: 0.076787\n",
      "[1250]\ttraining's rmse: 0.0744754\tvalid_1's rmse: 0.0767846\n",
      "[1275]\ttraining's rmse: 0.074461\tvalid_1's rmse: 0.0767822\n",
      "[1300]\ttraining's rmse: 0.0744504\tvalid_1's rmse: 0.0767796\n",
      "[1325]\ttraining's rmse: 0.0744383\tvalid_1's rmse: 0.0767769\n",
      "[1350]\ttraining's rmse: 0.0744276\tvalid_1's rmse: 0.0767744\n",
      "[1375]\ttraining's rmse: 0.0744164\tvalid_1's rmse: 0.0767717\n",
      "[1400]\ttraining's rmse: 0.0744081\tvalid_1's rmse: 0.0767695\n",
      "[1425]\ttraining's rmse: 0.0743975\tvalid_1's rmse: 0.076768\n",
      "[1450]\ttraining's rmse: 0.0743875\tvalid_1's rmse: 0.0767668\n",
      "[1475]\ttraining's rmse: 0.0743781\tvalid_1's rmse: 0.0767649\n",
      "[1500]\ttraining's rmse: 0.0743705\tvalid_1's rmse: 0.0767635\n",
      "[1525]\ttraining's rmse: 0.0743618\tvalid_1's rmse: 0.076762\n",
      "[1550]\ttraining's rmse: 0.0743526\tvalid_1's rmse: 0.0767604\n",
      "[1575]\ttraining's rmse: 0.0743466\tvalid_1's rmse: 0.0767584\n",
      "[1600]\ttraining's rmse: 0.0743409\tvalid_1's rmse: 0.0767572\n",
      "[1625]\ttraining's rmse: 0.0743344\tvalid_1's rmse: 0.0767556\n",
      "[1650]\ttraining's rmse: 0.0743294\tvalid_1's rmse: 0.0767545\n",
      "[1675]\ttraining's rmse: 0.0743255\tvalid_1's rmse: 0.0767535\n",
      "[1700]\ttraining's rmse: 0.0743202\tvalid_1's rmse: 0.0767522\n",
      "[1725]\ttraining's rmse: 0.0743138\tvalid_1's rmse: 0.0767511\n",
      "[1750]\ttraining's rmse: 0.0743077\tvalid_1's rmse: 0.0767503\n",
      "[1775]\ttraining's rmse: 0.0743034\tvalid_1's rmse: 0.0767493\n",
      "[1800]\ttraining's rmse: 0.0742988\tvalid_1's rmse: 0.0767485\n",
      "[1825]\ttraining's rmse: 0.0742952\tvalid_1's rmse: 0.0767479\n",
      "[1850]\ttraining's rmse: 0.0742906\tvalid_1's rmse: 0.0767469\n",
      "[1875]\ttraining's rmse: 0.0742865\tvalid_1's rmse: 0.0767463\n",
      "[1900]\ttraining's rmse: 0.0742825\tvalid_1's rmse: 0.076746\n",
      "[1925]\ttraining's rmse: 0.0742793\tvalid_1's rmse: 0.0767455\n",
      "[1950]\ttraining's rmse: 0.0742764\tvalid_1's rmse: 0.0767449\n",
      "[1975]\ttraining's rmse: 0.0742735\tvalid_1's rmse: 0.076744\n",
      "[2000]\ttraining's rmse: 0.0742699\tvalid_1's rmse: 0.0767434\n",
      "[2025]\ttraining's rmse: 0.0742674\tvalid_1's rmse: 0.0767431\n",
      "[2050]\ttraining's rmse: 0.0742644\tvalid_1's rmse: 0.0767424\n",
      "[2075]\ttraining's rmse: 0.0742623\tvalid_1's rmse: 0.0767419\n",
      "[2100]\ttraining's rmse: 0.07426\tvalid_1's rmse: 0.0767417\n",
      "[2125]\ttraining's rmse: 0.0742563\tvalid_1's rmse: 0.0767415\n",
      "[2150]\ttraining's rmse: 0.0742511\tvalid_1's rmse: 0.0767411\n",
      "[2175]\ttraining's rmse: 0.074249\tvalid_1's rmse: 0.0767407\n",
      "[2200]\ttraining's rmse: 0.0742473\tvalid_1's rmse: 0.0767409\n",
      "[2225]\ttraining's rmse: 0.0742451\tvalid_1's rmse: 0.0767407\n",
      "[2250]\ttraining's rmse: 0.0742436\tvalid_1's rmse: 0.0767409\n",
      "Early stopping, best iteration is:\n",
      "[2213]\ttraining's rmse: 0.074246\tvalid_1's rmse: 0.0767407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0778954\tvalid_1's rmse: 0.0746346\n",
      "[50]\ttraining's rmse: 0.0777998\tvalid_1's rmse: 0.0745887\n",
      "[75]\ttraining's rmse: 0.0777\tvalid_1's rmse: 0.074545\n",
      "[100]\ttraining's rmse: 0.0776121\tvalid_1's rmse: 0.074507\n",
      "[125]\ttraining's rmse: 0.0775202\tvalid_1's rmse: 0.0744685\n",
      "[150]\ttraining's rmse: 0.077434\tvalid_1's rmse: 0.0744326\n",
      "[175]\ttraining's rmse: 0.0773637\tvalid_1's rmse: 0.0744023\n",
      "[200]\ttraining's rmse: 0.0772885\tvalid_1's rmse: 0.0743766\n",
      "[225]\ttraining's rmse: 0.0772137\tvalid_1's rmse: 0.0743486\n",
      "[250]\ttraining's rmse: 0.0771529\tvalid_1's rmse: 0.0743242\n",
      "[275]\ttraining's rmse: 0.0770943\tvalid_1's rmse: 0.0743001\n",
      "[300]\ttraining's rmse: 0.0770358\tvalid_1's rmse: 0.0742776\n",
      "[325]\ttraining's rmse: 0.0769786\tvalid_1's rmse: 0.0742575\n",
      "[350]\ttraining's rmse: 0.0769201\tvalid_1's rmse: 0.0742375\n",
      "[375]\ttraining's rmse: 0.0768747\tvalid_1's rmse: 0.0742224\n",
      "[400]\ttraining's rmse: 0.0768244\tvalid_1's rmse: 0.0742108\n",
      "[425]\ttraining's rmse: 0.0767785\tvalid_1's rmse: 0.0741995\n",
      "[450]\ttraining's rmse: 0.0767353\tvalid_1's rmse: 0.0741833\n",
      "[475]\ttraining's rmse: 0.0766949\tvalid_1's rmse: 0.0741754\n",
      "[500]\ttraining's rmse: 0.0766621\tvalid_1's rmse: 0.0741618\n",
      "[525]\ttraining's rmse: 0.0766169\tvalid_1's rmse: 0.0741547\n",
      "[550]\ttraining's rmse: 0.0765765\tvalid_1's rmse: 0.0741417\n",
      "[575]\ttraining's rmse: 0.0765397\tvalid_1's rmse: 0.0741373\n",
      "[600]\ttraining's rmse: 0.0765044\tvalid_1's rmse: 0.0741378\n",
      "[625]\ttraining's rmse: 0.0764761\tvalid_1's rmse: 0.0741393\n",
      "Early stopping, best iteration is:\n",
      "[595]\ttraining's rmse: 0.0765117\tvalid_1's rmse: 0.0741348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.07841\tvalid_1's rmse: 0.0804062\n",
      "[50]\ttraining's rmse: 0.0782899\tvalid_1's rmse: 0.0803594\n",
      "[75]\ttraining's rmse: 0.078173\tvalid_1's rmse: 0.0803149\n",
      "[100]\ttraining's rmse: 0.0780666\tvalid_1's rmse: 0.080276\n",
      "[125]\ttraining's rmse: 0.0779569\tvalid_1's rmse: 0.080236\n",
      "[150]\ttraining's rmse: 0.0778577\tvalid_1's rmse: 0.0802001\n",
      "[175]\ttraining's rmse: 0.0777738\tvalid_1's rmse: 0.0801682\n",
      "[200]\ttraining's rmse: 0.0776856\tvalid_1's rmse: 0.0801375\n",
      "[225]\ttraining's rmse: 0.0775966\tvalid_1's rmse: 0.0801072\n",
      "[250]\ttraining's rmse: 0.0775233\tvalid_1's rmse: 0.0800792\n",
      "[275]\ttraining's rmse: 0.0774541\tvalid_1's rmse: 0.0800546\n",
      "[300]\ttraining's rmse: 0.0773855\tvalid_1's rmse: 0.080031\n",
      "[325]\ttraining's rmse: 0.0773195\tvalid_1's rmse: 0.0800085\n",
      "[350]\ttraining's rmse: 0.0772551\tvalid_1's rmse: 0.0799868\n",
      "[375]\ttraining's rmse: 0.0772015\tvalid_1's rmse: 0.0799694\n",
      "[400]\ttraining's rmse: 0.0771431\tvalid_1's rmse: 0.0799517\n",
      "[425]\ttraining's rmse: 0.0770894\tvalid_1's rmse: 0.0799358\n",
      "[450]\ttraining's rmse: 0.0770408\tvalid_1's rmse: 0.0799201\n",
      "[475]\ttraining's rmse: 0.0769967\tvalid_1's rmse: 0.0799068\n",
      "[500]\ttraining's rmse: 0.0769593\tvalid_1's rmse: 0.0798935\n",
      "[525]\ttraining's rmse: 0.0769089\tvalid_1's rmse: 0.0798792\n",
      "[550]\ttraining's rmse: 0.0768628\tvalid_1's rmse: 0.0798666\n",
      "[575]\ttraining's rmse: 0.0768211\tvalid_1's rmse: 0.0798556\n",
      "[600]\ttraining's rmse: 0.0767832\tvalid_1's rmse: 0.0798451\n",
      "[625]\ttraining's rmse: 0.0767528\tvalid_1's rmse: 0.0798359\n",
      "[650]\ttraining's rmse: 0.0767164\tvalid_1's rmse: 0.0798253\n",
      "[675]\ttraining's rmse: 0.0766794\tvalid_1's rmse: 0.0798162\n",
      "[700]\ttraining's rmse: 0.0766467\tvalid_1's rmse: 0.0798075\n",
      "[725]\ttraining's rmse: 0.0766125\tvalid_1's rmse: 0.0797998\n",
      "[750]\ttraining's rmse: 0.0765835\tvalid_1's rmse: 0.0797926\n",
      "[775]\ttraining's rmse: 0.0765621\tvalid_1's rmse: 0.0797861\n",
      "[800]\ttraining's rmse: 0.0765322\tvalid_1's rmse: 0.07978\n",
      "[825]\ttraining's rmse: 0.0765068\tvalid_1's rmse: 0.0797725\n",
      "[850]\ttraining's rmse: 0.0764796\tvalid_1's rmse: 0.0797667\n",
      "[875]\ttraining's rmse: 0.0764563\tvalid_1's rmse: 0.0797608\n",
      "[900]\ttraining's rmse: 0.07643\tvalid_1's rmse: 0.0797555\n",
      "[925]\ttraining's rmse: 0.0764062\tvalid_1's rmse: 0.0797498\n",
      "[950]\ttraining's rmse: 0.0763849\tvalid_1's rmse: 0.0797446\n",
      "[975]\ttraining's rmse: 0.0763637\tvalid_1's rmse: 0.0797389\n",
      "[1000]\ttraining's rmse: 0.0763441\tvalid_1's rmse: 0.0797337\n",
      "[1025]\ttraining's rmse: 0.0763244\tvalid_1's rmse: 0.0797284\n",
      "[1050]\ttraining's rmse: 0.0763091\tvalid_1's rmse: 0.0797239\n",
      "[1075]\ttraining's rmse: 0.0762928\tvalid_1's rmse: 0.0797208\n",
      "[1100]\ttraining's rmse: 0.0762775\tvalid_1's rmse: 0.079717\n",
      "[1125]\ttraining's rmse: 0.076262\tvalid_1's rmse: 0.0797137\n",
      "[1150]\ttraining's rmse: 0.0762458\tvalid_1's rmse: 0.0797099\n",
      "[1175]\ttraining's rmse: 0.07623\tvalid_1's rmse: 0.0797071\n",
      "[1200]\ttraining's rmse: 0.0762155\tvalid_1's rmse: 0.0797029\n",
      "[1225]\ttraining's rmse: 0.0762016\tvalid_1's rmse: 0.079699\n",
      "[1250]\ttraining's rmse: 0.0761885\tvalid_1's rmse: 0.0796964\n",
      "[1275]\ttraining's rmse: 0.0761732\tvalid_1's rmse: 0.0796951\n",
      "[1300]\ttraining's rmse: 0.0761631\tvalid_1's rmse: 0.0796929\n",
      "[1325]\ttraining's rmse: 0.076152\tvalid_1's rmse: 0.0796907\n",
      "[1350]\ttraining's rmse: 0.0761399\tvalid_1's rmse: 0.079688\n",
      "[1375]\ttraining's rmse: 0.076128\tvalid_1's rmse: 0.0796861\n",
      "[1400]\ttraining's rmse: 0.076118\tvalid_1's rmse: 0.0796833\n",
      "[1425]\ttraining's rmse: 0.076107\tvalid_1's rmse: 0.0796811\n",
      "[1450]\ttraining's rmse: 0.0760958\tvalid_1's rmse: 0.0796791\n",
      "[1475]\ttraining's rmse: 0.0760877\tvalid_1's rmse: 0.0796767\n",
      "[1500]\ttraining's rmse: 0.0760799\tvalid_1's rmse: 0.0796753\n",
      "[1525]\ttraining's rmse: 0.0760719\tvalid_1's rmse: 0.079673\n",
      "[1550]\ttraining's rmse: 0.0760636\tvalid_1's rmse: 0.0796711\n",
      "[1575]\ttraining's rmse: 0.0760583\tvalid_1's rmse: 0.0796695\n",
      "[1600]\ttraining's rmse: 0.076053\tvalid_1's rmse: 0.0796692\n",
      "[1625]\ttraining's rmse: 0.0760481\tvalid_1's rmse: 0.0796677\n",
      "[1650]\ttraining's rmse: 0.0760412\tvalid_1's rmse: 0.0796651\n",
      "[1675]\ttraining's rmse: 0.0760362\tvalid_1's rmse: 0.0796634\n",
      "[1700]\ttraining's rmse: 0.0760317\tvalid_1's rmse: 0.0796605\n",
      "[1725]\ttraining's rmse: 0.0760271\tvalid_1's rmse: 0.0796591\n",
      "[1750]\ttraining's rmse: 0.0760209\tvalid_1's rmse: 0.0796566\n",
      "[1775]\ttraining's rmse: 0.0760145\tvalid_1's rmse: 0.079656\n",
      "[1800]\ttraining's rmse: 0.0760076\tvalid_1's rmse: 0.0796553\n",
      "[1825]\ttraining's rmse: 0.0760033\tvalid_1's rmse: 0.079653\n",
      "[1850]\ttraining's rmse: 0.0759976\tvalid_1's rmse: 0.0796508\n",
      "[1875]\ttraining's rmse: 0.0759942\tvalid_1's rmse: 0.0796508\n",
      "[1900]\ttraining's rmse: 0.0759908\tvalid_1's rmse: 0.0796498\n",
      "[1925]\ttraining's rmse: 0.0759884\tvalid_1's rmse: 0.0796492\n",
      "[1950]\ttraining's rmse: 0.0759852\tvalid_1's rmse: 0.0796474\n",
      "[1975]\ttraining's rmse: 0.0759819\tvalid_1's rmse: 0.0796457\n",
      "[2000]\ttraining's rmse: 0.075978\tvalid_1's rmse: 0.0796441\n",
      "[2025]\ttraining's rmse: 0.0759753\tvalid_1's rmse: 0.0796423\n",
      "[2050]\ttraining's rmse: 0.0759712\tvalid_1's rmse: 0.0796418\n",
      "[2075]\ttraining's rmse: 0.0759684\tvalid_1's rmse: 0.0796415\n",
      "[2100]\ttraining's rmse: 0.0759656\tvalid_1's rmse: 0.0796406\n",
      "[2125]\ttraining's rmse: 0.075963\tvalid_1's rmse: 0.0796401\n",
      "[2150]\ttraining's rmse: 0.0759591\tvalid_1's rmse: 0.0796396\n",
      "[2175]\ttraining's rmse: 0.0759564\tvalid_1's rmse: 0.0796393\n",
      "[2200]\ttraining's rmse: 0.0759537\tvalid_1's rmse: 0.0796389\n",
      "[2225]\ttraining's rmse: 0.0759524\tvalid_1's rmse: 0.0796384\n",
      "[2250]\ttraining's rmse: 0.0759505\tvalid_1's rmse: 0.0796371\n",
      "[2275]\ttraining's rmse: 0.0759472\tvalid_1's rmse: 0.0796365\n",
      "[2300]\ttraining's rmse: 0.0759453\tvalid_1's rmse: 0.0796361\n",
      "[2325]\ttraining's rmse: 0.0759433\tvalid_1's rmse: 0.0796357\n",
      "[2350]\ttraining's rmse: 0.0759418\tvalid_1's rmse: 0.0796353\n",
      "[2375]\ttraining's rmse: 0.0759399\tvalid_1's rmse: 0.0796348\n",
      "[2400]\ttraining's rmse: 0.0759372\tvalid_1's rmse: 0.079635\n",
      "Early stopping, best iteration is:\n",
      "[2367]\ttraining's rmse: 0.0759402\tvalid_1's rmse: 0.0796348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0786212\tvalid_1's rmse: 0.0800178\n",
      "[50]\ttraining's rmse: 0.0785199\tvalid_1's rmse: 0.0799677\n",
      "[75]\ttraining's rmse: 0.0784148\tvalid_1's rmse: 0.0799191\n",
      "[100]\ttraining's rmse: 0.0783202\tvalid_1's rmse: 0.0798758\n",
      "[125]\ttraining's rmse: 0.0782208\tvalid_1's rmse: 0.0798316\n",
      "[150]\ttraining's rmse: 0.078132\tvalid_1's rmse: 0.0797912\n",
      "[175]\ttraining's rmse: 0.0780594\tvalid_1's rmse: 0.0797571\n",
      "[200]\ttraining's rmse: 0.0779767\tvalid_1's rmse: 0.0797215\n",
      "[225]\ttraining's rmse: 0.077898\tvalid_1's rmse: 0.079688\n",
      "[250]\ttraining's rmse: 0.0778321\tvalid_1's rmse: 0.0796578\n",
      "[275]\ttraining's rmse: 0.0777704\tvalid_1's rmse: 0.0796307\n",
      "[300]\ttraining's rmse: 0.0777105\tvalid_1's rmse: 0.079605\n",
      "[325]\ttraining's rmse: 0.0776441\tvalid_1's rmse: 0.0795791\n",
      "[350]\ttraining's rmse: 0.0775831\tvalid_1's rmse: 0.0795559\n",
      "[375]\ttraining's rmse: 0.0775335\tvalid_1's rmse: 0.0795363\n",
      "[400]\ttraining's rmse: 0.0774805\tvalid_1's rmse: 0.0795179\n",
      "[425]\ttraining's rmse: 0.0774316\tvalid_1's rmse: 0.0794987\n",
      "[450]\ttraining's rmse: 0.0773871\tvalid_1's rmse: 0.0794806\n",
      "[475]\ttraining's rmse: 0.0773457\tvalid_1's rmse: 0.0794643\n",
      "[500]\ttraining's rmse: 0.0773091\tvalid_1's rmse: 0.0794482\n",
      "[525]\ttraining's rmse: 0.077262\tvalid_1's rmse: 0.0794335\n",
      "[550]\ttraining's rmse: 0.0772184\tvalid_1's rmse: 0.0794189\n",
      "[575]\ttraining's rmse: 0.0771777\tvalid_1's rmse: 0.0794054\n",
      "[600]\ttraining's rmse: 0.0771402\tvalid_1's rmse: 0.0793936\n",
      "[625]\ttraining's rmse: 0.0771117\tvalid_1's rmse: 0.0793829\n",
      "[650]\ttraining's rmse: 0.0770755\tvalid_1's rmse: 0.0793702\n",
      "[675]\ttraining's rmse: 0.0770389\tvalid_1's rmse: 0.0793589\n",
      "[700]\ttraining's rmse: 0.0770064\tvalid_1's rmse: 0.0793486\n",
      "[725]\ttraining's rmse: 0.0769753\tvalid_1's rmse: 0.0793388\n",
      "[750]\ttraining's rmse: 0.0769458\tvalid_1's rmse: 0.0793293\n",
      "[775]\ttraining's rmse: 0.0769226\tvalid_1's rmse: 0.0793204\n",
      "[800]\ttraining's rmse: 0.0768914\tvalid_1's rmse: 0.0793122\n",
      "[825]\ttraining's rmse: 0.0768653\tvalid_1's rmse: 0.0793043\n",
      "[850]\ttraining's rmse: 0.0768382\tvalid_1's rmse: 0.0792971\n",
      "[875]\ttraining's rmse: 0.0768158\tvalid_1's rmse: 0.0792906\n",
      "[900]\ttraining's rmse: 0.076792\tvalid_1's rmse: 0.0792836\n",
      "[925]\ttraining's rmse: 0.0767685\tvalid_1's rmse: 0.0792776\n",
      "[950]\ttraining's rmse: 0.0767461\tvalid_1's rmse: 0.0792714\n",
      "[975]\ttraining's rmse: 0.0767263\tvalid_1's rmse: 0.0792659\n",
      "[1000]\ttraining's rmse: 0.0767068\tvalid_1's rmse: 0.0792609\n",
      "[1025]\ttraining's rmse: 0.0766864\tvalid_1's rmse: 0.0792561\n",
      "[1050]\ttraining's rmse: 0.0766671\tvalid_1's rmse: 0.0792513\n",
      "[1075]\ttraining's rmse: 0.0766484\tvalid_1's rmse: 0.0792473\n",
      "[1100]\ttraining's rmse: 0.0766348\tvalid_1's rmse: 0.0792431\n",
      "[1125]\ttraining's rmse: 0.0766178\tvalid_1's rmse: 0.0792387\n",
      "[1150]\ttraining's rmse: 0.0766024\tvalid_1's rmse: 0.0792353\n",
      "[1175]\ttraining's rmse: 0.0765879\tvalid_1's rmse: 0.0792318\n",
      "[1200]\ttraining's rmse: 0.0765728\tvalid_1's rmse: 0.0792285\n",
      "[1225]\ttraining's rmse: 0.0765599\tvalid_1's rmse: 0.0792256\n",
      "[1250]\ttraining's rmse: 0.0765465\tvalid_1's rmse: 0.079222\n",
      "[1275]\ttraining's rmse: 0.0765321\tvalid_1's rmse: 0.0792198\n",
      "[1300]\ttraining's rmse: 0.0765204\tvalid_1's rmse: 0.0792163\n",
      "[1325]\ttraining's rmse: 0.0765107\tvalid_1's rmse: 0.0792143\n",
      "[1350]\ttraining's rmse: 0.0764984\tvalid_1's rmse: 0.0792113\n",
      "[1375]\ttraining's rmse: 0.076487\tvalid_1's rmse: 0.0792092\n",
      "[1400]\ttraining's rmse: 0.0764772\tvalid_1's rmse: 0.0792067\n",
      "[1425]\ttraining's rmse: 0.0764666\tvalid_1's rmse: 0.079205\n",
      "[1450]\ttraining's rmse: 0.0764579\tvalid_1's rmse: 0.0792031\n",
      "[1475]\ttraining's rmse: 0.0764483\tvalid_1's rmse: 0.0792013\n",
      "[1500]\ttraining's rmse: 0.0764402\tvalid_1's rmse: 0.0791995\n",
      "[1525]\ttraining's rmse: 0.0764316\tvalid_1's rmse: 0.0791973\n",
      "[1550]\ttraining's rmse: 0.0764229\tvalid_1's rmse: 0.079196\n",
      "[1575]\ttraining's rmse: 0.0764166\tvalid_1's rmse: 0.0791945\n",
      "[1600]\ttraining's rmse: 0.0764102\tvalid_1's rmse: 0.0791935\n",
      "[1625]\ttraining's rmse: 0.0764047\tvalid_1's rmse: 0.0791926\n",
      "[1650]\ttraining's rmse: 0.0763987\tvalid_1's rmse: 0.0791918\n",
      "[1675]\ttraining's rmse: 0.0763937\tvalid_1's rmse: 0.0791906\n",
      "[1700]\ttraining's rmse: 0.0763894\tvalid_1's rmse: 0.0791894\n",
      "[1725]\ttraining's rmse: 0.0763838\tvalid_1's rmse: 0.0791886\n",
      "[1750]\ttraining's rmse: 0.0763798\tvalid_1's rmse: 0.0791882\n",
      "[1775]\ttraining's rmse: 0.0763733\tvalid_1's rmse: 0.0791876\n",
      "[1800]\ttraining's rmse: 0.076367\tvalid_1's rmse: 0.079187\n",
      "[1825]\ttraining's rmse: 0.0763612\tvalid_1's rmse: 0.0791864\n",
      "[1850]\ttraining's rmse: 0.0763574\tvalid_1's rmse: 0.0791852\n",
      "[1875]\ttraining's rmse: 0.0763543\tvalid_1's rmse: 0.0791852\n",
      "[1900]\ttraining's rmse: 0.0763507\tvalid_1's rmse: 0.0791848\n",
      "[1925]\ttraining's rmse: 0.076347\tvalid_1's rmse: 0.0791845\n",
      "[1950]\ttraining's rmse: 0.0763433\tvalid_1's rmse: 0.0791838\n",
      "[1975]\ttraining's rmse: 0.0763406\tvalid_1's rmse: 0.0791831\n",
      "[2000]\ttraining's rmse: 0.0763364\tvalid_1's rmse: 0.0791823\n",
      "[2025]\ttraining's rmse: 0.0763334\tvalid_1's rmse: 0.0791818\n",
      "[2050]\ttraining's rmse: 0.0763294\tvalid_1's rmse: 0.0791815\n",
      "[2075]\ttraining's rmse: 0.0763264\tvalid_1's rmse: 0.0791811\n",
      "[2100]\ttraining's rmse: 0.0763236\tvalid_1's rmse: 0.0791804\n",
      "[2125]\ttraining's rmse: 0.0763201\tvalid_1's rmse: 0.0791797\n",
      "[2150]\ttraining's rmse: 0.0763162\tvalid_1's rmse: 0.079179\n",
      "[2175]\ttraining's rmse: 0.0763146\tvalid_1's rmse: 0.0791791\n",
      "[2200]\ttraining's rmse: 0.0763119\tvalid_1's rmse: 0.0791789\n",
      "[2225]\ttraining's rmse: 0.0763091\tvalid_1's rmse: 0.0791787\n",
      "[2250]\ttraining's rmse: 0.076306\tvalid_1's rmse: 0.0791784\n",
      "[2275]\ttraining's rmse: 0.0763026\tvalid_1's rmse: 0.0791777\n",
      "[2300]\ttraining's rmse: 0.076301\tvalid_1's rmse: 0.0791777\n",
      "[2325]\ttraining's rmse: 0.0762986\tvalid_1's rmse: 0.0791773\n",
      "[2350]\ttraining's rmse: 0.0762967\tvalid_1's rmse: 0.079177\n",
      "[2375]\ttraining's rmse: 0.0762946\tvalid_1's rmse: 0.0791768\n",
      "[2400]\ttraining's rmse: 0.0762924\tvalid_1's rmse: 0.079177\n",
      "Early stopping, best iteration is:\n",
      "[2359]\ttraining's rmse: 0.0762958\tvalid_1's rmse: 0.0791767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0800989\tvalid_1's rmse: 0.0770067\n",
      "[50]\ttraining's rmse: 0.0799994\tvalid_1's rmse: 0.0769619\n",
      "[75]\ttraining's rmse: 0.0798968\tvalid_1's rmse: 0.0769167\n",
      "[100]\ttraining's rmse: 0.0798046\tvalid_1's rmse: 0.0768777\n",
      "[125]\ttraining's rmse: 0.0797093\tvalid_1's rmse: 0.0768384\n",
      "[150]\ttraining's rmse: 0.0796218\tvalid_1's rmse: 0.076801\n",
      "[175]\ttraining's rmse: 0.0795492\tvalid_1's rmse: 0.0767708\n",
      "[200]\ttraining's rmse: 0.0794681\tvalid_1's rmse: 0.0767387\n",
      "[225]\ttraining's rmse: 0.0793896\tvalid_1's rmse: 0.0767078\n",
      "[250]\ttraining's rmse: 0.0793248\tvalid_1's rmse: 0.0766806\n",
      "[275]\ttraining's rmse: 0.079265\tvalid_1's rmse: 0.0766565\n",
      "[300]\ttraining's rmse: 0.0792056\tvalid_1's rmse: 0.0766368\n",
      "[325]\ttraining's rmse: 0.0791459\tvalid_1's rmse: 0.076615\n",
      "[350]\ttraining's rmse: 0.079086\tvalid_1's rmse: 0.0765939\n",
      "[375]\ttraining's rmse: 0.0790383\tvalid_1's rmse: 0.076577\n",
      "[400]\ttraining's rmse: 0.0789872\tvalid_1's rmse: 0.0765634\n",
      "[425]\ttraining's rmse: 0.0789401\tvalid_1's rmse: 0.0765489\n",
      "[450]\ttraining's rmse: 0.0788979\tvalid_1's rmse: 0.0765349\n",
      "[475]\ttraining's rmse: 0.0788564\tvalid_1's rmse: 0.0765295\n",
      "[500]\ttraining's rmse: 0.0788224\tvalid_1's rmse: 0.0765172\n",
      "[525]\ttraining's rmse: 0.0787738\tvalid_1's rmse: 0.0765038\n",
      "[550]\ttraining's rmse: 0.0787335\tvalid_1's rmse: 0.0764917\n",
      "[575]\ttraining's rmse: 0.0786959\tvalid_1's rmse: 0.0764808\n",
      "[600]\ttraining's rmse: 0.0786575\tvalid_1's rmse: 0.0764713\n",
      "[625]\ttraining's rmse: 0.0786275\tvalid_1's rmse: 0.076463\n",
      "[650]\ttraining's rmse: 0.0785896\tvalid_1's rmse: 0.0764526\n",
      "[675]\ttraining's rmse: 0.0785518\tvalid_1's rmse: 0.0764456\n",
      "[700]\ttraining's rmse: 0.0785191\tvalid_1's rmse: 0.0764398\n",
      "[725]\ttraining's rmse: 0.0784875\tvalid_1's rmse: 0.0764446\n",
      "[750]\ttraining's rmse: 0.0784585\tvalid_1's rmse: 0.0764412\n",
      "[775]\ttraining's rmse: 0.0784341\tvalid_1's rmse: 0.0764385\n",
      "[800]\ttraining's rmse: 0.0784043\tvalid_1's rmse: 0.0764334\n",
      "[825]\ttraining's rmse: 0.078377\tvalid_1's rmse: 0.0764399\n",
      "[850]\ttraining's rmse: 0.0783504\tvalid_1's rmse: 0.0764349\n",
      "Early stopping, best iteration is:\n",
      "[804]\ttraining's rmse: 0.0783986\tvalid_1's rmse: 0.076433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0767154\tvalid_1's rmse: 0.0789755\n",
      "[50]\ttraining's rmse: 0.076609\tvalid_1's rmse: 0.078928\n",
      "[75]\ttraining's rmse: 0.0765\tvalid_1's rmse: 0.0788801\n",
      "[100]\ttraining's rmse: 0.0763995\tvalid_1's rmse: 0.0788399\n",
      "[125]\ttraining's rmse: 0.0762982\tvalid_1's rmse: 0.0787993\n",
      "[150]\ttraining's rmse: 0.0762053\tvalid_1's rmse: 0.0787604\n",
      "[175]\ttraining's rmse: 0.0761318\tvalid_1's rmse: 0.078727\n",
      "[200]\ttraining's rmse: 0.0760488\tvalid_1's rmse: 0.0786948\n",
      "[225]\ttraining's rmse: 0.0759687\tvalid_1's rmse: 0.078664\n",
      "[250]\ttraining's rmse: 0.0759025\tvalid_1's rmse: 0.0786366\n",
      "[275]\ttraining's rmse: 0.0758392\tvalid_1's rmse: 0.0786103\n",
      "[300]\ttraining's rmse: 0.0757761\tvalid_1's rmse: 0.078586\n",
      "[325]\ttraining's rmse: 0.0757125\tvalid_1's rmse: 0.0785623\n",
      "[350]\ttraining's rmse: 0.0756526\tvalid_1's rmse: 0.0785393\n",
      "[375]\ttraining's rmse: 0.0756016\tvalid_1's rmse: 0.0785195\n",
      "[400]\ttraining's rmse: 0.0755458\tvalid_1's rmse: 0.078501\n",
      "[425]\ttraining's rmse: 0.0754975\tvalid_1's rmse: 0.0784833\n",
      "[450]\ttraining's rmse: 0.0754508\tvalid_1's rmse: 0.0784639\n",
      "[475]\ttraining's rmse: 0.0754105\tvalid_1's rmse: 0.0784491\n",
      "[500]\ttraining's rmse: 0.0753752\tvalid_1's rmse: 0.0784347\n",
      "[525]\ttraining's rmse: 0.0753315\tvalid_1's rmse: 0.0784198\n",
      "[550]\ttraining's rmse: 0.0752894\tvalid_1's rmse: 0.0784065\n",
      "[575]\ttraining's rmse: 0.0752509\tvalid_1's rmse: 0.0783934\n",
      "[600]\ttraining's rmse: 0.0752155\tvalid_1's rmse: 0.0783817\n",
      "[625]\ttraining's rmse: 0.0751882\tvalid_1's rmse: 0.0783702\n",
      "[650]\ttraining's rmse: 0.0751529\tvalid_1's rmse: 0.0783598\n",
      "[675]\ttraining's rmse: 0.0751174\tvalid_1's rmse: 0.0783489\n",
      "[700]\ttraining's rmse: 0.0750902\tvalid_1's rmse: 0.078339\n",
      "[725]\ttraining's rmse: 0.0750573\tvalid_1's rmse: 0.078329\n",
      "[750]\ttraining's rmse: 0.075029\tvalid_1's rmse: 0.0783201\n",
      "[775]\ttraining's rmse: 0.0750089\tvalid_1's rmse: 0.078311\n",
      "[800]\ttraining's rmse: 0.0749816\tvalid_1's rmse: 0.0783044\n",
      "[825]\ttraining's rmse: 0.0749568\tvalid_1's rmse: 0.0782965\n",
      "[850]\ttraining's rmse: 0.0749314\tvalid_1's rmse: 0.0782898\n",
      "[875]\ttraining's rmse: 0.0749088\tvalid_1's rmse: 0.0782834\n",
      "[900]\ttraining's rmse: 0.0748835\tvalid_1's rmse: 0.0782767\n",
      "[925]\ttraining's rmse: 0.0748646\tvalid_1's rmse: 0.0782718\n",
      "[950]\ttraining's rmse: 0.0748459\tvalid_1's rmse: 0.0782659\n",
      "[975]\ttraining's rmse: 0.0748265\tvalid_1's rmse: 0.0782598\n",
      "[1000]\ttraining's rmse: 0.0748054\tvalid_1's rmse: 0.0782551\n",
      "[1025]\ttraining's rmse: 0.0747871\tvalid_1's rmse: 0.0782491\n",
      "[1050]\ttraining's rmse: 0.0747694\tvalid_1's rmse: 0.0782437\n",
      "[1075]\ttraining's rmse: 0.0747532\tvalid_1's rmse: 0.0782405\n",
      "[1100]\ttraining's rmse: 0.0747384\tvalid_1's rmse: 0.0782361\n",
      "[1125]\ttraining's rmse: 0.0747252\tvalid_1's rmse: 0.0782332\n",
      "[1150]\ttraining's rmse: 0.0747102\tvalid_1's rmse: 0.0782293\n",
      "[1175]\ttraining's rmse: 0.0746951\tvalid_1's rmse: 0.0782267\n",
      "[1200]\ttraining's rmse: 0.0746833\tvalid_1's rmse: 0.0782214\n",
      "[1225]\ttraining's rmse: 0.0746717\tvalid_1's rmse: 0.0782176\n",
      "[1250]\ttraining's rmse: 0.0746594\tvalid_1's rmse: 0.0782136\n",
      "[1275]\ttraining's rmse: 0.0746444\tvalid_1's rmse: 0.0782096\n",
      "[1300]\ttraining's rmse: 0.0746357\tvalid_1's rmse: 0.0782051\n",
      "[1325]\ttraining's rmse: 0.0746257\tvalid_1's rmse: 0.0782031\n",
      "[1350]\ttraining's rmse: 0.0746134\tvalid_1's rmse: 0.0782002\n",
      "[1375]\ttraining's rmse: 0.0746039\tvalid_1's rmse: 0.0781981\n",
      "[1400]\ttraining's rmse: 0.0745941\tvalid_1's rmse: 0.0781939\n",
      "[1425]\ttraining's rmse: 0.074586\tvalid_1's rmse: 0.0781921\n",
      "[1450]\ttraining's rmse: 0.0745785\tvalid_1's rmse: 0.0781893\n",
      "[1475]\ttraining's rmse: 0.0745711\tvalid_1's rmse: 0.078186\n",
      "[1500]\ttraining's rmse: 0.0745653\tvalid_1's rmse: 0.0781827\n",
      "[1525]\ttraining's rmse: 0.0745573\tvalid_1's rmse: 0.0781809\n",
      "[1550]\ttraining's rmse: 0.0745505\tvalid_1's rmse: 0.0781792\n",
      "[1575]\ttraining's rmse: 0.0745436\tvalid_1's rmse: 0.0781783\n",
      "[1600]\ttraining's rmse: 0.0745364\tvalid_1's rmse: 0.0781764\n",
      "[1625]\ttraining's rmse: 0.074532\tvalid_1's rmse: 0.0781742\n",
      "[1650]\ttraining's rmse: 0.0745259\tvalid_1's rmse: 0.078173\n",
      "[1675]\ttraining's rmse: 0.0745215\tvalid_1's rmse: 0.0781711\n",
      "[1700]\ttraining's rmse: 0.0745172\tvalid_1's rmse: 0.078169\n",
      "[1725]\ttraining's rmse: 0.0745127\tvalid_1's rmse: 0.0781684\n",
      "[1750]\ttraining's rmse: 0.0745065\tvalid_1's rmse: 0.0781659\n",
      "[1775]\ttraining's rmse: 0.0744997\tvalid_1's rmse: 0.0781649\n",
      "[1800]\ttraining's rmse: 0.0744965\tvalid_1's rmse: 0.0781631\n",
      "[1825]\ttraining's rmse: 0.0744913\tvalid_1's rmse: 0.0781617\n",
      "[1850]\ttraining's rmse: 0.0744885\tvalid_1's rmse: 0.0781602\n",
      "[1875]\ttraining's rmse: 0.0744837\tvalid_1's rmse: 0.07816\n",
      "[1900]\ttraining's rmse: 0.0744811\tvalid_1's rmse: 0.0781583\n",
      "[1925]\ttraining's rmse: 0.0744781\tvalid_1's rmse: 0.0781578\n",
      "[1950]\ttraining's rmse: 0.0744741\tvalid_1's rmse: 0.0781564\n",
      "[1975]\ttraining's rmse: 0.0744712\tvalid_1's rmse: 0.0781554\n",
      "[2000]\ttraining's rmse: 0.0744675\tvalid_1's rmse: 0.0781541\n",
      "[2025]\ttraining's rmse: 0.0744648\tvalid_1's rmse: 0.0781526\n",
      "[2050]\ttraining's rmse: 0.0744615\tvalid_1's rmse: 0.0781522\n",
      "[2075]\ttraining's rmse: 0.0744597\tvalid_1's rmse: 0.0781515\n",
      "[2100]\ttraining's rmse: 0.0744572\tvalid_1's rmse: 0.0781511\n",
      "[2125]\ttraining's rmse: 0.0744543\tvalid_1's rmse: 0.0781513\n",
      "[2150]\ttraining's rmse: 0.0744504\tvalid_1's rmse: 0.078151\n",
      "[2175]\ttraining's rmse: 0.0744468\tvalid_1's rmse: 0.0781511\n",
      "[2200]\ttraining's rmse: 0.0744446\tvalid_1's rmse: 0.0781505\n",
      "[2225]\ttraining's rmse: 0.0744424\tvalid_1's rmse: 0.07815\n",
      "[2250]\ttraining's rmse: 0.0744402\tvalid_1's rmse: 0.0781496\n",
      "[2275]\ttraining's rmse: 0.0744383\tvalid_1's rmse: 0.0781481\n",
      "[2300]\ttraining's rmse: 0.0744369\tvalid_1's rmse: 0.0781471\n",
      "[2325]\ttraining's rmse: 0.0744349\tvalid_1's rmse: 0.0781463\n",
      "[2350]\ttraining's rmse: 0.0744331\tvalid_1's rmse: 0.078146\n",
      "[2375]\ttraining's rmse: 0.07443\tvalid_1's rmse: 0.0781456\n",
      "[2400]\ttraining's rmse: 0.0744273\tvalid_1's rmse: 0.0781456\n",
      "[2425]\ttraining's rmse: 0.0744245\tvalid_1's rmse: 0.0781456\n",
      "Early stopping, best iteration is:\n",
      "[2384]\ttraining's rmse: 0.0744295\tvalid_1's rmse: 0.0781453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0769549\tvalid_1's rmse: 0.0785148\n",
      "[50]\ttraining's rmse: 0.0768551\tvalid_1's rmse: 0.078464\n",
      "[75]\ttraining's rmse: 0.0767528\tvalid_1's rmse: 0.0784134\n",
      "[100]\ttraining's rmse: 0.0766601\tvalid_1's rmse: 0.0783677\n",
      "[125]\ttraining's rmse: 0.076565\tvalid_1's rmse: 0.0783231\n",
      "[150]\ttraining's rmse: 0.0764787\tvalid_1's rmse: 0.0782821\n",
      "[175]\ttraining's rmse: 0.076409\tvalid_1's rmse: 0.0782487\n",
      "[200]\ttraining's rmse: 0.0763293\tvalid_1's rmse: 0.0782135\n",
      "[225]\ttraining's rmse: 0.0762548\tvalid_1's rmse: 0.0781805\n",
      "[250]\ttraining's rmse: 0.0761907\tvalid_1's rmse: 0.0781517\n",
      "[275]\ttraining's rmse: 0.0761305\tvalid_1's rmse: 0.0781245\n",
      "[300]\ttraining's rmse: 0.0760706\tvalid_1's rmse: 0.0780998\n",
      "[325]\ttraining's rmse: 0.0760104\tvalid_1's rmse: 0.0780741\n",
      "[350]\ttraining's rmse: 0.0759517\tvalid_1's rmse: 0.0780517\n",
      "[375]\ttraining's rmse: 0.0759036\tvalid_1's rmse: 0.0780315\n",
      "[400]\ttraining's rmse: 0.0758516\tvalid_1's rmse: 0.0780118\n",
      "[425]\ttraining's rmse: 0.0758041\tvalid_1's rmse: 0.0779934\n",
      "[450]\ttraining's rmse: 0.0757576\tvalid_1's rmse: 0.0779749\n",
      "[475]\ttraining's rmse: 0.0757167\tvalid_1's rmse: 0.0779589\n",
      "[500]\ttraining's rmse: 0.0756809\tvalid_1's rmse: 0.0779434\n",
      "[525]\ttraining's rmse: 0.0756384\tvalid_1's rmse: 0.0779292\n",
      "[550]\ttraining's rmse: 0.0755977\tvalid_1's rmse: 0.0779149\n",
      "[575]\ttraining's rmse: 0.0755607\tvalid_1's rmse: 0.0779019\n",
      "[600]\ttraining's rmse: 0.0755245\tvalid_1's rmse: 0.0778898\n",
      "[625]\ttraining's rmse: 0.0754975\tvalid_1's rmse: 0.0778788\n",
      "[650]\ttraining's rmse: 0.075462\tvalid_1's rmse: 0.0778681\n",
      "[675]\ttraining's rmse: 0.0754231\tvalid_1's rmse: 0.0778567\n",
      "[700]\ttraining's rmse: 0.0753925\tvalid_1's rmse: 0.0778467\n",
      "[725]\ttraining's rmse: 0.0753639\tvalid_1's rmse: 0.0778379\n",
      "[750]\ttraining's rmse: 0.0753351\tvalid_1's rmse: 0.0778298\n",
      "[775]\ttraining's rmse: 0.075311\tvalid_1's rmse: 0.0778214\n",
      "[800]\ttraining's rmse: 0.0752812\tvalid_1's rmse: 0.077814\n",
      "[825]\ttraining's rmse: 0.0752567\tvalid_1's rmse: 0.077806\n",
      "[850]\ttraining's rmse: 0.075233\tvalid_1's rmse: 0.0777999\n",
      "[875]\ttraining's rmse: 0.0752092\tvalid_1's rmse: 0.0777931\n",
      "[900]\ttraining's rmse: 0.0751851\tvalid_1's rmse: 0.0777869\n",
      "[925]\ttraining's rmse: 0.0751626\tvalid_1's rmse: 0.0777811\n",
      "[950]\ttraining's rmse: 0.0751414\tvalid_1's rmse: 0.0777752\n",
      "[975]\ttraining's rmse: 0.0751217\tvalid_1's rmse: 0.07777\n",
      "[1000]\ttraining's rmse: 0.0751016\tvalid_1's rmse: 0.0777647\n",
      "[1025]\ttraining's rmse: 0.0750806\tvalid_1's rmse: 0.0777607\n",
      "[1050]\ttraining's rmse: 0.0750627\tvalid_1's rmse: 0.0777558\n",
      "[1075]\ttraining's rmse: 0.0750446\tvalid_1's rmse: 0.0777516\n",
      "[1100]\ttraining's rmse: 0.0750323\tvalid_1's rmse: 0.0777479\n",
      "[1125]\ttraining's rmse: 0.0750171\tvalid_1's rmse: 0.0777443\n",
      "[1150]\ttraining's rmse: 0.0750032\tvalid_1's rmse: 0.0777417\n",
      "[1175]\ttraining's rmse: 0.0749881\tvalid_1's rmse: 0.0777392\n",
      "[1200]\ttraining's rmse: 0.0749721\tvalid_1's rmse: 0.0777364\n",
      "[1225]\ttraining's rmse: 0.0749592\tvalid_1's rmse: 0.0777332\n",
      "[1250]\ttraining's rmse: 0.0749485\tvalid_1's rmse: 0.0777302\n",
      "[1275]\ttraining's rmse: 0.0749335\tvalid_1's rmse: 0.0777276\n",
      "[1300]\ttraining's rmse: 0.0749238\tvalid_1's rmse: 0.0777252\n",
      "[1325]\ttraining's rmse: 0.0749132\tvalid_1's rmse: 0.0777232\n",
      "[1350]\ttraining's rmse: 0.074902\tvalid_1's rmse: 0.077721\n",
      "[1375]\ttraining's rmse: 0.0748917\tvalid_1's rmse: 0.0777187\n",
      "[1400]\ttraining's rmse: 0.0748835\tvalid_1's rmse: 0.0777162\n",
      "[1425]\ttraining's rmse: 0.0748734\tvalid_1's rmse: 0.0777141\n",
      "[1450]\ttraining's rmse: 0.0748627\tvalid_1's rmse: 0.0777127\n",
      "[1475]\ttraining's rmse: 0.0748557\tvalid_1's rmse: 0.0777109\n",
      "[1500]\ttraining's rmse: 0.0748484\tvalid_1's rmse: 0.0777095\n",
      "[1525]\ttraining's rmse: 0.0748416\tvalid_1's rmse: 0.077708\n",
      "[1550]\ttraining's rmse: 0.0748332\tvalid_1's rmse: 0.0777068\n",
      "[1575]\ttraining's rmse: 0.0748263\tvalid_1's rmse: 0.0777055\n",
      "[1600]\ttraining's rmse: 0.0748192\tvalid_1's rmse: 0.0777045\n",
      "[1625]\ttraining's rmse: 0.0748129\tvalid_1's rmse: 0.0777035\n",
      "[1650]\ttraining's rmse: 0.0748078\tvalid_1's rmse: 0.0777027\n",
      "[1675]\ttraining's rmse: 0.0748029\tvalid_1's rmse: 0.0777013\n",
      "[1700]\ttraining's rmse: 0.0747973\tvalid_1's rmse: 0.0777001\n",
      "[1725]\ttraining's rmse: 0.0747918\tvalid_1's rmse: 0.0776991\n",
      "[1750]\ttraining's rmse: 0.0747847\tvalid_1's rmse: 0.0776981\n",
      "[1775]\ttraining's rmse: 0.0747797\tvalid_1's rmse: 0.0776973\n",
      "[1800]\ttraining's rmse: 0.0747753\tvalid_1's rmse: 0.0776966\n",
      "[1825]\ttraining's rmse: 0.0747706\tvalid_1's rmse: 0.077696\n",
      "[1850]\ttraining's rmse: 0.0747667\tvalid_1's rmse: 0.077695\n",
      "[1875]\ttraining's rmse: 0.0747613\tvalid_1's rmse: 0.0776945\n",
      "[1900]\ttraining's rmse: 0.0747565\tvalid_1's rmse: 0.077694\n",
      "[1925]\ttraining's rmse: 0.074753\tvalid_1's rmse: 0.0776938\n",
      "[1950]\ttraining's rmse: 0.0747488\tvalid_1's rmse: 0.0776929\n",
      "[1975]\ttraining's rmse: 0.0747461\tvalid_1's rmse: 0.0776925\n",
      "[2000]\ttraining's rmse: 0.074742\tvalid_1's rmse: 0.0776918\n",
      "[2025]\ttraining's rmse: 0.0747377\tvalid_1's rmse: 0.0776911\n",
      "[2050]\ttraining's rmse: 0.0747341\tvalid_1's rmse: 0.0776908\n",
      "[2075]\ttraining's rmse: 0.0747313\tvalid_1's rmse: 0.0776903\n",
      "[2100]\ttraining's rmse: 0.0747291\tvalid_1's rmse: 0.0776903\n",
      "[2125]\ttraining's rmse: 0.074726\tvalid_1's rmse: 0.0776901\n",
      "[2150]\ttraining's rmse: 0.0747231\tvalid_1's rmse: 0.0776899\n",
      "[2175]\ttraining's rmse: 0.0747205\tvalid_1's rmse: 0.0776897\n",
      "[2200]\ttraining's rmse: 0.0747186\tvalid_1's rmse: 0.0776897\n",
      "Early stopping, best iteration is:\n",
      "[2159]\ttraining's rmse: 0.0747215\tvalid_1's rmse: 0.0776895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0786382\tvalid_1's rmse: 0.0750826\n",
      "[50]\ttraining's rmse: 0.0785392\tvalid_1's rmse: 0.0750373\n",
      "[75]\ttraining's rmse: 0.0784385\tvalid_1's rmse: 0.0749926\n",
      "[100]\ttraining's rmse: 0.0783478\tvalid_1's rmse: 0.0749522\n",
      "[125]\ttraining's rmse: 0.0782544\tvalid_1's rmse: 0.0749136\n",
      "[150]\ttraining's rmse: 0.0781687\tvalid_1's rmse: 0.0748785\n",
      "[175]\ttraining's rmse: 0.0780992\tvalid_1's rmse: 0.0748487\n",
      "[200]\ttraining's rmse: 0.0780224\tvalid_1's rmse: 0.0748196\n",
      "[225]\ttraining's rmse: 0.0779483\tvalid_1's rmse: 0.0747908\n",
      "[250]\ttraining's rmse: 0.0778882\tvalid_1's rmse: 0.0747658\n",
      "[275]\ttraining's rmse: 0.0778288\tvalid_1's rmse: 0.0747432\n",
      "[300]\ttraining's rmse: 0.0777697\tvalid_1's rmse: 0.074721\n",
      "[325]\ttraining's rmse: 0.0777103\tvalid_1's rmse: 0.0747006\n",
      "[350]\ttraining's rmse: 0.0776521\tvalid_1's rmse: 0.0746814\n",
      "[375]\ttraining's rmse: 0.077606\tvalid_1's rmse: 0.0746654\n",
      "[400]\ttraining's rmse: 0.0775545\tvalid_1's rmse: 0.0746534\n",
      "[425]\ttraining's rmse: 0.0775076\tvalid_1's rmse: 0.0746421\n",
      "[450]\ttraining's rmse: 0.0774631\tvalid_1's rmse: 0.0746312\n",
      "[475]\ttraining's rmse: 0.077422\tvalid_1's rmse: 0.0746185\n",
      "[500]\ttraining's rmse: 0.0773881\tvalid_1's rmse: 0.0746049\n",
      "[525]\ttraining's rmse: 0.077344\tvalid_1's rmse: 0.0745911\n",
      "[550]\ttraining's rmse: 0.0773032\tvalid_1's rmse: 0.0745793\n",
      "[575]\ttraining's rmse: 0.0772662\tvalid_1's rmse: 0.0745697\n",
      "[600]\ttraining's rmse: 0.07723\tvalid_1's rmse: 0.0745606\n",
      "[625]\ttraining's rmse: 0.0772006\tvalid_1's rmse: 0.0745582\n",
      "[650]\ttraining's rmse: 0.0771652\tvalid_1's rmse: 0.0745566\n",
      "[675]\ttraining's rmse: 0.0771286\tvalid_1's rmse: 0.0745573\n",
      "[700]\ttraining's rmse: 0.0770972\tvalid_1's rmse: 0.0745495\n",
      "[725]\ttraining's rmse: 0.0770652\tvalid_1's rmse: 0.0745535\n",
      "[750]\ttraining's rmse: 0.077036\tvalid_1's rmse: 0.0745469\n",
      "[775]\ttraining's rmse: 0.077011\tvalid_1's rmse: 0.0745477\n",
      "[800]\ttraining's rmse: 0.0769806\tvalid_1's rmse: 0.0745535\n",
      "[825]\ttraining's rmse: 0.0769536\tvalid_1's rmse: 0.0745576\n",
      "Early stopping, best iteration is:\n",
      "[786]\ttraining's rmse: 0.0769981\tvalid_1's rmse: 0.0745445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0794418\tvalid_1's rmse: 0.081603\n",
      "[50]\ttraining's rmse: 0.0793202\tvalid_1's rmse: 0.0815567\n",
      "[75]\ttraining's rmse: 0.0792027\tvalid_1's rmse: 0.0815111\n",
      "[100]\ttraining's rmse: 0.0790872\tvalid_1's rmse: 0.0814698\n",
      "[125]\ttraining's rmse: 0.0789748\tvalid_1's rmse: 0.0814277\n",
      "[150]\ttraining's rmse: 0.0788743\tvalid_1's rmse: 0.0813916\n",
      "[175]\ttraining's rmse: 0.0787883\tvalid_1's rmse: 0.0813591\n",
      "[200]\ttraining's rmse: 0.0786955\tvalid_1's rmse: 0.0813247\n",
      "[225]\ttraining's rmse: 0.0786018\tvalid_1's rmse: 0.0812936\n",
      "[250]\ttraining's rmse: 0.0785263\tvalid_1's rmse: 0.0812653\n",
      "[275]\ttraining's rmse: 0.0784539\tvalid_1's rmse: 0.081242\n",
      "[300]\ttraining's rmse: 0.0783837\tvalid_1's rmse: 0.0812179\n",
      "[325]\ttraining's rmse: 0.0783154\tvalid_1's rmse: 0.0811956\n",
      "[350]\ttraining's rmse: 0.0782463\tvalid_1's rmse: 0.0811731\n",
      "[375]\ttraining's rmse: 0.0781897\tvalid_1's rmse: 0.0811536\n",
      "[400]\ttraining's rmse: 0.0781258\tvalid_1's rmse: 0.0811359\n",
      "[425]\ttraining's rmse: 0.0780724\tvalid_1's rmse: 0.0811185\n",
      "[450]\ttraining's rmse: 0.0780237\tvalid_1's rmse: 0.0811013\n",
      "[475]\ttraining's rmse: 0.0779756\tvalid_1's rmse: 0.0810864\n",
      "[500]\ttraining's rmse: 0.077934\tvalid_1's rmse: 0.0810725\n",
      "[525]\ttraining's rmse: 0.077884\tvalid_1's rmse: 0.0810583\n",
      "[550]\ttraining's rmse: 0.0778369\tvalid_1's rmse: 0.081044\n",
      "[575]\ttraining's rmse: 0.0777947\tvalid_1's rmse: 0.081032\n",
      "[600]\ttraining's rmse: 0.0777539\tvalid_1's rmse: 0.0810208\n",
      "[625]\ttraining's rmse: 0.0777224\tvalid_1's rmse: 0.081011\n",
      "[650]\ttraining's rmse: 0.077682\tvalid_1's rmse: 0.0810002\n",
      "[675]\ttraining's rmse: 0.0776438\tvalid_1's rmse: 0.0809901\n",
      "[700]\ttraining's rmse: 0.0776116\tvalid_1's rmse: 0.0809819\n",
      "[725]\ttraining's rmse: 0.0775791\tvalid_1's rmse: 0.0809732\n",
      "[750]\ttraining's rmse: 0.0775497\tvalid_1's rmse: 0.080966\n",
      "[775]\ttraining's rmse: 0.0775241\tvalid_1's rmse: 0.0809571\n",
      "[800]\ttraining's rmse: 0.0774912\tvalid_1's rmse: 0.0809513\n",
      "[825]\ttraining's rmse: 0.0774642\tvalid_1's rmse: 0.080945\n",
      "[850]\ttraining's rmse: 0.0774361\tvalid_1's rmse: 0.0809392\n",
      "[875]\ttraining's rmse: 0.0774116\tvalid_1's rmse: 0.0809331\n",
      "[900]\ttraining's rmse: 0.0773847\tvalid_1's rmse: 0.0809272\n",
      "[925]\ttraining's rmse: 0.0773612\tvalid_1's rmse: 0.0809214\n",
      "[950]\ttraining's rmse: 0.0773391\tvalid_1's rmse: 0.0809161\n",
      "[975]\ttraining's rmse: 0.077316\tvalid_1's rmse: 0.0809112\n",
      "[1000]\ttraining's rmse: 0.0772942\tvalid_1's rmse: 0.0809051\n",
      "[1025]\ttraining's rmse: 0.0772754\tvalid_1's rmse: 0.0809007\n",
      "[1050]\ttraining's rmse: 0.0772571\tvalid_1's rmse: 0.0808957\n",
      "[1075]\ttraining's rmse: 0.0772393\tvalid_1's rmse: 0.0808924\n",
      "[1100]\ttraining's rmse: 0.0772233\tvalid_1's rmse: 0.0808883\n",
      "[1125]\ttraining's rmse: 0.0772051\tvalid_1's rmse: 0.0808837\n",
      "[1150]\ttraining's rmse: 0.0771875\tvalid_1's rmse: 0.0808802\n",
      "[1175]\ttraining's rmse: 0.0771729\tvalid_1's rmse: 0.0808786\n",
      "[1200]\ttraining's rmse: 0.0771604\tvalid_1's rmse: 0.0808748\n",
      "[1225]\ttraining's rmse: 0.0771463\tvalid_1's rmse: 0.0808721\n",
      "[1250]\ttraining's rmse: 0.0771325\tvalid_1's rmse: 0.0808686\n",
      "[1275]\ttraining's rmse: 0.077117\tvalid_1's rmse: 0.0808665\n",
      "[1300]\ttraining's rmse: 0.0771059\tvalid_1's rmse: 0.0808632\n",
      "[1325]\ttraining's rmse: 0.0770931\tvalid_1's rmse: 0.0808603\n",
      "[1350]\ttraining's rmse: 0.0770812\tvalid_1's rmse: 0.0808576\n",
      "[1375]\ttraining's rmse: 0.07707\tvalid_1's rmse: 0.0808535\n",
      "[1400]\ttraining's rmse: 0.0770599\tvalid_1's rmse: 0.0808508\n",
      "[1425]\ttraining's rmse: 0.0770489\tvalid_1's rmse: 0.0808501\n",
      "[1450]\ttraining's rmse: 0.0770371\tvalid_1's rmse: 0.0808468\n",
      "[1475]\ttraining's rmse: 0.077027\tvalid_1's rmse: 0.0808442\n",
      "[1500]\ttraining's rmse: 0.0770195\tvalid_1's rmse: 0.0808417\n",
      "[1525]\ttraining's rmse: 0.0770132\tvalid_1's rmse: 0.0808402\n",
      "[1550]\ttraining's rmse: 0.0770057\tvalid_1's rmse: 0.0808381\n",
      "[1575]\ttraining's rmse: 0.0769969\tvalid_1's rmse: 0.0808361\n",
      "[1600]\ttraining's rmse: 0.0769912\tvalid_1's rmse: 0.0808333\n",
      "[1625]\ttraining's rmse: 0.0769856\tvalid_1's rmse: 0.0808315\n",
      "[1650]\ttraining's rmse: 0.0769807\tvalid_1's rmse: 0.0808287\n",
      "[1675]\ttraining's rmse: 0.0769758\tvalid_1's rmse: 0.0808272\n",
      "[1700]\ttraining's rmse: 0.0769694\tvalid_1's rmse: 0.0808259\n",
      "[1725]\ttraining's rmse: 0.0769632\tvalid_1's rmse: 0.080825\n",
      "[1750]\ttraining's rmse: 0.0769572\tvalid_1's rmse: 0.0808235\n",
      "[1775]\ttraining's rmse: 0.0769524\tvalid_1's rmse: 0.0808224\n",
      "[1800]\ttraining's rmse: 0.076948\tvalid_1's rmse: 0.0808207\n",
      "[1825]\ttraining's rmse: 0.0769431\tvalid_1's rmse: 0.0808199\n",
      "[1850]\ttraining's rmse: 0.0769388\tvalid_1's rmse: 0.0808183\n",
      "[1875]\ttraining's rmse: 0.0769347\tvalid_1's rmse: 0.0808175\n",
      "[1900]\ttraining's rmse: 0.0769303\tvalid_1's rmse: 0.0808162\n",
      "[1925]\ttraining's rmse: 0.0769264\tvalid_1's rmse: 0.0808156\n",
      "[1950]\ttraining's rmse: 0.0769232\tvalid_1's rmse: 0.0808142\n",
      "[1975]\ttraining's rmse: 0.0769206\tvalid_1's rmse: 0.0808124\n",
      "[2000]\ttraining's rmse: 0.0769152\tvalid_1's rmse: 0.080812\n",
      "[2025]\ttraining's rmse: 0.0769116\tvalid_1's rmse: 0.0808098\n",
      "[2050]\ttraining's rmse: 0.0769084\tvalid_1's rmse: 0.0808088\n",
      "[2075]\ttraining's rmse: 0.0769054\tvalid_1's rmse: 0.0808074\n",
      "[2100]\ttraining's rmse: 0.0769023\tvalid_1's rmse: 0.0808061\n",
      "[2125]\ttraining's rmse: 0.0768999\tvalid_1's rmse: 0.0808059\n",
      "[2150]\ttraining's rmse: 0.0768964\tvalid_1's rmse: 0.0808054\n",
      "[2175]\ttraining's rmse: 0.0768931\tvalid_1's rmse: 0.0808046\n",
      "[2200]\ttraining's rmse: 0.0768913\tvalid_1's rmse: 0.0808042\n",
      "[2225]\ttraining's rmse: 0.0768886\tvalid_1's rmse: 0.080804\n",
      "[2250]\ttraining's rmse: 0.076887\tvalid_1's rmse: 0.0808039\n",
      "[2275]\ttraining's rmse: 0.0768835\tvalid_1's rmse: 0.0808034\n",
      "[2300]\ttraining's rmse: 0.0768809\tvalid_1's rmse: 0.0808031\n",
      "[2325]\ttraining's rmse: 0.0768776\tvalid_1's rmse: 0.0808015\n",
      "[2350]\ttraining's rmse: 0.0768751\tvalid_1's rmse: 0.080801\n",
      "[2375]\ttraining's rmse: 0.0768727\tvalid_1's rmse: 0.0808003\n",
      "[2400]\ttraining's rmse: 0.0768707\tvalid_1's rmse: 0.0808001\n",
      "[2425]\ttraining's rmse: 0.0768669\tvalid_1's rmse: 0.0807988\n",
      "[2450]\ttraining's rmse: 0.0768644\tvalid_1's rmse: 0.0807979\n",
      "[2475]\ttraining's rmse: 0.0768617\tvalid_1's rmse: 0.0807975\n",
      "[2500]\ttraining's rmse: 0.0768607\tvalid_1's rmse: 0.0807974\n",
      "[2525]\ttraining's rmse: 0.0768593\tvalid_1's rmse: 0.0807973\n",
      "[2550]\ttraining's rmse: 0.0768569\tvalid_1's rmse: 0.0807972\n",
      "[2575]\ttraining's rmse: 0.0768546\tvalid_1's rmse: 0.0807968\n",
      "[2600]\ttraining's rmse: 0.0768532\tvalid_1's rmse: 0.0807964\n",
      "[2625]\ttraining's rmse: 0.0768512\tvalid_1's rmse: 0.0807956\n",
      "[2650]\ttraining's rmse: 0.0768505\tvalid_1's rmse: 0.0807958\n",
      "[2675]\ttraining's rmse: 0.076849\tvalid_1's rmse: 0.0807958\n",
      "Early stopping, best iteration is:\n",
      "[2625]\ttraining's rmse: 0.0768512\tvalid_1's rmse: 0.0807956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0797011\tvalid_1's rmse: 0.081119\n",
      "[50]\ttraining's rmse: 0.0795944\tvalid_1's rmse: 0.0810678\n",
      "[75]\ttraining's rmse: 0.0794841\tvalid_1's rmse: 0.0810171\n",
      "[100]\ttraining's rmse: 0.0793867\tvalid_1's rmse: 0.0809746\n",
      "[125]\ttraining's rmse: 0.0792836\tvalid_1's rmse: 0.0809301\n",
      "[150]\ttraining's rmse: 0.0791891\tvalid_1's rmse: 0.0808876\n",
      "[175]\ttraining's rmse: 0.0791129\tvalid_1's rmse: 0.0808531\n",
      "[200]\ttraining's rmse: 0.079026\tvalid_1's rmse: 0.0808151\n",
      "[225]\ttraining's rmse: 0.0789434\tvalid_1's rmse: 0.0807829\n",
      "[250]\ttraining's rmse: 0.0788719\tvalid_1's rmse: 0.0807523\n",
      "[275]\ttraining's rmse: 0.0788088\tvalid_1's rmse: 0.0807256\n",
      "[300]\ttraining's rmse: 0.078744\tvalid_1's rmse: 0.0806989\n",
      "[325]\ttraining's rmse: 0.078675\tvalid_1's rmse: 0.0806725\n",
      "[350]\ttraining's rmse: 0.0786101\tvalid_1's rmse: 0.0806487\n",
      "[375]\ttraining's rmse: 0.0785598\tvalid_1's rmse: 0.0806289\n",
      "[400]\ttraining's rmse: 0.0785029\tvalid_1's rmse: 0.0806087\n",
      "[425]\ttraining's rmse: 0.0784516\tvalid_1's rmse: 0.080589\n",
      "[450]\ttraining's rmse: 0.0784059\tvalid_1's rmse: 0.0805714\n",
      "[475]\ttraining's rmse: 0.0783635\tvalid_1's rmse: 0.0805552\n",
      "[500]\ttraining's rmse: 0.0783259\tvalid_1's rmse: 0.0805382\n",
      "[525]\ttraining's rmse: 0.0782779\tvalid_1's rmse: 0.0805223\n",
      "[550]\ttraining's rmse: 0.0782344\tvalid_1's rmse: 0.0805083\n",
      "[575]\ttraining's rmse: 0.078193\tvalid_1's rmse: 0.0804939\n",
      "[600]\ttraining's rmse: 0.0781536\tvalid_1's rmse: 0.0804819\n",
      "[625]\ttraining's rmse: 0.0781219\tvalid_1's rmse: 0.0804704\n",
      "[650]\ttraining's rmse: 0.0780816\tvalid_1's rmse: 0.0804582\n",
      "[675]\ttraining's rmse: 0.0780439\tvalid_1's rmse: 0.0804471\n",
      "[700]\ttraining's rmse: 0.078011\tvalid_1's rmse: 0.0804364\n",
      "[725]\ttraining's rmse: 0.0779799\tvalid_1's rmse: 0.0804261\n",
      "[750]\ttraining's rmse: 0.0779513\tvalid_1's rmse: 0.0804174\n",
      "[775]\ttraining's rmse: 0.0779265\tvalid_1's rmse: 0.0804093\n",
      "[800]\ttraining's rmse: 0.0778938\tvalid_1's rmse: 0.0804008\n",
      "[825]\ttraining's rmse: 0.077867\tvalid_1's rmse: 0.0803925\n",
      "[850]\ttraining's rmse: 0.0778396\tvalid_1's rmse: 0.0803858\n",
      "[875]\ttraining's rmse: 0.0778162\tvalid_1's rmse: 0.0803789\n",
      "[900]\ttraining's rmse: 0.0777902\tvalid_1's rmse: 0.0803719\n",
      "[925]\ttraining's rmse: 0.0777655\tvalid_1's rmse: 0.0803659\n",
      "[950]\ttraining's rmse: 0.0777415\tvalid_1's rmse: 0.0803597\n",
      "[975]\ttraining's rmse: 0.0777194\tvalid_1's rmse: 0.0803542\n",
      "[1000]\ttraining's rmse: 0.0776998\tvalid_1's rmse: 0.0803494\n",
      "[1025]\ttraining's rmse: 0.07768\tvalid_1's rmse: 0.0803443\n",
      "[1050]\ttraining's rmse: 0.0776593\tvalid_1's rmse: 0.0803386\n",
      "[1075]\ttraining's rmse: 0.0776407\tvalid_1's rmse: 0.0803347\n",
      "[1100]\ttraining's rmse: 0.0776251\tvalid_1's rmse: 0.0803307\n",
      "[1125]\ttraining's rmse: 0.0776079\tvalid_1's rmse: 0.0803268\n",
      "[1150]\ttraining's rmse: 0.0775904\tvalid_1's rmse: 0.0803226\n",
      "[1175]\ttraining's rmse: 0.077574\tvalid_1's rmse: 0.0803188\n",
      "[1200]\ttraining's rmse: 0.0775584\tvalid_1's rmse: 0.0803152\n",
      "[1225]\ttraining's rmse: 0.077546\tvalid_1's rmse: 0.0803123\n",
      "[1250]\ttraining's rmse: 0.0775335\tvalid_1's rmse: 0.0803097\n",
      "[1275]\ttraining's rmse: 0.0775191\tvalid_1's rmse: 0.0803066\n",
      "[1300]\ttraining's rmse: 0.0775055\tvalid_1's rmse: 0.0803037\n",
      "[1325]\ttraining's rmse: 0.0774933\tvalid_1's rmse: 0.0803011\n",
      "[1350]\ttraining's rmse: 0.0774832\tvalid_1's rmse: 0.0802994\n",
      "[1375]\ttraining's rmse: 0.0774718\tvalid_1's rmse: 0.0802971\n",
      "[1400]\ttraining's rmse: 0.0774633\tvalid_1's rmse: 0.0802949\n",
      "[1425]\ttraining's rmse: 0.0774531\tvalid_1's rmse: 0.0802938\n",
      "[1450]\ttraining's rmse: 0.0774433\tvalid_1's rmse: 0.0802923\n",
      "[1475]\ttraining's rmse: 0.0774345\tvalid_1's rmse: 0.0802904\n",
      "[1500]\ttraining's rmse: 0.0774255\tvalid_1's rmse: 0.0802889\n",
      "[1525]\ttraining's rmse: 0.0774177\tvalid_1's rmse: 0.0802878\n",
      "[1550]\ttraining's rmse: 0.0774088\tvalid_1's rmse: 0.0802868\n",
      "[1575]\ttraining's rmse: 0.077401\tvalid_1's rmse: 0.080285\n",
      "[1600]\ttraining's rmse: 0.0773944\tvalid_1's rmse: 0.0802838\n",
      "[1625]\ttraining's rmse: 0.0773874\tvalid_1's rmse: 0.0802825\n",
      "[1650]\ttraining's rmse: 0.0773805\tvalid_1's rmse: 0.0802811\n",
      "[1675]\ttraining's rmse: 0.0773756\tvalid_1's rmse: 0.0802803\n",
      "[1700]\ttraining's rmse: 0.0773704\tvalid_1's rmse: 0.080279\n",
      "[1725]\ttraining's rmse: 0.0773642\tvalid_1's rmse: 0.0802779\n",
      "[1750]\ttraining's rmse: 0.0773574\tvalid_1's rmse: 0.0802777\n",
      "[1775]\ttraining's rmse: 0.0773527\tvalid_1's rmse: 0.0802769\n",
      "[1800]\ttraining's rmse: 0.0773471\tvalid_1's rmse: 0.0802757\n",
      "[1825]\ttraining's rmse: 0.0773408\tvalid_1's rmse: 0.0802745\n",
      "[1850]\ttraining's rmse: 0.0773355\tvalid_1's rmse: 0.0802738\n",
      "[1875]\ttraining's rmse: 0.0773303\tvalid_1's rmse: 0.0802733\n",
      "[1900]\ttraining's rmse: 0.0773256\tvalid_1's rmse: 0.0802732\n",
      "[1925]\ttraining's rmse: 0.0773214\tvalid_1's rmse: 0.0802729\n",
      "[1950]\ttraining's rmse: 0.0773175\tvalid_1's rmse: 0.0802717\n",
      "[1975]\ttraining's rmse: 0.0773146\tvalid_1's rmse: 0.0802714\n",
      "[2000]\ttraining's rmse: 0.07731\tvalid_1's rmse: 0.0802707\n",
      "[2025]\ttraining's rmse: 0.0773067\tvalid_1's rmse: 0.0802701\n",
      "[2050]\ttraining's rmse: 0.0773042\tvalid_1's rmse: 0.0802695\n",
      "[2075]\ttraining's rmse: 0.0773021\tvalid_1's rmse: 0.0802695\n",
      "[2100]\ttraining's rmse: 0.0772996\tvalid_1's rmse: 0.0802692\n",
      "[2125]\ttraining's rmse: 0.0772967\tvalid_1's rmse: 0.0802689\n",
      "[2150]\ttraining's rmse: 0.0772931\tvalid_1's rmse: 0.0802693\n",
      "Early stopping, best iteration is:\n",
      "[2121]\ttraining's rmse: 0.0772972\tvalid_1's rmse: 0.0802689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0812502\tvalid_1's rmse: 0.0779699\n",
      "[50]\ttraining's rmse: 0.0811474\tvalid_1's rmse: 0.0779229\n",
      "[75]\ttraining's rmse: 0.0810408\tvalid_1's rmse: 0.0778762\n",
      "[100]\ttraining's rmse: 0.0809444\tvalid_1's rmse: 0.0778353\n",
      "[125]\ttraining's rmse: 0.0808448\tvalid_1's rmse: 0.0777959\n",
      "[150]\ttraining's rmse: 0.0807559\tvalid_1's rmse: 0.0777596\n",
      "[175]\ttraining's rmse: 0.0806795\tvalid_1's rmse: 0.0777277\n",
      "[200]\ttraining's rmse: 0.0805966\tvalid_1's rmse: 0.0776949\n",
      "[225]\ttraining's rmse: 0.0805155\tvalid_1's rmse: 0.0776641\n",
      "[250]\ttraining's rmse: 0.0804475\tvalid_1's rmse: 0.0776379\n",
      "[275]\ttraining's rmse: 0.0803852\tvalid_1's rmse: 0.0776135\n",
      "[300]\ttraining's rmse: 0.0803216\tvalid_1's rmse: 0.0775899\n",
      "[325]\ttraining's rmse: 0.0802587\tvalid_1's rmse: 0.077568\n",
      "[350]\ttraining's rmse: 0.0801979\tvalid_1's rmse: 0.0775472\n",
      "[375]\ttraining's rmse: 0.0801477\tvalid_1's rmse: 0.0775311\n",
      "[400]\ttraining's rmse: 0.0800939\tvalid_1's rmse: 0.0775129\n",
      "[425]\ttraining's rmse: 0.0800446\tvalid_1's rmse: 0.0775005\n",
      "[450]\ttraining's rmse: 0.0799987\tvalid_1's rmse: 0.0774865\n",
      "[475]\ttraining's rmse: 0.0799567\tvalid_1's rmse: 0.0774735\n",
      "[500]\ttraining's rmse: 0.0799199\tvalid_1's rmse: 0.0774605\n",
      "[525]\ttraining's rmse: 0.079871\tvalid_1's rmse: 0.0774495\n",
      "[550]\ttraining's rmse: 0.0798281\tvalid_1's rmse: 0.0774411\n",
      "[575]\ttraining's rmse: 0.0797856\tvalid_1's rmse: 0.0774346\n",
      "[600]\ttraining's rmse: 0.0797453\tvalid_1's rmse: 0.0774247\n",
      "[625]\ttraining's rmse: 0.0797132\tvalid_1's rmse: 0.0774233\n",
      "[650]\ttraining's rmse: 0.0796738\tvalid_1's rmse: 0.0774165\n",
      "[675]\ttraining's rmse: 0.0796346\tvalid_1's rmse: 0.0774081\n",
      "[700]\ttraining's rmse: 0.0796024\tvalid_1's rmse: 0.0774051\n",
      "[725]\ttraining's rmse: 0.0795708\tvalid_1's rmse: 0.0774008\n",
      "[750]\ttraining's rmse: 0.0795419\tvalid_1's rmse: 0.0774019\n",
      "[775]\ttraining's rmse: 0.0795172\tvalid_1's rmse: 0.0773966\n",
      "[800]\ttraining's rmse: 0.0794837\tvalid_1's rmse: 0.0773947\n",
      "[825]\ttraining's rmse: 0.0794582\tvalid_1's rmse: 0.0773947\n",
      "[850]\ttraining's rmse: 0.0794286\tvalid_1's rmse: 0.0773894\n",
      "[875]\ttraining's rmse: 0.0794049\tvalid_1's rmse: 0.0773852\n",
      "[900]\ttraining's rmse: 0.0793779\tvalid_1's rmse: 0.0773884\n",
      "[925]\ttraining's rmse: 0.0793525\tvalid_1's rmse: 0.0773852\n",
      "Early stopping, best iteration is:\n",
      "[887]\ttraining's rmse: 0.0793904\tvalid_1's rmse: 0.0773826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0772771\tvalid_1's rmse: 0.0797438\n",
      "[50]\ttraining's rmse: 0.0771676\tvalid_1's rmse: 0.0796961\n",
      "[75]\ttraining's rmse: 0.0770561\tvalid_1's rmse: 0.0796492\n",
      "[100]\ttraining's rmse: 0.0769577\tvalid_1's rmse: 0.0796081\n",
      "[125]\ttraining's rmse: 0.0768554\tvalid_1's rmse: 0.0795658\n",
      "[150]\ttraining's rmse: 0.076766\tvalid_1's rmse: 0.0795278\n",
      "[175]\ttraining's rmse: 0.0766899\tvalid_1's rmse: 0.0794952\n",
      "[200]\ttraining's rmse: 0.07661\tvalid_1's rmse: 0.0794629\n",
      "[225]\ttraining's rmse: 0.0765296\tvalid_1's rmse: 0.0794315\n",
      "[250]\ttraining's rmse: 0.0764621\tvalid_1's rmse: 0.0794033\n",
      "[275]\ttraining's rmse: 0.0763981\tvalid_1's rmse: 0.0793775\n",
      "[300]\ttraining's rmse: 0.0763357\tvalid_1's rmse: 0.0793536\n",
      "[325]\ttraining's rmse: 0.0762722\tvalid_1's rmse: 0.0793287\n",
      "[350]\ttraining's rmse: 0.0762122\tvalid_1's rmse: 0.0793055\n",
      "[375]\ttraining's rmse: 0.0761631\tvalid_1's rmse: 0.0792858\n",
      "[400]\ttraining's rmse: 0.0761059\tvalid_1's rmse: 0.079267\n",
      "[425]\ttraining's rmse: 0.0760565\tvalid_1's rmse: 0.0792488\n",
      "[450]\ttraining's rmse: 0.0760118\tvalid_1's rmse: 0.0792312\n",
      "[475]\ttraining's rmse: 0.0759731\tvalid_1's rmse: 0.0792155\n",
      "[500]\ttraining's rmse: 0.0759383\tvalid_1's rmse: 0.0792011\n",
      "[525]\ttraining's rmse: 0.0758921\tvalid_1's rmse: 0.0791852\n",
      "[550]\ttraining's rmse: 0.0758519\tvalid_1's rmse: 0.079172\n",
      "[575]\ttraining's rmse: 0.0758149\tvalid_1's rmse: 0.079159\n",
      "[600]\ttraining's rmse: 0.0757776\tvalid_1's rmse: 0.0791466\n",
      "[625]\ttraining's rmse: 0.0757469\tvalid_1's rmse: 0.0791358\n",
      "[650]\ttraining's rmse: 0.0757128\tvalid_1's rmse: 0.0791249\n",
      "[675]\ttraining's rmse: 0.0756776\tvalid_1's rmse: 0.0791119\n",
      "[700]\ttraining's rmse: 0.0756459\tvalid_1's rmse: 0.0791012\n",
      "[725]\ttraining's rmse: 0.0756167\tvalid_1's rmse: 0.079092\n",
      "[750]\ttraining's rmse: 0.0755894\tvalid_1's rmse: 0.0790831\n",
      "[775]\ttraining's rmse: 0.0755689\tvalid_1's rmse: 0.0790731\n",
      "[800]\ttraining's rmse: 0.0755419\tvalid_1's rmse: 0.0790667\n",
      "[825]\ttraining's rmse: 0.0755169\tvalid_1's rmse: 0.0790579\n",
      "[850]\ttraining's rmse: 0.0754915\tvalid_1's rmse: 0.0790512\n",
      "[875]\ttraining's rmse: 0.0754694\tvalid_1's rmse: 0.0790437\n",
      "[900]\ttraining's rmse: 0.0754448\tvalid_1's rmse: 0.0790375\n",
      "[925]\ttraining's rmse: 0.0754227\tvalid_1's rmse: 0.079031\n",
      "[950]\ttraining's rmse: 0.0754024\tvalid_1's rmse: 0.079025\n",
      "[975]\ttraining's rmse: 0.0753853\tvalid_1's rmse: 0.0790192\n",
      "[1000]\ttraining's rmse: 0.0753642\tvalid_1's rmse: 0.0790135\n",
      "[1025]\ttraining's rmse: 0.0753424\tvalid_1's rmse: 0.0790076\n",
      "[1050]\ttraining's rmse: 0.0753262\tvalid_1's rmse: 0.0790017\n",
      "[1075]\ttraining's rmse: 0.075308\tvalid_1's rmse: 0.0789979\n",
      "[1100]\ttraining's rmse: 0.0752938\tvalid_1's rmse: 0.0789931\n",
      "[1125]\ttraining's rmse: 0.0752798\tvalid_1's rmse: 0.078989\n",
      "[1150]\ttraining's rmse: 0.0752615\tvalid_1's rmse: 0.0789857\n",
      "[1175]\ttraining's rmse: 0.0752455\tvalid_1's rmse: 0.0789833\n",
      "[1200]\ttraining's rmse: 0.0752311\tvalid_1's rmse: 0.0789785\n",
      "[1225]\ttraining's rmse: 0.0752177\tvalid_1's rmse: 0.0789746\n",
      "[1250]\ttraining's rmse: 0.0752053\tvalid_1's rmse: 0.0789711\n",
      "[1275]\ttraining's rmse: 0.075192\tvalid_1's rmse: 0.0789675\n",
      "[1300]\ttraining's rmse: 0.0751817\tvalid_1's rmse: 0.0789628\n",
      "[1325]\ttraining's rmse: 0.0751707\tvalid_1's rmse: 0.0789594\n",
      "[1350]\ttraining's rmse: 0.0751594\tvalid_1's rmse: 0.0789559\n",
      "[1375]\ttraining's rmse: 0.0751497\tvalid_1's rmse: 0.0789531\n",
      "[1400]\ttraining's rmse: 0.0751419\tvalid_1's rmse: 0.0789508\n",
      "[1425]\ttraining's rmse: 0.0751331\tvalid_1's rmse: 0.0789487\n",
      "[1450]\ttraining's rmse: 0.0751236\tvalid_1's rmse: 0.0789464\n",
      "[1475]\ttraining's rmse: 0.075114\tvalid_1's rmse: 0.0789437\n",
      "[1500]\ttraining's rmse: 0.0751053\tvalid_1's rmse: 0.0789405\n",
      "[1525]\ttraining's rmse: 0.0750993\tvalid_1's rmse: 0.078937\n",
      "[1550]\ttraining's rmse: 0.0750902\tvalid_1's rmse: 0.0789344\n",
      "[1575]\ttraining's rmse: 0.0750836\tvalid_1's rmse: 0.0789317\n",
      "[1600]\ttraining's rmse: 0.0750767\tvalid_1's rmse: 0.0789298\n",
      "[1625]\ttraining's rmse: 0.0750716\tvalid_1's rmse: 0.0789271\n",
      "[1650]\ttraining's rmse: 0.0750661\tvalid_1's rmse: 0.0789248\n",
      "[1675]\ttraining's rmse: 0.0750615\tvalid_1's rmse: 0.078924\n",
      "[1700]\ttraining's rmse: 0.0750568\tvalid_1's rmse: 0.0789217\n",
      "[1725]\ttraining's rmse: 0.0750531\tvalid_1's rmse: 0.078921\n",
      "[1750]\ttraining's rmse: 0.0750477\tvalid_1's rmse: 0.0789192\n",
      "[1775]\ttraining's rmse: 0.0750432\tvalid_1's rmse: 0.0789183\n",
      "[1800]\ttraining's rmse: 0.0750393\tvalid_1's rmse: 0.0789164\n",
      "[1825]\ttraining's rmse: 0.0750344\tvalid_1's rmse: 0.0789156\n",
      "[1850]\ttraining's rmse: 0.0750307\tvalid_1's rmse: 0.0789137\n",
      "[1875]\ttraining's rmse: 0.0750265\tvalid_1's rmse: 0.0789131\n",
      "[1900]\ttraining's rmse: 0.0750226\tvalid_1's rmse: 0.0789116\n",
      "[1925]\ttraining's rmse: 0.0750194\tvalid_1's rmse: 0.0789102\n",
      "[1950]\ttraining's rmse: 0.0750168\tvalid_1's rmse: 0.0789086\n",
      "[1975]\ttraining's rmse: 0.0750136\tvalid_1's rmse: 0.0789078\n",
      "[2000]\ttraining's rmse: 0.0750101\tvalid_1's rmse: 0.0789069\n",
      "[2025]\ttraining's rmse: 0.0750066\tvalid_1's rmse: 0.0789057\n",
      "[2050]\ttraining's rmse: 0.0750027\tvalid_1's rmse: 0.0789034\n",
      "[2075]\ttraining's rmse: 0.0750008\tvalid_1's rmse: 0.078902\n",
      "[2100]\ttraining's rmse: 0.074998\tvalid_1's rmse: 0.0789012\n",
      "[2125]\ttraining's rmse: 0.0749966\tvalid_1's rmse: 0.0789011\n",
      "[2150]\ttraining's rmse: 0.0749936\tvalid_1's rmse: 0.0789008\n",
      "[2175]\ttraining's rmse: 0.0749916\tvalid_1's rmse: 0.0788994\n",
      "[2200]\ttraining's rmse: 0.0749895\tvalid_1's rmse: 0.0788976\n",
      "[2225]\ttraining's rmse: 0.0749868\tvalid_1's rmse: 0.0788975\n",
      "[2250]\ttraining's rmse: 0.074984\tvalid_1's rmse: 0.0788963\n",
      "[2275]\ttraining's rmse: 0.0749805\tvalid_1's rmse: 0.0788954\n",
      "[2300]\ttraining's rmse: 0.0749781\tvalid_1's rmse: 0.0788951\n",
      "[2325]\ttraining's rmse: 0.0749748\tvalid_1's rmse: 0.0788946\n",
      "[2350]\ttraining's rmse: 0.0749731\tvalid_1's rmse: 0.0788945\n",
      "[2375]\ttraining's rmse: 0.0749712\tvalid_1's rmse: 0.0788944\n",
      "[2400]\ttraining's rmse: 0.0749691\tvalid_1's rmse: 0.0788936\n",
      "[2425]\ttraining's rmse: 0.0749675\tvalid_1's rmse: 0.0788934\n",
      "[2450]\ttraining's rmse: 0.0749663\tvalid_1's rmse: 0.0788933\n",
      "[2475]\ttraining's rmse: 0.0749646\tvalid_1's rmse: 0.078893\n",
      "[2500]\ttraining's rmse: 0.0749628\tvalid_1's rmse: 0.0788926\n",
      "[2525]\ttraining's rmse: 0.0749618\tvalid_1's rmse: 0.0788922\n",
      "[2550]\ttraining's rmse: 0.0749605\tvalid_1's rmse: 0.0788919\n",
      "[2575]\ttraining's rmse: 0.0749585\tvalid_1's rmse: 0.0788915\n",
      "[2600]\ttraining's rmse: 0.0749568\tvalid_1's rmse: 0.0788905\n",
      "[2625]\ttraining's rmse: 0.0749558\tvalid_1's rmse: 0.0788908\n",
      "[2650]\ttraining's rmse: 0.0749547\tvalid_1's rmse: 0.0788908\n",
      "Early stopping, best iteration is:\n",
      "[2604]\ttraining's rmse: 0.0749568\tvalid_1's rmse: 0.0788905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0776142\tvalid_1's rmse: 0.07909\n",
      "[50]\ttraining's rmse: 0.077514\tvalid_1's rmse: 0.0790392\n",
      "[75]\ttraining's rmse: 0.0774079\tvalid_1's rmse: 0.0789871\n",
      "[100]\ttraining's rmse: 0.0773156\tvalid_1's rmse: 0.0789417\n",
      "[125]\ttraining's rmse: 0.0772219\tvalid_1's rmse: 0.0788969\n",
      "[150]\ttraining's rmse: 0.0771344\tvalid_1's rmse: 0.0788564\n",
      "[175]\ttraining's rmse: 0.0770617\tvalid_1's rmse: 0.0788226\n",
      "[200]\ttraining's rmse: 0.076984\tvalid_1's rmse: 0.0787884\n",
      "[225]\ttraining's rmse: 0.0769069\tvalid_1's rmse: 0.078755\n",
      "[250]\ttraining's rmse: 0.0768409\tvalid_1's rmse: 0.0787253\n",
      "[275]\ttraining's rmse: 0.0767816\tvalid_1's rmse: 0.0786978\n",
      "[300]\ttraining's rmse: 0.0767238\tvalid_1's rmse: 0.0786732\n",
      "[325]\ttraining's rmse: 0.0766605\tvalid_1's rmse: 0.078647\n",
      "[350]\ttraining's rmse: 0.0765986\tvalid_1's rmse: 0.0786227\n",
      "[375]\ttraining's rmse: 0.0765509\tvalid_1's rmse: 0.0786017\n",
      "[400]\ttraining's rmse: 0.0764987\tvalid_1's rmse: 0.078582\n",
      "[425]\ttraining's rmse: 0.0764512\tvalid_1's rmse: 0.0785639\n",
      "[450]\ttraining's rmse: 0.0764059\tvalid_1's rmse: 0.0785469\n",
      "[475]\ttraining's rmse: 0.0763648\tvalid_1's rmse: 0.07853\n",
      "[500]\ttraining's rmse: 0.0763294\tvalid_1's rmse: 0.0785148\n",
      "[525]\ttraining's rmse: 0.076283\tvalid_1's rmse: 0.0784992\n",
      "[550]\ttraining's rmse: 0.076241\tvalid_1's rmse: 0.0784846\n",
      "[575]\ttraining's rmse: 0.0762029\tvalid_1's rmse: 0.0784718\n",
      "[600]\ttraining's rmse: 0.0761657\tvalid_1's rmse: 0.0784596\n",
      "[625]\ttraining's rmse: 0.0761358\tvalid_1's rmse: 0.0784478\n",
      "[650]\ttraining's rmse: 0.0760986\tvalid_1's rmse: 0.0784348\n",
      "[675]\ttraining's rmse: 0.0760613\tvalid_1's rmse: 0.0784234\n",
      "[700]\ttraining's rmse: 0.0760296\tvalid_1's rmse: 0.0784134\n",
      "[725]\ttraining's rmse: 0.0760003\tvalid_1's rmse: 0.0784042\n",
      "[750]\ttraining's rmse: 0.0759733\tvalid_1's rmse: 0.078396\n",
      "[775]\ttraining's rmse: 0.0759504\tvalid_1's rmse: 0.0783883\n",
      "[800]\ttraining's rmse: 0.075921\tvalid_1's rmse: 0.0783805\n",
      "[825]\ttraining's rmse: 0.0758974\tvalid_1's rmse: 0.0783733\n",
      "[850]\ttraining's rmse: 0.0758738\tvalid_1's rmse: 0.0783664\n",
      "[875]\ttraining's rmse: 0.0758518\tvalid_1's rmse: 0.0783597\n",
      "[900]\ttraining's rmse: 0.0758276\tvalid_1's rmse: 0.0783529\n",
      "[925]\ttraining's rmse: 0.0758057\tvalid_1's rmse: 0.0783469\n",
      "[950]\ttraining's rmse: 0.0757834\tvalid_1's rmse: 0.078342\n",
      "[975]\ttraining's rmse: 0.0757661\tvalid_1's rmse: 0.0783363\n",
      "[1000]\ttraining's rmse: 0.0757475\tvalid_1's rmse: 0.0783317\n",
      "[1025]\ttraining's rmse: 0.0757268\tvalid_1's rmse: 0.078327\n",
      "[1050]\ttraining's rmse: 0.0757077\tvalid_1's rmse: 0.0783222\n",
      "[1075]\ttraining's rmse: 0.0756895\tvalid_1's rmse: 0.0783187\n",
      "[1100]\ttraining's rmse: 0.0756756\tvalid_1's rmse: 0.078315\n",
      "[1125]\ttraining's rmse: 0.0756613\tvalid_1's rmse: 0.0783113\n",
      "[1150]\ttraining's rmse: 0.0756467\tvalid_1's rmse: 0.0783083\n",
      "[1175]\ttraining's rmse: 0.0756336\tvalid_1's rmse: 0.0783054\n",
      "[1200]\ttraining's rmse: 0.0756202\tvalid_1's rmse: 0.0783013\n",
      "[1225]\ttraining's rmse: 0.0756071\tvalid_1's rmse: 0.0782983\n",
      "[1250]\ttraining's rmse: 0.0755952\tvalid_1's rmse: 0.078296\n",
      "[1275]\ttraining's rmse: 0.0755809\tvalid_1's rmse: 0.0782933\n",
      "[1300]\ttraining's rmse: 0.0755699\tvalid_1's rmse: 0.0782905\n",
      "[1325]\ttraining's rmse: 0.075559\tvalid_1's rmse: 0.0782882\n",
      "[1350]\ttraining's rmse: 0.0755498\tvalid_1's rmse: 0.0782866\n",
      "[1375]\ttraining's rmse: 0.0755396\tvalid_1's rmse: 0.0782842\n",
      "[1400]\ttraining's rmse: 0.0755303\tvalid_1's rmse: 0.078282\n",
      "[1425]\ttraining's rmse: 0.0755214\tvalid_1's rmse: 0.0782804\n",
      "[1450]\ttraining's rmse: 0.0755113\tvalid_1's rmse: 0.0782784\n",
      "[1475]\ttraining's rmse: 0.0755025\tvalid_1's rmse: 0.0782763\n",
      "[1500]\ttraining's rmse: 0.0754956\tvalid_1's rmse: 0.0782747\n",
      "[1525]\ttraining's rmse: 0.0754866\tvalid_1's rmse: 0.0782728\n",
      "[1550]\ttraining's rmse: 0.0754802\tvalid_1's rmse: 0.0782718\n",
      "[1575]\ttraining's rmse: 0.075473\tvalid_1's rmse: 0.0782701\n",
      "[1600]\ttraining's rmse: 0.075468\tvalid_1's rmse: 0.0782696\n",
      "[1625]\ttraining's rmse: 0.0754622\tvalid_1's rmse: 0.0782684\n",
      "[1650]\ttraining's rmse: 0.0754564\tvalid_1's rmse: 0.0782676\n",
      "[1675]\ttraining's rmse: 0.0754506\tvalid_1's rmse: 0.0782663\n",
      "[1700]\ttraining's rmse: 0.0754467\tvalid_1's rmse: 0.0782654\n",
      "[1725]\ttraining's rmse: 0.0754409\tvalid_1's rmse: 0.0782642\n",
      "[1750]\ttraining's rmse: 0.0754349\tvalid_1's rmse: 0.0782631\n",
      "[1775]\ttraining's rmse: 0.0754297\tvalid_1's rmse: 0.0782625\n",
      "[1800]\ttraining's rmse: 0.0754228\tvalid_1's rmse: 0.0782617\n",
      "[1825]\ttraining's rmse: 0.0754182\tvalid_1's rmse: 0.0782611\n",
      "[1850]\ttraining's rmse: 0.0754142\tvalid_1's rmse: 0.0782604\n",
      "[1875]\ttraining's rmse: 0.0754104\tvalid_1's rmse: 0.0782597\n",
      "[1900]\ttraining's rmse: 0.0754065\tvalid_1's rmse: 0.0782594\n",
      "[1925]\ttraining's rmse: 0.0754026\tvalid_1's rmse: 0.0782589\n",
      "[1950]\ttraining's rmse: 0.0754008\tvalid_1's rmse: 0.0782586\n",
      "[1975]\ttraining's rmse: 0.0753976\tvalid_1's rmse: 0.0782579\n",
      "[2000]\ttraining's rmse: 0.0753948\tvalid_1's rmse: 0.0782576\n",
      "[2025]\ttraining's rmse: 0.075392\tvalid_1's rmse: 0.0782571\n",
      "[2050]\ttraining's rmse: 0.0753881\tvalid_1's rmse: 0.0782567\n",
      "[2075]\ttraining's rmse: 0.0753861\tvalid_1's rmse: 0.0782568\n",
      "[2100]\ttraining's rmse: 0.075384\tvalid_1's rmse: 0.0782565\n",
      "[2125]\ttraining's rmse: 0.0753818\tvalid_1's rmse: 0.0782563\n",
      "[2150]\ttraining's rmse: 0.0753785\tvalid_1's rmse: 0.078256\n",
      "[2175]\ttraining's rmse: 0.0753761\tvalid_1's rmse: 0.0782559\n",
      "[2200]\ttraining's rmse: 0.075374\tvalid_1's rmse: 0.0782556\n",
      "[2225]\ttraining's rmse: 0.0753721\tvalid_1's rmse: 0.0782556\n",
      "Early stopping, best iteration is:\n",
      "[2198]\ttraining's rmse: 0.0753741\tvalid_1's rmse: 0.0782555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.079308\tvalid_1's rmse: 0.0756363\n",
      "[50]\ttraining's rmse: 0.0792089\tvalid_1's rmse: 0.0755903\n",
      "[75]\ttraining's rmse: 0.0791065\tvalid_1's rmse: 0.0755452\n",
      "[100]\ttraining's rmse: 0.079013\tvalid_1's rmse: 0.0755077\n",
      "[125]\ttraining's rmse: 0.0789185\tvalid_1's rmse: 0.0754693\n",
      "[150]\ttraining's rmse: 0.0788317\tvalid_1's rmse: 0.0754333\n",
      "[175]\ttraining's rmse: 0.0787606\tvalid_1's rmse: 0.0754041\n",
      "[200]\ttraining's rmse: 0.0786832\tvalid_1's rmse: 0.0753738\n",
      "[225]\ttraining's rmse: 0.078607\tvalid_1's rmse: 0.0753482\n",
      "[250]\ttraining's rmse: 0.0785474\tvalid_1's rmse: 0.0753251\n",
      "[275]\ttraining's rmse: 0.0784864\tvalid_1's rmse: 0.0753013\n",
      "[300]\ttraining's rmse: 0.0784273\tvalid_1's rmse: 0.0752795\n",
      "[325]\ttraining's rmse: 0.0783669\tvalid_1's rmse: 0.0752594\n",
      "[350]\ttraining's rmse: 0.0783061\tvalid_1's rmse: 0.0752387\n",
      "[375]\ttraining's rmse: 0.0782599\tvalid_1's rmse: 0.0752228\n",
      "[400]\ttraining's rmse: 0.0782084\tvalid_1's rmse: 0.0752125\n",
      "[425]\ttraining's rmse: 0.0781621\tvalid_1's rmse: 0.0751977\n",
      "[450]\ttraining's rmse: 0.0781193\tvalid_1's rmse: 0.0751875\n",
      "[475]\ttraining's rmse: 0.0780783\tvalid_1's rmse: 0.0751828\n",
      "[500]\ttraining's rmse: 0.0780431\tvalid_1's rmse: 0.0751735\n",
      "[525]\ttraining's rmse: 0.0779961\tvalid_1's rmse: 0.0751663\n",
      "[550]\ttraining's rmse: 0.0779564\tvalid_1's rmse: 0.0751542\n",
      "[575]\ttraining's rmse: 0.077918\tvalid_1's rmse: 0.0751542\n",
      "[600]\ttraining's rmse: 0.0778807\tvalid_1's rmse: 0.0751459\n",
      "[625]\ttraining's rmse: 0.0778525\tvalid_1's rmse: 0.0751516\n",
      "[650]\ttraining's rmse: 0.0778163\tvalid_1's rmse: 0.0751503\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's rmse: 0.0778807\tvalid_1's rmse: 0.0751459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0804639\tvalid_1's rmse: 0.0824446\n",
      "[50]\ttraining's rmse: 0.080343\tvalid_1's rmse: 0.0823973\n",
      "[75]\ttraining's rmse: 0.0802165\tvalid_1's rmse: 0.0823504\n",
      "[100]\ttraining's rmse: 0.0801032\tvalid_1's rmse: 0.0823106\n",
      "[125]\ttraining's rmse: 0.0799897\tvalid_1's rmse: 0.0822692\n",
      "[150]\ttraining's rmse: 0.0798863\tvalid_1's rmse: 0.0822311\n",
      "[175]\ttraining's rmse: 0.0798019\tvalid_1's rmse: 0.0821976\n",
      "[200]\ttraining's rmse: 0.0797089\tvalid_1's rmse: 0.0821638\n",
      "[225]\ttraining's rmse: 0.0796189\tvalid_1's rmse: 0.0821342\n",
      "[250]\ttraining's rmse: 0.0795477\tvalid_1's rmse: 0.0821058\n",
      "[275]\ttraining's rmse: 0.0794786\tvalid_1's rmse: 0.0820816\n",
      "[300]\ttraining's rmse: 0.0794085\tvalid_1's rmse: 0.0820576\n",
      "[325]\ttraining's rmse: 0.0793393\tvalid_1's rmse: 0.0820336\n",
      "[350]\ttraining's rmse: 0.0792719\tvalid_1's rmse: 0.0820115\n",
      "[375]\ttraining's rmse: 0.0792146\tvalid_1's rmse: 0.081993\n",
      "[400]\ttraining's rmse: 0.0791532\tvalid_1's rmse: 0.0819746\n",
      "[425]\ttraining's rmse: 0.0790975\tvalid_1's rmse: 0.0819574\n",
      "[450]\ttraining's rmse: 0.0790474\tvalid_1's rmse: 0.0819406\n",
      "[475]\ttraining's rmse: 0.0790043\tvalid_1's rmse: 0.0819263\n",
      "[500]\ttraining's rmse: 0.0789661\tvalid_1's rmse: 0.0819123\n",
      "[525]\ttraining's rmse: 0.078918\tvalid_1's rmse: 0.0818975\n",
      "[550]\ttraining's rmse: 0.0788707\tvalid_1's rmse: 0.0818842\n",
      "[575]\ttraining's rmse: 0.0788284\tvalid_1's rmse: 0.0818726\n",
      "[600]\ttraining's rmse: 0.0787879\tvalid_1's rmse: 0.0818624\n",
      "[625]\ttraining's rmse: 0.0787548\tvalid_1's rmse: 0.0818524\n",
      "[650]\ttraining's rmse: 0.0787166\tvalid_1's rmse: 0.0818418\n",
      "[675]\ttraining's rmse: 0.0786766\tvalid_1's rmse: 0.0818309\n",
      "[700]\ttraining's rmse: 0.0786424\tvalid_1's rmse: 0.0818221\n",
      "[725]\ttraining's rmse: 0.0786052\tvalid_1's rmse: 0.0818132\n",
      "[750]\ttraining's rmse: 0.0785737\tvalid_1's rmse: 0.0818049\n",
      "[775]\ttraining's rmse: 0.0785486\tvalid_1's rmse: 0.081797\n",
      "[800]\ttraining's rmse: 0.0785171\tvalid_1's rmse: 0.0817893\n",
      "[825]\ttraining's rmse: 0.0784916\tvalid_1's rmse: 0.0817827\n",
      "[850]\ttraining's rmse: 0.0784621\tvalid_1's rmse: 0.0817764\n",
      "[875]\ttraining's rmse: 0.0784368\tvalid_1's rmse: 0.0817703\n",
      "[900]\ttraining's rmse: 0.0784106\tvalid_1's rmse: 0.0817641\n",
      "[925]\ttraining's rmse: 0.0783873\tvalid_1's rmse: 0.0817577\n",
      "[950]\ttraining's rmse: 0.0783635\tvalid_1's rmse: 0.0817513\n",
      "[975]\ttraining's rmse: 0.0783435\tvalid_1's rmse: 0.0817451\n",
      "[1000]\ttraining's rmse: 0.0783211\tvalid_1's rmse: 0.0817403\n",
      "[1025]\ttraining's rmse: 0.0783002\tvalid_1's rmse: 0.0817365\n",
      "[1050]\ttraining's rmse: 0.0782811\tvalid_1's rmse: 0.081731\n",
      "[1075]\ttraining's rmse: 0.0782623\tvalid_1's rmse: 0.0817273\n",
      "[1100]\ttraining's rmse: 0.078247\tvalid_1's rmse: 0.0817222\n",
      "[1125]\ttraining's rmse: 0.0782316\tvalid_1's rmse: 0.0817172\n",
      "[1150]\ttraining's rmse: 0.0782156\tvalid_1's rmse: 0.0817129\n",
      "[1175]\ttraining's rmse: 0.0782003\tvalid_1's rmse: 0.0817108\n",
      "[1200]\ttraining's rmse: 0.0781841\tvalid_1's rmse: 0.0817071\n",
      "[1225]\ttraining's rmse: 0.0781676\tvalid_1's rmse: 0.0817038\n",
      "[1250]\ttraining's rmse: 0.0781537\tvalid_1's rmse: 0.0817006\n",
      "[1275]\ttraining's rmse: 0.0781359\tvalid_1's rmse: 0.0816982\n",
      "[1300]\ttraining's rmse: 0.0781241\tvalid_1's rmse: 0.081694\n",
      "[1325]\ttraining's rmse: 0.0781115\tvalid_1's rmse: 0.0816915\n",
      "[1350]\ttraining's rmse: 0.0780967\tvalid_1's rmse: 0.0816882\n",
      "[1375]\ttraining's rmse: 0.0780841\tvalid_1's rmse: 0.0816848\n",
      "[1400]\ttraining's rmse: 0.0780763\tvalid_1's rmse: 0.0816814\n",
      "[1425]\ttraining's rmse: 0.0780634\tvalid_1's rmse: 0.0816796\n",
      "[1450]\ttraining's rmse: 0.0780523\tvalid_1's rmse: 0.0816776\n",
      "[1475]\ttraining's rmse: 0.0780422\tvalid_1's rmse: 0.081675\n",
      "[1500]\ttraining's rmse: 0.0780333\tvalid_1's rmse: 0.0816714\n",
      "[1525]\ttraining's rmse: 0.0780244\tvalid_1's rmse: 0.0816693\n",
      "[1550]\ttraining's rmse: 0.0780169\tvalid_1's rmse: 0.0816684\n",
      "[1575]\ttraining's rmse: 0.0780104\tvalid_1's rmse: 0.0816665\n",
      "[1600]\ttraining's rmse: 0.0780035\tvalid_1's rmse: 0.0816648\n",
      "[1625]\ttraining's rmse: 0.0779966\tvalid_1's rmse: 0.0816623\n",
      "[1650]\ttraining's rmse: 0.07799\tvalid_1's rmse: 0.0816607\n",
      "[1675]\ttraining's rmse: 0.0779847\tvalid_1's rmse: 0.0816589\n",
      "[1700]\ttraining's rmse: 0.0779796\tvalid_1's rmse: 0.0816573\n",
      "[1725]\ttraining's rmse: 0.0779741\tvalid_1's rmse: 0.0816559\n",
      "[1750]\ttraining's rmse: 0.0779679\tvalid_1's rmse: 0.081655\n",
      "[1775]\ttraining's rmse: 0.0779632\tvalid_1's rmse: 0.0816539\n",
      "[1800]\ttraining's rmse: 0.077959\tvalid_1's rmse: 0.0816527\n",
      "[1825]\ttraining's rmse: 0.0779541\tvalid_1's rmse: 0.0816512\n",
      "[1850]\ttraining's rmse: 0.07795\tvalid_1's rmse: 0.0816496\n",
      "[1875]\ttraining's rmse: 0.0779458\tvalid_1's rmse: 0.0816483\n",
      "[1900]\ttraining's rmse: 0.0779414\tvalid_1's rmse: 0.0816466\n",
      "[1925]\ttraining's rmse: 0.0779373\tvalid_1's rmse: 0.0816463\n",
      "[1950]\ttraining's rmse: 0.0779342\tvalid_1's rmse: 0.0816448\n",
      "[1975]\ttraining's rmse: 0.0779313\tvalid_1's rmse: 0.0816439\n",
      "[2000]\ttraining's rmse: 0.0779259\tvalid_1's rmse: 0.0816431\n",
      "[2025]\ttraining's rmse: 0.0779225\tvalid_1's rmse: 0.0816421\n",
      "[2050]\ttraining's rmse: 0.0779204\tvalid_1's rmse: 0.0816421\n",
      "[2075]\ttraining's rmse: 0.077918\tvalid_1's rmse: 0.0816409\n",
      "[2100]\ttraining's rmse: 0.077914\tvalid_1's rmse: 0.081641\n",
      "[2125]\ttraining's rmse: 0.0779102\tvalid_1's rmse: 0.0816405\n",
      "[2150]\ttraining's rmse: 0.0779079\tvalid_1's rmse: 0.0816397\n",
      "[2175]\ttraining's rmse: 0.0779049\tvalid_1's rmse: 0.0816394\n",
      "[2200]\ttraining's rmse: 0.077902\tvalid_1's rmse: 0.0816384\n",
      "[2225]\ttraining's rmse: 0.0778997\tvalid_1's rmse: 0.0816373\n",
      "[2250]\ttraining's rmse: 0.0778979\tvalid_1's rmse: 0.0816361\n",
      "[2275]\ttraining's rmse: 0.0778944\tvalid_1's rmse: 0.081635\n",
      "[2300]\ttraining's rmse: 0.0778911\tvalid_1's rmse: 0.081635\n",
      "[2325]\ttraining's rmse: 0.0778867\tvalid_1's rmse: 0.0816342\n",
      "[2350]\ttraining's rmse: 0.077884\tvalid_1's rmse: 0.0816335\n",
      "[2375]\ttraining's rmse: 0.0778823\tvalid_1's rmse: 0.0816329\n",
      "[2400]\ttraining's rmse: 0.077881\tvalid_1's rmse: 0.081633\n",
      "[2425]\ttraining's rmse: 0.0778778\tvalid_1's rmse: 0.0816329\n",
      "[2450]\ttraining's rmse: 0.0778764\tvalid_1's rmse: 0.0816325\n",
      "[2475]\ttraining's rmse: 0.0778748\tvalid_1's rmse: 0.0816315\n",
      "[2500]\ttraining's rmse: 0.0778728\tvalid_1's rmse: 0.0816311\n",
      "[2525]\ttraining's rmse: 0.0778711\tvalid_1's rmse: 0.0816307\n",
      "[2550]\ttraining's rmse: 0.0778688\tvalid_1's rmse: 0.0816305\n",
      "[2575]\ttraining's rmse: 0.0778666\tvalid_1's rmse: 0.0816303\n",
      "[2600]\ttraining's rmse: 0.0778632\tvalid_1's rmse: 0.0816301\n",
      "[2625]\ttraining's rmse: 0.0778616\tvalid_1's rmse: 0.0816293\n",
      "[2650]\ttraining's rmse: 0.0778601\tvalid_1's rmse: 0.0816289\n",
      "[2675]\ttraining's rmse: 0.0778574\tvalid_1's rmse: 0.0816278\n",
      "[2700]\ttraining's rmse: 0.0778558\tvalid_1's rmse: 0.0816272\n",
      "[2725]\ttraining's rmse: 0.0778536\tvalid_1's rmse: 0.0816266\n",
      "[2750]\ttraining's rmse: 0.0778521\tvalid_1's rmse: 0.0816262\n",
      "[2775]\ttraining's rmse: 0.07785\tvalid_1's rmse: 0.0816259\n",
      "[2800]\ttraining's rmse: 0.077848\tvalid_1's rmse: 0.0816258\n",
      "Early stopping, best iteration is:\n",
      "[2758]\ttraining's rmse: 0.0778508\tvalid_1's rmse: 0.0816257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0805146\tvalid_1's rmse: 0.0823633\n",
      "[50]\ttraining's rmse: 0.0804068\tvalid_1's rmse: 0.0823125\n",
      "[75]\ttraining's rmse: 0.0802974\tvalid_1's rmse: 0.0822621\n",
      "[100]\ttraining's rmse: 0.0801988\tvalid_1's rmse: 0.0822184\n",
      "[125]\ttraining's rmse: 0.080095\tvalid_1's rmse: 0.0821747\n",
      "[150]\ttraining's rmse: 0.080002\tvalid_1's rmse: 0.0821335\n",
      "[175]\ttraining's rmse: 0.079926\tvalid_1's rmse: 0.0820992\n",
      "[200]\ttraining's rmse: 0.0798401\tvalid_1's rmse: 0.0820631\n",
      "[225]\ttraining's rmse: 0.079756\tvalid_1's rmse: 0.0820293\n",
      "[250]\ttraining's rmse: 0.0796853\tvalid_1's rmse: 0.0819978\n",
      "[275]\ttraining's rmse: 0.0796217\tvalid_1's rmse: 0.0819687\n",
      "[300]\ttraining's rmse: 0.0795557\tvalid_1's rmse: 0.0819417\n",
      "[325]\ttraining's rmse: 0.0794872\tvalid_1's rmse: 0.0819157\n",
      "[350]\ttraining's rmse: 0.0794232\tvalid_1's rmse: 0.0818925\n",
      "[375]\ttraining's rmse: 0.0793723\tvalid_1's rmse: 0.0818724\n",
      "[400]\ttraining's rmse: 0.0793162\tvalid_1's rmse: 0.0818515\n",
      "[425]\ttraining's rmse: 0.079265\tvalid_1's rmse: 0.0818333\n",
      "[450]\ttraining's rmse: 0.0792173\tvalid_1's rmse: 0.0818151\n",
      "[475]\ttraining's rmse: 0.0791741\tvalid_1's rmse: 0.0817992\n",
      "[500]\ttraining's rmse: 0.0791353\tvalid_1's rmse: 0.081782\n",
      "[525]\ttraining's rmse: 0.0790871\tvalid_1's rmse: 0.0817658\n",
      "[550]\ttraining's rmse: 0.0790422\tvalid_1's rmse: 0.0817511\n",
      "[575]\ttraining's rmse: 0.0790019\tvalid_1's rmse: 0.0817374\n",
      "[600]\ttraining's rmse: 0.0789625\tvalid_1's rmse: 0.0817249\n",
      "[625]\ttraining's rmse: 0.0789304\tvalid_1's rmse: 0.0817125\n",
      "[650]\ttraining's rmse: 0.0788912\tvalid_1's rmse: 0.0817004\n",
      "[675]\ttraining's rmse: 0.0788546\tvalid_1's rmse: 0.0816888\n",
      "[700]\ttraining's rmse: 0.0788195\tvalid_1's rmse: 0.0816773\n",
      "[725]\ttraining's rmse: 0.0787862\tvalid_1's rmse: 0.081668\n",
      "[750]\ttraining's rmse: 0.0787555\tvalid_1's rmse: 0.0816596\n",
      "[775]\ttraining's rmse: 0.0787316\tvalid_1's rmse: 0.0816503\n",
      "[800]\ttraining's rmse: 0.078699\tvalid_1's rmse: 0.081642\n",
      "[825]\ttraining's rmse: 0.0786727\tvalid_1's rmse: 0.0816335\n",
      "[850]\ttraining's rmse: 0.0786447\tvalid_1's rmse: 0.0816258\n",
      "[875]\ttraining's rmse: 0.0786218\tvalid_1's rmse: 0.0816195\n",
      "[900]\ttraining's rmse: 0.0785936\tvalid_1's rmse: 0.0816114\n",
      "[925]\ttraining's rmse: 0.0785695\tvalid_1's rmse: 0.0816054\n",
      "[950]\ttraining's rmse: 0.078547\tvalid_1's rmse: 0.0815993\n",
      "[975]\ttraining's rmse: 0.0785272\tvalid_1's rmse: 0.0815934\n",
      "[1000]\ttraining's rmse: 0.0785053\tvalid_1's rmse: 0.0815883\n",
      "[1025]\ttraining's rmse: 0.0784832\tvalid_1's rmse: 0.0815834\n",
      "[1050]\ttraining's rmse: 0.0784639\tvalid_1's rmse: 0.0815782\n",
      "[1075]\ttraining's rmse: 0.0784463\tvalid_1's rmse: 0.081574\n",
      "[1100]\ttraining's rmse: 0.0784301\tvalid_1's rmse: 0.08157\n",
      "[1125]\ttraining's rmse: 0.0784136\tvalid_1's rmse: 0.0815661\n",
      "[1150]\ttraining's rmse: 0.0783945\tvalid_1's rmse: 0.0815613\n",
      "[1175]\ttraining's rmse: 0.0783792\tvalid_1's rmse: 0.0815581\n",
      "[1200]\ttraining's rmse: 0.0783641\tvalid_1's rmse: 0.0815545\n",
      "[1225]\ttraining's rmse: 0.0783461\tvalid_1's rmse: 0.0815505\n",
      "[1250]\ttraining's rmse: 0.0783343\tvalid_1's rmse: 0.081548\n",
      "[1275]\ttraining's rmse: 0.0783196\tvalid_1's rmse: 0.0815448\n",
      "[1300]\ttraining's rmse: 0.0783085\tvalid_1's rmse: 0.0815424\n",
      "[1325]\ttraining's rmse: 0.0782983\tvalid_1's rmse: 0.0815406\n",
      "[1350]\ttraining's rmse: 0.0782852\tvalid_1's rmse: 0.0815387\n",
      "[1375]\ttraining's rmse: 0.0782732\tvalid_1's rmse: 0.0815368\n",
      "[1400]\ttraining's rmse: 0.0782632\tvalid_1's rmse: 0.0815344\n",
      "[1425]\ttraining's rmse: 0.0782518\tvalid_1's rmse: 0.0815323\n",
      "[1450]\ttraining's rmse: 0.0782408\tvalid_1's rmse: 0.0815304\n",
      "[1475]\ttraining's rmse: 0.0782324\tvalid_1's rmse: 0.081529\n",
      "[1500]\ttraining's rmse: 0.078224\tvalid_1's rmse: 0.0815273\n",
      "[1525]\ttraining's rmse: 0.0782163\tvalid_1's rmse: 0.0815259\n",
      "[1550]\ttraining's rmse: 0.078209\tvalid_1's rmse: 0.0815247\n",
      "[1575]\ttraining's rmse: 0.0782017\tvalid_1's rmse: 0.0815234\n",
      "[1600]\ttraining's rmse: 0.078194\tvalid_1's rmse: 0.0815226\n",
      "[1625]\ttraining's rmse: 0.0781859\tvalid_1's rmse: 0.0815209\n",
      "[1650]\ttraining's rmse: 0.0781793\tvalid_1's rmse: 0.0815197\n",
      "[1675]\ttraining's rmse: 0.0781752\tvalid_1's rmse: 0.0815184\n",
      "[1700]\ttraining's rmse: 0.0781687\tvalid_1's rmse: 0.0815174\n",
      "[1725]\ttraining's rmse: 0.0781636\tvalid_1's rmse: 0.0815161\n",
      "[1750]\ttraining's rmse: 0.0781567\tvalid_1's rmse: 0.0815157\n",
      "[1775]\ttraining's rmse: 0.0781499\tvalid_1's rmse: 0.0815151\n",
      "[1800]\ttraining's rmse: 0.0781458\tvalid_1's rmse: 0.0815145\n",
      "[1825]\ttraining's rmse: 0.0781413\tvalid_1's rmse: 0.0815139\n",
      "[1850]\ttraining's rmse: 0.0781372\tvalid_1's rmse: 0.0815134\n",
      "[1875]\ttraining's rmse: 0.0781331\tvalid_1's rmse: 0.0815134\n",
      "[1900]\ttraining's rmse: 0.07813\tvalid_1's rmse: 0.0815131\n",
      "[1925]\ttraining's rmse: 0.078126\tvalid_1's rmse: 0.0815126\n",
      "[1950]\ttraining's rmse: 0.0781227\tvalid_1's rmse: 0.0815118\n",
      "[1975]\ttraining's rmse: 0.0781181\tvalid_1's rmse: 0.0815114\n",
      "[2000]\ttraining's rmse: 0.0781144\tvalid_1's rmse: 0.0815106\n",
      "[2025]\ttraining's rmse: 0.0781108\tvalid_1's rmse: 0.0815102\n",
      "[2050]\ttraining's rmse: 0.0781081\tvalid_1's rmse: 0.0815099\n",
      "[2075]\ttraining's rmse: 0.0781048\tvalid_1's rmse: 0.081509\n",
      "[2100]\ttraining's rmse: 0.0781009\tvalid_1's rmse: 0.0815083\n",
      "[2125]\ttraining's rmse: 0.0780983\tvalid_1's rmse: 0.0815081\n",
      "[2150]\ttraining's rmse: 0.0780948\tvalid_1's rmse: 0.0815078\n",
      "[2175]\ttraining's rmse: 0.0780925\tvalid_1's rmse: 0.081508\n",
      "[2200]\ttraining's rmse: 0.0780904\tvalid_1's rmse: 0.0815077\n",
      "[2225]\ttraining's rmse: 0.0780864\tvalid_1's rmse: 0.0815073\n",
      "[2250]\ttraining's rmse: 0.0780836\tvalid_1's rmse: 0.0815072\n",
      "[2275]\ttraining's rmse: 0.0780806\tvalid_1's rmse: 0.0815068\n",
      "[2300]\ttraining's rmse: 0.0780785\tvalid_1's rmse: 0.0815064\n",
      "[2325]\ttraining's rmse: 0.0780762\tvalid_1's rmse: 0.0815058\n",
      "[2350]\ttraining's rmse: 0.0780744\tvalid_1's rmse: 0.0815055\n",
      "[2375]\ttraining's rmse: 0.0780726\tvalid_1's rmse: 0.0815052\n",
      "[2400]\ttraining's rmse: 0.0780703\tvalid_1's rmse: 0.0815052\n",
      "[2425]\ttraining's rmse: 0.0780675\tvalid_1's rmse: 0.0815046\n",
      "[2450]\ttraining's rmse: 0.0780642\tvalid_1's rmse: 0.0815043\n",
      "[2475]\ttraining's rmse: 0.0780616\tvalid_1's rmse: 0.0815044\n",
      "[2500]\ttraining's rmse: 0.0780585\tvalid_1's rmse: 0.0815041\n",
      "[2525]\ttraining's rmse: 0.0780557\tvalid_1's rmse: 0.0815038\n",
      "[2550]\ttraining's rmse: 0.0780531\tvalid_1's rmse: 0.0815037\n",
      "[2575]\ttraining's rmse: 0.0780509\tvalid_1's rmse: 0.0815035\n",
      "[2600]\ttraining's rmse: 0.0780493\tvalid_1's rmse: 0.0815033\n",
      "[2625]\ttraining's rmse: 0.0780479\tvalid_1's rmse: 0.0815031\n",
      "[2650]\ttraining's rmse: 0.0780465\tvalid_1's rmse: 0.081503\n",
      "[2675]\ttraining's rmse: 0.0780447\tvalid_1's rmse: 0.0815028\n",
      "[2700]\ttraining's rmse: 0.0780433\tvalid_1's rmse: 0.0815027\n",
      "[2725]\ttraining's rmse: 0.0780406\tvalid_1's rmse: 0.0815028\n",
      "Early stopping, best iteration is:\n",
      "[2691]\ttraining's rmse: 0.0780438\tvalid_1's rmse: 0.0815026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0822872\tvalid_1's rmse: 0.0787605\n",
      "[50]\ttraining's rmse: 0.0821838\tvalid_1's rmse: 0.0787137\n",
      "[75]\ttraining's rmse: 0.0820726\tvalid_1's rmse: 0.078667\n",
      "[100]\ttraining's rmse: 0.0819764\tvalid_1's rmse: 0.0786255\n",
      "[125]\ttraining's rmse: 0.081874\tvalid_1's rmse: 0.0785841\n",
      "[150]\ttraining's rmse: 0.0817803\tvalid_1's rmse: 0.0785464\n",
      "[175]\ttraining's rmse: 0.0817029\tvalid_1's rmse: 0.078515\n",
      "[200]\ttraining's rmse: 0.0816192\tvalid_1's rmse: 0.0784846\n",
      "[225]\ttraining's rmse: 0.081537\tvalid_1's rmse: 0.078455\n",
      "[250]\ttraining's rmse: 0.0814683\tvalid_1's rmse: 0.0784291\n",
      "[275]\ttraining's rmse: 0.0814058\tvalid_1's rmse: 0.078404\n",
      "[300]\ttraining's rmse: 0.0813425\tvalid_1's rmse: 0.0783824\n",
      "[325]\ttraining's rmse: 0.0812801\tvalid_1's rmse: 0.0783596\n",
      "[350]\ttraining's rmse: 0.0812195\tvalid_1's rmse: 0.0783387\n",
      "[375]\ttraining's rmse: 0.081169\tvalid_1's rmse: 0.0783219\n",
      "[400]\ttraining's rmse: 0.0811113\tvalid_1's rmse: 0.0783046\n",
      "[425]\ttraining's rmse: 0.0810619\tvalid_1's rmse: 0.0782911\n",
      "[450]\ttraining's rmse: 0.0810133\tvalid_1's rmse: 0.0782753\n",
      "[475]\ttraining's rmse: 0.0809696\tvalid_1's rmse: 0.0782653\n",
      "[500]\ttraining's rmse: 0.0809315\tvalid_1's rmse: 0.0782524\n",
      "[525]\ttraining's rmse: 0.0808837\tvalid_1's rmse: 0.0782396\n",
      "[550]\ttraining's rmse: 0.0808387\tvalid_1's rmse: 0.0782281\n",
      "[575]\ttraining's rmse: 0.0807964\tvalid_1's rmse: 0.0782184\n",
      "[600]\ttraining's rmse: 0.0807567\tvalid_1's rmse: 0.078209\n",
      "[625]\ttraining's rmse: 0.0807242\tvalid_1's rmse: 0.0782002\n",
      "[650]\ttraining's rmse: 0.0806863\tvalid_1's rmse: 0.0781959\n",
      "[675]\ttraining's rmse: 0.0806474\tvalid_1's rmse: 0.0781899\n",
      "[700]\ttraining's rmse: 0.080613\tvalid_1's rmse: 0.0781824\n",
      "[725]\ttraining's rmse: 0.0805828\tvalid_1's rmse: 0.0781813\n",
      "[750]\ttraining's rmse: 0.0805518\tvalid_1's rmse: 0.0781807\n",
      "[775]\ttraining's rmse: 0.0805277\tvalid_1's rmse: 0.078177\n",
      "[800]\ttraining's rmse: 0.0804956\tvalid_1's rmse: 0.0781714\n",
      "[825]\ttraining's rmse: 0.0804674\tvalid_1's rmse: 0.0781699\n",
      "[850]\ttraining's rmse: 0.0804388\tvalid_1's rmse: 0.0781641\n",
      "[875]\ttraining's rmse: 0.0804134\tvalid_1's rmse: 0.0781624\n",
      "[900]\ttraining's rmse: 0.0803859\tvalid_1's rmse: 0.0781575\n",
      "[925]\ttraining's rmse: 0.0803615\tvalid_1's rmse: 0.0781586\n",
      "[950]\ttraining's rmse: 0.0803372\tvalid_1's rmse: 0.078155\n",
      "[975]\ttraining's rmse: 0.0803134\tvalid_1's rmse: 0.0781671\n",
      "[1000]\ttraining's rmse: 0.0802919\tvalid_1's rmse: 0.0781691\n",
      "Early stopping, best iteration is:\n",
      "[962]\ttraining's rmse: 0.0803247\tvalid_1's rmse: 0.0781531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0779513\tvalid_1's rmse: 0.0804823\n",
      "[50]\ttraining's rmse: 0.0778397\tvalid_1's rmse: 0.0804322\n",
      "[75]\ttraining's rmse: 0.0777302\tvalid_1's rmse: 0.0803827\n",
      "[100]\ttraining's rmse: 0.0776284\tvalid_1's rmse: 0.0803393\n",
      "[125]\ttraining's rmse: 0.0775241\tvalid_1's rmse: 0.0802957\n",
      "[150]\ttraining's rmse: 0.0774328\tvalid_1's rmse: 0.0802557\n",
      "[175]\ttraining's rmse: 0.0773581\tvalid_1's rmse: 0.0802203\n",
      "[200]\ttraining's rmse: 0.0772756\tvalid_1's rmse: 0.0801847\n",
      "[225]\ttraining's rmse: 0.0771929\tvalid_1's rmse: 0.0801522\n",
      "[250]\ttraining's rmse: 0.0771259\tvalid_1's rmse: 0.0801235\n",
      "[275]\ttraining's rmse: 0.0770614\tvalid_1's rmse: 0.0800961\n",
      "[300]\ttraining's rmse: 0.076997\tvalid_1's rmse: 0.0800679\n",
      "[325]\ttraining's rmse: 0.0769303\tvalid_1's rmse: 0.0800423\n",
      "[350]\ttraining's rmse: 0.0768697\tvalid_1's rmse: 0.0800186\n",
      "[375]\ttraining's rmse: 0.0768199\tvalid_1's rmse: 0.079998\n",
      "[400]\ttraining's rmse: 0.0767636\tvalid_1's rmse: 0.0799775\n",
      "[425]\ttraining's rmse: 0.0767157\tvalid_1's rmse: 0.0799604\n",
      "[450]\ttraining's rmse: 0.0766706\tvalid_1's rmse: 0.0799421\n",
      "[475]\ttraining's rmse: 0.0766321\tvalid_1's rmse: 0.0799257\n",
      "[500]\ttraining's rmse: 0.0765975\tvalid_1's rmse: 0.0799087\n",
      "[525]\ttraining's rmse: 0.0765514\tvalid_1's rmse: 0.0798925\n",
      "[550]\ttraining's rmse: 0.0765108\tvalid_1's rmse: 0.0798778\n",
      "[575]\ttraining's rmse: 0.0764739\tvalid_1's rmse: 0.0798645\n",
      "[600]\ttraining's rmse: 0.0764363\tvalid_1's rmse: 0.0798513\n",
      "[625]\ttraining's rmse: 0.0764055\tvalid_1's rmse: 0.0798412\n",
      "[650]\ttraining's rmse: 0.0763686\tvalid_1's rmse: 0.0798292\n",
      "[675]\ttraining's rmse: 0.0763324\tvalid_1's rmse: 0.079817\n",
      "[700]\ttraining's rmse: 0.0763021\tvalid_1's rmse: 0.0798057\n",
      "[725]\ttraining's rmse: 0.0762715\tvalid_1's rmse: 0.0797961\n",
      "[750]\ttraining's rmse: 0.0762455\tvalid_1's rmse: 0.0797864\n",
      "[775]\ttraining's rmse: 0.076221\tvalid_1's rmse: 0.0797773\n",
      "[800]\ttraining's rmse: 0.0761944\tvalid_1's rmse: 0.0797701\n",
      "[825]\ttraining's rmse: 0.076172\tvalid_1's rmse: 0.0797614\n",
      "[850]\ttraining's rmse: 0.0761465\tvalid_1's rmse: 0.0797541\n",
      "[875]\ttraining's rmse: 0.0761235\tvalid_1's rmse: 0.0797463\n",
      "[900]\ttraining's rmse: 0.0760979\tvalid_1's rmse: 0.0797387\n",
      "[925]\ttraining's rmse: 0.0760774\tvalid_1's rmse: 0.079732\n",
      "[950]\ttraining's rmse: 0.0760593\tvalid_1's rmse: 0.0797251\n",
      "[975]\ttraining's rmse: 0.0760373\tvalid_1's rmse: 0.0797184\n",
      "[1000]\ttraining's rmse: 0.0760151\tvalid_1's rmse: 0.0797125\n",
      "[1025]\ttraining's rmse: 0.0759957\tvalid_1's rmse: 0.0797061\n",
      "[1050]\ttraining's rmse: 0.0759785\tvalid_1's rmse: 0.0797006\n",
      "[1075]\ttraining's rmse: 0.0759632\tvalid_1's rmse: 0.0796964\n",
      "[1100]\ttraining's rmse: 0.0759497\tvalid_1's rmse: 0.0796911\n",
      "[1125]\ttraining's rmse: 0.075936\tvalid_1's rmse: 0.0796862\n",
      "[1150]\ttraining's rmse: 0.075921\tvalid_1's rmse: 0.079682\n",
      "[1175]\ttraining's rmse: 0.0759075\tvalid_1's rmse: 0.0796783\n",
      "[1200]\ttraining's rmse: 0.0758935\tvalid_1's rmse: 0.079674\n",
      "[1225]\ttraining's rmse: 0.0758804\tvalid_1's rmse: 0.0796704\n",
      "[1250]\ttraining's rmse: 0.0758657\tvalid_1's rmse: 0.0796665\n",
      "[1275]\ttraining's rmse: 0.0758502\tvalid_1's rmse: 0.079663\n",
      "[1300]\ttraining's rmse: 0.075841\tvalid_1's rmse: 0.0796589\n",
      "[1325]\ttraining's rmse: 0.0758268\tvalid_1's rmse: 0.0796555\n",
      "[1350]\ttraining's rmse: 0.0758122\tvalid_1's rmse: 0.0796521\n",
      "[1375]\ttraining's rmse: 0.0758028\tvalid_1's rmse: 0.0796486\n",
      "[1400]\ttraining's rmse: 0.0757947\tvalid_1's rmse: 0.0796459\n",
      "[1425]\ttraining's rmse: 0.0757851\tvalid_1's rmse: 0.0796431\n",
      "[1450]\ttraining's rmse: 0.0757748\tvalid_1's rmse: 0.0796414\n",
      "[1475]\ttraining's rmse: 0.0757659\tvalid_1's rmse: 0.0796383\n",
      "[1500]\ttraining's rmse: 0.0757575\tvalid_1's rmse: 0.0796349\n",
      "[1525]\ttraining's rmse: 0.0757499\tvalid_1's rmse: 0.0796321\n",
      "[1550]\ttraining's rmse: 0.0757436\tvalid_1's rmse: 0.0796299\n",
      "[1575]\ttraining's rmse: 0.0757379\tvalid_1's rmse: 0.0796277\n",
      "[1600]\ttraining's rmse: 0.0757319\tvalid_1's rmse: 0.0796259\n",
      "[1625]\ttraining's rmse: 0.0757269\tvalid_1's rmse: 0.0796228\n",
      "[1650]\ttraining's rmse: 0.0757213\tvalid_1's rmse: 0.0796208\n",
      "[1675]\ttraining's rmse: 0.0757161\tvalid_1's rmse: 0.0796191\n",
      "[1700]\ttraining's rmse: 0.0757094\tvalid_1's rmse: 0.0796177\n",
      "[1725]\ttraining's rmse: 0.0757038\tvalid_1's rmse: 0.0796156\n",
      "[1750]\ttraining's rmse: 0.0756997\tvalid_1's rmse: 0.0796145\n",
      "[1775]\ttraining's rmse: 0.0756963\tvalid_1's rmse: 0.0796125\n",
      "[1800]\ttraining's rmse: 0.0756928\tvalid_1's rmse: 0.0796114\n",
      "[1825]\ttraining's rmse: 0.0756879\tvalid_1's rmse: 0.0796095\n",
      "[1850]\ttraining's rmse: 0.0756826\tvalid_1's rmse: 0.0796069\n",
      "[1875]\ttraining's rmse: 0.0756784\tvalid_1's rmse: 0.0796058\n",
      "[1900]\ttraining's rmse: 0.075674\tvalid_1's rmse: 0.0796044\n",
      "[1925]\ttraining's rmse: 0.0756695\tvalid_1's rmse: 0.0796034\n",
      "[1950]\ttraining's rmse: 0.0756655\tvalid_1's rmse: 0.0796016\n",
      "[1975]\ttraining's rmse: 0.075663\tvalid_1's rmse: 0.0796004\n",
      "[2000]\ttraining's rmse: 0.0756589\tvalid_1's rmse: 0.0795995\n",
      "[2025]\ttraining's rmse: 0.0756555\tvalid_1's rmse: 0.0795985\n",
      "[2050]\ttraining's rmse: 0.0756516\tvalid_1's rmse: 0.0795978\n",
      "[2075]\ttraining's rmse: 0.0756492\tvalid_1's rmse: 0.0795962\n",
      "[2100]\ttraining's rmse: 0.0756465\tvalid_1's rmse: 0.079595\n",
      "[2125]\ttraining's rmse: 0.0756447\tvalid_1's rmse: 0.0795951\n",
      "[2150]\ttraining's rmse: 0.0756397\tvalid_1's rmse: 0.079594\n",
      "[2175]\ttraining's rmse: 0.075638\tvalid_1's rmse: 0.0795933\n",
      "[2200]\ttraining's rmse: 0.0756353\tvalid_1's rmse: 0.0795925\n",
      "[2225]\ttraining's rmse: 0.0756333\tvalid_1's rmse: 0.0795918\n",
      "[2250]\ttraining's rmse: 0.0756307\tvalid_1's rmse: 0.0795908\n",
      "[2275]\ttraining's rmse: 0.0756278\tvalid_1's rmse: 0.0795903\n",
      "[2300]\ttraining's rmse: 0.0756263\tvalid_1's rmse: 0.0795898\n",
      "[2325]\ttraining's rmse: 0.0756245\tvalid_1's rmse: 0.0795894\n",
      "[2350]\ttraining's rmse: 0.0756223\tvalid_1's rmse: 0.0795886\n",
      "[2375]\ttraining's rmse: 0.0756202\tvalid_1's rmse: 0.0795867\n",
      "[2400]\ttraining's rmse: 0.0756173\tvalid_1's rmse: 0.0795864\n",
      "[2425]\ttraining's rmse: 0.0756151\tvalid_1's rmse: 0.0795859\n",
      "[2450]\ttraining's rmse: 0.0756121\tvalid_1's rmse: 0.0795853\n",
      "[2475]\ttraining's rmse: 0.075609\tvalid_1's rmse: 0.0795851\n",
      "[2500]\ttraining's rmse: 0.0756071\tvalid_1's rmse: 0.0795852\n",
      "[2525]\ttraining's rmse: 0.0756052\tvalid_1's rmse: 0.0795845\n",
      "[2550]\ttraining's rmse: 0.0756024\tvalid_1's rmse: 0.0795838\n",
      "[2575]\ttraining's rmse: 0.0756008\tvalid_1's rmse: 0.0795833\n",
      "[2600]\ttraining's rmse: 0.0755988\tvalid_1's rmse: 0.079583\n",
      "[2625]\ttraining's rmse: 0.0755978\tvalid_1's rmse: 0.0795827\n",
      "[2650]\ttraining's rmse: 0.0755967\tvalid_1's rmse: 0.0795822\n",
      "[2675]\ttraining's rmse: 0.0755954\tvalid_1's rmse: 0.0795822\n",
      "[2700]\ttraining's rmse: 0.0755935\tvalid_1's rmse: 0.0795819\n",
      "[2725]\ttraining's rmse: 0.0755923\tvalid_1's rmse: 0.0795822\n",
      "[2750]\ttraining's rmse: 0.0755896\tvalid_1's rmse: 0.0795822\n",
      "Early stopping, best iteration is:\n",
      "[2701]\ttraining's rmse: 0.0755934\tvalid_1's rmse: 0.0795819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0782514\tvalid_1's rmse: 0.079905\n",
      "[50]\ttraining's rmse: 0.0781466\tvalid_1's rmse: 0.0798516\n",
      "[75]\ttraining's rmse: 0.0780407\tvalid_1's rmse: 0.0798001\n",
      "[100]\ttraining's rmse: 0.0779477\tvalid_1's rmse: 0.0797549\n",
      "[125]\ttraining's rmse: 0.0778501\tvalid_1's rmse: 0.0797092\n",
      "[150]\ttraining's rmse: 0.0777625\tvalid_1's rmse: 0.0796682\n",
      "[175]\ttraining's rmse: 0.0776904\tvalid_1's rmse: 0.0796331\n",
      "[200]\ttraining's rmse: 0.077608\tvalid_1's rmse: 0.0795978\n",
      "[225]\ttraining's rmse: 0.0775303\tvalid_1's rmse: 0.0795647\n",
      "[250]\ttraining's rmse: 0.0774648\tvalid_1's rmse: 0.0795351\n",
      "[275]\ttraining's rmse: 0.077403\tvalid_1's rmse: 0.0795085\n",
      "[300]\ttraining's rmse: 0.0773419\tvalid_1's rmse: 0.0794823\n",
      "[325]\ttraining's rmse: 0.077278\tvalid_1's rmse: 0.0794562\n",
      "[350]\ttraining's rmse: 0.0772174\tvalid_1's rmse: 0.0794323\n",
      "[375]\ttraining's rmse: 0.077168\tvalid_1's rmse: 0.0794115\n",
      "[400]\ttraining's rmse: 0.0771149\tvalid_1's rmse: 0.0793923\n",
      "[425]\ttraining's rmse: 0.0770649\tvalid_1's rmse: 0.0793726\n",
      "[450]\ttraining's rmse: 0.077019\tvalid_1's rmse: 0.0793551\n",
      "[475]\ttraining's rmse: 0.076977\tvalid_1's rmse: 0.0793383\n",
      "[500]\ttraining's rmse: 0.0769417\tvalid_1's rmse: 0.0793236\n",
      "[525]\ttraining's rmse: 0.0768964\tvalid_1's rmse: 0.0793086\n",
      "[550]\ttraining's rmse: 0.0768532\tvalid_1's rmse: 0.0792926\n",
      "[575]\ttraining's rmse: 0.0768146\tvalid_1's rmse: 0.0792803\n",
      "[600]\ttraining's rmse: 0.0767761\tvalid_1's rmse: 0.0792676\n",
      "[625]\ttraining's rmse: 0.0767469\tvalid_1's rmse: 0.0792573\n",
      "[650]\ttraining's rmse: 0.0767083\tvalid_1's rmse: 0.0792452\n",
      "[675]\ttraining's rmse: 0.076672\tvalid_1's rmse: 0.0792343\n",
      "[700]\ttraining's rmse: 0.0766381\tvalid_1's rmse: 0.0792242\n",
      "[725]\ttraining's rmse: 0.0766083\tvalid_1's rmse: 0.0792151\n",
      "[750]\ttraining's rmse: 0.0765789\tvalid_1's rmse: 0.0792067\n",
      "[775]\ttraining's rmse: 0.076556\tvalid_1's rmse: 0.0791988\n",
      "[800]\ttraining's rmse: 0.0765256\tvalid_1's rmse: 0.079191\n",
      "[825]\ttraining's rmse: 0.0765008\tvalid_1's rmse: 0.0791833\n",
      "[850]\ttraining's rmse: 0.0764762\tvalid_1's rmse: 0.0791767\n",
      "[875]\ttraining's rmse: 0.0764511\tvalid_1's rmse: 0.0791698\n",
      "[900]\ttraining's rmse: 0.0764264\tvalid_1's rmse: 0.0791627\n",
      "[925]\ttraining's rmse: 0.0764036\tvalid_1's rmse: 0.0791568\n",
      "[950]\ttraining's rmse: 0.0763834\tvalid_1's rmse: 0.0791515\n",
      "[975]\ttraining's rmse: 0.0763635\tvalid_1's rmse: 0.0791463\n",
      "[1000]\ttraining's rmse: 0.0763434\tvalid_1's rmse: 0.0791414\n",
      "[1025]\ttraining's rmse: 0.0763231\tvalid_1's rmse: 0.0791369\n",
      "[1050]\ttraining's rmse: 0.0763066\tvalid_1's rmse: 0.0791323\n",
      "[1075]\ttraining's rmse: 0.0762879\tvalid_1's rmse: 0.0791288\n",
      "[1100]\ttraining's rmse: 0.0762743\tvalid_1's rmse: 0.0791249\n",
      "[1125]\ttraining's rmse: 0.0762584\tvalid_1's rmse: 0.0791209\n",
      "[1150]\ttraining's rmse: 0.0762411\tvalid_1's rmse: 0.0791176\n",
      "[1175]\ttraining's rmse: 0.0762286\tvalid_1's rmse: 0.0791152\n",
      "[1200]\ttraining's rmse: 0.0762145\tvalid_1's rmse: 0.0791124\n",
      "[1225]\ttraining's rmse: 0.0762029\tvalid_1's rmse: 0.0791096\n",
      "[1250]\ttraining's rmse: 0.0761903\tvalid_1's rmse: 0.0791061\n",
      "[1275]\ttraining's rmse: 0.0761762\tvalid_1's rmse: 0.0791033\n",
      "[1300]\ttraining's rmse: 0.0761652\tvalid_1's rmse: 0.0791007\n",
      "[1325]\ttraining's rmse: 0.0761547\tvalid_1's rmse: 0.0790984\n",
      "[1350]\ttraining's rmse: 0.0761425\tvalid_1's rmse: 0.0790965\n",
      "[1375]\ttraining's rmse: 0.0761321\tvalid_1's rmse: 0.0790949\n",
      "[1400]\ttraining's rmse: 0.0761224\tvalid_1's rmse: 0.0790925\n",
      "[1425]\ttraining's rmse: 0.0761104\tvalid_1's rmse: 0.0790912\n",
      "[1450]\ttraining's rmse: 0.0761003\tvalid_1's rmse: 0.0790887\n",
      "[1475]\ttraining's rmse: 0.0760918\tvalid_1's rmse: 0.0790873\n",
      "[1500]\ttraining's rmse: 0.0760853\tvalid_1's rmse: 0.079086\n",
      "[1525]\ttraining's rmse: 0.0760766\tvalid_1's rmse: 0.079085\n",
      "[1550]\ttraining's rmse: 0.0760678\tvalid_1's rmse: 0.0790842\n",
      "[1575]\ttraining's rmse: 0.0760617\tvalid_1's rmse: 0.0790828\n",
      "[1600]\ttraining's rmse: 0.0760553\tvalid_1's rmse: 0.0790818\n",
      "[1625]\ttraining's rmse: 0.0760477\tvalid_1's rmse: 0.0790807\n",
      "[1650]\ttraining's rmse: 0.0760422\tvalid_1's rmse: 0.0790796\n",
      "[1675]\ttraining's rmse: 0.0760376\tvalid_1's rmse: 0.0790788\n",
      "[1700]\ttraining's rmse: 0.0760333\tvalid_1's rmse: 0.0790779\n",
      "[1725]\ttraining's rmse: 0.0760285\tvalid_1's rmse: 0.079077\n",
      "[1750]\ttraining's rmse: 0.0760227\tvalid_1's rmse: 0.0790758\n",
      "[1775]\ttraining's rmse: 0.0760189\tvalid_1's rmse: 0.0790754\n",
      "[1800]\ttraining's rmse: 0.0760134\tvalid_1's rmse: 0.0790747\n",
      "[1825]\ttraining's rmse: 0.0760068\tvalid_1's rmse: 0.0790741\n",
      "[1850]\ttraining's rmse: 0.0760004\tvalid_1's rmse: 0.0790729\n",
      "[1875]\ttraining's rmse: 0.0759966\tvalid_1's rmse: 0.0790726\n",
      "[1900]\ttraining's rmse: 0.0759928\tvalid_1's rmse: 0.0790726\n",
      "[1925]\ttraining's rmse: 0.0759896\tvalid_1's rmse: 0.079072\n",
      "[1950]\ttraining's rmse: 0.0759868\tvalid_1's rmse: 0.0790716\n",
      "[1975]\ttraining's rmse: 0.0759834\tvalid_1's rmse: 0.0790709\n",
      "[2000]\ttraining's rmse: 0.0759801\tvalid_1's rmse: 0.0790702\n",
      "[2025]\ttraining's rmse: 0.0759774\tvalid_1's rmse: 0.0790698\n",
      "[2050]\ttraining's rmse: 0.075974\tvalid_1's rmse: 0.0790691\n",
      "[2075]\ttraining's rmse: 0.075971\tvalid_1's rmse: 0.0790688\n",
      "[2100]\ttraining's rmse: 0.0759685\tvalid_1's rmse: 0.0790683\n",
      "[2125]\ttraining's rmse: 0.0759662\tvalid_1's rmse: 0.0790682\n",
      "[2150]\ttraining's rmse: 0.0759624\tvalid_1's rmse: 0.0790679\n",
      "[2175]\ttraining's rmse: 0.0759582\tvalid_1's rmse: 0.0790679\n",
      "[2200]\ttraining's rmse: 0.0759561\tvalid_1's rmse: 0.0790676\n",
      "[2225]\ttraining's rmse: 0.0759539\tvalid_1's rmse: 0.0790672\n",
      "[2250]\ttraining's rmse: 0.0759511\tvalid_1's rmse: 0.0790669\n",
      "[2275]\ttraining's rmse: 0.075948\tvalid_1's rmse: 0.0790663\n",
      "[2300]\ttraining's rmse: 0.0759456\tvalid_1's rmse: 0.079066\n",
      "[2325]\ttraining's rmse: 0.0759438\tvalid_1's rmse: 0.079066\n",
      "[2350]\ttraining's rmse: 0.0759419\tvalid_1's rmse: 0.0790659\n",
      "[2375]\ttraining's rmse: 0.0759397\tvalid_1's rmse: 0.0790655\n",
      "[2400]\ttraining's rmse: 0.0759372\tvalid_1's rmse: 0.079066\n",
      "[2425]\ttraining's rmse: 0.0759355\tvalid_1's rmse: 0.0790659\n",
      "Early stopping, best iteration is:\n",
      "[2377]\ttraining's rmse: 0.0759397\tvalid_1's rmse: 0.0790655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.080085\tvalid_1's rmse: 0.0761662\n",
      "[50]\ttraining's rmse: 0.0799838\tvalid_1's rmse: 0.0761187\n",
      "[75]\ttraining's rmse: 0.0798813\tvalid_1's rmse: 0.0760733\n",
      "[100]\ttraining's rmse: 0.0797863\tvalid_1's rmse: 0.0760336\n",
      "[125]\ttraining's rmse: 0.0796906\tvalid_1's rmse: 0.0759948\n",
      "[150]\ttraining's rmse: 0.0796004\tvalid_1's rmse: 0.0759595\n",
      "[175]\ttraining's rmse: 0.0795301\tvalid_1's rmse: 0.0759314\n",
      "[200]\ttraining's rmse: 0.0794526\tvalid_1's rmse: 0.0759032\n",
      "[225]\ttraining's rmse: 0.0793762\tvalid_1's rmse: 0.0758784\n",
      "[250]\ttraining's rmse: 0.0793143\tvalid_1's rmse: 0.0758548\n",
      "[275]\ttraining's rmse: 0.0792529\tvalid_1's rmse: 0.0758299\n",
      "[300]\ttraining's rmse: 0.0791933\tvalid_1's rmse: 0.0758081\n",
      "[325]\ttraining's rmse: 0.0791344\tvalid_1's rmse: 0.0757876\n",
      "[350]\ttraining's rmse: 0.0790728\tvalid_1's rmse: 0.0757669\n",
      "[375]\ttraining's rmse: 0.0790248\tvalid_1's rmse: 0.075751\n",
      "[400]\ttraining's rmse: 0.0789705\tvalid_1's rmse: 0.0757402\n",
      "[425]\ttraining's rmse: 0.0789222\tvalid_1's rmse: 0.0757253\n",
      "[450]\ttraining's rmse: 0.0788806\tvalid_1's rmse: 0.0757106\n",
      "[475]\ttraining's rmse: 0.0788404\tvalid_1's rmse: 0.0757028\n",
      "[500]\ttraining's rmse: 0.0788079\tvalid_1's rmse: 0.0756912\n",
      "[525]\ttraining's rmse: 0.078762\tvalid_1's rmse: 0.0756775\n",
      "[550]\ttraining's rmse: 0.0787206\tvalid_1's rmse: 0.0756655\n",
      "[575]\ttraining's rmse: 0.0786833\tvalid_1's rmse: 0.0756607\n",
      "[600]\ttraining's rmse: 0.0786438\tvalid_1's rmse: 0.0756509\n",
      "[625]\ttraining's rmse: 0.0786155\tvalid_1's rmse: 0.0756487\n",
      "[650]\ttraining's rmse: 0.0785772\tvalid_1's rmse: 0.0756463\n",
      "[675]\ttraining's rmse: 0.0785403\tvalid_1's rmse: 0.0756382\n",
      "[700]\ttraining's rmse: 0.0785075\tvalid_1's rmse: 0.0756352\n",
      "[725]\ttraining's rmse: 0.0784761\tvalid_1's rmse: 0.0756367\n",
      "[750]\ttraining's rmse: 0.0784464\tvalid_1's rmse: 0.075637\n",
      "[775]\ttraining's rmse: 0.0784227\tvalid_1's rmse: 0.0756382\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 0.0784538\tvalid_1's rmse: 0.0756322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0813368\tvalid_1's rmse: 0.0833599\n",
      "[50]\ttraining's rmse: 0.0812142\tvalid_1's rmse: 0.0833136\n",
      "[75]\ttraining's rmse: 0.0810874\tvalid_1's rmse: 0.0832638\n",
      "[100]\ttraining's rmse: 0.0809718\tvalid_1's rmse: 0.0832237\n",
      "[125]\ttraining's rmse: 0.0808572\tvalid_1's rmse: 0.0831819\n",
      "[150]\ttraining's rmse: 0.0807525\tvalid_1's rmse: 0.0831441\n",
      "[175]\ttraining's rmse: 0.0806664\tvalid_1's rmse: 0.0831124\n",
      "[200]\ttraining's rmse: 0.0805725\tvalid_1's rmse: 0.0830798\n",
      "[225]\ttraining's rmse: 0.0804798\tvalid_1's rmse: 0.0830475\n",
      "[250]\ttraining's rmse: 0.0804049\tvalid_1's rmse: 0.0830196\n",
      "[275]\ttraining's rmse: 0.0803312\tvalid_1's rmse: 0.0829945\n",
      "[300]\ttraining's rmse: 0.0802589\tvalid_1's rmse: 0.0829697\n",
      "[325]\ttraining's rmse: 0.0801888\tvalid_1's rmse: 0.0829477\n",
      "[350]\ttraining's rmse: 0.0801184\tvalid_1's rmse: 0.0829249\n",
      "[375]\ttraining's rmse: 0.0800623\tvalid_1's rmse: 0.0829052\n",
      "[400]\ttraining's rmse: 0.080001\tvalid_1's rmse: 0.082887\n",
      "[425]\ttraining's rmse: 0.0799482\tvalid_1's rmse: 0.0828692\n",
      "[450]\ttraining's rmse: 0.0798978\tvalid_1's rmse: 0.0828516\n",
      "[475]\ttraining's rmse: 0.0798532\tvalid_1's rmse: 0.0828367\n",
      "[500]\ttraining's rmse: 0.0798136\tvalid_1's rmse: 0.0828233\n",
      "[525]\ttraining's rmse: 0.0797637\tvalid_1's rmse: 0.0828082\n",
      "[550]\ttraining's rmse: 0.0797183\tvalid_1's rmse: 0.0827936\n",
      "[575]\ttraining's rmse: 0.0796745\tvalid_1's rmse: 0.0827814\n",
      "[600]\ttraining's rmse: 0.0796312\tvalid_1's rmse: 0.0827699\n",
      "[625]\ttraining's rmse: 0.0795983\tvalid_1's rmse: 0.0827609\n",
      "[650]\ttraining's rmse: 0.0795584\tvalid_1's rmse: 0.0827512\n",
      "[675]\ttraining's rmse: 0.079519\tvalid_1's rmse: 0.0827401\n",
      "[700]\ttraining's rmse: 0.0794819\tvalid_1's rmse: 0.082731\n",
      "[725]\ttraining's rmse: 0.0794481\tvalid_1's rmse: 0.0827214\n",
      "[750]\ttraining's rmse: 0.079417\tvalid_1's rmse: 0.0827136\n",
      "[775]\ttraining's rmse: 0.0793929\tvalid_1's rmse: 0.0827056\n",
      "[800]\ttraining's rmse: 0.0793583\tvalid_1's rmse: 0.0826985\n",
      "[825]\ttraining's rmse: 0.079332\tvalid_1's rmse: 0.0826911\n",
      "[850]\ttraining's rmse: 0.0793037\tvalid_1's rmse: 0.082685\n",
      "[875]\ttraining's rmse: 0.0792799\tvalid_1's rmse: 0.0826788\n",
      "[900]\ttraining's rmse: 0.0792518\tvalid_1's rmse: 0.0826734\n",
      "[925]\ttraining's rmse: 0.0792265\tvalid_1's rmse: 0.082667\n",
      "[950]\ttraining's rmse: 0.0792041\tvalid_1's rmse: 0.0826611\n",
      "[975]\ttraining's rmse: 0.0791828\tvalid_1's rmse: 0.0826556\n",
      "[1000]\ttraining's rmse: 0.0791611\tvalid_1's rmse: 0.082651\n",
      "[1025]\ttraining's rmse: 0.0791379\tvalid_1's rmse: 0.0826461\n",
      "[1050]\ttraining's rmse: 0.0791177\tvalid_1's rmse: 0.082642\n",
      "[1075]\ttraining's rmse: 0.079099\tvalid_1's rmse: 0.0826382\n",
      "[1100]\ttraining's rmse: 0.0790815\tvalid_1's rmse: 0.0826342\n",
      "[1125]\ttraining's rmse: 0.0790648\tvalid_1's rmse: 0.0826305\n",
      "[1150]\ttraining's rmse: 0.0790464\tvalid_1's rmse: 0.0826273\n",
      "[1175]\ttraining's rmse: 0.0790288\tvalid_1's rmse: 0.0826243\n",
      "[1200]\ttraining's rmse: 0.0790111\tvalid_1's rmse: 0.0826193\n",
      "[1225]\ttraining's rmse: 0.0789972\tvalid_1's rmse: 0.0826159\n",
      "[1250]\ttraining's rmse: 0.078985\tvalid_1's rmse: 0.0826134\n",
      "[1275]\ttraining's rmse: 0.0789708\tvalid_1's rmse: 0.08261\n",
      "[1300]\ttraining's rmse: 0.0789586\tvalid_1's rmse: 0.082606\n",
      "[1325]\ttraining's rmse: 0.0789448\tvalid_1's rmse: 0.0826039\n",
      "[1350]\ttraining's rmse: 0.0789296\tvalid_1's rmse: 0.0826014\n",
      "[1375]\ttraining's rmse: 0.0789162\tvalid_1's rmse: 0.0825985\n",
      "[1400]\ttraining's rmse: 0.0789069\tvalid_1's rmse: 0.0825953\n",
      "[1425]\ttraining's rmse: 0.0788954\tvalid_1's rmse: 0.0825931\n",
      "[1450]\ttraining's rmse: 0.0788828\tvalid_1's rmse: 0.0825907\n",
      "[1475]\ttraining's rmse: 0.0788729\tvalid_1's rmse: 0.082589\n",
      "[1500]\ttraining's rmse: 0.0788632\tvalid_1's rmse: 0.0825868\n",
      "[1525]\ttraining's rmse: 0.0788558\tvalid_1's rmse: 0.0825842\n",
      "[1550]\ttraining's rmse: 0.0788464\tvalid_1's rmse: 0.0825826\n",
      "[1575]\ttraining's rmse: 0.0788374\tvalid_1's rmse: 0.0825811\n",
      "[1600]\ttraining's rmse: 0.0788306\tvalid_1's rmse: 0.0825786\n",
      "[1625]\ttraining's rmse: 0.0788229\tvalid_1's rmse: 0.0825758\n",
      "[1650]\ttraining's rmse: 0.0788154\tvalid_1's rmse: 0.0825729\n",
      "[1675]\ttraining's rmse: 0.0788107\tvalid_1's rmse: 0.0825707\n",
      "[1700]\ttraining's rmse: 0.0788063\tvalid_1's rmse: 0.0825697\n",
      "[1725]\ttraining's rmse: 0.0787993\tvalid_1's rmse: 0.0825686\n",
      "[1750]\ttraining's rmse: 0.0787929\tvalid_1's rmse: 0.0825665\n",
      "[1775]\ttraining's rmse: 0.0787878\tvalid_1's rmse: 0.0825646\n",
      "[1800]\ttraining's rmse: 0.0787832\tvalid_1's rmse: 0.0825639\n",
      "[1825]\ttraining's rmse: 0.0787789\tvalid_1's rmse: 0.0825633\n",
      "[1850]\ttraining's rmse: 0.0787735\tvalid_1's rmse: 0.0825612\n",
      "[1875]\ttraining's rmse: 0.0787689\tvalid_1's rmse: 0.0825609\n",
      "[1900]\ttraining's rmse: 0.0787658\tvalid_1's rmse: 0.0825607\n",
      "[1925]\ttraining's rmse: 0.078761\tvalid_1's rmse: 0.0825592\n",
      "[1950]\ttraining's rmse: 0.0787569\tvalid_1's rmse: 0.0825589\n",
      "[1975]\ttraining's rmse: 0.0787534\tvalid_1's rmse: 0.0825585\n",
      "[2000]\ttraining's rmse: 0.0787497\tvalid_1's rmse: 0.0825575\n",
      "[2025]\ttraining's rmse: 0.0787474\tvalid_1's rmse: 0.0825561\n",
      "[2050]\ttraining's rmse: 0.0787444\tvalid_1's rmse: 0.0825553\n",
      "[2075]\ttraining's rmse: 0.0787407\tvalid_1's rmse: 0.0825546\n",
      "[2100]\ttraining's rmse: 0.0787378\tvalid_1's rmse: 0.0825537\n",
      "[2125]\ttraining's rmse: 0.0787342\tvalid_1's rmse: 0.0825528\n",
      "[2150]\ttraining's rmse: 0.0787312\tvalid_1's rmse: 0.0825518\n",
      "[2175]\ttraining's rmse: 0.0787271\tvalid_1's rmse: 0.0825512\n",
      "[2200]\ttraining's rmse: 0.0787253\tvalid_1's rmse: 0.0825506\n",
      "[2225]\ttraining's rmse: 0.0787212\tvalid_1's rmse: 0.0825491\n",
      "[2250]\ttraining's rmse: 0.078718\tvalid_1's rmse: 0.0825485\n",
      "[2275]\ttraining's rmse: 0.078714\tvalid_1's rmse: 0.0825479\n",
      "[2300]\ttraining's rmse: 0.0787123\tvalid_1's rmse: 0.0825472\n",
      "[2325]\ttraining's rmse: 0.0787102\tvalid_1's rmse: 0.0825465\n",
      "[2350]\ttraining's rmse: 0.0787086\tvalid_1's rmse: 0.0825462\n",
      "[2375]\ttraining's rmse: 0.0787057\tvalid_1's rmse: 0.0825462\n",
      "[2400]\ttraining's rmse: 0.078703\tvalid_1's rmse: 0.0825456\n",
      "[2425]\ttraining's rmse: 0.0787\tvalid_1's rmse: 0.0825452\n",
      "[2450]\ttraining's rmse: 0.0786981\tvalid_1's rmse: 0.0825446\n",
      "[2475]\ttraining's rmse: 0.0786957\tvalid_1's rmse: 0.0825444\n",
      "[2500]\ttraining's rmse: 0.0786923\tvalid_1's rmse: 0.0825439\n",
      "[2525]\ttraining's rmse: 0.0786899\tvalid_1's rmse: 0.0825434\n",
      "[2550]\ttraining's rmse: 0.0786877\tvalid_1's rmse: 0.0825429\n",
      "[2575]\ttraining's rmse: 0.0786864\tvalid_1's rmse: 0.0825425\n",
      "[2600]\ttraining's rmse: 0.0786853\tvalid_1's rmse: 0.0825417\n",
      "[2625]\ttraining's rmse: 0.0786843\tvalid_1's rmse: 0.0825417\n",
      "[2650]\ttraining's rmse: 0.0786824\tvalid_1's rmse: 0.0825413\n",
      "[2675]\ttraining's rmse: 0.0786809\tvalid_1's rmse: 0.0825411\n",
      "[2700]\ttraining's rmse: 0.0786796\tvalid_1's rmse: 0.0825412\n",
      "[2725]\ttraining's rmse: 0.0786776\tvalid_1's rmse: 0.0825413\n",
      "Early stopping, best iteration is:\n",
      "[2676]\ttraining's rmse: 0.0786809\tvalid_1's rmse: 0.082541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.081351\tvalid_1's rmse: 0.0833628\n",
      "[50]\ttraining's rmse: 0.0812416\tvalid_1's rmse: 0.0833118\n",
      "[75]\ttraining's rmse: 0.0811278\tvalid_1's rmse: 0.08326\n",
      "[100]\ttraining's rmse: 0.0810253\tvalid_1's rmse: 0.0832142\n",
      "[125]\ttraining's rmse: 0.0809215\tvalid_1's rmse: 0.0831694\n",
      "[150]\ttraining's rmse: 0.0808263\tvalid_1's rmse: 0.0831264\n",
      "[175]\ttraining's rmse: 0.080749\tvalid_1's rmse: 0.0830929\n",
      "[200]\ttraining's rmse: 0.0806602\tvalid_1's rmse: 0.083056\n",
      "[225]\ttraining's rmse: 0.080576\tvalid_1's rmse: 0.0830228\n",
      "[250]\ttraining's rmse: 0.0805037\tvalid_1's rmse: 0.0829921\n",
      "[275]\ttraining's rmse: 0.0804388\tvalid_1's rmse: 0.0829651\n",
      "[300]\ttraining's rmse: 0.080374\tvalid_1's rmse: 0.0829392\n",
      "[325]\ttraining's rmse: 0.0803053\tvalid_1's rmse: 0.0829128\n",
      "[350]\ttraining's rmse: 0.0802422\tvalid_1's rmse: 0.0828897\n",
      "[375]\ttraining's rmse: 0.0801904\tvalid_1's rmse: 0.0828689\n",
      "[400]\ttraining's rmse: 0.0801333\tvalid_1's rmse: 0.0828489\n",
      "[425]\ttraining's rmse: 0.0800801\tvalid_1's rmse: 0.082829\n",
      "[450]\ttraining's rmse: 0.0800316\tvalid_1's rmse: 0.0828106\n",
      "[475]\ttraining's rmse: 0.0799849\tvalid_1's rmse: 0.0827932\n",
      "[500]\ttraining's rmse: 0.0799462\tvalid_1's rmse: 0.0827765\n",
      "[525]\ttraining's rmse: 0.0798965\tvalid_1's rmse: 0.0827605\n",
      "[550]\ttraining's rmse: 0.0798518\tvalid_1's rmse: 0.0827459\n",
      "[575]\ttraining's rmse: 0.0798097\tvalid_1's rmse: 0.0827317\n",
      "[600]\ttraining's rmse: 0.0797693\tvalid_1's rmse: 0.082718\n",
      "[625]\ttraining's rmse: 0.0797369\tvalid_1's rmse: 0.0827058\n",
      "[650]\ttraining's rmse: 0.079697\tvalid_1's rmse: 0.0826927\n",
      "[675]\ttraining's rmse: 0.0796574\tvalid_1's rmse: 0.0826822\n",
      "[700]\ttraining's rmse: 0.0796212\tvalid_1's rmse: 0.0826703\n",
      "[725]\ttraining's rmse: 0.0795869\tvalid_1's rmse: 0.0826605\n",
      "[750]\ttraining's rmse: 0.0795569\tvalid_1's rmse: 0.0826517\n",
      "[775]\ttraining's rmse: 0.0795329\tvalid_1's rmse: 0.0826427\n",
      "[800]\ttraining's rmse: 0.0794982\tvalid_1's rmse: 0.0826346\n",
      "[825]\ttraining's rmse: 0.0794719\tvalid_1's rmse: 0.0826262\n",
      "[850]\ttraining's rmse: 0.0794432\tvalid_1's rmse: 0.0826196\n",
      "[875]\ttraining's rmse: 0.0794171\tvalid_1's rmse: 0.0826125\n",
      "[900]\ttraining's rmse: 0.0793914\tvalid_1's rmse: 0.0826058\n",
      "[925]\ttraining's rmse: 0.0793669\tvalid_1's rmse: 0.0825999\n",
      "[950]\ttraining's rmse: 0.0793424\tvalid_1's rmse: 0.082594\n",
      "[975]\ttraining's rmse: 0.0793217\tvalid_1's rmse: 0.0825879\n",
      "[1000]\ttraining's rmse: 0.0793025\tvalid_1's rmse: 0.0825825\n",
      "[1025]\ttraining's rmse: 0.0792787\tvalid_1's rmse: 0.0825775\n",
      "[1050]\ttraining's rmse: 0.0792602\tvalid_1's rmse: 0.0825725\n",
      "[1075]\ttraining's rmse: 0.0792406\tvalid_1's rmse: 0.0825687\n",
      "[1100]\ttraining's rmse: 0.0792251\tvalid_1's rmse: 0.0825638\n",
      "[1125]\ttraining's rmse: 0.0792081\tvalid_1's rmse: 0.0825602\n",
      "[1150]\ttraining's rmse: 0.0791923\tvalid_1's rmse: 0.082556\n",
      "[1175]\ttraining's rmse: 0.0791764\tvalid_1's rmse: 0.0825523\n",
      "[1200]\ttraining's rmse: 0.0791617\tvalid_1's rmse: 0.0825489\n",
      "[1225]\ttraining's rmse: 0.0791489\tvalid_1's rmse: 0.0825458\n",
      "[1250]\ttraining's rmse: 0.0791368\tvalid_1's rmse: 0.0825433\n",
      "[1275]\ttraining's rmse: 0.0791204\tvalid_1's rmse: 0.0825412\n",
      "[1300]\ttraining's rmse: 0.079108\tvalid_1's rmse: 0.0825378\n",
      "[1325]\ttraining's rmse: 0.0790945\tvalid_1's rmse: 0.082535\n",
      "[1350]\ttraining's rmse: 0.0790829\tvalid_1's rmse: 0.0825328\n",
      "[1375]\ttraining's rmse: 0.0790707\tvalid_1's rmse: 0.0825307\n",
      "[1400]\ttraining's rmse: 0.0790616\tvalid_1's rmse: 0.082528\n",
      "[1425]\ttraining's rmse: 0.0790506\tvalid_1's rmse: 0.0825263\n",
      "[1450]\ttraining's rmse: 0.079041\tvalid_1's rmse: 0.0825247\n",
      "[1475]\ttraining's rmse: 0.0790307\tvalid_1's rmse: 0.0825228\n",
      "[1500]\ttraining's rmse: 0.0790228\tvalid_1's rmse: 0.0825213\n",
      "[1525]\ttraining's rmse: 0.0790144\tvalid_1's rmse: 0.08252\n",
      "[1550]\ttraining's rmse: 0.0790066\tvalid_1's rmse: 0.0825191\n",
      "[1575]\ttraining's rmse: 0.0789989\tvalid_1's rmse: 0.0825175\n",
      "[1600]\ttraining's rmse: 0.078993\tvalid_1's rmse: 0.0825165\n",
      "[1625]\ttraining's rmse: 0.0789871\tvalid_1's rmse: 0.0825153\n",
      "[1650]\ttraining's rmse: 0.07898\tvalid_1's rmse: 0.0825144\n",
      "[1675]\ttraining's rmse: 0.0789748\tvalid_1's rmse: 0.0825131\n",
      "[1700]\ttraining's rmse: 0.078969\tvalid_1's rmse: 0.0825118\n",
      "[1725]\ttraining's rmse: 0.0789636\tvalid_1's rmse: 0.0825112\n",
      "[1750]\ttraining's rmse: 0.078958\tvalid_1's rmse: 0.0825105\n",
      "[1775]\ttraining's rmse: 0.0789534\tvalid_1's rmse: 0.0825098\n",
      "[1800]\ttraining's rmse: 0.0789479\tvalid_1's rmse: 0.0825089\n",
      "[1825]\ttraining's rmse: 0.0789437\tvalid_1's rmse: 0.082508\n",
      "[1850]\ttraining's rmse: 0.07894\tvalid_1's rmse: 0.0825072\n",
      "[1875]\ttraining's rmse: 0.0789352\tvalid_1's rmse: 0.0825069\n",
      "[1900]\ttraining's rmse: 0.0789303\tvalid_1's rmse: 0.0825069\n",
      "[1925]\ttraining's rmse: 0.078926\tvalid_1's rmse: 0.0825062\n",
      "[1950]\ttraining's rmse: 0.0789226\tvalid_1's rmse: 0.0825051\n",
      "[1975]\ttraining's rmse: 0.0789192\tvalid_1's rmse: 0.0825046\n",
      "[2000]\ttraining's rmse: 0.0789151\tvalid_1's rmse: 0.0825036\n",
      "[2025]\ttraining's rmse: 0.078911\tvalid_1's rmse: 0.082503\n",
      "[2050]\ttraining's rmse: 0.0789079\tvalid_1's rmse: 0.0825025\n",
      "[2075]\ttraining's rmse: 0.0789055\tvalid_1's rmse: 0.0825022\n",
      "[2100]\ttraining's rmse: 0.078903\tvalid_1's rmse: 0.0825019\n",
      "[2125]\ttraining's rmse: 0.0789013\tvalid_1's rmse: 0.0825018\n",
      "[2150]\ttraining's rmse: 0.0788983\tvalid_1's rmse: 0.082502\n",
      "Early stopping, best iteration is:\n",
      "[2111]\ttraining's rmse: 0.0789021\tvalid_1's rmse: 0.0825016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.083243\tvalid_1's rmse: 0.0795121\n",
      "[50]\ttraining's rmse: 0.0831369\tvalid_1's rmse: 0.0794652\n",
      "[75]\ttraining's rmse: 0.0830259\tvalid_1's rmse: 0.0794171\n",
      "[100]\ttraining's rmse: 0.0829253\tvalid_1's rmse: 0.0793758\n",
      "[125]\ttraining's rmse: 0.0828217\tvalid_1's rmse: 0.0793348\n",
      "[150]\ttraining's rmse: 0.0827288\tvalid_1's rmse: 0.0792973\n",
      "[175]\ttraining's rmse: 0.082649\tvalid_1's rmse: 0.079267\n",
      "[200]\ttraining's rmse: 0.0825639\tvalid_1's rmse: 0.0792349\n",
      "[225]\ttraining's rmse: 0.0824791\tvalid_1's rmse: 0.0792044\n",
      "[250]\ttraining's rmse: 0.0824108\tvalid_1's rmse: 0.079179\n",
      "[275]\ttraining's rmse: 0.0823478\tvalid_1's rmse: 0.079155\n",
      "[300]\ttraining's rmse: 0.0822833\tvalid_1's rmse: 0.0791322\n",
      "[325]\ttraining's rmse: 0.0822189\tvalid_1's rmse: 0.0791117\n",
      "[350]\ttraining's rmse: 0.0821557\tvalid_1's rmse: 0.0790914\n",
      "[375]\ttraining's rmse: 0.0821056\tvalid_1's rmse: 0.0790766\n",
      "[400]\ttraining's rmse: 0.0820477\tvalid_1's rmse: 0.0790631\n",
      "[425]\ttraining's rmse: 0.0819964\tvalid_1's rmse: 0.0790479\n",
      "[450]\ttraining's rmse: 0.0819478\tvalid_1's rmse: 0.0790345\n",
      "[475]\ttraining's rmse: 0.0819038\tvalid_1's rmse: 0.0790206\n",
      "[500]\ttraining's rmse: 0.0818667\tvalid_1's rmse: 0.0790088\n",
      "[525]\ttraining's rmse: 0.0818161\tvalid_1's rmse: 0.0789966\n",
      "[550]\ttraining's rmse: 0.0817715\tvalid_1's rmse: 0.0789833\n",
      "[575]\ttraining's rmse: 0.0817307\tvalid_1's rmse: 0.0789735\n",
      "[600]\ttraining's rmse: 0.0816895\tvalid_1's rmse: 0.0789661\n",
      "[625]\ttraining's rmse: 0.0816571\tvalid_1's rmse: 0.0789621\n",
      "[650]\ttraining's rmse: 0.0816184\tvalid_1's rmse: 0.0789552\n",
      "[675]\ttraining's rmse: 0.0815784\tvalid_1's rmse: 0.0789525\n",
      "[700]\ttraining's rmse: 0.081544\tvalid_1's rmse: 0.0789457\n",
      "[725]\ttraining's rmse: 0.0815115\tvalid_1's rmse: 0.0789429\n",
      "[750]\ttraining's rmse: 0.0814795\tvalid_1's rmse: 0.0789378\n",
      "[775]\ttraining's rmse: 0.0814557\tvalid_1's rmse: 0.0789406\n",
      "[800]\ttraining's rmse: 0.081422\tvalid_1's rmse: 0.0789397\n",
      "[825]\ttraining's rmse: 0.0813943\tvalid_1's rmse: 0.0789359\n",
      "[850]\ttraining's rmse: 0.0813649\tvalid_1's rmse: 0.0789309\n",
      "[875]\ttraining's rmse: 0.08134\tvalid_1's rmse: 0.0789371\n",
      "[900]\ttraining's rmse: 0.0813123\tvalid_1's rmse: 0.0789421\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's rmse: 0.081358\tvalid_1's rmse: 0.0789297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0783693\tvalid_1's rmse: 0.0808996\n",
      "[50]\ttraining's rmse: 0.0782582\tvalid_1's rmse: 0.0808475\n",
      "[75]\ttraining's rmse: 0.0781444\tvalid_1's rmse: 0.080797\n",
      "[100]\ttraining's rmse: 0.0780411\tvalid_1's rmse: 0.0807529\n",
      "[125]\ttraining's rmse: 0.0779366\tvalid_1's rmse: 0.080708\n",
      "[150]\ttraining's rmse: 0.0778446\tvalid_1's rmse: 0.080668\n",
      "[175]\ttraining's rmse: 0.0777704\tvalid_1's rmse: 0.0806328\n",
      "[200]\ttraining's rmse: 0.0776875\tvalid_1's rmse: 0.0805973\n",
      "[225]\ttraining's rmse: 0.0776051\tvalid_1's rmse: 0.0805637\n",
      "[250]\ttraining's rmse: 0.0775358\tvalid_1's rmse: 0.0805337\n",
      "[275]\ttraining's rmse: 0.0774729\tvalid_1's rmse: 0.0805062\n",
      "[300]\ttraining's rmse: 0.0774098\tvalid_1's rmse: 0.0804789\n",
      "[325]\ttraining's rmse: 0.0773445\tvalid_1's rmse: 0.080454\n",
      "[350]\ttraining's rmse: 0.077283\tvalid_1's rmse: 0.0804291\n",
      "[375]\ttraining's rmse: 0.0772334\tvalid_1's rmse: 0.0804078\n",
      "[400]\ttraining's rmse: 0.0771808\tvalid_1's rmse: 0.0803864\n",
      "[425]\ttraining's rmse: 0.0771314\tvalid_1's rmse: 0.0803647\n",
      "[450]\ttraining's rmse: 0.0770863\tvalid_1's rmse: 0.0803463\n",
      "[475]\ttraining's rmse: 0.0770465\tvalid_1's rmse: 0.0803286\n",
      "[500]\ttraining's rmse: 0.0770082\tvalid_1's rmse: 0.0803107\n",
      "[525]\ttraining's rmse: 0.0769649\tvalid_1's rmse: 0.0802953\n",
      "[550]\ttraining's rmse: 0.0769247\tvalid_1's rmse: 0.0802808\n",
      "[575]\ttraining's rmse: 0.0768856\tvalid_1's rmse: 0.0802674\n",
      "[600]\ttraining's rmse: 0.0768501\tvalid_1's rmse: 0.0802534\n",
      "[625]\ttraining's rmse: 0.0768207\tvalid_1's rmse: 0.080241\n",
      "[650]\ttraining's rmse: 0.0767851\tvalid_1's rmse: 0.0802282\n",
      "[675]\ttraining's rmse: 0.0767508\tvalid_1's rmse: 0.0802157\n",
      "[700]\ttraining's rmse: 0.0767202\tvalid_1's rmse: 0.0802036\n",
      "[725]\ttraining's rmse: 0.0766894\tvalid_1's rmse: 0.0801924\n",
      "[750]\ttraining's rmse: 0.0766613\tvalid_1's rmse: 0.080182\n",
      "[775]\ttraining's rmse: 0.0766374\tvalid_1's rmse: 0.0801722\n",
      "[800]\ttraining's rmse: 0.076609\tvalid_1's rmse: 0.0801636\n",
      "[825]\ttraining's rmse: 0.0765853\tvalid_1's rmse: 0.0801555\n",
      "[850]\ttraining's rmse: 0.0765577\tvalid_1's rmse: 0.0801471\n",
      "[875]\ttraining's rmse: 0.0765348\tvalid_1's rmse: 0.0801392\n",
      "[900]\ttraining's rmse: 0.0765087\tvalid_1's rmse: 0.0801313\n",
      "[925]\ttraining's rmse: 0.0764851\tvalid_1's rmse: 0.0801226\n",
      "[950]\ttraining's rmse: 0.0764654\tvalid_1's rmse: 0.0801162\n",
      "[975]\ttraining's rmse: 0.0764452\tvalid_1's rmse: 0.0801094\n",
      "[1000]\ttraining's rmse: 0.0764246\tvalid_1's rmse: 0.0801035\n",
      "[1025]\ttraining's rmse: 0.0764044\tvalid_1's rmse: 0.0800965\n",
      "[1050]\ttraining's rmse: 0.0763877\tvalid_1's rmse: 0.0800896\n",
      "[1075]\ttraining's rmse: 0.0763716\tvalid_1's rmse: 0.0800853\n",
      "[1100]\ttraining's rmse: 0.0763566\tvalid_1's rmse: 0.0800807\n",
      "[1125]\ttraining's rmse: 0.0763422\tvalid_1's rmse: 0.080075\n",
      "[1150]\ttraining's rmse: 0.0763261\tvalid_1's rmse: 0.080071\n",
      "[1175]\ttraining's rmse: 0.0763126\tvalid_1's rmse: 0.0800666\n",
      "[1200]\ttraining's rmse: 0.0763002\tvalid_1's rmse: 0.0800613\n",
      "[1225]\ttraining's rmse: 0.0762883\tvalid_1's rmse: 0.0800567\n",
      "[1250]\ttraining's rmse: 0.0762754\tvalid_1's rmse: 0.0800534\n",
      "[1275]\ttraining's rmse: 0.0762613\tvalid_1's rmse: 0.08005\n",
      "[1300]\ttraining's rmse: 0.076252\tvalid_1's rmse: 0.0800456\n",
      "[1325]\ttraining's rmse: 0.0762418\tvalid_1's rmse: 0.0800424\n",
      "[1350]\ttraining's rmse: 0.0762304\tvalid_1's rmse: 0.08004\n",
      "[1375]\ttraining's rmse: 0.0762187\tvalid_1's rmse: 0.0800362\n",
      "[1400]\ttraining's rmse: 0.0762106\tvalid_1's rmse: 0.0800324\n",
      "[1425]\ttraining's rmse: 0.0761997\tvalid_1's rmse: 0.0800283\n",
      "[1450]\ttraining's rmse: 0.0761908\tvalid_1's rmse: 0.0800261\n",
      "[1475]\ttraining's rmse: 0.0761824\tvalid_1's rmse: 0.0800238\n",
      "[1500]\ttraining's rmse: 0.0761742\tvalid_1's rmse: 0.0800197\n",
      "[1525]\ttraining's rmse: 0.0761683\tvalid_1's rmse: 0.0800168\n",
      "[1550]\ttraining's rmse: 0.0761595\tvalid_1's rmse: 0.0800137\n",
      "[1575]\ttraining's rmse: 0.0761523\tvalid_1's rmse: 0.0800099\n",
      "[1600]\ttraining's rmse: 0.0761468\tvalid_1's rmse: 0.0800076\n",
      "[1625]\ttraining's rmse: 0.0761408\tvalid_1's rmse: 0.080005\n",
      "[1650]\ttraining's rmse: 0.0761365\tvalid_1's rmse: 0.0800027\n",
      "[1675]\ttraining's rmse: 0.0761304\tvalid_1's rmse: 0.0799994\n",
      "[1700]\ttraining's rmse: 0.0761256\tvalid_1's rmse: 0.0799979\n",
      "[1725]\ttraining's rmse: 0.0761201\tvalid_1's rmse: 0.0799963\n",
      "[1750]\ttraining's rmse: 0.0761133\tvalid_1's rmse: 0.0799942\n",
      "[1775]\ttraining's rmse: 0.0761085\tvalid_1's rmse: 0.0799921\n",
      "[1800]\ttraining's rmse: 0.0761029\tvalid_1's rmse: 0.0799912\n",
      "[1825]\ttraining's rmse: 0.0760967\tvalid_1's rmse: 0.0799894\n",
      "[1850]\ttraining's rmse: 0.076094\tvalid_1's rmse: 0.0799882\n",
      "[1875]\ttraining's rmse: 0.0760894\tvalid_1's rmse: 0.0799872\n",
      "[1900]\ttraining's rmse: 0.076085\tvalid_1's rmse: 0.0799853\n",
      "[1925]\ttraining's rmse: 0.076082\tvalid_1's rmse: 0.0799844\n",
      "[1950]\ttraining's rmse: 0.0760791\tvalid_1's rmse: 0.079984\n",
      "[1975]\ttraining's rmse: 0.0760755\tvalid_1's rmse: 0.0799835\n",
      "[2000]\ttraining's rmse: 0.076073\tvalid_1's rmse: 0.0799831\n",
      "[2025]\ttraining's rmse: 0.07607\tvalid_1's rmse: 0.0799818\n",
      "[2050]\ttraining's rmse: 0.0760655\tvalid_1's rmse: 0.0799808\n",
      "[2075]\ttraining's rmse: 0.0760625\tvalid_1's rmse: 0.0799803\n",
      "[2100]\ttraining's rmse: 0.0760603\tvalid_1's rmse: 0.07998\n",
      "[2125]\ttraining's rmse: 0.0760586\tvalid_1's rmse: 0.0799798\n",
      "[2150]\ttraining's rmse: 0.076054\tvalid_1's rmse: 0.079979\n",
      "[2175]\ttraining's rmse: 0.0760512\tvalid_1's rmse: 0.0799784\n",
      "[2200]\ttraining's rmse: 0.0760489\tvalid_1's rmse: 0.0799772\n",
      "[2225]\ttraining's rmse: 0.0760466\tvalid_1's rmse: 0.079976\n",
      "[2250]\ttraining's rmse: 0.0760443\tvalid_1's rmse: 0.0799747\n",
      "[2275]\ttraining's rmse: 0.0760421\tvalid_1's rmse: 0.0799737\n",
      "[2300]\ttraining's rmse: 0.07604\tvalid_1's rmse: 0.079973\n",
      "[2325]\ttraining's rmse: 0.0760372\tvalid_1's rmse: 0.0799719\n",
      "[2350]\ttraining's rmse: 0.0760357\tvalid_1's rmse: 0.0799717\n",
      "[2375]\ttraining's rmse: 0.0760343\tvalid_1's rmse: 0.0799717\n",
      "[2400]\ttraining's rmse: 0.076032\tvalid_1's rmse: 0.0799711\n",
      "[2425]\ttraining's rmse: 0.0760298\tvalid_1's rmse: 0.0799703\n",
      "[2450]\ttraining's rmse: 0.0760265\tvalid_1's rmse: 0.0799693\n",
      "[2475]\ttraining's rmse: 0.0760244\tvalid_1's rmse: 0.0799686\n",
      "[2500]\ttraining's rmse: 0.0760224\tvalid_1's rmse: 0.0799682\n",
      "[2525]\ttraining's rmse: 0.0760202\tvalid_1's rmse: 0.0799681\n",
      "[2550]\ttraining's rmse: 0.0760178\tvalid_1's rmse: 0.0799679\n",
      "[2575]\ttraining's rmse: 0.076015\tvalid_1's rmse: 0.0799674\n",
      "[2600]\ttraining's rmse: 0.0760137\tvalid_1's rmse: 0.0799667\n",
      "[2625]\ttraining's rmse: 0.0760129\tvalid_1's rmse: 0.0799669\n",
      "Early stopping, best iteration is:\n",
      "[2585]\ttraining's rmse: 0.0760146\tvalid_1's rmse: 0.0799667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0786285\tvalid_1's rmse: 0.0803972\n",
      "[50]\ttraining's rmse: 0.0785222\tvalid_1's rmse: 0.0803429\n",
      "[75]\ttraining's rmse: 0.0784149\tvalid_1's rmse: 0.0802903\n",
      "[100]\ttraining's rmse: 0.0783215\tvalid_1's rmse: 0.0802445\n",
      "[125]\ttraining's rmse: 0.0782237\tvalid_1's rmse: 0.0801986\n",
      "[150]\ttraining's rmse: 0.0781336\tvalid_1's rmse: 0.080156\n",
      "[175]\ttraining's rmse: 0.0780603\tvalid_1's rmse: 0.0801203\n",
      "[200]\ttraining's rmse: 0.0779776\tvalid_1's rmse: 0.0800836\n",
      "[225]\ttraining's rmse: 0.0778987\tvalid_1's rmse: 0.0800491\n",
      "[250]\ttraining's rmse: 0.0778328\tvalid_1's rmse: 0.0800188\n",
      "[275]\ttraining's rmse: 0.0777714\tvalid_1's rmse: 0.0799903\n",
      "[300]\ttraining's rmse: 0.0777094\tvalid_1's rmse: 0.0799646\n",
      "[325]\ttraining's rmse: 0.077646\tvalid_1's rmse: 0.0799387\n",
      "[350]\ttraining's rmse: 0.0775833\tvalid_1's rmse: 0.0799145\n",
      "[375]\ttraining's rmse: 0.0775338\tvalid_1's rmse: 0.0798937\n",
      "[400]\ttraining's rmse: 0.0774783\tvalid_1's rmse: 0.0798725\n",
      "[425]\ttraining's rmse: 0.0774294\tvalid_1's rmse: 0.0798536\n",
      "[450]\ttraining's rmse: 0.0773824\tvalid_1's rmse: 0.0798348\n",
      "[475]\ttraining's rmse: 0.0773396\tvalid_1's rmse: 0.0798184\n",
      "[500]\ttraining's rmse: 0.0773009\tvalid_1's rmse: 0.0798026\n",
      "[525]\ttraining's rmse: 0.0772553\tvalid_1's rmse: 0.0797863\n",
      "[550]\ttraining's rmse: 0.0772102\tvalid_1's rmse: 0.0797712\n",
      "[575]\ttraining's rmse: 0.0771695\tvalid_1's rmse: 0.0797575\n",
      "[600]\ttraining's rmse: 0.0771315\tvalid_1's rmse: 0.079745\n",
      "[625]\ttraining's rmse: 0.077102\tvalid_1's rmse: 0.0797343\n",
      "[650]\ttraining's rmse: 0.0770646\tvalid_1's rmse: 0.0797218\n",
      "[675]\ttraining's rmse: 0.0770273\tvalid_1's rmse: 0.0797106\n",
      "[700]\ttraining's rmse: 0.0769962\tvalid_1's rmse: 0.0797005\n",
      "[725]\ttraining's rmse: 0.076966\tvalid_1's rmse: 0.0796906\n",
      "[750]\ttraining's rmse: 0.0769365\tvalid_1's rmse: 0.0796818\n",
      "[775]\ttraining's rmse: 0.076912\tvalid_1's rmse: 0.0796729\n",
      "[800]\ttraining's rmse: 0.0768811\tvalid_1's rmse: 0.0796649\n",
      "[825]\ttraining's rmse: 0.0768543\tvalid_1's rmse: 0.079657\n",
      "[850]\ttraining's rmse: 0.0768291\tvalid_1's rmse: 0.0796512\n",
      "[875]\ttraining's rmse: 0.0768066\tvalid_1's rmse: 0.0796452\n",
      "[900]\ttraining's rmse: 0.0767815\tvalid_1's rmse: 0.0796377\n",
      "[925]\ttraining's rmse: 0.0767592\tvalid_1's rmse: 0.0796316\n",
      "[950]\ttraining's rmse: 0.0767377\tvalid_1's rmse: 0.079626\n",
      "[975]\ttraining's rmse: 0.0767164\tvalid_1's rmse: 0.07962\n",
      "[1000]\ttraining's rmse: 0.0766974\tvalid_1's rmse: 0.0796152\n",
      "[1025]\ttraining's rmse: 0.0766746\tvalid_1's rmse: 0.0796099\n",
      "[1050]\ttraining's rmse: 0.0766564\tvalid_1's rmse: 0.0796052\n",
      "[1075]\ttraining's rmse: 0.076638\tvalid_1's rmse: 0.0796017\n",
      "[1100]\ttraining's rmse: 0.0766252\tvalid_1's rmse: 0.0795984\n",
      "[1125]\ttraining's rmse: 0.0766097\tvalid_1's rmse: 0.0795944\n",
      "[1150]\ttraining's rmse: 0.0765934\tvalid_1's rmse: 0.079591\n",
      "[1175]\ttraining's rmse: 0.0765796\tvalid_1's rmse: 0.0795876\n",
      "[1200]\ttraining's rmse: 0.076566\tvalid_1's rmse: 0.0795837\n",
      "[1225]\ttraining's rmse: 0.076553\tvalid_1's rmse: 0.0795809\n",
      "[1250]\ttraining's rmse: 0.0765414\tvalid_1's rmse: 0.079578\n",
      "[1275]\ttraining's rmse: 0.0765257\tvalid_1's rmse: 0.0795759\n",
      "[1300]\ttraining's rmse: 0.0765153\tvalid_1's rmse: 0.0795733\n",
      "[1325]\ttraining's rmse: 0.076504\tvalid_1's rmse: 0.0795714\n",
      "[1350]\ttraining's rmse: 0.0764908\tvalid_1's rmse: 0.0795693\n",
      "[1375]\ttraining's rmse: 0.0764796\tvalid_1's rmse: 0.0795675\n",
      "[1400]\ttraining's rmse: 0.0764709\tvalid_1's rmse: 0.0795658\n",
      "[1425]\ttraining's rmse: 0.0764605\tvalid_1's rmse: 0.0795637\n",
      "[1450]\ttraining's rmse: 0.0764501\tvalid_1's rmse: 0.0795614\n",
      "[1475]\ttraining's rmse: 0.0764427\tvalid_1's rmse: 0.0795603\n",
      "[1500]\ttraining's rmse: 0.0764356\tvalid_1's rmse: 0.0795582\n",
      "[1525]\ttraining's rmse: 0.0764278\tvalid_1's rmse: 0.0795565\n",
      "[1550]\ttraining's rmse: 0.076419\tvalid_1's rmse: 0.0795555\n",
      "[1575]\ttraining's rmse: 0.0764117\tvalid_1's rmse: 0.0795542\n",
      "[1600]\ttraining's rmse: 0.076405\tvalid_1's rmse: 0.0795535\n",
      "[1625]\ttraining's rmse: 0.076399\tvalid_1's rmse: 0.0795526\n",
      "[1650]\ttraining's rmse: 0.0763923\tvalid_1's rmse: 0.0795522\n",
      "[1675]\ttraining's rmse: 0.0763877\tvalid_1's rmse: 0.079551\n",
      "[1700]\ttraining's rmse: 0.0763828\tvalid_1's rmse: 0.0795503\n",
      "[1725]\ttraining's rmse: 0.0763779\tvalid_1's rmse: 0.079549\n",
      "[1750]\ttraining's rmse: 0.07637\tvalid_1's rmse: 0.0795483\n",
      "[1775]\ttraining's rmse: 0.0763643\tvalid_1's rmse: 0.0795477\n",
      "[1800]\ttraining's rmse: 0.0763593\tvalid_1's rmse: 0.0795471\n",
      "[1825]\ttraining's rmse: 0.0763544\tvalid_1's rmse: 0.0795465\n",
      "[1850]\ttraining's rmse: 0.07635\tvalid_1's rmse: 0.0795457\n",
      "[1875]\ttraining's rmse: 0.0763473\tvalid_1's rmse: 0.0795461\n",
      "[1900]\ttraining's rmse: 0.0763438\tvalid_1's rmse: 0.0795458\n",
      "Early stopping, best iteration is:\n",
      "[1853]\ttraining's rmse: 0.0763497\tvalid_1's rmse: 0.0795457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.08054\tvalid_1's rmse: 0.0764988\n",
      "[50]\ttraining's rmse: 0.0804343\tvalid_1's rmse: 0.0764503\n",
      "[75]\ttraining's rmse: 0.0803301\tvalid_1's rmse: 0.0764046\n",
      "[100]\ttraining's rmse: 0.0802359\tvalid_1's rmse: 0.0763621\n",
      "[125]\ttraining's rmse: 0.0801399\tvalid_1's rmse: 0.0763211\n",
      "[150]\ttraining's rmse: 0.0800481\tvalid_1's rmse: 0.0762852\n",
      "[175]\ttraining's rmse: 0.0799746\tvalid_1's rmse: 0.0762551\n",
      "[200]\ttraining's rmse: 0.0798944\tvalid_1's rmse: 0.0762253\n",
      "[225]\ttraining's rmse: 0.0798162\tvalid_1's rmse: 0.0761957\n",
      "[250]\ttraining's rmse: 0.0797512\tvalid_1's rmse: 0.0761704\n",
      "[275]\ttraining's rmse: 0.0796894\tvalid_1's rmse: 0.0761471\n",
      "[300]\ttraining's rmse: 0.079629\tvalid_1's rmse: 0.0761241\n",
      "[325]\ttraining's rmse: 0.0795671\tvalid_1's rmse: 0.0761017\n",
      "[350]\ttraining's rmse: 0.0795072\tvalid_1's rmse: 0.0760823\n",
      "[375]\ttraining's rmse: 0.0794584\tvalid_1's rmse: 0.0760651\n",
      "[400]\ttraining's rmse: 0.0794056\tvalid_1's rmse: 0.0760527\n",
      "[425]\ttraining's rmse: 0.0793576\tvalid_1's rmse: 0.0760432\n",
      "[450]\ttraining's rmse: 0.0793112\tvalid_1's rmse: 0.0760344\n",
      "[475]\ttraining's rmse: 0.079269\tvalid_1's rmse: 0.0760208\n",
      "[500]\ttraining's rmse: 0.0792346\tvalid_1's rmse: 0.076009\n",
      "[525]\ttraining's rmse: 0.0791878\tvalid_1's rmse: 0.0760088\n",
      "[550]\ttraining's rmse: 0.0791447\tvalid_1's rmse: 0.0760007\n",
      "[575]\ttraining's rmse: 0.0791053\tvalid_1's rmse: 0.0759899\n",
      "[600]\ttraining's rmse: 0.0790655\tvalid_1's rmse: 0.0759804\n",
      "[625]\ttraining's rmse: 0.0790345\tvalid_1's rmse: 0.0759761\n",
      "[650]\ttraining's rmse: 0.0789959\tvalid_1's rmse: 0.075975\n",
      "[675]\ttraining's rmse: 0.0789576\tvalid_1's rmse: 0.0759669\n",
      "[700]\ttraining's rmse: 0.078925\tvalid_1's rmse: 0.0759638\n",
      "[725]\ttraining's rmse: 0.0788928\tvalid_1's rmse: 0.0759643\n",
      "[750]\ttraining's rmse: 0.0788619\tvalid_1's rmse: 0.0759726\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's rmse: 0.0788993\tvalid_1's rmse: 0.0759577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0822447\tvalid_1's rmse: 0.0842444\n",
      "[50]\ttraining's rmse: 0.0821167\tvalid_1's rmse: 0.0841964\n",
      "[75]\ttraining's rmse: 0.0819908\tvalid_1's rmse: 0.084146\n",
      "[100]\ttraining's rmse: 0.0818719\tvalid_1's rmse: 0.0841031\n",
      "[125]\ttraining's rmse: 0.0817519\tvalid_1's rmse: 0.0840609\n",
      "[150]\ttraining's rmse: 0.0816461\tvalid_1's rmse: 0.0840227\n",
      "[175]\ttraining's rmse: 0.0815582\tvalid_1's rmse: 0.0839894\n",
      "[200]\ttraining's rmse: 0.0814612\tvalid_1's rmse: 0.0839545\n",
      "[225]\ttraining's rmse: 0.0813628\tvalid_1's rmse: 0.0839218\n",
      "[250]\ttraining's rmse: 0.0812839\tvalid_1's rmse: 0.083893\n",
      "[275]\ttraining's rmse: 0.0812086\tvalid_1's rmse: 0.0838664\n",
      "[300]\ttraining's rmse: 0.0811358\tvalid_1's rmse: 0.0838429\n",
      "[325]\ttraining's rmse: 0.0810607\tvalid_1's rmse: 0.0838185\n",
      "[350]\ttraining's rmse: 0.0809902\tvalid_1's rmse: 0.0837968\n",
      "[375]\ttraining's rmse: 0.0809298\tvalid_1's rmse: 0.0837776\n",
      "[400]\ttraining's rmse: 0.0808662\tvalid_1's rmse: 0.0837592\n",
      "[425]\ttraining's rmse: 0.0808102\tvalid_1's rmse: 0.0837421\n",
      "[450]\ttraining's rmse: 0.0807562\tvalid_1's rmse: 0.0837252\n",
      "[475]\ttraining's rmse: 0.0807091\tvalid_1's rmse: 0.0837108\n",
      "[500]\ttraining's rmse: 0.0806668\tvalid_1's rmse: 0.0836962\n",
      "[525]\ttraining's rmse: 0.0806145\tvalid_1's rmse: 0.0836808\n",
      "[550]\ttraining's rmse: 0.0805657\tvalid_1's rmse: 0.0836663\n",
      "[575]\ttraining's rmse: 0.0805196\tvalid_1's rmse: 0.0836541\n",
      "[600]\ttraining's rmse: 0.080475\tvalid_1's rmse: 0.0836423\n",
      "[625]\ttraining's rmse: 0.0804403\tvalid_1's rmse: 0.0836322\n",
      "[650]\ttraining's rmse: 0.0803992\tvalid_1's rmse: 0.083622\n",
      "[675]\ttraining's rmse: 0.0803574\tvalid_1's rmse: 0.0836095\n",
      "[700]\ttraining's rmse: 0.0803216\tvalid_1's rmse: 0.0836001\n",
      "[725]\ttraining's rmse: 0.0802866\tvalid_1's rmse: 0.0835909\n",
      "[750]\ttraining's rmse: 0.0802527\tvalid_1's rmse: 0.0835826\n",
      "[775]\ttraining's rmse: 0.0802268\tvalid_1's rmse: 0.083575\n",
      "[800]\ttraining's rmse: 0.080192\tvalid_1's rmse: 0.0835668\n",
      "[825]\ttraining's rmse: 0.0801651\tvalid_1's rmse: 0.0835599\n",
      "[850]\ttraining's rmse: 0.0801349\tvalid_1's rmse: 0.0835535\n",
      "[875]\ttraining's rmse: 0.0801094\tvalid_1's rmse: 0.0835476\n",
      "[900]\ttraining's rmse: 0.0800823\tvalid_1's rmse: 0.0835407\n",
      "[925]\ttraining's rmse: 0.0800577\tvalid_1's rmse: 0.0835351\n",
      "[950]\ttraining's rmse: 0.0800337\tvalid_1's rmse: 0.0835288\n",
      "[975]\ttraining's rmse: 0.0800101\tvalid_1's rmse: 0.0835234\n",
      "[1000]\ttraining's rmse: 0.0799848\tvalid_1's rmse: 0.0835179\n",
      "[1025]\ttraining's rmse: 0.079963\tvalid_1's rmse: 0.0835132\n",
      "[1050]\ttraining's rmse: 0.0799412\tvalid_1's rmse: 0.0835078\n",
      "[1075]\ttraining's rmse: 0.0799215\tvalid_1's rmse: 0.0835028\n",
      "[1100]\ttraining's rmse: 0.0799051\tvalid_1's rmse: 0.0834991\n",
      "[1125]\ttraining's rmse: 0.0798882\tvalid_1's rmse: 0.0834941\n",
      "[1150]\ttraining's rmse: 0.0798674\tvalid_1's rmse: 0.0834901\n",
      "[1175]\ttraining's rmse: 0.0798501\tvalid_1's rmse: 0.0834879\n",
      "[1200]\ttraining's rmse: 0.0798354\tvalid_1's rmse: 0.0834831\n",
      "[1225]\ttraining's rmse: 0.0798203\tvalid_1's rmse: 0.0834805\n",
      "[1250]\ttraining's rmse: 0.0798047\tvalid_1's rmse: 0.0834771\n",
      "[1275]\ttraining's rmse: 0.079788\tvalid_1's rmse: 0.0834751\n",
      "[1300]\ttraining's rmse: 0.0797724\tvalid_1's rmse: 0.0834719\n",
      "[1325]\ttraining's rmse: 0.0797587\tvalid_1's rmse: 0.0834693\n",
      "[1350]\ttraining's rmse: 0.0797449\tvalid_1's rmse: 0.0834665\n",
      "[1375]\ttraining's rmse: 0.0797333\tvalid_1's rmse: 0.0834635\n",
      "[1400]\ttraining's rmse: 0.0797246\tvalid_1's rmse: 0.0834606\n",
      "[1425]\ttraining's rmse: 0.0797109\tvalid_1's rmse: 0.0834587\n",
      "[1450]\ttraining's rmse: 0.0797006\tvalid_1's rmse: 0.0834572\n",
      "[1475]\ttraining's rmse: 0.0796893\tvalid_1's rmse: 0.0834533\n",
      "[1500]\ttraining's rmse: 0.079681\tvalid_1's rmse: 0.0834505\n",
      "[1525]\ttraining's rmse: 0.079673\tvalid_1's rmse: 0.083448\n",
      "[1550]\ttraining's rmse: 0.0796624\tvalid_1's rmse: 0.0834466\n",
      "[1575]\ttraining's rmse: 0.0796557\tvalid_1's rmse: 0.0834443\n",
      "[1600]\ttraining's rmse: 0.0796495\tvalid_1's rmse: 0.0834427\n",
      "[1625]\ttraining's rmse: 0.0796421\tvalid_1's rmse: 0.0834399\n",
      "[1650]\ttraining's rmse: 0.0796369\tvalid_1's rmse: 0.0834381\n",
      "[1675]\ttraining's rmse: 0.0796306\tvalid_1's rmse: 0.0834361\n",
      "[1700]\ttraining's rmse: 0.0796252\tvalid_1's rmse: 0.0834345\n",
      "[1725]\ttraining's rmse: 0.0796182\tvalid_1's rmse: 0.0834326\n",
      "[1750]\ttraining's rmse: 0.0796121\tvalid_1's rmse: 0.083431\n",
      "[1775]\ttraining's rmse: 0.0796049\tvalid_1's rmse: 0.0834297\n",
      "[1800]\ttraining's rmse: 0.0795991\tvalid_1's rmse: 0.0834283\n",
      "[1825]\ttraining's rmse: 0.0795931\tvalid_1's rmse: 0.0834264\n",
      "[1850]\ttraining's rmse: 0.0795863\tvalid_1's rmse: 0.0834246\n",
      "[1875]\ttraining's rmse: 0.0795826\tvalid_1's rmse: 0.0834243\n",
      "[1900]\ttraining's rmse: 0.0795785\tvalid_1's rmse: 0.0834235\n",
      "[1925]\ttraining's rmse: 0.0795739\tvalid_1's rmse: 0.083422\n",
      "[1950]\ttraining's rmse: 0.0795699\tvalid_1's rmse: 0.0834209\n",
      "[1975]\ttraining's rmse: 0.0795663\tvalid_1's rmse: 0.0834197\n",
      "[2000]\ttraining's rmse: 0.0795632\tvalid_1's rmse: 0.0834184\n",
      "[2025]\ttraining's rmse: 0.0795591\tvalid_1's rmse: 0.0834165\n",
      "[2050]\ttraining's rmse: 0.0795555\tvalid_1's rmse: 0.0834147\n",
      "[2075]\ttraining's rmse: 0.0795515\tvalid_1's rmse: 0.0834137\n",
      "[2100]\ttraining's rmse: 0.0795491\tvalid_1's rmse: 0.0834131\n",
      "[2125]\ttraining's rmse: 0.0795455\tvalid_1's rmse: 0.0834127\n",
      "[2150]\ttraining's rmse: 0.0795412\tvalid_1's rmse: 0.0834117\n",
      "[2175]\ttraining's rmse: 0.079538\tvalid_1's rmse: 0.0834113\n",
      "[2200]\ttraining's rmse: 0.0795347\tvalid_1's rmse: 0.0834107\n",
      "[2225]\ttraining's rmse: 0.0795322\tvalid_1's rmse: 0.0834089\n",
      "[2250]\ttraining's rmse: 0.07953\tvalid_1's rmse: 0.0834075\n",
      "[2275]\ttraining's rmse: 0.0795271\tvalid_1's rmse: 0.0834065\n",
      "[2300]\ttraining's rmse: 0.0795239\tvalid_1's rmse: 0.0834057\n",
      "[2325]\ttraining's rmse: 0.0795205\tvalid_1's rmse: 0.0834048\n",
      "[2350]\ttraining's rmse: 0.0795187\tvalid_1's rmse: 0.0834043\n",
      "[2375]\ttraining's rmse: 0.0795168\tvalid_1's rmse: 0.0834041\n",
      "[2400]\ttraining's rmse: 0.0795129\tvalid_1's rmse: 0.0834033\n",
      "[2425]\ttraining's rmse: 0.0795104\tvalid_1's rmse: 0.083403\n",
      "[2450]\ttraining's rmse: 0.079508\tvalid_1's rmse: 0.0834026\n",
      "[2475]\ttraining's rmse: 0.0795063\tvalid_1's rmse: 0.0834023\n",
      "[2500]\ttraining's rmse: 0.0795043\tvalid_1's rmse: 0.0834021\n",
      "[2525]\ttraining's rmse: 0.0795021\tvalid_1's rmse: 0.0834016\n",
      "[2550]\ttraining's rmse: 0.0795003\tvalid_1's rmse: 0.0834008\n",
      "[2575]\ttraining's rmse: 0.0794989\tvalid_1's rmse: 0.0834005\n",
      "[2600]\ttraining's rmse: 0.079498\tvalid_1's rmse: 0.0834005\n",
      "[2625]\ttraining's rmse: 0.0794965\tvalid_1's rmse: 0.0834001\n",
      "[2650]\ttraining's rmse: 0.0794954\tvalid_1's rmse: 0.0833995\n",
      "[2675]\ttraining's rmse: 0.0794941\tvalid_1's rmse: 0.0833991\n",
      "[2700]\ttraining's rmse: 0.0794929\tvalid_1's rmse: 0.0833987\n",
      "[2725]\ttraining's rmse: 0.0794909\tvalid_1's rmse: 0.0833991\n",
      "[2750]\ttraining's rmse: 0.0794897\tvalid_1's rmse: 0.0833986\n",
      "[2775]\ttraining's rmse: 0.0794879\tvalid_1's rmse: 0.0833981\n",
      "[2800]\ttraining's rmse: 0.0794858\tvalid_1's rmse: 0.083398\n",
      "[2825]\ttraining's rmse: 0.0794846\tvalid_1's rmse: 0.0833978\n",
      "[2850]\ttraining's rmse: 0.0794829\tvalid_1's rmse: 0.0833976\n",
      "[2875]\ttraining's rmse: 0.0794813\tvalid_1's rmse: 0.0833975\n",
      "[2900]\ttraining's rmse: 0.0794795\tvalid_1's rmse: 0.0833972\n",
      "[2925]\ttraining's rmse: 0.0794788\tvalid_1's rmse: 0.0833969\n",
      "[2950]\ttraining's rmse: 0.0794777\tvalid_1's rmse: 0.083397\n",
      "[2975]\ttraining's rmse: 0.0794764\tvalid_1's rmse: 0.0833971\n",
      "Early stopping, best iteration is:\n",
      "[2932]\ttraining's rmse: 0.0794785\tvalid_1's rmse: 0.0833968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0822156\tvalid_1's rmse: 0.0843254\n",
      "[50]\ttraining's rmse: 0.0821021\tvalid_1's rmse: 0.0842734\n",
      "[75]\ttraining's rmse: 0.0819844\tvalid_1's rmse: 0.0842224\n",
      "[100]\ttraining's rmse: 0.081878\tvalid_1's rmse: 0.0841769\n",
      "[125]\ttraining's rmse: 0.0817676\tvalid_1's rmse: 0.0841309\n",
      "[150]\ttraining's rmse: 0.0816656\tvalid_1's rmse: 0.08409\n",
      "[175]\ttraining's rmse: 0.0815836\tvalid_1's rmse: 0.0840543\n",
      "[200]\ttraining's rmse: 0.0814938\tvalid_1's rmse: 0.0840179\n",
      "[225]\ttraining's rmse: 0.0814056\tvalid_1's rmse: 0.0839842\n",
      "[250]\ttraining's rmse: 0.0813309\tvalid_1's rmse: 0.0839539\n",
      "[275]\ttraining's rmse: 0.0812611\tvalid_1's rmse: 0.0839264\n",
      "[300]\ttraining's rmse: 0.0811933\tvalid_1's rmse: 0.0839007\n",
      "[325]\ttraining's rmse: 0.0811215\tvalid_1's rmse: 0.0838754\n",
      "[350]\ttraining's rmse: 0.0810559\tvalid_1's rmse: 0.0838511\n",
      "[375]\ttraining's rmse: 0.0809998\tvalid_1's rmse: 0.08383\n",
      "[400]\ttraining's rmse: 0.0809384\tvalid_1's rmse: 0.0838096\n",
      "[425]\ttraining's rmse: 0.080884\tvalid_1's rmse: 0.0837892\n",
      "[450]\ttraining's rmse: 0.0808301\tvalid_1's rmse: 0.0837707\n",
      "[475]\ttraining's rmse: 0.0807836\tvalid_1's rmse: 0.0837531\n",
      "[500]\ttraining's rmse: 0.0807425\tvalid_1's rmse: 0.0837359\n",
      "[525]\ttraining's rmse: 0.0806894\tvalid_1's rmse: 0.0837197\n",
      "[550]\ttraining's rmse: 0.0806424\tvalid_1's rmse: 0.0837057\n",
      "[575]\ttraining's rmse: 0.0805997\tvalid_1's rmse: 0.0836916\n",
      "[600]\ttraining's rmse: 0.0805547\tvalid_1's rmse: 0.083677\n",
      "[625]\ttraining's rmse: 0.0805223\tvalid_1's rmse: 0.0836652\n",
      "[650]\ttraining's rmse: 0.0804819\tvalid_1's rmse: 0.0836525\n",
      "[675]\ttraining's rmse: 0.0804418\tvalid_1's rmse: 0.0836414\n",
      "[700]\ttraining's rmse: 0.0804071\tvalid_1's rmse: 0.0836307\n",
      "[725]\ttraining's rmse: 0.0803741\tvalid_1's rmse: 0.0836219\n",
      "[750]\ttraining's rmse: 0.0803413\tvalid_1's rmse: 0.0836121\n",
      "[775]\ttraining's rmse: 0.0803144\tvalid_1's rmse: 0.0836032\n",
      "[800]\ttraining's rmse: 0.0802811\tvalid_1's rmse: 0.0835947\n",
      "[825]\ttraining's rmse: 0.0802523\tvalid_1's rmse: 0.0835864\n",
      "[850]\ttraining's rmse: 0.080225\tvalid_1's rmse: 0.0835791\n",
      "[875]\ttraining's rmse: 0.0802011\tvalid_1's rmse: 0.083572\n",
      "[900]\ttraining's rmse: 0.0801747\tvalid_1's rmse: 0.083565\n",
      "[925]\ttraining's rmse: 0.0801484\tvalid_1's rmse: 0.0835596\n",
      "[950]\ttraining's rmse: 0.0801232\tvalid_1's rmse: 0.0835521\n",
      "[975]\ttraining's rmse: 0.0801003\tvalid_1's rmse: 0.0835465\n",
      "[1000]\ttraining's rmse: 0.0800791\tvalid_1's rmse: 0.0835415\n",
      "[1025]\ttraining's rmse: 0.0800557\tvalid_1's rmse: 0.083537\n",
      "[1050]\ttraining's rmse: 0.0800367\tvalid_1's rmse: 0.083532\n",
      "[1075]\ttraining's rmse: 0.0800175\tvalid_1's rmse: 0.083529\n",
      "[1100]\ttraining's rmse: 0.0800021\tvalid_1's rmse: 0.0835239\n",
      "[1125]\ttraining's rmse: 0.079984\tvalid_1's rmse: 0.0835199\n",
      "[1150]\ttraining's rmse: 0.079968\tvalid_1's rmse: 0.0835164\n",
      "[1175]\ttraining's rmse: 0.0799528\tvalid_1's rmse: 0.0835129\n",
      "[1200]\ttraining's rmse: 0.0799378\tvalid_1's rmse: 0.0835092\n",
      "[1225]\ttraining's rmse: 0.0799251\tvalid_1's rmse: 0.0835061\n",
      "[1250]\ttraining's rmse: 0.0799106\tvalid_1's rmse: 0.0835027\n",
      "[1275]\ttraining's rmse: 0.0798934\tvalid_1's rmse: 0.0835011\n",
      "[1300]\ttraining's rmse: 0.079881\tvalid_1's rmse: 0.0834982\n",
      "[1325]\ttraining's rmse: 0.0798695\tvalid_1's rmse: 0.0834955\n",
      "[1350]\ttraining's rmse: 0.079859\tvalid_1's rmse: 0.0834938\n",
      "[1375]\ttraining's rmse: 0.0798464\tvalid_1's rmse: 0.0834922\n",
      "[1400]\ttraining's rmse: 0.079838\tvalid_1's rmse: 0.0834895\n",
      "[1425]\ttraining's rmse: 0.0798275\tvalid_1's rmse: 0.0834881\n",
      "[1450]\ttraining's rmse: 0.0798159\tvalid_1's rmse: 0.0834862\n",
      "[1475]\ttraining's rmse: 0.0798073\tvalid_1's rmse: 0.0834842\n",
      "[1500]\ttraining's rmse: 0.079798\tvalid_1's rmse: 0.0834824\n",
      "[1525]\ttraining's rmse: 0.0797906\tvalid_1's rmse: 0.0834806\n",
      "[1550]\ttraining's rmse: 0.0797812\tvalid_1's rmse: 0.0834792\n",
      "[1575]\ttraining's rmse: 0.0797745\tvalid_1's rmse: 0.0834774\n",
      "[1600]\ttraining's rmse: 0.0797686\tvalid_1's rmse: 0.0834771\n",
      "[1625]\ttraining's rmse: 0.0797631\tvalid_1's rmse: 0.0834762\n",
      "[1650]\ttraining's rmse: 0.0797567\tvalid_1's rmse: 0.0834758\n",
      "[1675]\ttraining's rmse: 0.079752\tvalid_1's rmse: 0.0834751\n",
      "[1700]\ttraining's rmse: 0.0797461\tvalid_1's rmse: 0.0834738\n",
      "[1725]\ttraining's rmse: 0.0797401\tvalid_1's rmse: 0.0834728\n",
      "[1750]\ttraining's rmse: 0.079733\tvalid_1's rmse: 0.083472\n",
      "[1775]\ttraining's rmse: 0.0797275\tvalid_1's rmse: 0.0834718\n",
      "[1800]\ttraining's rmse: 0.0797222\tvalid_1's rmse: 0.0834713\n",
      "[1825]\ttraining's rmse: 0.0797162\tvalid_1's rmse: 0.0834706\n",
      "[1850]\ttraining's rmse: 0.0797118\tvalid_1's rmse: 0.0834699\n",
      "[1875]\ttraining's rmse: 0.0797062\tvalid_1's rmse: 0.0834691\n",
      "[1900]\ttraining's rmse: 0.0797032\tvalid_1's rmse: 0.083469\n",
      "[1925]\ttraining's rmse: 0.079699\tvalid_1's rmse: 0.0834683\n",
      "[1950]\ttraining's rmse: 0.0796952\tvalid_1's rmse: 0.0834677\n",
      "[1975]\ttraining's rmse: 0.0796907\tvalid_1's rmse: 0.0834675\n",
      "[2000]\ttraining's rmse: 0.0796863\tvalid_1's rmse: 0.0834673\n",
      "[2025]\ttraining's rmse: 0.0796829\tvalid_1's rmse: 0.0834669\n",
      "[2050]\ttraining's rmse: 0.0796794\tvalid_1's rmse: 0.0834666\n",
      "[2075]\ttraining's rmse: 0.0796764\tvalid_1's rmse: 0.0834665\n",
      "[2100]\ttraining's rmse: 0.079674\tvalid_1's rmse: 0.0834662\n",
      "[2125]\ttraining's rmse: 0.0796719\tvalid_1's rmse: 0.083466\n",
      "[2150]\ttraining's rmse: 0.079669\tvalid_1's rmse: 0.0834659\n",
      "[2175]\ttraining's rmse: 0.079665\tvalid_1's rmse: 0.0834657\n",
      "[2200]\ttraining's rmse: 0.0796628\tvalid_1's rmse: 0.0834655\n",
      "[2225]\ttraining's rmse: 0.0796607\tvalid_1's rmse: 0.0834652\n",
      "[2250]\ttraining's rmse: 0.0796578\tvalid_1's rmse: 0.0834647\n",
      "[2275]\ttraining's rmse: 0.079654\tvalid_1's rmse: 0.083464\n",
      "[2300]\ttraining's rmse: 0.0796501\tvalid_1's rmse: 0.0834634\n",
      "[2325]\ttraining's rmse: 0.0796473\tvalid_1's rmse: 0.0834634\n",
      "[2350]\ttraining's rmse: 0.079646\tvalid_1's rmse: 0.0834632\n",
      "[2375]\ttraining's rmse: 0.0796437\tvalid_1's rmse: 0.0834634\n",
      "[2400]\ttraining's rmse: 0.0796398\tvalid_1's rmse: 0.0834633\n",
      "Early stopping, best iteration is:\n",
      "[2352]\ttraining's rmse: 0.0796456\tvalid_1's rmse: 0.0834631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0841674\tvalid_1's rmse: 0.0803695\n",
      "[50]\ttraining's rmse: 0.0840612\tvalid_1's rmse: 0.0803215\n",
      "[75]\ttraining's rmse: 0.0839507\tvalid_1's rmse: 0.0802724\n",
      "[100]\ttraining's rmse: 0.0838505\tvalid_1's rmse: 0.0802306\n",
      "[125]\ttraining's rmse: 0.083747\tvalid_1's rmse: 0.0801872\n",
      "[150]\ttraining's rmse: 0.0836493\tvalid_1's rmse: 0.0801486\n",
      "[175]\ttraining's rmse: 0.0835688\tvalid_1's rmse: 0.0801146\n",
      "[200]\ttraining's rmse: 0.0834807\tvalid_1's rmse: 0.0800822\n",
      "[225]\ttraining's rmse: 0.0833969\tvalid_1's rmse: 0.0800497\n",
      "[250]\ttraining's rmse: 0.0833265\tvalid_1's rmse: 0.0800216\n",
      "[275]\ttraining's rmse: 0.0832618\tvalid_1's rmse: 0.079996\n",
      "[300]\ttraining's rmse: 0.0831983\tvalid_1's rmse: 0.0799714\n",
      "[325]\ttraining's rmse: 0.0831328\tvalid_1's rmse: 0.0799493\n",
      "[350]\ttraining's rmse: 0.0830697\tvalid_1's rmse: 0.0799273\n",
      "[375]\ttraining's rmse: 0.0830158\tvalid_1's rmse: 0.0799103\n",
      "[400]\ttraining's rmse: 0.082959\tvalid_1's rmse: 0.0798916\n",
      "[425]\ttraining's rmse: 0.0829066\tvalid_1's rmse: 0.0798749\n",
      "[450]\ttraining's rmse: 0.0828565\tvalid_1's rmse: 0.079861\n",
      "[475]\ttraining's rmse: 0.0828141\tvalid_1's rmse: 0.0798506\n",
      "[500]\ttraining's rmse: 0.0827776\tvalid_1's rmse: 0.0798379\n",
      "[525]\ttraining's rmse: 0.0827283\tvalid_1's rmse: 0.0798246\n",
      "[550]\ttraining's rmse: 0.0826841\tvalid_1's rmse: 0.0798125\n",
      "[575]\ttraining's rmse: 0.082641\tvalid_1's rmse: 0.0797996\n",
      "[600]\ttraining's rmse: 0.0825984\tvalid_1's rmse: 0.079791\n",
      "[625]\ttraining's rmse: 0.0825654\tvalid_1's rmse: 0.0797807\n",
      "[650]\ttraining's rmse: 0.0825252\tvalid_1's rmse: 0.0797709\n",
      "[675]\ttraining's rmse: 0.0824834\tvalid_1's rmse: 0.0797621\n",
      "[700]\ttraining's rmse: 0.0824484\tvalid_1's rmse: 0.0797536\n",
      "[725]\ttraining's rmse: 0.0824158\tvalid_1's rmse: 0.079753\n",
      "[750]\ttraining's rmse: 0.0823829\tvalid_1's rmse: 0.0797474\n",
      "[775]\ttraining's rmse: 0.0823571\tvalid_1's rmse: 0.0797416\n",
      "[800]\ttraining's rmse: 0.0823236\tvalid_1's rmse: 0.0797389\n",
      "[825]\ttraining's rmse: 0.0822963\tvalid_1's rmse: 0.0797376\n",
      "[850]\ttraining's rmse: 0.0822651\tvalid_1's rmse: 0.0797372\n",
      "[875]\ttraining's rmse: 0.0822403\tvalid_1's rmse: 0.0797332\n",
      "[900]\ttraining's rmse: 0.0822121\tvalid_1's rmse: 0.0797347\n",
      "[925]\ttraining's rmse: 0.0821865\tvalid_1's rmse: 0.0797361\n",
      "Early stopping, best iteration is:\n",
      "[889]\ttraining's rmse: 0.0822245\tvalid_1's rmse: 0.0797306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0788611\tvalid_1's rmse: 0.081529\n",
      "[50]\ttraining's rmse: 0.0787467\tvalid_1's rmse: 0.0814757\n",
      "[75]\ttraining's rmse: 0.0786358\tvalid_1's rmse: 0.0814223\n",
      "[100]\ttraining's rmse: 0.0785335\tvalid_1's rmse: 0.0813774\n",
      "[125]\ttraining's rmse: 0.0784294\tvalid_1's rmse: 0.0813322\n",
      "[150]\ttraining's rmse: 0.0783343\tvalid_1's rmse: 0.0812907\n",
      "[175]\ttraining's rmse: 0.0782566\tvalid_1's rmse: 0.0812564\n",
      "[200]\ttraining's rmse: 0.0781717\tvalid_1's rmse: 0.0812212\n",
      "[225]\ttraining's rmse: 0.0780918\tvalid_1's rmse: 0.0811866\n",
      "[250]\ttraining's rmse: 0.0780234\tvalid_1's rmse: 0.0811553\n",
      "[275]\ttraining's rmse: 0.0779578\tvalid_1's rmse: 0.0811266\n",
      "[300]\ttraining's rmse: 0.0778944\tvalid_1's rmse: 0.0811004\n",
      "[325]\ttraining's rmse: 0.07783\tvalid_1's rmse: 0.0810742\n",
      "[350]\ttraining's rmse: 0.0777677\tvalid_1's rmse: 0.0810494\n",
      "[375]\ttraining's rmse: 0.0777173\tvalid_1's rmse: 0.0810292\n",
      "[400]\ttraining's rmse: 0.0776632\tvalid_1's rmse: 0.0810089\n",
      "[425]\ttraining's rmse: 0.0776152\tvalid_1's rmse: 0.0809899\n",
      "[450]\ttraining's rmse: 0.0775676\tvalid_1's rmse: 0.0809701\n",
      "[475]\ttraining's rmse: 0.0775283\tvalid_1's rmse: 0.0809519\n",
      "[500]\ttraining's rmse: 0.0774926\tvalid_1's rmse: 0.0809338\n",
      "[525]\ttraining's rmse: 0.0774473\tvalid_1's rmse: 0.0809178\n",
      "[550]\ttraining's rmse: 0.0774061\tvalid_1's rmse: 0.0809011\n",
      "[575]\ttraining's rmse: 0.0773682\tvalid_1's rmse: 0.0808868\n",
      "[600]\ttraining's rmse: 0.0773297\tvalid_1's rmse: 0.0808717\n",
      "[625]\ttraining's rmse: 0.0772999\tvalid_1's rmse: 0.0808602\n",
      "[650]\ttraining's rmse: 0.0772643\tvalid_1's rmse: 0.0808471\n",
      "[675]\ttraining's rmse: 0.0772296\tvalid_1's rmse: 0.0808344\n",
      "[700]\ttraining's rmse: 0.077199\tvalid_1's rmse: 0.0808233\n",
      "[725]\ttraining's rmse: 0.0771695\tvalid_1's rmse: 0.0808118\n",
      "[750]\ttraining's rmse: 0.0771433\tvalid_1's rmse: 0.0808017\n",
      "[775]\ttraining's rmse: 0.0771222\tvalid_1's rmse: 0.0807922\n",
      "[800]\ttraining's rmse: 0.0770928\tvalid_1's rmse: 0.0807836\n",
      "[825]\ttraining's rmse: 0.0770668\tvalid_1's rmse: 0.0807731\n",
      "[850]\ttraining's rmse: 0.0770406\tvalid_1's rmse: 0.0807656\n",
      "[875]\ttraining's rmse: 0.0770168\tvalid_1's rmse: 0.0807573\n",
      "[900]\ttraining's rmse: 0.0769925\tvalid_1's rmse: 0.0807495\n",
      "[925]\ttraining's rmse: 0.0769719\tvalid_1's rmse: 0.0807419\n",
      "[950]\ttraining's rmse: 0.076952\tvalid_1's rmse: 0.0807344\n",
      "[975]\ttraining's rmse: 0.0769312\tvalid_1's rmse: 0.0807289\n",
      "[1000]\ttraining's rmse: 0.0769119\tvalid_1's rmse: 0.0807213\n",
      "[1025]\ttraining's rmse: 0.0768888\tvalid_1's rmse: 0.0807143\n",
      "[1050]\ttraining's rmse: 0.0768707\tvalid_1's rmse: 0.0807079\n",
      "[1075]\ttraining's rmse: 0.0768546\tvalid_1's rmse: 0.080703\n",
      "[1100]\ttraining's rmse: 0.0768401\tvalid_1's rmse: 0.0806972\n",
      "[1125]\ttraining's rmse: 0.0768258\tvalid_1's rmse: 0.0806919\n",
      "[1150]\ttraining's rmse: 0.076814\tvalid_1's rmse: 0.0806866\n",
      "[1175]\ttraining's rmse: 0.0768008\tvalid_1's rmse: 0.0806839\n",
      "[1200]\ttraining's rmse: 0.0767879\tvalid_1's rmse: 0.08068\n",
      "[1225]\ttraining's rmse: 0.0767738\tvalid_1's rmse: 0.0806747\n",
      "[1250]\ttraining's rmse: 0.0767631\tvalid_1's rmse: 0.0806716\n",
      "[1275]\ttraining's rmse: 0.076749\tvalid_1's rmse: 0.0806679\n",
      "[1300]\ttraining's rmse: 0.0767381\tvalid_1's rmse: 0.0806628\n",
      "[1325]\ttraining's rmse: 0.0767274\tvalid_1's rmse: 0.0806598\n",
      "[1350]\ttraining's rmse: 0.0767147\tvalid_1's rmse: 0.0806559\n",
      "[1375]\ttraining's rmse: 0.0767034\tvalid_1's rmse: 0.080653\n",
      "[1400]\ttraining's rmse: 0.0766958\tvalid_1's rmse: 0.0806505\n",
      "[1425]\ttraining's rmse: 0.0766845\tvalid_1's rmse: 0.0806486\n",
      "[1450]\ttraining's rmse: 0.0766736\tvalid_1's rmse: 0.0806443\n",
      "[1475]\ttraining's rmse: 0.0766646\tvalid_1's rmse: 0.0806421\n",
      "[1500]\ttraining's rmse: 0.0766559\tvalid_1's rmse: 0.0806395\n",
      "[1525]\ttraining's rmse: 0.0766491\tvalid_1's rmse: 0.080637\n",
      "[1550]\ttraining's rmse: 0.0766417\tvalid_1's rmse: 0.0806351\n",
      "[1575]\ttraining's rmse: 0.076635\tvalid_1's rmse: 0.0806327\n",
      "[1600]\ttraining's rmse: 0.0766302\tvalid_1's rmse: 0.0806311\n",
      "[1625]\ttraining's rmse: 0.0766239\tvalid_1's rmse: 0.0806282\n",
      "[1650]\ttraining's rmse: 0.0766179\tvalid_1's rmse: 0.0806253\n",
      "[1675]\ttraining's rmse: 0.0766131\tvalid_1's rmse: 0.0806236\n",
      "[1700]\ttraining's rmse: 0.0766081\tvalid_1's rmse: 0.0806209\n",
      "[1725]\ttraining's rmse: 0.0766027\tvalid_1's rmse: 0.0806191\n",
      "[1750]\ttraining's rmse: 0.0765977\tvalid_1's rmse: 0.0806174\n",
      "[1775]\ttraining's rmse: 0.0765929\tvalid_1's rmse: 0.0806162\n",
      "[1800]\ttraining's rmse: 0.0765868\tvalid_1's rmse: 0.080615\n",
      "[1825]\ttraining's rmse: 0.0765821\tvalid_1's rmse: 0.0806125\n",
      "[1850]\ttraining's rmse: 0.0765776\tvalid_1's rmse: 0.0806103\n",
      "[1875]\ttraining's rmse: 0.0765729\tvalid_1's rmse: 0.0806092\n",
      "[1900]\ttraining's rmse: 0.0765698\tvalid_1's rmse: 0.0806088\n",
      "[1925]\ttraining's rmse: 0.0765649\tvalid_1's rmse: 0.0806069\n",
      "[1950]\ttraining's rmse: 0.0765623\tvalid_1's rmse: 0.0806053\n",
      "[1975]\ttraining's rmse: 0.0765598\tvalid_1's rmse: 0.0806047\n",
      "[2000]\ttraining's rmse: 0.076555\tvalid_1's rmse: 0.0806039\n",
      "[2025]\ttraining's rmse: 0.0765527\tvalid_1's rmse: 0.0806024\n",
      "[2050]\ttraining's rmse: 0.0765486\tvalid_1's rmse: 0.0806018\n",
      "[2075]\ttraining's rmse: 0.0765464\tvalid_1's rmse: 0.0806018\n",
      "[2100]\ttraining's rmse: 0.0765439\tvalid_1's rmse: 0.0806013\n",
      "[2125]\ttraining's rmse: 0.0765409\tvalid_1's rmse: 0.0805999\n",
      "[2150]\ttraining's rmse: 0.0765376\tvalid_1's rmse: 0.0805985\n",
      "[2175]\ttraining's rmse: 0.0765359\tvalid_1's rmse: 0.080598\n",
      "[2200]\ttraining's rmse: 0.0765334\tvalid_1's rmse: 0.0805972\n",
      "[2225]\ttraining's rmse: 0.0765314\tvalid_1's rmse: 0.0805962\n",
      "[2250]\ttraining's rmse: 0.0765286\tvalid_1's rmse: 0.080595\n",
      "[2275]\ttraining's rmse: 0.0765251\tvalid_1's rmse: 0.0805948\n",
      "[2300]\ttraining's rmse: 0.076523\tvalid_1's rmse: 0.0805941\n",
      "[2325]\ttraining's rmse: 0.0765209\tvalid_1's rmse: 0.080593\n",
      "[2350]\ttraining's rmse: 0.0765192\tvalid_1's rmse: 0.080592\n",
      "[2375]\ttraining's rmse: 0.0765171\tvalid_1's rmse: 0.0805919\n",
      "[2400]\ttraining's rmse: 0.0765146\tvalid_1's rmse: 0.0805915\n",
      "[2425]\ttraining's rmse: 0.0765123\tvalid_1's rmse: 0.0805911\n",
      "[2450]\ttraining's rmse: 0.0765109\tvalid_1's rmse: 0.0805899\n",
      "[2475]\ttraining's rmse: 0.0765096\tvalid_1's rmse: 0.0805893\n",
      "[2500]\ttraining's rmse: 0.0765083\tvalid_1's rmse: 0.080589\n",
      "[2525]\ttraining's rmse: 0.0765065\tvalid_1's rmse: 0.0805879\n",
      "[2550]\ttraining's rmse: 0.0765049\tvalid_1's rmse: 0.0805881\n",
      "[2575]\ttraining's rmse: 0.0765033\tvalid_1's rmse: 0.0805878\n",
      "[2600]\ttraining's rmse: 0.0765009\tvalid_1's rmse: 0.0805873\n",
      "[2625]\ttraining's rmse: 0.0764986\tvalid_1's rmse: 0.0805869\n",
      "[2650]\ttraining's rmse: 0.0764974\tvalid_1's rmse: 0.0805866\n",
      "[2675]\ttraining's rmse: 0.0764964\tvalid_1's rmse: 0.0805866\n",
      "[2700]\ttraining's rmse: 0.0764948\tvalid_1's rmse: 0.0805856\n",
      "[2725]\ttraining's rmse: 0.0764926\tvalid_1's rmse: 0.0805856\n",
      "[2750]\ttraining's rmse: 0.0764909\tvalid_1's rmse: 0.0805852\n",
      "[2775]\ttraining's rmse: 0.0764893\tvalid_1's rmse: 0.080585\n",
      "[2800]\ttraining's rmse: 0.0764881\tvalid_1's rmse: 0.0805851\n",
      "Early stopping, best iteration is:\n",
      "[2772]\ttraining's rmse: 0.0764894\tvalid_1's rmse: 0.0805849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0791222\tvalid_1's rmse: 0.0810208\n",
      "[50]\ttraining's rmse: 0.0790159\tvalid_1's rmse: 0.0809659\n",
      "[75]\ttraining's rmse: 0.0789085\tvalid_1's rmse: 0.0809124\n",
      "[100]\ttraining's rmse: 0.0788131\tvalid_1's rmse: 0.0808661\n",
      "[125]\ttraining's rmse: 0.0787131\tvalid_1's rmse: 0.0808193\n",
      "[150]\ttraining's rmse: 0.0786229\tvalid_1's rmse: 0.0807767\n",
      "[175]\ttraining's rmse: 0.0785474\tvalid_1's rmse: 0.0807413\n",
      "[200]\ttraining's rmse: 0.0784618\tvalid_1's rmse: 0.0807052\n",
      "[225]\ttraining's rmse: 0.0783808\tvalid_1's rmse: 0.0806694\n",
      "[250]\ttraining's rmse: 0.0783123\tvalid_1's rmse: 0.0806383\n",
      "[275]\ttraining's rmse: 0.0782493\tvalid_1's rmse: 0.0806097\n",
      "[300]\ttraining's rmse: 0.0781868\tvalid_1's rmse: 0.0805826\n",
      "[325]\ttraining's rmse: 0.0781215\tvalid_1's rmse: 0.0805566\n",
      "[350]\ttraining's rmse: 0.0780604\tvalid_1's rmse: 0.0805334\n",
      "[375]\ttraining's rmse: 0.0780078\tvalid_1's rmse: 0.0805132\n",
      "[400]\ttraining's rmse: 0.0779527\tvalid_1's rmse: 0.0804924\n",
      "[425]\ttraining's rmse: 0.0779027\tvalid_1's rmse: 0.0804729\n",
      "[450]\ttraining's rmse: 0.077854\tvalid_1's rmse: 0.0804536\n",
      "[475]\ttraining's rmse: 0.0778098\tvalid_1's rmse: 0.0804373\n",
      "[500]\ttraining's rmse: 0.0777709\tvalid_1's rmse: 0.0804212\n",
      "[525]\ttraining's rmse: 0.0777234\tvalid_1's rmse: 0.0804053\n",
      "[550]\ttraining's rmse: 0.0776789\tvalid_1's rmse: 0.0803895\n",
      "[575]\ttraining's rmse: 0.0776407\tvalid_1's rmse: 0.0803774\n",
      "[600]\ttraining's rmse: 0.0776022\tvalid_1's rmse: 0.0803642\n",
      "[625]\ttraining's rmse: 0.0775707\tvalid_1's rmse: 0.0803528\n",
      "[650]\ttraining's rmse: 0.0775324\tvalid_1's rmse: 0.0803413\n",
      "[675]\ttraining's rmse: 0.0774927\tvalid_1's rmse: 0.0803298\n",
      "[700]\ttraining's rmse: 0.0774573\tvalid_1's rmse: 0.0803194\n",
      "[725]\ttraining's rmse: 0.0774263\tvalid_1's rmse: 0.080311\n",
      "[750]\ttraining's rmse: 0.0773949\tvalid_1's rmse: 0.0803026\n",
      "[775]\ttraining's rmse: 0.07737\tvalid_1's rmse: 0.0802944\n",
      "[800]\ttraining's rmse: 0.0773382\tvalid_1's rmse: 0.0802869\n",
      "[825]\ttraining's rmse: 0.0773118\tvalid_1's rmse: 0.0802789\n",
      "[850]\ttraining's rmse: 0.077285\tvalid_1's rmse: 0.0802716\n",
      "[875]\ttraining's rmse: 0.0772592\tvalid_1's rmse: 0.0802647\n",
      "[900]\ttraining's rmse: 0.0772348\tvalid_1's rmse: 0.0802574\n",
      "[925]\ttraining's rmse: 0.0772117\tvalid_1's rmse: 0.0802514\n",
      "[950]\ttraining's rmse: 0.0771894\tvalid_1's rmse: 0.0802465\n",
      "[975]\ttraining's rmse: 0.0771693\tvalid_1's rmse: 0.080241\n",
      "[1000]\ttraining's rmse: 0.0771481\tvalid_1's rmse: 0.0802352\n",
      "[1025]\ttraining's rmse: 0.0771257\tvalid_1's rmse: 0.0802307\n",
      "[1050]\ttraining's rmse: 0.0771073\tvalid_1's rmse: 0.0802258\n",
      "[1075]\ttraining's rmse: 0.0770889\tvalid_1's rmse: 0.0802223\n",
      "[1100]\ttraining's rmse: 0.0770769\tvalid_1's rmse: 0.080218\n",
      "[1125]\ttraining's rmse: 0.0770608\tvalid_1's rmse: 0.0802146\n",
      "[1150]\ttraining's rmse: 0.0770457\tvalid_1's rmse: 0.0802119\n",
      "[1175]\ttraining's rmse: 0.0770313\tvalid_1's rmse: 0.0802087\n",
      "[1200]\ttraining's rmse: 0.0770175\tvalid_1's rmse: 0.0802055\n",
      "[1225]\ttraining's rmse: 0.0770038\tvalid_1's rmse: 0.0802026\n",
      "[1250]\ttraining's rmse: 0.0769917\tvalid_1's rmse: 0.0801997\n",
      "[1275]\ttraining's rmse: 0.0769771\tvalid_1's rmse: 0.0801975\n",
      "[1300]\ttraining's rmse: 0.0769656\tvalid_1's rmse: 0.0801952\n",
      "[1325]\ttraining's rmse: 0.076954\tvalid_1's rmse: 0.0801927\n",
      "[1350]\ttraining's rmse: 0.0769434\tvalid_1's rmse: 0.0801909\n",
      "[1375]\ttraining's rmse: 0.0769325\tvalid_1's rmse: 0.0801889\n",
      "[1400]\ttraining's rmse: 0.0769254\tvalid_1's rmse: 0.0801869\n",
      "[1425]\ttraining's rmse: 0.0769166\tvalid_1's rmse: 0.0801862\n",
      "[1450]\ttraining's rmse: 0.0769067\tvalid_1's rmse: 0.0801852\n",
      "[1475]\ttraining's rmse: 0.0768993\tvalid_1's rmse: 0.0801839\n",
      "[1500]\ttraining's rmse: 0.0768914\tvalid_1's rmse: 0.0801823\n",
      "[1525]\ttraining's rmse: 0.0768825\tvalid_1's rmse: 0.080181\n",
      "[1550]\ttraining's rmse: 0.0768746\tvalid_1's rmse: 0.0801797\n",
      "[1575]\ttraining's rmse: 0.0768653\tvalid_1's rmse: 0.0801778\n",
      "[1600]\ttraining's rmse: 0.0768592\tvalid_1's rmse: 0.0801771\n",
      "[1625]\ttraining's rmse: 0.076852\tvalid_1's rmse: 0.0801755\n",
      "[1650]\ttraining's rmse: 0.0768455\tvalid_1's rmse: 0.0801747\n",
      "[1675]\ttraining's rmse: 0.0768409\tvalid_1's rmse: 0.0801736\n",
      "[1700]\ttraining's rmse: 0.0768368\tvalid_1's rmse: 0.0801729\n",
      "[1725]\ttraining's rmse: 0.0768314\tvalid_1's rmse: 0.080172\n",
      "[1750]\ttraining's rmse: 0.0768251\tvalid_1's rmse: 0.0801713\n",
      "[1775]\ttraining's rmse: 0.0768206\tvalid_1's rmse: 0.0801707\n",
      "[1800]\ttraining's rmse: 0.0768161\tvalid_1's rmse: 0.0801702\n",
      "[1825]\ttraining's rmse: 0.0768101\tvalid_1's rmse: 0.0801694\n",
      "[1850]\ttraining's rmse: 0.0768057\tvalid_1's rmse: 0.0801685\n",
      "[1875]\ttraining's rmse: 0.0768023\tvalid_1's rmse: 0.080168\n",
      "[1900]\ttraining's rmse: 0.0767978\tvalid_1's rmse: 0.0801676\n",
      "[1925]\ttraining's rmse: 0.0767938\tvalid_1's rmse: 0.0801673\n",
      "[1950]\ttraining's rmse: 0.07679\tvalid_1's rmse: 0.0801666\n",
      "[1975]\ttraining's rmse: 0.0767866\tvalid_1's rmse: 0.0801659\n",
      "[2000]\ttraining's rmse: 0.076783\tvalid_1's rmse: 0.0801653\n",
      "[2025]\ttraining's rmse: 0.0767798\tvalid_1's rmse: 0.0801648\n",
      "[2050]\ttraining's rmse: 0.076776\tvalid_1's rmse: 0.0801646\n",
      "[2075]\ttraining's rmse: 0.0767733\tvalid_1's rmse: 0.0801645\n",
      "[2100]\ttraining's rmse: 0.0767707\tvalid_1's rmse: 0.0801643\n",
      "[2125]\ttraining's rmse: 0.076766\tvalid_1's rmse: 0.0801635\n",
      "[2150]\ttraining's rmse: 0.0767626\tvalid_1's rmse: 0.0801635\n",
      "[2175]\ttraining's rmse: 0.0767603\tvalid_1's rmse: 0.0801634\n",
      "[2200]\ttraining's rmse: 0.0767576\tvalid_1's rmse: 0.0801636\n",
      "Early stopping, best iteration is:\n",
      "[2160]\ttraining's rmse: 0.0767616\tvalid_1's rmse: 0.0801632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0811668\tvalid_1's rmse: 0.0768548\n",
      "[50]\ttraining's rmse: 0.0810605\tvalid_1's rmse: 0.0768071\n",
      "[75]\ttraining's rmse: 0.0809524\tvalid_1's rmse: 0.0767603\n",
      "[100]\ttraining's rmse: 0.0808565\tvalid_1's rmse: 0.0767193\n",
      "[125]\ttraining's rmse: 0.0807568\tvalid_1's rmse: 0.0766774\n",
      "[150]\ttraining's rmse: 0.0806657\tvalid_1's rmse: 0.0766411\n",
      "[175]\ttraining's rmse: 0.0805914\tvalid_1's rmse: 0.0766112\n",
      "[200]\ttraining's rmse: 0.0805112\tvalid_1's rmse: 0.0765808\n",
      "[225]\ttraining's rmse: 0.0804326\tvalid_1's rmse: 0.0765512\n",
      "[250]\ttraining's rmse: 0.0803687\tvalid_1's rmse: 0.0765262\n",
      "[275]\ttraining's rmse: 0.080307\tvalid_1's rmse: 0.0765019\n",
      "[300]\ttraining's rmse: 0.0802457\tvalid_1's rmse: 0.0764799\n",
      "[325]\ttraining's rmse: 0.0801844\tvalid_1's rmse: 0.0764581\n",
      "[350]\ttraining's rmse: 0.0801255\tvalid_1's rmse: 0.0764392\n",
      "[375]\ttraining's rmse: 0.0800759\tvalid_1's rmse: 0.0764227\n",
      "[400]\ttraining's rmse: 0.0800211\tvalid_1's rmse: 0.0764048\n",
      "[425]\ttraining's rmse: 0.0799698\tvalid_1's rmse: 0.0763948\n",
      "[450]\ttraining's rmse: 0.079925\tvalid_1's rmse: 0.0763831\n",
      "[475]\ttraining's rmse: 0.0798831\tvalid_1's rmse: 0.0763698\n",
      "[500]\ttraining's rmse: 0.0798458\tvalid_1's rmse: 0.076357\n",
      "[525]\ttraining's rmse: 0.0797968\tvalid_1's rmse: 0.0763438\n",
      "[550]\ttraining's rmse: 0.0797528\tvalid_1's rmse: 0.0763381\n",
      "[575]\ttraining's rmse: 0.0797129\tvalid_1's rmse: 0.0763333\n",
      "[600]\ttraining's rmse: 0.0796718\tvalid_1's rmse: 0.0763331\n",
      "[625]\ttraining's rmse: 0.0796405\tvalid_1's rmse: 0.0763302\n",
      "Early stopping, best iteration is:\n",
      "[593]\ttraining's rmse: 0.0796857\tvalid_1's rmse: 0.0763259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0831963\tvalid_1's rmse: 0.0853034\n",
      "[50]\ttraining's rmse: 0.0830616\tvalid_1's rmse: 0.0852546\n",
      "[75]\ttraining's rmse: 0.0829204\tvalid_1's rmse: 0.0852047\n",
      "[100]\ttraining's rmse: 0.0827946\tvalid_1's rmse: 0.0851605\n",
      "[125]\ttraining's rmse: 0.0826641\tvalid_1's rmse: 0.0851179\n",
      "[150]\ttraining's rmse: 0.0825481\tvalid_1's rmse: 0.0850792\n",
      "[175]\ttraining's rmse: 0.0824543\tvalid_1's rmse: 0.0850443\n",
      "[200]\ttraining's rmse: 0.0823521\tvalid_1's rmse: 0.0850105\n",
      "[225]\ttraining's rmse: 0.0822485\tvalid_1's rmse: 0.0849773\n",
      "[250]\ttraining's rmse: 0.0821674\tvalid_1's rmse: 0.0849482\n",
      "[275]\ttraining's rmse: 0.0820863\tvalid_1's rmse: 0.0849225\n",
      "[300]\ttraining's rmse: 0.0820081\tvalid_1's rmse: 0.0848982\n",
      "[325]\ttraining's rmse: 0.0819276\tvalid_1's rmse: 0.0848743\n",
      "[350]\ttraining's rmse: 0.0818494\tvalid_1's rmse: 0.0848509\n",
      "[375]\ttraining's rmse: 0.0817863\tvalid_1's rmse: 0.0848316\n",
      "[400]\ttraining's rmse: 0.0817134\tvalid_1's rmse: 0.084812\n",
      "[425]\ttraining's rmse: 0.0816493\tvalid_1's rmse: 0.0847925\n",
      "[450]\ttraining's rmse: 0.0815929\tvalid_1's rmse: 0.0847736\n",
      "[475]\ttraining's rmse: 0.0815408\tvalid_1's rmse: 0.0847572\n",
      "[500]\ttraining's rmse: 0.081497\tvalid_1's rmse: 0.084742\n",
      "[525]\ttraining's rmse: 0.0814422\tvalid_1's rmse: 0.0847269\n",
      "[550]\ttraining's rmse: 0.0813904\tvalid_1's rmse: 0.0847127\n",
      "[575]\ttraining's rmse: 0.0813431\tvalid_1's rmse: 0.0846995\n",
      "[600]\ttraining's rmse: 0.0812951\tvalid_1's rmse: 0.0846881\n",
      "[625]\ttraining's rmse: 0.0812571\tvalid_1's rmse: 0.084677\n",
      "[650]\ttraining's rmse: 0.0812144\tvalid_1's rmse: 0.0846664\n",
      "[675]\ttraining's rmse: 0.0811688\tvalid_1's rmse: 0.0846553\n",
      "[700]\ttraining's rmse: 0.0811299\tvalid_1's rmse: 0.0846439\n",
      "[725]\ttraining's rmse: 0.0810944\tvalid_1's rmse: 0.0846344\n",
      "[750]\ttraining's rmse: 0.0810613\tvalid_1's rmse: 0.0846261\n",
      "[775]\ttraining's rmse: 0.0810332\tvalid_1's rmse: 0.0846177\n",
      "[800]\ttraining's rmse: 0.0809964\tvalid_1's rmse: 0.0846088\n",
      "[825]\ttraining's rmse: 0.0809667\tvalid_1's rmse: 0.0846015\n",
      "[850]\ttraining's rmse: 0.0809345\tvalid_1's rmse: 0.0845951\n",
      "[875]\ttraining's rmse: 0.0809058\tvalid_1's rmse: 0.0845879\n",
      "[900]\ttraining's rmse: 0.0808769\tvalid_1's rmse: 0.0845814\n",
      "[925]\ttraining's rmse: 0.0808504\tvalid_1's rmse: 0.0845757\n",
      "[950]\ttraining's rmse: 0.0808257\tvalid_1's rmse: 0.0845703\n",
      "[975]\ttraining's rmse: 0.080802\tvalid_1's rmse: 0.0845639\n",
      "[1000]\ttraining's rmse: 0.0807776\tvalid_1's rmse: 0.0845584\n",
      "[1025]\ttraining's rmse: 0.0807562\tvalid_1's rmse: 0.0845523\n",
      "[1050]\ttraining's rmse: 0.080734\tvalid_1's rmse: 0.0845474\n",
      "[1075]\ttraining's rmse: 0.0807123\tvalid_1's rmse: 0.0845435\n",
      "[1100]\ttraining's rmse: 0.0806941\tvalid_1's rmse: 0.0845383\n",
      "[1125]\ttraining's rmse: 0.0806737\tvalid_1's rmse: 0.0845335\n",
      "[1150]\ttraining's rmse: 0.0806553\tvalid_1's rmse: 0.0845303\n",
      "[1175]\ttraining's rmse: 0.0806372\tvalid_1's rmse: 0.084528\n",
      "[1200]\ttraining's rmse: 0.0806195\tvalid_1's rmse: 0.0845222\n",
      "[1225]\ttraining's rmse: 0.0806034\tvalid_1's rmse: 0.084519\n",
      "[1250]\ttraining's rmse: 0.0805891\tvalid_1's rmse: 0.0845155\n",
      "[1275]\ttraining's rmse: 0.0805732\tvalid_1's rmse: 0.0845132\n",
      "[1300]\ttraining's rmse: 0.0805589\tvalid_1's rmse: 0.084509\n",
      "[1325]\ttraining's rmse: 0.080546\tvalid_1's rmse: 0.0845059\n",
      "[1350]\ttraining's rmse: 0.0805319\tvalid_1's rmse: 0.0845038\n",
      "[1375]\ttraining's rmse: 0.0805187\tvalid_1's rmse: 0.0845011\n",
      "[1400]\ttraining's rmse: 0.080508\tvalid_1's rmse: 0.084498\n",
      "[1425]\ttraining's rmse: 0.0804931\tvalid_1's rmse: 0.0844954\n",
      "[1450]\ttraining's rmse: 0.0804823\tvalid_1's rmse: 0.0844931\n",
      "[1475]\ttraining's rmse: 0.0804714\tvalid_1's rmse: 0.0844909\n",
      "[1500]\ttraining's rmse: 0.0804621\tvalid_1's rmse: 0.0844878\n",
      "[1525]\ttraining's rmse: 0.080453\tvalid_1's rmse: 0.0844856\n",
      "[1550]\ttraining's rmse: 0.0804459\tvalid_1's rmse: 0.0844832\n",
      "[1575]\ttraining's rmse: 0.080437\tvalid_1's rmse: 0.0844813\n",
      "[1600]\ttraining's rmse: 0.08043\tvalid_1's rmse: 0.08448\n",
      "[1625]\ttraining's rmse: 0.0804224\tvalid_1's rmse: 0.084478\n",
      "[1650]\ttraining's rmse: 0.0804144\tvalid_1's rmse: 0.0844761\n",
      "[1675]\ttraining's rmse: 0.0804078\tvalid_1's rmse: 0.0844747\n",
      "[1700]\ttraining's rmse: 0.0804029\tvalid_1's rmse: 0.0844738\n",
      "[1725]\ttraining's rmse: 0.0803975\tvalid_1's rmse: 0.084472\n",
      "[1750]\ttraining's rmse: 0.0803915\tvalid_1's rmse: 0.0844703\n",
      "[1775]\ttraining's rmse: 0.0803853\tvalid_1's rmse: 0.0844696\n",
      "[1800]\ttraining's rmse: 0.0803798\tvalid_1's rmse: 0.0844688\n",
      "[1825]\ttraining's rmse: 0.0803749\tvalid_1's rmse: 0.0844673\n",
      "[1850]\ttraining's rmse: 0.0803705\tvalid_1's rmse: 0.0844657\n",
      "[1875]\ttraining's rmse: 0.0803661\tvalid_1's rmse: 0.0844652\n",
      "[1900]\ttraining's rmse: 0.0803624\tvalid_1's rmse: 0.0844637\n",
      "[1925]\ttraining's rmse: 0.0803585\tvalid_1's rmse: 0.0844633\n",
      "[1950]\ttraining's rmse: 0.0803528\tvalid_1's rmse: 0.0844621\n",
      "[1975]\ttraining's rmse: 0.0803482\tvalid_1's rmse: 0.084461\n",
      "[2000]\ttraining's rmse: 0.0803442\tvalid_1's rmse: 0.0844599\n",
      "[2025]\ttraining's rmse: 0.08034\tvalid_1's rmse: 0.0844585\n",
      "[2050]\ttraining's rmse: 0.0803372\tvalid_1's rmse: 0.0844568\n",
      "[2075]\ttraining's rmse: 0.0803338\tvalid_1's rmse: 0.0844554\n",
      "[2100]\ttraining's rmse: 0.0803301\tvalid_1's rmse: 0.0844535\n",
      "[2125]\ttraining's rmse: 0.0803261\tvalid_1's rmse: 0.0844524\n",
      "[2150]\ttraining's rmse: 0.0803236\tvalid_1's rmse: 0.0844514\n",
      "[2175]\ttraining's rmse: 0.0803216\tvalid_1's rmse: 0.0844512\n",
      "[2200]\ttraining's rmse: 0.0803185\tvalid_1's rmse: 0.0844507\n",
      "[2225]\ttraining's rmse: 0.080316\tvalid_1's rmse: 0.08445\n",
      "[2250]\ttraining's rmse: 0.0803125\tvalid_1's rmse: 0.0844498\n",
      "[2275]\ttraining's rmse: 0.08031\tvalid_1's rmse: 0.0844497\n",
      "[2300]\ttraining's rmse: 0.080308\tvalid_1's rmse: 0.084449\n",
      "[2325]\ttraining's rmse: 0.0803045\tvalid_1's rmse: 0.0844473\n",
      "[2350]\ttraining's rmse: 0.0803025\tvalid_1's rmse: 0.0844469\n",
      "[2375]\ttraining's rmse: 0.0802997\tvalid_1's rmse: 0.0844469\n",
      "[2400]\ttraining's rmse: 0.0802959\tvalid_1's rmse: 0.0844466\n",
      "[2425]\ttraining's rmse: 0.0802932\tvalid_1's rmse: 0.0844457\n",
      "[2450]\ttraining's rmse: 0.080291\tvalid_1's rmse: 0.0844456\n",
      "[2475]\ttraining's rmse: 0.0802875\tvalid_1's rmse: 0.0844448\n",
      "[2500]\ttraining's rmse: 0.0802852\tvalid_1's rmse: 0.0844446\n",
      "[2525]\ttraining's rmse: 0.0802833\tvalid_1's rmse: 0.0844439\n",
      "[2550]\ttraining's rmse: 0.0802809\tvalid_1's rmse: 0.084444\n",
      "[2575]\ttraining's rmse: 0.0802792\tvalid_1's rmse: 0.0844436\n",
      "[2600]\ttraining's rmse: 0.0802775\tvalid_1's rmse: 0.0844434\n",
      "[2625]\ttraining's rmse: 0.0802751\tvalid_1's rmse: 0.0844428\n",
      "[2650]\ttraining's rmse: 0.0802735\tvalid_1's rmse: 0.0844427\n",
      "[2675]\ttraining's rmse: 0.0802714\tvalid_1's rmse: 0.0844415\n",
      "[2700]\ttraining's rmse: 0.0802705\tvalid_1's rmse: 0.0844412\n",
      "[2725]\ttraining's rmse: 0.0802682\tvalid_1's rmse: 0.0844411\n",
      "[2750]\ttraining's rmse: 0.0802664\tvalid_1's rmse: 0.0844411\n",
      "[2775]\ttraining's rmse: 0.0802632\tvalid_1's rmse: 0.0844407\n",
      "[2800]\ttraining's rmse: 0.0802617\tvalid_1's rmse: 0.0844404\n",
      "[2825]\ttraining's rmse: 0.0802601\tvalid_1's rmse: 0.0844405\n",
      "[2850]\ttraining's rmse: 0.0802581\tvalid_1's rmse: 0.0844406\n",
      "Early stopping, best iteration is:\n",
      "[2805]\ttraining's rmse: 0.0802616\tvalid_1's rmse: 0.0844403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0831634\tvalid_1's rmse: 0.0854009\n",
      "[50]\ttraining's rmse: 0.0830479\tvalid_1's rmse: 0.0853476\n",
      "[75]\ttraining's rmse: 0.0829255\tvalid_1's rmse: 0.0852959\n",
      "[100]\ttraining's rmse: 0.0828142\tvalid_1's rmse: 0.0852483\n",
      "[125]\ttraining's rmse: 0.0827007\tvalid_1's rmse: 0.0852011\n",
      "[150]\ttraining's rmse: 0.082598\tvalid_1's rmse: 0.0851581\n",
      "[175]\ttraining's rmse: 0.0825149\tvalid_1's rmse: 0.0851221\n",
      "[200]\ttraining's rmse: 0.0824204\tvalid_1's rmse: 0.085085\n",
      "[225]\ttraining's rmse: 0.0823282\tvalid_1's rmse: 0.0850506\n",
      "[250]\ttraining's rmse: 0.0822513\tvalid_1's rmse: 0.0850199\n",
      "[275]\ttraining's rmse: 0.0821794\tvalid_1's rmse: 0.0849925\n",
      "[300]\ttraining's rmse: 0.0821099\tvalid_1's rmse: 0.0849659\n",
      "[325]\ttraining's rmse: 0.0820352\tvalid_1's rmse: 0.0849389\n",
      "[350]\ttraining's rmse: 0.0819687\tvalid_1's rmse: 0.0849154\n",
      "[375]\ttraining's rmse: 0.0819127\tvalid_1's rmse: 0.084894\n",
      "[400]\ttraining's rmse: 0.0818524\tvalid_1's rmse: 0.0848745\n",
      "[425]\ttraining's rmse: 0.081795\tvalid_1's rmse: 0.0848549\n",
      "[450]\ttraining's rmse: 0.0817426\tvalid_1's rmse: 0.0848356\n",
      "[475]\ttraining's rmse: 0.0816939\tvalid_1's rmse: 0.0848187\n",
      "[500]\ttraining's rmse: 0.0816531\tvalid_1's rmse: 0.0848028\n",
      "[525]\ttraining's rmse: 0.0816\tvalid_1's rmse: 0.084787\n",
      "[550]\ttraining's rmse: 0.0815514\tvalid_1's rmse: 0.0847719\n",
      "[575]\ttraining's rmse: 0.0815072\tvalid_1's rmse: 0.084758\n",
      "[600]\ttraining's rmse: 0.0814625\tvalid_1's rmse: 0.0847452\n",
      "[625]\ttraining's rmse: 0.0814262\tvalid_1's rmse: 0.084733\n",
      "[650]\ttraining's rmse: 0.0813851\tvalid_1's rmse: 0.0847205\n",
      "[675]\ttraining's rmse: 0.081342\tvalid_1's rmse: 0.0847089\n",
      "[700]\ttraining's rmse: 0.0813064\tvalid_1's rmse: 0.0846974\n",
      "[725]\ttraining's rmse: 0.0812731\tvalid_1's rmse: 0.0846882\n",
      "[750]\ttraining's rmse: 0.0812403\tvalid_1's rmse: 0.0846778\n",
      "[775]\ttraining's rmse: 0.0812128\tvalid_1's rmse: 0.0846684\n",
      "[800]\ttraining's rmse: 0.0811781\tvalid_1's rmse: 0.0846604\n",
      "[825]\ttraining's rmse: 0.0811498\tvalid_1's rmse: 0.0846523\n",
      "[850]\ttraining's rmse: 0.0811208\tvalid_1's rmse: 0.0846457\n",
      "[875]\ttraining's rmse: 0.0810931\tvalid_1's rmse: 0.084639\n",
      "[900]\ttraining's rmse: 0.0810629\tvalid_1's rmse: 0.0846331\n",
      "[925]\ttraining's rmse: 0.0810354\tvalid_1's rmse: 0.0846268\n",
      "[950]\ttraining's rmse: 0.0810114\tvalid_1's rmse: 0.084621\n",
      "[975]\ttraining's rmse: 0.0809884\tvalid_1's rmse: 0.0846153\n",
      "[1000]\ttraining's rmse: 0.0809662\tvalid_1's rmse: 0.0846095\n",
      "[1025]\ttraining's rmse: 0.0809418\tvalid_1's rmse: 0.0846047\n",
      "[1050]\ttraining's rmse: 0.0809213\tvalid_1's rmse: 0.0845992\n",
      "[1075]\ttraining's rmse: 0.0809014\tvalid_1's rmse: 0.0845952\n",
      "[1100]\ttraining's rmse: 0.0808842\tvalid_1's rmse: 0.084591\n",
      "[1125]\ttraining's rmse: 0.080866\tvalid_1's rmse: 0.0845868\n",
      "[1150]\ttraining's rmse: 0.0808478\tvalid_1's rmse: 0.0845839\n",
      "[1175]\ttraining's rmse: 0.0808333\tvalid_1's rmse: 0.084581\n",
      "[1200]\ttraining's rmse: 0.0808171\tvalid_1's rmse: 0.084578\n",
      "[1225]\ttraining's rmse: 0.0808021\tvalid_1's rmse: 0.0845752\n",
      "[1250]\ttraining's rmse: 0.0807881\tvalid_1's rmse: 0.0845723\n",
      "[1275]\ttraining's rmse: 0.0807726\tvalid_1's rmse: 0.0845706\n",
      "[1300]\ttraining's rmse: 0.0807592\tvalid_1's rmse: 0.0845675\n",
      "[1325]\ttraining's rmse: 0.0807467\tvalid_1's rmse: 0.0845651\n",
      "[1350]\ttraining's rmse: 0.0807332\tvalid_1's rmse: 0.0845633\n",
      "[1375]\ttraining's rmse: 0.0807192\tvalid_1's rmse: 0.0845616\n",
      "[1400]\ttraining's rmse: 0.0807083\tvalid_1's rmse: 0.0845596\n",
      "[1425]\ttraining's rmse: 0.0806965\tvalid_1's rmse: 0.0845578\n",
      "[1450]\ttraining's rmse: 0.0806839\tvalid_1's rmse: 0.0845565\n",
      "[1475]\ttraining's rmse: 0.0806749\tvalid_1's rmse: 0.0845543\n",
      "[1500]\ttraining's rmse: 0.0806654\tvalid_1's rmse: 0.0845528\n",
      "[1525]\ttraining's rmse: 0.080655\tvalid_1's rmse: 0.084551\n",
      "[1550]\ttraining's rmse: 0.0806468\tvalid_1's rmse: 0.0845501\n",
      "[1575]\ttraining's rmse: 0.0806384\tvalid_1's rmse: 0.0845482\n",
      "[1600]\ttraining's rmse: 0.0806317\tvalid_1's rmse: 0.0845473\n",
      "[1625]\ttraining's rmse: 0.0806242\tvalid_1's rmse: 0.0845461\n",
      "[1650]\ttraining's rmse: 0.0806181\tvalid_1's rmse: 0.084545\n",
      "[1675]\ttraining's rmse: 0.0806125\tvalid_1's rmse: 0.084544\n",
      "[1700]\ttraining's rmse: 0.0806065\tvalid_1's rmse: 0.0845428\n",
      "[1725]\ttraining's rmse: 0.0805987\tvalid_1's rmse: 0.0845422\n",
      "[1750]\ttraining's rmse: 0.0805927\tvalid_1's rmse: 0.0845416\n",
      "[1775]\ttraining's rmse: 0.0805863\tvalid_1's rmse: 0.0845407\n",
      "[1800]\ttraining's rmse: 0.0805797\tvalid_1's rmse: 0.0845404\n",
      "[1825]\ttraining's rmse: 0.0805757\tvalid_1's rmse: 0.0845395\n",
      "[1850]\ttraining's rmse: 0.0805705\tvalid_1's rmse: 0.0845386\n",
      "[1875]\ttraining's rmse: 0.0805662\tvalid_1's rmse: 0.0845383\n",
      "[1900]\ttraining's rmse: 0.0805622\tvalid_1's rmse: 0.0845381\n",
      "[1925]\ttraining's rmse: 0.0805577\tvalid_1's rmse: 0.0845374\n",
      "[1950]\ttraining's rmse: 0.0805535\tvalid_1's rmse: 0.0845371\n",
      "[1975]\ttraining's rmse: 0.0805501\tvalid_1's rmse: 0.0845364\n",
      "[2000]\ttraining's rmse: 0.0805463\tvalid_1's rmse: 0.0845359\n",
      "[2025]\ttraining's rmse: 0.0805432\tvalid_1's rmse: 0.0845353\n",
      "[2050]\ttraining's rmse: 0.0805395\tvalid_1's rmse: 0.0845348\n",
      "[2075]\ttraining's rmse: 0.080536\tvalid_1's rmse: 0.0845341\n",
      "[2100]\ttraining's rmse: 0.0805327\tvalid_1's rmse: 0.0845341\n",
      "[2125]\ttraining's rmse: 0.0805299\tvalid_1's rmse: 0.0845339\n",
      "[2150]\ttraining's rmse: 0.0805266\tvalid_1's rmse: 0.084534\n",
      "Early stopping, best iteration is:\n",
      "[2123]\ttraining's rmse: 0.08053\tvalid_1's rmse: 0.0845338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0852245\tvalid_1's rmse: 0.0812099\n",
      "[50]\ttraining's rmse: 0.0851099\tvalid_1's rmse: 0.0811609\n",
      "[75]\ttraining's rmse: 0.0849888\tvalid_1's rmse: 0.0811093\n",
      "[100]\ttraining's rmse: 0.0848804\tvalid_1's rmse: 0.0810653\n",
      "[125]\ttraining's rmse: 0.0847662\tvalid_1's rmse: 0.0810221\n",
      "[150]\ttraining's rmse: 0.0846662\tvalid_1's rmse: 0.0809825\n",
      "[175]\ttraining's rmse: 0.0845807\tvalid_1's rmse: 0.0809484\n",
      "[200]\ttraining's rmse: 0.0844874\tvalid_1's rmse: 0.0809161\n",
      "[225]\ttraining's rmse: 0.0843963\tvalid_1's rmse: 0.0808846\n",
      "[250]\ttraining's rmse: 0.0843223\tvalid_1's rmse: 0.0808563\n",
      "[275]\ttraining's rmse: 0.0842521\tvalid_1's rmse: 0.0808297\n",
      "[300]\ttraining's rmse: 0.0841806\tvalid_1's rmse: 0.0808055\n",
      "[325]\ttraining's rmse: 0.0841107\tvalid_1's rmse: 0.0807814\n",
      "[350]\ttraining's rmse: 0.0840448\tvalid_1's rmse: 0.0807606\n",
      "[375]\ttraining's rmse: 0.0839902\tvalid_1's rmse: 0.0807413\n",
      "[400]\ttraining's rmse: 0.0839284\tvalid_1's rmse: 0.080725\n",
      "[425]\ttraining's rmse: 0.0838722\tvalid_1's rmse: 0.0807097\n",
      "[450]\ttraining's rmse: 0.0838218\tvalid_1's rmse: 0.0806939\n",
      "[475]\ttraining's rmse: 0.0837751\tvalid_1's rmse: 0.0806844\n",
      "[500]\ttraining's rmse: 0.0837347\tvalid_1's rmse: 0.0806723\n",
      "[525]\ttraining's rmse: 0.0836803\tvalid_1's rmse: 0.0806593\n",
      "[550]\ttraining's rmse: 0.0836339\tvalid_1's rmse: 0.0806461\n",
      "[575]\ttraining's rmse: 0.0835896\tvalid_1's rmse: 0.0806347\n",
      "[600]\ttraining's rmse: 0.0835461\tvalid_1's rmse: 0.0806241\n",
      "[625]\ttraining's rmse: 0.0835106\tvalid_1's rmse: 0.0806158\n",
      "[650]\ttraining's rmse: 0.083469\tvalid_1's rmse: 0.0806093\n",
      "[675]\ttraining's rmse: 0.0834254\tvalid_1's rmse: 0.0806021\n",
      "[700]\ttraining's rmse: 0.083388\tvalid_1's rmse: 0.0805973\n",
      "[725]\ttraining's rmse: 0.0833505\tvalid_1's rmse: 0.0805978\n",
      "[750]\ttraining's rmse: 0.0833189\tvalid_1's rmse: 0.0805941\n",
      "[775]\ttraining's rmse: 0.0832908\tvalid_1's rmse: 0.0805965\n",
      "[800]\ttraining's rmse: 0.0832549\tvalid_1's rmse: 0.0805925\n",
      "[825]\ttraining's rmse: 0.0832246\tvalid_1's rmse: 0.0805913\n",
      "[850]\ttraining's rmse: 0.0831933\tvalid_1's rmse: 0.0805864\n",
      "[875]\ttraining's rmse: 0.0831655\tvalid_1's rmse: 0.0805815\n",
      "[900]\ttraining's rmse: 0.0831346\tvalid_1's rmse: 0.0805791\n",
      "[925]\ttraining's rmse: 0.0831085\tvalid_1's rmse: 0.0805792\n",
      "[950]\ttraining's rmse: 0.0830835\tvalid_1's rmse: 0.0805743\n",
      "[975]\ttraining's rmse: 0.0830579\tvalid_1's rmse: 0.0805756\n",
      "[1000]\ttraining's rmse: 0.0830355\tvalid_1's rmse: 0.0805775\n",
      "[1025]\ttraining's rmse: 0.0830098\tvalid_1's rmse: 0.0805834\n",
      "Early stopping, best iteration is:\n",
      "[999]\ttraining's rmse: 0.0830364\tvalid_1's rmse: 0.0805724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0793647\tvalid_1's rmse: 0.082031\n",
      "[50]\ttraining's rmse: 0.0792527\tvalid_1's rmse: 0.0819772\n",
      "[75]\ttraining's rmse: 0.0791409\tvalid_1's rmse: 0.0819227\n",
      "[100]\ttraining's rmse: 0.0790383\tvalid_1's rmse: 0.0818769\n",
      "[125]\ttraining's rmse: 0.07893\tvalid_1's rmse: 0.0818305\n",
      "[150]\ttraining's rmse: 0.0788332\tvalid_1's rmse: 0.0817863\n",
      "[175]\ttraining's rmse: 0.078755\tvalid_1's rmse: 0.0817497\n",
      "[200]\ttraining's rmse: 0.0786697\tvalid_1's rmse: 0.0817123\n",
      "[225]\ttraining's rmse: 0.0785875\tvalid_1's rmse: 0.0816785\n",
      "[250]\ttraining's rmse: 0.0785176\tvalid_1's rmse: 0.0816475\n",
      "[275]\ttraining's rmse: 0.0784509\tvalid_1's rmse: 0.0816165\n",
      "[300]\ttraining's rmse: 0.0783845\tvalid_1's rmse: 0.0815879\n",
      "[325]\ttraining's rmse: 0.0783165\tvalid_1's rmse: 0.0815612\n",
      "[350]\ttraining's rmse: 0.0782555\tvalid_1's rmse: 0.0815358\n",
      "[375]\ttraining's rmse: 0.0782045\tvalid_1's rmse: 0.0815129\n",
      "[400]\ttraining's rmse: 0.0781486\tvalid_1's rmse: 0.0814907\n",
      "[425]\ttraining's rmse: 0.0781003\tvalid_1's rmse: 0.0814704\n",
      "[450]\ttraining's rmse: 0.0780548\tvalid_1's rmse: 0.0814498\n",
      "[475]\ttraining's rmse: 0.0780126\tvalid_1's rmse: 0.0814311\n",
      "[500]\ttraining's rmse: 0.0779757\tvalid_1's rmse: 0.0814133\n",
      "[525]\ttraining's rmse: 0.0779304\tvalid_1's rmse: 0.0813963\n",
      "[550]\ttraining's rmse: 0.0778861\tvalid_1's rmse: 0.0813795\n",
      "[575]\ttraining's rmse: 0.0778466\tvalid_1's rmse: 0.0813643\n",
      "[600]\ttraining's rmse: 0.0778101\tvalid_1's rmse: 0.0813488\n",
      "[625]\ttraining's rmse: 0.0777786\tvalid_1's rmse: 0.0813359\n",
      "[650]\ttraining's rmse: 0.0777407\tvalid_1's rmse: 0.0813222\n",
      "[675]\ttraining's rmse: 0.0777051\tvalid_1's rmse: 0.0813091\n",
      "[700]\ttraining's rmse: 0.0776734\tvalid_1's rmse: 0.0812967\n",
      "[725]\ttraining's rmse: 0.0776422\tvalid_1's rmse: 0.0812864\n",
      "[750]\ttraining's rmse: 0.0776135\tvalid_1's rmse: 0.0812769\n",
      "[775]\ttraining's rmse: 0.0775896\tvalid_1's rmse: 0.0812669\n",
      "[800]\ttraining's rmse: 0.0775592\tvalid_1's rmse: 0.0812574\n",
      "[825]\ttraining's rmse: 0.0775353\tvalid_1's rmse: 0.0812477\n",
      "[850]\ttraining's rmse: 0.07751\tvalid_1's rmse: 0.0812404\n",
      "[875]\ttraining's rmse: 0.0774855\tvalid_1's rmse: 0.0812313\n",
      "[900]\ttraining's rmse: 0.07746\tvalid_1's rmse: 0.0812238\n",
      "[925]\ttraining's rmse: 0.0774382\tvalid_1's rmse: 0.0812164\n",
      "[950]\ttraining's rmse: 0.0774195\tvalid_1's rmse: 0.0812101\n",
      "[975]\ttraining's rmse: 0.0773988\tvalid_1's rmse: 0.0812033\n",
      "[1000]\ttraining's rmse: 0.0773769\tvalid_1's rmse: 0.0811963\n",
      "[1025]\ttraining's rmse: 0.0773571\tvalid_1's rmse: 0.0811893\n",
      "[1050]\ttraining's rmse: 0.0773394\tvalid_1's rmse: 0.0811837\n",
      "[1075]\ttraining's rmse: 0.0773214\tvalid_1's rmse: 0.0811794\n",
      "[1100]\ttraining's rmse: 0.0773065\tvalid_1's rmse: 0.0811742\n",
      "[1125]\ttraining's rmse: 0.0772932\tvalid_1's rmse: 0.0811681\n",
      "[1150]\ttraining's rmse: 0.0772762\tvalid_1's rmse: 0.0811639\n",
      "[1175]\ttraining's rmse: 0.0772617\tvalid_1's rmse: 0.0811614\n",
      "[1200]\ttraining's rmse: 0.0772476\tvalid_1's rmse: 0.0811564\n",
      "[1225]\ttraining's rmse: 0.0772344\tvalid_1's rmse: 0.0811518\n",
      "[1250]\ttraining's rmse: 0.0772219\tvalid_1's rmse: 0.0811487\n",
      "[1275]\ttraining's rmse: 0.0772084\tvalid_1's rmse: 0.0811454\n",
      "[1300]\ttraining's rmse: 0.0771997\tvalid_1's rmse: 0.0811415\n",
      "[1325]\ttraining's rmse: 0.0771887\tvalid_1's rmse: 0.0811386\n",
      "[1350]\ttraining's rmse: 0.077178\tvalid_1's rmse: 0.0811351\n",
      "[1375]\ttraining's rmse: 0.0771685\tvalid_1's rmse: 0.0811311\n",
      "[1400]\ttraining's rmse: 0.0771584\tvalid_1's rmse: 0.0811281\n",
      "[1425]\ttraining's rmse: 0.0771494\tvalid_1's rmse: 0.0811257\n",
      "[1450]\ttraining's rmse: 0.0771384\tvalid_1's rmse: 0.0811226\n",
      "[1475]\ttraining's rmse: 0.0771308\tvalid_1's rmse: 0.0811201\n",
      "[1500]\ttraining's rmse: 0.0771209\tvalid_1's rmse: 0.0811166\n",
      "[1525]\ttraining's rmse: 0.0771138\tvalid_1's rmse: 0.0811145\n",
      "[1550]\ttraining's rmse: 0.0771068\tvalid_1's rmse: 0.0811127\n",
      "[1575]\ttraining's rmse: 0.0770988\tvalid_1's rmse: 0.0811107\n",
      "[1600]\ttraining's rmse: 0.0770931\tvalid_1's rmse: 0.0811083\n",
      "[1625]\ttraining's rmse: 0.0770844\tvalid_1's rmse: 0.0811041\n",
      "[1650]\ttraining's rmse: 0.0770768\tvalid_1's rmse: 0.0811019\n",
      "[1675]\ttraining's rmse: 0.077072\tvalid_1's rmse: 0.0811007\n",
      "[1700]\ttraining's rmse: 0.0770661\tvalid_1's rmse: 0.081098\n",
      "[1725]\ttraining's rmse: 0.0770607\tvalid_1's rmse: 0.0810963\n",
      "[1750]\ttraining's rmse: 0.0770536\tvalid_1's rmse: 0.0810936\n",
      "[1775]\ttraining's rmse: 0.0770496\tvalid_1's rmse: 0.0810918\n",
      "[1800]\ttraining's rmse: 0.0770453\tvalid_1's rmse: 0.0810903\n",
      "[1825]\ttraining's rmse: 0.0770404\tvalid_1's rmse: 0.0810885\n",
      "[1850]\ttraining's rmse: 0.0770356\tvalid_1's rmse: 0.0810866\n",
      "[1875]\ttraining's rmse: 0.0770313\tvalid_1's rmse: 0.0810844\n",
      "[1900]\ttraining's rmse: 0.0770279\tvalid_1's rmse: 0.0810825\n",
      "[1925]\ttraining's rmse: 0.0770232\tvalid_1's rmse: 0.0810813\n",
      "[1950]\ttraining's rmse: 0.0770196\tvalid_1's rmse: 0.08108\n",
      "[1975]\ttraining's rmse: 0.0770166\tvalid_1's rmse: 0.0810789\n",
      "[2000]\ttraining's rmse: 0.0770122\tvalid_1's rmse: 0.0810781\n",
      "[2025]\ttraining's rmse: 0.0770092\tvalid_1's rmse: 0.0810774\n",
      "[2050]\ttraining's rmse: 0.0770056\tvalid_1's rmse: 0.0810757\n",
      "[2075]\ttraining's rmse: 0.0770031\tvalid_1's rmse: 0.0810752\n",
      "[2100]\ttraining's rmse: 0.0769999\tvalid_1's rmse: 0.081075\n",
      "[2125]\ttraining's rmse: 0.0769964\tvalid_1's rmse: 0.0810735\n",
      "[2150]\ttraining's rmse: 0.0769921\tvalid_1's rmse: 0.0810728\n",
      "[2175]\ttraining's rmse: 0.0769902\tvalid_1's rmse: 0.0810724\n",
      "[2200]\ttraining's rmse: 0.0769871\tvalid_1's rmse: 0.0810713\n",
      "[2225]\ttraining's rmse: 0.0769843\tvalid_1's rmse: 0.0810704\n",
      "[2250]\ttraining's rmse: 0.0769825\tvalid_1's rmse: 0.0810693\n",
      "[2275]\ttraining's rmse: 0.07698\tvalid_1's rmse: 0.0810689\n",
      "[2300]\ttraining's rmse: 0.076977\tvalid_1's rmse: 0.0810672\n",
      "[2325]\ttraining's rmse: 0.0769753\tvalid_1's rmse: 0.081067\n",
      "[2350]\ttraining's rmse: 0.0769736\tvalid_1's rmse: 0.0810663\n",
      "[2375]\ttraining's rmse: 0.0769713\tvalid_1's rmse: 0.0810656\n",
      "[2400]\ttraining's rmse: 0.0769688\tvalid_1's rmse: 0.0810651\n",
      "[2425]\ttraining's rmse: 0.076967\tvalid_1's rmse: 0.0810648\n",
      "[2450]\ttraining's rmse: 0.0769655\tvalid_1's rmse: 0.0810646\n",
      "[2475]\ttraining's rmse: 0.0769631\tvalid_1's rmse: 0.081064\n",
      "[2500]\ttraining's rmse: 0.0769614\tvalid_1's rmse: 0.0810633\n",
      "[2525]\ttraining's rmse: 0.0769602\tvalid_1's rmse: 0.0810629\n",
      "[2550]\ttraining's rmse: 0.0769591\tvalid_1's rmse: 0.0810631\n",
      "[2575]\ttraining's rmse: 0.0769574\tvalid_1's rmse: 0.0810627\n",
      "[2600]\ttraining's rmse: 0.0769562\tvalid_1's rmse: 0.0810628\n",
      "[2625]\ttraining's rmse: 0.076955\tvalid_1's rmse: 0.0810618\n",
      "[2650]\ttraining's rmse: 0.076954\tvalid_1's rmse: 0.0810621\n",
      "[2675]\ttraining's rmse: 0.0769515\tvalid_1's rmse: 0.081062\n",
      "Early stopping, best iteration is:\n",
      "[2629]\ttraining's rmse: 0.0769547\tvalid_1's rmse: 0.0810618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0795802\tvalid_1's rmse: 0.0816111\n",
      "[50]\ttraining's rmse: 0.0794717\tvalid_1's rmse: 0.0815561\n",
      "[75]\ttraining's rmse: 0.0793605\tvalid_1's rmse: 0.0815016\n",
      "[100]\ttraining's rmse: 0.0792635\tvalid_1's rmse: 0.0814548\n",
      "[125]\ttraining's rmse: 0.0791596\tvalid_1's rmse: 0.0814056\n",
      "[150]\ttraining's rmse: 0.0790661\tvalid_1's rmse: 0.0813611\n",
      "[175]\ttraining's rmse: 0.0789887\tvalid_1's rmse: 0.0813234\n",
      "[200]\ttraining's rmse: 0.0789018\tvalid_1's rmse: 0.0812854\n",
      "[225]\ttraining's rmse: 0.078821\tvalid_1's rmse: 0.081251\n",
      "[250]\ttraining's rmse: 0.0787537\tvalid_1's rmse: 0.0812194\n",
      "[275]\ttraining's rmse: 0.0786906\tvalid_1's rmse: 0.0811897\n",
      "[300]\ttraining's rmse: 0.0786269\tvalid_1's rmse: 0.0811621\n",
      "[325]\ttraining's rmse: 0.0785588\tvalid_1's rmse: 0.0811358\n",
      "[350]\ttraining's rmse: 0.0784941\tvalid_1's rmse: 0.0811105\n",
      "[375]\ttraining's rmse: 0.0784427\tvalid_1's rmse: 0.0810903\n",
      "[400]\ttraining's rmse: 0.0783856\tvalid_1's rmse: 0.081069\n",
      "[425]\ttraining's rmse: 0.0783331\tvalid_1's rmse: 0.0810501\n",
      "[450]\ttraining's rmse: 0.0782841\tvalid_1's rmse: 0.081031\n",
      "[475]\ttraining's rmse: 0.07824\tvalid_1's rmse: 0.0810136\n",
      "[500]\ttraining's rmse: 0.0782018\tvalid_1's rmse: 0.080997\n",
      "[525]\ttraining's rmse: 0.0781513\tvalid_1's rmse: 0.0809802\n",
      "[550]\ttraining's rmse: 0.0781046\tvalid_1's rmse: 0.080965\n",
      "[575]\ttraining's rmse: 0.0780631\tvalid_1's rmse: 0.080951\n",
      "[600]\ttraining's rmse: 0.0780238\tvalid_1's rmse: 0.080938\n",
      "[625]\ttraining's rmse: 0.0779934\tvalid_1's rmse: 0.0809265\n",
      "[650]\ttraining's rmse: 0.0779556\tvalid_1's rmse: 0.0809142\n",
      "[675]\ttraining's rmse: 0.0779168\tvalid_1's rmse: 0.0809028\n",
      "[700]\ttraining's rmse: 0.0778831\tvalid_1's rmse: 0.0808923\n",
      "[725]\ttraining's rmse: 0.0778499\tvalid_1's rmse: 0.0808824\n",
      "[750]\ttraining's rmse: 0.0778191\tvalid_1's rmse: 0.0808736\n",
      "[775]\ttraining's rmse: 0.0777941\tvalid_1's rmse: 0.0808652\n",
      "[800]\ttraining's rmse: 0.0777619\tvalid_1's rmse: 0.0808566\n",
      "[825]\ttraining's rmse: 0.077736\tvalid_1's rmse: 0.0808483\n",
      "[850]\ttraining's rmse: 0.0777104\tvalid_1's rmse: 0.0808417\n",
      "[875]\ttraining's rmse: 0.0776868\tvalid_1's rmse: 0.080836\n",
      "[900]\ttraining's rmse: 0.0776608\tvalid_1's rmse: 0.0808287\n",
      "[925]\ttraining's rmse: 0.0776371\tvalid_1's rmse: 0.0808225\n",
      "[950]\ttraining's rmse: 0.0776138\tvalid_1's rmse: 0.0808167\n",
      "[975]\ttraining's rmse: 0.077594\tvalid_1's rmse: 0.0808109\n",
      "[1000]\ttraining's rmse: 0.0775733\tvalid_1's rmse: 0.0808061\n",
      "[1025]\ttraining's rmse: 0.0775518\tvalid_1's rmse: 0.0808013\n",
      "[1050]\ttraining's rmse: 0.0775345\tvalid_1's rmse: 0.0807967\n",
      "[1075]\ttraining's rmse: 0.0775141\tvalid_1's rmse: 0.0807932\n",
      "[1100]\ttraining's rmse: 0.0774995\tvalid_1's rmse: 0.0807895\n",
      "[1125]\ttraining's rmse: 0.0774826\tvalid_1's rmse: 0.080786\n",
      "[1150]\ttraining's rmse: 0.0774667\tvalid_1's rmse: 0.0807826\n",
      "[1175]\ttraining's rmse: 0.0774517\tvalid_1's rmse: 0.08078\n",
      "[1200]\ttraining's rmse: 0.0774373\tvalid_1's rmse: 0.0807771\n",
      "[1225]\ttraining's rmse: 0.0774225\tvalid_1's rmse: 0.0807743\n",
      "[1250]\ttraining's rmse: 0.0774102\tvalid_1's rmse: 0.0807709\n",
      "[1275]\ttraining's rmse: 0.0773975\tvalid_1's rmse: 0.080769\n",
      "[1300]\ttraining's rmse: 0.0773865\tvalid_1's rmse: 0.0807665\n",
      "[1325]\ttraining's rmse: 0.0773753\tvalid_1's rmse: 0.0807649\n",
      "[1350]\ttraining's rmse: 0.077363\tvalid_1's rmse: 0.0807631\n",
      "[1375]\ttraining's rmse: 0.0773525\tvalid_1's rmse: 0.0807613\n",
      "[1400]\ttraining's rmse: 0.0773443\tvalid_1's rmse: 0.0807592\n",
      "[1425]\ttraining's rmse: 0.0773363\tvalid_1's rmse: 0.0807582\n",
      "[1450]\ttraining's rmse: 0.0773253\tvalid_1's rmse: 0.080757\n",
      "[1475]\ttraining's rmse: 0.0773159\tvalid_1's rmse: 0.0807551\n",
      "[1500]\ttraining's rmse: 0.077307\tvalid_1's rmse: 0.0807535\n",
      "[1525]\ttraining's rmse: 0.0772997\tvalid_1's rmse: 0.0807519\n",
      "[1550]\ttraining's rmse: 0.0772914\tvalid_1's rmse: 0.0807507\n",
      "[1575]\ttraining's rmse: 0.0772848\tvalid_1's rmse: 0.0807493\n",
      "[1600]\ttraining's rmse: 0.0772774\tvalid_1's rmse: 0.0807484\n",
      "[1625]\ttraining's rmse: 0.0772703\tvalid_1's rmse: 0.0807469\n",
      "[1650]\ttraining's rmse: 0.0772641\tvalid_1's rmse: 0.0807459\n",
      "[1675]\ttraining's rmse: 0.0772595\tvalid_1's rmse: 0.0807451\n",
      "[1700]\ttraining's rmse: 0.0772553\tvalid_1's rmse: 0.080744\n",
      "[1725]\ttraining's rmse: 0.0772492\tvalid_1's rmse: 0.0807426\n",
      "[1750]\ttraining's rmse: 0.0772429\tvalid_1's rmse: 0.0807423\n",
      "[1775]\ttraining's rmse: 0.0772368\tvalid_1's rmse: 0.0807412\n",
      "[1800]\ttraining's rmse: 0.0772306\tvalid_1's rmse: 0.0807403\n",
      "[1825]\ttraining's rmse: 0.0772249\tvalid_1's rmse: 0.0807393\n",
      "[1850]\ttraining's rmse: 0.0772209\tvalid_1's rmse: 0.0807383\n",
      "[1875]\ttraining's rmse: 0.0772164\tvalid_1's rmse: 0.0807375\n",
      "[1900]\ttraining's rmse: 0.0772135\tvalid_1's rmse: 0.0807371\n",
      "[1925]\ttraining's rmse: 0.0772103\tvalid_1's rmse: 0.0807373\n",
      "[1950]\ttraining's rmse: 0.0772072\tvalid_1's rmse: 0.0807366\n",
      "[1975]\ttraining's rmse: 0.0772038\tvalid_1's rmse: 0.0807358\n",
      "[2000]\ttraining's rmse: 0.077201\tvalid_1's rmse: 0.0807356\n",
      "[2025]\ttraining's rmse: 0.0771991\tvalid_1's rmse: 0.0807357\n",
      "[2050]\ttraining's rmse: 0.0771956\tvalid_1's rmse: 0.0807354\n",
      "[2075]\ttraining's rmse: 0.0771922\tvalid_1's rmse: 0.0807348\n",
      "[2100]\ttraining's rmse: 0.0771897\tvalid_1's rmse: 0.0807341\n",
      "[2125]\ttraining's rmse: 0.0771877\tvalid_1's rmse: 0.0807342\n",
      "[2150]\ttraining's rmse: 0.0771837\tvalid_1's rmse: 0.0807341\n",
      "[2175]\ttraining's rmse: 0.0771817\tvalid_1's rmse: 0.0807344\n",
      "Early stopping, best iteration is:\n",
      "[2132]\ttraining's rmse: 0.077187\tvalid_1's rmse: 0.080734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0817102\tvalid_1's rmse: 0.07727\n",
      "[50]\ttraining's rmse: 0.0816023\tvalid_1's rmse: 0.0772206\n",
      "[75]\ttraining's rmse: 0.0814926\tvalid_1's rmse: 0.0771742\n",
      "[100]\ttraining's rmse: 0.081395\tvalid_1's rmse: 0.0771324\n",
      "[125]\ttraining's rmse: 0.0812929\tvalid_1's rmse: 0.0770906\n",
      "[150]\ttraining's rmse: 0.0811973\tvalid_1's rmse: 0.077053\n",
      "[175]\ttraining's rmse: 0.0811196\tvalid_1's rmse: 0.0770219\n",
      "[200]\ttraining's rmse: 0.0810376\tvalid_1's rmse: 0.0769909\n",
      "[225]\ttraining's rmse: 0.0809586\tvalid_1's rmse: 0.0769612\n",
      "[250]\ttraining's rmse: 0.0808907\tvalid_1's rmse: 0.0769361\n",
      "[275]\ttraining's rmse: 0.080828\tvalid_1's rmse: 0.0769115\n",
      "[300]\ttraining's rmse: 0.0807651\tvalid_1's rmse: 0.0768885\n",
      "[325]\ttraining's rmse: 0.0807007\tvalid_1's rmse: 0.0768661\n",
      "[350]\ttraining's rmse: 0.080639\tvalid_1's rmse: 0.0768457\n",
      "[375]\ttraining's rmse: 0.0805876\tvalid_1's rmse: 0.076828\n",
      "[400]\ttraining's rmse: 0.0805301\tvalid_1's rmse: 0.0768171\n",
      "[425]\ttraining's rmse: 0.0804785\tvalid_1's rmse: 0.0768012\n",
      "[450]\ttraining's rmse: 0.0804313\tvalid_1's rmse: 0.0767893\n",
      "[475]\ttraining's rmse: 0.080387\tvalid_1's rmse: 0.0767764\n",
      "[500]\ttraining's rmse: 0.0803498\tvalid_1's rmse: 0.0767641\n",
      "[525]\ttraining's rmse: 0.0803018\tvalid_1's rmse: 0.0767536\n",
      "[550]\ttraining's rmse: 0.0802565\tvalid_1's rmse: 0.0767411\n",
      "[575]\ttraining's rmse: 0.0802162\tvalid_1's rmse: 0.0767372\n",
      "[600]\ttraining's rmse: 0.0801765\tvalid_1's rmse: 0.0767274\n",
      "[625]\ttraining's rmse: 0.0801449\tvalid_1's rmse: 0.076718\n",
      "[650]\ttraining's rmse: 0.0801048\tvalid_1's rmse: 0.0767185\n",
      "[675]\ttraining's rmse: 0.0800645\tvalid_1's rmse: 0.076714\n",
      "[700]\ttraining's rmse: 0.0800319\tvalid_1's rmse: 0.0767091\n",
      "[725]\ttraining's rmse: 0.080001\tvalid_1's rmse: 0.0767164\n",
      "[750]\ttraining's rmse: 0.079969\tvalid_1's rmse: 0.0767278\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0800261\tvalid_1's rmse: 0.0767082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0840382\tvalid_1's rmse: 0.0860203\n",
      "[50]\ttraining's rmse: 0.0838978\tvalid_1's rmse: 0.0859708\n",
      "[75]\ttraining's rmse: 0.0837512\tvalid_1's rmse: 0.08592\n",
      "[100]\ttraining's rmse: 0.0836175\tvalid_1's rmse: 0.0858757\n",
      "[125]\ttraining's rmse: 0.0834882\tvalid_1's rmse: 0.0858317\n",
      "[150]\ttraining's rmse: 0.0833684\tvalid_1's rmse: 0.0857922\n",
      "[175]\ttraining's rmse: 0.0832702\tvalid_1's rmse: 0.0857591\n",
      "[200]\ttraining's rmse: 0.0831613\tvalid_1's rmse: 0.0857248\n",
      "[225]\ttraining's rmse: 0.0830536\tvalid_1's rmse: 0.085691\n",
      "[250]\ttraining's rmse: 0.0829668\tvalid_1's rmse: 0.0856599\n",
      "[275]\ttraining's rmse: 0.082883\tvalid_1's rmse: 0.0856331\n",
      "[300]\ttraining's rmse: 0.0828016\tvalid_1's rmse: 0.0856075\n",
      "[325]\ttraining's rmse: 0.0827208\tvalid_1's rmse: 0.0855856\n",
      "[350]\ttraining's rmse: 0.0826409\tvalid_1's rmse: 0.0855607\n",
      "[375]\ttraining's rmse: 0.082573\tvalid_1's rmse: 0.0855415\n",
      "[400]\ttraining's rmse: 0.0825032\tvalid_1's rmse: 0.0855221\n",
      "[425]\ttraining's rmse: 0.0824393\tvalid_1's rmse: 0.0855035\n",
      "[450]\ttraining's rmse: 0.0823789\tvalid_1's rmse: 0.0854843\n",
      "[475]\ttraining's rmse: 0.0823228\tvalid_1's rmse: 0.0854693\n",
      "[500]\ttraining's rmse: 0.0822785\tvalid_1's rmse: 0.0854561\n",
      "[525]\ttraining's rmse: 0.0822193\tvalid_1's rmse: 0.0854404\n",
      "[550]\ttraining's rmse: 0.0821662\tvalid_1's rmse: 0.0854257\n",
      "[575]\ttraining's rmse: 0.0821198\tvalid_1's rmse: 0.0854144\n",
      "[600]\ttraining's rmse: 0.0820723\tvalid_1's rmse: 0.0854039\n",
      "[625]\ttraining's rmse: 0.0820352\tvalid_1's rmse: 0.0853929\n",
      "[650]\ttraining's rmse: 0.0819902\tvalid_1's rmse: 0.0853817\n",
      "[675]\ttraining's rmse: 0.0819425\tvalid_1's rmse: 0.085371\n",
      "[700]\ttraining's rmse: 0.0819034\tvalid_1's rmse: 0.0853619\n",
      "[725]\ttraining's rmse: 0.0818645\tvalid_1's rmse: 0.0853525\n",
      "[750]\ttraining's rmse: 0.0818277\tvalid_1's rmse: 0.0853431\n",
      "[775]\ttraining's rmse: 0.0817998\tvalid_1's rmse: 0.0853346\n",
      "[800]\ttraining's rmse: 0.081762\tvalid_1's rmse: 0.085325\n",
      "[825]\ttraining's rmse: 0.0817322\tvalid_1's rmse: 0.085317\n",
      "[850]\ttraining's rmse: 0.0816943\tvalid_1's rmse: 0.08531\n",
      "[875]\ttraining's rmse: 0.0816671\tvalid_1's rmse: 0.0853033\n",
      "[900]\ttraining's rmse: 0.0816341\tvalid_1's rmse: 0.0852968\n",
      "[925]\ttraining's rmse: 0.0816087\tvalid_1's rmse: 0.0852907\n",
      "[950]\ttraining's rmse: 0.081582\tvalid_1's rmse: 0.0852849\n",
      "[975]\ttraining's rmse: 0.0815583\tvalid_1's rmse: 0.0852788\n",
      "[1000]\ttraining's rmse: 0.0815337\tvalid_1's rmse: 0.0852736\n",
      "[1025]\ttraining's rmse: 0.081509\tvalid_1's rmse: 0.0852689\n",
      "[1050]\ttraining's rmse: 0.0814889\tvalid_1's rmse: 0.0852633\n",
      "[1075]\ttraining's rmse: 0.0814658\tvalid_1's rmse: 0.0852597\n",
      "[1100]\ttraining's rmse: 0.0814451\tvalid_1's rmse: 0.0852548\n",
      "[1125]\ttraining's rmse: 0.0814248\tvalid_1's rmse: 0.0852495\n",
      "[1150]\ttraining's rmse: 0.0814029\tvalid_1's rmse: 0.0852459\n",
      "[1175]\ttraining's rmse: 0.0813857\tvalid_1's rmse: 0.0852432\n",
      "[1200]\ttraining's rmse: 0.0813679\tvalid_1's rmse: 0.0852388\n",
      "[1225]\ttraining's rmse: 0.0813509\tvalid_1's rmse: 0.0852359\n",
      "[1250]\ttraining's rmse: 0.0813353\tvalid_1's rmse: 0.0852321\n",
      "[1275]\ttraining's rmse: 0.081317\tvalid_1's rmse: 0.0852293\n",
      "[1300]\ttraining's rmse: 0.0813032\tvalid_1's rmse: 0.0852258\n",
      "[1325]\ttraining's rmse: 0.0812902\tvalid_1's rmse: 0.0852226\n",
      "[1350]\ttraining's rmse: 0.0812755\tvalid_1's rmse: 0.0852193\n",
      "[1375]\ttraining's rmse: 0.0812612\tvalid_1's rmse: 0.0852167\n",
      "[1400]\ttraining's rmse: 0.0812491\tvalid_1's rmse: 0.0852131\n",
      "[1425]\ttraining's rmse: 0.0812376\tvalid_1's rmse: 0.085212\n",
      "[1450]\ttraining's rmse: 0.0812272\tvalid_1's rmse: 0.0852098\n",
      "[1475]\ttraining's rmse: 0.0812179\tvalid_1's rmse: 0.0852071\n",
      "[1500]\ttraining's rmse: 0.081208\tvalid_1's rmse: 0.0852051\n",
      "[1525]\ttraining's rmse: 0.0811978\tvalid_1's rmse: 0.0852029\n",
      "[1550]\ttraining's rmse: 0.0811875\tvalid_1's rmse: 0.0852014\n",
      "[1575]\ttraining's rmse: 0.0811777\tvalid_1's rmse: 0.0852\n",
      "[1600]\ttraining's rmse: 0.081171\tvalid_1's rmse: 0.085199\n",
      "[1625]\ttraining's rmse: 0.0811634\tvalid_1's rmse: 0.0851958\n",
      "[1650]\ttraining's rmse: 0.081156\tvalid_1's rmse: 0.0851933\n",
      "[1675]\ttraining's rmse: 0.0811501\tvalid_1's rmse: 0.0851907\n",
      "[1700]\ttraining's rmse: 0.081143\tvalid_1's rmse: 0.0851891\n",
      "[1725]\ttraining's rmse: 0.0811365\tvalid_1's rmse: 0.0851873\n",
      "[1750]\ttraining's rmse: 0.0811297\tvalid_1's rmse: 0.0851865\n",
      "[1775]\ttraining's rmse: 0.081123\tvalid_1's rmse: 0.0851851\n",
      "[1800]\ttraining's rmse: 0.0811169\tvalid_1's rmse: 0.0851832\n",
      "[1825]\ttraining's rmse: 0.0811089\tvalid_1's rmse: 0.0851814\n",
      "[1850]\ttraining's rmse: 0.0811047\tvalid_1's rmse: 0.0851791\n",
      "[1875]\ttraining's rmse: 0.0811002\tvalid_1's rmse: 0.085178\n",
      "[1900]\ttraining's rmse: 0.0810957\tvalid_1's rmse: 0.085177\n",
      "[1925]\ttraining's rmse: 0.0810897\tvalid_1's rmse: 0.0851764\n",
      "[1950]\ttraining's rmse: 0.0810867\tvalid_1's rmse: 0.0851746\n",
      "[1975]\ttraining's rmse: 0.0810827\tvalid_1's rmse: 0.0851731\n",
      "[2000]\ttraining's rmse: 0.0810776\tvalid_1's rmse: 0.0851723\n",
      "[2025]\ttraining's rmse: 0.0810734\tvalid_1's rmse: 0.0851706\n",
      "[2050]\ttraining's rmse: 0.0810695\tvalid_1's rmse: 0.0851695\n",
      "[2075]\ttraining's rmse: 0.0810653\tvalid_1's rmse: 0.0851679\n",
      "[2100]\ttraining's rmse: 0.081062\tvalid_1's rmse: 0.0851675\n",
      "[2125]\ttraining's rmse: 0.0810581\tvalid_1's rmse: 0.0851667\n",
      "[2150]\ttraining's rmse: 0.0810547\tvalid_1's rmse: 0.0851657\n",
      "[2175]\ttraining's rmse: 0.0810503\tvalid_1's rmse: 0.0851648\n",
      "[2200]\ttraining's rmse: 0.0810461\tvalid_1's rmse: 0.0851633\n",
      "[2225]\ttraining's rmse: 0.0810425\tvalid_1's rmse: 0.0851617\n",
      "[2250]\ttraining's rmse: 0.0810378\tvalid_1's rmse: 0.0851608\n",
      "[2275]\ttraining's rmse: 0.0810358\tvalid_1's rmse: 0.0851607\n",
      "[2300]\ttraining's rmse: 0.0810323\tvalid_1's rmse: 0.0851593\n",
      "[2325]\ttraining's rmse: 0.0810304\tvalid_1's rmse: 0.0851586\n",
      "[2350]\ttraining's rmse: 0.0810268\tvalid_1's rmse: 0.0851575\n",
      "[2375]\ttraining's rmse: 0.0810245\tvalid_1's rmse: 0.0851569\n",
      "[2400]\ttraining's rmse: 0.0810211\tvalid_1's rmse: 0.085156\n",
      "[2425]\ttraining's rmse: 0.0810188\tvalid_1's rmse: 0.0851558\n",
      "[2450]\ttraining's rmse: 0.0810152\tvalid_1's rmse: 0.0851552\n",
      "[2475]\ttraining's rmse: 0.0810125\tvalid_1's rmse: 0.0851547\n",
      "[2500]\ttraining's rmse: 0.0810101\tvalid_1's rmse: 0.0851547\n",
      "[2525]\ttraining's rmse: 0.0810074\tvalid_1's rmse: 0.0851541\n",
      "[2550]\ttraining's rmse: 0.0810054\tvalid_1's rmse: 0.0851535\n",
      "[2575]\ttraining's rmse: 0.0810023\tvalid_1's rmse: 0.0851529\n",
      "[2600]\ttraining's rmse: 0.0810004\tvalid_1's rmse: 0.0851527\n",
      "[2625]\ttraining's rmse: 0.0809975\tvalid_1's rmse: 0.0851517\n",
      "[2650]\ttraining's rmse: 0.0809949\tvalid_1's rmse: 0.0851513\n",
      "[2675]\ttraining's rmse: 0.0809924\tvalid_1's rmse: 0.0851509\n",
      "[2700]\ttraining's rmse: 0.0809895\tvalid_1's rmse: 0.0851501\n",
      "[2725]\ttraining's rmse: 0.0809873\tvalid_1's rmse: 0.0851496\n",
      "[2750]\ttraining's rmse: 0.0809863\tvalid_1's rmse: 0.0851492\n",
      "[2775]\ttraining's rmse: 0.0809845\tvalid_1's rmse: 0.0851489\n",
      "[2800]\ttraining's rmse: 0.080983\tvalid_1's rmse: 0.0851488\n",
      "[2825]\ttraining's rmse: 0.0809817\tvalid_1's rmse: 0.0851485\n",
      "[2850]\ttraining's rmse: 0.0809808\tvalid_1's rmse: 0.0851487\n",
      "[2875]\ttraining's rmse: 0.0809793\tvalid_1's rmse: 0.0851488\n",
      "Early stopping, best iteration is:\n",
      "[2836]\ttraining's rmse: 0.0809814\tvalid_1's rmse: 0.0851485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0839536\tvalid_1's rmse: 0.0862335\n",
      "[50]\ttraining's rmse: 0.083833\tvalid_1's rmse: 0.0861795\n",
      "[75]\ttraining's rmse: 0.0837075\tvalid_1's rmse: 0.0861241\n",
      "[100]\ttraining's rmse: 0.0835951\tvalid_1's rmse: 0.0860756\n",
      "[125]\ttraining's rmse: 0.083475\tvalid_1's rmse: 0.0860278\n",
      "[150]\ttraining's rmse: 0.0833688\tvalid_1's rmse: 0.0859824\n",
      "[175]\ttraining's rmse: 0.0832822\tvalid_1's rmse: 0.0859463\n",
      "[200]\ttraining's rmse: 0.0831847\tvalid_1's rmse: 0.085907\n",
      "[225]\ttraining's rmse: 0.0830909\tvalid_1's rmse: 0.0858709\n",
      "[250]\ttraining's rmse: 0.0830105\tvalid_1's rmse: 0.0858365\n",
      "[275]\ttraining's rmse: 0.0829373\tvalid_1's rmse: 0.0858071\n",
      "[300]\ttraining's rmse: 0.0828645\tvalid_1's rmse: 0.0857791\n",
      "[325]\ttraining's rmse: 0.0827898\tvalid_1's rmse: 0.0857507\n",
      "[350]\ttraining's rmse: 0.0827184\tvalid_1's rmse: 0.0857257\n",
      "[375]\ttraining's rmse: 0.0826586\tvalid_1's rmse: 0.0857034\n",
      "[400]\ttraining's rmse: 0.0825943\tvalid_1's rmse: 0.0856827\n",
      "[425]\ttraining's rmse: 0.0825338\tvalid_1's rmse: 0.0856615\n",
      "[450]\ttraining's rmse: 0.0824803\tvalid_1's rmse: 0.0856421\n",
      "[475]\ttraining's rmse: 0.0824315\tvalid_1's rmse: 0.0856244\n",
      "[500]\ttraining's rmse: 0.0823885\tvalid_1's rmse: 0.0856063\n",
      "[525]\ttraining's rmse: 0.0823355\tvalid_1's rmse: 0.0855895\n",
      "[550]\ttraining's rmse: 0.0822851\tvalid_1's rmse: 0.085574\n",
      "[575]\ttraining's rmse: 0.0822383\tvalid_1's rmse: 0.085559\n",
      "[600]\ttraining's rmse: 0.0821933\tvalid_1's rmse: 0.085545\n",
      "[625]\ttraining's rmse: 0.0821567\tvalid_1's rmse: 0.0855323\n",
      "[650]\ttraining's rmse: 0.0821129\tvalid_1's rmse: 0.0855193\n",
      "[675]\ttraining's rmse: 0.0820715\tvalid_1's rmse: 0.0855086\n",
      "[700]\ttraining's rmse: 0.0820318\tvalid_1's rmse: 0.0854971\n",
      "[725]\ttraining's rmse: 0.0819972\tvalid_1's rmse: 0.0854877\n",
      "[750]\ttraining's rmse: 0.0819646\tvalid_1's rmse: 0.0854773\n",
      "[775]\ttraining's rmse: 0.0819356\tvalid_1's rmse: 0.0854672\n",
      "[800]\ttraining's rmse: 0.081901\tvalid_1's rmse: 0.085458\n",
      "[825]\ttraining's rmse: 0.0818706\tvalid_1's rmse: 0.0854495\n",
      "[850]\ttraining's rmse: 0.0818407\tvalid_1's rmse: 0.0854429\n",
      "[875]\ttraining's rmse: 0.0818129\tvalid_1's rmse: 0.0854351\n",
      "[900]\ttraining's rmse: 0.0817818\tvalid_1's rmse: 0.0854275\n",
      "[925]\ttraining's rmse: 0.0817544\tvalid_1's rmse: 0.0854209\n",
      "[950]\ttraining's rmse: 0.0817289\tvalid_1's rmse: 0.0854147\n",
      "[975]\ttraining's rmse: 0.0817027\tvalid_1's rmse: 0.0854092\n",
      "[1000]\ttraining's rmse: 0.0816805\tvalid_1's rmse: 0.0854043\n",
      "[1025]\ttraining's rmse: 0.0816566\tvalid_1's rmse: 0.0854007\n",
      "[1050]\ttraining's rmse: 0.0816336\tvalid_1's rmse: 0.0853949\n",
      "[1075]\ttraining's rmse: 0.0816127\tvalid_1's rmse: 0.0853909\n",
      "[1100]\ttraining's rmse: 0.0815971\tvalid_1's rmse: 0.0853869\n",
      "[1125]\ttraining's rmse: 0.0815772\tvalid_1's rmse: 0.0853828\n",
      "[1150]\ttraining's rmse: 0.081557\tvalid_1's rmse: 0.0853789\n",
      "[1175]\ttraining's rmse: 0.0815406\tvalid_1's rmse: 0.0853759\n",
      "[1200]\ttraining's rmse: 0.0815239\tvalid_1's rmse: 0.0853724\n",
      "[1225]\ttraining's rmse: 0.081507\tvalid_1's rmse: 0.0853691\n",
      "[1250]\ttraining's rmse: 0.0814933\tvalid_1's rmse: 0.0853656\n",
      "[1275]\ttraining's rmse: 0.0814752\tvalid_1's rmse: 0.0853633\n",
      "[1300]\ttraining's rmse: 0.0814611\tvalid_1's rmse: 0.0853606\n",
      "[1325]\ttraining's rmse: 0.0814485\tvalid_1's rmse: 0.0853582\n",
      "[1350]\ttraining's rmse: 0.0814341\tvalid_1's rmse: 0.0853568\n",
      "[1375]\ttraining's rmse: 0.0814204\tvalid_1's rmse: 0.0853553\n",
      "[1400]\ttraining's rmse: 0.0814089\tvalid_1's rmse: 0.0853524\n",
      "[1425]\ttraining's rmse: 0.0813972\tvalid_1's rmse: 0.0853507\n",
      "[1450]\ttraining's rmse: 0.0813859\tvalid_1's rmse: 0.0853492\n",
      "[1475]\ttraining's rmse: 0.0813762\tvalid_1's rmse: 0.085347\n",
      "[1500]\ttraining's rmse: 0.0813677\tvalid_1's rmse: 0.0853454\n",
      "[1525]\ttraining's rmse: 0.0813568\tvalid_1's rmse: 0.0853439\n",
      "[1550]\ttraining's rmse: 0.0813476\tvalid_1's rmse: 0.0853432\n",
      "[1575]\ttraining's rmse: 0.0813388\tvalid_1's rmse: 0.0853417\n",
      "[1600]\ttraining's rmse: 0.0813311\tvalid_1's rmse: 0.0853404\n",
      "[1625]\ttraining's rmse: 0.0813229\tvalid_1's rmse: 0.0853393\n",
      "[1650]\ttraining's rmse: 0.081315\tvalid_1's rmse: 0.0853386\n",
      "[1675]\ttraining's rmse: 0.0813085\tvalid_1's rmse: 0.0853372\n",
      "[1700]\ttraining's rmse: 0.0813033\tvalid_1's rmse: 0.0853359\n",
      "[1725]\ttraining's rmse: 0.0812967\tvalid_1's rmse: 0.0853337\n",
      "[1750]\ttraining's rmse: 0.0812895\tvalid_1's rmse: 0.0853326\n",
      "[1775]\ttraining's rmse: 0.0812833\tvalid_1's rmse: 0.0853322\n",
      "[1800]\ttraining's rmse: 0.0812775\tvalid_1's rmse: 0.0853309\n",
      "[1825]\ttraining's rmse: 0.0812728\tvalid_1's rmse: 0.0853303\n",
      "[1850]\ttraining's rmse: 0.0812675\tvalid_1's rmse: 0.0853297\n",
      "[1875]\ttraining's rmse: 0.0812612\tvalid_1's rmse: 0.0853284\n",
      "[1900]\ttraining's rmse: 0.0812568\tvalid_1's rmse: 0.0853282\n",
      "[1925]\ttraining's rmse: 0.0812528\tvalid_1's rmse: 0.0853273\n",
      "[1950]\ttraining's rmse: 0.0812498\tvalid_1's rmse: 0.0853267\n",
      "[1975]\ttraining's rmse: 0.0812462\tvalid_1's rmse: 0.0853263\n",
      "[2000]\ttraining's rmse: 0.0812396\tvalid_1's rmse: 0.0853256\n",
      "[2025]\ttraining's rmse: 0.0812356\tvalid_1's rmse: 0.0853247\n",
      "[2050]\ttraining's rmse: 0.0812307\tvalid_1's rmse: 0.0853243\n",
      "[2075]\ttraining's rmse: 0.0812278\tvalid_1's rmse: 0.0853239\n",
      "[2100]\ttraining's rmse: 0.0812247\tvalid_1's rmse: 0.0853238\n",
      "[2125]\ttraining's rmse: 0.0812204\tvalid_1's rmse: 0.0853234\n",
      "[2150]\ttraining's rmse: 0.0812173\tvalid_1's rmse: 0.0853231\n",
      "[2175]\ttraining's rmse: 0.0812143\tvalid_1's rmse: 0.0853233\n",
      "[2200]\ttraining's rmse: 0.0812109\tvalid_1's rmse: 0.0853226\n",
      "[2225]\ttraining's rmse: 0.0812065\tvalid_1's rmse: 0.0853222\n",
      "[2250]\ttraining's rmse: 0.0812031\tvalid_1's rmse: 0.0853222\n",
      "[2275]\ttraining's rmse: 0.0811996\tvalid_1's rmse: 0.085322\n",
      "Early stopping, best iteration is:\n",
      "[2239]\ttraining's rmse: 0.0812038\tvalid_1's rmse: 0.0853219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.085994\tvalid_1's rmse: 0.0820768\n",
      "[50]\ttraining's rmse: 0.0858735\tvalid_1's rmse: 0.0820258\n",
      "[75]\ttraining's rmse: 0.0857448\tvalid_1's rmse: 0.0819739\n",
      "[100]\ttraining's rmse: 0.0856308\tvalid_1's rmse: 0.081931\n",
      "[125]\ttraining's rmse: 0.0855114\tvalid_1's rmse: 0.0818879\n",
      "[150]\ttraining's rmse: 0.0854041\tvalid_1's rmse: 0.0818495\n",
      "[175]\ttraining's rmse: 0.0853139\tvalid_1's rmse: 0.0818172\n",
      "[200]\ttraining's rmse: 0.0852169\tvalid_1's rmse: 0.0817836\n",
      "[225]\ttraining's rmse: 0.0851216\tvalid_1's rmse: 0.081751\n",
      "[250]\ttraining's rmse: 0.0850418\tvalid_1's rmse: 0.0817241\n",
      "[275]\ttraining's rmse: 0.0849697\tvalid_1's rmse: 0.0816981\n",
      "[300]\ttraining's rmse: 0.0848947\tvalid_1's rmse: 0.0816742\n",
      "[325]\ttraining's rmse: 0.0848177\tvalid_1's rmse: 0.0816504\n",
      "[350]\ttraining's rmse: 0.0847461\tvalid_1's rmse: 0.081628\n",
      "[375]\ttraining's rmse: 0.0846873\tvalid_1's rmse: 0.0816128\n",
      "[400]\ttraining's rmse: 0.0846207\tvalid_1's rmse: 0.0815986\n",
      "[425]\ttraining's rmse: 0.0845619\tvalid_1's rmse: 0.0815834\n",
      "[450]\ttraining's rmse: 0.0845088\tvalid_1's rmse: 0.0815671\n",
      "[475]\ttraining's rmse: 0.0844598\tvalid_1's rmse: 0.0815543\n",
      "[500]\ttraining's rmse: 0.0844169\tvalid_1's rmse: 0.0815411\n",
      "[525]\ttraining's rmse: 0.0843614\tvalid_1's rmse: 0.0815285\n",
      "[550]\ttraining's rmse: 0.084311\tvalid_1's rmse: 0.0815164\n",
      "[575]\ttraining's rmse: 0.0842625\tvalid_1's rmse: 0.0815078\n",
      "[600]\ttraining's rmse: 0.0842162\tvalid_1's rmse: 0.0815012\n",
      "[625]\ttraining's rmse: 0.0841804\tvalid_1's rmse: 0.0814964\n",
      "[650]\ttraining's rmse: 0.0841328\tvalid_1's rmse: 0.0814928\n",
      "[675]\ttraining's rmse: 0.0840874\tvalid_1's rmse: 0.081484\n",
      "[700]\ttraining's rmse: 0.084047\tvalid_1's rmse: 0.0814754\n",
      "[725]\ttraining's rmse: 0.0840106\tvalid_1's rmse: 0.0814748\n",
      "[750]\ttraining's rmse: 0.0839761\tvalid_1's rmse: 0.0814758\n",
      "[775]\ttraining's rmse: 0.0839465\tvalid_1's rmse: 0.0814729\n",
      "[800]\ttraining's rmse: 0.0839088\tvalid_1's rmse: 0.081473\n",
      "[825]\ttraining's rmse: 0.0838766\tvalid_1's rmse: 0.0814695\n",
      "[850]\ttraining's rmse: 0.0838461\tvalid_1's rmse: 0.0814649\n",
      "[875]\ttraining's rmse: 0.0838172\tvalid_1's rmse: 0.0814623\n",
      "[900]\ttraining's rmse: 0.0837865\tvalid_1's rmse: 0.0814581\n",
      "[925]\ttraining's rmse: 0.0837561\tvalid_1's rmse: 0.0814615\n",
      "[950]\ttraining's rmse: 0.0837295\tvalid_1's rmse: 0.0814685\n",
      "Early stopping, best iteration is:\n",
      "[909]\ttraining's rmse: 0.0837766\tvalid_1's rmse: 0.081457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0798175\tvalid_1's rmse: 0.0826909\n",
      "[50]\ttraining's rmse: 0.079703\tvalid_1's rmse: 0.0826356\n",
      "[75]\ttraining's rmse: 0.0795898\tvalid_1's rmse: 0.0825822\n",
      "[100]\ttraining's rmse: 0.0794859\tvalid_1's rmse: 0.0825366\n",
      "[125]\ttraining's rmse: 0.0793805\tvalid_1's rmse: 0.0824881\n",
      "[150]\ttraining's rmse: 0.0792851\tvalid_1's rmse: 0.0824447\n",
      "[175]\ttraining's rmse: 0.0792059\tvalid_1's rmse: 0.0824074\n",
      "[200]\ttraining's rmse: 0.0791203\tvalid_1's rmse: 0.0823695\n",
      "[225]\ttraining's rmse: 0.079037\tvalid_1's rmse: 0.082332\n",
      "[250]\ttraining's rmse: 0.0789685\tvalid_1's rmse: 0.0823008\n",
      "[275]\ttraining's rmse: 0.0789025\tvalid_1's rmse: 0.08227\n",
      "[300]\ttraining's rmse: 0.0788369\tvalid_1's rmse: 0.0822409\n",
      "[325]\ttraining's rmse: 0.0787697\tvalid_1's rmse: 0.082213\n",
      "[350]\ttraining's rmse: 0.0787079\tvalid_1's rmse: 0.0821859\n",
      "[375]\ttraining's rmse: 0.0786554\tvalid_1's rmse: 0.0821645\n",
      "[400]\ttraining's rmse: 0.078599\tvalid_1's rmse: 0.0821427\n",
      "[425]\ttraining's rmse: 0.0785514\tvalid_1's rmse: 0.082123\n",
      "[450]\ttraining's rmse: 0.078505\tvalid_1's rmse: 0.0821033\n",
      "[475]\ttraining's rmse: 0.0784626\tvalid_1's rmse: 0.0820829\n",
      "[500]\ttraining's rmse: 0.078424\tvalid_1's rmse: 0.0820659\n",
      "[525]\ttraining's rmse: 0.0783781\tvalid_1's rmse: 0.0820499\n",
      "[550]\ttraining's rmse: 0.0783338\tvalid_1's rmse: 0.0820355\n",
      "[575]\ttraining's rmse: 0.0782945\tvalid_1's rmse: 0.0820205\n",
      "[600]\ttraining's rmse: 0.0782595\tvalid_1's rmse: 0.0820056\n",
      "[625]\ttraining's rmse: 0.0782292\tvalid_1's rmse: 0.081993\n",
      "[650]\ttraining's rmse: 0.0781923\tvalid_1's rmse: 0.0819798\n",
      "[675]\ttraining's rmse: 0.0781566\tvalid_1's rmse: 0.0819665\n",
      "[700]\ttraining's rmse: 0.0781254\tvalid_1's rmse: 0.0819553\n",
      "[725]\ttraining's rmse: 0.0780946\tvalid_1's rmse: 0.0819458\n",
      "[750]\ttraining's rmse: 0.0780654\tvalid_1's rmse: 0.0819352\n",
      "[775]\ttraining's rmse: 0.0780419\tvalid_1's rmse: 0.0819254\n",
      "[800]\ttraining's rmse: 0.0780117\tvalid_1's rmse: 0.0819162\n",
      "[825]\ttraining's rmse: 0.0779856\tvalid_1's rmse: 0.0819064\n",
      "[850]\ttraining's rmse: 0.0779615\tvalid_1's rmse: 0.0818982\n",
      "[875]\ttraining's rmse: 0.0779385\tvalid_1's rmse: 0.0818886\n",
      "[900]\ttraining's rmse: 0.0779145\tvalid_1's rmse: 0.0818812\n",
      "[925]\ttraining's rmse: 0.0778908\tvalid_1's rmse: 0.0818727\n",
      "[950]\ttraining's rmse: 0.0778688\tvalid_1's rmse: 0.081867\n",
      "[975]\ttraining's rmse: 0.0778476\tvalid_1's rmse: 0.0818596\n",
      "[1000]\ttraining's rmse: 0.0778284\tvalid_1's rmse: 0.0818539\n",
      "[1025]\ttraining's rmse: 0.0778087\tvalid_1's rmse: 0.0818463\n",
      "[1050]\ttraining's rmse: 0.0777926\tvalid_1's rmse: 0.0818387\n",
      "[1075]\ttraining's rmse: 0.0777736\tvalid_1's rmse: 0.0818342\n",
      "[1100]\ttraining's rmse: 0.0777601\tvalid_1's rmse: 0.0818294\n",
      "[1125]\ttraining's rmse: 0.0777448\tvalid_1's rmse: 0.0818221\n",
      "[1150]\ttraining's rmse: 0.0777276\tvalid_1's rmse: 0.0818185\n",
      "[1175]\ttraining's rmse: 0.0777133\tvalid_1's rmse: 0.0818148\n",
      "[1200]\ttraining's rmse: 0.0777016\tvalid_1's rmse: 0.0818097\n",
      "[1225]\ttraining's rmse: 0.0776866\tvalid_1's rmse: 0.0818039\n",
      "[1250]\ttraining's rmse: 0.077674\tvalid_1's rmse: 0.0817983\n",
      "[1275]\ttraining's rmse: 0.0776582\tvalid_1's rmse: 0.0817942\n",
      "[1300]\ttraining's rmse: 0.0776463\tvalid_1's rmse: 0.081789\n",
      "[1325]\ttraining's rmse: 0.0776345\tvalid_1's rmse: 0.0817866\n",
      "[1350]\ttraining's rmse: 0.0776247\tvalid_1's rmse: 0.0817844\n",
      "[1375]\ttraining's rmse: 0.0776145\tvalid_1's rmse: 0.0817806\n",
      "[1400]\ttraining's rmse: 0.0776064\tvalid_1's rmse: 0.0817759\n",
      "[1425]\ttraining's rmse: 0.0775963\tvalid_1's rmse: 0.081773\n",
      "[1450]\ttraining's rmse: 0.077584\tvalid_1's rmse: 0.0817705\n",
      "[1475]\ttraining's rmse: 0.0775745\tvalid_1's rmse: 0.0817678\n",
      "[1500]\ttraining's rmse: 0.0775661\tvalid_1's rmse: 0.0817652\n",
      "[1525]\ttraining's rmse: 0.0775567\tvalid_1's rmse: 0.0817627\n",
      "[1550]\ttraining's rmse: 0.0775491\tvalid_1's rmse: 0.0817599\n",
      "[1575]\ttraining's rmse: 0.0775409\tvalid_1's rmse: 0.081757\n",
      "[1600]\ttraining's rmse: 0.0775361\tvalid_1's rmse: 0.0817542\n",
      "[1625]\ttraining's rmse: 0.0775286\tvalid_1's rmse: 0.0817522\n",
      "[1650]\ttraining's rmse: 0.0775204\tvalid_1's rmse: 0.0817497\n",
      "[1675]\ttraining's rmse: 0.0775157\tvalid_1's rmse: 0.0817475\n",
      "[1700]\ttraining's rmse: 0.0775125\tvalid_1's rmse: 0.0817456\n",
      "[1725]\ttraining's rmse: 0.0775075\tvalid_1's rmse: 0.0817445\n",
      "[1750]\ttraining's rmse: 0.0775009\tvalid_1's rmse: 0.0817431\n",
      "[1775]\ttraining's rmse: 0.077496\tvalid_1's rmse: 0.0817409\n",
      "[1800]\ttraining's rmse: 0.0774909\tvalid_1's rmse: 0.0817395\n",
      "[1825]\ttraining's rmse: 0.0774876\tvalid_1's rmse: 0.0817384\n",
      "[1850]\ttraining's rmse: 0.0774834\tvalid_1's rmse: 0.0817364\n",
      "[1875]\ttraining's rmse: 0.0774778\tvalid_1's rmse: 0.0817353\n",
      "[1900]\ttraining's rmse: 0.0774739\tvalid_1's rmse: 0.0817345\n",
      "[1925]\ttraining's rmse: 0.0774694\tvalid_1's rmse: 0.0817337\n",
      "[1950]\ttraining's rmse: 0.0774655\tvalid_1's rmse: 0.0817326\n",
      "[1975]\ttraining's rmse: 0.0774625\tvalid_1's rmse: 0.0817308\n",
      "[2000]\ttraining's rmse: 0.0774575\tvalid_1's rmse: 0.0817306\n",
      "[2025]\ttraining's rmse: 0.0774545\tvalid_1's rmse: 0.081729\n",
      "[2050]\ttraining's rmse: 0.0774526\tvalid_1's rmse: 0.0817279\n",
      "[2075]\ttraining's rmse: 0.0774502\tvalid_1's rmse: 0.0817271\n",
      "[2100]\ttraining's rmse: 0.0774477\tvalid_1's rmse: 0.0817259\n",
      "[2125]\ttraining's rmse: 0.077445\tvalid_1's rmse: 0.0817244\n",
      "[2150]\ttraining's rmse: 0.0774403\tvalid_1's rmse: 0.0817223\n",
      "[2175]\ttraining's rmse: 0.0774386\tvalid_1's rmse: 0.0817218\n",
      "[2200]\ttraining's rmse: 0.077436\tvalid_1's rmse: 0.081721\n",
      "[2225]\ttraining's rmse: 0.0774325\tvalid_1's rmse: 0.0817204\n",
      "[2250]\ttraining's rmse: 0.0774305\tvalid_1's rmse: 0.0817199\n",
      "[2275]\ttraining's rmse: 0.0774275\tvalid_1's rmse: 0.0817192\n",
      "[2300]\ttraining's rmse: 0.0774255\tvalid_1's rmse: 0.0817179\n",
      "[2325]\ttraining's rmse: 0.0774227\tvalid_1's rmse: 0.0817172\n",
      "[2350]\ttraining's rmse: 0.0774207\tvalid_1's rmse: 0.0817164\n",
      "[2375]\ttraining's rmse: 0.077416\tvalid_1's rmse: 0.0817149\n",
      "[2400]\ttraining's rmse: 0.0774142\tvalid_1's rmse: 0.0817139\n",
      "[2425]\ttraining's rmse: 0.0774119\tvalid_1's rmse: 0.0817136\n",
      "[2450]\ttraining's rmse: 0.0774104\tvalid_1's rmse: 0.0817133\n",
      "[2475]\ttraining's rmse: 0.0774088\tvalid_1's rmse: 0.0817136\n",
      "Early stopping, best iteration is:\n",
      "[2449]\ttraining's rmse: 0.0774104\tvalid_1's rmse: 0.0817133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.080134\tvalid_1's rmse: 0.0820637\n",
      "[50]\ttraining's rmse: 0.0800228\tvalid_1's rmse: 0.0820077\n",
      "[75]\ttraining's rmse: 0.0799098\tvalid_1's rmse: 0.0819526\n",
      "[100]\ttraining's rmse: 0.079809\tvalid_1's rmse: 0.0819039\n",
      "[125]\ttraining's rmse: 0.0797041\tvalid_1's rmse: 0.0818554\n",
      "[150]\ttraining's rmse: 0.0796081\tvalid_1's rmse: 0.0818105\n",
      "[175]\ttraining's rmse: 0.0795294\tvalid_1's rmse: 0.0817741\n",
      "[200]\ttraining's rmse: 0.0794402\tvalid_1's rmse: 0.0817352\n",
      "[225]\ttraining's rmse: 0.0793588\tvalid_1's rmse: 0.0816998\n",
      "[250]\ttraining's rmse: 0.0792893\tvalid_1's rmse: 0.0816687\n",
      "[275]\ttraining's rmse: 0.0792237\tvalid_1's rmse: 0.0816395\n",
      "[300]\ttraining's rmse: 0.079158\tvalid_1's rmse: 0.0816107\n",
      "[325]\ttraining's rmse: 0.0790908\tvalid_1's rmse: 0.0815831\n",
      "[350]\ttraining's rmse: 0.0790266\tvalid_1's rmse: 0.0815584\n",
      "[375]\ttraining's rmse: 0.0789721\tvalid_1's rmse: 0.081537\n",
      "[400]\ttraining's rmse: 0.0789137\tvalid_1's rmse: 0.0815148\n",
      "[425]\ttraining's rmse: 0.0788612\tvalid_1's rmse: 0.0814958\n",
      "[450]\ttraining's rmse: 0.0788123\tvalid_1's rmse: 0.0814768\n",
      "[475]\ttraining's rmse: 0.0787659\tvalid_1's rmse: 0.0814602\n",
      "[500]\ttraining's rmse: 0.0787263\tvalid_1's rmse: 0.0814438\n",
      "[525]\ttraining's rmse: 0.0786783\tvalid_1's rmse: 0.0814277\n",
      "[550]\ttraining's rmse: 0.0786318\tvalid_1's rmse: 0.0814122\n",
      "[575]\ttraining's rmse: 0.0785889\tvalid_1's rmse: 0.0813984\n",
      "[600]\ttraining's rmse: 0.0785477\tvalid_1's rmse: 0.0813863\n",
      "[625]\ttraining's rmse: 0.0785177\tvalid_1's rmse: 0.0813741\n",
      "[650]\ttraining's rmse: 0.0784799\tvalid_1's rmse: 0.0813619\n",
      "[675]\ttraining's rmse: 0.0784397\tvalid_1's rmse: 0.08135\n",
      "[700]\ttraining's rmse: 0.0784052\tvalid_1's rmse: 0.0813394\n",
      "[725]\ttraining's rmse: 0.0783747\tvalid_1's rmse: 0.0813301\n",
      "[750]\ttraining's rmse: 0.0783438\tvalid_1's rmse: 0.0813208\n",
      "[775]\ttraining's rmse: 0.0783194\tvalid_1's rmse: 0.0813125\n",
      "[800]\ttraining's rmse: 0.0782875\tvalid_1's rmse: 0.0813043\n",
      "[825]\ttraining's rmse: 0.0782601\tvalid_1's rmse: 0.0812955\n",
      "[850]\ttraining's rmse: 0.0782319\tvalid_1's rmse: 0.0812886\n",
      "[875]\ttraining's rmse: 0.078207\tvalid_1's rmse: 0.0812823\n",
      "[900]\ttraining's rmse: 0.0781824\tvalid_1's rmse: 0.0812754\n",
      "[925]\ttraining's rmse: 0.0781584\tvalid_1's rmse: 0.0812699\n",
      "[950]\ttraining's rmse: 0.0781356\tvalid_1's rmse: 0.0812639\n",
      "[975]\ttraining's rmse: 0.0781153\tvalid_1's rmse: 0.0812587\n",
      "[1000]\ttraining's rmse: 0.0780953\tvalid_1's rmse: 0.0812533\n",
      "[1025]\ttraining's rmse: 0.0780716\tvalid_1's rmse: 0.0812482\n",
      "[1050]\ttraining's rmse: 0.0780518\tvalid_1's rmse: 0.0812435\n",
      "[1075]\ttraining's rmse: 0.0780335\tvalid_1's rmse: 0.0812399\n",
      "[1100]\ttraining's rmse: 0.0780178\tvalid_1's rmse: 0.0812359\n",
      "[1125]\ttraining's rmse: 0.0780011\tvalid_1's rmse: 0.0812326\n",
      "[1150]\ttraining's rmse: 0.0779856\tvalid_1's rmse: 0.0812291\n",
      "[1175]\ttraining's rmse: 0.0779711\tvalid_1's rmse: 0.0812264\n",
      "[1200]\ttraining's rmse: 0.0779548\tvalid_1's rmse: 0.0812236\n",
      "[1225]\ttraining's rmse: 0.0779411\tvalid_1's rmse: 0.0812209\n",
      "[1250]\ttraining's rmse: 0.0779266\tvalid_1's rmse: 0.0812179\n",
      "[1275]\ttraining's rmse: 0.0779133\tvalid_1's rmse: 0.081215\n",
      "[1300]\ttraining's rmse: 0.0779022\tvalid_1's rmse: 0.0812127\n",
      "[1325]\ttraining's rmse: 0.0778924\tvalid_1's rmse: 0.0812109\n",
      "[1350]\ttraining's rmse: 0.0778803\tvalid_1's rmse: 0.0812086\n",
      "[1375]\ttraining's rmse: 0.0778689\tvalid_1's rmse: 0.0812065\n",
      "[1400]\ttraining's rmse: 0.0778606\tvalid_1's rmse: 0.0812045\n",
      "[1425]\ttraining's rmse: 0.0778516\tvalid_1's rmse: 0.0812032\n",
      "[1450]\ttraining's rmse: 0.0778407\tvalid_1's rmse: 0.0812018\n",
      "[1475]\ttraining's rmse: 0.0778303\tvalid_1's rmse: 0.0811995\n",
      "[1500]\ttraining's rmse: 0.0778235\tvalid_1's rmse: 0.0811978\n",
      "[1525]\ttraining's rmse: 0.0778141\tvalid_1's rmse: 0.081196\n",
      "[1550]\ttraining's rmse: 0.0778046\tvalid_1's rmse: 0.0811947\n",
      "[1575]\ttraining's rmse: 0.0777969\tvalid_1's rmse: 0.0811938\n",
      "[1600]\ttraining's rmse: 0.0777896\tvalid_1's rmse: 0.0811929\n",
      "[1625]\ttraining's rmse: 0.0777814\tvalid_1's rmse: 0.081192\n",
      "[1650]\ttraining's rmse: 0.0777747\tvalid_1's rmse: 0.0811908\n",
      "[1675]\ttraining's rmse: 0.0777693\tvalid_1's rmse: 0.0811898\n",
      "[1700]\ttraining's rmse: 0.077764\tvalid_1's rmse: 0.0811891\n",
      "[1725]\ttraining's rmse: 0.077758\tvalid_1's rmse: 0.0811883\n",
      "[1750]\ttraining's rmse: 0.0777518\tvalid_1's rmse: 0.0811874\n",
      "[1775]\ttraining's rmse: 0.0777469\tvalid_1's rmse: 0.0811868\n",
      "[1800]\ttraining's rmse: 0.077741\tvalid_1's rmse: 0.081186\n",
      "[1825]\ttraining's rmse: 0.0777353\tvalid_1's rmse: 0.0811849\n",
      "[1850]\ttraining's rmse: 0.0777312\tvalid_1's rmse: 0.0811843\n",
      "[1875]\ttraining's rmse: 0.0777263\tvalid_1's rmse: 0.0811835\n",
      "[1900]\ttraining's rmse: 0.0777231\tvalid_1's rmse: 0.0811832\n",
      "[1925]\ttraining's rmse: 0.0777193\tvalid_1's rmse: 0.0811825\n",
      "[1950]\ttraining's rmse: 0.0777156\tvalid_1's rmse: 0.0811817\n",
      "[1975]\ttraining's rmse: 0.0777129\tvalid_1's rmse: 0.0811812\n",
      "[2000]\ttraining's rmse: 0.0777075\tvalid_1's rmse: 0.0811809\n",
      "[2025]\ttraining's rmse: 0.0777032\tvalid_1's rmse: 0.0811805\n",
      "[2050]\ttraining's rmse: 0.0777004\tvalid_1's rmse: 0.0811801\n",
      "[2075]\ttraining's rmse: 0.077697\tvalid_1's rmse: 0.0811798\n",
      "[2100]\ttraining's rmse: 0.0776936\tvalid_1's rmse: 0.0811793\n",
      "[2125]\ttraining's rmse: 0.07769\tvalid_1's rmse: 0.0811792\n",
      "[2150]\ttraining's rmse: 0.0776863\tvalid_1's rmse: 0.0811792\n",
      "[2175]\ttraining's rmse: 0.0776837\tvalid_1's rmse: 0.0811791\n",
      "[2200]\ttraining's rmse: 0.0776815\tvalid_1's rmse: 0.0811788\n",
      "[2225]\ttraining's rmse: 0.0776789\tvalid_1's rmse: 0.0811788\n",
      "[2250]\ttraining's rmse: 0.0776761\tvalid_1's rmse: 0.0811789\n",
      "Early stopping, best iteration is:\n",
      "[2208]\ttraining's rmse: 0.0776802\tvalid_1's rmse: 0.0811786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0822614\tvalid_1's rmse: 0.0777236\n",
      "[50]\ttraining's rmse: 0.0821475\tvalid_1's rmse: 0.0776741\n",
      "[75]\ttraining's rmse: 0.0820332\tvalid_1's rmse: 0.0776264\n",
      "[100]\ttraining's rmse: 0.0819304\tvalid_1's rmse: 0.0775834\n",
      "[125]\ttraining's rmse: 0.081825\tvalid_1's rmse: 0.0775418\n",
      "[150]\ttraining's rmse: 0.0817277\tvalid_1's rmse: 0.077505\n",
      "[175]\ttraining's rmse: 0.0816496\tvalid_1's rmse: 0.0774748\n",
      "[200]\ttraining's rmse: 0.0815633\tvalid_1's rmse: 0.0774434\n",
      "[225]\ttraining's rmse: 0.0814817\tvalid_1's rmse: 0.0774134\n",
      "[250]\ttraining's rmse: 0.0814129\tvalid_1's rmse: 0.0773895\n",
      "[275]\ttraining's rmse: 0.0813472\tvalid_1's rmse: 0.0773651\n",
      "[300]\ttraining's rmse: 0.0812825\tvalid_1's rmse: 0.0773414\n",
      "[325]\ttraining's rmse: 0.081219\tvalid_1's rmse: 0.0773196\n",
      "[350]\ttraining's rmse: 0.0811555\tvalid_1's rmse: 0.0772998\n",
      "[375]\ttraining's rmse: 0.0811029\tvalid_1's rmse: 0.0772826\n",
      "[400]\ttraining's rmse: 0.0810471\tvalid_1's rmse: 0.0772665\n",
      "[425]\ttraining's rmse: 0.080997\tvalid_1's rmse: 0.0772508\n",
      "[450]\ttraining's rmse: 0.0809503\tvalid_1's rmse: 0.0772352\n",
      "[475]\ttraining's rmse: 0.0809061\tvalid_1's rmse: 0.0772224\n",
      "[500]\ttraining's rmse: 0.0808687\tvalid_1's rmse: 0.0772092\n",
      "[525]\ttraining's rmse: 0.0808185\tvalid_1's rmse: 0.0771953\n",
      "[550]\ttraining's rmse: 0.0807725\tvalid_1's rmse: 0.0771852\n",
      "[575]\ttraining's rmse: 0.0807324\tvalid_1's rmse: 0.0771752\n",
      "[600]\ttraining's rmse: 0.0806927\tvalid_1's rmse: 0.0771666\n",
      "[625]\ttraining's rmse: 0.0806629\tvalid_1's rmse: 0.0771684\n",
      "[650]\ttraining's rmse: 0.0806242\tvalid_1's rmse: 0.0771598\n",
      "[675]\ttraining's rmse: 0.0805851\tvalid_1's rmse: 0.0771568\n",
      "[700]\ttraining's rmse: 0.0805508\tvalid_1's rmse: 0.0771493\n",
      "[725]\ttraining's rmse: 0.0805181\tvalid_1's rmse: 0.0771643\n",
      "[750]\ttraining's rmse: 0.0804859\tvalid_1's rmse: 0.0771631\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's rmse: 0.0805508\tvalid_1's rmse: 0.0771493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0851319\tvalid_1's rmse: 0.0868347\n",
      "[50]\ttraining's rmse: 0.0849879\tvalid_1's rmse: 0.0867836\n",
      "[75]\ttraining's rmse: 0.0848427\tvalid_1's rmse: 0.0867318\n",
      "[100]\ttraining's rmse: 0.0847071\tvalid_1's rmse: 0.0866852\n",
      "[125]\ttraining's rmse: 0.0845742\tvalid_1's rmse: 0.0866407\n",
      "[150]\ttraining's rmse: 0.0844534\tvalid_1's rmse: 0.0865987\n",
      "[175]\ttraining's rmse: 0.084349\tvalid_1's rmse: 0.0865629\n",
      "[200]\ttraining's rmse: 0.0842389\tvalid_1's rmse: 0.086529\n",
      "[225]\ttraining's rmse: 0.0841309\tvalid_1's rmse: 0.0864948\n",
      "[250]\ttraining's rmse: 0.0840388\tvalid_1's rmse: 0.0864643\n",
      "[275]\ttraining's rmse: 0.0839542\tvalid_1's rmse: 0.0864363\n",
      "[300]\ttraining's rmse: 0.0838728\tvalid_1's rmse: 0.0864115\n",
      "[325]\ttraining's rmse: 0.0837913\tvalid_1's rmse: 0.0863866\n",
      "[350]\ttraining's rmse: 0.0837091\tvalid_1's rmse: 0.0863617\n",
      "[375]\ttraining's rmse: 0.0836394\tvalid_1's rmse: 0.0863418\n",
      "[400]\ttraining's rmse: 0.0835657\tvalid_1's rmse: 0.0863209\n",
      "[425]\ttraining's rmse: 0.0835002\tvalid_1's rmse: 0.086303\n",
      "[450]\ttraining's rmse: 0.0834407\tvalid_1's rmse: 0.0862852\n",
      "[475]\ttraining's rmse: 0.0833859\tvalid_1's rmse: 0.0862707\n",
      "[500]\ttraining's rmse: 0.0833412\tvalid_1's rmse: 0.0862548\n",
      "[525]\ttraining's rmse: 0.0832809\tvalid_1's rmse: 0.0862381\n",
      "[550]\ttraining's rmse: 0.0832261\tvalid_1's rmse: 0.0862249\n",
      "[575]\ttraining's rmse: 0.0831754\tvalid_1's rmse: 0.0862124\n",
      "[600]\ttraining's rmse: 0.083126\tvalid_1's rmse: 0.0862\n",
      "[625]\ttraining's rmse: 0.0830863\tvalid_1's rmse: 0.0861881\n",
      "[650]\ttraining's rmse: 0.0830403\tvalid_1's rmse: 0.0861772\n",
      "[675]\ttraining's rmse: 0.0829948\tvalid_1's rmse: 0.0861651\n",
      "[700]\ttraining's rmse: 0.0829547\tvalid_1's rmse: 0.0861541\n",
      "[725]\ttraining's rmse: 0.0829191\tvalid_1's rmse: 0.0861454\n",
      "[750]\ttraining's rmse: 0.0828801\tvalid_1's rmse: 0.0861363\n",
      "[775]\ttraining's rmse: 0.0828514\tvalid_1's rmse: 0.0861286\n",
      "[800]\ttraining's rmse: 0.0828114\tvalid_1's rmse: 0.086121\n",
      "[825]\ttraining's rmse: 0.0827806\tvalid_1's rmse: 0.0861125\n",
      "[850]\ttraining's rmse: 0.0827437\tvalid_1's rmse: 0.0861059\n",
      "[875]\ttraining's rmse: 0.0827143\tvalid_1's rmse: 0.0861002\n",
      "[900]\ttraining's rmse: 0.0826807\tvalid_1's rmse: 0.0860934\n",
      "[925]\ttraining's rmse: 0.0826536\tvalid_1's rmse: 0.0860877\n",
      "[950]\ttraining's rmse: 0.0826249\tvalid_1's rmse: 0.0860809\n",
      "[975]\ttraining's rmse: 0.0825992\tvalid_1's rmse: 0.0860755\n",
      "[1000]\ttraining's rmse: 0.0825758\tvalid_1's rmse: 0.0860704\n",
      "[1025]\ttraining's rmse: 0.0825512\tvalid_1's rmse: 0.0860656\n",
      "[1050]\ttraining's rmse: 0.0825284\tvalid_1's rmse: 0.0860603\n",
      "[1075]\ttraining's rmse: 0.0825082\tvalid_1's rmse: 0.0860556\n",
      "[1100]\ttraining's rmse: 0.082489\tvalid_1's rmse: 0.0860511\n",
      "[1125]\ttraining's rmse: 0.0824691\tvalid_1's rmse: 0.0860467\n",
      "[1150]\ttraining's rmse: 0.0824477\tvalid_1's rmse: 0.0860425\n",
      "[1175]\ttraining's rmse: 0.0824287\tvalid_1's rmse: 0.0860397\n",
      "[1200]\ttraining's rmse: 0.0824129\tvalid_1's rmse: 0.0860359\n",
      "[1225]\ttraining's rmse: 0.0823974\tvalid_1's rmse: 0.0860322\n",
      "[1250]\ttraining's rmse: 0.0823813\tvalid_1's rmse: 0.0860287\n",
      "[1275]\ttraining's rmse: 0.0823624\tvalid_1's rmse: 0.0860264\n",
      "[1300]\ttraining's rmse: 0.0823493\tvalid_1's rmse: 0.0860217\n",
      "[1325]\ttraining's rmse: 0.082334\tvalid_1's rmse: 0.0860192\n",
      "[1350]\ttraining's rmse: 0.0823203\tvalid_1's rmse: 0.0860167\n",
      "[1375]\ttraining's rmse: 0.0823054\tvalid_1's rmse: 0.0860138\n",
      "[1400]\ttraining's rmse: 0.0822942\tvalid_1's rmse: 0.0860103\n",
      "[1425]\ttraining's rmse: 0.0822829\tvalid_1's rmse: 0.0860081\n",
      "[1450]\ttraining's rmse: 0.0822688\tvalid_1's rmse: 0.0860046\n",
      "[1475]\ttraining's rmse: 0.0822568\tvalid_1's rmse: 0.086002\n",
      "[1500]\ttraining's rmse: 0.0822464\tvalid_1's rmse: 0.0859984\n",
      "[1525]\ttraining's rmse: 0.0822355\tvalid_1's rmse: 0.0859952\n",
      "[1550]\ttraining's rmse: 0.0822231\tvalid_1's rmse: 0.0859934\n",
      "[1575]\ttraining's rmse: 0.0822152\tvalid_1's rmse: 0.0859907\n",
      "[1600]\ttraining's rmse: 0.0822055\tvalid_1's rmse: 0.08599\n",
      "[1625]\ttraining's rmse: 0.0821977\tvalid_1's rmse: 0.0859871\n",
      "[1650]\ttraining's rmse: 0.0821896\tvalid_1's rmse: 0.0859843\n",
      "[1675]\ttraining's rmse: 0.0821834\tvalid_1's rmse: 0.0859824\n",
      "[1700]\ttraining's rmse: 0.082177\tvalid_1's rmse: 0.0859807\n",
      "[1725]\ttraining's rmse: 0.0821708\tvalid_1's rmse: 0.0859801\n",
      "[1750]\ttraining's rmse: 0.0821638\tvalid_1's rmse: 0.0859788\n",
      "[1775]\ttraining's rmse: 0.0821573\tvalid_1's rmse: 0.0859781\n",
      "[1800]\ttraining's rmse: 0.0821523\tvalid_1's rmse: 0.0859764\n",
      "[1825]\ttraining's rmse: 0.0821474\tvalid_1's rmse: 0.0859746\n",
      "[1850]\ttraining's rmse: 0.0821427\tvalid_1's rmse: 0.0859731\n",
      "[1875]\ttraining's rmse: 0.0821385\tvalid_1's rmse: 0.0859722\n",
      "[1900]\ttraining's rmse: 0.0821331\tvalid_1's rmse: 0.0859711\n",
      "[1925]\ttraining's rmse: 0.0821275\tvalid_1's rmse: 0.0859695\n",
      "[1950]\ttraining's rmse: 0.0821219\tvalid_1's rmse: 0.0859672\n",
      "[1975]\ttraining's rmse: 0.0821169\tvalid_1's rmse: 0.0859659\n",
      "[2000]\ttraining's rmse: 0.0821115\tvalid_1's rmse: 0.0859653\n",
      "[2025]\ttraining's rmse: 0.0821074\tvalid_1's rmse: 0.0859637\n",
      "[2050]\ttraining's rmse: 0.0821033\tvalid_1's rmse: 0.0859627\n",
      "[2075]\ttraining's rmse: 0.0820997\tvalid_1's rmse: 0.0859607\n",
      "[2100]\ttraining's rmse: 0.0820955\tvalid_1's rmse: 0.0859593\n",
      "[2125]\ttraining's rmse: 0.0820921\tvalid_1's rmse: 0.0859583\n",
      "[2150]\ttraining's rmse: 0.0820875\tvalid_1's rmse: 0.0859572\n",
      "[2175]\ttraining's rmse: 0.0820841\tvalid_1's rmse: 0.0859566\n",
      "[2200]\ttraining's rmse: 0.0820813\tvalid_1's rmse: 0.0859561\n",
      "[2225]\ttraining's rmse: 0.0820782\tvalid_1's rmse: 0.0859543\n",
      "[2250]\ttraining's rmse: 0.0820743\tvalid_1's rmse: 0.0859536\n",
      "[2275]\ttraining's rmse: 0.0820713\tvalid_1's rmse: 0.0859531\n",
      "[2300]\ttraining's rmse: 0.0820664\tvalid_1's rmse: 0.0859528\n",
      "[2325]\ttraining's rmse: 0.0820617\tvalid_1's rmse: 0.0859511\n",
      "[2350]\ttraining's rmse: 0.0820585\tvalid_1's rmse: 0.0859504\n",
      "[2375]\ttraining's rmse: 0.0820567\tvalid_1's rmse: 0.0859501\n",
      "[2400]\ttraining's rmse: 0.0820539\tvalid_1's rmse: 0.0859492\n",
      "[2425]\ttraining's rmse: 0.0820514\tvalid_1's rmse: 0.0859485\n",
      "[2450]\ttraining's rmse: 0.0820481\tvalid_1's rmse: 0.0859476\n",
      "[2475]\ttraining's rmse: 0.0820458\tvalid_1's rmse: 0.0859471\n",
      "[2500]\ttraining's rmse: 0.0820435\tvalid_1's rmse: 0.0859461\n",
      "[2525]\ttraining's rmse: 0.0820407\tvalid_1's rmse: 0.0859454\n",
      "[2550]\ttraining's rmse: 0.0820379\tvalid_1's rmse: 0.0859445\n",
      "[2575]\ttraining's rmse: 0.0820366\tvalid_1's rmse: 0.0859444\n",
      "[2600]\ttraining's rmse: 0.0820342\tvalid_1's rmse: 0.0859443\n",
      "[2625]\ttraining's rmse: 0.082033\tvalid_1's rmse: 0.0859427\n",
      "[2650]\ttraining's rmse: 0.082031\tvalid_1's rmse: 0.085941\n",
      "[2675]\ttraining's rmse: 0.0820295\tvalid_1's rmse: 0.0859398\n",
      "[2700]\ttraining's rmse: 0.0820281\tvalid_1's rmse: 0.0859395\n",
      "[2725]\ttraining's rmse: 0.0820259\tvalid_1's rmse: 0.0859393\n",
      "[2750]\ttraining's rmse: 0.0820242\tvalid_1's rmse: 0.0859386\n",
      "[2775]\ttraining's rmse: 0.082022\tvalid_1's rmse: 0.0859389\n",
      "Early stopping, best iteration is:\n",
      "[2747]\ttraining's rmse: 0.0820243\tvalid_1's rmse: 0.0859385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.08499\tvalid_1's rmse: 0.0871521\n",
      "[50]\ttraining's rmse: 0.084867\tvalid_1's rmse: 0.0870974\n",
      "[75]\ttraining's rmse: 0.0847383\tvalid_1's rmse: 0.0870429\n",
      "[100]\ttraining's rmse: 0.0846228\tvalid_1's rmse: 0.086993\n",
      "[125]\ttraining's rmse: 0.084503\tvalid_1's rmse: 0.0869465\n",
      "[150]\ttraining's rmse: 0.0843933\tvalid_1's rmse: 0.0869007\n",
      "[175]\ttraining's rmse: 0.0843033\tvalid_1's rmse: 0.0868626\n",
      "[200]\ttraining's rmse: 0.0842034\tvalid_1's rmse: 0.0868238\n",
      "[225]\ttraining's rmse: 0.0841063\tvalid_1's rmse: 0.0867861\n",
      "[250]\ttraining's rmse: 0.0840227\tvalid_1's rmse: 0.0867526\n",
      "[275]\ttraining's rmse: 0.0839466\tvalid_1's rmse: 0.0867228\n",
      "[300]\ttraining's rmse: 0.0838728\tvalid_1's rmse: 0.0866938\n",
      "[325]\ttraining's rmse: 0.0837981\tvalid_1's rmse: 0.0866661\n",
      "[350]\ttraining's rmse: 0.0837251\tvalid_1's rmse: 0.0866398\n",
      "[375]\ttraining's rmse: 0.083665\tvalid_1's rmse: 0.0866177\n",
      "[400]\ttraining's rmse: 0.0835989\tvalid_1's rmse: 0.0865955\n",
      "[425]\ttraining's rmse: 0.0835415\tvalid_1's rmse: 0.0865743\n",
      "[450]\ttraining's rmse: 0.0834868\tvalid_1's rmse: 0.0865549\n",
      "[475]\ttraining's rmse: 0.0834379\tvalid_1's rmse: 0.0865369\n",
      "[500]\ttraining's rmse: 0.083397\tvalid_1's rmse: 0.0865205\n",
      "[525]\ttraining's rmse: 0.0833413\tvalid_1's rmse: 0.0865028\n",
      "[550]\ttraining's rmse: 0.0832891\tvalid_1's rmse: 0.0864868\n",
      "[575]\ttraining's rmse: 0.0832412\tvalid_1's rmse: 0.0864726\n",
      "[600]\ttraining's rmse: 0.0831971\tvalid_1's rmse: 0.0864599\n",
      "[625]\ttraining's rmse: 0.0831604\tvalid_1's rmse: 0.0864467\n",
      "[650]\ttraining's rmse: 0.0831149\tvalid_1's rmse: 0.0864325\n",
      "[675]\ttraining's rmse: 0.0830708\tvalid_1's rmse: 0.0864205\n",
      "[700]\ttraining's rmse: 0.0830298\tvalid_1's rmse: 0.0864088\n",
      "[725]\ttraining's rmse: 0.0829914\tvalid_1's rmse: 0.0863979\n",
      "[750]\ttraining's rmse: 0.0829581\tvalid_1's rmse: 0.0863887\n",
      "[775]\ttraining's rmse: 0.0829282\tvalid_1's rmse: 0.0863793\n",
      "[800]\ttraining's rmse: 0.0828915\tvalid_1's rmse: 0.0863712\n",
      "[825]\ttraining's rmse: 0.0828616\tvalid_1's rmse: 0.0863631\n",
      "[850]\ttraining's rmse: 0.08283\tvalid_1's rmse: 0.0863558\n",
      "[875]\ttraining's rmse: 0.0828015\tvalid_1's rmse: 0.0863488\n",
      "[900]\ttraining's rmse: 0.0827729\tvalid_1's rmse: 0.0863405\n",
      "[925]\ttraining's rmse: 0.0827444\tvalid_1's rmse: 0.0863347\n",
      "[950]\ttraining's rmse: 0.0827184\tvalid_1's rmse: 0.0863283\n",
      "[975]\ttraining's rmse: 0.0826942\tvalid_1's rmse: 0.0863223\n",
      "[1000]\ttraining's rmse: 0.0826707\tvalid_1's rmse: 0.0863165\n",
      "[1025]\ttraining's rmse: 0.0826461\tvalid_1's rmse: 0.0863107\n",
      "[1050]\ttraining's rmse: 0.0826253\tvalid_1's rmse: 0.0863056\n",
      "[1075]\ttraining's rmse: 0.0826037\tvalid_1's rmse: 0.0863015\n",
      "[1100]\ttraining's rmse: 0.0825859\tvalid_1's rmse: 0.0862964\n",
      "[1125]\ttraining's rmse: 0.0825665\tvalid_1's rmse: 0.086293\n",
      "[1150]\ttraining's rmse: 0.082546\tvalid_1's rmse: 0.0862888\n",
      "[1175]\ttraining's rmse: 0.0825277\tvalid_1's rmse: 0.0862864\n",
      "[1200]\ttraining's rmse: 0.0825105\tvalid_1's rmse: 0.0862834\n",
      "[1225]\ttraining's rmse: 0.0824948\tvalid_1's rmse: 0.0862805\n",
      "[1250]\ttraining's rmse: 0.0824787\tvalid_1's rmse: 0.0862778\n",
      "[1275]\ttraining's rmse: 0.0824617\tvalid_1's rmse: 0.0862756\n",
      "[1300]\ttraining's rmse: 0.0824477\tvalid_1's rmse: 0.0862727\n",
      "[1325]\ttraining's rmse: 0.0824317\tvalid_1's rmse: 0.0862707\n",
      "[1350]\ttraining's rmse: 0.0824157\tvalid_1's rmse: 0.0862684\n",
      "[1375]\ttraining's rmse: 0.0824025\tvalid_1's rmse: 0.0862663\n",
      "[1400]\ttraining's rmse: 0.0823907\tvalid_1's rmse: 0.0862633\n",
      "[1425]\ttraining's rmse: 0.0823789\tvalid_1's rmse: 0.0862621\n",
      "[1450]\ttraining's rmse: 0.0823683\tvalid_1's rmse: 0.0862608\n",
      "[1475]\ttraining's rmse: 0.082358\tvalid_1's rmse: 0.0862591\n",
      "[1500]\ttraining's rmse: 0.0823486\tvalid_1's rmse: 0.0862566\n",
      "[1525]\ttraining's rmse: 0.0823388\tvalid_1's rmse: 0.0862554\n",
      "[1550]\ttraining's rmse: 0.082329\tvalid_1's rmse: 0.0862545\n",
      "[1575]\ttraining's rmse: 0.0823202\tvalid_1's rmse: 0.0862532\n",
      "[1600]\ttraining's rmse: 0.0823116\tvalid_1's rmse: 0.0862525\n",
      "[1625]\ttraining's rmse: 0.082301\tvalid_1's rmse: 0.0862506\n",
      "[1650]\ttraining's rmse: 0.0822942\tvalid_1's rmse: 0.0862497\n",
      "[1675]\ttraining's rmse: 0.082288\tvalid_1's rmse: 0.086249\n",
      "[1700]\ttraining's rmse: 0.0822821\tvalid_1's rmse: 0.0862481\n",
      "[1725]\ttraining's rmse: 0.0822755\tvalid_1's rmse: 0.086247\n",
      "[1750]\ttraining's rmse: 0.0822681\tvalid_1's rmse: 0.0862459\n",
      "[1775]\ttraining's rmse: 0.0822631\tvalid_1's rmse: 0.0862452\n",
      "[1800]\ttraining's rmse: 0.0822568\tvalid_1's rmse: 0.0862444\n",
      "[1825]\ttraining's rmse: 0.0822512\tvalid_1's rmse: 0.086244\n",
      "[1850]\ttraining's rmse: 0.0822461\tvalid_1's rmse: 0.0862432\n",
      "[1875]\ttraining's rmse: 0.082241\tvalid_1's rmse: 0.0862426\n",
      "[1900]\ttraining's rmse: 0.0822376\tvalid_1's rmse: 0.0862426\n",
      "[1925]\ttraining's rmse: 0.0822309\tvalid_1's rmse: 0.086242\n",
      "[1950]\ttraining's rmse: 0.0822275\tvalid_1's rmse: 0.0862413\n",
      "[1975]\ttraining's rmse: 0.0822246\tvalid_1's rmse: 0.0862407\n",
      "[2000]\ttraining's rmse: 0.0822195\tvalid_1's rmse: 0.0862402\n",
      "[2025]\ttraining's rmse: 0.0822157\tvalid_1's rmse: 0.0862397\n",
      "[2050]\ttraining's rmse: 0.0822119\tvalid_1's rmse: 0.0862395\n",
      "[2075]\ttraining's rmse: 0.0822086\tvalid_1's rmse: 0.0862386\n",
      "[2100]\ttraining's rmse: 0.0822041\tvalid_1's rmse: 0.0862377\n",
      "[2125]\ttraining's rmse: 0.0821996\tvalid_1's rmse: 0.086237\n",
      "[2150]\ttraining's rmse: 0.0821943\tvalid_1's rmse: 0.086237\n",
      "[2175]\ttraining's rmse: 0.0821899\tvalid_1's rmse: 0.0862369\n",
      "[2200]\ttraining's rmse: 0.0821873\tvalid_1's rmse: 0.0862366\n",
      "[2225]\ttraining's rmse: 0.0821827\tvalid_1's rmse: 0.0862361\n",
      "[2250]\ttraining's rmse: 0.0821804\tvalid_1's rmse: 0.086236\n",
      "[2275]\ttraining's rmse: 0.0821756\tvalid_1's rmse: 0.0862355\n",
      "[2300]\ttraining's rmse: 0.0821726\tvalid_1's rmse: 0.0862351\n",
      "[2325]\ttraining's rmse: 0.0821701\tvalid_1's rmse: 0.0862346\n",
      "[2350]\ttraining's rmse: 0.0821668\tvalid_1's rmse: 0.0862344\n",
      "[2375]\ttraining's rmse: 0.0821648\tvalid_1's rmse: 0.0862342\n",
      "[2400]\ttraining's rmse: 0.0821616\tvalid_1's rmse: 0.0862345\n",
      "[2425]\ttraining's rmse: 0.0821595\tvalid_1's rmse: 0.0862341\n",
      "Early stopping, best iteration is:\n",
      "[2385]\ttraining's rmse: 0.0821629\tvalid_1's rmse: 0.086234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0868574\tvalid_1's rmse: 0.0833483\n",
      "[50]\ttraining's rmse: 0.086735\tvalid_1's rmse: 0.0832977\n",
      "[75]\ttraining's rmse: 0.0866009\tvalid_1's rmse: 0.0832451\n",
      "[100]\ttraining's rmse: 0.0864824\tvalid_1's rmse: 0.0832003\n",
      "[125]\ttraining's rmse: 0.0863627\tvalid_1's rmse: 0.0831578\n",
      "[150]\ttraining's rmse: 0.0862535\tvalid_1's rmse: 0.0831177\n",
      "[175]\ttraining's rmse: 0.0861584\tvalid_1's rmse: 0.0830831\n",
      "[200]\ttraining's rmse: 0.0860554\tvalid_1's rmse: 0.0830495\n",
      "[225]\ttraining's rmse: 0.085956\tvalid_1's rmse: 0.0830154\n",
      "[250]\ttraining's rmse: 0.0858733\tvalid_1's rmse: 0.0829865\n",
      "[275]\ttraining's rmse: 0.0857997\tvalid_1's rmse: 0.0829618\n",
      "[300]\ttraining's rmse: 0.0857222\tvalid_1's rmse: 0.082939\n",
      "[325]\ttraining's rmse: 0.0856456\tvalid_1's rmse: 0.082916\n",
      "[350]\ttraining's rmse: 0.0855704\tvalid_1's rmse: 0.0828947\n",
      "[375]\ttraining's rmse: 0.0855095\tvalid_1's rmse: 0.0828803\n",
      "[400]\ttraining's rmse: 0.0854445\tvalid_1's rmse: 0.0828675\n",
      "[425]\ttraining's rmse: 0.0853841\tvalid_1's rmse: 0.0828548\n",
      "[450]\ttraining's rmse: 0.0853289\tvalid_1's rmse: 0.082839\n",
      "[475]\ttraining's rmse: 0.0852778\tvalid_1's rmse: 0.082825\n",
      "[500]\ttraining's rmse: 0.0852342\tvalid_1's rmse: 0.0828117\n",
      "[525]\ttraining's rmse: 0.0851759\tvalid_1's rmse: 0.0827992\n",
      "[550]\ttraining's rmse: 0.0851225\tvalid_1's rmse: 0.0827868\n",
      "[575]\ttraining's rmse: 0.0850736\tvalid_1's rmse: 0.0827788\n",
      "[600]\ttraining's rmse: 0.0850279\tvalid_1's rmse: 0.0827694\n",
      "[625]\ttraining's rmse: 0.0849898\tvalid_1's rmse: 0.0827602\n",
      "[650]\ttraining's rmse: 0.0849446\tvalid_1's rmse: 0.0827549\n",
      "[675]\ttraining's rmse: 0.0848974\tvalid_1's rmse: 0.0827527\n",
      "[700]\ttraining's rmse: 0.0848571\tvalid_1's rmse: 0.0827481\n",
      "[725]\ttraining's rmse: 0.0848184\tvalid_1's rmse: 0.0827508\n",
      "[750]\ttraining's rmse: 0.0847823\tvalid_1's rmse: 0.082752\n",
      "[775]\ttraining's rmse: 0.0847518\tvalid_1's rmse: 0.0827467\n",
      "[800]\ttraining's rmse: 0.0847116\tvalid_1's rmse: 0.0827412\n",
      "[825]\ttraining's rmse: 0.0846816\tvalid_1's rmse: 0.0827357\n",
      "[850]\ttraining's rmse: 0.0846475\tvalid_1's rmse: 0.0827354\n",
      "[875]\ttraining's rmse: 0.0846199\tvalid_1's rmse: 0.0827354\n",
      "[900]\ttraining's rmse: 0.0845877\tvalid_1's rmse: 0.0827365\n",
      "[925]\ttraining's rmse: 0.0845561\tvalid_1's rmse: 0.0827383\n",
      "Early stopping, best iteration is:\n",
      "[890]\ttraining's rmse: 0.0846005\tvalid_1's rmse: 0.0827329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0803719\tvalid_1's rmse: 0.0831296\n",
      "[50]\ttraining's rmse: 0.080255\tvalid_1's rmse: 0.0830743\n",
      "[75]\ttraining's rmse: 0.0801361\tvalid_1's rmse: 0.0830211\n",
      "[100]\ttraining's rmse: 0.0800283\tvalid_1's rmse: 0.0829728\n",
      "[125]\ttraining's rmse: 0.0799149\tvalid_1's rmse: 0.0829258\n",
      "[150]\ttraining's rmse: 0.0798148\tvalid_1's rmse: 0.0828824\n",
      "[175]\ttraining's rmse: 0.0797297\tvalid_1's rmse: 0.0828427\n",
      "[200]\ttraining's rmse: 0.0796406\tvalid_1's rmse: 0.0828047\n",
      "[225]\ttraining's rmse: 0.0795537\tvalid_1's rmse: 0.0827705\n",
      "[250]\ttraining's rmse: 0.0794827\tvalid_1's rmse: 0.0827379\n",
      "[275]\ttraining's rmse: 0.0794142\tvalid_1's rmse: 0.0827084\n",
      "[300]\ttraining's rmse: 0.0793429\tvalid_1's rmse: 0.0826795\n",
      "[325]\ttraining's rmse: 0.0792751\tvalid_1's rmse: 0.0826517\n",
      "[350]\ttraining's rmse: 0.0792127\tvalid_1's rmse: 0.0826272\n",
      "[375]\ttraining's rmse: 0.0791577\tvalid_1's rmse: 0.082603\n",
      "[400]\ttraining's rmse: 0.0790986\tvalid_1's rmse: 0.0825795\n",
      "[425]\ttraining's rmse: 0.0790474\tvalid_1's rmse: 0.082559\n",
      "[450]\ttraining's rmse: 0.0789987\tvalid_1's rmse: 0.0825383\n",
      "[475]\ttraining's rmse: 0.0789576\tvalid_1's rmse: 0.0825201\n",
      "[500]\ttraining's rmse: 0.0789181\tvalid_1's rmse: 0.0825018\n",
      "[525]\ttraining's rmse: 0.0788713\tvalid_1's rmse: 0.0824856\n",
      "[550]\ttraining's rmse: 0.0788251\tvalid_1's rmse: 0.08247\n",
      "[575]\ttraining's rmse: 0.0787826\tvalid_1's rmse: 0.0824563\n",
      "[600]\ttraining's rmse: 0.0787426\tvalid_1's rmse: 0.0824429\n",
      "[625]\ttraining's rmse: 0.0787109\tvalid_1's rmse: 0.0824292\n",
      "[650]\ttraining's rmse: 0.0786746\tvalid_1's rmse: 0.0824156\n",
      "[675]\ttraining's rmse: 0.0786372\tvalid_1's rmse: 0.0824013\n",
      "[700]\ttraining's rmse: 0.0786025\tvalid_1's rmse: 0.0823895\n",
      "[725]\ttraining's rmse: 0.0785712\tvalid_1's rmse: 0.0823799\n",
      "[750]\ttraining's rmse: 0.0785396\tvalid_1's rmse: 0.0823692\n",
      "[775]\ttraining's rmse: 0.0785156\tvalid_1's rmse: 0.0823593\n",
      "[800]\ttraining's rmse: 0.0784844\tvalid_1's rmse: 0.0823508\n",
      "[825]\ttraining's rmse: 0.0784567\tvalid_1's rmse: 0.0823409\n",
      "[850]\ttraining's rmse: 0.0784276\tvalid_1's rmse: 0.0823333\n",
      "[875]\ttraining's rmse: 0.0784025\tvalid_1's rmse: 0.0823242\n",
      "[900]\ttraining's rmse: 0.0783753\tvalid_1's rmse: 0.0823166\n",
      "[925]\ttraining's rmse: 0.0783516\tvalid_1's rmse: 0.0823094\n",
      "[950]\ttraining's rmse: 0.0783286\tvalid_1's rmse: 0.082303\n",
      "[975]\ttraining's rmse: 0.0783054\tvalid_1's rmse: 0.0822968\n",
      "[1000]\ttraining's rmse: 0.0782872\tvalid_1's rmse: 0.0822906\n",
      "[1025]\ttraining's rmse: 0.0782647\tvalid_1's rmse: 0.0822826\n",
      "[1050]\ttraining's rmse: 0.0782447\tvalid_1's rmse: 0.082276\n",
      "[1075]\ttraining's rmse: 0.078229\tvalid_1's rmse: 0.0822722\n",
      "[1100]\ttraining's rmse: 0.0782131\tvalid_1's rmse: 0.0822664\n",
      "[1125]\ttraining's rmse: 0.0781962\tvalid_1's rmse: 0.0822584\n",
      "[1150]\ttraining's rmse: 0.0781785\tvalid_1's rmse: 0.0822543\n",
      "[1175]\ttraining's rmse: 0.0781655\tvalid_1's rmse: 0.0822507\n",
      "[1200]\ttraining's rmse: 0.0781491\tvalid_1's rmse: 0.0822447\n",
      "[1225]\ttraining's rmse: 0.078135\tvalid_1's rmse: 0.0822403\n",
      "[1250]\ttraining's rmse: 0.0781231\tvalid_1's rmse: 0.0822367\n",
      "[1275]\ttraining's rmse: 0.0781096\tvalid_1's rmse: 0.0822332\n",
      "[1300]\ttraining's rmse: 0.0780971\tvalid_1's rmse: 0.082229\n",
      "[1325]\ttraining's rmse: 0.0780833\tvalid_1's rmse: 0.0822247\n",
      "[1350]\ttraining's rmse: 0.0780724\tvalid_1's rmse: 0.0822222\n",
      "[1375]\ttraining's rmse: 0.0780604\tvalid_1's rmse: 0.0822189\n",
      "[1400]\ttraining's rmse: 0.0780501\tvalid_1's rmse: 0.0822154\n",
      "[1425]\ttraining's rmse: 0.0780375\tvalid_1's rmse: 0.0822127\n",
      "[1450]\ttraining's rmse: 0.0780256\tvalid_1's rmse: 0.0822093\n",
      "[1475]\ttraining's rmse: 0.0780165\tvalid_1's rmse: 0.0822053\n",
      "[1500]\ttraining's rmse: 0.078008\tvalid_1's rmse: 0.0822026\n",
      "[1525]\ttraining's rmse: 0.0779991\tvalid_1's rmse: 0.0822\n",
      "[1550]\ttraining's rmse: 0.0779917\tvalid_1's rmse: 0.0821987\n",
      "[1575]\ttraining's rmse: 0.0779849\tvalid_1's rmse: 0.0821962\n",
      "[1600]\ttraining's rmse: 0.0779764\tvalid_1's rmse: 0.0821936\n",
      "[1625]\ttraining's rmse: 0.0779697\tvalid_1's rmse: 0.0821904\n",
      "[1650]\ttraining's rmse: 0.0779636\tvalid_1's rmse: 0.0821871\n",
      "[1675]\ttraining's rmse: 0.0779585\tvalid_1's rmse: 0.0821845\n",
      "[1700]\ttraining's rmse: 0.0779535\tvalid_1's rmse: 0.0821825\n",
      "[1725]\ttraining's rmse: 0.0779478\tvalid_1's rmse: 0.0821804\n",
      "[1750]\ttraining's rmse: 0.0779423\tvalid_1's rmse: 0.0821784\n",
      "[1775]\ttraining's rmse: 0.077935\tvalid_1's rmse: 0.0821768\n",
      "[1800]\ttraining's rmse: 0.0779302\tvalid_1's rmse: 0.0821762\n",
      "[1825]\ttraining's rmse: 0.0779267\tvalid_1's rmse: 0.082175\n",
      "[1850]\ttraining's rmse: 0.0779207\tvalid_1's rmse: 0.0821733\n",
      "[1875]\ttraining's rmse: 0.0779149\tvalid_1's rmse: 0.0821726\n",
      "[1900]\ttraining's rmse: 0.07791\tvalid_1's rmse: 0.0821714\n",
      "[1925]\ttraining's rmse: 0.0779064\tvalid_1's rmse: 0.0821702\n",
      "[1950]\ttraining's rmse: 0.0779027\tvalid_1's rmse: 0.0821683\n",
      "[1975]\ttraining's rmse: 0.0778995\tvalid_1's rmse: 0.0821682\n",
      "[2000]\ttraining's rmse: 0.0778948\tvalid_1's rmse: 0.0821668\n",
      "[2025]\ttraining's rmse: 0.0778918\tvalid_1's rmse: 0.0821649\n",
      "[2050]\ttraining's rmse: 0.0778881\tvalid_1's rmse: 0.0821627\n",
      "[2075]\ttraining's rmse: 0.0778849\tvalid_1's rmse: 0.0821611\n",
      "[2100]\ttraining's rmse: 0.077882\tvalid_1's rmse: 0.0821599\n",
      "[2125]\ttraining's rmse: 0.07788\tvalid_1's rmse: 0.0821598\n",
      "[2150]\ttraining's rmse: 0.077877\tvalid_1's rmse: 0.0821598\n",
      "Early stopping, best iteration is:\n",
      "[2118]\ttraining's rmse: 0.0778804\tvalid_1's rmse: 0.0821597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0807109\tvalid_1's rmse: 0.0824634\n",
      "[50]\ttraining's rmse: 0.0805965\tvalid_1's rmse: 0.0824074\n",
      "[75]\ttraining's rmse: 0.0804809\tvalid_1's rmse: 0.0823517\n",
      "[100]\ttraining's rmse: 0.0803756\tvalid_1's rmse: 0.0823014\n",
      "[125]\ttraining's rmse: 0.0802656\tvalid_1's rmse: 0.0822508\n",
      "[150]\ttraining's rmse: 0.0801684\tvalid_1's rmse: 0.0822057\n",
      "[175]\ttraining's rmse: 0.0800876\tvalid_1's rmse: 0.0821678\n",
      "[200]\ttraining's rmse: 0.0799966\tvalid_1's rmse: 0.0821288\n",
      "[225]\ttraining's rmse: 0.0799138\tvalid_1's rmse: 0.0820936\n",
      "[250]\ttraining's rmse: 0.0798424\tvalid_1's rmse: 0.0820606\n",
      "[275]\ttraining's rmse: 0.0797731\tvalid_1's rmse: 0.0820301\n",
      "[300]\ttraining's rmse: 0.0797038\tvalid_1's rmse: 0.0820021\n",
      "[325]\ttraining's rmse: 0.0796351\tvalid_1's rmse: 0.0819742\n",
      "[350]\ttraining's rmse: 0.0795668\tvalid_1's rmse: 0.0819487\n",
      "[375]\ttraining's rmse: 0.0795111\tvalid_1's rmse: 0.0819265\n",
      "[400]\ttraining's rmse: 0.0794534\tvalid_1's rmse: 0.0819056\n",
      "[425]\ttraining's rmse: 0.0793998\tvalid_1's rmse: 0.081886\n",
      "[450]\ttraining's rmse: 0.0793496\tvalid_1's rmse: 0.0818661\n",
      "[475]\ttraining's rmse: 0.0793042\tvalid_1's rmse: 0.0818493\n",
      "[500]\ttraining's rmse: 0.0792632\tvalid_1's rmse: 0.0818325\n",
      "[525]\ttraining's rmse: 0.0792121\tvalid_1's rmse: 0.0818159\n",
      "[550]\ttraining's rmse: 0.0791644\tvalid_1's rmse: 0.0817987\n",
      "[575]\ttraining's rmse: 0.0791198\tvalid_1's rmse: 0.0817843\n",
      "[600]\ttraining's rmse: 0.0790781\tvalid_1's rmse: 0.0817712\n",
      "[625]\ttraining's rmse: 0.0790446\tvalid_1's rmse: 0.081759\n",
      "[650]\ttraining's rmse: 0.0790066\tvalid_1's rmse: 0.081747\n",
      "[675]\ttraining's rmse: 0.0789666\tvalid_1's rmse: 0.081736\n",
      "[700]\ttraining's rmse: 0.0789299\tvalid_1's rmse: 0.0817249\n",
      "[725]\ttraining's rmse: 0.0788977\tvalid_1's rmse: 0.0817159\n",
      "[750]\ttraining's rmse: 0.078865\tvalid_1's rmse: 0.0817054\n",
      "[775]\ttraining's rmse: 0.0788388\tvalid_1's rmse: 0.0816976\n",
      "[800]\ttraining's rmse: 0.0788066\tvalid_1's rmse: 0.081689\n",
      "[825]\ttraining's rmse: 0.0787784\tvalid_1's rmse: 0.0816807\n",
      "[850]\ttraining's rmse: 0.0787504\tvalid_1's rmse: 0.0816737\n",
      "[875]\ttraining's rmse: 0.0787265\tvalid_1's rmse: 0.0816671\n",
      "[900]\ttraining's rmse: 0.078701\tvalid_1's rmse: 0.0816606\n",
      "[925]\ttraining's rmse: 0.0786774\tvalid_1's rmse: 0.0816557\n",
      "[950]\ttraining's rmse: 0.0786565\tvalid_1's rmse: 0.0816503\n",
      "[975]\ttraining's rmse: 0.0786365\tvalid_1's rmse: 0.0816452\n",
      "[1000]\ttraining's rmse: 0.0786167\tvalid_1's rmse: 0.0816396\n",
      "[1025]\ttraining's rmse: 0.0785937\tvalid_1's rmse: 0.0816352\n",
      "[1050]\ttraining's rmse: 0.0785753\tvalid_1's rmse: 0.0816309\n",
      "[1075]\ttraining's rmse: 0.0785549\tvalid_1's rmse: 0.0816264\n",
      "[1100]\ttraining's rmse: 0.0785397\tvalid_1's rmse: 0.0816225\n",
      "[1125]\ttraining's rmse: 0.0785224\tvalid_1's rmse: 0.0816188\n",
      "[1150]\ttraining's rmse: 0.0785063\tvalid_1's rmse: 0.0816149\n",
      "[1175]\ttraining's rmse: 0.0784908\tvalid_1's rmse: 0.0816114\n",
      "[1200]\ttraining's rmse: 0.0784749\tvalid_1's rmse: 0.0816077\n",
      "[1225]\ttraining's rmse: 0.0784617\tvalid_1's rmse: 0.081605\n",
      "[1250]\ttraining's rmse: 0.0784486\tvalid_1's rmse: 0.0816019\n",
      "[1275]\ttraining's rmse: 0.078432\tvalid_1's rmse: 0.0815998\n",
      "[1300]\ttraining's rmse: 0.0784202\tvalid_1's rmse: 0.0815969\n",
      "[1325]\ttraining's rmse: 0.078406\tvalid_1's rmse: 0.0815948\n",
      "[1350]\ttraining's rmse: 0.0783925\tvalid_1's rmse: 0.0815923\n",
      "[1375]\ttraining's rmse: 0.0783813\tvalid_1's rmse: 0.0815909\n",
      "[1400]\ttraining's rmse: 0.0783731\tvalid_1's rmse: 0.0815888\n",
      "[1425]\ttraining's rmse: 0.0783644\tvalid_1's rmse: 0.0815875\n",
      "[1450]\ttraining's rmse: 0.0783529\tvalid_1's rmse: 0.0815855\n",
      "[1475]\ttraining's rmse: 0.0783422\tvalid_1's rmse: 0.0815837\n",
      "[1500]\ttraining's rmse: 0.0783346\tvalid_1's rmse: 0.081582\n",
      "[1525]\ttraining's rmse: 0.0783256\tvalid_1's rmse: 0.0815808\n",
      "[1550]\ttraining's rmse: 0.078318\tvalid_1's rmse: 0.0815795\n",
      "[1575]\ttraining's rmse: 0.0783111\tvalid_1's rmse: 0.0815781\n",
      "[1600]\ttraining's rmse: 0.0783034\tvalid_1's rmse: 0.0815775\n",
      "[1625]\ttraining's rmse: 0.0782967\tvalid_1's rmse: 0.0815765\n",
      "[1650]\ttraining's rmse: 0.078289\tvalid_1's rmse: 0.0815755\n",
      "[1675]\ttraining's rmse: 0.0782835\tvalid_1's rmse: 0.0815743\n",
      "[1700]\ttraining's rmse: 0.0782775\tvalid_1's rmse: 0.0815733\n",
      "[1725]\ttraining's rmse: 0.0782727\tvalid_1's rmse: 0.0815721\n",
      "[1750]\ttraining's rmse: 0.0782644\tvalid_1's rmse: 0.0815709\n",
      "[1775]\ttraining's rmse: 0.0782577\tvalid_1's rmse: 0.0815702\n",
      "[1800]\ttraining's rmse: 0.078252\tvalid_1's rmse: 0.0815692\n",
      "[1825]\ttraining's rmse: 0.0782468\tvalid_1's rmse: 0.0815686\n",
      "[1850]\ttraining's rmse: 0.0782429\tvalid_1's rmse: 0.0815683\n",
      "[1875]\ttraining's rmse: 0.0782395\tvalid_1's rmse: 0.0815677\n",
      "[1900]\ttraining's rmse: 0.0782351\tvalid_1's rmse: 0.0815676\n",
      "[1925]\ttraining's rmse: 0.0782318\tvalid_1's rmse: 0.0815672\n",
      "[1950]\ttraining's rmse: 0.0782285\tvalid_1's rmse: 0.0815667\n",
      "[1975]\ttraining's rmse: 0.0782247\tvalid_1's rmse: 0.081566\n",
      "[2000]\ttraining's rmse: 0.0782205\tvalid_1's rmse: 0.0815656\n",
      "[2025]\ttraining's rmse: 0.0782175\tvalid_1's rmse: 0.0815651\n",
      "[2050]\ttraining's rmse: 0.0782134\tvalid_1's rmse: 0.081565\n",
      "[2075]\ttraining's rmse: 0.0782099\tvalid_1's rmse: 0.0815648\n",
      "[2100]\ttraining's rmse: 0.0782077\tvalid_1's rmse: 0.0815645\n",
      "[2125]\ttraining's rmse: 0.0782043\tvalid_1's rmse: 0.081564\n",
      "[2150]\ttraining's rmse: 0.0782\tvalid_1's rmse: 0.0815638\n",
      "[2175]\ttraining's rmse: 0.0781966\tvalid_1's rmse: 0.0815637\n",
      "[2200]\ttraining's rmse: 0.0781921\tvalid_1's rmse: 0.0815635\n",
      "[2225]\ttraining's rmse: 0.0781887\tvalid_1's rmse: 0.0815632\n",
      "[2250]\ttraining's rmse: 0.0781847\tvalid_1's rmse: 0.0815628\n",
      "[2275]\ttraining's rmse: 0.0781819\tvalid_1's rmse: 0.0815625\n",
      "[2300]\ttraining's rmse: 0.0781794\tvalid_1's rmse: 0.0815622\n",
      "[2325]\ttraining's rmse: 0.0781757\tvalid_1's rmse: 0.081562\n",
      "[2350]\ttraining's rmse: 0.0781733\tvalid_1's rmse: 0.0815613\n",
      "[2375]\ttraining's rmse: 0.0781703\tvalid_1's rmse: 0.0815611\n",
      "[2400]\ttraining's rmse: 0.0781667\tvalid_1's rmse: 0.0815611\n",
      "[2425]\ttraining's rmse: 0.0781637\tvalid_1's rmse: 0.0815609\n",
      "[2450]\ttraining's rmse: 0.0781613\tvalid_1's rmse: 0.0815605\n",
      "[2475]\ttraining's rmse: 0.0781595\tvalid_1's rmse: 0.0815606\n",
      "Early stopping, best iteration is:\n",
      "[2442]\ttraining's rmse: 0.0781618\tvalid_1's rmse: 0.0815605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0826836\tvalid_1's rmse: 0.0784511\n",
      "[50]\ttraining's rmse: 0.0825679\tvalid_1's rmse: 0.0783997\n",
      "[75]\ttraining's rmse: 0.082452\tvalid_1's rmse: 0.0783536\n",
      "[100]\ttraining's rmse: 0.0823509\tvalid_1's rmse: 0.078311\n",
      "[125]\ttraining's rmse: 0.0822451\tvalid_1's rmse: 0.0782689\n",
      "[150]\ttraining's rmse: 0.0821449\tvalid_1's rmse: 0.0782311\n",
      "[175]\ttraining's rmse: 0.0820643\tvalid_1's rmse: 0.0782002\n",
      "[200]\ttraining's rmse: 0.0819797\tvalid_1's rmse: 0.0781692\n",
      "[225]\ttraining's rmse: 0.081898\tvalid_1's rmse: 0.0781448\n",
      "[250]\ttraining's rmse: 0.0818274\tvalid_1's rmse: 0.0781198\n",
      "[275]\ttraining's rmse: 0.0817607\tvalid_1's rmse: 0.0780942\n",
      "[300]\ttraining's rmse: 0.0816962\tvalid_1's rmse: 0.078078\n",
      "[325]\ttraining's rmse: 0.0816322\tvalid_1's rmse: 0.0780563\n",
      "[350]\ttraining's rmse: 0.0815694\tvalid_1's rmse: 0.0780372\n",
      "[375]\ttraining's rmse: 0.0815156\tvalid_1's rmse: 0.078019\n",
      "[400]\ttraining's rmse: 0.0814583\tvalid_1's rmse: 0.0780022\n",
      "[425]\ttraining's rmse: 0.0814068\tvalid_1's rmse: 0.0779875\n",
      "[450]\ttraining's rmse: 0.0813593\tvalid_1's rmse: 0.077972\n",
      "[475]\ttraining's rmse: 0.0813142\tvalid_1's rmse: 0.0779635\n",
      "[500]\ttraining's rmse: 0.0812769\tvalid_1's rmse: 0.0779558\n",
      "[525]\ttraining's rmse: 0.0812278\tvalid_1's rmse: 0.0779486\n",
      "[550]\ttraining's rmse: 0.0811811\tvalid_1's rmse: 0.0779359\n",
      "[575]\ttraining's rmse: 0.081139\tvalid_1's rmse: 0.0779249\n",
      "[600]\ttraining's rmse: 0.0810977\tvalid_1's rmse: 0.0779264\n",
      "[625]\ttraining's rmse: 0.0810653\tvalid_1's rmse: 0.0779292\n",
      "[650]\ttraining's rmse: 0.0810245\tvalid_1's rmse: 0.0779254\n",
      "[675]\ttraining's rmse: 0.0809834\tvalid_1's rmse: 0.0779174\n",
      "[700]\ttraining's rmse: 0.080946\tvalid_1's rmse: 0.0779158\n",
      "[725]\ttraining's rmse: 0.080912\tvalid_1's rmse: 0.0779086\n",
      "[750]\ttraining's rmse: 0.0808798\tvalid_1's rmse: 0.0779049\n",
      "[775]\ttraining's rmse: 0.0808536\tvalid_1's rmse: 0.0778985\n",
      "[800]\ttraining's rmse: 0.0808205\tvalid_1's rmse: 0.0778977\n",
      "[825]\ttraining's rmse: 0.0807924\tvalid_1's rmse: 0.0779067\n",
      "Early stopping, best iteration is:\n",
      "[797]\ttraining's rmse: 0.0808243\tvalid_1's rmse: 0.0778931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0862732\tvalid_1's rmse: 0.0875533\n",
      "[50]\ttraining's rmse: 0.0860912\tvalid_1's rmse: 0.0875032\n",
      "[75]\ttraining's rmse: 0.0859058\tvalid_1's rmse: 0.0874519\n",
      "[100]\ttraining's rmse: 0.0857412\tvalid_1's rmse: 0.0874062\n",
      "[125]\ttraining's rmse: 0.085576\tvalid_1's rmse: 0.0873614\n",
      "[150]\ttraining's rmse: 0.0854273\tvalid_1's rmse: 0.0873202\n",
      "[175]\ttraining's rmse: 0.0852983\tvalid_1's rmse: 0.0872853\n",
      "[200]\ttraining's rmse: 0.0851671\tvalid_1's rmse: 0.0872491\n",
      "[225]\ttraining's rmse: 0.0850402\tvalid_1's rmse: 0.087215\n",
      "[250]\ttraining's rmse: 0.0849322\tvalid_1's rmse: 0.0871841\n",
      "[275]\ttraining's rmse: 0.0848325\tvalid_1's rmse: 0.0871552\n",
      "[300]\ttraining's rmse: 0.0847332\tvalid_1's rmse: 0.08713\n",
      "[325]\ttraining's rmse: 0.084635\tvalid_1's rmse: 0.0871056\n",
      "[350]\ttraining's rmse: 0.0845414\tvalid_1's rmse: 0.0870825\n",
      "[375]\ttraining's rmse: 0.084461\tvalid_1's rmse: 0.087063\n",
      "[400]\ttraining's rmse: 0.084374\tvalid_1's rmse: 0.0870422\n",
      "[425]\ttraining's rmse: 0.0842983\tvalid_1's rmse: 0.0870234\n",
      "[450]\ttraining's rmse: 0.0842299\tvalid_1's rmse: 0.087006\n",
      "[475]\ttraining's rmse: 0.0841636\tvalid_1's rmse: 0.0869896\n",
      "[500]\ttraining's rmse: 0.0841095\tvalid_1's rmse: 0.0869738\n",
      "[525]\ttraining's rmse: 0.0840409\tvalid_1's rmse: 0.086957\n",
      "[550]\ttraining's rmse: 0.0839817\tvalid_1's rmse: 0.086943\n",
      "[575]\ttraining's rmse: 0.0839231\tvalid_1's rmse: 0.0869291\n",
      "[600]\ttraining's rmse: 0.0838677\tvalid_1's rmse: 0.0869169\n",
      "[625]\ttraining's rmse: 0.083824\tvalid_1's rmse: 0.0869044\n",
      "[650]\ttraining's rmse: 0.0837723\tvalid_1's rmse: 0.0868926\n",
      "[675]\ttraining's rmse: 0.0837211\tvalid_1's rmse: 0.0868813\n",
      "[700]\ttraining's rmse: 0.0836758\tvalid_1's rmse: 0.086872\n",
      "[725]\ttraining's rmse: 0.0836352\tvalid_1's rmse: 0.086863\n",
      "[750]\ttraining's rmse: 0.0835939\tvalid_1's rmse: 0.086854\n",
      "[775]\ttraining's rmse: 0.0835611\tvalid_1's rmse: 0.0868451\n",
      "[800]\ttraining's rmse: 0.0835216\tvalid_1's rmse: 0.0868365\n",
      "[825]\ttraining's rmse: 0.0834891\tvalid_1's rmse: 0.086829\n",
      "[850]\ttraining's rmse: 0.083451\tvalid_1's rmse: 0.0868213\n",
      "[875]\ttraining's rmse: 0.0834181\tvalid_1's rmse: 0.0868142\n",
      "[900]\ttraining's rmse: 0.0833849\tvalid_1's rmse: 0.0868082\n",
      "[925]\ttraining's rmse: 0.0833556\tvalid_1's rmse: 0.0868013\n",
      "[950]\ttraining's rmse: 0.0833287\tvalid_1's rmse: 0.086795\n",
      "[975]\ttraining's rmse: 0.0833011\tvalid_1's rmse: 0.0867875\n",
      "[1000]\ttraining's rmse: 0.0832712\tvalid_1's rmse: 0.0867819\n",
      "[1025]\ttraining's rmse: 0.0832439\tvalid_1's rmse: 0.086777\n",
      "[1050]\ttraining's rmse: 0.0832164\tvalid_1's rmse: 0.0867722\n",
      "[1075]\ttraining's rmse: 0.0831922\tvalid_1's rmse: 0.0867678\n",
      "[1100]\ttraining's rmse: 0.0831723\tvalid_1's rmse: 0.0867633\n",
      "[1125]\ttraining's rmse: 0.0831539\tvalid_1's rmse: 0.0867586\n",
      "[1150]\ttraining's rmse: 0.0831326\tvalid_1's rmse: 0.0867542\n",
      "[1175]\ttraining's rmse: 0.0831111\tvalid_1's rmse: 0.0867504\n",
      "[1200]\ttraining's rmse: 0.0830927\tvalid_1's rmse: 0.0867454\n",
      "[1225]\ttraining's rmse: 0.0830745\tvalid_1's rmse: 0.0867415\n",
      "[1250]\ttraining's rmse: 0.0830586\tvalid_1's rmse: 0.0867378\n",
      "[1275]\ttraining's rmse: 0.0830388\tvalid_1's rmse: 0.0867343\n",
      "[1300]\ttraining's rmse: 0.0830236\tvalid_1's rmse: 0.0867311\n",
      "[1325]\ttraining's rmse: 0.0830087\tvalid_1's rmse: 0.0867282\n",
      "[1350]\ttraining's rmse: 0.0829929\tvalid_1's rmse: 0.0867243\n",
      "[1375]\ttraining's rmse: 0.0829763\tvalid_1's rmse: 0.0867204\n",
      "[1400]\ttraining's rmse: 0.0829614\tvalid_1's rmse: 0.0867157\n",
      "[1425]\ttraining's rmse: 0.0829491\tvalid_1's rmse: 0.0867132\n",
      "[1450]\ttraining's rmse: 0.0829368\tvalid_1's rmse: 0.0867099\n",
      "[1475]\ttraining's rmse: 0.0829271\tvalid_1's rmse: 0.0867072\n",
      "[1500]\ttraining's rmse: 0.0829158\tvalid_1's rmse: 0.0867055\n",
      "[1525]\ttraining's rmse: 0.0829053\tvalid_1's rmse: 0.0867017\n",
      "[1550]\ttraining's rmse: 0.0828937\tvalid_1's rmse: 0.0867002\n",
      "[1575]\ttraining's rmse: 0.0828822\tvalid_1's rmse: 0.0866978\n",
      "[1600]\ttraining's rmse: 0.0828718\tvalid_1's rmse: 0.0866965\n",
      "[1625]\ttraining's rmse: 0.0828631\tvalid_1's rmse: 0.0866931\n",
      "[1650]\ttraining's rmse: 0.0828546\tvalid_1's rmse: 0.0866919\n",
      "[1675]\ttraining's rmse: 0.0828485\tvalid_1's rmse: 0.0866908\n",
      "[1700]\ttraining's rmse: 0.0828419\tvalid_1's rmse: 0.0866889\n",
      "[1725]\ttraining's rmse: 0.082835\tvalid_1's rmse: 0.0866876\n",
      "[1750]\ttraining's rmse: 0.0828249\tvalid_1's rmse: 0.0866855\n",
      "[1775]\ttraining's rmse: 0.0828189\tvalid_1's rmse: 0.0866839\n",
      "[1800]\ttraining's rmse: 0.0828114\tvalid_1's rmse: 0.0866824\n",
      "[1825]\ttraining's rmse: 0.0828044\tvalid_1's rmse: 0.0866797\n",
      "[1850]\ttraining's rmse: 0.0827977\tvalid_1's rmse: 0.0866766\n",
      "[1875]\ttraining's rmse: 0.0827934\tvalid_1's rmse: 0.0866758\n",
      "[1900]\ttraining's rmse: 0.0827881\tvalid_1's rmse: 0.0866753\n",
      "[1925]\ttraining's rmse: 0.0827802\tvalid_1's rmse: 0.0866739\n",
      "[1950]\ttraining's rmse: 0.082776\tvalid_1's rmse: 0.0866724\n",
      "[1975]\ttraining's rmse: 0.0827707\tvalid_1's rmse: 0.08667\n",
      "[2000]\ttraining's rmse: 0.0827652\tvalid_1's rmse: 0.0866684\n",
      "[2025]\ttraining's rmse: 0.0827609\tvalid_1's rmse: 0.0866664\n",
      "[2050]\ttraining's rmse: 0.0827563\tvalid_1's rmse: 0.086665\n",
      "[2075]\ttraining's rmse: 0.0827521\tvalid_1's rmse: 0.0866634\n",
      "[2100]\ttraining's rmse: 0.0827496\tvalid_1's rmse: 0.0866627\n",
      "[2125]\ttraining's rmse: 0.0827459\tvalid_1's rmse: 0.0866621\n",
      "[2150]\ttraining's rmse: 0.0827425\tvalid_1's rmse: 0.0866619\n",
      "[2175]\ttraining's rmse: 0.0827403\tvalid_1's rmse: 0.0866611\n",
      "[2200]\ttraining's rmse: 0.0827363\tvalid_1's rmse: 0.0866594\n",
      "[2225]\ttraining's rmse: 0.0827338\tvalid_1's rmse: 0.0866584\n",
      "[2250]\ttraining's rmse: 0.0827302\tvalid_1's rmse: 0.0866572\n",
      "[2275]\ttraining's rmse: 0.0827269\tvalid_1's rmse: 0.0866563\n",
      "[2300]\ttraining's rmse: 0.0827249\tvalid_1's rmse: 0.0866556\n",
      "[2325]\ttraining's rmse: 0.0827209\tvalid_1's rmse: 0.0866552\n",
      "[2350]\ttraining's rmse: 0.0827184\tvalid_1's rmse: 0.0866549\n",
      "[2375]\ttraining's rmse: 0.0827149\tvalid_1's rmse: 0.0866541\n",
      "[2400]\ttraining's rmse: 0.0827124\tvalid_1's rmse: 0.0866531\n",
      "[2425]\ttraining's rmse: 0.0827092\tvalid_1's rmse: 0.0866516\n",
      "[2450]\ttraining's rmse: 0.0827066\tvalid_1's rmse: 0.0866515\n",
      "[2475]\ttraining's rmse: 0.0827038\tvalid_1's rmse: 0.0866511\n",
      "[2500]\ttraining's rmse: 0.082701\tvalid_1's rmse: 0.0866508\n",
      "[2525]\ttraining's rmse: 0.0826984\tvalid_1's rmse: 0.0866506\n",
      "[2550]\ttraining's rmse: 0.0826959\tvalid_1's rmse: 0.0866501\n",
      "[2575]\ttraining's rmse: 0.0826939\tvalid_1's rmse: 0.0866501\n",
      "[2600]\ttraining's rmse: 0.0826918\tvalid_1's rmse: 0.0866499\n",
      "[2625]\ttraining's rmse: 0.08269\tvalid_1's rmse: 0.0866484\n",
      "[2650]\ttraining's rmse: 0.0826873\tvalid_1's rmse: 0.0866472\n",
      "[2675]\ttraining's rmse: 0.0826862\tvalid_1's rmse: 0.0866469\n",
      "[2700]\ttraining's rmse: 0.0826854\tvalid_1's rmse: 0.086647\n",
      "[2725]\ttraining's rmse: 0.0826839\tvalid_1's rmse: 0.0866468\n",
      "[2750]\ttraining's rmse: 0.0826816\tvalid_1's rmse: 0.086646\n",
      "[2775]\ttraining's rmse: 0.0826802\tvalid_1's rmse: 0.0866463\n",
      "[2800]\ttraining's rmse: 0.0826786\tvalid_1's rmse: 0.0866457\n",
      "[2825]\ttraining's rmse: 0.082677\tvalid_1's rmse: 0.0866455\n",
      "[2850]\ttraining's rmse: 0.0826749\tvalid_1's rmse: 0.0866459\n",
      "[2875]\ttraining's rmse: 0.0826729\tvalid_1's rmse: 0.0866451\n",
      "[2900]\ttraining's rmse: 0.0826718\tvalid_1's rmse: 0.0866446\n",
      "[2925]\ttraining's rmse: 0.0826704\tvalid_1's rmse: 0.0866446\n",
      "[2950]\ttraining's rmse: 0.0826691\tvalid_1's rmse: 0.0866438\n",
      "[2975]\ttraining's rmse: 0.082667\tvalid_1's rmse: 0.0866435\n",
      "[3000]\ttraining's rmse: 0.0826651\tvalid_1's rmse: 0.0866427\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0826651\tvalid_1's rmse: 0.0866427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.086149\tvalid_1's rmse: 0.0878177\n",
      "[50]\ttraining's rmse: 0.0859859\tvalid_1's rmse: 0.0877615\n",
      "[75]\ttraining's rmse: 0.0858193\tvalid_1's rmse: 0.0877056\n",
      "[100]\ttraining's rmse: 0.0856693\tvalid_1's rmse: 0.0876553\n",
      "[125]\ttraining's rmse: 0.0855175\tvalid_1's rmse: 0.0876043\n",
      "[150]\ttraining's rmse: 0.0853822\tvalid_1's rmse: 0.087557\n",
      "[175]\ttraining's rmse: 0.0852651\tvalid_1's rmse: 0.0875192\n",
      "[200]\ttraining's rmse: 0.0851426\tvalid_1's rmse: 0.08748\n",
      "[225]\ttraining's rmse: 0.0850243\tvalid_1's rmse: 0.0874427\n",
      "[250]\ttraining's rmse: 0.0849219\tvalid_1's rmse: 0.0874082\n",
      "[275]\ttraining's rmse: 0.084829\tvalid_1's rmse: 0.0873783\n",
      "[300]\ttraining's rmse: 0.0847382\tvalid_1's rmse: 0.0873488\n",
      "[325]\ttraining's rmse: 0.0846469\tvalid_1's rmse: 0.0873198\n",
      "[350]\ttraining's rmse: 0.084556\tvalid_1's rmse: 0.0872936\n",
      "[375]\ttraining's rmse: 0.084485\tvalid_1's rmse: 0.0872715\n",
      "[400]\ttraining's rmse: 0.0844067\tvalid_1's rmse: 0.0872489\n",
      "[425]\ttraining's rmse: 0.0843377\tvalid_1's rmse: 0.0872266\n",
      "[450]\ttraining's rmse: 0.0842729\tvalid_1's rmse: 0.0872066\n",
      "[475]\ttraining's rmse: 0.0842133\tvalid_1's rmse: 0.0871879\n",
      "[500]\ttraining's rmse: 0.0841636\tvalid_1's rmse: 0.0871707\n",
      "[525]\ttraining's rmse: 0.0841003\tvalid_1's rmse: 0.0871532\n",
      "[550]\ttraining's rmse: 0.0840426\tvalid_1's rmse: 0.0871376\n",
      "[575]\ttraining's rmse: 0.0839883\tvalid_1's rmse: 0.0871233\n",
      "[600]\ttraining's rmse: 0.0839368\tvalid_1's rmse: 0.0871093\n",
      "[625]\ttraining's rmse: 0.0838933\tvalid_1's rmse: 0.0870961\n",
      "[650]\ttraining's rmse: 0.083845\tvalid_1's rmse: 0.0870821\n",
      "[675]\ttraining's rmse: 0.0837998\tvalid_1's rmse: 0.0870698\n",
      "[700]\ttraining's rmse: 0.0837577\tvalid_1's rmse: 0.0870585\n",
      "[725]\ttraining's rmse: 0.0837184\tvalid_1's rmse: 0.0870477\n",
      "[750]\ttraining's rmse: 0.083682\tvalid_1's rmse: 0.0870379\n",
      "[775]\ttraining's rmse: 0.0836479\tvalid_1's rmse: 0.0870266\n",
      "[800]\ttraining's rmse: 0.0836077\tvalid_1's rmse: 0.0870176\n",
      "[825]\ttraining's rmse: 0.0835756\tvalid_1's rmse: 0.0870079\n",
      "[850]\ttraining's rmse: 0.0835401\tvalid_1's rmse: 0.0869999\n",
      "[875]\ttraining's rmse: 0.0835089\tvalid_1's rmse: 0.0869927\n",
      "[900]\ttraining's rmse: 0.0834779\tvalid_1's rmse: 0.0869855\n",
      "[925]\ttraining's rmse: 0.083448\tvalid_1's rmse: 0.086979\n",
      "[950]\ttraining's rmse: 0.0834206\tvalid_1's rmse: 0.0869727\n",
      "[975]\ttraining's rmse: 0.0833955\tvalid_1's rmse: 0.0869665\n",
      "[1000]\ttraining's rmse: 0.0833693\tvalid_1's rmse: 0.0869616\n",
      "[1025]\ttraining's rmse: 0.0833428\tvalid_1's rmse: 0.0869561\n",
      "[1050]\ttraining's rmse: 0.0833202\tvalid_1's rmse: 0.0869508\n",
      "[1075]\ttraining's rmse: 0.0832967\tvalid_1's rmse: 0.0869471\n",
      "[1100]\ttraining's rmse: 0.0832761\tvalid_1's rmse: 0.0869423\n",
      "[1125]\ttraining's rmse: 0.0832553\tvalid_1's rmse: 0.0869377\n",
      "[1150]\ttraining's rmse: 0.0832347\tvalid_1's rmse: 0.0869335\n",
      "[1175]\ttraining's rmse: 0.0832159\tvalid_1's rmse: 0.0869301\n",
      "[1200]\ttraining's rmse: 0.0832\tvalid_1's rmse: 0.0869261\n",
      "[1225]\ttraining's rmse: 0.0831815\tvalid_1's rmse: 0.0869225\n",
      "[1250]\ttraining's rmse: 0.0831627\tvalid_1's rmse: 0.0869189\n",
      "[1275]\ttraining's rmse: 0.0831435\tvalid_1's rmse: 0.0869174\n",
      "[1300]\ttraining's rmse: 0.0831302\tvalid_1's rmse: 0.0869146\n",
      "[1325]\ttraining's rmse: 0.0831162\tvalid_1's rmse: 0.0869119\n",
      "[1350]\ttraining's rmse: 0.0830992\tvalid_1's rmse: 0.0869099\n",
      "[1375]\ttraining's rmse: 0.0830852\tvalid_1's rmse: 0.0869075\n",
      "[1400]\ttraining's rmse: 0.0830722\tvalid_1's rmse: 0.0869043\n",
      "[1425]\ttraining's rmse: 0.0830589\tvalid_1's rmse: 0.0869028\n",
      "[1450]\ttraining's rmse: 0.0830462\tvalid_1's rmse: 0.0869009\n",
      "[1475]\ttraining's rmse: 0.0830344\tvalid_1's rmse: 0.0868988\n",
      "[1500]\ttraining's rmse: 0.0830241\tvalid_1's rmse: 0.0868971\n",
      "[1525]\ttraining's rmse: 0.0830139\tvalid_1's rmse: 0.0868953\n",
      "[1550]\ttraining's rmse: 0.0830026\tvalid_1's rmse: 0.0868946\n",
      "[1575]\ttraining's rmse: 0.0829925\tvalid_1's rmse: 0.0868932\n",
      "[1600]\ttraining's rmse: 0.0829845\tvalid_1's rmse: 0.086893\n",
      "[1625]\ttraining's rmse: 0.0829761\tvalid_1's rmse: 0.0868917\n",
      "[1650]\ttraining's rmse: 0.0829665\tvalid_1's rmse: 0.0868902\n",
      "[1675]\ttraining's rmse: 0.0829603\tvalid_1's rmse: 0.0868893\n",
      "[1700]\ttraining's rmse: 0.082954\tvalid_1's rmse: 0.0868879\n",
      "[1725]\ttraining's rmse: 0.082946\tvalid_1's rmse: 0.0868868\n",
      "[1750]\ttraining's rmse: 0.0829385\tvalid_1's rmse: 0.0868862\n",
      "[1775]\ttraining's rmse: 0.0829323\tvalid_1's rmse: 0.0868853\n",
      "[1800]\ttraining's rmse: 0.0829258\tvalid_1's rmse: 0.0868843\n",
      "[1825]\ttraining's rmse: 0.0829196\tvalid_1's rmse: 0.0868837\n",
      "[1850]\ttraining's rmse: 0.082914\tvalid_1's rmse: 0.0868828\n",
      "[1875]\ttraining's rmse: 0.0829079\tvalid_1's rmse: 0.0868825\n",
      "[1900]\ttraining's rmse: 0.0829041\tvalid_1's rmse: 0.0868818\n",
      "[1925]\ttraining's rmse: 0.0828973\tvalid_1's rmse: 0.0868813\n",
      "[1950]\ttraining's rmse: 0.0828926\tvalid_1's rmse: 0.0868806\n",
      "[1975]\ttraining's rmse: 0.0828888\tvalid_1's rmse: 0.0868797\n",
      "[2000]\ttraining's rmse: 0.0828833\tvalid_1's rmse: 0.0868794\n",
      "[2025]\ttraining's rmse: 0.0828805\tvalid_1's rmse: 0.0868788\n",
      "[2050]\ttraining's rmse: 0.0828754\tvalid_1's rmse: 0.0868784\n",
      "[2075]\ttraining's rmse: 0.082872\tvalid_1's rmse: 0.0868778\n",
      "[2100]\ttraining's rmse: 0.0828683\tvalid_1's rmse: 0.0868773\n",
      "[2125]\ttraining's rmse: 0.0828647\tvalid_1's rmse: 0.0868771\n",
      "[2150]\ttraining's rmse: 0.082861\tvalid_1's rmse: 0.0868773\n",
      "Early stopping, best iteration is:\n",
      "[2113]\ttraining's rmse: 0.0828659\tvalid_1's rmse: 0.0868769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0875465\tvalid_1's rmse: 0.0850638\n",
      "[50]\ttraining's rmse: 0.087419\tvalid_1's rmse: 0.0850143\n",
      "[75]\ttraining's rmse: 0.0872859\tvalid_1's rmse: 0.0849649\n",
      "[100]\ttraining's rmse: 0.0871643\tvalid_1's rmse: 0.0849204\n",
      "[125]\ttraining's rmse: 0.0870371\tvalid_1's rmse: 0.0848768\n",
      "[150]\ttraining's rmse: 0.0869214\tvalid_1's rmse: 0.0848361\n",
      "[175]\ttraining's rmse: 0.0868243\tvalid_1's rmse: 0.084804\n",
      "[200]\ttraining's rmse: 0.086717\tvalid_1's rmse: 0.084771\n",
      "[225]\ttraining's rmse: 0.0866141\tvalid_1's rmse: 0.0847396\n",
      "[250]\ttraining's rmse: 0.0865312\tvalid_1's rmse: 0.0847118\n",
      "[275]\ttraining's rmse: 0.086454\tvalid_1's rmse: 0.0846868\n",
      "[300]\ttraining's rmse: 0.0863754\tvalid_1's rmse: 0.0846631\n",
      "[325]\ttraining's rmse: 0.0862982\tvalid_1's rmse: 0.0846409\n",
      "[350]\ttraining's rmse: 0.086223\tvalid_1's rmse: 0.0846202\n",
      "[375]\ttraining's rmse: 0.0861595\tvalid_1's rmse: 0.0846023\n",
      "[400]\ttraining's rmse: 0.0860912\tvalid_1's rmse: 0.0845863\n",
      "[425]\ttraining's rmse: 0.0860294\tvalid_1's rmse: 0.0845694\n",
      "[450]\ttraining's rmse: 0.0859708\tvalid_1's rmse: 0.0845555\n",
      "[475]\ttraining's rmse: 0.0859173\tvalid_1's rmse: 0.084542\n",
      "[500]\ttraining's rmse: 0.0858725\tvalid_1's rmse: 0.0845287\n",
      "[525]\ttraining's rmse: 0.0858151\tvalid_1's rmse: 0.0845154\n",
      "[550]\ttraining's rmse: 0.0857603\tvalid_1's rmse: 0.0845025\n",
      "[575]\ttraining's rmse: 0.0857097\tvalid_1's rmse: 0.0844953\n",
      "[600]\ttraining's rmse: 0.0856628\tvalid_1's rmse: 0.0844867\n",
      "[625]\ttraining's rmse: 0.0856229\tvalid_1's rmse: 0.0844833\n",
      "[650]\ttraining's rmse: 0.0855724\tvalid_1's rmse: 0.0844825\n",
      "[675]\ttraining's rmse: 0.0855241\tvalid_1's rmse: 0.0844738\n",
      "[700]\ttraining's rmse: 0.0854834\tvalid_1's rmse: 0.0844658\n",
      "[725]\ttraining's rmse: 0.0854457\tvalid_1's rmse: 0.0844678\n",
      "[750]\ttraining's rmse: 0.0854096\tvalid_1's rmse: 0.0844704\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0854754\tvalid_1's rmse: 0.0844648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0808905\tvalid_1's rmse: 0.0835747\n",
      "[50]\ttraining's rmse: 0.0807699\tvalid_1's rmse: 0.083518\n",
      "[75]\ttraining's rmse: 0.0806473\tvalid_1's rmse: 0.0834626\n",
      "[100]\ttraining's rmse: 0.0805348\tvalid_1's rmse: 0.0834162\n",
      "[125]\ttraining's rmse: 0.0804221\tvalid_1's rmse: 0.0833675\n",
      "[150]\ttraining's rmse: 0.0803184\tvalid_1's rmse: 0.0833216\n",
      "[175]\ttraining's rmse: 0.0802344\tvalid_1's rmse: 0.0832836\n",
      "[200]\ttraining's rmse: 0.0801431\tvalid_1's rmse: 0.083244\n",
      "[225]\ttraining's rmse: 0.0800557\tvalid_1's rmse: 0.0832073\n",
      "[250]\ttraining's rmse: 0.0799802\tvalid_1's rmse: 0.0831743\n",
      "[275]\ttraining's rmse: 0.0799089\tvalid_1's rmse: 0.0831426\n",
      "[300]\ttraining's rmse: 0.0798392\tvalid_1's rmse: 0.0831129\n",
      "[325]\ttraining's rmse: 0.0797685\tvalid_1's rmse: 0.0830851\n",
      "[350]\ttraining's rmse: 0.0797031\tvalid_1's rmse: 0.0830585\n",
      "[375]\ttraining's rmse: 0.0796479\tvalid_1's rmse: 0.0830353\n",
      "[400]\ttraining's rmse: 0.0795877\tvalid_1's rmse: 0.0830115\n",
      "[425]\ttraining's rmse: 0.079537\tvalid_1's rmse: 0.0829901\n",
      "[450]\ttraining's rmse: 0.0794845\tvalid_1's rmse: 0.0829684\n",
      "[475]\ttraining's rmse: 0.0794391\tvalid_1's rmse: 0.0829485\n",
      "[500]\ttraining's rmse: 0.0793993\tvalid_1's rmse: 0.0829311\n",
      "[525]\ttraining's rmse: 0.0793492\tvalid_1's rmse: 0.0829128\n",
      "[550]\ttraining's rmse: 0.0793019\tvalid_1's rmse: 0.0828959\n",
      "[575]\ttraining's rmse: 0.0792583\tvalid_1's rmse: 0.082881\n",
      "[600]\ttraining's rmse: 0.0792178\tvalid_1's rmse: 0.0828671\n",
      "[625]\ttraining's rmse: 0.0791843\tvalid_1's rmse: 0.0828533\n",
      "[650]\ttraining's rmse: 0.0791465\tvalid_1's rmse: 0.0828391\n",
      "[675]\ttraining's rmse: 0.0791074\tvalid_1's rmse: 0.0828263\n",
      "[700]\ttraining's rmse: 0.0790759\tvalid_1's rmse: 0.0828148\n",
      "[725]\ttraining's rmse: 0.079042\tvalid_1's rmse: 0.0828039\n",
      "[750]\ttraining's rmse: 0.0790095\tvalid_1's rmse: 0.0827934\n",
      "[775]\ttraining's rmse: 0.0789844\tvalid_1's rmse: 0.0827804\n",
      "[800]\ttraining's rmse: 0.0789537\tvalid_1's rmse: 0.0827724\n",
      "[825]\ttraining's rmse: 0.0789287\tvalid_1's rmse: 0.0827611\n",
      "[850]\ttraining's rmse: 0.078901\tvalid_1's rmse: 0.0827522\n",
      "[875]\ttraining's rmse: 0.0788753\tvalid_1's rmse: 0.0827436\n",
      "[900]\ttraining's rmse: 0.0788471\tvalid_1's rmse: 0.0827353\n",
      "[925]\ttraining's rmse: 0.0788226\tvalid_1's rmse: 0.0827277\n",
      "[950]\ttraining's rmse: 0.0788005\tvalid_1's rmse: 0.0827191\n",
      "[975]\ttraining's rmse: 0.0787786\tvalid_1's rmse: 0.0827125\n",
      "[1000]\ttraining's rmse: 0.0787575\tvalid_1's rmse: 0.0827054\n",
      "[1025]\ttraining's rmse: 0.0787367\tvalid_1's rmse: 0.0826972\n",
      "[1050]\ttraining's rmse: 0.0787166\tvalid_1's rmse: 0.0826913\n",
      "[1075]\ttraining's rmse: 0.0786962\tvalid_1's rmse: 0.0826863\n",
      "[1100]\ttraining's rmse: 0.0786797\tvalid_1's rmse: 0.0826804\n",
      "[1125]\ttraining's rmse: 0.0786642\tvalid_1's rmse: 0.0826752\n",
      "[1150]\ttraining's rmse: 0.0786492\tvalid_1's rmse: 0.0826701\n",
      "[1175]\ttraining's rmse: 0.0786338\tvalid_1's rmse: 0.082666\n",
      "[1200]\ttraining's rmse: 0.0786194\tvalid_1's rmse: 0.0826605\n",
      "[1225]\ttraining's rmse: 0.078606\tvalid_1's rmse: 0.0826556\n",
      "[1250]\ttraining's rmse: 0.0785934\tvalid_1's rmse: 0.08265\n",
      "[1275]\ttraining's rmse: 0.0785766\tvalid_1's rmse: 0.0826465\n",
      "[1300]\ttraining's rmse: 0.0785635\tvalid_1's rmse: 0.0826428\n",
      "[1325]\ttraining's rmse: 0.0785529\tvalid_1's rmse: 0.0826397\n",
      "[1350]\ttraining's rmse: 0.0785429\tvalid_1's rmse: 0.0826376\n",
      "[1375]\ttraining's rmse: 0.0785305\tvalid_1's rmse: 0.082634\n",
      "[1400]\ttraining's rmse: 0.07852\tvalid_1's rmse: 0.0826296\n",
      "[1425]\ttraining's rmse: 0.0785082\tvalid_1's rmse: 0.0826271\n",
      "[1450]\ttraining's rmse: 0.0784962\tvalid_1's rmse: 0.0826228\n",
      "[1475]\ttraining's rmse: 0.078486\tvalid_1's rmse: 0.0826188\n",
      "[1500]\ttraining's rmse: 0.0784783\tvalid_1's rmse: 0.0826166\n",
      "[1525]\ttraining's rmse: 0.0784693\tvalid_1's rmse: 0.0826132\n",
      "[1550]\ttraining's rmse: 0.07846\tvalid_1's rmse: 0.0826109\n",
      "[1575]\ttraining's rmse: 0.0784518\tvalid_1's rmse: 0.0826088\n",
      "[1600]\ttraining's rmse: 0.0784444\tvalid_1's rmse: 0.082607\n",
      "[1625]\ttraining's rmse: 0.0784378\tvalid_1's rmse: 0.082604\n",
      "[1650]\ttraining's rmse: 0.0784305\tvalid_1's rmse: 0.0826013\n",
      "[1675]\ttraining's rmse: 0.0784246\tvalid_1's rmse: 0.0825994\n",
      "[1700]\ttraining's rmse: 0.0784186\tvalid_1's rmse: 0.0825959\n",
      "[1725]\ttraining's rmse: 0.0784114\tvalid_1's rmse: 0.0825945\n",
      "[1750]\ttraining's rmse: 0.0784042\tvalid_1's rmse: 0.0825914\n",
      "[1775]\ttraining's rmse: 0.0783996\tvalid_1's rmse: 0.0825902\n",
      "[1800]\ttraining's rmse: 0.0783947\tvalid_1's rmse: 0.0825888\n",
      "[1825]\ttraining's rmse: 0.0783871\tvalid_1's rmse: 0.0825878\n",
      "[1850]\ttraining's rmse: 0.0783818\tvalid_1's rmse: 0.0825862\n",
      "[1875]\ttraining's rmse: 0.0783772\tvalid_1's rmse: 0.0825853\n",
      "[1900]\ttraining's rmse: 0.0783732\tvalid_1's rmse: 0.0825839\n",
      "[1925]\ttraining's rmse: 0.0783674\tvalid_1's rmse: 0.0825831\n",
      "[1950]\ttraining's rmse: 0.0783634\tvalid_1's rmse: 0.0825817\n",
      "[1975]\ttraining's rmse: 0.0783597\tvalid_1's rmse: 0.0825804\n",
      "[2000]\ttraining's rmse: 0.078355\tvalid_1's rmse: 0.0825792\n",
      "[2025]\ttraining's rmse: 0.078352\tvalid_1's rmse: 0.0825781\n",
      "[2050]\ttraining's rmse: 0.0783474\tvalid_1's rmse: 0.0825758\n",
      "[2075]\ttraining's rmse: 0.0783443\tvalid_1's rmse: 0.0825744\n",
      "[2100]\ttraining's rmse: 0.0783428\tvalid_1's rmse: 0.0825741\n",
      "[2125]\ttraining's rmse: 0.0783401\tvalid_1's rmse: 0.0825727\n",
      "[2150]\ttraining's rmse: 0.0783379\tvalid_1's rmse: 0.0825727\n",
      "[2175]\ttraining's rmse: 0.0783343\tvalid_1's rmse: 0.082572\n",
      "[2200]\ttraining's rmse: 0.0783312\tvalid_1's rmse: 0.0825708\n",
      "[2225]\ttraining's rmse: 0.078329\tvalid_1's rmse: 0.0825703\n",
      "[2250]\ttraining's rmse: 0.0783256\tvalid_1's rmse: 0.0825692\n",
      "[2275]\ttraining's rmse: 0.0783212\tvalid_1's rmse: 0.0825691\n",
      "[2300]\ttraining's rmse: 0.0783194\tvalid_1's rmse: 0.0825686\n",
      "[2325]\ttraining's rmse: 0.0783174\tvalid_1's rmse: 0.0825678\n",
      "[2350]\ttraining's rmse: 0.0783151\tvalid_1's rmse: 0.0825665\n",
      "[2375]\ttraining's rmse: 0.0783121\tvalid_1's rmse: 0.0825662\n",
      "[2400]\ttraining's rmse: 0.0783102\tvalid_1's rmse: 0.0825652\n",
      "[2425]\ttraining's rmse: 0.0783082\tvalid_1's rmse: 0.0825649\n",
      "[2450]\ttraining's rmse: 0.0783065\tvalid_1's rmse: 0.0825642\n",
      "[2475]\ttraining's rmse: 0.0783042\tvalid_1's rmse: 0.082564\n",
      "[2500]\ttraining's rmse: 0.078302\tvalid_1's rmse: 0.082563\n",
      "[2525]\ttraining's rmse: 0.0783001\tvalid_1's rmse: 0.0825624\n",
      "[2550]\ttraining's rmse: 0.0782975\tvalid_1's rmse: 0.082562\n",
      "[2575]\ttraining's rmse: 0.0782944\tvalid_1's rmse: 0.0825616\n",
      "[2600]\ttraining's rmse: 0.0782923\tvalid_1's rmse: 0.0825613\n",
      "[2625]\ttraining's rmse: 0.0782906\tvalid_1's rmse: 0.0825608\n",
      "[2650]\ttraining's rmse: 0.0782885\tvalid_1's rmse: 0.0825603\n",
      "[2675]\ttraining's rmse: 0.0782859\tvalid_1's rmse: 0.0825594\n",
      "[2700]\ttraining's rmse: 0.0782847\tvalid_1's rmse: 0.0825587\n",
      "[2725]\ttraining's rmse: 0.0782831\tvalid_1's rmse: 0.0825585\n",
      "[2750]\ttraining's rmse: 0.0782811\tvalid_1's rmse: 0.0825585\n",
      "[2775]\ttraining's rmse: 0.0782801\tvalid_1's rmse: 0.0825586\n",
      "[2800]\ttraining's rmse: 0.0782782\tvalid_1's rmse: 0.0825578\n",
      "[2825]\ttraining's rmse: 0.0782764\tvalid_1's rmse: 0.0825576\n",
      "[2850]\ttraining's rmse: 0.0782747\tvalid_1's rmse: 0.0825577\n",
      "Early stopping, best iteration is:\n",
      "[2804]\ttraining's rmse: 0.0782781\tvalid_1's rmse: 0.0825575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0811588\tvalid_1's rmse: 0.0830444\n",
      "[50]\ttraining's rmse: 0.0810442\tvalid_1's rmse: 0.0829859\n",
      "[75]\ttraining's rmse: 0.0809258\tvalid_1's rmse: 0.082929\n",
      "[100]\ttraining's rmse: 0.0808192\tvalid_1's rmse: 0.0828762\n",
      "[125]\ttraining's rmse: 0.0807048\tvalid_1's rmse: 0.082824\n",
      "[150]\ttraining's rmse: 0.0806035\tvalid_1's rmse: 0.0827768\n",
      "[175]\ttraining's rmse: 0.0805201\tvalid_1's rmse: 0.0827388\n",
      "[200]\ttraining's rmse: 0.080427\tvalid_1's rmse: 0.0826985\n",
      "[225]\ttraining's rmse: 0.0803418\tvalid_1's rmse: 0.0826621\n",
      "[250]\ttraining's rmse: 0.0802679\tvalid_1's rmse: 0.0826283\n",
      "[275]\ttraining's rmse: 0.0801979\tvalid_1's rmse: 0.0825967\n",
      "[300]\ttraining's rmse: 0.0801268\tvalid_1's rmse: 0.0825668\n",
      "[325]\ttraining's rmse: 0.0800565\tvalid_1's rmse: 0.0825372\n",
      "[350]\ttraining's rmse: 0.0799892\tvalid_1's rmse: 0.0825111\n",
      "[375]\ttraining's rmse: 0.0799339\tvalid_1's rmse: 0.082488\n",
      "[400]\ttraining's rmse: 0.0798743\tvalid_1's rmse: 0.0824652\n",
      "[425]\ttraining's rmse: 0.07982\tvalid_1's rmse: 0.0824449\n",
      "[450]\ttraining's rmse: 0.0797672\tvalid_1's rmse: 0.0824252\n",
      "[475]\ttraining's rmse: 0.0797203\tvalid_1's rmse: 0.0824075\n",
      "[500]\ttraining's rmse: 0.0796792\tvalid_1's rmse: 0.0823903\n",
      "[525]\ttraining's rmse: 0.0796294\tvalid_1's rmse: 0.0823732\n",
      "[550]\ttraining's rmse: 0.0795791\tvalid_1's rmse: 0.0823555\n",
      "[575]\ttraining's rmse: 0.0795346\tvalid_1's rmse: 0.0823405\n",
      "[600]\ttraining's rmse: 0.0794911\tvalid_1's rmse: 0.0823259\n",
      "[625]\ttraining's rmse: 0.079458\tvalid_1's rmse: 0.0823138\n",
      "[650]\ttraining's rmse: 0.0794182\tvalid_1's rmse: 0.0823013\n",
      "[675]\ttraining's rmse: 0.0793754\tvalid_1's rmse: 0.082289\n",
      "[700]\ttraining's rmse: 0.0793393\tvalid_1's rmse: 0.0822779\n",
      "[725]\ttraining's rmse: 0.0793064\tvalid_1's rmse: 0.0822678\n",
      "[750]\ttraining's rmse: 0.0792738\tvalid_1's rmse: 0.0822581\n",
      "[775]\ttraining's rmse: 0.079247\tvalid_1's rmse: 0.0822492\n",
      "[800]\ttraining's rmse: 0.0792132\tvalid_1's rmse: 0.0822412\n",
      "[825]\ttraining's rmse: 0.0791854\tvalid_1's rmse: 0.0822329\n",
      "[850]\ttraining's rmse: 0.0791586\tvalid_1's rmse: 0.0822263\n",
      "[875]\ttraining's rmse: 0.0791324\tvalid_1's rmse: 0.0822192\n",
      "[900]\ttraining's rmse: 0.0791058\tvalid_1's rmse: 0.0822122\n",
      "[925]\ttraining's rmse: 0.0790794\tvalid_1's rmse: 0.0822052\n",
      "[950]\ttraining's rmse: 0.0790581\tvalid_1's rmse: 0.0821998\n",
      "[975]\ttraining's rmse: 0.0790367\tvalid_1's rmse: 0.0821947\n",
      "[1000]\ttraining's rmse: 0.0790152\tvalid_1's rmse: 0.0821905\n",
      "[1025]\ttraining's rmse: 0.0789927\tvalid_1's rmse: 0.0821858\n",
      "[1050]\ttraining's rmse: 0.0789731\tvalid_1's rmse: 0.0821808\n",
      "[1075]\ttraining's rmse: 0.0789529\tvalid_1's rmse: 0.0821769\n",
      "[1100]\ttraining's rmse: 0.078937\tvalid_1's rmse: 0.0821732\n",
      "[1125]\ttraining's rmse: 0.0789204\tvalid_1's rmse: 0.0821694\n",
      "[1150]\ttraining's rmse: 0.0789022\tvalid_1's rmse: 0.0821654\n",
      "[1175]\ttraining's rmse: 0.0788885\tvalid_1's rmse: 0.0821622\n",
      "[1200]\ttraining's rmse: 0.0788735\tvalid_1's rmse: 0.082159\n",
      "[1225]\ttraining's rmse: 0.0788603\tvalid_1's rmse: 0.0821565\n",
      "[1250]\ttraining's rmse: 0.0788449\tvalid_1's rmse: 0.082153\n",
      "[1275]\ttraining's rmse: 0.0788298\tvalid_1's rmse: 0.0821504\n",
      "[1300]\ttraining's rmse: 0.0788191\tvalid_1's rmse: 0.082148\n",
      "[1325]\ttraining's rmse: 0.0788073\tvalid_1's rmse: 0.0821458\n",
      "[1350]\ttraining's rmse: 0.0787937\tvalid_1's rmse: 0.0821443\n",
      "[1375]\ttraining's rmse: 0.0787816\tvalid_1's rmse: 0.0821421\n",
      "[1400]\ttraining's rmse: 0.0787726\tvalid_1's rmse: 0.0821398\n",
      "[1425]\ttraining's rmse: 0.0787632\tvalid_1's rmse: 0.082138\n",
      "[1450]\ttraining's rmse: 0.0787527\tvalid_1's rmse: 0.0821366\n",
      "[1475]\ttraining's rmse: 0.0787414\tvalid_1's rmse: 0.0821344\n",
      "[1500]\ttraining's rmse: 0.0787343\tvalid_1's rmse: 0.0821327\n",
      "[1525]\ttraining's rmse: 0.0787232\tvalid_1's rmse: 0.0821308\n",
      "[1550]\ttraining's rmse: 0.078716\tvalid_1's rmse: 0.0821294\n",
      "[1575]\ttraining's rmse: 0.0787085\tvalid_1's rmse: 0.0821278\n",
      "[1600]\ttraining's rmse: 0.0786997\tvalid_1's rmse: 0.0821268\n",
      "[1625]\ttraining's rmse: 0.0786926\tvalid_1's rmse: 0.0821253\n",
      "[1650]\ttraining's rmse: 0.0786859\tvalid_1's rmse: 0.0821242\n",
      "[1675]\ttraining's rmse: 0.0786809\tvalid_1's rmse: 0.082123\n",
      "[1700]\ttraining's rmse: 0.0786749\tvalid_1's rmse: 0.0821219\n",
      "[1725]\ttraining's rmse: 0.078668\tvalid_1's rmse: 0.0821208\n",
      "[1750]\ttraining's rmse: 0.0786608\tvalid_1's rmse: 0.0821197\n",
      "[1775]\ttraining's rmse: 0.0786547\tvalid_1's rmse: 0.0821187\n",
      "[1800]\ttraining's rmse: 0.0786496\tvalid_1's rmse: 0.0821181\n",
      "[1825]\ttraining's rmse: 0.0786435\tvalid_1's rmse: 0.0821171\n",
      "[1850]\ttraining's rmse: 0.0786385\tvalid_1's rmse: 0.0821163\n",
      "[1875]\ttraining's rmse: 0.0786344\tvalid_1's rmse: 0.0821164\n",
      "[1900]\ttraining's rmse: 0.0786281\tvalid_1's rmse: 0.0821158\n",
      "[1925]\ttraining's rmse: 0.0786245\tvalid_1's rmse: 0.0821151\n",
      "[1950]\ttraining's rmse: 0.0786215\tvalid_1's rmse: 0.0821145\n",
      "[1975]\ttraining's rmse: 0.0786183\tvalid_1's rmse: 0.0821141\n",
      "[2000]\ttraining's rmse: 0.0786119\tvalid_1's rmse: 0.0821131\n",
      "[2025]\ttraining's rmse: 0.0786092\tvalid_1's rmse: 0.0821128\n",
      "[2050]\ttraining's rmse: 0.0786053\tvalid_1's rmse: 0.0821124\n",
      "[2075]\ttraining's rmse: 0.078603\tvalid_1's rmse: 0.082112\n",
      "[2100]\ttraining's rmse: 0.0786008\tvalid_1's rmse: 0.082112\n",
      "[2125]\ttraining's rmse: 0.078598\tvalid_1's rmse: 0.0821117\n",
      "[2150]\ttraining's rmse: 0.0785949\tvalid_1's rmse: 0.0821116\n",
      "[2175]\ttraining's rmse: 0.0785927\tvalid_1's rmse: 0.0821116\n",
      "[2200]\ttraining's rmse: 0.0785902\tvalid_1's rmse: 0.0821115\n",
      "[2225]\ttraining's rmse: 0.0785874\tvalid_1's rmse: 0.0821112\n",
      "[2250]\ttraining's rmse: 0.0785846\tvalid_1's rmse: 0.0821112\n",
      "[2275]\ttraining's rmse: 0.0785804\tvalid_1's rmse: 0.0821107\n",
      "[2300]\ttraining's rmse: 0.0785777\tvalid_1's rmse: 0.0821105\n",
      "[2325]\ttraining's rmse: 0.0785738\tvalid_1's rmse: 0.0821102\n",
      "[2350]\ttraining's rmse: 0.0785705\tvalid_1's rmse: 0.0821097\n",
      "[2375]\ttraining's rmse: 0.0785677\tvalid_1's rmse: 0.0821093\n",
      "[2400]\ttraining's rmse: 0.0785651\tvalid_1's rmse: 0.0821094\n",
      "[2425]\ttraining's rmse: 0.0785631\tvalid_1's rmse: 0.0821094\n",
      "Early stopping, best iteration is:\n",
      "[2390]\ttraining's rmse: 0.0785659\tvalid_1's rmse: 0.0821092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0831926\tvalid_1's rmse: 0.0789016\n",
      "[50]\ttraining's rmse: 0.0830753\tvalid_1's rmse: 0.0788507\n",
      "[75]\ttraining's rmse: 0.0829579\tvalid_1's rmse: 0.0788031\n",
      "[100]\ttraining's rmse: 0.0828521\tvalid_1's rmse: 0.0787593\n",
      "[125]\ttraining's rmse: 0.0827437\tvalid_1's rmse: 0.0787168\n",
      "[150]\ttraining's rmse: 0.082643\tvalid_1's rmse: 0.0786799\n",
      "[175]\ttraining's rmse: 0.0825639\tvalid_1's rmse: 0.0786489\n",
      "[200]\ttraining's rmse: 0.0824757\tvalid_1's rmse: 0.0786175\n",
      "[225]\ttraining's rmse: 0.0823918\tvalid_1's rmse: 0.0785867\n",
      "[250]\ttraining's rmse: 0.0823203\tvalid_1's rmse: 0.0785603\n",
      "[275]\ttraining's rmse: 0.0822528\tvalid_1's rmse: 0.0785354\n",
      "[300]\ttraining's rmse: 0.0821867\tvalid_1's rmse: 0.0785107\n",
      "[325]\ttraining's rmse: 0.0821202\tvalid_1's rmse: 0.0784875\n",
      "[350]\ttraining's rmse: 0.082054\tvalid_1's rmse: 0.0784672\n",
      "[375]\ttraining's rmse: 0.0819989\tvalid_1's rmse: 0.0784491\n",
      "[400]\ttraining's rmse: 0.0819397\tvalid_1's rmse: 0.0784315\n",
      "[425]\ttraining's rmse: 0.0818861\tvalid_1's rmse: 0.0784157\n",
      "[450]\ttraining's rmse: 0.081836\tvalid_1's rmse: 0.0784004\n",
      "[475]\ttraining's rmse: 0.0817902\tvalid_1's rmse: 0.0783874\n",
      "[500]\ttraining's rmse: 0.0817494\tvalid_1's rmse: 0.07838\n",
      "[525]\ttraining's rmse: 0.0817009\tvalid_1's rmse: 0.0783666\n",
      "[550]\ttraining's rmse: 0.0816548\tvalid_1's rmse: 0.0783631\n",
      "[575]\ttraining's rmse: 0.0816126\tvalid_1's rmse: 0.0783523\n",
      "[600]\ttraining's rmse: 0.0815699\tvalid_1's rmse: 0.0783482\n",
      "[625]\ttraining's rmse: 0.0815362\tvalid_1's rmse: 0.0783427\n",
      "[650]\ttraining's rmse: 0.0814955\tvalid_1's rmse: 0.0783391\n",
      "[675]\ttraining's rmse: 0.0814536\tvalid_1's rmse: 0.07833\n",
      "[700]\ttraining's rmse: 0.0814158\tvalid_1's rmse: 0.0783214\n",
      "[725]\ttraining's rmse: 0.0813843\tvalid_1's rmse: 0.0783147\n",
      "[750]\ttraining's rmse: 0.081352\tvalid_1's rmse: 0.0783125\n",
      "[775]\ttraining's rmse: 0.0813245\tvalid_1's rmse: 0.0783122\n",
      "[800]\ttraining's rmse: 0.0812892\tvalid_1's rmse: 0.0783056\n",
      "[825]\ttraining's rmse: 0.0812626\tvalid_1's rmse: 0.0783073\n",
      "[850]\ttraining's rmse: 0.0812339\tvalid_1's rmse: 0.0783018\n",
      "[875]\ttraining's rmse: 0.0812081\tvalid_1's rmse: 0.0782972\n",
      "[900]\ttraining's rmse: 0.0811809\tvalid_1's rmse: 0.0783052\n",
      "[925]\ttraining's rmse: 0.0811534\tvalid_1's rmse: 0.0783197\n",
      "Early stopping, best iteration is:\n",
      "[880]\ttraining's rmse: 0.0812033\tvalid_1's rmse: 0.0782962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0869465\tvalid_1's rmse: 0.0881308\n",
      "[50]\ttraining's rmse: 0.0867585\tvalid_1's rmse: 0.0880782\n",
      "[75]\ttraining's rmse: 0.0865705\tvalid_1's rmse: 0.0880271\n",
      "[100]\ttraining's rmse: 0.0864005\tvalid_1's rmse: 0.0879803\n",
      "[125]\ttraining's rmse: 0.0862332\tvalid_1's rmse: 0.0879339\n",
      "[150]\ttraining's rmse: 0.0860793\tvalid_1's rmse: 0.0878928\n",
      "[175]\ttraining's rmse: 0.0859461\tvalid_1's rmse: 0.0878563\n",
      "[200]\ttraining's rmse: 0.0858053\tvalid_1's rmse: 0.0878218\n",
      "[225]\ttraining's rmse: 0.0856705\tvalid_1's rmse: 0.0877893\n",
      "[250]\ttraining's rmse: 0.0855535\tvalid_1's rmse: 0.0877571\n",
      "[275]\ttraining's rmse: 0.0854473\tvalid_1's rmse: 0.0877293\n",
      "[300]\ttraining's rmse: 0.0853426\tvalid_1's rmse: 0.0877024\n",
      "[325]\ttraining's rmse: 0.0852394\tvalid_1's rmse: 0.0876789\n",
      "[350]\ttraining's rmse: 0.085143\tvalid_1's rmse: 0.0876544\n",
      "[375]\ttraining's rmse: 0.0850585\tvalid_1's rmse: 0.0876351\n",
      "[400]\ttraining's rmse: 0.0849718\tvalid_1's rmse: 0.0876155\n",
      "[425]\ttraining's rmse: 0.084895\tvalid_1's rmse: 0.0875977\n",
      "[450]\ttraining's rmse: 0.0848228\tvalid_1's rmse: 0.08758\n",
      "[475]\ttraining's rmse: 0.0847593\tvalid_1's rmse: 0.0875638\n",
      "[500]\ttraining's rmse: 0.0847018\tvalid_1's rmse: 0.0875489\n",
      "[525]\ttraining's rmse: 0.0846314\tvalid_1's rmse: 0.0875313\n",
      "[550]\ttraining's rmse: 0.0845678\tvalid_1's rmse: 0.0875179\n",
      "[575]\ttraining's rmse: 0.0845073\tvalid_1's rmse: 0.0875049\n",
      "[600]\ttraining's rmse: 0.0844516\tvalid_1's rmse: 0.0874922\n",
      "[625]\ttraining's rmse: 0.0844044\tvalid_1's rmse: 0.0874811\n",
      "[650]\ttraining's rmse: 0.0843489\tvalid_1's rmse: 0.0874686\n",
      "[675]\ttraining's rmse: 0.0842981\tvalid_1's rmse: 0.0874571\n",
      "[700]\ttraining's rmse: 0.0842514\tvalid_1's rmse: 0.0874468\n",
      "[725]\ttraining's rmse: 0.0842088\tvalid_1's rmse: 0.0874372\n",
      "[750]\ttraining's rmse: 0.0841649\tvalid_1's rmse: 0.0874289\n",
      "[775]\ttraining's rmse: 0.0841291\tvalid_1's rmse: 0.0874202\n",
      "[800]\ttraining's rmse: 0.0840892\tvalid_1's rmse: 0.087412\n",
      "[825]\ttraining's rmse: 0.0840525\tvalid_1's rmse: 0.0874032\n",
      "[850]\ttraining's rmse: 0.0840135\tvalid_1's rmse: 0.0873955\n",
      "[875]\ttraining's rmse: 0.0839827\tvalid_1's rmse: 0.0873899\n",
      "[900]\ttraining's rmse: 0.0839468\tvalid_1's rmse: 0.0873832\n",
      "[925]\ttraining's rmse: 0.0839167\tvalid_1's rmse: 0.0873752\n",
      "[950]\ttraining's rmse: 0.0838871\tvalid_1's rmse: 0.0873696\n",
      "[975]\ttraining's rmse: 0.0838579\tvalid_1's rmse: 0.0873642\n",
      "[1000]\ttraining's rmse: 0.0838321\tvalid_1's rmse: 0.0873593\n",
      "[1025]\ttraining's rmse: 0.0838041\tvalid_1's rmse: 0.0873516\n",
      "[1050]\ttraining's rmse: 0.083778\tvalid_1's rmse: 0.0873468\n",
      "[1075]\ttraining's rmse: 0.0837525\tvalid_1's rmse: 0.0873429\n",
      "[1100]\ttraining's rmse: 0.0837296\tvalid_1's rmse: 0.0873372\n",
      "[1125]\ttraining's rmse: 0.0837095\tvalid_1's rmse: 0.0873327\n",
      "[1150]\ttraining's rmse: 0.0836875\tvalid_1's rmse: 0.0873276\n",
      "[1175]\ttraining's rmse: 0.0836659\tvalid_1's rmse: 0.087325\n",
      "[1200]\ttraining's rmse: 0.0836471\tvalid_1's rmse: 0.0873207\n",
      "[1225]\ttraining's rmse: 0.0836256\tvalid_1's rmse: 0.0873173\n",
      "[1250]\ttraining's rmse: 0.0836075\tvalid_1's rmse: 0.0873135\n",
      "[1275]\ttraining's rmse: 0.0835877\tvalid_1's rmse: 0.0873114\n",
      "[1300]\ttraining's rmse: 0.0835735\tvalid_1's rmse: 0.0873077\n",
      "[1325]\ttraining's rmse: 0.0835585\tvalid_1's rmse: 0.087304\n",
      "[1350]\ttraining's rmse: 0.0835406\tvalid_1's rmse: 0.0873009\n",
      "[1375]\ttraining's rmse: 0.0835249\tvalid_1's rmse: 0.0872966\n",
      "[1400]\ttraining's rmse: 0.0835116\tvalid_1's rmse: 0.0872931\n",
      "[1425]\ttraining's rmse: 0.0834943\tvalid_1's rmse: 0.0872905\n",
      "[1450]\ttraining's rmse: 0.0834796\tvalid_1's rmse: 0.0872873\n",
      "[1475]\ttraining's rmse: 0.0834648\tvalid_1's rmse: 0.0872831\n",
      "[1500]\ttraining's rmse: 0.0834544\tvalid_1's rmse: 0.0872803\n",
      "[1525]\ttraining's rmse: 0.0834439\tvalid_1's rmse: 0.0872787\n",
      "[1550]\ttraining's rmse: 0.0834312\tvalid_1's rmse: 0.0872765\n",
      "[1575]\ttraining's rmse: 0.0834202\tvalid_1's rmse: 0.087273\n",
      "[1600]\ttraining's rmse: 0.0834127\tvalid_1's rmse: 0.0872708\n",
      "[1625]\ttraining's rmse: 0.0834055\tvalid_1's rmse: 0.0872682\n",
      "[1650]\ttraining's rmse: 0.0833989\tvalid_1's rmse: 0.087266\n",
      "[1675]\ttraining's rmse: 0.0833922\tvalid_1's rmse: 0.0872635\n",
      "[1700]\ttraining's rmse: 0.0833863\tvalid_1's rmse: 0.0872621\n",
      "[1725]\ttraining's rmse: 0.0833782\tvalid_1's rmse: 0.0872616\n",
      "[1750]\ttraining's rmse: 0.083371\tvalid_1's rmse: 0.08726\n",
      "[1775]\ttraining's rmse: 0.0833658\tvalid_1's rmse: 0.0872588\n",
      "[1800]\ttraining's rmse: 0.0833596\tvalid_1's rmse: 0.0872575\n",
      "[1825]\ttraining's rmse: 0.0833518\tvalid_1's rmse: 0.0872562\n",
      "[1850]\ttraining's rmse: 0.083346\tvalid_1's rmse: 0.0872546\n",
      "[1875]\ttraining's rmse: 0.0833407\tvalid_1's rmse: 0.0872535\n",
      "[1900]\ttraining's rmse: 0.0833355\tvalid_1's rmse: 0.0872524\n",
      "[1925]\ttraining's rmse: 0.0833319\tvalid_1's rmse: 0.0872514\n",
      "[1950]\ttraining's rmse: 0.0833272\tvalid_1's rmse: 0.0872495\n",
      "[1975]\ttraining's rmse: 0.0833221\tvalid_1's rmse: 0.0872474\n",
      "[2000]\ttraining's rmse: 0.0833177\tvalid_1's rmse: 0.0872465\n",
      "[2025]\ttraining's rmse: 0.0833124\tvalid_1's rmse: 0.0872446\n",
      "[2050]\ttraining's rmse: 0.0833085\tvalid_1's rmse: 0.0872438\n",
      "[2075]\ttraining's rmse: 0.0833047\tvalid_1's rmse: 0.0872425\n",
      "[2100]\ttraining's rmse: 0.0833007\tvalid_1's rmse: 0.0872414\n",
      "[2125]\ttraining's rmse: 0.0832966\tvalid_1's rmse: 0.0872403\n",
      "[2150]\ttraining's rmse: 0.0832921\tvalid_1's rmse: 0.0872392\n",
      "[2175]\ttraining's rmse: 0.0832898\tvalid_1's rmse: 0.0872393\n",
      "[2200]\ttraining's rmse: 0.0832854\tvalid_1's rmse: 0.0872379\n",
      "[2225]\ttraining's rmse: 0.0832804\tvalid_1's rmse: 0.0872367\n",
      "[2250]\ttraining's rmse: 0.0832783\tvalid_1's rmse: 0.0872354\n",
      "[2275]\ttraining's rmse: 0.0832744\tvalid_1's rmse: 0.0872341\n",
      "[2300]\ttraining's rmse: 0.0832723\tvalid_1's rmse: 0.0872339\n",
      "[2325]\ttraining's rmse: 0.0832692\tvalid_1's rmse: 0.0872333\n",
      "[2350]\ttraining's rmse: 0.083267\tvalid_1's rmse: 0.087233\n",
      "[2375]\ttraining's rmse: 0.0832639\tvalid_1's rmse: 0.0872321\n",
      "[2400]\ttraining's rmse: 0.083259\tvalid_1's rmse: 0.0872321\n",
      "[2425]\ttraining's rmse: 0.0832564\tvalid_1's rmse: 0.0872311\n",
      "[2450]\ttraining's rmse: 0.0832536\tvalid_1's rmse: 0.0872297\n",
      "[2475]\ttraining's rmse: 0.0832497\tvalid_1's rmse: 0.0872292\n",
      "[2500]\ttraining's rmse: 0.083247\tvalid_1's rmse: 0.0872292\n",
      "[2525]\ttraining's rmse: 0.0832442\tvalid_1's rmse: 0.087229\n",
      "[2550]\ttraining's rmse: 0.0832413\tvalid_1's rmse: 0.0872286\n",
      "[2575]\ttraining's rmse: 0.083238\tvalid_1's rmse: 0.0872273\n",
      "[2600]\ttraining's rmse: 0.0832356\tvalid_1's rmse: 0.0872272\n",
      "[2625]\ttraining's rmse: 0.0832335\tvalid_1's rmse: 0.087226\n",
      "[2650]\ttraining's rmse: 0.083232\tvalid_1's rmse: 0.0872258\n",
      "[2675]\ttraining's rmse: 0.0832306\tvalid_1's rmse: 0.0872252\n",
      "[2700]\ttraining's rmse: 0.0832282\tvalid_1's rmse: 0.0872244\n",
      "[2725]\ttraining's rmse: 0.0832263\tvalid_1's rmse: 0.0872244\n",
      "[2750]\ttraining's rmse: 0.0832235\tvalid_1's rmse: 0.0872243\n",
      "[2775]\ttraining's rmse: 0.0832201\tvalid_1's rmse: 0.0872242\n",
      "[2800]\ttraining's rmse: 0.0832184\tvalid_1's rmse: 0.0872238\n",
      "[2825]\ttraining's rmse: 0.083217\tvalid_1's rmse: 0.0872238\n",
      "[2850]\ttraining's rmse: 0.0832149\tvalid_1's rmse: 0.087223\n",
      "[2875]\ttraining's rmse: 0.0832116\tvalid_1's rmse: 0.0872223\n",
      "[2900]\ttraining's rmse: 0.0832102\tvalid_1's rmse: 0.087222\n",
      "[2925]\ttraining's rmse: 0.0832083\tvalid_1's rmse: 0.0872221\n",
      "[2950]\ttraining's rmse: 0.0832061\tvalid_1's rmse: 0.0872214\n",
      "[2975]\ttraining's rmse: 0.0832044\tvalid_1's rmse: 0.0872216\n",
      "[3000]\ttraining's rmse: 0.0832028\tvalid_1's rmse: 0.0872214\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\ttraining's rmse: 0.0832028\tvalid_1's rmse: 0.0872214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0867181\tvalid_1's rmse: 0.0886175\n",
      "[50]\ttraining's rmse: 0.0865553\tvalid_1's rmse: 0.0885606\n",
      "[75]\ttraining's rmse: 0.0863881\tvalid_1's rmse: 0.0885028\n",
      "[100]\ttraining's rmse: 0.0862355\tvalid_1's rmse: 0.088452\n",
      "[125]\ttraining's rmse: 0.0860797\tvalid_1's rmse: 0.0884013\n",
      "[150]\ttraining's rmse: 0.0859417\tvalid_1's rmse: 0.0883546\n",
      "[175]\ttraining's rmse: 0.0858271\tvalid_1's rmse: 0.0883162\n",
      "[200]\ttraining's rmse: 0.0857042\tvalid_1's rmse: 0.0882765\n",
      "[225]\ttraining's rmse: 0.0855863\tvalid_1's rmse: 0.0882397\n",
      "[250]\ttraining's rmse: 0.0854879\tvalid_1's rmse: 0.0882061\n",
      "[275]\ttraining's rmse: 0.0853914\tvalid_1's rmse: 0.0881746\n",
      "[300]\ttraining's rmse: 0.0852982\tvalid_1's rmse: 0.0881457\n",
      "[325]\ttraining's rmse: 0.0852058\tvalid_1's rmse: 0.0881175\n",
      "[350]\ttraining's rmse: 0.08512\tvalid_1's rmse: 0.0880931\n",
      "[375]\ttraining's rmse: 0.0850509\tvalid_1's rmse: 0.0880713\n",
      "[400]\ttraining's rmse: 0.084971\tvalid_1's rmse: 0.0880485\n",
      "[425]\ttraining's rmse: 0.0849004\tvalid_1's rmse: 0.0880265\n",
      "[450]\ttraining's rmse: 0.0848349\tvalid_1's rmse: 0.0880065\n",
      "[475]\ttraining's rmse: 0.0847751\tvalid_1's rmse: 0.087987\n",
      "[500]\ttraining's rmse: 0.0847266\tvalid_1's rmse: 0.0879696\n",
      "[525]\ttraining's rmse: 0.0846618\tvalid_1's rmse: 0.0879509\n",
      "[550]\ttraining's rmse: 0.0846028\tvalid_1's rmse: 0.0879342\n",
      "[575]\ttraining's rmse: 0.0845509\tvalid_1's rmse: 0.087919\n",
      "[600]\ttraining's rmse: 0.0844983\tvalid_1's rmse: 0.0879042\n",
      "[625]\ttraining's rmse: 0.0844566\tvalid_1's rmse: 0.0878912\n",
      "[650]\ttraining's rmse: 0.0844084\tvalid_1's rmse: 0.0878772\n",
      "[675]\ttraining's rmse: 0.0843614\tvalid_1's rmse: 0.0878651\n",
      "[700]\ttraining's rmse: 0.0843202\tvalid_1's rmse: 0.0878533\n",
      "[725]\ttraining's rmse: 0.0842807\tvalid_1's rmse: 0.0878433\n",
      "[750]\ttraining's rmse: 0.0842451\tvalid_1's rmse: 0.0878334\n",
      "[775]\ttraining's rmse: 0.0842122\tvalid_1's rmse: 0.0878228\n",
      "[800]\ttraining's rmse: 0.084172\tvalid_1's rmse: 0.0878134\n",
      "[825]\ttraining's rmse: 0.0841376\tvalid_1's rmse: 0.0878046\n",
      "[850]\ttraining's rmse: 0.0841045\tvalid_1's rmse: 0.0877971\n",
      "[875]\ttraining's rmse: 0.0840741\tvalid_1's rmse: 0.08779\n",
      "[900]\ttraining's rmse: 0.0840418\tvalid_1's rmse: 0.0877824\n",
      "[925]\ttraining's rmse: 0.0840129\tvalid_1's rmse: 0.0877757\n",
      "[950]\ttraining's rmse: 0.0839841\tvalid_1's rmse: 0.0877694\n",
      "[975]\ttraining's rmse: 0.0839581\tvalid_1's rmse: 0.0877642\n",
      "[1000]\ttraining's rmse: 0.0839338\tvalid_1's rmse: 0.0877585\n",
      "[1025]\ttraining's rmse: 0.083905\tvalid_1's rmse: 0.0877529\n",
      "[1050]\ttraining's rmse: 0.0838813\tvalid_1's rmse: 0.0877474\n",
      "[1075]\ttraining's rmse: 0.0838594\tvalid_1's rmse: 0.0877437\n",
      "[1100]\ttraining's rmse: 0.0838388\tvalid_1's rmse: 0.0877384\n",
      "[1125]\ttraining's rmse: 0.083816\tvalid_1's rmse: 0.0877343\n",
      "[1150]\ttraining's rmse: 0.083796\tvalid_1's rmse: 0.0877299\n",
      "[1175]\ttraining's rmse: 0.083777\tvalid_1's rmse: 0.0877267\n",
      "[1200]\ttraining's rmse: 0.0837597\tvalid_1's rmse: 0.087722\n",
      "[1225]\ttraining's rmse: 0.0837434\tvalid_1's rmse: 0.0877184\n",
      "[1250]\ttraining's rmse: 0.0837286\tvalid_1's rmse: 0.0877159\n",
      "[1275]\ttraining's rmse: 0.0837092\tvalid_1's rmse: 0.0877128\n",
      "[1300]\ttraining's rmse: 0.0836955\tvalid_1's rmse: 0.0877092\n",
      "[1325]\ttraining's rmse: 0.0836804\tvalid_1's rmse: 0.0877062\n",
      "[1350]\ttraining's rmse: 0.0836635\tvalid_1's rmse: 0.0877035\n",
      "[1375]\ttraining's rmse: 0.0836513\tvalid_1's rmse: 0.0877012\n",
      "[1400]\ttraining's rmse: 0.0836398\tvalid_1's rmse: 0.087699\n",
      "[1425]\ttraining's rmse: 0.0836262\tvalid_1's rmse: 0.0876975\n",
      "[1450]\ttraining's rmse: 0.0836142\tvalid_1's rmse: 0.0876964\n",
      "[1475]\ttraining's rmse: 0.0836017\tvalid_1's rmse: 0.0876947\n",
      "[1500]\ttraining's rmse: 0.0835933\tvalid_1's rmse: 0.0876928\n",
      "[1525]\ttraining's rmse: 0.0835848\tvalid_1's rmse: 0.0876918\n",
      "[1550]\ttraining's rmse: 0.083575\tvalid_1's rmse: 0.0876908\n",
      "[1575]\ttraining's rmse: 0.0835654\tvalid_1's rmse: 0.0876894\n",
      "[1600]\ttraining's rmse: 0.0835577\tvalid_1's rmse: 0.0876885\n",
      "[1625]\ttraining's rmse: 0.0835481\tvalid_1's rmse: 0.0876868\n",
      "[1650]\ttraining's rmse: 0.0835384\tvalid_1's rmse: 0.087686\n",
      "[1675]\ttraining's rmse: 0.0835299\tvalid_1's rmse: 0.0876848\n",
      "[1700]\ttraining's rmse: 0.0835235\tvalid_1's rmse: 0.0876846\n",
      "[1725]\ttraining's rmse: 0.0835151\tvalid_1's rmse: 0.0876831\n",
      "[1750]\ttraining's rmse: 0.0835076\tvalid_1's rmse: 0.0876819\n",
      "[1775]\ttraining's rmse: 0.0835022\tvalid_1's rmse: 0.0876812\n",
      "[1800]\ttraining's rmse: 0.0834954\tvalid_1's rmse: 0.0876801\n",
      "[1825]\ttraining's rmse: 0.0834889\tvalid_1's rmse: 0.0876797\n",
      "[1850]\ttraining's rmse: 0.0834834\tvalid_1's rmse: 0.0876789\n",
      "[1875]\ttraining's rmse: 0.0834794\tvalid_1's rmse: 0.0876783\n",
      "[1900]\ttraining's rmse: 0.0834741\tvalid_1's rmse: 0.0876779\n",
      "[1925]\ttraining's rmse: 0.0834698\tvalid_1's rmse: 0.0876776\n",
      "[1950]\ttraining's rmse: 0.0834649\tvalid_1's rmse: 0.0876765\n",
      "[1975]\ttraining's rmse: 0.0834611\tvalid_1's rmse: 0.0876763\n",
      "[2000]\ttraining's rmse: 0.0834546\tvalid_1's rmse: 0.0876754\n",
      "[2025]\ttraining's rmse: 0.0834496\tvalid_1's rmse: 0.0876745\n",
      "[2050]\ttraining's rmse: 0.0834446\tvalid_1's rmse: 0.0876744\n",
      "[2075]\ttraining's rmse: 0.0834408\tvalid_1's rmse: 0.0876734\n",
      "[2100]\ttraining's rmse: 0.0834358\tvalid_1's rmse: 0.0876732\n",
      "[2125]\ttraining's rmse: 0.0834311\tvalid_1's rmse: 0.0876729\n",
      "[2150]\ttraining's rmse: 0.0834273\tvalid_1's rmse: 0.0876724\n",
      "[2175]\ttraining's rmse: 0.0834231\tvalid_1's rmse: 0.0876722\n",
      "[2200]\ttraining's rmse: 0.0834193\tvalid_1's rmse: 0.0876716\n",
      "[2225]\ttraining's rmse: 0.0834152\tvalid_1's rmse: 0.0876708\n",
      "[2250]\ttraining's rmse: 0.0834117\tvalid_1's rmse: 0.0876706\n",
      "[2275]\ttraining's rmse: 0.0834084\tvalid_1's rmse: 0.0876702\n",
      "[2300]\ttraining's rmse: 0.083404\tvalid_1's rmse: 0.0876691\n",
      "[2325]\ttraining's rmse: 0.0833996\tvalid_1's rmse: 0.0876686\n",
      "[2350]\ttraining's rmse: 0.0833965\tvalid_1's rmse: 0.0876682\n",
      "[2375]\ttraining's rmse: 0.0833944\tvalid_1's rmse: 0.087668\n",
      "[2400]\ttraining's rmse: 0.0833917\tvalid_1's rmse: 0.0876681\n",
      "[2425]\ttraining's rmse: 0.0833884\tvalid_1's rmse: 0.0876676\n",
      "[2450]\ttraining's rmse: 0.0833861\tvalid_1's rmse: 0.0876672\n",
      "[2475]\ttraining's rmse: 0.0833822\tvalid_1's rmse: 0.087667\n",
      "[2500]\ttraining's rmse: 0.0833798\tvalid_1's rmse: 0.0876668\n",
      "[2525]\ttraining's rmse: 0.0833765\tvalid_1's rmse: 0.0876664\n",
      "[2550]\ttraining's rmse: 0.0833737\tvalid_1's rmse: 0.0876663\n",
      "[2575]\ttraining's rmse: 0.0833717\tvalid_1's rmse: 0.0876663\n",
      "[2600]\ttraining's rmse: 0.0833686\tvalid_1's rmse: 0.0876661\n",
      "[2625]\ttraining's rmse: 0.0833669\tvalid_1's rmse: 0.087666\n",
      "[2650]\ttraining's rmse: 0.0833643\tvalid_1's rmse: 0.087666\n",
      "[2675]\ttraining's rmse: 0.0833615\tvalid_1's rmse: 0.0876658\n",
      "[2700]\ttraining's rmse: 0.0833598\tvalid_1's rmse: 0.0876659\n",
      "[2725]\ttraining's rmse: 0.0833583\tvalid_1's rmse: 0.0876661\n",
      "Early stopping, best iteration is:\n",
      "[2687]\ttraining's rmse: 0.0833606\tvalid_1's rmse: 0.0876657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0882283\tvalid_1's rmse: 0.085621\n",
      "[50]\ttraining's rmse: 0.0880963\tvalid_1's rmse: 0.08557\n",
      "[75]\ttraining's rmse: 0.087956\tvalid_1's rmse: 0.0855179\n",
      "[100]\ttraining's rmse: 0.087828\tvalid_1's rmse: 0.0854716\n",
      "[125]\ttraining's rmse: 0.0876959\tvalid_1's rmse: 0.0854266\n",
      "[150]\ttraining's rmse: 0.0875748\tvalid_1's rmse: 0.0853879\n",
      "[175]\ttraining's rmse: 0.0874743\tvalid_1's rmse: 0.0853542\n",
      "[200]\ttraining's rmse: 0.0873649\tvalid_1's rmse: 0.0853203\n",
      "[225]\ttraining's rmse: 0.0872589\tvalid_1's rmse: 0.0852888\n",
      "[250]\ttraining's rmse: 0.0871683\tvalid_1's rmse: 0.0852634\n",
      "[275]\ttraining's rmse: 0.087087\tvalid_1's rmse: 0.0852379\n",
      "[300]\ttraining's rmse: 0.0870037\tvalid_1's rmse: 0.0852153\n",
      "[325]\ttraining's rmse: 0.0869175\tvalid_1's rmse: 0.085192\n",
      "[350]\ttraining's rmse: 0.0868385\tvalid_1's rmse: 0.0851707\n",
      "[375]\ttraining's rmse: 0.0867716\tvalid_1's rmse: 0.0851525\n",
      "[400]\ttraining's rmse: 0.0867008\tvalid_1's rmse: 0.0851341\n",
      "[425]\ttraining's rmse: 0.0866345\tvalid_1's rmse: 0.0851174\n",
      "[450]\ttraining's rmse: 0.0865743\tvalid_1's rmse: 0.0851031\n",
      "[475]\ttraining's rmse: 0.0865185\tvalid_1's rmse: 0.0850909\n",
      "[500]\ttraining's rmse: 0.086471\tvalid_1's rmse: 0.0850775\n",
      "[525]\ttraining's rmse: 0.0864076\tvalid_1's rmse: 0.0850659\n",
      "[550]\ttraining's rmse: 0.0863521\tvalid_1's rmse: 0.0850546\n",
      "[575]\ttraining's rmse: 0.0863002\tvalid_1's rmse: 0.0850469\n",
      "[600]\ttraining's rmse: 0.0862506\tvalid_1's rmse: 0.085039\n",
      "[625]\ttraining's rmse: 0.0862106\tvalid_1's rmse: 0.0850325\n",
      "[650]\ttraining's rmse: 0.08616\tvalid_1's rmse: 0.0850286\n",
      "[675]\ttraining's rmse: 0.0861091\tvalid_1's rmse: 0.0850277\n",
      "[700]\ttraining's rmse: 0.086065\tvalid_1's rmse: 0.0850296\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's rmse: 0.086119\tvalid_1's rmse: 0.0850231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0811883\tvalid_1's rmse: 0.0839008\n",
      "[50]\ttraining's rmse: 0.0810649\tvalid_1's rmse: 0.0838438\n",
      "[75]\ttraining's rmse: 0.0809422\tvalid_1's rmse: 0.083787\n",
      "[100]\ttraining's rmse: 0.080831\tvalid_1's rmse: 0.0837396\n",
      "[125]\ttraining's rmse: 0.0807163\tvalid_1's rmse: 0.0836892\n",
      "[150]\ttraining's rmse: 0.0806146\tvalid_1's rmse: 0.0836429\n",
      "[175]\ttraining's rmse: 0.0805272\tvalid_1's rmse: 0.0836047\n",
      "[200]\ttraining's rmse: 0.0804326\tvalid_1's rmse: 0.0835662\n",
      "[225]\ttraining's rmse: 0.0803452\tvalid_1's rmse: 0.0835312\n",
      "[250]\ttraining's rmse: 0.0802696\tvalid_1's rmse: 0.083496\n",
      "[275]\ttraining's rmse: 0.0801997\tvalid_1's rmse: 0.083463\n",
      "[300]\ttraining's rmse: 0.08013\tvalid_1's rmse: 0.083433\n",
      "[325]\ttraining's rmse: 0.0800583\tvalid_1's rmse: 0.083406\n",
      "[350]\ttraining's rmse: 0.0799912\tvalid_1's rmse: 0.0833784\n",
      "[375]\ttraining's rmse: 0.0799345\tvalid_1's rmse: 0.0833551\n",
      "[400]\ttraining's rmse: 0.0798736\tvalid_1's rmse: 0.0833313\n",
      "[425]\ttraining's rmse: 0.0798218\tvalid_1's rmse: 0.0833099\n",
      "[450]\ttraining's rmse: 0.0797704\tvalid_1's rmse: 0.0832888\n",
      "[475]\ttraining's rmse: 0.0797224\tvalid_1's rmse: 0.0832669\n",
      "[500]\ttraining's rmse: 0.0796833\tvalid_1's rmse: 0.0832493\n",
      "[525]\ttraining's rmse: 0.0796356\tvalid_1's rmse: 0.0832316\n",
      "[550]\ttraining's rmse: 0.0795891\tvalid_1's rmse: 0.0832143\n",
      "[575]\ttraining's rmse: 0.0795496\tvalid_1's rmse: 0.0831995\n",
      "[600]\ttraining's rmse: 0.0795086\tvalid_1's rmse: 0.083182\n",
      "[625]\ttraining's rmse: 0.0794727\tvalid_1's rmse: 0.0831685\n",
      "[650]\ttraining's rmse: 0.0794334\tvalid_1's rmse: 0.0831546\n",
      "[675]\ttraining's rmse: 0.0793934\tvalid_1's rmse: 0.0831385\n",
      "[700]\ttraining's rmse: 0.0793598\tvalid_1's rmse: 0.0831257\n",
      "[725]\ttraining's rmse: 0.0793281\tvalid_1's rmse: 0.0831144\n",
      "[750]\ttraining's rmse: 0.0792974\tvalid_1's rmse: 0.0831033\n",
      "[775]\ttraining's rmse: 0.079271\tvalid_1's rmse: 0.0830921\n",
      "[800]\ttraining's rmse: 0.0792375\tvalid_1's rmse: 0.0830843\n",
      "[825]\ttraining's rmse: 0.0792109\tvalid_1's rmse: 0.0830732\n",
      "[850]\ttraining's rmse: 0.0791833\tvalid_1's rmse: 0.083066\n",
      "[875]\ttraining's rmse: 0.079158\tvalid_1's rmse: 0.0830559\n",
      "[900]\ttraining's rmse: 0.0791297\tvalid_1's rmse: 0.0830471\n",
      "[925]\ttraining's rmse: 0.0791045\tvalid_1's rmse: 0.0830372\n",
      "[950]\ttraining's rmse: 0.0790828\tvalid_1's rmse: 0.0830297\n",
      "[975]\ttraining's rmse: 0.0790629\tvalid_1's rmse: 0.0830249\n",
      "[1000]\ttraining's rmse: 0.0790431\tvalid_1's rmse: 0.0830193\n",
      "[1025]\ttraining's rmse: 0.0790221\tvalid_1's rmse: 0.0830124\n",
      "[1050]\ttraining's rmse: 0.0790033\tvalid_1's rmse: 0.083006\n",
      "[1075]\ttraining's rmse: 0.078984\tvalid_1's rmse: 0.0829999\n",
      "[1100]\ttraining's rmse: 0.0789687\tvalid_1's rmse: 0.0829939\n",
      "[1125]\ttraining's rmse: 0.0789517\tvalid_1's rmse: 0.082988\n",
      "[1150]\ttraining's rmse: 0.0789366\tvalid_1's rmse: 0.0829831\n",
      "[1175]\ttraining's rmse: 0.0789206\tvalid_1's rmse: 0.082978\n",
      "[1200]\ttraining's rmse: 0.0789066\tvalid_1's rmse: 0.082972\n",
      "[1225]\ttraining's rmse: 0.0788924\tvalid_1's rmse: 0.082967\n",
      "[1250]\ttraining's rmse: 0.0788788\tvalid_1's rmse: 0.0829619\n",
      "[1275]\ttraining's rmse: 0.0788656\tvalid_1's rmse: 0.0829581\n",
      "[1300]\ttraining's rmse: 0.0788528\tvalid_1's rmse: 0.0829536\n",
      "[1325]\ttraining's rmse: 0.0788391\tvalid_1's rmse: 0.0829499\n",
      "[1350]\ttraining's rmse: 0.0788254\tvalid_1's rmse: 0.0829461\n",
      "[1375]\ttraining's rmse: 0.0788128\tvalid_1's rmse: 0.0829408\n",
      "[1400]\ttraining's rmse: 0.0788028\tvalid_1's rmse: 0.0829371\n",
      "[1425]\ttraining's rmse: 0.0787913\tvalid_1's rmse: 0.082934\n",
      "[1450]\ttraining's rmse: 0.0787785\tvalid_1's rmse: 0.082932\n",
      "[1475]\ttraining's rmse: 0.0787704\tvalid_1's rmse: 0.0829291\n",
      "[1500]\ttraining's rmse: 0.078762\tvalid_1's rmse: 0.0829266\n",
      "[1525]\ttraining's rmse: 0.0787539\tvalid_1's rmse: 0.0829242\n",
      "[1550]\ttraining's rmse: 0.0787451\tvalid_1's rmse: 0.0829227\n",
      "[1575]\ttraining's rmse: 0.0787386\tvalid_1's rmse: 0.0829204\n",
      "[1600]\ttraining's rmse: 0.0787302\tvalid_1's rmse: 0.0829184\n",
      "[1625]\ttraining's rmse: 0.0787229\tvalid_1's rmse: 0.0829157\n",
      "[1650]\ttraining's rmse: 0.078716\tvalid_1's rmse: 0.0829135\n",
      "[1675]\ttraining's rmse: 0.0787103\tvalid_1's rmse: 0.0829112\n",
      "[1700]\ttraining's rmse: 0.0787044\tvalid_1's rmse: 0.0829074\n",
      "[1725]\ttraining's rmse: 0.0786989\tvalid_1's rmse: 0.0829051\n",
      "[1750]\ttraining's rmse: 0.0786931\tvalid_1's rmse: 0.0829027\n",
      "[1775]\ttraining's rmse: 0.0786888\tvalid_1's rmse: 0.082901\n",
      "[1800]\ttraining's rmse: 0.0786832\tvalid_1's rmse: 0.0829\n",
      "[1825]\ttraining's rmse: 0.078678\tvalid_1's rmse: 0.0828978\n",
      "[1850]\ttraining's rmse: 0.0786745\tvalid_1's rmse: 0.0828964\n",
      "[1875]\ttraining's rmse: 0.0786705\tvalid_1's rmse: 0.0828954\n",
      "[1900]\ttraining's rmse: 0.0786656\tvalid_1's rmse: 0.0828937\n",
      "[1925]\ttraining's rmse: 0.07866\tvalid_1's rmse: 0.0828925\n",
      "[1950]\ttraining's rmse: 0.0786567\tvalid_1's rmse: 0.0828907\n",
      "[1975]\ttraining's rmse: 0.0786527\tvalid_1's rmse: 0.0828901\n",
      "[2000]\ttraining's rmse: 0.0786491\tvalid_1's rmse: 0.0828887\n",
      "[2025]\ttraining's rmse: 0.0786454\tvalid_1's rmse: 0.0828873\n",
      "[2050]\ttraining's rmse: 0.0786424\tvalid_1's rmse: 0.082886\n",
      "[2075]\ttraining's rmse: 0.0786393\tvalid_1's rmse: 0.0828857\n",
      "[2100]\ttraining's rmse: 0.0786366\tvalid_1's rmse: 0.0828848\n",
      "[2125]\ttraining's rmse: 0.0786336\tvalid_1's rmse: 0.0828837\n",
      "[2150]\ttraining's rmse: 0.0786303\tvalid_1's rmse: 0.0828825\n",
      "[2175]\ttraining's rmse: 0.078628\tvalid_1's rmse: 0.0828819\n",
      "[2200]\ttraining's rmse: 0.0786248\tvalid_1's rmse: 0.082881\n",
      "[2225]\ttraining's rmse: 0.0786222\tvalid_1's rmse: 0.0828806\n",
      "[2250]\ttraining's rmse: 0.0786188\tvalid_1's rmse: 0.0828806\n",
      "[2275]\ttraining's rmse: 0.078616\tvalid_1's rmse: 0.0828803\n",
      "[2300]\ttraining's rmse: 0.0786136\tvalid_1's rmse: 0.0828799\n",
      "[2325]\ttraining's rmse: 0.0786108\tvalid_1's rmse: 0.082879\n",
      "[2350]\ttraining's rmse: 0.0786083\tvalid_1's rmse: 0.0828789\n",
      "[2375]\ttraining's rmse: 0.0786061\tvalid_1's rmse: 0.0828779\n",
      "[2400]\ttraining's rmse: 0.0786024\tvalid_1's rmse: 0.0828771\n",
      "[2425]\ttraining's rmse: 0.0786008\tvalid_1's rmse: 0.0828766\n",
      "[2450]\ttraining's rmse: 0.0785988\tvalid_1's rmse: 0.0828762\n",
      "[2475]\ttraining's rmse: 0.0785974\tvalid_1's rmse: 0.0828758\n",
      "[2500]\ttraining's rmse: 0.078595\tvalid_1's rmse: 0.0828758\n",
      "[2525]\ttraining's rmse: 0.0785927\tvalid_1's rmse: 0.0828751\n",
      "[2550]\ttraining's rmse: 0.0785903\tvalid_1's rmse: 0.0828746\n",
      "[2575]\ttraining's rmse: 0.0785886\tvalid_1's rmse: 0.0828741\n",
      "[2600]\ttraining's rmse: 0.078586\tvalid_1's rmse: 0.0828738\n",
      "[2625]\ttraining's rmse: 0.0785841\tvalid_1's rmse: 0.0828726\n",
      "[2650]\ttraining's rmse: 0.0785817\tvalid_1's rmse: 0.0828723\n",
      "[2675]\ttraining's rmse: 0.0785803\tvalid_1's rmse: 0.0828717\n",
      "[2700]\ttraining's rmse: 0.0785783\tvalid_1's rmse: 0.0828714\n",
      "[2725]\ttraining's rmse: 0.0785756\tvalid_1's rmse: 0.0828713\n",
      "[2750]\ttraining's rmse: 0.0785739\tvalid_1's rmse: 0.0828707\n",
      "[2775]\ttraining's rmse: 0.0785709\tvalid_1's rmse: 0.0828704\n",
      "[2800]\ttraining's rmse: 0.0785692\tvalid_1's rmse: 0.0828706\n",
      "Early stopping, best iteration is:\n",
      "[2755]\ttraining's rmse: 0.0785735\tvalid_1's rmse: 0.0828703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0814727\tvalid_1's rmse: 0.0833349\n",
      "[50]\ttraining's rmse: 0.0813531\tvalid_1's rmse: 0.0832757\n",
      "[75]\ttraining's rmse: 0.0812355\tvalid_1's rmse: 0.0832168\n",
      "[100]\ttraining's rmse: 0.0811305\tvalid_1's rmse: 0.0831652\n",
      "[125]\ttraining's rmse: 0.0810172\tvalid_1's rmse: 0.0831127\n",
      "[150]\ttraining's rmse: 0.080916\tvalid_1's rmse: 0.0830644\n",
      "[175]\ttraining's rmse: 0.0808315\tvalid_1's rmse: 0.0830254\n",
      "[200]\ttraining's rmse: 0.0807388\tvalid_1's rmse: 0.0829852\n",
      "[225]\ttraining's rmse: 0.0806514\tvalid_1's rmse: 0.0829473\n",
      "[250]\ttraining's rmse: 0.0805777\tvalid_1's rmse: 0.082914\n",
      "[275]\ttraining's rmse: 0.0805077\tvalid_1's rmse: 0.0828824\n",
      "[300]\ttraining's rmse: 0.0804354\tvalid_1's rmse: 0.0828525\n",
      "[325]\ttraining's rmse: 0.0803634\tvalid_1's rmse: 0.0828239\n",
      "[350]\ttraining's rmse: 0.0802956\tvalid_1's rmse: 0.0827975\n",
      "[375]\ttraining's rmse: 0.0802392\tvalid_1's rmse: 0.0827752\n",
      "[400]\ttraining's rmse: 0.0801783\tvalid_1's rmse: 0.0827525\n",
      "[425]\ttraining's rmse: 0.0801234\tvalid_1's rmse: 0.0827305\n",
      "[450]\ttraining's rmse: 0.0800707\tvalid_1's rmse: 0.0827103\n",
      "[475]\ttraining's rmse: 0.0800217\tvalid_1's rmse: 0.082693\n",
      "[500]\ttraining's rmse: 0.0799801\tvalid_1's rmse: 0.082675\n",
      "[525]\ttraining's rmse: 0.0799271\tvalid_1's rmse: 0.0826576\n",
      "[550]\ttraining's rmse: 0.0798797\tvalid_1's rmse: 0.082642\n",
      "[575]\ttraining's rmse: 0.0798349\tvalid_1's rmse: 0.0826276\n",
      "[600]\ttraining's rmse: 0.0797908\tvalid_1's rmse: 0.0826144\n",
      "[625]\ttraining's rmse: 0.0797561\tvalid_1's rmse: 0.082601\n",
      "[650]\ttraining's rmse: 0.0797156\tvalid_1's rmse: 0.0825883\n",
      "[675]\ttraining's rmse: 0.0796746\tvalid_1's rmse: 0.0825768\n",
      "[700]\ttraining's rmse: 0.0796394\tvalid_1's rmse: 0.0825658\n",
      "[725]\ttraining's rmse: 0.0796064\tvalid_1's rmse: 0.082556\n",
      "[750]\ttraining's rmse: 0.0795748\tvalid_1's rmse: 0.082547\n",
      "[775]\ttraining's rmse: 0.0795465\tvalid_1's rmse: 0.0825379\n",
      "[800]\ttraining's rmse: 0.079512\tvalid_1's rmse: 0.0825291\n",
      "[825]\ttraining's rmse: 0.0794836\tvalid_1's rmse: 0.0825219\n",
      "[850]\ttraining's rmse: 0.0794556\tvalid_1's rmse: 0.0825151\n",
      "[875]\ttraining's rmse: 0.0794306\tvalid_1's rmse: 0.0825086\n",
      "[900]\ttraining's rmse: 0.0794033\tvalid_1's rmse: 0.0825016\n",
      "[925]\ttraining's rmse: 0.0793787\tvalid_1's rmse: 0.0824951\n",
      "[950]\ttraining's rmse: 0.0793552\tvalid_1's rmse: 0.0824892\n",
      "[975]\ttraining's rmse: 0.0793307\tvalid_1's rmse: 0.0824838\n",
      "[1000]\ttraining's rmse: 0.0793108\tvalid_1's rmse: 0.0824787\n",
      "[1025]\ttraining's rmse: 0.0792879\tvalid_1's rmse: 0.0824739\n",
      "[1050]\ttraining's rmse: 0.0792688\tvalid_1's rmse: 0.0824694\n",
      "[1075]\ttraining's rmse: 0.0792473\tvalid_1's rmse: 0.0824653\n",
      "[1100]\ttraining's rmse: 0.079232\tvalid_1's rmse: 0.0824616\n",
      "[1125]\ttraining's rmse: 0.079214\tvalid_1's rmse: 0.0824579\n",
      "[1150]\ttraining's rmse: 0.0791974\tvalid_1's rmse: 0.0824546\n",
      "[1175]\ttraining's rmse: 0.0791821\tvalid_1's rmse: 0.0824517\n",
      "[1200]\ttraining's rmse: 0.0791677\tvalid_1's rmse: 0.0824484\n",
      "[1225]\ttraining's rmse: 0.0791538\tvalid_1's rmse: 0.0824459\n",
      "[1250]\ttraining's rmse: 0.0791401\tvalid_1's rmse: 0.0824424\n",
      "[1275]\ttraining's rmse: 0.0791244\tvalid_1's rmse: 0.0824402\n",
      "[1300]\ttraining's rmse: 0.0791136\tvalid_1's rmse: 0.0824377\n",
      "[1325]\ttraining's rmse: 0.0791012\tvalid_1's rmse: 0.0824361\n",
      "[1350]\ttraining's rmse: 0.0790877\tvalid_1's rmse: 0.0824347\n",
      "[1375]\ttraining's rmse: 0.0790767\tvalid_1's rmse: 0.0824329\n",
      "[1400]\ttraining's rmse: 0.0790671\tvalid_1's rmse: 0.0824304\n",
      "[1425]\ttraining's rmse: 0.0790548\tvalid_1's rmse: 0.0824281\n",
      "[1450]\ttraining's rmse: 0.079046\tvalid_1's rmse: 0.082427\n",
      "[1475]\ttraining's rmse: 0.0790357\tvalid_1's rmse: 0.0824251\n",
      "[1500]\ttraining's rmse: 0.0790263\tvalid_1's rmse: 0.0824237\n",
      "[1525]\ttraining's rmse: 0.0790176\tvalid_1's rmse: 0.0824219\n",
      "[1550]\ttraining's rmse: 0.0790105\tvalid_1's rmse: 0.0824207\n",
      "[1575]\ttraining's rmse: 0.0790019\tvalid_1's rmse: 0.0824196\n",
      "[1600]\ttraining's rmse: 0.0789955\tvalid_1's rmse: 0.0824186\n",
      "[1625]\ttraining's rmse: 0.0789854\tvalid_1's rmse: 0.0824173\n",
      "[1650]\ttraining's rmse: 0.0789793\tvalid_1's rmse: 0.0824165\n",
      "[1675]\ttraining's rmse: 0.0789747\tvalid_1's rmse: 0.0824154\n",
      "[1700]\ttraining's rmse: 0.0789685\tvalid_1's rmse: 0.0824139\n",
      "[1725]\ttraining's rmse: 0.0789633\tvalid_1's rmse: 0.0824131\n",
      "[1750]\ttraining's rmse: 0.0789562\tvalid_1's rmse: 0.0824126\n",
      "[1775]\ttraining's rmse: 0.0789505\tvalid_1's rmse: 0.082412\n",
      "[1800]\ttraining's rmse: 0.0789441\tvalid_1's rmse: 0.0824112\n",
      "[1825]\ttraining's rmse: 0.0789379\tvalid_1's rmse: 0.0824102\n",
      "[1850]\ttraining's rmse: 0.078932\tvalid_1's rmse: 0.0824094\n",
      "[1875]\ttraining's rmse: 0.0789277\tvalid_1's rmse: 0.082409\n",
      "[1900]\ttraining's rmse: 0.0789232\tvalid_1's rmse: 0.0824087\n",
      "[1925]\ttraining's rmse: 0.078919\tvalid_1's rmse: 0.0824083\n",
      "[1950]\ttraining's rmse: 0.0789155\tvalid_1's rmse: 0.0824074\n",
      "[1975]\ttraining's rmse: 0.0789119\tvalid_1's rmse: 0.0824071\n",
      "[2000]\ttraining's rmse: 0.0789077\tvalid_1's rmse: 0.0824068\n",
      "[2025]\ttraining's rmse: 0.0789048\tvalid_1's rmse: 0.0824066\n",
      "[2050]\ttraining's rmse: 0.078901\tvalid_1's rmse: 0.0824063\n",
      "[2075]\ttraining's rmse: 0.078898\tvalid_1's rmse: 0.0824062\n",
      "[2100]\ttraining's rmse: 0.0788953\tvalid_1's rmse: 0.0824063\n",
      "Early stopping, best iteration is:\n",
      "[2060]\ttraining's rmse: 0.0788996\tvalid_1's rmse: 0.082406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.083499\tvalid_1's rmse: 0.0792094\n",
      "[50]\ttraining's rmse: 0.083382\tvalid_1's rmse: 0.0791564\n",
      "[75]\ttraining's rmse: 0.083263\tvalid_1's rmse: 0.0791067\n",
      "[100]\ttraining's rmse: 0.0831561\tvalid_1's rmse: 0.0790619\n",
      "[125]\ttraining's rmse: 0.0830465\tvalid_1's rmse: 0.079018\n",
      "[150]\ttraining's rmse: 0.0829442\tvalid_1's rmse: 0.0789801\n",
      "[175]\ttraining's rmse: 0.0828615\tvalid_1's rmse: 0.0789489\n",
      "[200]\ttraining's rmse: 0.0827726\tvalid_1's rmse: 0.0789171\n",
      "[225]\ttraining's rmse: 0.0826853\tvalid_1's rmse: 0.0788862\n",
      "[250]\ttraining's rmse: 0.0826103\tvalid_1's rmse: 0.0788595\n",
      "[275]\ttraining's rmse: 0.0825437\tvalid_1's rmse: 0.0788335\n",
      "[300]\ttraining's rmse: 0.0824761\tvalid_1's rmse: 0.0788126\n",
      "[325]\ttraining's rmse: 0.0824078\tvalid_1's rmse: 0.0787907\n",
      "[350]\ttraining's rmse: 0.0823416\tvalid_1's rmse: 0.0787692\n",
      "[375]\ttraining's rmse: 0.0822871\tvalid_1's rmse: 0.0787519\n",
      "[400]\ttraining's rmse: 0.0822276\tvalid_1's rmse: 0.0787341\n",
      "[425]\ttraining's rmse: 0.0821743\tvalid_1's rmse: 0.0787182\n",
      "[450]\ttraining's rmse: 0.0821267\tvalid_1's rmse: 0.0787026\n",
      "[475]\ttraining's rmse: 0.08208\tvalid_1's rmse: 0.0786886\n",
      "[500]\ttraining's rmse: 0.0820413\tvalid_1's rmse: 0.0786759\n",
      "[525]\ttraining's rmse: 0.0819908\tvalid_1's rmse: 0.0786624\n",
      "[550]\ttraining's rmse: 0.081943\tvalid_1's rmse: 0.0786595\n",
      "[575]\ttraining's rmse: 0.0819011\tvalid_1's rmse: 0.0786484\n",
      "[600]\ttraining's rmse: 0.0818583\tvalid_1's rmse: 0.078638\n",
      "[625]\ttraining's rmse: 0.0818253\tvalid_1's rmse: 0.078634\n",
      "[650]\ttraining's rmse: 0.0817839\tvalid_1's rmse: 0.0786289\n",
      "[675]\ttraining's rmse: 0.0817411\tvalid_1's rmse: 0.0786264\n",
      "[700]\ttraining's rmse: 0.0817061\tvalid_1's rmse: 0.0786179\n",
      "[725]\ttraining's rmse: 0.0816744\tvalid_1's rmse: 0.0786183\n",
      "[750]\ttraining's rmse: 0.0816424\tvalid_1's rmse: 0.0786264\n",
      "[775]\ttraining's rmse: 0.0816146\tvalid_1's rmse: 0.0786262\n",
      "Early stopping, best iteration is:\n",
      "[748]\ttraining's rmse: 0.0816472\tvalid_1's rmse: 0.0786148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876977\tvalid_1's rmse: 0.0890518\n",
      "[50]\ttraining's rmse: 0.0875032\tvalid_1's rmse: 0.0889989\n",
      "[75]\ttraining's rmse: 0.0873087\tvalid_1's rmse: 0.0889453\n",
      "[100]\ttraining's rmse: 0.0871297\tvalid_1's rmse: 0.0888995\n",
      "[125]\ttraining's rmse: 0.0869604\tvalid_1's rmse: 0.0888564\n",
      "[150]\ttraining's rmse: 0.0868009\tvalid_1's rmse: 0.0888159\n",
      "[175]\ttraining's rmse: 0.0866649\tvalid_1's rmse: 0.0887792\n",
      "[200]\ttraining's rmse: 0.0865257\tvalid_1's rmse: 0.0887439\n",
      "[225]\ttraining's rmse: 0.0863923\tvalid_1's rmse: 0.08871\n",
      "[250]\ttraining's rmse: 0.0862736\tvalid_1's rmse: 0.0886783\n",
      "[275]\ttraining's rmse: 0.0861635\tvalid_1's rmse: 0.0886481\n",
      "[300]\ttraining's rmse: 0.0860584\tvalid_1's rmse: 0.088621\n",
      "[325]\ttraining's rmse: 0.0859546\tvalid_1's rmse: 0.0885968\n",
      "[350]\ttraining's rmse: 0.0858526\tvalid_1's rmse: 0.0885737\n",
      "[375]\ttraining's rmse: 0.0857609\tvalid_1's rmse: 0.0885544\n",
      "[400]\ttraining's rmse: 0.0856728\tvalid_1's rmse: 0.0885343\n",
      "[425]\ttraining's rmse: 0.0855912\tvalid_1's rmse: 0.0885143\n",
      "[450]\ttraining's rmse: 0.0855167\tvalid_1's rmse: 0.0884951\n",
      "[475]\ttraining's rmse: 0.0854502\tvalid_1's rmse: 0.0884784\n",
      "[500]\ttraining's rmse: 0.0853941\tvalid_1's rmse: 0.088463\n",
      "[525]\ttraining's rmse: 0.085321\tvalid_1's rmse: 0.0884467\n",
      "[550]\ttraining's rmse: 0.0852572\tvalid_1's rmse: 0.0884314\n",
      "[575]\ttraining's rmse: 0.0851994\tvalid_1's rmse: 0.0884194\n",
      "[600]\ttraining's rmse: 0.0851392\tvalid_1's rmse: 0.088406\n",
      "[625]\ttraining's rmse: 0.0850881\tvalid_1's rmse: 0.0883943\n",
      "[650]\ttraining's rmse: 0.0850359\tvalid_1's rmse: 0.088382\n",
      "[675]\ttraining's rmse: 0.0849844\tvalid_1's rmse: 0.0883715\n",
      "[700]\ttraining's rmse: 0.0849361\tvalid_1's rmse: 0.0883606\n",
      "[725]\ttraining's rmse: 0.0848935\tvalid_1's rmse: 0.0883515\n",
      "[750]\ttraining's rmse: 0.0848508\tvalid_1's rmse: 0.0883431\n",
      "[775]\ttraining's rmse: 0.084814\tvalid_1's rmse: 0.0883327\n",
      "[800]\ttraining's rmse: 0.0847693\tvalid_1's rmse: 0.0883243\n",
      "[825]\ttraining's rmse: 0.0847357\tvalid_1's rmse: 0.0883147\n",
      "[850]\ttraining's rmse: 0.0846978\tvalid_1's rmse: 0.0883068\n",
      "[875]\ttraining's rmse: 0.0846644\tvalid_1's rmse: 0.0882996\n",
      "[900]\ttraining's rmse: 0.0846273\tvalid_1's rmse: 0.088292\n",
      "[925]\ttraining's rmse: 0.0845991\tvalid_1's rmse: 0.0882851\n",
      "[950]\ttraining's rmse: 0.0845697\tvalid_1's rmse: 0.088278\n",
      "[975]\ttraining's rmse: 0.0845424\tvalid_1's rmse: 0.0882723\n",
      "[1000]\ttraining's rmse: 0.0845163\tvalid_1's rmse: 0.0882678\n",
      "[1025]\ttraining's rmse: 0.0844885\tvalid_1's rmse: 0.0882622\n",
      "[1050]\ttraining's rmse: 0.0844669\tvalid_1's rmse: 0.0882572\n",
      "[1075]\ttraining's rmse: 0.0844416\tvalid_1's rmse: 0.0882517\n",
      "[1100]\ttraining's rmse: 0.0844202\tvalid_1's rmse: 0.0882467\n",
      "[1125]\ttraining's rmse: 0.0844003\tvalid_1's rmse: 0.0882411\n",
      "[1150]\ttraining's rmse: 0.0843793\tvalid_1's rmse: 0.0882377\n",
      "[1175]\ttraining's rmse: 0.0843613\tvalid_1's rmse: 0.0882337\n",
      "[1200]\ttraining's rmse: 0.0843436\tvalid_1's rmse: 0.0882295\n",
      "[1225]\ttraining's rmse: 0.0843238\tvalid_1's rmse: 0.0882254\n",
      "[1250]\ttraining's rmse: 0.0843065\tvalid_1's rmse: 0.088221\n",
      "[1275]\ttraining's rmse: 0.0842906\tvalid_1's rmse: 0.0882186\n",
      "[1300]\ttraining's rmse: 0.0842762\tvalid_1's rmse: 0.0882139\n",
      "[1325]\ttraining's rmse: 0.08426\tvalid_1's rmse: 0.0882111\n",
      "[1350]\ttraining's rmse: 0.084245\tvalid_1's rmse: 0.0882088\n",
      "[1375]\ttraining's rmse: 0.0842318\tvalid_1's rmse: 0.0882047\n",
      "[1400]\ttraining's rmse: 0.0842173\tvalid_1's rmse: 0.0882007\n",
      "[1425]\ttraining's rmse: 0.0841998\tvalid_1's rmse: 0.088198\n",
      "[1450]\ttraining's rmse: 0.0841849\tvalid_1's rmse: 0.0881955\n",
      "[1475]\ttraining's rmse: 0.0841706\tvalid_1's rmse: 0.0881915\n",
      "[1500]\ttraining's rmse: 0.0841594\tvalid_1's rmse: 0.0881891\n",
      "[1525]\ttraining's rmse: 0.0841484\tvalid_1's rmse: 0.088186\n",
      "[1550]\ttraining's rmse: 0.084138\tvalid_1's rmse: 0.0881838\n",
      "[1575]\ttraining's rmse: 0.0841295\tvalid_1's rmse: 0.0881806\n",
      "[1600]\ttraining's rmse: 0.0841215\tvalid_1's rmse: 0.0881784\n",
      "[1625]\ttraining's rmse: 0.0841104\tvalid_1's rmse: 0.0881761\n",
      "[1650]\ttraining's rmse: 0.0841023\tvalid_1's rmse: 0.0881736\n",
      "[1675]\ttraining's rmse: 0.0840966\tvalid_1's rmse: 0.0881718\n",
      "[1700]\ttraining's rmse: 0.0840879\tvalid_1's rmse: 0.0881696\n",
      "[1725]\ttraining's rmse: 0.0840819\tvalid_1's rmse: 0.0881686\n",
      "[1750]\ttraining's rmse: 0.0840762\tvalid_1's rmse: 0.0881665\n",
      "[1775]\ttraining's rmse: 0.0840698\tvalid_1's rmse: 0.0881653\n",
      "[1800]\ttraining's rmse: 0.0840631\tvalid_1's rmse: 0.0881636\n",
      "[1825]\ttraining's rmse: 0.0840559\tvalid_1's rmse: 0.0881626\n",
      "[1850]\ttraining's rmse: 0.0840478\tvalid_1's rmse: 0.0881605\n",
      "[1875]\ttraining's rmse: 0.084042\tvalid_1's rmse: 0.0881589\n",
      "[1900]\ttraining's rmse: 0.0840363\tvalid_1's rmse: 0.0881572\n",
      "[1925]\ttraining's rmse: 0.0840311\tvalid_1's rmse: 0.088156\n",
      "[1950]\ttraining's rmse: 0.0840259\tvalid_1's rmse: 0.0881542\n",
      "[1975]\ttraining's rmse: 0.0840207\tvalid_1's rmse: 0.0881528\n",
      "[2000]\ttraining's rmse: 0.0840155\tvalid_1's rmse: 0.0881518\n",
      "[2025]\ttraining's rmse: 0.0840105\tvalid_1's rmse: 0.08815\n",
      "[2050]\ttraining's rmse: 0.0840062\tvalid_1's rmse: 0.0881499\n",
      "[2075]\ttraining's rmse: 0.0840025\tvalid_1's rmse: 0.0881484\n",
      "[2100]\ttraining's rmse: 0.0839997\tvalid_1's rmse: 0.0881475\n",
      "[2125]\ttraining's rmse: 0.0839954\tvalid_1's rmse: 0.0881464\n",
      "[2150]\ttraining's rmse: 0.0839905\tvalid_1's rmse: 0.088146\n",
      "[2175]\ttraining's rmse: 0.0839867\tvalid_1's rmse: 0.0881448\n",
      "[2200]\ttraining's rmse: 0.0839845\tvalid_1's rmse: 0.0881444\n",
      "[2225]\ttraining's rmse: 0.0839804\tvalid_1's rmse: 0.0881439\n",
      "[2250]\ttraining's rmse: 0.0839776\tvalid_1's rmse: 0.0881436\n",
      "[2275]\ttraining's rmse: 0.0839742\tvalid_1's rmse: 0.0881431\n",
      "[2300]\ttraining's rmse: 0.0839712\tvalid_1's rmse: 0.0881423\n",
      "[2325]\ttraining's rmse: 0.0839682\tvalid_1's rmse: 0.0881416\n",
      "[2350]\ttraining's rmse: 0.0839651\tvalid_1's rmse: 0.0881409\n",
      "[2375]\ttraining's rmse: 0.0839624\tvalid_1's rmse: 0.0881395\n",
      "[2400]\ttraining's rmse: 0.0839596\tvalid_1's rmse: 0.088139\n",
      "[2425]\ttraining's rmse: 0.0839563\tvalid_1's rmse: 0.0881374\n",
      "[2450]\ttraining's rmse: 0.0839542\tvalid_1's rmse: 0.0881369\n",
      "[2475]\ttraining's rmse: 0.0839489\tvalid_1's rmse: 0.0881364\n",
      "[2500]\ttraining's rmse: 0.0839456\tvalid_1's rmse: 0.088136\n",
      "[2525]\ttraining's rmse: 0.0839428\tvalid_1's rmse: 0.0881355\n",
      "[2550]\ttraining's rmse: 0.0839405\tvalid_1's rmse: 0.0881352\n",
      "[2575]\ttraining's rmse: 0.0839381\tvalid_1's rmse: 0.0881341\n",
      "[2600]\ttraining's rmse: 0.0839354\tvalid_1's rmse: 0.0881337\n",
      "[2625]\ttraining's rmse: 0.083933\tvalid_1's rmse: 0.0881331\n",
      "[2650]\ttraining's rmse: 0.0839308\tvalid_1's rmse: 0.0881329\n",
      "[2675]\ttraining's rmse: 0.0839289\tvalid_1's rmse: 0.0881315\n",
      "[2700]\ttraining's rmse: 0.083927\tvalid_1's rmse: 0.0881301\n",
      "[2725]\ttraining's rmse: 0.0839247\tvalid_1's rmse: 0.0881298\n",
      "[2750]\ttraining's rmse: 0.0839224\tvalid_1's rmse: 0.0881292\n",
      "[2775]\ttraining's rmse: 0.08392\tvalid_1's rmse: 0.0881292\n",
      "[2800]\ttraining's rmse: 0.0839179\tvalid_1's rmse: 0.0881287\n",
      "[2825]\ttraining's rmse: 0.0839144\tvalid_1's rmse: 0.088128\n",
      "[2850]\ttraining's rmse: 0.0839129\tvalid_1's rmse: 0.0881281\n",
      "Early stopping, best iteration is:\n",
      "[2812]\ttraining's rmse: 0.083916\tvalid_1's rmse: 0.0881277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876952\tvalid_1's rmse: 0.0890954\n",
      "[50]\ttraining's rmse: 0.0875256\tvalid_1's rmse: 0.0890401\n",
      "[75]\ttraining's rmse: 0.0873541\tvalid_1's rmse: 0.0889816\n",
      "[100]\ttraining's rmse: 0.0872013\tvalid_1's rmse: 0.0889312\n",
      "[125]\ttraining's rmse: 0.0870477\tvalid_1's rmse: 0.0888813\n",
      "[150]\ttraining's rmse: 0.0869063\tvalid_1's rmse: 0.0888348\n",
      "[175]\ttraining's rmse: 0.0867833\tvalid_1's rmse: 0.088795\n",
      "[200]\ttraining's rmse: 0.0866555\tvalid_1's rmse: 0.0887528\n",
      "[225]\ttraining's rmse: 0.0865348\tvalid_1's rmse: 0.0887154\n",
      "[250]\ttraining's rmse: 0.0864299\tvalid_1's rmse: 0.0886801\n",
      "[275]\ttraining's rmse: 0.0863316\tvalid_1's rmse: 0.0886493\n",
      "[300]\ttraining's rmse: 0.0862397\tvalid_1's rmse: 0.0886201\n",
      "[325]\ttraining's rmse: 0.0861478\tvalid_1's rmse: 0.0885918\n",
      "[350]\ttraining's rmse: 0.0860561\tvalid_1's rmse: 0.0885648\n",
      "[375]\ttraining's rmse: 0.0859816\tvalid_1's rmse: 0.0885439\n",
      "[400]\ttraining's rmse: 0.0859008\tvalid_1's rmse: 0.0885226\n",
      "[425]\ttraining's rmse: 0.0858285\tvalid_1's rmse: 0.0885006\n",
      "[450]\ttraining's rmse: 0.0857631\tvalid_1's rmse: 0.0884812\n",
      "[475]\ttraining's rmse: 0.0857012\tvalid_1's rmse: 0.0884619\n",
      "[500]\ttraining's rmse: 0.0856467\tvalid_1's rmse: 0.0884438\n",
      "[525]\ttraining's rmse: 0.0855808\tvalid_1's rmse: 0.0884265\n",
      "[550]\ttraining's rmse: 0.0855197\tvalid_1's rmse: 0.0884107\n",
      "[575]\ttraining's rmse: 0.0854656\tvalid_1's rmse: 0.0883954\n",
      "[600]\ttraining's rmse: 0.0854132\tvalid_1's rmse: 0.0883822\n",
      "[625]\ttraining's rmse: 0.0853681\tvalid_1's rmse: 0.0883693\n",
      "[650]\ttraining's rmse: 0.0853193\tvalid_1's rmse: 0.088357\n",
      "[675]\ttraining's rmse: 0.0852703\tvalid_1's rmse: 0.0883455\n",
      "[700]\ttraining's rmse: 0.0852265\tvalid_1's rmse: 0.0883335\n",
      "[725]\ttraining's rmse: 0.0851876\tvalid_1's rmse: 0.0883233\n",
      "[750]\ttraining's rmse: 0.0851488\tvalid_1's rmse: 0.0883131\n",
      "[775]\ttraining's rmse: 0.0851181\tvalid_1's rmse: 0.0883025\n",
      "[800]\ttraining's rmse: 0.0850771\tvalid_1's rmse: 0.0882933\n",
      "[825]\ttraining's rmse: 0.0850436\tvalid_1's rmse: 0.0882849\n",
      "[850]\ttraining's rmse: 0.085011\tvalid_1's rmse: 0.0882783\n",
      "[875]\ttraining's rmse: 0.0849799\tvalid_1's rmse: 0.0882715\n",
      "[900]\ttraining's rmse: 0.0849458\tvalid_1's rmse: 0.0882639\n",
      "[925]\ttraining's rmse: 0.0849166\tvalid_1's rmse: 0.0882573\n",
      "[950]\ttraining's rmse: 0.0848899\tvalid_1's rmse: 0.0882506\n",
      "[975]\ttraining's rmse: 0.0848652\tvalid_1's rmse: 0.0882447\n",
      "[1000]\ttraining's rmse: 0.0848407\tvalid_1's rmse: 0.08824\n",
      "[1025]\ttraining's rmse: 0.0848132\tvalid_1's rmse: 0.088235\n",
      "[1050]\ttraining's rmse: 0.0847897\tvalid_1's rmse: 0.0882293\n",
      "[1075]\ttraining's rmse: 0.0847652\tvalid_1's rmse: 0.088225\n",
      "[1100]\ttraining's rmse: 0.084746\tvalid_1's rmse: 0.088221\n",
      "[1125]\ttraining's rmse: 0.0847245\tvalid_1's rmse: 0.0882173\n",
      "[1150]\ttraining's rmse: 0.0847029\tvalid_1's rmse: 0.0882137\n",
      "[1175]\ttraining's rmse: 0.0846866\tvalid_1's rmse: 0.0882113\n",
      "[1200]\ttraining's rmse: 0.0846681\tvalid_1's rmse: 0.0882074\n",
      "[1225]\ttraining's rmse: 0.0846497\tvalid_1's rmse: 0.0882037\n",
      "[1250]\ttraining's rmse: 0.084633\tvalid_1's rmse: 0.0881999\n",
      "[1275]\ttraining's rmse: 0.084615\tvalid_1's rmse: 0.0881981\n",
      "[1300]\ttraining's rmse: 0.0846013\tvalid_1's rmse: 0.088195\n",
      "[1325]\ttraining's rmse: 0.0845856\tvalid_1's rmse: 0.0881928\n",
      "[1350]\ttraining's rmse: 0.0845672\tvalid_1's rmse: 0.088191\n",
      "[1375]\ttraining's rmse: 0.0845532\tvalid_1's rmse: 0.0881891\n",
      "[1400]\ttraining's rmse: 0.0845379\tvalid_1's rmse: 0.0881875\n",
      "[1425]\ttraining's rmse: 0.0845207\tvalid_1's rmse: 0.0881863\n",
      "[1450]\ttraining's rmse: 0.0845062\tvalid_1's rmse: 0.0881853\n",
      "[1475]\ttraining's rmse: 0.0844944\tvalid_1's rmse: 0.0881839\n",
      "[1500]\ttraining's rmse: 0.084486\tvalid_1's rmse: 0.0881822\n",
      "[1525]\ttraining's rmse: 0.0844752\tvalid_1's rmse: 0.0881802\n",
      "[1550]\ttraining's rmse: 0.0844616\tvalid_1's rmse: 0.088179\n",
      "[1575]\ttraining's rmse: 0.0844523\tvalid_1's rmse: 0.0881777\n",
      "[1600]\ttraining's rmse: 0.0844442\tvalid_1's rmse: 0.0881769\n",
      "[1625]\ttraining's rmse: 0.0844365\tvalid_1's rmse: 0.0881754\n",
      "[1650]\ttraining's rmse: 0.0844286\tvalid_1's rmse: 0.0881745\n",
      "[1675]\ttraining's rmse: 0.0844203\tvalid_1's rmse: 0.0881738\n",
      "[1700]\ttraining's rmse: 0.0844134\tvalid_1's rmse: 0.0881723\n",
      "[1725]\ttraining's rmse: 0.084406\tvalid_1's rmse: 0.088171\n",
      "[1750]\ttraining's rmse: 0.0843976\tvalid_1's rmse: 0.0881702\n",
      "[1775]\ttraining's rmse: 0.0843913\tvalid_1's rmse: 0.0881699\n",
      "[1800]\ttraining's rmse: 0.0843842\tvalid_1's rmse: 0.0881693\n",
      "[1825]\ttraining's rmse: 0.084377\tvalid_1's rmse: 0.0881691\n",
      "[1850]\ttraining's rmse: 0.084371\tvalid_1's rmse: 0.0881685\n",
      "[1875]\ttraining's rmse: 0.0843661\tvalid_1's rmse: 0.0881681\n",
      "[1900]\ttraining's rmse: 0.0843615\tvalid_1's rmse: 0.0881678\n",
      "[1925]\ttraining's rmse: 0.0843559\tvalid_1's rmse: 0.0881673\n",
      "[1950]\ttraining's rmse: 0.0843518\tvalid_1's rmse: 0.0881667\n",
      "[1975]\ttraining's rmse: 0.0843466\tvalid_1's rmse: 0.0881659\n",
      "[2000]\ttraining's rmse: 0.0843423\tvalid_1's rmse: 0.0881654\n",
      "[2025]\ttraining's rmse: 0.0843391\tvalid_1's rmse: 0.0881649\n",
      "[2050]\ttraining's rmse: 0.0843336\tvalid_1's rmse: 0.0881642\n",
      "[2075]\ttraining's rmse: 0.0843308\tvalid_1's rmse: 0.0881639\n",
      "[2100]\ttraining's rmse: 0.0843266\tvalid_1's rmse: 0.0881635\n",
      "[2125]\ttraining's rmse: 0.0843233\tvalid_1's rmse: 0.0881631\n",
      "[2150]\ttraining's rmse: 0.0843204\tvalid_1's rmse: 0.0881629\n",
      "[2175]\ttraining's rmse: 0.084316\tvalid_1's rmse: 0.0881626\n",
      "[2200]\ttraining's rmse: 0.0843126\tvalid_1's rmse: 0.0881622\n",
      "[2225]\ttraining's rmse: 0.0843079\tvalid_1's rmse: 0.0881614\n",
      "[2250]\ttraining's rmse: 0.0843035\tvalid_1's rmse: 0.0881611\n",
      "[2275]\ttraining's rmse: 0.0842998\tvalid_1's rmse: 0.0881608\n",
      "[2300]\ttraining's rmse: 0.0842976\tvalid_1's rmse: 0.0881605\n",
      "[2325]\ttraining's rmse: 0.0842938\tvalid_1's rmse: 0.0881603\n",
      "[2350]\ttraining's rmse: 0.0842914\tvalid_1's rmse: 0.0881606\n",
      "Early stopping, best iteration is:\n",
      "[2309]\ttraining's rmse: 0.0842963\tvalid_1's rmse: 0.0881602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0889298\tvalid_1's rmse: 0.086666\n",
      "[50]\ttraining's rmse: 0.0887934\tvalid_1's rmse: 0.0866145\n",
      "[75]\ttraining's rmse: 0.0886512\tvalid_1's rmse: 0.0865624\n",
      "[100]\ttraining's rmse: 0.0885227\tvalid_1's rmse: 0.0865164\n",
      "[125]\ttraining's rmse: 0.0883897\tvalid_1's rmse: 0.0864713\n",
      "[150]\ttraining's rmse: 0.0882694\tvalid_1's rmse: 0.0864302\n",
      "[175]\ttraining's rmse: 0.0881678\tvalid_1's rmse: 0.086396\n",
      "[200]\ttraining's rmse: 0.0880539\tvalid_1's rmse: 0.0863628\n",
      "[225]\ttraining's rmse: 0.0879469\tvalid_1's rmse: 0.0863314\n",
      "[250]\ttraining's rmse: 0.0878572\tvalid_1's rmse: 0.0863042\n",
      "[275]\ttraining's rmse: 0.0877755\tvalid_1's rmse: 0.0862785\n",
      "[300]\ttraining's rmse: 0.0876904\tvalid_1's rmse: 0.0862566\n",
      "[325]\ttraining's rmse: 0.0876056\tvalid_1's rmse: 0.0862346\n",
      "[350]\ttraining's rmse: 0.0875257\tvalid_1's rmse: 0.0862129\n",
      "[375]\ttraining's rmse: 0.0874575\tvalid_1's rmse: 0.0861951\n",
      "[400]\ttraining's rmse: 0.0873847\tvalid_1's rmse: 0.0861769\n",
      "[425]\ttraining's rmse: 0.0873197\tvalid_1's rmse: 0.0861607\n",
      "[450]\ttraining's rmse: 0.0872555\tvalid_1's rmse: 0.0861453\n",
      "[475]\ttraining's rmse: 0.0871971\tvalid_1's rmse: 0.0861329\n",
      "[500]\ttraining's rmse: 0.0871492\tvalid_1's rmse: 0.0861202\n",
      "[525]\ttraining's rmse: 0.0870861\tvalid_1's rmse: 0.086111\n",
      "[550]\ttraining's rmse: 0.0870281\tvalid_1's rmse: 0.0860989\n",
      "[575]\ttraining's rmse: 0.0869742\tvalid_1's rmse: 0.0860935\n",
      "[600]\ttraining's rmse: 0.0869233\tvalid_1's rmse: 0.0860851\n",
      "[625]\ttraining's rmse: 0.0868805\tvalid_1's rmse: 0.0860771\n",
      "[650]\ttraining's rmse: 0.0868291\tvalid_1's rmse: 0.0860734\n",
      "[675]\ttraining's rmse: 0.0867797\tvalid_1's rmse: 0.086071\n",
      "[700]\ttraining's rmse: 0.0867357\tvalid_1's rmse: 0.0860646\n",
      "[725]\ttraining's rmse: 0.0866958\tvalid_1's rmse: 0.0860665\n",
      "[750]\ttraining's rmse: 0.0866569\tvalid_1's rmse: 0.0860654\n",
      "Early stopping, best iteration is:\n",
      "[708]\ttraining's rmse: 0.0867227\tvalid_1's rmse: 0.0860627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0815573\tvalid_1's rmse: 0.0844155\n",
      "[50]\ttraining's rmse: 0.0814342\tvalid_1's rmse: 0.0843552\n",
      "[75]\ttraining's rmse: 0.0813095\tvalid_1's rmse: 0.0842966\n",
      "[100]\ttraining's rmse: 0.0811964\tvalid_1's rmse: 0.0842476\n",
      "[125]\ttraining's rmse: 0.0810801\tvalid_1's rmse: 0.0841958\n",
      "[150]\ttraining's rmse: 0.0809777\tvalid_1's rmse: 0.0841478\n",
      "[175]\ttraining's rmse: 0.0808938\tvalid_1's rmse: 0.0841086\n",
      "[200]\ttraining's rmse: 0.0808029\tvalid_1's rmse: 0.0840669\n",
      "[225]\ttraining's rmse: 0.0807122\tvalid_1's rmse: 0.0840295\n",
      "[250]\ttraining's rmse: 0.0806348\tvalid_1's rmse: 0.0839937\n",
      "[275]\ttraining's rmse: 0.0805644\tvalid_1's rmse: 0.0839602\n",
      "[300]\ttraining's rmse: 0.0804952\tvalid_1's rmse: 0.0839286\n",
      "[325]\ttraining's rmse: 0.0804234\tvalid_1's rmse: 0.0839014\n",
      "[350]\ttraining's rmse: 0.0803531\tvalid_1's rmse: 0.0838724\n",
      "[375]\ttraining's rmse: 0.0802972\tvalid_1's rmse: 0.0838494\n",
      "[400]\ttraining's rmse: 0.0802378\tvalid_1's rmse: 0.083827\n",
      "[425]\ttraining's rmse: 0.0801811\tvalid_1's rmse: 0.0838025\n",
      "[450]\ttraining's rmse: 0.0801304\tvalid_1's rmse: 0.0837808\n",
      "[475]\ttraining's rmse: 0.0800828\tvalid_1's rmse: 0.0837585\n",
      "[500]\ttraining's rmse: 0.0800418\tvalid_1's rmse: 0.0837397\n",
      "[525]\ttraining's rmse: 0.0799942\tvalid_1's rmse: 0.0837223\n",
      "[550]\ttraining's rmse: 0.0799476\tvalid_1's rmse: 0.0837061\n",
      "[575]\ttraining's rmse: 0.0799051\tvalid_1's rmse: 0.0836916\n",
      "[600]\ttraining's rmse: 0.0798625\tvalid_1's rmse: 0.0836748\n",
      "[625]\ttraining's rmse: 0.0798298\tvalid_1's rmse: 0.0836615\n",
      "[650]\ttraining's rmse: 0.0797901\tvalid_1's rmse: 0.0836464\n",
      "[675]\ttraining's rmse: 0.0797505\tvalid_1's rmse: 0.0836322\n",
      "[700]\ttraining's rmse: 0.0797153\tvalid_1's rmse: 0.0836193\n",
      "[725]\ttraining's rmse: 0.0796813\tvalid_1's rmse: 0.0836077\n",
      "[750]\ttraining's rmse: 0.0796492\tvalid_1's rmse: 0.0835963\n",
      "[775]\ttraining's rmse: 0.0796237\tvalid_1's rmse: 0.0835838\n",
      "[800]\ttraining's rmse: 0.0795914\tvalid_1's rmse: 0.0835736\n",
      "[825]\ttraining's rmse: 0.0795659\tvalid_1's rmse: 0.0835632\n",
      "[850]\ttraining's rmse: 0.0795362\tvalid_1's rmse: 0.0835532\n",
      "[875]\ttraining's rmse: 0.0795113\tvalid_1's rmse: 0.0835441\n",
      "[900]\ttraining's rmse: 0.0794844\tvalid_1's rmse: 0.0835344\n",
      "[925]\ttraining's rmse: 0.0794614\tvalid_1's rmse: 0.0835269\n",
      "[950]\ttraining's rmse: 0.0794403\tvalid_1's rmse: 0.0835196\n",
      "[975]\ttraining's rmse: 0.0794185\tvalid_1's rmse: 0.0835127\n",
      "[1000]\ttraining's rmse: 0.0793973\tvalid_1's rmse: 0.0835056\n",
      "[1025]\ttraining's rmse: 0.0793734\tvalid_1's rmse: 0.0834979\n",
      "[1050]\ttraining's rmse: 0.0793543\tvalid_1's rmse: 0.0834914\n",
      "[1075]\ttraining's rmse: 0.0793346\tvalid_1's rmse: 0.0834857\n",
      "[1100]\ttraining's rmse: 0.0793184\tvalid_1's rmse: 0.0834796\n",
      "[1125]\ttraining's rmse: 0.0793033\tvalid_1's rmse: 0.0834732\n",
      "[1150]\ttraining's rmse: 0.0792845\tvalid_1's rmse: 0.0834679\n",
      "[1175]\ttraining's rmse: 0.0792675\tvalid_1's rmse: 0.083463\n",
      "[1200]\ttraining's rmse: 0.0792545\tvalid_1's rmse: 0.0834582\n",
      "[1225]\ttraining's rmse: 0.0792395\tvalid_1's rmse: 0.0834531\n",
      "[1250]\ttraining's rmse: 0.0792243\tvalid_1's rmse: 0.08345\n",
      "[1275]\ttraining's rmse: 0.0792047\tvalid_1's rmse: 0.0834454\n",
      "[1300]\ttraining's rmse: 0.0791923\tvalid_1's rmse: 0.0834404\n",
      "[1325]\ttraining's rmse: 0.07918\tvalid_1's rmse: 0.0834359\n",
      "[1350]\ttraining's rmse: 0.0791686\tvalid_1's rmse: 0.0834331\n",
      "[1375]\ttraining's rmse: 0.0791573\tvalid_1's rmse: 0.0834298\n",
      "[1400]\ttraining's rmse: 0.0791465\tvalid_1's rmse: 0.0834258\n",
      "[1425]\ttraining's rmse: 0.0791346\tvalid_1's rmse: 0.0834239\n",
      "[1450]\ttraining's rmse: 0.0791232\tvalid_1's rmse: 0.0834218\n",
      "[1475]\ttraining's rmse: 0.0791146\tvalid_1's rmse: 0.0834186\n",
      "[1500]\ttraining's rmse: 0.0791056\tvalid_1's rmse: 0.0834158\n",
      "[1525]\ttraining's rmse: 0.0790968\tvalid_1's rmse: 0.0834138\n",
      "[1550]\ttraining's rmse: 0.0790889\tvalid_1's rmse: 0.0834111\n",
      "[1575]\ttraining's rmse: 0.0790812\tvalid_1's rmse: 0.0834077\n",
      "[1600]\ttraining's rmse: 0.0790755\tvalid_1's rmse: 0.0834058\n",
      "[1625]\ttraining's rmse: 0.07907\tvalid_1's rmse: 0.0834035\n",
      "[1650]\ttraining's rmse: 0.0790638\tvalid_1's rmse: 0.0834012\n",
      "[1675]\ttraining's rmse: 0.079057\tvalid_1's rmse: 0.0833995\n",
      "[1700]\ttraining's rmse: 0.0790505\tvalid_1's rmse: 0.0833981\n",
      "[1725]\ttraining's rmse: 0.0790455\tvalid_1's rmse: 0.0833962\n",
      "[1750]\ttraining's rmse: 0.0790387\tvalid_1's rmse: 0.0833948\n",
      "[1775]\ttraining's rmse: 0.0790314\tvalid_1's rmse: 0.083394\n",
      "[1800]\ttraining's rmse: 0.0790272\tvalid_1's rmse: 0.0833927\n",
      "[1825]\ttraining's rmse: 0.079022\tvalid_1's rmse: 0.0833929\n",
      "[1850]\ttraining's rmse: 0.0790176\tvalid_1's rmse: 0.0833916\n",
      "[1875]\ttraining's rmse: 0.0790133\tvalid_1's rmse: 0.083391\n",
      "[1900]\ttraining's rmse: 0.0790093\tvalid_1's rmse: 0.0833908\n",
      "[1925]\ttraining's rmse: 0.0790049\tvalid_1's rmse: 0.0833905\n",
      "[1950]\ttraining's rmse: 0.0790019\tvalid_1's rmse: 0.0833884\n",
      "[1975]\ttraining's rmse: 0.0789984\tvalid_1's rmse: 0.0833876\n",
      "[2000]\ttraining's rmse: 0.0789949\tvalid_1's rmse: 0.083386\n",
      "[2025]\ttraining's rmse: 0.078992\tvalid_1's rmse: 0.0833848\n",
      "[2050]\ttraining's rmse: 0.078988\tvalid_1's rmse: 0.0833843\n",
      "[2075]\ttraining's rmse: 0.0789847\tvalid_1's rmse: 0.0833831\n",
      "[2100]\ttraining's rmse: 0.0789821\tvalid_1's rmse: 0.0833821\n",
      "[2125]\ttraining's rmse: 0.0789792\tvalid_1's rmse: 0.0833815\n",
      "[2150]\ttraining's rmse: 0.0789758\tvalid_1's rmse: 0.0833814\n",
      "Early stopping, best iteration is:\n",
      "[2112]\ttraining's rmse: 0.0789803\tvalid_1's rmse: 0.0833813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0819486\tvalid_1's rmse: 0.0836402\n",
      "[50]\ttraining's rmse: 0.0818292\tvalid_1's rmse: 0.0835805\n",
      "[75]\ttraining's rmse: 0.0817081\tvalid_1's rmse: 0.083523\n",
      "[100]\ttraining's rmse: 0.0816004\tvalid_1's rmse: 0.0834712\n",
      "[125]\ttraining's rmse: 0.0814852\tvalid_1's rmse: 0.0834182\n",
      "[150]\ttraining's rmse: 0.0813836\tvalid_1's rmse: 0.0833707\n",
      "[175]\ttraining's rmse: 0.0812973\tvalid_1's rmse: 0.0833298\n",
      "[200]\ttraining's rmse: 0.0812035\tvalid_1's rmse: 0.0832901\n",
      "[225]\ttraining's rmse: 0.0811161\tvalid_1's rmse: 0.0832536\n",
      "[250]\ttraining's rmse: 0.0810421\tvalid_1's rmse: 0.0832206\n",
      "[275]\ttraining's rmse: 0.0809719\tvalid_1's rmse: 0.0831876\n",
      "[300]\ttraining's rmse: 0.0809015\tvalid_1's rmse: 0.0831578\n",
      "[325]\ttraining's rmse: 0.0808292\tvalid_1's rmse: 0.0831281\n",
      "[350]\ttraining's rmse: 0.0807586\tvalid_1's rmse: 0.0831005\n",
      "[375]\ttraining's rmse: 0.0807028\tvalid_1's rmse: 0.0830779\n",
      "[400]\ttraining's rmse: 0.0806411\tvalid_1's rmse: 0.0830539\n",
      "[425]\ttraining's rmse: 0.0805844\tvalid_1's rmse: 0.0830327\n",
      "[450]\ttraining's rmse: 0.0805314\tvalid_1's rmse: 0.0830123\n",
      "[475]\ttraining's rmse: 0.0804827\tvalid_1's rmse: 0.0829942\n",
      "[500]\ttraining's rmse: 0.0804405\tvalid_1's rmse: 0.0829778\n",
      "[525]\ttraining's rmse: 0.0803877\tvalid_1's rmse: 0.0829604\n",
      "[550]\ttraining's rmse: 0.0803385\tvalid_1's rmse: 0.0829442\n",
      "[575]\ttraining's rmse: 0.0802944\tvalid_1's rmse: 0.0829304\n",
      "[600]\ttraining's rmse: 0.0802495\tvalid_1's rmse: 0.082916\n",
      "[625]\ttraining's rmse: 0.0802147\tvalid_1's rmse: 0.0829035\n",
      "[650]\ttraining's rmse: 0.0801752\tvalid_1's rmse: 0.0828911\n",
      "[675]\ttraining's rmse: 0.0801315\tvalid_1's rmse: 0.0828787\n",
      "[700]\ttraining's rmse: 0.0800936\tvalid_1's rmse: 0.0828675\n",
      "[725]\ttraining's rmse: 0.0800589\tvalid_1's rmse: 0.0828571\n",
      "[750]\ttraining's rmse: 0.080027\tvalid_1's rmse: 0.0828482\n",
      "[775]\ttraining's rmse: 0.0800002\tvalid_1's rmse: 0.0828393\n",
      "[800]\ttraining's rmse: 0.0799645\tvalid_1's rmse: 0.0828299\n",
      "[825]\ttraining's rmse: 0.0799352\tvalid_1's rmse: 0.0828211\n",
      "[850]\ttraining's rmse: 0.0799056\tvalid_1's rmse: 0.0828139\n",
      "[875]\ttraining's rmse: 0.0798796\tvalid_1's rmse: 0.0828078\n",
      "[900]\ttraining's rmse: 0.0798508\tvalid_1's rmse: 0.0828003\n",
      "[925]\ttraining's rmse: 0.079826\tvalid_1's rmse: 0.0827944\n",
      "[950]\ttraining's rmse: 0.0798021\tvalid_1's rmse: 0.0827892\n",
      "[975]\ttraining's rmse: 0.0797782\tvalid_1's rmse: 0.0827836\n",
      "[1000]\ttraining's rmse: 0.0797585\tvalid_1's rmse: 0.082779\n",
      "[1025]\ttraining's rmse: 0.0797364\tvalid_1's rmse: 0.0827751\n",
      "[1050]\ttraining's rmse: 0.0797174\tvalid_1's rmse: 0.0827709\n",
      "[1075]\ttraining's rmse: 0.0796961\tvalid_1's rmse: 0.0827669\n",
      "[1100]\ttraining's rmse: 0.0796803\tvalid_1's rmse: 0.0827631\n",
      "[1125]\ttraining's rmse: 0.0796635\tvalid_1's rmse: 0.0827598\n",
      "[1150]\ttraining's rmse: 0.0796455\tvalid_1's rmse: 0.0827565\n",
      "[1175]\ttraining's rmse: 0.0796286\tvalid_1's rmse: 0.0827531\n",
      "[1200]\ttraining's rmse: 0.0796125\tvalid_1's rmse: 0.0827497\n",
      "[1225]\ttraining's rmse: 0.0795984\tvalid_1's rmse: 0.0827472\n",
      "[1250]\ttraining's rmse: 0.0795855\tvalid_1's rmse: 0.0827443\n",
      "[1275]\ttraining's rmse: 0.0795684\tvalid_1's rmse: 0.0827413\n",
      "[1300]\ttraining's rmse: 0.0795545\tvalid_1's rmse: 0.0827391\n",
      "[1325]\ttraining's rmse: 0.0795429\tvalid_1's rmse: 0.0827363\n",
      "[1350]\ttraining's rmse: 0.0795284\tvalid_1's rmse: 0.0827341\n",
      "[1375]\ttraining's rmse: 0.0795155\tvalid_1's rmse: 0.0827319\n",
      "[1400]\ttraining's rmse: 0.0795061\tvalid_1's rmse: 0.0827294\n",
      "[1425]\ttraining's rmse: 0.0794959\tvalid_1's rmse: 0.0827277\n",
      "[1450]\ttraining's rmse: 0.0794868\tvalid_1's rmse: 0.0827268\n",
      "[1475]\ttraining's rmse: 0.0794769\tvalid_1's rmse: 0.0827254\n",
      "[1500]\ttraining's rmse: 0.079467\tvalid_1's rmse: 0.082724\n",
      "[1525]\ttraining's rmse: 0.0794567\tvalid_1's rmse: 0.0827228\n",
      "[1550]\ttraining's rmse: 0.0794473\tvalid_1's rmse: 0.0827216\n",
      "[1575]\ttraining's rmse: 0.079439\tvalid_1's rmse: 0.0827203\n",
      "[1600]\ttraining's rmse: 0.0794324\tvalid_1's rmse: 0.0827196\n",
      "[1625]\ttraining's rmse: 0.0794256\tvalid_1's rmse: 0.0827182\n",
      "[1650]\ttraining's rmse: 0.0794198\tvalid_1's rmse: 0.0827174\n",
      "[1675]\ttraining's rmse: 0.0794144\tvalid_1's rmse: 0.0827164\n",
      "[1700]\ttraining's rmse: 0.0794101\tvalid_1's rmse: 0.0827156\n",
      "[1725]\ttraining's rmse: 0.0794046\tvalid_1's rmse: 0.0827152\n",
      "[1750]\ttraining's rmse: 0.0793986\tvalid_1's rmse: 0.0827151\n",
      "[1775]\ttraining's rmse: 0.0793925\tvalid_1's rmse: 0.082715\n",
      "[1800]\ttraining's rmse: 0.0793844\tvalid_1's rmse: 0.0827146\n",
      "[1825]\ttraining's rmse: 0.0793776\tvalid_1's rmse: 0.0827137\n",
      "[1850]\ttraining's rmse: 0.0793722\tvalid_1's rmse: 0.0827131\n",
      "[1875]\ttraining's rmse: 0.079367\tvalid_1's rmse: 0.0827122\n",
      "[1900]\ttraining's rmse: 0.0793605\tvalid_1's rmse: 0.0827116\n",
      "[1925]\ttraining's rmse: 0.0793553\tvalid_1's rmse: 0.0827111\n",
      "[1950]\ttraining's rmse: 0.0793514\tvalid_1's rmse: 0.0827101\n",
      "[1975]\ttraining's rmse: 0.0793468\tvalid_1's rmse: 0.0827091\n",
      "[2000]\ttraining's rmse: 0.0793417\tvalid_1's rmse: 0.0827084\n",
      "[2025]\ttraining's rmse: 0.0793381\tvalid_1's rmse: 0.0827081\n",
      "[2050]\ttraining's rmse: 0.0793334\tvalid_1's rmse: 0.0827074\n",
      "[2075]\ttraining's rmse: 0.0793304\tvalid_1's rmse: 0.0827075\n",
      "[2100]\ttraining's rmse: 0.0793258\tvalid_1's rmse: 0.0827073\n",
      "[2125]\ttraining's rmse: 0.0793237\tvalid_1's rmse: 0.0827072\n",
      "[2150]\ttraining's rmse: 0.0793208\tvalid_1's rmse: 0.0827072\n",
      "Early stopping, best iteration is:\n",
      "[2123]\ttraining's rmse: 0.0793238\tvalid_1's rmse: 0.0827071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0839059\tvalid_1's rmse: 0.0796444\n",
      "[50]\ttraining's rmse: 0.0837844\tvalid_1's rmse: 0.0795917\n",
      "[75]\ttraining's rmse: 0.083664\tvalid_1's rmse: 0.0795416\n",
      "[100]\ttraining's rmse: 0.0835558\tvalid_1's rmse: 0.0794973\n",
      "[125]\ttraining's rmse: 0.0834438\tvalid_1's rmse: 0.0794541\n",
      "[150]\ttraining's rmse: 0.08334\tvalid_1's rmse: 0.0794161\n",
      "[175]\ttraining's rmse: 0.0832547\tvalid_1's rmse: 0.0793824\n",
      "[200]\ttraining's rmse: 0.0831653\tvalid_1's rmse: 0.0793486\n",
      "[225]\ttraining's rmse: 0.08308\tvalid_1's rmse: 0.0793172\n",
      "[250]\ttraining's rmse: 0.0830062\tvalid_1's rmse: 0.079291\n",
      "[275]\ttraining's rmse: 0.0829371\tvalid_1's rmse: 0.0792654\n",
      "[300]\ttraining's rmse: 0.0828686\tvalid_1's rmse: 0.0792411\n",
      "[325]\ttraining's rmse: 0.0827989\tvalid_1's rmse: 0.079218\n",
      "[350]\ttraining's rmse: 0.0827326\tvalid_1's rmse: 0.0791972\n",
      "[375]\ttraining's rmse: 0.0826769\tvalid_1's rmse: 0.0791791\n",
      "[400]\ttraining's rmse: 0.0826145\tvalid_1's rmse: 0.0791608\n",
      "[425]\ttraining's rmse: 0.0825599\tvalid_1's rmse: 0.0791492\n",
      "[450]\ttraining's rmse: 0.0825114\tvalid_1's rmse: 0.0791334\n",
      "[475]\ttraining's rmse: 0.082463\tvalid_1's rmse: 0.0791235\n",
      "[500]\ttraining's rmse: 0.0824237\tvalid_1's rmse: 0.0791156\n",
      "[525]\ttraining's rmse: 0.0823733\tvalid_1's rmse: 0.0791014\n",
      "[550]\ttraining's rmse: 0.0823272\tvalid_1's rmse: 0.0790947\n",
      "[575]\ttraining's rmse: 0.0822841\tvalid_1's rmse: 0.0790887\n",
      "[600]\ttraining's rmse: 0.0822411\tvalid_1's rmse: 0.0790787\n",
      "[625]\ttraining's rmse: 0.0822074\tvalid_1's rmse: 0.0790687\n",
      "[650]\ttraining's rmse: 0.0821654\tvalid_1's rmse: 0.0790643\n",
      "[675]\ttraining's rmse: 0.0821226\tvalid_1's rmse: 0.079069\n",
      "[700]\ttraining's rmse: 0.0820861\tvalid_1's rmse: 0.0790605\n",
      "[725]\ttraining's rmse: 0.0820517\tvalid_1's rmse: 0.0790521\n",
      "[750]\ttraining's rmse: 0.0820181\tvalid_1's rmse: 0.0790632\n",
      "[775]\ttraining's rmse: 0.0819911\tvalid_1's rmse: 0.0790599\n",
      "Early stopping, best iteration is:\n",
      "[737]\ttraining's rmse: 0.082036\tvalid_1's rmse: 0.0790478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0780293\tvalid_1's rmse: 0.0799841\n",
      "[50]\ttraining's rmse: 0.0779083\tvalid_1's rmse: 0.0799365\n",
      "[75]\ttraining's rmse: 0.0777884\tvalid_1's rmse: 0.0798894\n",
      "[100]\ttraining's rmse: 0.0776804\tvalid_1's rmse: 0.079849\n",
      "[125]\ttraining's rmse: 0.0775707\tvalid_1's rmse: 0.0798089\n",
      "[150]\ttraining's rmse: 0.0774714\tvalid_1's rmse: 0.0797708\n",
      "[175]\ttraining's rmse: 0.0773895\tvalid_1's rmse: 0.0797393\n",
      "[200]\ttraining's rmse: 0.0772984\tvalid_1's rmse: 0.0797079\n",
      "[225]\ttraining's rmse: 0.0772088\tvalid_1's rmse: 0.0796769\n",
      "[250]\ttraining's rmse: 0.0771353\tvalid_1's rmse: 0.0796491\n",
      "[275]\ttraining's rmse: 0.0770663\tvalid_1's rmse: 0.0796246\n",
      "[300]\ttraining's rmse: 0.0769974\tvalid_1's rmse: 0.0796015\n",
      "[325]\ttraining's rmse: 0.0769314\tvalid_1's rmse: 0.0795789\n",
      "[350]\ttraining's rmse: 0.0768679\tvalid_1's rmse: 0.0795563\n",
      "[375]\ttraining's rmse: 0.0768155\tvalid_1's rmse: 0.0795385\n",
      "[400]\ttraining's rmse: 0.0767554\tvalid_1's rmse: 0.0795204\n",
      "[425]\ttraining's rmse: 0.0767023\tvalid_1's rmse: 0.0795037\n",
      "[450]\ttraining's rmse: 0.0766541\tvalid_1's rmse: 0.0794856\n",
      "[475]\ttraining's rmse: 0.0766124\tvalid_1's rmse: 0.079472\n",
      "[500]\ttraining's rmse: 0.0765727\tvalid_1's rmse: 0.0794591\n",
      "[525]\ttraining's rmse: 0.0765227\tvalid_1's rmse: 0.0794446\n",
      "[550]\ttraining's rmse: 0.0764792\tvalid_1's rmse: 0.0794318\n",
      "[575]\ttraining's rmse: 0.0764383\tvalid_1's rmse: 0.0794213\n",
      "[600]\ttraining's rmse: 0.0763973\tvalid_1's rmse: 0.0794093\n",
      "[625]\ttraining's rmse: 0.0763638\tvalid_1's rmse: 0.0793994\n",
      "[650]\ttraining's rmse: 0.0763276\tvalid_1's rmse: 0.0793895\n",
      "[675]\ttraining's rmse: 0.0762931\tvalid_1's rmse: 0.0793793\n",
      "[700]\ttraining's rmse: 0.0762605\tvalid_1's rmse: 0.0793699\n",
      "[725]\ttraining's rmse: 0.0762272\tvalid_1's rmse: 0.0793617\n",
      "[750]\ttraining's rmse: 0.0761956\tvalid_1's rmse: 0.0793539\n",
      "[775]\ttraining's rmse: 0.0761701\tvalid_1's rmse: 0.079346\n",
      "[800]\ttraining's rmse: 0.0761403\tvalid_1's rmse: 0.0793391\n",
      "[825]\ttraining's rmse: 0.0761142\tvalid_1's rmse: 0.0793326\n",
      "[850]\ttraining's rmse: 0.0760865\tvalid_1's rmse: 0.0793262\n",
      "[875]\ttraining's rmse: 0.0760642\tvalid_1's rmse: 0.0793209\n",
      "[900]\ttraining's rmse: 0.0760354\tvalid_1's rmse: 0.0793151\n",
      "[925]\ttraining's rmse: 0.0760111\tvalid_1's rmse: 0.0793092\n",
      "[950]\ttraining's rmse: 0.0759873\tvalid_1's rmse: 0.0793031\n",
      "[975]\ttraining's rmse: 0.0759671\tvalid_1's rmse: 0.0792984\n",
      "[1000]\ttraining's rmse: 0.0759473\tvalid_1's rmse: 0.0792942\n",
      "[1025]\ttraining's rmse: 0.0759266\tvalid_1's rmse: 0.0792897\n",
      "[1050]\ttraining's rmse: 0.0759081\tvalid_1's rmse: 0.0792846\n",
      "[1075]\ttraining's rmse: 0.0758913\tvalid_1's rmse: 0.0792812\n",
      "[1100]\ttraining's rmse: 0.0758753\tvalid_1's rmse: 0.0792778\n",
      "[1125]\ttraining's rmse: 0.07586\tvalid_1's rmse: 0.0792727\n",
      "[1150]\ttraining's rmse: 0.0758442\tvalid_1's rmse: 0.0792687\n",
      "[1175]\ttraining's rmse: 0.0758304\tvalid_1's rmse: 0.0792655\n",
      "[1200]\ttraining's rmse: 0.0758164\tvalid_1's rmse: 0.0792623\n",
      "[1225]\ttraining's rmse: 0.0758042\tvalid_1's rmse: 0.0792586\n",
      "[1250]\ttraining's rmse: 0.0757922\tvalid_1's rmse: 0.0792529\n",
      "[1275]\ttraining's rmse: 0.0757777\tvalid_1's rmse: 0.0792505\n",
      "[1300]\ttraining's rmse: 0.0757677\tvalid_1's rmse: 0.0792474\n",
      "[1325]\ttraining's rmse: 0.0757551\tvalid_1's rmse: 0.0792442\n",
      "[1350]\ttraining's rmse: 0.0757437\tvalid_1's rmse: 0.0792423\n",
      "[1375]\ttraining's rmse: 0.0757362\tvalid_1's rmse: 0.0792409\n",
      "[1400]\ttraining's rmse: 0.075728\tvalid_1's rmse: 0.0792376\n",
      "[1425]\ttraining's rmse: 0.0757179\tvalid_1's rmse: 0.0792358\n",
      "[1450]\ttraining's rmse: 0.0757096\tvalid_1's rmse: 0.0792343\n",
      "[1475]\ttraining's rmse: 0.0757018\tvalid_1's rmse: 0.0792317\n",
      "[1500]\ttraining's rmse: 0.0756952\tvalid_1's rmse: 0.0792291\n",
      "[1525]\ttraining's rmse: 0.0756889\tvalid_1's rmse: 0.0792261\n",
      "[1550]\ttraining's rmse: 0.0756818\tvalid_1's rmse: 0.0792237\n",
      "[1575]\ttraining's rmse: 0.0756755\tvalid_1's rmse: 0.0792229\n",
      "[1600]\ttraining's rmse: 0.0756703\tvalid_1's rmse: 0.0792222\n",
      "[1625]\ttraining's rmse: 0.0756641\tvalid_1's rmse: 0.0792203\n",
      "[1650]\ttraining's rmse: 0.0756578\tvalid_1's rmse: 0.0792184\n",
      "[1675]\ttraining's rmse: 0.0756525\tvalid_1's rmse: 0.0792171\n",
      "[1700]\ttraining's rmse: 0.0756483\tvalid_1's rmse: 0.0792157\n",
      "[1725]\ttraining's rmse: 0.0756433\tvalid_1's rmse: 0.0792144\n",
      "[1750]\ttraining's rmse: 0.0756377\tvalid_1's rmse: 0.0792134\n",
      "[1775]\ttraining's rmse: 0.0756341\tvalid_1's rmse: 0.0792125\n",
      "[1800]\ttraining's rmse: 0.0756291\tvalid_1's rmse: 0.0792112\n",
      "[1825]\ttraining's rmse: 0.0756257\tvalid_1's rmse: 0.0792107\n",
      "[1850]\ttraining's rmse: 0.0756219\tvalid_1's rmse: 0.0792088\n",
      "[1875]\ttraining's rmse: 0.0756184\tvalid_1's rmse: 0.0792087\n",
      "[1900]\ttraining's rmse: 0.0756155\tvalid_1's rmse: 0.0792066\n",
      "[1925]\ttraining's rmse: 0.0756117\tvalid_1's rmse: 0.0792061\n",
      "[1950]\ttraining's rmse: 0.075608\tvalid_1's rmse: 0.079205\n",
      "[1975]\ttraining's rmse: 0.0756055\tvalid_1's rmse: 0.0792045\n",
      "[2000]\ttraining's rmse: 0.0756027\tvalid_1's rmse: 0.0792022\n",
      "[2025]\ttraining's rmse: 0.0755998\tvalid_1's rmse: 0.0792006\n",
      "[2050]\ttraining's rmse: 0.0755956\tvalid_1's rmse: 0.0791994\n",
      "[2075]\ttraining's rmse: 0.0755932\tvalid_1's rmse: 0.0791988\n",
      "[2100]\ttraining's rmse: 0.0755891\tvalid_1's rmse: 0.0791982\n",
      "[2125]\ttraining's rmse: 0.0755862\tvalid_1's rmse: 0.0791979\n",
      "[2150]\ttraining's rmse: 0.0755821\tvalid_1's rmse: 0.0791968\n",
      "[2175]\ttraining's rmse: 0.0755803\tvalid_1's rmse: 0.0791966\n",
      "[2200]\ttraining's rmse: 0.075578\tvalid_1's rmse: 0.0791965\n",
      "[2225]\ttraining's rmse: 0.0755762\tvalid_1's rmse: 0.0791959\n",
      "[2250]\ttraining's rmse: 0.0755736\tvalid_1's rmse: 0.0791959\n",
      "[2275]\ttraining's rmse: 0.0755697\tvalid_1's rmse: 0.0791955\n",
      "[2300]\ttraining's rmse: 0.0755675\tvalid_1's rmse: 0.0791947\n",
      "[2325]\ttraining's rmse: 0.0755658\tvalid_1's rmse: 0.0791942\n",
      "[2350]\ttraining's rmse: 0.0755642\tvalid_1's rmse: 0.0791928\n",
      "[2375]\ttraining's rmse: 0.0755629\tvalid_1's rmse: 0.0791925\n",
      "[2400]\ttraining's rmse: 0.0755609\tvalid_1's rmse: 0.0791922\n",
      "[2425]\ttraining's rmse: 0.0755579\tvalid_1's rmse: 0.0791914\n",
      "[2450]\ttraining's rmse: 0.0755548\tvalid_1's rmse: 0.0791913\n",
      "[2475]\ttraining's rmse: 0.0755531\tvalid_1's rmse: 0.0791905\n",
      "[2500]\ttraining's rmse: 0.0755512\tvalid_1's rmse: 0.0791903\n",
      "[2525]\ttraining's rmse: 0.0755494\tvalid_1's rmse: 0.0791903\n",
      "Early stopping, best iteration is:\n",
      "[2482]\ttraining's rmse: 0.0755527\tvalid_1's rmse: 0.0791901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0781685\tvalid_1's rmse: 0.0797293\n",
      "[50]\ttraining's rmse: 0.0780669\tvalid_1's rmse: 0.0796778\n",
      "[75]\ttraining's rmse: 0.0779611\tvalid_1's rmse: 0.0796289\n",
      "[100]\ttraining's rmse: 0.0778688\tvalid_1's rmse: 0.079584\n",
      "[125]\ttraining's rmse: 0.077772\tvalid_1's rmse: 0.0795403\n",
      "[150]\ttraining's rmse: 0.0776835\tvalid_1's rmse: 0.0794992\n",
      "[175]\ttraining's rmse: 0.0776088\tvalid_1's rmse: 0.0794651\n",
      "[200]\ttraining's rmse: 0.0775266\tvalid_1's rmse: 0.0794303\n",
      "[225]\ttraining's rmse: 0.0774476\tvalid_1's rmse: 0.0793978\n",
      "[250]\ttraining's rmse: 0.0773811\tvalid_1's rmse: 0.0793687\n",
      "[275]\ttraining's rmse: 0.0773209\tvalid_1's rmse: 0.0793422\n",
      "[300]\ttraining's rmse: 0.0772608\tvalid_1's rmse: 0.0793179\n",
      "[325]\ttraining's rmse: 0.0771981\tvalid_1's rmse: 0.0792932\n",
      "[350]\ttraining's rmse: 0.0771376\tvalid_1's rmse: 0.0792705\n",
      "[375]\ttraining's rmse: 0.0770861\tvalid_1's rmse: 0.0792504\n",
      "[400]\ttraining's rmse: 0.0770333\tvalid_1's rmse: 0.0792308\n",
      "[425]\ttraining's rmse: 0.076984\tvalid_1's rmse: 0.0792121\n",
      "[450]\ttraining's rmse: 0.0769382\tvalid_1's rmse: 0.0791954\n",
      "[475]\ttraining's rmse: 0.0768967\tvalid_1's rmse: 0.0791791\n",
      "[500]\ttraining's rmse: 0.076861\tvalid_1's rmse: 0.0791644\n",
      "[525]\ttraining's rmse: 0.0768129\tvalid_1's rmse: 0.0791495\n",
      "[550]\ttraining's rmse: 0.0767696\tvalid_1's rmse: 0.0791354\n",
      "[575]\ttraining's rmse: 0.0767316\tvalid_1's rmse: 0.0791225\n",
      "[600]\ttraining's rmse: 0.076695\tvalid_1's rmse: 0.0791102\n",
      "[625]\ttraining's rmse: 0.0766644\tvalid_1's rmse: 0.0790992\n",
      "[650]\ttraining's rmse: 0.0766277\tvalid_1's rmse: 0.0790878\n",
      "[675]\ttraining's rmse: 0.07659\tvalid_1's rmse: 0.0790769\n",
      "[700]\ttraining's rmse: 0.0765591\tvalid_1's rmse: 0.0790679\n",
      "[725]\ttraining's rmse: 0.076529\tvalid_1's rmse: 0.0790585\n",
      "[750]\ttraining's rmse: 0.0764999\tvalid_1's rmse: 0.079049\n",
      "[775]\ttraining's rmse: 0.0764747\tvalid_1's rmse: 0.0790399\n",
      "[800]\ttraining's rmse: 0.0764457\tvalid_1's rmse: 0.0790325\n",
      "[825]\ttraining's rmse: 0.07642\tvalid_1's rmse: 0.0790246\n",
      "[850]\ttraining's rmse: 0.0763956\tvalid_1's rmse: 0.0790182\n",
      "[875]\ttraining's rmse: 0.0763727\tvalid_1's rmse: 0.0790115\n",
      "[900]\ttraining's rmse: 0.07635\tvalid_1's rmse: 0.0790049\n",
      "[925]\ttraining's rmse: 0.076327\tvalid_1's rmse: 0.0789993\n",
      "[950]\ttraining's rmse: 0.0763025\tvalid_1's rmse: 0.0789932\n",
      "[975]\ttraining's rmse: 0.0762822\tvalid_1's rmse: 0.0789877\n",
      "[1000]\ttraining's rmse: 0.0762633\tvalid_1's rmse: 0.0789822\n",
      "[1025]\ttraining's rmse: 0.0762406\tvalid_1's rmse: 0.0789776\n",
      "[1050]\ttraining's rmse: 0.076223\tvalid_1's rmse: 0.0789727\n",
      "[1075]\ttraining's rmse: 0.0762049\tvalid_1's rmse: 0.0789691\n",
      "[1100]\ttraining's rmse: 0.076189\tvalid_1's rmse: 0.0789648\n",
      "[1125]\ttraining's rmse: 0.0761727\tvalid_1's rmse: 0.078961\n",
      "[1150]\ttraining's rmse: 0.0761562\tvalid_1's rmse: 0.0789578\n",
      "[1175]\ttraining's rmse: 0.0761429\tvalid_1's rmse: 0.0789544\n",
      "[1200]\ttraining's rmse: 0.0761291\tvalid_1's rmse: 0.078951\n",
      "[1225]\ttraining's rmse: 0.0761159\tvalid_1's rmse: 0.0789479\n",
      "[1250]\ttraining's rmse: 0.0761047\tvalid_1's rmse: 0.0789446\n",
      "[1275]\ttraining's rmse: 0.076092\tvalid_1's rmse: 0.0789421\n",
      "[1300]\ttraining's rmse: 0.0760805\tvalid_1's rmse: 0.078939\n",
      "[1325]\ttraining's rmse: 0.0760688\tvalid_1's rmse: 0.078937\n",
      "[1350]\ttraining's rmse: 0.0760557\tvalid_1's rmse: 0.0789345\n",
      "[1375]\ttraining's rmse: 0.0760458\tvalid_1's rmse: 0.0789329\n",
      "[1400]\ttraining's rmse: 0.0760356\tvalid_1's rmse: 0.0789305\n",
      "[1425]\ttraining's rmse: 0.076026\tvalid_1's rmse: 0.0789286\n",
      "[1450]\ttraining's rmse: 0.0760146\tvalid_1's rmse: 0.0789269\n",
      "[1475]\ttraining's rmse: 0.0760064\tvalid_1's rmse: 0.0789246\n",
      "[1500]\ttraining's rmse: 0.0759975\tvalid_1's rmse: 0.0789227\n",
      "[1525]\ttraining's rmse: 0.075989\tvalid_1's rmse: 0.0789211\n",
      "[1550]\ttraining's rmse: 0.0759819\tvalid_1's rmse: 0.0789195\n",
      "[1575]\ttraining's rmse: 0.0759749\tvalid_1's rmse: 0.0789182\n",
      "[1600]\ttraining's rmse: 0.0759696\tvalid_1's rmse: 0.0789173\n",
      "[1625]\ttraining's rmse: 0.0759612\tvalid_1's rmse: 0.0789154\n",
      "[1650]\ttraining's rmse: 0.0759533\tvalid_1's rmse: 0.0789143\n",
      "[1675]\ttraining's rmse: 0.0759478\tvalid_1's rmse: 0.0789131\n",
      "[1700]\ttraining's rmse: 0.0759428\tvalid_1's rmse: 0.0789121\n",
      "[1725]\ttraining's rmse: 0.0759387\tvalid_1's rmse: 0.0789108\n",
      "[1750]\ttraining's rmse: 0.0759338\tvalid_1's rmse: 0.0789102\n",
      "[1775]\ttraining's rmse: 0.0759279\tvalid_1's rmse: 0.0789091\n",
      "[1800]\ttraining's rmse: 0.0759227\tvalid_1's rmse: 0.0789081\n",
      "[1825]\ttraining's rmse: 0.0759179\tvalid_1's rmse: 0.0789073\n",
      "[1850]\ttraining's rmse: 0.0759139\tvalid_1's rmse: 0.0789065\n",
      "[1875]\ttraining's rmse: 0.0759106\tvalid_1's rmse: 0.078906\n",
      "[1900]\ttraining's rmse: 0.0759058\tvalid_1's rmse: 0.0789051\n",
      "[1925]\ttraining's rmse: 0.0759021\tvalid_1's rmse: 0.0789049\n",
      "[1950]\ttraining's rmse: 0.0758987\tvalid_1's rmse: 0.078904\n",
      "[1975]\ttraining's rmse: 0.0758964\tvalid_1's rmse: 0.0789034\n",
      "[2000]\ttraining's rmse: 0.0758923\tvalid_1's rmse: 0.0789028\n",
      "[2025]\ttraining's rmse: 0.0758896\tvalid_1's rmse: 0.0789021\n",
      "[2050]\ttraining's rmse: 0.0758862\tvalid_1's rmse: 0.0789016\n",
      "[2075]\ttraining's rmse: 0.0758837\tvalid_1's rmse: 0.0789014\n",
      "[2100]\ttraining's rmse: 0.0758812\tvalid_1's rmse: 0.0789008\n",
      "[2125]\ttraining's rmse: 0.0758786\tvalid_1's rmse: 0.0789009\n",
      "[2150]\ttraining's rmse: 0.0758758\tvalid_1's rmse: 0.0789008\n",
      "[2175]\ttraining's rmse: 0.0758735\tvalid_1's rmse: 0.0789006\n",
      "[2200]\ttraining's rmse: 0.0758706\tvalid_1's rmse: 0.0789004\n",
      "[2225]\ttraining's rmse: 0.0758675\tvalid_1's rmse: 0.0788998\n",
      "[2250]\ttraining's rmse: 0.0758645\tvalid_1's rmse: 0.0788995\n",
      "[2275]\ttraining's rmse: 0.0758607\tvalid_1's rmse: 0.0788993\n",
      "[2300]\ttraining's rmse: 0.0758586\tvalid_1's rmse: 0.078899\n",
      "[2325]\ttraining's rmse: 0.0758571\tvalid_1's rmse: 0.0788983\n",
      "[2350]\ttraining's rmse: 0.075855\tvalid_1's rmse: 0.0788979\n",
      "[2375]\ttraining's rmse: 0.0758523\tvalid_1's rmse: 0.0788979\n",
      "[2400]\ttraining's rmse: 0.0758505\tvalid_1's rmse: 0.0788978\n",
      "[2425]\ttraining's rmse: 0.0758482\tvalid_1's rmse: 0.0788978\n",
      "Early stopping, best iteration is:\n",
      "[2386]\ttraining's rmse: 0.0758513\tvalid_1's rmse: 0.0788976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0797427\tvalid_1's rmse: 0.0765259\n",
      "[50]\ttraining's rmse: 0.0796444\tvalid_1's rmse: 0.0764806\n",
      "[75]\ttraining's rmse: 0.0795386\tvalid_1's rmse: 0.0764352\n",
      "[100]\ttraining's rmse: 0.079447\tvalid_1's rmse: 0.0763949\n",
      "[125]\ttraining's rmse: 0.0793522\tvalid_1's rmse: 0.0763558\n",
      "[150]\ttraining's rmse: 0.0792629\tvalid_1's rmse: 0.0763195\n",
      "[175]\ttraining's rmse: 0.079189\tvalid_1's rmse: 0.0762906\n",
      "[200]\ttraining's rmse: 0.0791078\tvalid_1's rmse: 0.0762607\n",
      "[225]\ttraining's rmse: 0.0790289\tvalid_1's rmse: 0.0762326\n",
      "[250]\ttraining's rmse: 0.0789663\tvalid_1's rmse: 0.076208\n",
      "[275]\ttraining's rmse: 0.0789058\tvalid_1's rmse: 0.0761842\n",
      "[300]\ttraining's rmse: 0.078846\tvalid_1's rmse: 0.0761607\n",
      "[325]\ttraining's rmse: 0.0787846\tvalid_1's rmse: 0.0761399\n",
      "[350]\ttraining's rmse: 0.0787246\tvalid_1's rmse: 0.0761181\n",
      "[375]\ttraining's rmse: 0.0786772\tvalid_1's rmse: 0.0761003\n",
      "[400]\ttraining's rmse: 0.0786235\tvalid_1's rmse: 0.0760897\n",
      "[425]\ttraining's rmse: 0.0785747\tvalid_1's rmse: 0.0760772\n",
      "[450]\ttraining's rmse: 0.0785307\tvalid_1's rmse: 0.0760614\n",
      "[475]\ttraining's rmse: 0.0784905\tvalid_1's rmse: 0.0760573\n",
      "[500]\ttraining's rmse: 0.0784552\tvalid_1's rmse: 0.0760435\n",
      "[525]\ttraining's rmse: 0.0784072\tvalid_1's rmse: 0.0760302\n",
      "[550]\ttraining's rmse: 0.0783631\tvalid_1's rmse: 0.076023\n",
      "[575]\ttraining's rmse: 0.0783244\tvalid_1's rmse: 0.0760188\n",
      "[600]\ttraining's rmse: 0.0782854\tvalid_1's rmse: 0.0760086\n",
      "[625]\ttraining's rmse: 0.0782563\tvalid_1's rmse: 0.076003\n",
      "[650]\ttraining's rmse: 0.0782199\tvalid_1's rmse: 0.0760035\n",
      "[675]\ttraining's rmse: 0.0781806\tvalid_1's rmse: 0.0759959\n",
      "[700]\ttraining's rmse: 0.0781484\tvalid_1's rmse: 0.0759881\n",
      "[725]\ttraining's rmse: 0.0781168\tvalid_1's rmse: 0.0759972\n",
      "[750]\ttraining's rmse: 0.0780872\tvalid_1's rmse: 0.0759903\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's rmse: 0.0781446\tvalid_1's rmse: 0.0759877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0773193\tvalid_1's rmse: 0.0796322\n",
      "[50]\ttraining's rmse: 0.0772068\tvalid_1's rmse: 0.0795832\n",
      "[75]\ttraining's rmse: 0.0770934\tvalid_1's rmse: 0.0795371\n",
      "[100]\ttraining's rmse: 0.0769913\tvalid_1's rmse: 0.0794952\n",
      "[125]\ttraining's rmse: 0.0768851\tvalid_1's rmse: 0.0794537\n",
      "[150]\ttraining's rmse: 0.076789\tvalid_1's rmse: 0.079416\n",
      "[175]\ttraining's rmse: 0.0767094\tvalid_1's rmse: 0.0793851\n",
      "[200]\ttraining's rmse: 0.0766245\tvalid_1's rmse: 0.0793521\n",
      "[225]\ttraining's rmse: 0.0765391\tvalid_1's rmse: 0.0793209\n",
      "[250]\ttraining's rmse: 0.076471\tvalid_1's rmse: 0.0792932\n",
      "[275]\ttraining's rmse: 0.0764073\tvalid_1's rmse: 0.0792689\n",
      "[300]\ttraining's rmse: 0.0763393\tvalid_1's rmse: 0.0792435\n",
      "[325]\ttraining's rmse: 0.0762729\tvalid_1's rmse: 0.0792195\n",
      "[350]\ttraining's rmse: 0.0762114\tvalid_1's rmse: 0.0791977\n",
      "[375]\ttraining's rmse: 0.0761586\tvalid_1's rmse: 0.0791798\n",
      "[400]\ttraining's rmse: 0.0761006\tvalid_1's rmse: 0.0791617\n",
      "[425]\ttraining's rmse: 0.0760517\tvalid_1's rmse: 0.0791455\n",
      "[450]\ttraining's rmse: 0.0760063\tvalid_1's rmse: 0.0791286\n",
      "[475]\ttraining's rmse: 0.075963\tvalid_1's rmse: 0.0791133\n",
      "[500]\ttraining's rmse: 0.075925\tvalid_1's rmse: 0.0790991\n",
      "[525]\ttraining's rmse: 0.0758775\tvalid_1's rmse: 0.0790846\n",
      "[550]\ttraining's rmse: 0.0758331\tvalid_1's rmse: 0.0790712\n",
      "[575]\ttraining's rmse: 0.0757943\tvalid_1's rmse: 0.079059\n",
      "[600]\ttraining's rmse: 0.0757579\tvalid_1's rmse: 0.079048\n",
      "[625]\ttraining's rmse: 0.0757282\tvalid_1's rmse: 0.0790377\n",
      "[650]\ttraining's rmse: 0.0756933\tvalid_1's rmse: 0.0790261\n",
      "[675]\ttraining's rmse: 0.0756584\tvalid_1's rmse: 0.0790151\n",
      "[700]\ttraining's rmse: 0.0756257\tvalid_1's rmse: 0.0790043\n",
      "[725]\ttraining's rmse: 0.0755953\tvalid_1's rmse: 0.0789953\n",
      "[750]\ttraining's rmse: 0.0755677\tvalid_1's rmse: 0.0789861\n",
      "[775]\ttraining's rmse: 0.0755438\tvalid_1's rmse: 0.0789777\n",
      "[800]\ttraining's rmse: 0.0755124\tvalid_1's rmse: 0.0789704\n",
      "[825]\ttraining's rmse: 0.0754878\tvalid_1's rmse: 0.0789634\n",
      "[850]\ttraining's rmse: 0.0754607\tvalid_1's rmse: 0.0789564\n",
      "[875]\ttraining's rmse: 0.0754362\tvalid_1's rmse: 0.0789495\n",
      "[900]\ttraining's rmse: 0.0754125\tvalid_1's rmse: 0.0789432\n",
      "[925]\ttraining's rmse: 0.0753884\tvalid_1's rmse: 0.0789362\n",
      "[950]\ttraining's rmse: 0.0753681\tvalid_1's rmse: 0.0789305\n",
      "[975]\ttraining's rmse: 0.0753492\tvalid_1's rmse: 0.0789254\n",
      "[1000]\ttraining's rmse: 0.0753297\tvalid_1's rmse: 0.0789206\n",
      "[1025]\ttraining's rmse: 0.0753073\tvalid_1's rmse: 0.0789162\n",
      "[1050]\ttraining's rmse: 0.0752903\tvalid_1's rmse: 0.0789107\n",
      "[1075]\ttraining's rmse: 0.0752743\tvalid_1's rmse: 0.0789074\n",
      "[1100]\ttraining's rmse: 0.0752596\tvalid_1's rmse: 0.0789036\n",
      "[1125]\ttraining's rmse: 0.0752443\tvalid_1's rmse: 0.0788988\n",
      "[1150]\ttraining's rmse: 0.075228\tvalid_1's rmse: 0.0788942\n",
      "[1175]\ttraining's rmse: 0.0752154\tvalid_1's rmse: 0.0788921\n",
      "[1200]\ttraining's rmse: 0.0752031\tvalid_1's rmse: 0.0788881\n",
      "[1225]\ttraining's rmse: 0.0751921\tvalid_1's rmse: 0.0788855\n",
      "[1250]\ttraining's rmse: 0.0751784\tvalid_1's rmse: 0.0788829\n",
      "[1275]\ttraining's rmse: 0.0751654\tvalid_1's rmse: 0.0788811\n",
      "[1300]\ttraining's rmse: 0.0751547\tvalid_1's rmse: 0.0788783\n",
      "[1325]\ttraining's rmse: 0.0751429\tvalid_1's rmse: 0.0788757\n",
      "[1350]\ttraining's rmse: 0.0751333\tvalid_1's rmse: 0.0788732\n",
      "[1375]\ttraining's rmse: 0.0751203\tvalid_1's rmse: 0.0788707\n",
      "[1400]\ttraining's rmse: 0.07511\tvalid_1's rmse: 0.0788675\n",
      "[1425]\ttraining's rmse: 0.075102\tvalid_1's rmse: 0.0788646\n",
      "[1450]\ttraining's rmse: 0.0750891\tvalid_1's rmse: 0.0788618\n",
      "[1475]\ttraining's rmse: 0.0750785\tvalid_1's rmse: 0.078859\n",
      "[1500]\ttraining's rmse: 0.0750712\tvalid_1's rmse: 0.0788563\n",
      "[1525]\ttraining's rmse: 0.0750654\tvalid_1's rmse: 0.0788538\n",
      "[1550]\ttraining's rmse: 0.075058\tvalid_1's rmse: 0.0788521\n",
      "[1575]\ttraining's rmse: 0.0750515\tvalid_1's rmse: 0.0788503\n",
      "[1600]\ttraining's rmse: 0.0750457\tvalid_1's rmse: 0.0788488\n",
      "[1625]\ttraining's rmse: 0.0750392\tvalid_1's rmse: 0.0788463\n",
      "[1650]\ttraining's rmse: 0.0750335\tvalid_1's rmse: 0.0788443\n",
      "[1675]\ttraining's rmse: 0.0750293\tvalid_1's rmse: 0.0788424\n",
      "[1700]\ttraining's rmse: 0.0750251\tvalid_1's rmse: 0.0788409\n",
      "[1725]\ttraining's rmse: 0.0750207\tvalid_1's rmse: 0.0788396\n",
      "[1750]\ttraining's rmse: 0.0750142\tvalid_1's rmse: 0.0788387\n",
      "[1775]\ttraining's rmse: 0.0750091\tvalid_1's rmse: 0.0788374\n",
      "[1800]\ttraining's rmse: 0.0750054\tvalid_1's rmse: 0.0788364\n",
      "[1825]\ttraining's rmse: 0.0750002\tvalid_1's rmse: 0.0788357\n",
      "[1850]\ttraining's rmse: 0.0749955\tvalid_1's rmse: 0.0788341\n",
      "[1875]\ttraining's rmse: 0.0749912\tvalid_1's rmse: 0.0788326\n",
      "[1900]\ttraining's rmse: 0.0749876\tvalid_1's rmse: 0.0788316\n",
      "[1925]\ttraining's rmse: 0.0749829\tvalid_1's rmse: 0.07883\n",
      "[1950]\ttraining's rmse: 0.0749802\tvalid_1's rmse: 0.0788282\n",
      "[1975]\ttraining's rmse: 0.0749768\tvalid_1's rmse: 0.0788274\n",
      "[2000]\ttraining's rmse: 0.0749729\tvalid_1's rmse: 0.0788269\n",
      "[2025]\ttraining's rmse: 0.0749693\tvalid_1's rmse: 0.0788261\n",
      "[2050]\ttraining's rmse: 0.0749657\tvalid_1's rmse: 0.0788241\n",
      "[2075]\ttraining's rmse: 0.074962\tvalid_1's rmse: 0.0788235\n",
      "[2100]\ttraining's rmse: 0.0749591\tvalid_1's rmse: 0.0788231\n",
      "[2125]\ttraining's rmse: 0.0749565\tvalid_1's rmse: 0.0788233\n",
      "[2150]\ttraining's rmse: 0.0749538\tvalid_1's rmse: 0.0788229\n",
      "[2175]\ttraining's rmse: 0.0749513\tvalid_1's rmse: 0.0788227\n",
      "[2200]\ttraining's rmse: 0.0749494\tvalid_1's rmse: 0.078822\n",
      "[2225]\ttraining's rmse: 0.0749469\tvalid_1's rmse: 0.0788202\n",
      "[2250]\ttraining's rmse: 0.074943\tvalid_1's rmse: 0.0788199\n",
      "[2275]\ttraining's rmse: 0.0749406\tvalid_1's rmse: 0.0788186\n",
      "[2300]\ttraining's rmse: 0.0749387\tvalid_1's rmse: 0.0788184\n",
      "[2325]\ttraining's rmse: 0.0749361\tvalid_1's rmse: 0.0788179\n",
      "[2350]\ttraining's rmse: 0.0749351\tvalid_1's rmse: 0.0788173\n",
      "[2375]\ttraining's rmse: 0.0749327\tvalid_1's rmse: 0.0788165\n",
      "[2400]\ttraining's rmse: 0.0749304\tvalid_1's rmse: 0.0788163\n",
      "[2425]\ttraining's rmse: 0.0749282\tvalid_1's rmse: 0.0788157\n",
      "[2450]\ttraining's rmse: 0.0749262\tvalid_1's rmse: 0.0788152\n",
      "[2475]\ttraining's rmse: 0.0749241\tvalid_1's rmse: 0.078815\n",
      "[2500]\ttraining's rmse: 0.0749218\tvalid_1's rmse: 0.078814\n",
      "[2525]\ttraining's rmse: 0.0749199\tvalid_1's rmse: 0.0788134\n",
      "[2550]\ttraining's rmse: 0.0749185\tvalid_1's rmse: 0.0788134\n",
      "[2575]\ttraining's rmse: 0.0749166\tvalid_1's rmse: 0.0788133\n",
      "[2600]\ttraining's rmse: 0.0749152\tvalid_1's rmse: 0.0788134\n",
      "[2625]\ttraining's rmse: 0.0749137\tvalid_1's rmse: 0.0788132\n",
      "[2650]\ttraining's rmse: 0.0749128\tvalid_1's rmse: 0.0788129\n",
      "[2675]\ttraining's rmse: 0.0749116\tvalid_1's rmse: 0.0788121\n",
      "[2700]\ttraining's rmse: 0.0749105\tvalid_1's rmse: 0.0788123\n",
      "Early stopping, best iteration is:\n",
      "[2664]\ttraining's rmse: 0.0749121\tvalid_1's rmse: 0.0788121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0777244\tvalid_1's rmse: 0.0788504\n",
      "[50]\ttraining's rmse: 0.0776215\tvalid_1's rmse: 0.0787997\n",
      "[75]\ttraining's rmse: 0.0775155\tvalid_1's rmse: 0.0787489\n",
      "[100]\ttraining's rmse: 0.0774216\tvalid_1's rmse: 0.0787047\n",
      "[125]\ttraining's rmse: 0.077325\tvalid_1's rmse: 0.0786607\n",
      "[150]\ttraining's rmse: 0.0772374\tvalid_1's rmse: 0.0786199\n",
      "[175]\ttraining's rmse: 0.0771631\tvalid_1's rmse: 0.0785868\n",
      "[200]\ttraining's rmse: 0.0770807\tvalid_1's rmse: 0.0785519\n",
      "[225]\ttraining's rmse: 0.0770025\tvalid_1's rmse: 0.0785192\n",
      "[250]\ttraining's rmse: 0.0769349\tvalid_1's rmse: 0.0784893\n",
      "[275]\ttraining's rmse: 0.0768736\tvalid_1's rmse: 0.078462\n",
      "[300]\ttraining's rmse: 0.0768131\tvalid_1's rmse: 0.0784371\n",
      "[325]\ttraining's rmse: 0.0767509\tvalid_1's rmse: 0.0784117\n",
      "[350]\ttraining's rmse: 0.0766903\tvalid_1's rmse: 0.078389\n",
      "[375]\ttraining's rmse: 0.0766408\tvalid_1's rmse: 0.0783686\n",
      "[400]\ttraining's rmse: 0.0765888\tvalid_1's rmse: 0.0783505\n",
      "[425]\ttraining's rmse: 0.0765408\tvalid_1's rmse: 0.0783318\n",
      "[450]\ttraining's rmse: 0.0764949\tvalid_1's rmse: 0.0783139\n",
      "[475]\ttraining's rmse: 0.0764545\tvalid_1's rmse: 0.0782974\n",
      "[500]\ttraining's rmse: 0.0764181\tvalid_1's rmse: 0.0782822\n",
      "[525]\ttraining's rmse: 0.0763719\tvalid_1's rmse: 0.0782671\n",
      "[550]\ttraining's rmse: 0.0763298\tvalid_1's rmse: 0.0782524\n",
      "[575]\ttraining's rmse: 0.0762929\tvalid_1's rmse: 0.0782397\n",
      "[600]\ttraining's rmse: 0.0762545\tvalid_1's rmse: 0.0782274\n",
      "[625]\ttraining's rmse: 0.0762248\tvalid_1's rmse: 0.0782163\n",
      "[650]\ttraining's rmse: 0.0761874\tvalid_1's rmse: 0.0782041\n",
      "[675]\ttraining's rmse: 0.0761504\tvalid_1's rmse: 0.0781942\n",
      "[700]\ttraining's rmse: 0.0761168\tvalid_1's rmse: 0.0781842\n",
      "[725]\ttraining's rmse: 0.0760862\tvalid_1's rmse: 0.0781748\n",
      "[750]\ttraining's rmse: 0.0760572\tvalid_1's rmse: 0.0781667\n",
      "[775]\ttraining's rmse: 0.0760331\tvalid_1's rmse: 0.0781595\n",
      "[800]\ttraining's rmse: 0.0760027\tvalid_1's rmse: 0.0781517\n",
      "[825]\ttraining's rmse: 0.0759772\tvalid_1's rmse: 0.0781437\n",
      "[850]\ttraining's rmse: 0.0759506\tvalid_1's rmse: 0.0781373\n",
      "[875]\ttraining's rmse: 0.0759285\tvalid_1's rmse: 0.0781313\n",
      "[900]\ttraining's rmse: 0.075905\tvalid_1's rmse: 0.0781245\n",
      "[925]\ttraining's rmse: 0.0758815\tvalid_1's rmse: 0.0781192\n",
      "[950]\ttraining's rmse: 0.0758591\tvalid_1's rmse: 0.0781129\n",
      "[975]\ttraining's rmse: 0.0758386\tvalid_1's rmse: 0.0781075\n",
      "[1000]\ttraining's rmse: 0.0758218\tvalid_1's rmse: 0.0781031\n",
      "[1025]\ttraining's rmse: 0.0758018\tvalid_1's rmse: 0.0780984\n",
      "[1050]\ttraining's rmse: 0.0757837\tvalid_1's rmse: 0.0780938\n",
      "[1075]\ttraining's rmse: 0.0757675\tvalid_1's rmse: 0.0780902\n",
      "[1100]\ttraining's rmse: 0.0757537\tvalid_1's rmse: 0.0780865\n",
      "[1125]\ttraining's rmse: 0.0757373\tvalid_1's rmse: 0.0780827\n",
      "[1150]\ttraining's rmse: 0.0757187\tvalid_1's rmse: 0.0780787\n",
      "[1175]\ttraining's rmse: 0.0757025\tvalid_1's rmse: 0.0780753\n",
      "[1200]\ttraining's rmse: 0.0756889\tvalid_1's rmse: 0.0780721\n",
      "[1225]\ttraining's rmse: 0.0756754\tvalid_1's rmse: 0.0780687\n",
      "[1250]\ttraining's rmse: 0.075663\tvalid_1's rmse: 0.0780656\n",
      "[1275]\ttraining's rmse: 0.0756457\tvalid_1's rmse: 0.0780632\n",
      "[1300]\ttraining's rmse: 0.0756354\tvalid_1's rmse: 0.0780608\n",
      "[1325]\ttraining's rmse: 0.0756237\tvalid_1's rmse: 0.0780588\n",
      "[1350]\ttraining's rmse: 0.0756122\tvalid_1's rmse: 0.078056\n",
      "[1375]\ttraining's rmse: 0.0756023\tvalid_1's rmse: 0.078055\n",
      "[1400]\ttraining's rmse: 0.0755935\tvalid_1's rmse: 0.0780528\n",
      "[1425]\ttraining's rmse: 0.0755842\tvalid_1's rmse: 0.0780509\n",
      "[1450]\ttraining's rmse: 0.075571\tvalid_1's rmse: 0.0780488\n",
      "[1475]\ttraining's rmse: 0.0755608\tvalid_1's rmse: 0.0780464\n",
      "[1500]\ttraining's rmse: 0.0755532\tvalid_1's rmse: 0.078045\n",
      "[1525]\ttraining's rmse: 0.0755445\tvalid_1's rmse: 0.0780434\n",
      "[1550]\ttraining's rmse: 0.0755371\tvalid_1's rmse: 0.078042\n",
      "[1575]\ttraining's rmse: 0.0755301\tvalid_1's rmse: 0.0780403\n",
      "[1600]\ttraining's rmse: 0.0755236\tvalid_1's rmse: 0.0780397\n",
      "[1625]\ttraining's rmse: 0.0755166\tvalid_1's rmse: 0.0780383\n",
      "[1650]\ttraining's rmse: 0.0755107\tvalid_1's rmse: 0.078037\n",
      "[1675]\ttraining's rmse: 0.0755055\tvalid_1's rmse: 0.0780356\n",
      "[1700]\ttraining's rmse: 0.0754997\tvalid_1's rmse: 0.0780349\n",
      "[1725]\ttraining's rmse: 0.0754945\tvalid_1's rmse: 0.0780344\n",
      "[1750]\ttraining's rmse: 0.0754882\tvalid_1's rmse: 0.0780335\n",
      "[1775]\ttraining's rmse: 0.0754838\tvalid_1's rmse: 0.0780328\n",
      "[1800]\ttraining's rmse: 0.075479\tvalid_1's rmse: 0.0780326\n",
      "[1825]\ttraining's rmse: 0.0754736\tvalid_1's rmse: 0.0780318\n",
      "[1850]\ttraining's rmse: 0.075469\tvalid_1's rmse: 0.0780311\n",
      "[1875]\ttraining's rmse: 0.0754655\tvalid_1's rmse: 0.0780308\n",
      "[1900]\ttraining's rmse: 0.0754624\tvalid_1's rmse: 0.0780307\n",
      "[1925]\ttraining's rmse: 0.0754574\tvalid_1's rmse: 0.0780302\n",
      "[1950]\ttraining's rmse: 0.0754553\tvalid_1's rmse: 0.0780296\n",
      "[1975]\ttraining's rmse: 0.0754516\tvalid_1's rmse: 0.078029\n",
      "[2000]\ttraining's rmse: 0.0754466\tvalid_1's rmse: 0.0780284\n",
      "[2025]\ttraining's rmse: 0.0754444\tvalid_1's rmse: 0.0780279\n",
      "[2050]\ttraining's rmse: 0.0754415\tvalid_1's rmse: 0.0780276\n",
      "[2075]\ttraining's rmse: 0.0754382\tvalid_1's rmse: 0.0780271\n",
      "[2100]\ttraining's rmse: 0.0754349\tvalid_1's rmse: 0.0780267\n",
      "[2125]\ttraining's rmse: 0.075433\tvalid_1's rmse: 0.0780266\n",
      "[2150]\ttraining's rmse: 0.0754305\tvalid_1's rmse: 0.0780264\n",
      "[2175]\ttraining's rmse: 0.0754284\tvalid_1's rmse: 0.0780262\n",
      "[2200]\ttraining's rmse: 0.075426\tvalid_1's rmse: 0.0780255\n",
      "[2225]\ttraining's rmse: 0.0754236\tvalid_1's rmse: 0.0780253\n",
      "[2250]\ttraining's rmse: 0.0754205\tvalid_1's rmse: 0.0780254\n",
      "[2275]\ttraining's rmse: 0.0754178\tvalid_1's rmse: 0.0780251\n",
      "[2300]\ttraining's rmse: 0.0754161\tvalid_1's rmse: 0.0780248\n",
      "[2325]\ttraining's rmse: 0.0754146\tvalid_1's rmse: 0.0780248\n",
      "[2350]\ttraining's rmse: 0.0754135\tvalid_1's rmse: 0.078025\n",
      "Early stopping, best iteration is:\n",
      "[2308]\ttraining's rmse: 0.0754157\tvalid_1's rmse: 0.0780247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0791298\tvalid_1's rmse: 0.0759827\n",
      "[50]\ttraining's rmse: 0.0790319\tvalid_1's rmse: 0.0759366\n",
      "[75]\ttraining's rmse: 0.0789301\tvalid_1's rmse: 0.0758909\n",
      "[100]\ttraining's rmse: 0.0788408\tvalid_1's rmse: 0.0758521\n",
      "[125]\ttraining's rmse: 0.0787468\tvalid_1's rmse: 0.0758125\n",
      "[150]\ttraining's rmse: 0.0786586\tvalid_1's rmse: 0.0757764\n",
      "[175]\ttraining's rmse: 0.0785874\tvalid_1's rmse: 0.0757495\n",
      "[200]\ttraining's rmse: 0.0785077\tvalid_1's rmse: 0.0757181\n",
      "[225]\ttraining's rmse: 0.0784321\tvalid_1's rmse: 0.0756905\n",
      "[250]\ttraining's rmse: 0.0783708\tvalid_1's rmse: 0.0756666\n",
      "[275]\ttraining's rmse: 0.0783111\tvalid_1's rmse: 0.0756432\n",
      "[300]\ttraining's rmse: 0.0782513\tvalid_1's rmse: 0.0756205\n",
      "[325]\ttraining's rmse: 0.0781913\tvalid_1's rmse: 0.0756001\n",
      "[350]\ttraining's rmse: 0.0781317\tvalid_1's rmse: 0.0755799\n",
      "[375]\ttraining's rmse: 0.0780849\tvalid_1's rmse: 0.0755642\n",
      "[400]\ttraining's rmse: 0.0780329\tvalid_1's rmse: 0.0755513\n",
      "[425]\ttraining's rmse: 0.0779845\tvalid_1's rmse: 0.0755365\n",
      "[450]\ttraining's rmse: 0.0779406\tvalid_1's rmse: 0.0755221\n",
      "[475]\ttraining's rmse: 0.0779001\tvalid_1's rmse: 0.0755178\n",
      "[500]\ttraining's rmse: 0.0778672\tvalid_1's rmse: 0.0755051\n",
      "[525]\ttraining's rmse: 0.0778225\tvalid_1's rmse: 0.0754979\n",
      "[550]\ttraining's rmse: 0.0777817\tvalid_1's rmse: 0.0754963\n",
      "[575]\ttraining's rmse: 0.0777423\tvalid_1's rmse: 0.0754919\n",
      "[600]\ttraining's rmse: 0.0777046\tvalid_1's rmse: 0.0754921\n",
      "[625]\ttraining's rmse: 0.0776762\tvalid_1's rmse: 0.0755037\n",
      "Early stopping, best iteration is:\n",
      "[593]\ttraining's rmse: 0.0777167\tvalid_1's rmse: 0.0754852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0790717\tvalid_1's rmse: 0.0811704\n",
      "[50]\ttraining's rmse: 0.0789504\tvalid_1's rmse: 0.0811232\n",
      "[75]\ttraining's rmse: 0.0788322\tvalid_1's rmse: 0.0810773\n",
      "[100]\ttraining's rmse: 0.0787211\tvalid_1's rmse: 0.0810384\n",
      "[125]\ttraining's rmse: 0.0786125\tvalid_1's rmse: 0.0809967\n",
      "[150]\ttraining's rmse: 0.0785135\tvalid_1's rmse: 0.080959\n",
      "[175]\ttraining's rmse: 0.0784318\tvalid_1's rmse: 0.0809256\n",
      "[200]\ttraining's rmse: 0.078343\tvalid_1's rmse: 0.0808925\n",
      "[225]\ttraining's rmse: 0.0782519\tvalid_1's rmse: 0.0808625\n",
      "[250]\ttraining's rmse: 0.07818\tvalid_1's rmse: 0.0808349\n",
      "[275]\ttraining's rmse: 0.0781103\tvalid_1's rmse: 0.0808098\n",
      "[300]\ttraining's rmse: 0.078041\tvalid_1's rmse: 0.0807867\n",
      "[325]\ttraining's rmse: 0.0779724\tvalid_1's rmse: 0.0807627\n",
      "[350]\ttraining's rmse: 0.0779062\tvalid_1's rmse: 0.0807401\n",
      "[375]\ttraining's rmse: 0.0778518\tvalid_1's rmse: 0.080722\n",
      "[400]\ttraining's rmse: 0.0777904\tvalid_1's rmse: 0.0807045\n",
      "[425]\ttraining's rmse: 0.0777376\tvalid_1's rmse: 0.0806868\n",
      "[450]\ttraining's rmse: 0.0776897\tvalid_1's rmse: 0.0806706\n",
      "[475]\ttraining's rmse: 0.0776463\tvalid_1's rmse: 0.080655\n",
      "[500]\ttraining's rmse: 0.07761\tvalid_1's rmse: 0.0806401\n",
      "[525]\ttraining's rmse: 0.0775616\tvalid_1's rmse: 0.0806256\n",
      "[550]\ttraining's rmse: 0.0775166\tvalid_1's rmse: 0.0806115\n",
      "[575]\ttraining's rmse: 0.0774755\tvalid_1's rmse: 0.0806007\n",
      "[600]\ttraining's rmse: 0.0774356\tvalid_1's rmse: 0.0805894\n",
      "[625]\ttraining's rmse: 0.0774024\tvalid_1's rmse: 0.0805788\n",
      "[650]\ttraining's rmse: 0.0773634\tvalid_1's rmse: 0.0805676\n",
      "[675]\ttraining's rmse: 0.0773284\tvalid_1's rmse: 0.0805583\n",
      "[700]\ttraining's rmse: 0.0772942\tvalid_1's rmse: 0.0805489\n",
      "[725]\ttraining's rmse: 0.0772614\tvalid_1's rmse: 0.0805393\n",
      "[750]\ttraining's rmse: 0.0772322\tvalid_1's rmse: 0.0805316\n",
      "[775]\ttraining's rmse: 0.077208\tvalid_1's rmse: 0.0805248\n",
      "[800]\ttraining's rmse: 0.0771762\tvalid_1's rmse: 0.0805183\n",
      "[825]\ttraining's rmse: 0.0771486\tvalid_1's rmse: 0.0805112\n",
      "[850]\ttraining's rmse: 0.0771192\tvalid_1's rmse: 0.0805053\n",
      "[875]\ttraining's rmse: 0.0770968\tvalid_1's rmse: 0.0804989\n",
      "[900]\ttraining's rmse: 0.0770702\tvalid_1's rmse: 0.0804935\n",
      "[925]\ttraining's rmse: 0.0770467\tvalid_1's rmse: 0.0804873\n",
      "[950]\ttraining's rmse: 0.0770267\tvalid_1's rmse: 0.0804819\n",
      "[975]\ttraining's rmse: 0.0770084\tvalid_1's rmse: 0.0804787\n",
      "[1000]\ttraining's rmse: 0.0769872\tvalid_1's rmse: 0.0804734\n",
      "[1025]\ttraining's rmse: 0.0769676\tvalid_1's rmse: 0.0804685\n",
      "[1050]\ttraining's rmse: 0.0769483\tvalid_1's rmse: 0.0804639\n",
      "[1075]\ttraining's rmse: 0.0769305\tvalid_1's rmse: 0.08046\n",
      "[1100]\ttraining's rmse: 0.076914\tvalid_1's rmse: 0.0804557\n",
      "[1125]\ttraining's rmse: 0.0768988\tvalid_1's rmse: 0.0804516\n",
      "[1150]\ttraining's rmse: 0.0768828\tvalid_1's rmse: 0.0804477\n",
      "[1175]\ttraining's rmse: 0.0768682\tvalid_1's rmse: 0.0804454\n",
      "[1200]\ttraining's rmse: 0.0768527\tvalid_1's rmse: 0.0804412\n",
      "[1225]\ttraining's rmse: 0.0768396\tvalid_1's rmse: 0.0804374\n",
      "[1250]\ttraining's rmse: 0.0768255\tvalid_1's rmse: 0.0804338\n",
      "[1275]\ttraining's rmse: 0.0768071\tvalid_1's rmse: 0.0804313\n",
      "[1300]\ttraining's rmse: 0.0767942\tvalid_1's rmse: 0.0804279\n",
      "[1325]\ttraining's rmse: 0.0767839\tvalid_1's rmse: 0.0804246\n",
      "[1350]\ttraining's rmse: 0.0767737\tvalid_1's rmse: 0.0804234\n",
      "[1375]\ttraining's rmse: 0.0767628\tvalid_1's rmse: 0.080422\n",
      "[1400]\ttraining's rmse: 0.0767535\tvalid_1's rmse: 0.0804183\n",
      "[1425]\ttraining's rmse: 0.0767448\tvalid_1's rmse: 0.0804163\n",
      "[1450]\ttraining's rmse: 0.0767354\tvalid_1's rmse: 0.080415\n",
      "[1475]\ttraining's rmse: 0.0767253\tvalid_1's rmse: 0.0804113\n",
      "[1500]\ttraining's rmse: 0.0767184\tvalid_1's rmse: 0.0804084\n",
      "[1525]\ttraining's rmse: 0.0767067\tvalid_1's rmse: 0.080406\n",
      "[1550]\ttraining's rmse: 0.0766987\tvalid_1's rmse: 0.0804048\n",
      "[1575]\ttraining's rmse: 0.0766925\tvalid_1's rmse: 0.0804034\n",
      "[1600]\ttraining's rmse: 0.0766875\tvalid_1's rmse: 0.0804025\n",
      "[1625]\ttraining's rmse: 0.0766823\tvalid_1's rmse: 0.0803991\n",
      "[1650]\ttraining's rmse: 0.0766759\tvalid_1's rmse: 0.0803955\n",
      "[1675]\ttraining's rmse: 0.0766711\tvalid_1's rmse: 0.0803937\n",
      "[1700]\ttraining's rmse: 0.0766667\tvalid_1's rmse: 0.0803919\n",
      "[1725]\ttraining's rmse: 0.0766593\tvalid_1's rmse: 0.0803903\n",
      "[1750]\ttraining's rmse: 0.0766542\tvalid_1's rmse: 0.0803886\n",
      "[1775]\ttraining's rmse: 0.0766492\tvalid_1's rmse: 0.0803872\n",
      "[1800]\ttraining's rmse: 0.0766445\tvalid_1's rmse: 0.0803861\n",
      "[1825]\ttraining's rmse: 0.0766384\tvalid_1's rmse: 0.0803841\n",
      "[1850]\ttraining's rmse: 0.0766339\tvalid_1's rmse: 0.0803829\n",
      "[1875]\ttraining's rmse: 0.0766304\tvalid_1's rmse: 0.0803831\n",
      "[1900]\ttraining's rmse: 0.0766277\tvalid_1's rmse: 0.0803825\n",
      "[1925]\ttraining's rmse: 0.0766227\tvalid_1's rmse: 0.0803819\n",
      "[1950]\ttraining's rmse: 0.0766196\tvalid_1's rmse: 0.0803803\n",
      "[1975]\ttraining's rmse: 0.0766171\tvalid_1's rmse: 0.0803796\n",
      "[2000]\ttraining's rmse: 0.076613\tvalid_1's rmse: 0.0803779\n",
      "[2025]\ttraining's rmse: 0.0766087\tvalid_1's rmse: 0.0803768\n",
      "[2050]\ttraining's rmse: 0.0766061\tvalid_1's rmse: 0.0803755\n",
      "[2075]\ttraining's rmse: 0.0766031\tvalid_1's rmse: 0.0803744\n",
      "[2100]\ttraining's rmse: 0.076601\tvalid_1's rmse: 0.0803745\n",
      "[2125]\ttraining's rmse: 0.0765984\tvalid_1's rmse: 0.0803741\n",
      "[2150]\ttraining's rmse: 0.0765946\tvalid_1's rmse: 0.0803734\n",
      "[2175]\ttraining's rmse: 0.0765925\tvalid_1's rmse: 0.0803731\n",
      "[2200]\ttraining's rmse: 0.0765902\tvalid_1's rmse: 0.0803725\n",
      "[2225]\ttraining's rmse: 0.0765878\tvalid_1's rmse: 0.0803718\n",
      "[2250]\ttraining's rmse: 0.0765857\tvalid_1's rmse: 0.0803713\n",
      "[2275]\ttraining's rmse: 0.0765824\tvalid_1's rmse: 0.080371\n",
      "[2300]\ttraining's rmse: 0.0765794\tvalid_1's rmse: 0.0803701\n",
      "[2325]\ttraining's rmse: 0.0765767\tvalid_1's rmse: 0.0803693\n",
      "[2350]\ttraining's rmse: 0.0765738\tvalid_1's rmse: 0.0803689\n",
      "[2375]\ttraining's rmse: 0.0765714\tvalid_1's rmse: 0.080369\n",
      "[2400]\ttraining's rmse: 0.0765693\tvalid_1's rmse: 0.0803691\n",
      "[2425]\ttraining's rmse: 0.076567\tvalid_1's rmse: 0.080369\n",
      "[2450]\ttraining's rmse: 0.0765652\tvalid_1's rmse: 0.0803689\n",
      "Early stopping, best iteration is:\n",
      "[2412]\ttraining's rmse: 0.0765679\tvalid_1's rmse: 0.0803686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0793357\tvalid_1's rmse: 0.080684\n",
      "[50]\ttraining's rmse: 0.0792336\tvalid_1's rmse: 0.0806343\n",
      "[75]\ttraining's rmse: 0.0791261\tvalid_1's rmse: 0.0805861\n",
      "[100]\ttraining's rmse: 0.079032\tvalid_1's rmse: 0.0805426\n",
      "[125]\ttraining's rmse: 0.0789318\tvalid_1's rmse: 0.080498\n",
      "[150]\ttraining's rmse: 0.0788423\tvalid_1's rmse: 0.0804575\n",
      "[175]\ttraining's rmse: 0.0787671\tvalid_1's rmse: 0.0804225\n",
      "[200]\ttraining's rmse: 0.0786833\tvalid_1's rmse: 0.0803878\n",
      "[225]\ttraining's rmse: 0.0786013\tvalid_1's rmse: 0.0803562\n",
      "[250]\ttraining's rmse: 0.0785345\tvalid_1's rmse: 0.0803258\n",
      "[275]\ttraining's rmse: 0.0784715\tvalid_1's rmse: 0.0802982\n",
      "[300]\ttraining's rmse: 0.0784099\tvalid_1's rmse: 0.0802736\n",
      "[325]\ttraining's rmse: 0.0783457\tvalid_1's rmse: 0.0802487\n",
      "[350]\ttraining's rmse: 0.078284\tvalid_1's rmse: 0.0802266\n",
      "[375]\ttraining's rmse: 0.078236\tvalid_1's rmse: 0.0802066\n",
      "[400]\ttraining's rmse: 0.07818\tvalid_1's rmse: 0.0801874\n",
      "[425]\ttraining's rmse: 0.0781293\tvalid_1's rmse: 0.0801685\n",
      "[450]\ttraining's rmse: 0.0780821\tvalid_1's rmse: 0.0801504\n",
      "[475]\ttraining's rmse: 0.0780405\tvalid_1's rmse: 0.0801352\n",
      "[500]\ttraining's rmse: 0.0780064\tvalid_1's rmse: 0.0801208\n",
      "[525]\ttraining's rmse: 0.0779589\tvalid_1's rmse: 0.0801053\n",
      "[550]\ttraining's rmse: 0.077916\tvalid_1's rmse: 0.0800913\n",
      "[575]\ttraining's rmse: 0.0778763\tvalid_1's rmse: 0.080078\n",
      "[600]\ttraining's rmse: 0.0778365\tvalid_1's rmse: 0.0800645\n",
      "[625]\ttraining's rmse: 0.077807\tvalid_1's rmse: 0.0800523\n",
      "[650]\ttraining's rmse: 0.0777687\tvalid_1's rmse: 0.0800408\n",
      "[675]\ttraining's rmse: 0.0777312\tvalid_1's rmse: 0.0800305\n",
      "[700]\ttraining's rmse: 0.077696\tvalid_1's rmse: 0.0800196\n",
      "[725]\ttraining's rmse: 0.0776637\tvalid_1's rmse: 0.0800107\n",
      "[750]\ttraining's rmse: 0.0776335\tvalid_1's rmse: 0.0800018\n",
      "[775]\ttraining's rmse: 0.0776101\tvalid_1's rmse: 0.0799936\n",
      "[800]\ttraining's rmse: 0.0775791\tvalid_1's rmse: 0.0799861\n",
      "[825]\ttraining's rmse: 0.0775545\tvalid_1's rmse: 0.0799775\n",
      "[850]\ttraining's rmse: 0.0775274\tvalid_1's rmse: 0.0799707\n",
      "[875]\ttraining's rmse: 0.0775042\tvalid_1's rmse: 0.0799637\n",
      "[900]\ttraining's rmse: 0.077479\tvalid_1's rmse: 0.079957\n",
      "[925]\ttraining's rmse: 0.0774557\tvalid_1's rmse: 0.0799514\n",
      "[950]\ttraining's rmse: 0.0774333\tvalid_1's rmse: 0.0799455\n",
      "[975]\ttraining's rmse: 0.0774125\tvalid_1's rmse: 0.0799394\n",
      "[1000]\ttraining's rmse: 0.0773906\tvalid_1's rmse: 0.0799345\n",
      "[1025]\ttraining's rmse: 0.0773685\tvalid_1's rmse: 0.0799291\n",
      "[1050]\ttraining's rmse: 0.0773498\tvalid_1's rmse: 0.0799245\n",
      "[1075]\ttraining's rmse: 0.0773326\tvalid_1's rmse: 0.079921\n",
      "[1100]\ttraining's rmse: 0.077319\tvalid_1's rmse: 0.0799172\n",
      "[1125]\ttraining's rmse: 0.0773019\tvalid_1's rmse: 0.0799127\n",
      "[1150]\ttraining's rmse: 0.077286\tvalid_1's rmse: 0.0799094\n",
      "[1175]\ttraining's rmse: 0.0772705\tvalid_1's rmse: 0.0799057\n",
      "[1200]\ttraining's rmse: 0.0772564\tvalid_1's rmse: 0.0799021\n",
      "[1225]\ttraining's rmse: 0.0772433\tvalid_1's rmse: 0.079899\n",
      "[1250]\ttraining's rmse: 0.0772301\tvalid_1's rmse: 0.0798954\n",
      "[1275]\ttraining's rmse: 0.0772137\tvalid_1's rmse: 0.0798924\n",
      "[1300]\ttraining's rmse: 0.0772044\tvalid_1's rmse: 0.0798901\n",
      "[1325]\ttraining's rmse: 0.0771921\tvalid_1's rmse: 0.0798878\n",
      "[1350]\ttraining's rmse: 0.0771789\tvalid_1's rmse: 0.0798856\n",
      "[1375]\ttraining's rmse: 0.077169\tvalid_1's rmse: 0.079884\n",
      "[1400]\ttraining's rmse: 0.0771592\tvalid_1's rmse: 0.0798819\n",
      "[1425]\ttraining's rmse: 0.0771475\tvalid_1's rmse: 0.0798795\n",
      "[1450]\ttraining's rmse: 0.0771371\tvalid_1's rmse: 0.0798779\n",
      "[1475]\ttraining's rmse: 0.077129\tvalid_1's rmse: 0.0798762\n",
      "[1500]\ttraining's rmse: 0.077121\tvalid_1's rmse: 0.0798745\n",
      "[1525]\ttraining's rmse: 0.077113\tvalid_1's rmse: 0.079873\n",
      "[1550]\ttraining's rmse: 0.0771031\tvalid_1's rmse: 0.0798722\n",
      "[1575]\ttraining's rmse: 0.0770947\tvalid_1's rmse: 0.0798704\n",
      "[1600]\ttraining's rmse: 0.0770889\tvalid_1's rmse: 0.0798695\n",
      "[1625]\ttraining's rmse: 0.0770827\tvalid_1's rmse: 0.079868\n",
      "[1650]\ttraining's rmse: 0.0770751\tvalid_1's rmse: 0.0798671\n",
      "[1675]\ttraining's rmse: 0.0770707\tvalid_1's rmse: 0.079866\n",
      "[1700]\ttraining's rmse: 0.0770655\tvalid_1's rmse: 0.079865\n",
      "[1725]\ttraining's rmse: 0.0770595\tvalid_1's rmse: 0.0798636\n",
      "[1750]\ttraining's rmse: 0.0770527\tvalid_1's rmse: 0.0798624\n",
      "[1775]\ttraining's rmse: 0.0770471\tvalid_1's rmse: 0.0798614\n",
      "[1800]\ttraining's rmse: 0.0770415\tvalid_1's rmse: 0.0798609\n",
      "[1825]\ttraining's rmse: 0.0770369\tvalid_1's rmse: 0.0798602\n",
      "[1850]\ttraining's rmse: 0.0770311\tvalid_1's rmse: 0.079859\n",
      "[1875]\ttraining's rmse: 0.0770268\tvalid_1's rmse: 0.0798585\n",
      "[1900]\ttraining's rmse: 0.0770223\tvalid_1's rmse: 0.0798579\n",
      "[1925]\ttraining's rmse: 0.0770181\tvalid_1's rmse: 0.0798573\n",
      "[1950]\ttraining's rmse: 0.0770146\tvalid_1's rmse: 0.079857\n",
      "[1975]\ttraining's rmse: 0.0770102\tvalid_1's rmse: 0.0798563\n",
      "[2000]\ttraining's rmse: 0.0770052\tvalid_1's rmse: 0.0798557\n",
      "[2025]\ttraining's rmse: 0.0770015\tvalid_1's rmse: 0.079855\n",
      "[2050]\ttraining's rmse: 0.0769996\tvalid_1's rmse: 0.079855\n",
      "[2075]\ttraining's rmse: 0.0769953\tvalid_1's rmse: 0.0798545\n",
      "[2100]\ttraining's rmse: 0.0769926\tvalid_1's rmse: 0.0798538\n",
      "[2125]\ttraining's rmse: 0.0769899\tvalid_1's rmse: 0.0798537\n",
      "[2150]\ttraining's rmse: 0.0769861\tvalid_1's rmse: 0.0798527\n",
      "[2175]\ttraining's rmse: 0.0769834\tvalid_1's rmse: 0.0798524\n",
      "[2200]\ttraining's rmse: 0.0769818\tvalid_1's rmse: 0.0798521\n",
      "[2225]\ttraining's rmse: 0.0769796\tvalid_1's rmse: 0.0798519\n",
      "[2250]\ttraining's rmse: 0.0769768\tvalid_1's rmse: 0.0798521\n",
      "[2275]\ttraining's rmse: 0.0769739\tvalid_1's rmse: 0.0798518\n",
      "[2300]\ttraining's rmse: 0.0769718\tvalid_1's rmse: 0.0798514\n",
      "[2325]\ttraining's rmse: 0.0769695\tvalid_1's rmse: 0.0798512\n",
      "[2350]\ttraining's rmse: 0.0769681\tvalid_1's rmse: 0.0798514\n",
      "Early stopping, best iteration is:\n",
      "[2307]\ttraining's rmse: 0.0769706\tvalid_1's rmse: 0.079851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0808149\tvalid_1's rmse: 0.0776638\n",
      "[50]\ttraining's rmse: 0.0807153\tvalid_1's rmse: 0.077619\n",
      "[75]\ttraining's rmse: 0.0806118\tvalid_1's rmse: 0.0775729\n",
      "[100]\ttraining's rmse: 0.0805189\tvalid_1's rmse: 0.0775331\n",
      "[125]\ttraining's rmse: 0.0804215\tvalid_1's rmse: 0.0774938\n",
      "[150]\ttraining's rmse: 0.0803341\tvalid_1's rmse: 0.0774574\n",
      "[175]\ttraining's rmse: 0.0802602\tvalid_1's rmse: 0.0774276\n",
      "[200]\ttraining's rmse: 0.0801786\tvalid_1's rmse: 0.0773975\n",
      "[225]\ttraining's rmse: 0.0801008\tvalid_1's rmse: 0.0773683\n",
      "[250]\ttraining's rmse: 0.0800353\tvalid_1's rmse: 0.0773438\n",
      "[275]\ttraining's rmse: 0.0799728\tvalid_1's rmse: 0.077322\n",
      "[300]\ttraining's rmse: 0.0799102\tvalid_1's rmse: 0.077299\n",
      "[325]\ttraining's rmse: 0.0798481\tvalid_1's rmse: 0.0772765\n",
      "[350]\ttraining's rmse: 0.0797871\tvalid_1's rmse: 0.0772541\n",
      "[375]\ttraining's rmse: 0.0797378\tvalid_1's rmse: 0.0772455\n",
      "[400]\ttraining's rmse: 0.079684\tvalid_1's rmse: 0.0772364\n",
      "[425]\ttraining's rmse: 0.0796361\tvalid_1's rmse: 0.0772252\n",
      "[450]\ttraining's rmse: 0.0795918\tvalid_1's rmse: 0.0772141\n",
      "[475]\ttraining's rmse: 0.07955\tvalid_1's rmse: 0.0772013\n",
      "[500]\ttraining's rmse: 0.0795153\tvalid_1's rmse: 0.0771891\n",
      "[525]\ttraining's rmse: 0.0794683\tvalid_1's rmse: 0.0771851\n",
      "[550]\ttraining's rmse: 0.0794258\tvalid_1's rmse: 0.0771719\n",
      "[575]\ttraining's rmse: 0.0793855\tvalid_1's rmse: 0.077161\n",
      "[600]\ttraining's rmse: 0.0793453\tvalid_1's rmse: 0.0771549\n",
      "[625]\ttraining's rmse: 0.0793139\tvalid_1's rmse: 0.0771494\n",
      "[650]\ttraining's rmse: 0.0792754\tvalid_1's rmse: 0.0771403\n",
      "[675]\ttraining's rmse: 0.0792374\tvalid_1's rmse: 0.0771358\n",
      "[700]\ttraining's rmse: 0.0792043\tvalid_1's rmse: 0.0771273\n",
      "[725]\ttraining's rmse: 0.079172\tvalid_1's rmse: 0.0771265\n",
      "[750]\ttraining's rmse: 0.0791428\tvalid_1's rmse: 0.0771229\n",
      "[775]\ttraining's rmse: 0.0791199\tvalid_1's rmse: 0.0771167\n",
      "[800]\ttraining's rmse: 0.0790874\tvalid_1's rmse: 0.0771154\n",
      "[825]\ttraining's rmse: 0.0790612\tvalid_1's rmse: 0.0771092\n",
      "[850]\ttraining's rmse: 0.0790349\tvalid_1's rmse: 0.0771042\n",
      "[875]\ttraining's rmse: 0.0790115\tvalid_1's rmse: 0.077106\n",
      "[900]\ttraining's rmse: 0.0789856\tvalid_1's rmse: 0.0771114\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's rmse: 0.0790282\tvalid_1's rmse: 0.0771029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0780059\tvalid_1's rmse: 0.0801805\n",
      "[50]\ttraining's rmse: 0.0778939\tvalid_1's rmse: 0.0801314\n",
      "[75]\ttraining's rmse: 0.077782\tvalid_1's rmse: 0.0800837\n",
      "[100]\ttraining's rmse: 0.0776793\tvalid_1's rmse: 0.0800414\n",
      "[125]\ttraining's rmse: 0.0775755\tvalid_1's rmse: 0.0799985\n",
      "[150]\ttraining's rmse: 0.0774808\tvalid_1's rmse: 0.079961\n",
      "[175]\ttraining's rmse: 0.0774036\tvalid_1's rmse: 0.0799283\n",
      "[200]\ttraining's rmse: 0.0773205\tvalid_1's rmse: 0.0798955\n",
      "[225]\ttraining's rmse: 0.077236\tvalid_1's rmse: 0.0798624\n",
      "[250]\ttraining's rmse: 0.0771666\tvalid_1's rmse: 0.0798346\n",
      "[275]\ttraining's rmse: 0.0771021\tvalid_1's rmse: 0.0798102\n",
      "[300]\ttraining's rmse: 0.0770373\tvalid_1's rmse: 0.0797857\n",
      "[325]\ttraining's rmse: 0.0769712\tvalid_1's rmse: 0.0797623\n",
      "[350]\ttraining's rmse: 0.0769075\tvalid_1's rmse: 0.0797383\n",
      "[375]\ttraining's rmse: 0.0768557\tvalid_1's rmse: 0.0797179\n",
      "[400]\ttraining's rmse: 0.0767954\tvalid_1's rmse: 0.0796983\n",
      "[425]\ttraining's rmse: 0.0767428\tvalid_1's rmse: 0.079681\n",
      "[450]\ttraining's rmse: 0.0766973\tvalid_1's rmse: 0.0796627\n",
      "[475]\ttraining's rmse: 0.0766551\tvalid_1's rmse: 0.079646\n",
      "[500]\ttraining's rmse: 0.076616\tvalid_1's rmse: 0.0796309\n",
      "[525]\ttraining's rmse: 0.07657\tvalid_1's rmse: 0.0796173\n",
      "[550]\ttraining's rmse: 0.0765267\tvalid_1's rmse: 0.0796033\n",
      "[575]\ttraining's rmse: 0.0764865\tvalid_1's rmse: 0.07959\n",
      "[600]\ttraining's rmse: 0.0764496\tvalid_1's rmse: 0.0795775\n",
      "[625]\ttraining's rmse: 0.0764178\tvalid_1's rmse: 0.0795657\n",
      "[650]\ttraining's rmse: 0.0763807\tvalid_1's rmse: 0.079553\n",
      "[675]\ttraining's rmse: 0.0763452\tvalid_1's rmse: 0.0795416\n",
      "[700]\ttraining's rmse: 0.0763147\tvalid_1's rmse: 0.0795318\n",
      "[725]\ttraining's rmse: 0.0762864\tvalid_1's rmse: 0.0795232\n",
      "[750]\ttraining's rmse: 0.0762565\tvalid_1's rmse: 0.079514\n",
      "[775]\ttraining's rmse: 0.0762324\tvalid_1's rmse: 0.079503\n",
      "[800]\ttraining's rmse: 0.0762008\tvalid_1's rmse: 0.0794951\n",
      "[825]\ttraining's rmse: 0.0761732\tvalid_1's rmse: 0.0794882\n",
      "[850]\ttraining's rmse: 0.0761473\tvalid_1's rmse: 0.0794822\n",
      "[875]\ttraining's rmse: 0.0761273\tvalid_1's rmse: 0.0794754\n",
      "[900]\ttraining's rmse: 0.0761032\tvalid_1's rmse: 0.07947\n",
      "[925]\ttraining's rmse: 0.0760806\tvalid_1's rmse: 0.0794637\n",
      "[950]\ttraining's rmse: 0.0760611\tvalid_1's rmse: 0.0794586\n",
      "[975]\ttraining's rmse: 0.0760391\tvalid_1's rmse: 0.0794523\n",
      "[1000]\ttraining's rmse: 0.0760176\tvalid_1's rmse: 0.0794464\n",
      "[1025]\ttraining's rmse: 0.0759976\tvalid_1's rmse: 0.0794413\n",
      "[1050]\ttraining's rmse: 0.0759795\tvalid_1's rmse: 0.0794353\n",
      "[1075]\ttraining's rmse: 0.0759619\tvalid_1's rmse: 0.0794315\n",
      "[1100]\ttraining's rmse: 0.0759466\tvalid_1's rmse: 0.0794277\n",
      "[1125]\ttraining's rmse: 0.0759309\tvalid_1's rmse: 0.0794225\n",
      "[1150]\ttraining's rmse: 0.0759151\tvalid_1's rmse: 0.0794189\n",
      "[1175]\ttraining's rmse: 0.0758989\tvalid_1's rmse: 0.0794162\n",
      "[1200]\ttraining's rmse: 0.0758864\tvalid_1's rmse: 0.0794118\n",
      "[1225]\ttraining's rmse: 0.0758742\tvalid_1's rmse: 0.0794098\n",
      "[1250]\ttraining's rmse: 0.0758613\tvalid_1's rmse: 0.0794067\n",
      "[1275]\ttraining's rmse: 0.0758464\tvalid_1's rmse: 0.0794048\n",
      "[1300]\ttraining's rmse: 0.0758364\tvalid_1's rmse: 0.0794017\n",
      "[1325]\ttraining's rmse: 0.0758259\tvalid_1's rmse: 0.0793985\n",
      "[1350]\ttraining's rmse: 0.0758141\tvalid_1's rmse: 0.0793957\n",
      "[1375]\ttraining's rmse: 0.075803\tvalid_1's rmse: 0.0793945\n",
      "[1400]\ttraining's rmse: 0.0757952\tvalid_1's rmse: 0.0793915\n",
      "[1425]\ttraining's rmse: 0.0757846\tvalid_1's rmse: 0.0793894\n",
      "[1450]\ttraining's rmse: 0.075776\tvalid_1's rmse: 0.0793872\n",
      "[1475]\ttraining's rmse: 0.0757665\tvalid_1's rmse: 0.0793842\n",
      "[1500]\ttraining's rmse: 0.0757589\tvalid_1's rmse: 0.0793812\n",
      "[1525]\ttraining's rmse: 0.0757507\tvalid_1's rmse: 0.0793787\n",
      "[1550]\ttraining's rmse: 0.0757426\tvalid_1's rmse: 0.0793776\n",
      "[1575]\ttraining's rmse: 0.0757357\tvalid_1's rmse: 0.0793755\n",
      "[1600]\ttraining's rmse: 0.075731\tvalid_1's rmse: 0.0793739\n",
      "[1625]\ttraining's rmse: 0.0757251\tvalid_1's rmse: 0.0793718\n",
      "[1650]\ttraining's rmse: 0.0757187\tvalid_1's rmse: 0.0793711\n",
      "[1675]\ttraining's rmse: 0.0757147\tvalid_1's rmse: 0.0793699\n",
      "[1700]\ttraining's rmse: 0.0757084\tvalid_1's rmse: 0.0793677\n",
      "[1725]\ttraining's rmse: 0.0757037\tvalid_1's rmse: 0.0793665\n",
      "[1750]\ttraining's rmse: 0.0756973\tvalid_1's rmse: 0.0793658\n",
      "[1775]\ttraining's rmse: 0.0756917\tvalid_1's rmse: 0.0793645\n",
      "[1800]\ttraining's rmse: 0.0756875\tvalid_1's rmse: 0.079364\n",
      "[1825]\ttraining's rmse: 0.0756825\tvalid_1's rmse: 0.0793619\n",
      "[1850]\ttraining's rmse: 0.0756759\tvalid_1's rmse: 0.0793608\n",
      "[1875]\ttraining's rmse: 0.0756725\tvalid_1's rmse: 0.0793597\n",
      "[1900]\ttraining's rmse: 0.0756684\tvalid_1's rmse: 0.0793593\n",
      "[1925]\ttraining's rmse: 0.0756622\tvalid_1's rmse: 0.0793587\n",
      "[1950]\ttraining's rmse: 0.0756591\tvalid_1's rmse: 0.0793571\n",
      "[1975]\ttraining's rmse: 0.075654\tvalid_1's rmse: 0.0793558\n",
      "[2000]\ttraining's rmse: 0.0756504\tvalid_1's rmse: 0.0793547\n",
      "[2025]\ttraining's rmse: 0.0756475\tvalid_1's rmse: 0.0793537\n",
      "[2050]\ttraining's rmse: 0.0756437\tvalid_1's rmse: 0.0793524\n",
      "[2075]\ttraining's rmse: 0.0756408\tvalid_1's rmse: 0.0793509\n",
      "[2100]\ttraining's rmse: 0.0756375\tvalid_1's rmse: 0.0793488\n",
      "[2125]\ttraining's rmse: 0.0756362\tvalid_1's rmse: 0.0793484\n",
      "[2150]\ttraining's rmse: 0.0756332\tvalid_1's rmse: 0.0793477\n",
      "[2175]\ttraining's rmse: 0.0756312\tvalid_1's rmse: 0.0793478\n",
      "[2200]\ttraining's rmse: 0.0756296\tvalid_1's rmse: 0.0793472\n",
      "[2225]\ttraining's rmse: 0.075626\tvalid_1's rmse: 0.0793458\n",
      "[2250]\ttraining's rmse: 0.0756233\tvalid_1's rmse: 0.0793444\n",
      "[2275]\ttraining's rmse: 0.0756198\tvalid_1's rmse: 0.0793424\n",
      "[2300]\ttraining's rmse: 0.0756173\tvalid_1's rmse: 0.0793419\n",
      "[2325]\ttraining's rmse: 0.075614\tvalid_1's rmse: 0.0793422\n",
      "[2350]\ttraining's rmse: 0.0756116\tvalid_1's rmse: 0.0793419\n",
      "[2375]\ttraining's rmse: 0.07561\tvalid_1's rmse: 0.0793408\n",
      "[2400]\ttraining's rmse: 0.075607\tvalid_1's rmse: 0.0793404\n",
      "[2425]\ttraining's rmse: 0.0756046\tvalid_1's rmse: 0.0793404\n",
      "[2450]\ttraining's rmse: 0.0756028\tvalid_1's rmse: 0.0793399\n",
      "[2475]\ttraining's rmse: 0.0756012\tvalid_1's rmse: 0.0793403\n",
      "Early stopping, best iteration is:\n",
      "[2449]\ttraining's rmse: 0.0756029\tvalid_1's rmse: 0.0793398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0782188\tvalid_1's rmse: 0.0797665\n",
      "[50]\ttraining's rmse: 0.078115\tvalid_1's rmse: 0.0797155\n",
      "[75]\ttraining's rmse: 0.0780091\tvalid_1's rmse: 0.0796657\n",
      "[100]\ttraining's rmse: 0.0779142\tvalid_1's rmse: 0.079621\n",
      "[125]\ttraining's rmse: 0.0778163\tvalid_1's rmse: 0.0795753\n",
      "[150]\ttraining's rmse: 0.0777235\tvalid_1's rmse: 0.0795345\n",
      "[175]\ttraining's rmse: 0.0776497\tvalid_1's rmse: 0.0795011\n",
      "[200]\ttraining's rmse: 0.0775694\tvalid_1's rmse: 0.0794674\n",
      "[225]\ttraining's rmse: 0.077491\tvalid_1's rmse: 0.0794348\n",
      "[250]\ttraining's rmse: 0.0774244\tvalid_1's rmse: 0.0794055\n",
      "[275]\ttraining's rmse: 0.0773632\tvalid_1's rmse: 0.0793787\n",
      "[300]\ttraining's rmse: 0.0773008\tvalid_1's rmse: 0.0793533\n",
      "[325]\ttraining's rmse: 0.0772359\tvalid_1's rmse: 0.0793285\n",
      "[350]\ttraining's rmse: 0.0771735\tvalid_1's rmse: 0.0793047\n",
      "[375]\ttraining's rmse: 0.0771238\tvalid_1's rmse: 0.0792854\n",
      "[400]\ttraining's rmse: 0.0770696\tvalid_1's rmse: 0.0792653\n",
      "[425]\ttraining's rmse: 0.0770214\tvalid_1's rmse: 0.0792472\n",
      "[450]\ttraining's rmse: 0.076974\tvalid_1's rmse: 0.0792299\n",
      "[475]\ttraining's rmse: 0.0769318\tvalid_1's rmse: 0.0792138\n",
      "[500]\ttraining's rmse: 0.0768933\tvalid_1's rmse: 0.0791988\n",
      "[525]\ttraining's rmse: 0.0768457\tvalid_1's rmse: 0.0791823\n",
      "[550]\ttraining's rmse: 0.0768046\tvalid_1's rmse: 0.079168\n",
      "[575]\ttraining's rmse: 0.0767659\tvalid_1's rmse: 0.0791555\n",
      "[600]\ttraining's rmse: 0.0767276\tvalid_1's rmse: 0.079144\n",
      "[625]\ttraining's rmse: 0.0766987\tvalid_1's rmse: 0.0791328\n",
      "[650]\ttraining's rmse: 0.0766613\tvalid_1's rmse: 0.0791207\n",
      "[675]\ttraining's rmse: 0.0766233\tvalid_1's rmse: 0.07911\n",
      "[700]\ttraining's rmse: 0.0765907\tvalid_1's rmse: 0.0791001\n",
      "[725]\ttraining's rmse: 0.0765604\tvalid_1's rmse: 0.0790912\n",
      "[750]\ttraining's rmse: 0.0765315\tvalid_1's rmse: 0.0790824\n",
      "[775]\ttraining's rmse: 0.0765073\tvalid_1's rmse: 0.0790746\n",
      "[800]\ttraining's rmse: 0.0764773\tvalid_1's rmse: 0.079068\n",
      "[825]\ttraining's rmse: 0.0764516\tvalid_1's rmse: 0.0790603\n",
      "[850]\ttraining's rmse: 0.0764263\tvalid_1's rmse: 0.0790541\n",
      "[875]\ttraining's rmse: 0.0764024\tvalid_1's rmse: 0.079048\n",
      "[900]\ttraining's rmse: 0.0763777\tvalid_1's rmse: 0.079041\n",
      "[925]\ttraining's rmse: 0.0763543\tvalid_1's rmse: 0.0790352\n",
      "[950]\ttraining's rmse: 0.0763348\tvalid_1's rmse: 0.0790302\n",
      "[975]\ttraining's rmse: 0.0763137\tvalid_1's rmse: 0.0790251\n",
      "[1000]\ttraining's rmse: 0.0762938\tvalid_1's rmse: 0.0790206\n",
      "[1025]\ttraining's rmse: 0.0762719\tvalid_1's rmse: 0.079016\n",
      "[1050]\ttraining's rmse: 0.0762547\tvalid_1's rmse: 0.0790115\n",
      "[1075]\ttraining's rmse: 0.0762362\tvalid_1's rmse: 0.0790079\n",
      "[1100]\ttraining's rmse: 0.076221\tvalid_1's rmse: 0.0790041\n",
      "[1125]\ttraining's rmse: 0.0762041\tvalid_1's rmse: 0.0790001\n",
      "[1150]\ttraining's rmse: 0.0761869\tvalid_1's rmse: 0.0789964\n",
      "[1175]\ttraining's rmse: 0.076172\tvalid_1's rmse: 0.0789934\n",
      "[1200]\ttraining's rmse: 0.0761581\tvalid_1's rmse: 0.0789905\n",
      "[1225]\ttraining's rmse: 0.0761449\tvalid_1's rmse: 0.0789875\n",
      "[1250]\ttraining's rmse: 0.0761315\tvalid_1's rmse: 0.0789848\n",
      "[1275]\ttraining's rmse: 0.0761159\tvalid_1's rmse: 0.0789827\n",
      "[1300]\ttraining's rmse: 0.0761043\tvalid_1's rmse: 0.0789797\n",
      "[1325]\ttraining's rmse: 0.0760929\tvalid_1's rmse: 0.0789781\n",
      "[1350]\ttraining's rmse: 0.0760813\tvalid_1's rmse: 0.0789759\n",
      "[1375]\ttraining's rmse: 0.0760684\tvalid_1's rmse: 0.0789734\n",
      "[1400]\ttraining's rmse: 0.0760576\tvalid_1's rmse: 0.0789707\n",
      "[1425]\ttraining's rmse: 0.0760462\tvalid_1's rmse: 0.0789689\n",
      "[1450]\ttraining's rmse: 0.0760369\tvalid_1's rmse: 0.0789672\n",
      "[1475]\ttraining's rmse: 0.0760273\tvalid_1's rmse: 0.0789658\n",
      "[1500]\ttraining's rmse: 0.0760186\tvalid_1's rmse: 0.0789639\n",
      "[1525]\ttraining's rmse: 0.0760115\tvalid_1's rmse: 0.0789627\n",
      "[1550]\ttraining's rmse: 0.0760037\tvalid_1's rmse: 0.0789618\n",
      "[1575]\ttraining's rmse: 0.0759958\tvalid_1's rmse: 0.0789603\n",
      "[1600]\ttraining's rmse: 0.0759896\tvalid_1's rmse: 0.0789595\n",
      "[1625]\ttraining's rmse: 0.0759819\tvalid_1's rmse: 0.078959\n",
      "[1650]\ttraining's rmse: 0.0759756\tvalid_1's rmse: 0.0789578\n",
      "[1675]\ttraining's rmse: 0.0759704\tvalid_1's rmse: 0.0789567\n",
      "[1700]\ttraining's rmse: 0.0759652\tvalid_1's rmse: 0.0789554\n",
      "[1725]\ttraining's rmse: 0.0759607\tvalid_1's rmse: 0.0789541\n",
      "[1750]\ttraining's rmse: 0.0759543\tvalid_1's rmse: 0.078953\n",
      "[1775]\ttraining's rmse: 0.0759492\tvalid_1's rmse: 0.0789523\n",
      "[1800]\ttraining's rmse: 0.0759446\tvalid_1's rmse: 0.0789518\n",
      "[1825]\ttraining's rmse: 0.0759409\tvalid_1's rmse: 0.0789513\n",
      "[1850]\ttraining's rmse: 0.0759367\tvalid_1's rmse: 0.0789505\n",
      "[1875]\ttraining's rmse: 0.0759332\tvalid_1's rmse: 0.0789506\n",
      "[1900]\ttraining's rmse: 0.0759299\tvalid_1's rmse: 0.0789503\n",
      "[1925]\ttraining's rmse: 0.075927\tvalid_1's rmse: 0.07895\n",
      "[1950]\ttraining's rmse: 0.0759232\tvalid_1's rmse: 0.0789493\n",
      "[1975]\ttraining's rmse: 0.0759204\tvalid_1's rmse: 0.0789489\n",
      "[2000]\ttraining's rmse: 0.0759152\tvalid_1's rmse: 0.0789484\n",
      "[2025]\ttraining's rmse: 0.075911\tvalid_1's rmse: 0.0789479\n",
      "[2050]\ttraining's rmse: 0.0759075\tvalid_1's rmse: 0.0789474\n",
      "[2075]\ttraining's rmse: 0.0759043\tvalid_1's rmse: 0.0789471\n",
      "[2100]\ttraining's rmse: 0.0759016\tvalid_1's rmse: 0.0789468\n",
      "[2125]\ttraining's rmse: 0.0758983\tvalid_1's rmse: 0.0789467\n",
      "[2150]\ttraining's rmse: 0.0758953\tvalid_1's rmse: 0.0789468\n",
      "[2175]\ttraining's rmse: 0.0758924\tvalid_1's rmse: 0.0789463\n",
      "[2200]\ttraining's rmse: 0.0758906\tvalid_1's rmse: 0.0789457\n",
      "[2225]\ttraining's rmse: 0.0758869\tvalid_1's rmse: 0.078945\n",
      "[2250]\ttraining's rmse: 0.0758845\tvalid_1's rmse: 0.0789447\n",
      "[2275]\ttraining's rmse: 0.0758806\tvalid_1's rmse: 0.0789446\n",
      "[2300]\ttraining's rmse: 0.0758783\tvalid_1's rmse: 0.0789446\n",
      "[2325]\ttraining's rmse: 0.0758767\tvalid_1's rmse: 0.0789445\n",
      "[2350]\ttraining's rmse: 0.0758747\tvalid_1's rmse: 0.0789446\n",
      "[2375]\ttraining's rmse: 0.0758729\tvalid_1's rmse: 0.0789443\n",
      "[2400]\ttraining's rmse: 0.0758692\tvalid_1's rmse: 0.0789438\n",
      "[2425]\ttraining's rmse: 0.0758676\tvalid_1's rmse: 0.0789438\n",
      "[2450]\ttraining's rmse: 0.0758656\tvalid_1's rmse: 0.0789438\n",
      "Early stopping, best iteration is:\n",
      "[2403]\ttraining's rmse: 0.0758689\tvalid_1's rmse: 0.0789436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0798653\tvalid_1's rmse: 0.0764235\n",
      "[50]\ttraining's rmse: 0.0797667\tvalid_1's rmse: 0.076379\n",
      "[75]\ttraining's rmse: 0.0796639\tvalid_1's rmse: 0.0763341\n",
      "[100]\ttraining's rmse: 0.0795741\tvalid_1's rmse: 0.076295\n",
      "[125]\ttraining's rmse: 0.079479\tvalid_1's rmse: 0.0762622\n",
      "[150]\ttraining's rmse: 0.0793911\tvalid_1's rmse: 0.0762261\n",
      "[175]\ttraining's rmse: 0.0793187\tvalid_1's rmse: 0.0761961\n",
      "[200]\ttraining's rmse: 0.0792396\tvalid_1's rmse: 0.0761662\n",
      "[225]\ttraining's rmse: 0.0791648\tvalid_1's rmse: 0.0761374\n",
      "[250]\ttraining's rmse: 0.079103\tvalid_1's rmse: 0.076113\n",
      "[275]\ttraining's rmse: 0.0790435\tvalid_1's rmse: 0.0760884\n",
      "[300]\ttraining's rmse: 0.0789842\tvalid_1's rmse: 0.0760657\n",
      "[325]\ttraining's rmse: 0.0789259\tvalid_1's rmse: 0.0760439\n",
      "[350]\ttraining's rmse: 0.0788674\tvalid_1's rmse: 0.0760235\n",
      "[375]\ttraining's rmse: 0.0788202\tvalid_1's rmse: 0.0760065\n",
      "[400]\ttraining's rmse: 0.0787689\tvalid_1's rmse: 0.0759964\n",
      "[425]\ttraining's rmse: 0.0787202\tvalid_1's rmse: 0.0759879\n",
      "[450]\ttraining's rmse: 0.078676\tvalid_1's rmse: 0.0759757\n",
      "[475]\ttraining's rmse: 0.0786335\tvalid_1's rmse: 0.075974\n",
      "[500]\ttraining's rmse: 0.0785992\tvalid_1's rmse: 0.0759608\n",
      "[525]\ttraining's rmse: 0.0785523\tvalid_1's rmse: 0.0759546\n",
      "[550]\ttraining's rmse: 0.0785108\tvalid_1's rmse: 0.0759425\n",
      "[575]\ttraining's rmse: 0.0784721\tvalid_1's rmse: 0.0759451\n",
      "[600]\ttraining's rmse: 0.0784337\tvalid_1's rmse: 0.0759406\n",
      "[625]\ttraining's rmse: 0.0784035\tvalid_1's rmse: 0.075941\n",
      "[650]\ttraining's rmse: 0.0783675\tvalid_1's rmse: 0.075933\n",
      "[675]\ttraining's rmse: 0.0783306\tvalid_1's rmse: 0.0759412\n",
      "[700]\ttraining's rmse: 0.0782968\tvalid_1's rmse: 0.0759401\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's rmse: 0.0783612\tvalid_1's rmse: 0.0759322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0800932\tvalid_1's rmse: 0.082358\n",
      "[50]\ttraining's rmse: 0.0799701\tvalid_1's rmse: 0.0823106\n",
      "[75]\ttraining's rmse: 0.079846\tvalid_1's rmse: 0.0822618\n",
      "[100]\ttraining's rmse: 0.079731\tvalid_1's rmse: 0.0822206\n",
      "[125]\ttraining's rmse: 0.0796212\tvalid_1's rmse: 0.0821786\n",
      "[150]\ttraining's rmse: 0.0795161\tvalid_1's rmse: 0.0821399\n",
      "[175]\ttraining's rmse: 0.0794305\tvalid_1's rmse: 0.0821079\n",
      "[200]\ttraining's rmse: 0.0793345\tvalid_1's rmse: 0.0820745\n",
      "[225]\ttraining's rmse: 0.0792447\tvalid_1's rmse: 0.0820431\n",
      "[250]\ttraining's rmse: 0.079169\tvalid_1's rmse: 0.0820141\n",
      "[275]\ttraining's rmse: 0.0790975\tvalid_1's rmse: 0.0819874\n",
      "[300]\ttraining's rmse: 0.0790258\tvalid_1's rmse: 0.0819618\n",
      "[325]\ttraining's rmse: 0.0789569\tvalid_1's rmse: 0.0819376\n",
      "[350]\ttraining's rmse: 0.0788899\tvalid_1's rmse: 0.0819151\n",
      "[375]\ttraining's rmse: 0.0788366\tvalid_1's rmse: 0.0818972\n",
      "[400]\ttraining's rmse: 0.0787737\tvalid_1's rmse: 0.0818768\n",
      "[425]\ttraining's rmse: 0.0787194\tvalid_1's rmse: 0.081859\n",
      "[450]\ttraining's rmse: 0.078668\tvalid_1's rmse: 0.0818401\n",
      "[475]\ttraining's rmse: 0.0786235\tvalid_1's rmse: 0.0818257\n",
      "[500]\ttraining's rmse: 0.0785837\tvalid_1's rmse: 0.0818097\n",
      "[525]\ttraining's rmse: 0.078534\tvalid_1's rmse: 0.0817948\n",
      "[550]\ttraining's rmse: 0.078488\tvalid_1's rmse: 0.0817811\n",
      "[575]\ttraining's rmse: 0.0784427\tvalid_1's rmse: 0.0817688\n",
      "[600]\ttraining's rmse: 0.0784005\tvalid_1's rmse: 0.0817568\n",
      "[625]\ttraining's rmse: 0.0783679\tvalid_1's rmse: 0.0817459\n",
      "[650]\ttraining's rmse: 0.0783295\tvalid_1's rmse: 0.0817356\n",
      "[675]\ttraining's rmse: 0.0782892\tvalid_1's rmse: 0.0817254\n",
      "[700]\ttraining's rmse: 0.0782556\tvalid_1's rmse: 0.0817159\n",
      "[725]\ttraining's rmse: 0.0782233\tvalid_1's rmse: 0.0817076\n",
      "[750]\ttraining's rmse: 0.0781911\tvalid_1's rmse: 0.0816993\n",
      "[775]\ttraining's rmse: 0.0781655\tvalid_1's rmse: 0.0816916\n",
      "[800]\ttraining's rmse: 0.0781319\tvalid_1's rmse: 0.0816833\n",
      "[825]\ttraining's rmse: 0.078105\tvalid_1's rmse: 0.0816755\n",
      "[850]\ttraining's rmse: 0.0780767\tvalid_1's rmse: 0.081669\n",
      "[875]\ttraining's rmse: 0.078053\tvalid_1's rmse: 0.0816629\n",
      "[900]\ttraining's rmse: 0.078026\tvalid_1's rmse: 0.0816573\n",
      "[925]\ttraining's rmse: 0.0780015\tvalid_1's rmse: 0.0816506\n",
      "[950]\ttraining's rmse: 0.0779784\tvalid_1's rmse: 0.0816445\n",
      "[975]\ttraining's rmse: 0.077959\tvalid_1's rmse: 0.0816383\n",
      "[1000]\ttraining's rmse: 0.0779356\tvalid_1's rmse: 0.0816339\n",
      "[1025]\ttraining's rmse: 0.0779142\tvalid_1's rmse: 0.0816295\n",
      "[1050]\ttraining's rmse: 0.0778944\tvalid_1's rmse: 0.0816242\n",
      "[1075]\ttraining's rmse: 0.0778764\tvalid_1's rmse: 0.0816202\n",
      "[1100]\ttraining's rmse: 0.0778609\tvalid_1's rmse: 0.0816159\n",
      "[1125]\ttraining's rmse: 0.0778436\tvalid_1's rmse: 0.0816112\n",
      "[1150]\ttraining's rmse: 0.0778245\tvalid_1's rmse: 0.0816073\n",
      "[1175]\ttraining's rmse: 0.0778094\tvalid_1's rmse: 0.0816048\n",
      "[1200]\ttraining's rmse: 0.0777944\tvalid_1's rmse: 0.081599\n",
      "[1225]\ttraining's rmse: 0.0777807\tvalid_1's rmse: 0.081595\n",
      "[1250]\ttraining's rmse: 0.0777688\tvalid_1's rmse: 0.081592\n",
      "[1275]\ttraining's rmse: 0.077754\tvalid_1's rmse: 0.08159\n",
      "[1300]\ttraining's rmse: 0.0777412\tvalid_1's rmse: 0.0815864\n",
      "[1325]\ttraining's rmse: 0.0777287\tvalid_1's rmse: 0.0815837\n",
      "[1350]\ttraining's rmse: 0.0777149\tvalid_1's rmse: 0.0815814\n",
      "[1375]\ttraining's rmse: 0.0777046\tvalid_1's rmse: 0.0815796\n",
      "[1400]\ttraining's rmse: 0.0776959\tvalid_1's rmse: 0.0815776\n",
      "[1425]\ttraining's rmse: 0.0776839\tvalid_1's rmse: 0.0815754\n",
      "[1450]\ttraining's rmse: 0.0776734\tvalid_1's rmse: 0.0815719\n",
      "[1475]\ttraining's rmse: 0.0776636\tvalid_1's rmse: 0.0815697\n",
      "[1500]\ttraining's rmse: 0.0776555\tvalid_1's rmse: 0.0815669\n",
      "[1525]\ttraining's rmse: 0.0776463\tvalid_1's rmse: 0.081566\n",
      "[1550]\ttraining's rmse: 0.0776383\tvalid_1's rmse: 0.0815636\n",
      "[1575]\ttraining's rmse: 0.0776311\tvalid_1's rmse: 0.0815613\n",
      "[1600]\ttraining's rmse: 0.0776259\tvalid_1's rmse: 0.0815598\n",
      "[1625]\ttraining's rmse: 0.0776185\tvalid_1's rmse: 0.0815575\n",
      "[1650]\ttraining's rmse: 0.0776125\tvalid_1's rmse: 0.0815554\n",
      "[1675]\ttraining's rmse: 0.0776081\tvalid_1's rmse: 0.0815544\n",
      "[1700]\ttraining's rmse: 0.0776036\tvalid_1's rmse: 0.0815531\n",
      "[1725]\ttraining's rmse: 0.0775989\tvalid_1's rmse: 0.0815522\n",
      "[1750]\ttraining's rmse: 0.0775913\tvalid_1's rmse: 0.0815496\n",
      "[1775]\ttraining's rmse: 0.0775871\tvalid_1's rmse: 0.0815489\n",
      "[1800]\ttraining's rmse: 0.0775825\tvalid_1's rmse: 0.0815465\n",
      "[1825]\ttraining's rmse: 0.0775784\tvalid_1's rmse: 0.0815451\n",
      "[1850]\ttraining's rmse: 0.0775735\tvalid_1's rmse: 0.0815434\n",
      "[1875]\ttraining's rmse: 0.0775692\tvalid_1's rmse: 0.0815425\n",
      "[1900]\ttraining's rmse: 0.0775648\tvalid_1's rmse: 0.0815421\n",
      "[1925]\ttraining's rmse: 0.0775618\tvalid_1's rmse: 0.0815417\n",
      "[1950]\ttraining's rmse: 0.0775581\tvalid_1's rmse: 0.0815405\n",
      "[1975]\ttraining's rmse: 0.0775551\tvalid_1's rmse: 0.0815386\n",
      "[2000]\ttraining's rmse: 0.0775498\tvalid_1's rmse: 0.0815378\n",
      "[2025]\ttraining's rmse: 0.0775473\tvalid_1's rmse: 0.0815363\n",
      "[2050]\ttraining's rmse: 0.0775426\tvalid_1's rmse: 0.0815353\n",
      "[2075]\ttraining's rmse: 0.0775394\tvalid_1's rmse: 0.0815342\n",
      "[2100]\ttraining's rmse: 0.0775352\tvalid_1's rmse: 0.0815325\n",
      "[2125]\ttraining's rmse: 0.0775328\tvalid_1's rmse: 0.0815318\n",
      "[2150]\ttraining's rmse: 0.0775284\tvalid_1's rmse: 0.0815305\n",
      "[2175]\ttraining's rmse: 0.0775257\tvalid_1's rmse: 0.0815297\n",
      "[2200]\ttraining's rmse: 0.0775227\tvalid_1's rmse: 0.081529\n",
      "[2225]\ttraining's rmse: 0.0775203\tvalid_1's rmse: 0.0815283\n",
      "[2250]\ttraining's rmse: 0.0775173\tvalid_1's rmse: 0.0815281\n",
      "[2275]\ttraining's rmse: 0.0775148\tvalid_1's rmse: 0.0815276\n",
      "[2300]\ttraining's rmse: 0.0775088\tvalid_1's rmse: 0.0815269\n",
      "[2325]\ttraining's rmse: 0.0775052\tvalid_1's rmse: 0.0815252\n",
      "[2350]\ttraining's rmse: 0.0775035\tvalid_1's rmse: 0.0815253\n",
      "[2375]\ttraining's rmse: 0.0775017\tvalid_1's rmse: 0.0815249\n",
      "[2400]\ttraining's rmse: 0.0774996\tvalid_1's rmse: 0.0815238\n",
      "[2425]\ttraining's rmse: 0.0774965\tvalid_1's rmse: 0.0815229\n",
      "[2450]\ttraining's rmse: 0.0774945\tvalid_1's rmse: 0.0815221\n",
      "[2475]\ttraining's rmse: 0.0774908\tvalid_1's rmse: 0.0815221\n",
      "[2500]\ttraining's rmse: 0.0774888\tvalid_1's rmse: 0.081522\n",
      "[2525]\ttraining's rmse: 0.0774863\tvalid_1's rmse: 0.0815217\n",
      "[2550]\ttraining's rmse: 0.077484\tvalid_1's rmse: 0.0815209\n",
      "[2575]\ttraining's rmse: 0.0774824\tvalid_1's rmse: 0.0815204\n",
      "[2600]\ttraining's rmse: 0.0774796\tvalid_1's rmse: 0.0815202\n",
      "[2625]\ttraining's rmse: 0.0774785\tvalid_1's rmse: 0.0815202\n",
      "[2650]\ttraining's rmse: 0.0774764\tvalid_1's rmse: 0.0815198\n",
      "[2675]\ttraining's rmse: 0.0774744\tvalid_1's rmse: 0.0815197\n",
      "[2700]\ttraining's rmse: 0.0774728\tvalid_1's rmse: 0.081519\n",
      "[2725]\ttraining's rmse: 0.0774707\tvalid_1's rmse: 0.0815186\n",
      "[2750]\ttraining's rmse: 0.07747\tvalid_1's rmse: 0.0815186\n",
      "[2775]\ttraining's rmse: 0.077469\tvalid_1's rmse: 0.0815186\n",
      "[2800]\ttraining's rmse: 0.0774675\tvalid_1's rmse: 0.0815184\n",
      "[2825]\ttraining's rmse: 0.0774663\tvalid_1's rmse: 0.0815185\n",
      "Early stopping, best iteration is:\n",
      "[2783]\ttraining's rmse: 0.0774686\tvalid_1's rmse: 0.0815183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0804015\tvalid_1's rmse: 0.0817756\n",
      "[50]\ttraining's rmse: 0.0802903\tvalid_1's rmse: 0.0817239\n",
      "[75]\ttraining's rmse: 0.0801773\tvalid_1's rmse: 0.0816737\n",
      "[100]\ttraining's rmse: 0.0800783\tvalid_1's rmse: 0.0816292\n",
      "[125]\ttraining's rmse: 0.0799763\tvalid_1's rmse: 0.0815857\n",
      "[150]\ttraining's rmse: 0.0798805\tvalid_1's rmse: 0.0815434\n",
      "[175]\ttraining's rmse: 0.0797996\tvalid_1's rmse: 0.0815094\n",
      "[200]\ttraining's rmse: 0.079712\tvalid_1's rmse: 0.0814733\n",
      "[225]\ttraining's rmse: 0.0796293\tvalid_1's rmse: 0.0814416\n",
      "[250]\ttraining's rmse: 0.079559\tvalid_1's rmse: 0.0814113\n",
      "[275]\ttraining's rmse: 0.0794937\tvalid_1's rmse: 0.0813837\n",
      "[300]\ttraining's rmse: 0.0794287\tvalid_1's rmse: 0.0813577\n",
      "[325]\ttraining's rmse: 0.0793609\tvalid_1's rmse: 0.081332\n",
      "[350]\ttraining's rmse: 0.0792977\tvalid_1's rmse: 0.0813085\n",
      "[375]\ttraining's rmse: 0.0792453\tvalid_1's rmse: 0.0812881\n",
      "[400]\ttraining's rmse: 0.0791854\tvalid_1's rmse: 0.0812675\n",
      "[425]\ttraining's rmse: 0.0791332\tvalid_1's rmse: 0.0812492\n",
      "[450]\ttraining's rmse: 0.0790845\tvalid_1's rmse: 0.081231\n",
      "[475]\ttraining's rmse: 0.0790403\tvalid_1's rmse: 0.081214\n",
      "[500]\ttraining's rmse: 0.0790028\tvalid_1's rmse: 0.0811989\n",
      "[525]\ttraining's rmse: 0.0789546\tvalid_1's rmse: 0.0811839\n",
      "[550]\ttraining's rmse: 0.0789107\tvalid_1's rmse: 0.0811695\n",
      "[575]\ttraining's rmse: 0.0788694\tvalid_1's rmse: 0.081156\n",
      "[600]\ttraining's rmse: 0.0788276\tvalid_1's rmse: 0.0811433\n",
      "[625]\ttraining's rmse: 0.0787963\tvalid_1's rmse: 0.0811316\n",
      "[650]\ttraining's rmse: 0.0787567\tvalid_1's rmse: 0.0811189\n",
      "[675]\ttraining's rmse: 0.0787185\tvalid_1's rmse: 0.0811077\n",
      "[700]\ttraining's rmse: 0.078684\tvalid_1's rmse: 0.0810977\n",
      "[725]\ttraining's rmse: 0.0786533\tvalid_1's rmse: 0.0810876\n",
      "[750]\ttraining's rmse: 0.0786255\tvalid_1's rmse: 0.0810797\n",
      "[775]\ttraining's rmse: 0.0786006\tvalid_1's rmse: 0.0810702\n",
      "[800]\ttraining's rmse: 0.0785674\tvalid_1's rmse: 0.0810621\n",
      "[825]\ttraining's rmse: 0.0785423\tvalid_1's rmse: 0.0810537\n",
      "[850]\ttraining's rmse: 0.0785152\tvalid_1's rmse: 0.0810474\n",
      "[875]\ttraining's rmse: 0.0784899\tvalid_1's rmse: 0.081041\n",
      "[900]\ttraining's rmse: 0.0784629\tvalid_1's rmse: 0.0810339\n",
      "[925]\ttraining's rmse: 0.0784391\tvalid_1's rmse: 0.0810274\n",
      "[950]\ttraining's rmse: 0.0784166\tvalid_1's rmse: 0.0810227\n",
      "[975]\ttraining's rmse: 0.078396\tvalid_1's rmse: 0.0810171\n",
      "[1000]\ttraining's rmse: 0.0783755\tvalid_1's rmse: 0.0810116\n",
      "[1025]\ttraining's rmse: 0.0783527\tvalid_1's rmse: 0.0810078\n",
      "[1050]\ttraining's rmse: 0.078333\tvalid_1's rmse: 0.0810026\n",
      "[1075]\ttraining's rmse: 0.0783137\tvalid_1's rmse: 0.0809987\n",
      "[1100]\ttraining's rmse: 0.0782988\tvalid_1's rmse: 0.0809947\n",
      "[1125]\ttraining's rmse: 0.0782831\tvalid_1's rmse: 0.0809908\n",
      "[1150]\ttraining's rmse: 0.0782684\tvalid_1's rmse: 0.0809874\n",
      "[1175]\ttraining's rmse: 0.078254\tvalid_1's rmse: 0.0809839\n",
      "[1200]\ttraining's rmse: 0.0782402\tvalid_1's rmse: 0.0809809\n",
      "[1225]\ttraining's rmse: 0.0782247\tvalid_1's rmse: 0.0809776\n",
      "[1250]\ttraining's rmse: 0.0782113\tvalid_1's rmse: 0.0809747\n",
      "[1275]\ttraining's rmse: 0.0781948\tvalid_1's rmse: 0.0809731\n",
      "[1300]\ttraining's rmse: 0.0781837\tvalid_1's rmse: 0.0809701\n",
      "[1325]\ttraining's rmse: 0.078173\tvalid_1's rmse: 0.0809678\n",
      "[1350]\ttraining's rmse: 0.0781591\tvalid_1's rmse: 0.0809648\n",
      "[1375]\ttraining's rmse: 0.0781468\tvalid_1's rmse: 0.0809623\n",
      "[1400]\ttraining's rmse: 0.0781383\tvalid_1's rmse: 0.0809594\n",
      "[1425]\ttraining's rmse: 0.0781285\tvalid_1's rmse: 0.0809578\n",
      "[1450]\ttraining's rmse: 0.0781177\tvalid_1's rmse: 0.0809566\n",
      "[1475]\ttraining's rmse: 0.0781083\tvalid_1's rmse: 0.0809547\n",
      "[1500]\ttraining's rmse: 0.0781004\tvalid_1's rmse: 0.0809532\n",
      "[1525]\ttraining's rmse: 0.0780915\tvalid_1's rmse: 0.080952\n",
      "[1550]\ttraining's rmse: 0.0780836\tvalid_1's rmse: 0.080951\n",
      "[1575]\ttraining's rmse: 0.0780757\tvalid_1's rmse: 0.0809492\n",
      "[1600]\ttraining's rmse: 0.0780709\tvalid_1's rmse: 0.0809486\n",
      "[1625]\ttraining's rmse: 0.078064\tvalid_1's rmse: 0.0809472\n",
      "[1650]\ttraining's rmse: 0.0780575\tvalid_1's rmse: 0.0809462\n",
      "[1675]\ttraining's rmse: 0.0780513\tvalid_1's rmse: 0.0809449\n",
      "[1700]\ttraining's rmse: 0.0780461\tvalid_1's rmse: 0.0809438\n",
      "[1725]\ttraining's rmse: 0.0780404\tvalid_1's rmse: 0.0809429\n",
      "[1750]\ttraining's rmse: 0.0780342\tvalid_1's rmse: 0.0809421\n",
      "[1775]\ttraining's rmse: 0.0780288\tvalid_1's rmse: 0.0809414\n",
      "[1800]\ttraining's rmse: 0.0780245\tvalid_1's rmse: 0.0809406\n",
      "[1825]\ttraining's rmse: 0.0780195\tvalid_1's rmse: 0.0809402\n",
      "[1850]\ttraining's rmse: 0.0780143\tvalid_1's rmse: 0.080939\n",
      "[1875]\ttraining's rmse: 0.0780102\tvalid_1's rmse: 0.0809385\n",
      "[1900]\ttraining's rmse: 0.0780069\tvalid_1's rmse: 0.0809381\n",
      "[1925]\ttraining's rmse: 0.0780035\tvalid_1's rmse: 0.0809381\n",
      "[1950]\ttraining's rmse: 0.0779984\tvalid_1's rmse: 0.080937\n",
      "[1975]\ttraining's rmse: 0.0779938\tvalid_1's rmse: 0.0809358\n",
      "[2000]\ttraining's rmse: 0.0779889\tvalid_1's rmse: 0.0809353\n",
      "[2025]\ttraining's rmse: 0.0779853\tvalid_1's rmse: 0.0809347\n",
      "[2050]\ttraining's rmse: 0.07798\tvalid_1's rmse: 0.0809341\n",
      "[2075]\ttraining's rmse: 0.0779775\tvalid_1's rmse: 0.0809332\n",
      "[2100]\ttraining's rmse: 0.0779734\tvalid_1's rmse: 0.0809326\n",
      "[2125]\ttraining's rmse: 0.0779708\tvalid_1's rmse: 0.0809326\n",
      "[2150]\ttraining's rmse: 0.0779668\tvalid_1's rmse: 0.0809324\n",
      "[2175]\ttraining's rmse: 0.0779634\tvalid_1's rmse: 0.080932\n",
      "[2200]\ttraining's rmse: 0.0779599\tvalid_1's rmse: 0.0809318\n",
      "[2225]\ttraining's rmse: 0.0779579\tvalid_1's rmse: 0.0809316\n",
      "[2250]\ttraining's rmse: 0.0779555\tvalid_1's rmse: 0.0809314\n",
      "[2275]\ttraining's rmse: 0.0779531\tvalid_1's rmse: 0.0809312\n",
      "[2300]\ttraining's rmse: 0.0779504\tvalid_1's rmse: 0.080931\n",
      "[2325]\ttraining's rmse: 0.0779475\tvalid_1's rmse: 0.0809309\n",
      "[2350]\ttraining's rmse: 0.0779455\tvalid_1's rmse: 0.0809307\n",
      "[2375]\ttraining's rmse: 0.0779427\tvalid_1's rmse: 0.0809303\n",
      "[2400]\ttraining's rmse: 0.0779406\tvalid_1's rmse: 0.0809305\n",
      "[2425]\ttraining's rmse: 0.0779392\tvalid_1's rmse: 0.0809304\n",
      "Early stopping, best iteration is:\n",
      "[2384]\ttraining's rmse: 0.0779422\tvalid_1's rmse: 0.0809301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0819541\tvalid_1's rmse: 0.0786174\n",
      "[50]\ttraining's rmse: 0.0818526\tvalid_1's rmse: 0.0785712\n",
      "[75]\ttraining's rmse: 0.0817438\tvalid_1's rmse: 0.0785262\n",
      "[100]\ttraining's rmse: 0.0816474\tvalid_1's rmse: 0.0784864\n",
      "[125]\ttraining's rmse: 0.0815455\tvalid_1's rmse: 0.078447\n",
      "[150]\ttraining's rmse: 0.0814519\tvalid_1's rmse: 0.0784102\n",
      "[175]\ttraining's rmse: 0.0813731\tvalid_1's rmse: 0.0783815\n",
      "[200]\ttraining's rmse: 0.0812878\tvalid_1's rmse: 0.0783511\n",
      "[225]\ttraining's rmse: 0.0812068\tvalid_1's rmse: 0.0783209\n",
      "[250]\ttraining's rmse: 0.0811401\tvalid_1's rmse: 0.078295\n",
      "[275]\ttraining's rmse: 0.0810771\tvalid_1's rmse: 0.0782718\n",
      "[300]\ttraining's rmse: 0.081013\tvalid_1's rmse: 0.0782494\n",
      "[325]\ttraining's rmse: 0.0809482\tvalid_1's rmse: 0.0782271\n",
      "[350]\ttraining's rmse: 0.0808859\tvalid_1's rmse: 0.0782069\n",
      "[375]\ttraining's rmse: 0.0808355\tvalid_1's rmse: 0.0781935\n",
      "[400]\ttraining's rmse: 0.0807805\tvalid_1's rmse: 0.0781806\n",
      "[425]\ttraining's rmse: 0.0807323\tvalid_1's rmse: 0.0781655\n",
      "[450]\ttraining's rmse: 0.0806835\tvalid_1's rmse: 0.0781514\n",
      "[475]\ttraining's rmse: 0.0806407\tvalid_1's rmse: 0.078139\n",
      "[500]\ttraining's rmse: 0.0806044\tvalid_1's rmse: 0.0781267\n",
      "[525]\ttraining's rmse: 0.0805552\tvalid_1's rmse: 0.0781123\n",
      "[550]\ttraining's rmse: 0.0805129\tvalid_1's rmse: 0.0781017\n",
      "[575]\ttraining's rmse: 0.080472\tvalid_1's rmse: 0.0780913\n",
      "[600]\ttraining's rmse: 0.0804323\tvalid_1's rmse: 0.0780821\n",
      "[625]\ttraining's rmse: 0.0804014\tvalid_1's rmse: 0.0780757\n",
      "[650]\ttraining's rmse: 0.0803601\tvalid_1's rmse: 0.0780697\n",
      "[675]\ttraining's rmse: 0.0803198\tvalid_1's rmse: 0.0780664\n",
      "[700]\ttraining's rmse: 0.0802864\tvalid_1's rmse: 0.0780593\n",
      "[725]\ttraining's rmse: 0.0802526\tvalid_1's rmse: 0.0780608\n",
      "[750]\ttraining's rmse: 0.0802221\tvalid_1's rmse: 0.0780631\n",
      "[775]\ttraining's rmse: 0.0801974\tvalid_1's rmse: 0.0780623\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 0.0802303\tvalid_1's rmse: 0.0780561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0785636\tvalid_1's rmse: 0.0809296\n",
      "[50]\ttraining's rmse: 0.078452\tvalid_1's rmse: 0.0808807\n",
      "[75]\ttraining's rmse: 0.0783369\tvalid_1's rmse: 0.0808322\n",
      "[100]\ttraining's rmse: 0.0782347\tvalid_1's rmse: 0.0807908\n",
      "[125]\ttraining's rmse: 0.0781277\tvalid_1's rmse: 0.0807481\n",
      "[150]\ttraining's rmse: 0.07803\tvalid_1's rmse: 0.0807106\n",
      "[175]\ttraining's rmse: 0.0779511\tvalid_1's rmse: 0.0806773\n",
      "[200]\ttraining's rmse: 0.0778677\tvalid_1's rmse: 0.0806445\n",
      "[225]\ttraining's rmse: 0.0777858\tvalid_1's rmse: 0.080612\n",
      "[250]\ttraining's rmse: 0.0777176\tvalid_1's rmse: 0.0805825\n",
      "[275]\ttraining's rmse: 0.0776518\tvalid_1's rmse: 0.0805566\n",
      "[300]\ttraining's rmse: 0.0775868\tvalid_1's rmse: 0.0805314\n",
      "[325]\ttraining's rmse: 0.0775203\tvalid_1's rmse: 0.0805065\n",
      "[350]\ttraining's rmse: 0.0774573\tvalid_1's rmse: 0.080484\n",
      "[375]\ttraining's rmse: 0.0774064\tvalid_1's rmse: 0.0804648\n",
      "[400]\ttraining's rmse: 0.0773478\tvalid_1's rmse: 0.0804457\n",
      "[425]\ttraining's rmse: 0.0772988\tvalid_1's rmse: 0.0804273\n",
      "[450]\ttraining's rmse: 0.0772512\tvalid_1's rmse: 0.0804088\n",
      "[475]\ttraining's rmse: 0.0772082\tvalid_1's rmse: 0.0803924\n",
      "[500]\ttraining's rmse: 0.0771701\tvalid_1's rmse: 0.0803773\n",
      "[525]\ttraining's rmse: 0.0771241\tvalid_1's rmse: 0.0803623\n",
      "[550]\ttraining's rmse: 0.0770832\tvalid_1's rmse: 0.0803485\n",
      "[575]\ttraining's rmse: 0.0770446\tvalid_1's rmse: 0.0803357\n",
      "[600]\ttraining's rmse: 0.0770078\tvalid_1's rmse: 0.0803245\n",
      "[625]\ttraining's rmse: 0.0769756\tvalid_1's rmse: 0.080313\n",
      "[650]\ttraining's rmse: 0.0769414\tvalid_1's rmse: 0.0803025\n",
      "[675]\ttraining's rmse: 0.0769055\tvalid_1's rmse: 0.0802905\n",
      "[700]\ttraining's rmse: 0.0768737\tvalid_1's rmse: 0.0802813\n",
      "[725]\ttraining's rmse: 0.0768401\tvalid_1's rmse: 0.0802713\n",
      "[750]\ttraining's rmse: 0.0768087\tvalid_1's rmse: 0.0802627\n",
      "[775]\ttraining's rmse: 0.0767855\tvalid_1's rmse: 0.0802531\n",
      "[800]\ttraining's rmse: 0.0767552\tvalid_1's rmse: 0.0802447\n",
      "[825]\ttraining's rmse: 0.0767324\tvalid_1's rmse: 0.0802375\n",
      "[850]\ttraining's rmse: 0.0767052\tvalid_1's rmse: 0.0802312\n",
      "[875]\ttraining's rmse: 0.0766818\tvalid_1's rmse: 0.0802243\n",
      "[900]\ttraining's rmse: 0.0766554\tvalid_1's rmse: 0.0802166\n",
      "[925]\ttraining's rmse: 0.0766319\tvalid_1's rmse: 0.0802099\n",
      "[950]\ttraining's rmse: 0.0766107\tvalid_1's rmse: 0.0802043\n",
      "[975]\ttraining's rmse: 0.0765925\tvalid_1's rmse: 0.0801989\n",
      "[1000]\ttraining's rmse: 0.076573\tvalid_1's rmse: 0.0801943\n",
      "[1025]\ttraining's rmse: 0.0765519\tvalid_1's rmse: 0.0801876\n",
      "[1050]\ttraining's rmse: 0.0765339\tvalid_1's rmse: 0.080183\n",
      "[1075]\ttraining's rmse: 0.0765179\tvalid_1's rmse: 0.0801778\n",
      "[1100]\ttraining's rmse: 0.0765031\tvalid_1's rmse: 0.0801732\n",
      "[1125]\ttraining's rmse: 0.0764889\tvalid_1's rmse: 0.0801672\n",
      "[1150]\ttraining's rmse: 0.0764718\tvalid_1's rmse: 0.0801634\n",
      "[1175]\ttraining's rmse: 0.0764573\tvalid_1's rmse: 0.0801604\n",
      "[1200]\ttraining's rmse: 0.076444\tvalid_1's rmse: 0.0801565\n",
      "[1225]\ttraining's rmse: 0.0764299\tvalid_1's rmse: 0.0801522\n",
      "[1250]\ttraining's rmse: 0.0764174\tvalid_1's rmse: 0.0801487\n",
      "[1275]\ttraining's rmse: 0.0764007\tvalid_1's rmse: 0.0801458\n",
      "[1300]\ttraining's rmse: 0.0763917\tvalid_1's rmse: 0.0801432\n",
      "[1325]\ttraining's rmse: 0.0763802\tvalid_1's rmse: 0.0801394\n",
      "[1350]\ttraining's rmse: 0.0763686\tvalid_1's rmse: 0.0801367\n",
      "[1375]\ttraining's rmse: 0.0763575\tvalid_1's rmse: 0.0801349\n",
      "[1400]\ttraining's rmse: 0.0763492\tvalid_1's rmse: 0.0801308\n",
      "[1425]\ttraining's rmse: 0.0763379\tvalid_1's rmse: 0.0801286\n",
      "[1450]\ttraining's rmse: 0.0763268\tvalid_1's rmse: 0.0801261\n",
      "[1475]\ttraining's rmse: 0.0763171\tvalid_1's rmse: 0.0801237\n",
      "[1500]\ttraining's rmse: 0.0763094\tvalid_1's rmse: 0.0801213\n",
      "[1525]\ttraining's rmse: 0.0763014\tvalid_1's rmse: 0.0801193\n",
      "[1550]\ttraining's rmse: 0.0762935\tvalid_1's rmse: 0.0801179\n",
      "[1575]\ttraining's rmse: 0.0762847\tvalid_1's rmse: 0.0801155\n",
      "[1600]\ttraining's rmse: 0.0762779\tvalid_1's rmse: 0.0801132\n",
      "[1625]\ttraining's rmse: 0.0762716\tvalid_1's rmse: 0.0801101\n",
      "[1650]\ttraining's rmse: 0.0762664\tvalid_1's rmse: 0.0801077\n",
      "[1675]\ttraining's rmse: 0.0762611\tvalid_1's rmse: 0.0801069\n",
      "[1700]\ttraining's rmse: 0.0762565\tvalid_1's rmse: 0.0801041\n",
      "[1725]\ttraining's rmse: 0.0762496\tvalid_1's rmse: 0.0801018\n",
      "[1750]\ttraining's rmse: 0.0762449\tvalid_1's rmse: 0.0800987\n",
      "[1775]\ttraining's rmse: 0.0762391\tvalid_1's rmse: 0.0800975\n",
      "[1800]\ttraining's rmse: 0.0762345\tvalid_1's rmse: 0.0800939\n",
      "[1825]\ttraining's rmse: 0.0762303\tvalid_1's rmse: 0.0800935\n",
      "[1850]\ttraining's rmse: 0.0762267\tvalid_1's rmse: 0.0800928\n",
      "[1875]\ttraining's rmse: 0.0762217\tvalid_1's rmse: 0.0800918\n",
      "[1900]\ttraining's rmse: 0.0762173\tvalid_1's rmse: 0.0800909\n",
      "[1925]\ttraining's rmse: 0.0762137\tvalid_1's rmse: 0.0800904\n",
      "[1950]\ttraining's rmse: 0.0762101\tvalid_1's rmse: 0.0800897\n",
      "[1975]\ttraining's rmse: 0.0762073\tvalid_1's rmse: 0.0800888\n",
      "[2000]\ttraining's rmse: 0.0762034\tvalid_1's rmse: 0.0800886\n",
      "[2025]\ttraining's rmse: 0.0762008\tvalid_1's rmse: 0.0800867\n",
      "[2050]\ttraining's rmse: 0.0761981\tvalid_1's rmse: 0.0800848\n",
      "[2075]\ttraining's rmse: 0.0761955\tvalid_1's rmse: 0.0800846\n",
      "[2100]\ttraining's rmse: 0.0761932\tvalid_1's rmse: 0.0800832\n",
      "[2125]\ttraining's rmse: 0.0761908\tvalid_1's rmse: 0.0800826\n",
      "[2150]\ttraining's rmse: 0.0761877\tvalid_1's rmse: 0.0800826\n",
      "[2175]\ttraining's rmse: 0.0761858\tvalid_1's rmse: 0.0800818\n",
      "[2200]\ttraining's rmse: 0.0761833\tvalid_1's rmse: 0.0800806\n",
      "[2225]\ttraining's rmse: 0.076181\tvalid_1's rmse: 0.0800797\n",
      "[2250]\ttraining's rmse: 0.0761786\tvalid_1's rmse: 0.080079\n",
      "[2275]\ttraining's rmse: 0.076176\tvalid_1's rmse: 0.0800778\n",
      "[2300]\ttraining's rmse: 0.0761728\tvalid_1's rmse: 0.0800767\n",
      "[2325]\ttraining's rmse: 0.0761704\tvalid_1's rmse: 0.0800759\n",
      "[2350]\ttraining's rmse: 0.0761681\tvalid_1's rmse: 0.0800754\n",
      "[2375]\ttraining's rmse: 0.0761654\tvalid_1's rmse: 0.080074\n",
      "[2400]\ttraining's rmse: 0.0761627\tvalid_1's rmse: 0.0800733\n",
      "[2425]\ttraining's rmse: 0.0761607\tvalid_1's rmse: 0.0800726\n",
      "[2450]\ttraining's rmse: 0.076159\tvalid_1's rmse: 0.0800719\n",
      "[2475]\ttraining's rmse: 0.0761564\tvalid_1's rmse: 0.0800712\n",
      "[2500]\ttraining's rmse: 0.0761546\tvalid_1's rmse: 0.0800706\n",
      "[2525]\ttraining's rmse: 0.0761524\tvalid_1's rmse: 0.0800703\n",
      "[2550]\ttraining's rmse: 0.0761511\tvalid_1's rmse: 0.0800704\n",
      "[2575]\ttraining's rmse: 0.07615\tvalid_1's rmse: 0.08007\n",
      "[2600]\ttraining's rmse: 0.0761487\tvalid_1's rmse: 0.0800696\n",
      "[2625]\ttraining's rmse: 0.0761475\tvalid_1's rmse: 0.0800695\n",
      "[2650]\ttraining's rmse: 0.0761459\tvalid_1's rmse: 0.0800693\n",
      "[2675]\ttraining's rmse: 0.0761445\tvalid_1's rmse: 0.0800688\n",
      "[2700]\ttraining's rmse: 0.0761434\tvalid_1's rmse: 0.0800687\n",
      "[2725]\ttraining's rmse: 0.0761414\tvalid_1's rmse: 0.0800678\n",
      "[2750]\ttraining's rmse: 0.0761404\tvalid_1's rmse: 0.0800676\n",
      "[2775]\ttraining's rmse: 0.0761394\tvalid_1's rmse: 0.0800676\n",
      "[2800]\ttraining's rmse: 0.0761383\tvalid_1's rmse: 0.0800677\n",
      "Early stopping, best iteration is:\n",
      "[2762]\ttraining's rmse: 0.0761398\tvalid_1's rmse: 0.0800674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0788667\tvalid_1's rmse: 0.0803394\n",
      "[50]\ttraining's rmse: 0.0787623\tvalid_1's rmse: 0.0802886\n",
      "[75]\ttraining's rmse: 0.0786555\tvalid_1's rmse: 0.0802381\n",
      "[100]\ttraining's rmse: 0.07856\tvalid_1's rmse: 0.0801939\n",
      "[125]\ttraining's rmse: 0.0784593\tvalid_1's rmse: 0.0801477\n",
      "[150]\ttraining's rmse: 0.0783686\tvalid_1's rmse: 0.0801069\n",
      "[175]\ttraining's rmse: 0.0782929\tvalid_1's rmse: 0.0800727\n",
      "[200]\ttraining's rmse: 0.0782121\tvalid_1's rmse: 0.0800381\n",
      "[225]\ttraining's rmse: 0.0781329\tvalid_1's rmse: 0.0800062\n",
      "[250]\ttraining's rmse: 0.0780668\tvalid_1's rmse: 0.0799776\n",
      "[275]\ttraining's rmse: 0.0780058\tvalid_1's rmse: 0.0799505\n",
      "[300]\ttraining's rmse: 0.0779416\tvalid_1's rmse: 0.0799246\n",
      "[325]\ttraining's rmse: 0.0778768\tvalid_1's rmse: 0.0798987\n",
      "[350]\ttraining's rmse: 0.0778131\tvalid_1's rmse: 0.0798752\n",
      "[375]\ttraining's rmse: 0.0777606\tvalid_1's rmse: 0.0798552\n",
      "[400]\ttraining's rmse: 0.0777065\tvalid_1's rmse: 0.0798361\n",
      "[425]\ttraining's rmse: 0.077657\tvalid_1's rmse: 0.079818\n",
      "[450]\ttraining's rmse: 0.0776089\tvalid_1's rmse: 0.0798\n",
      "[475]\ttraining's rmse: 0.077566\tvalid_1's rmse: 0.0797829\n",
      "[500]\ttraining's rmse: 0.0775273\tvalid_1's rmse: 0.0797678\n",
      "[525]\ttraining's rmse: 0.0774817\tvalid_1's rmse: 0.0797525\n",
      "[550]\ttraining's rmse: 0.077439\tvalid_1's rmse: 0.0797387\n",
      "[575]\ttraining's rmse: 0.0773988\tvalid_1's rmse: 0.0797265\n",
      "[600]\ttraining's rmse: 0.077362\tvalid_1's rmse: 0.0797145\n",
      "[625]\ttraining's rmse: 0.0773319\tvalid_1's rmse: 0.0797031\n",
      "[650]\ttraining's rmse: 0.0772942\tvalid_1's rmse: 0.0796915\n",
      "[675]\ttraining's rmse: 0.077256\tvalid_1's rmse: 0.0796812\n",
      "[700]\ttraining's rmse: 0.0772225\tvalid_1's rmse: 0.0796707\n",
      "[725]\ttraining's rmse: 0.0771908\tvalid_1's rmse: 0.0796619\n",
      "[750]\ttraining's rmse: 0.0771624\tvalid_1's rmse: 0.0796535\n",
      "[775]\ttraining's rmse: 0.0771381\tvalid_1's rmse: 0.0796454\n",
      "[800]\ttraining's rmse: 0.0771062\tvalid_1's rmse: 0.0796387\n",
      "[825]\ttraining's rmse: 0.0770805\tvalid_1's rmse: 0.0796314\n",
      "[850]\ttraining's rmse: 0.0770546\tvalid_1's rmse: 0.079625\n",
      "[875]\ttraining's rmse: 0.0770316\tvalid_1's rmse: 0.0796181\n",
      "[900]\ttraining's rmse: 0.077007\tvalid_1's rmse: 0.0796121\n",
      "[925]\ttraining's rmse: 0.0769842\tvalid_1's rmse: 0.0796069\n",
      "[950]\ttraining's rmse: 0.0769627\tvalid_1's rmse: 0.0796016\n",
      "[975]\ttraining's rmse: 0.0769415\tvalid_1's rmse: 0.079597\n",
      "[1000]\ttraining's rmse: 0.076923\tvalid_1's rmse: 0.079593\n",
      "[1025]\ttraining's rmse: 0.0769001\tvalid_1's rmse: 0.0795879\n",
      "[1050]\ttraining's rmse: 0.0768816\tvalid_1's rmse: 0.0795833\n",
      "[1075]\ttraining's rmse: 0.0768627\tvalid_1's rmse: 0.0795793\n",
      "[1100]\ttraining's rmse: 0.0768482\tvalid_1's rmse: 0.0795758\n",
      "[1125]\ttraining's rmse: 0.0768316\tvalid_1's rmse: 0.0795715\n",
      "[1150]\ttraining's rmse: 0.0768158\tvalid_1's rmse: 0.0795683\n",
      "[1175]\ttraining's rmse: 0.0768004\tvalid_1's rmse: 0.0795655\n",
      "[1200]\ttraining's rmse: 0.0767848\tvalid_1's rmse: 0.0795618\n",
      "[1225]\ttraining's rmse: 0.0767693\tvalid_1's rmse: 0.0795585\n",
      "[1250]\ttraining's rmse: 0.0767572\tvalid_1's rmse: 0.0795557\n",
      "[1275]\ttraining's rmse: 0.076741\tvalid_1's rmse: 0.0795531\n",
      "[1300]\ttraining's rmse: 0.0767299\tvalid_1's rmse: 0.0795507\n",
      "[1325]\ttraining's rmse: 0.0767174\tvalid_1's rmse: 0.0795493\n",
      "[1350]\ttraining's rmse: 0.0767058\tvalid_1's rmse: 0.0795475\n",
      "[1375]\ttraining's rmse: 0.0766952\tvalid_1's rmse: 0.0795453\n",
      "[1400]\ttraining's rmse: 0.0766865\tvalid_1's rmse: 0.0795428\n",
      "[1425]\ttraining's rmse: 0.0766783\tvalid_1's rmse: 0.0795412\n",
      "[1450]\ttraining's rmse: 0.0766696\tvalid_1's rmse: 0.07954\n",
      "[1475]\ttraining's rmse: 0.0766613\tvalid_1's rmse: 0.0795379\n",
      "[1500]\ttraining's rmse: 0.0766532\tvalid_1's rmse: 0.0795367\n",
      "[1525]\ttraining's rmse: 0.0766455\tvalid_1's rmse: 0.079535\n",
      "[1550]\ttraining's rmse: 0.0766384\tvalid_1's rmse: 0.0795339\n",
      "[1575]\ttraining's rmse: 0.0766309\tvalid_1's rmse: 0.0795322\n",
      "[1600]\ttraining's rmse: 0.076623\tvalid_1's rmse: 0.0795315\n",
      "[1625]\ttraining's rmse: 0.0766166\tvalid_1's rmse: 0.0795301\n",
      "[1650]\ttraining's rmse: 0.0766089\tvalid_1's rmse: 0.0795289\n",
      "[1675]\ttraining's rmse: 0.0766042\tvalid_1's rmse: 0.0795274\n",
      "[1700]\ttraining's rmse: 0.0765988\tvalid_1's rmse: 0.0795259\n",
      "[1725]\ttraining's rmse: 0.0765935\tvalid_1's rmse: 0.0795254\n",
      "[1750]\ttraining's rmse: 0.0765884\tvalid_1's rmse: 0.079525\n",
      "[1775]\ttraining's rmse: 0.0765834\tvalid_1's rmse: 0.0795242\n",
      "[1800]\ttraining's rmse: 0.0765791\tvalid_1's rmse: 0.0795236\n",
      "[1825]\ttraining's rmse: 0.0765735\tvalid_1's rmse: 0.079523\n",
      "[1850]\ttraining's rmse: 0.0765678\tvalid_1's rmse: 0.0795222\n",
      "[1875]\ttraining's rmse: 0.0765637\tvalid_1's rmse: 0.0795218\n",
      "[1900]\ttraining's rmse: 0.0765608\tvalid_1's rmse: 0.0795218\n",
      "[1925]\ttraining's rmse: 0.0765581\tvalid_1's rmse: 0.0795218\n",
      "[1950]\ttraining's rmse: 0.0765545\tvalid_1's rmse: 0.0795211\n",
      "[1975]\ttraining's rmse: 0.0765511\tvalid_1's rmse: 0.0795211\n",
      "[2000]\ttraining's rmse: 0.0765462\tvalid_1's rmse: 0.0795206\n",
      "[2025]\ttraining's rmse: 0.0765436\tvalid_1's rmse: 0.07952\n",
      "[2050]\ttraining's rmse: 0.0765396\tvalid_1's rmse: 0.0795194\n",
      "[2075]\ttraining's rmse: 0.0765372\tvalid_1's rmse: 0.0795187\n",
      "[2100]\ttraining's rmse: 0.0765341\tvalid_1's rmse: 0.0795186\n",
      "[2125]\ttraining's rmse: 0.0765316\tvalid_1's rmse: 0.0795188\n",
      "Early stopping, best iteration is:\n",
      "[2076]\ttraining's rmse: 0.0765371\tvalid_1's rmse: 0.0795186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0805235\tvalid_1's rmse: 0.0769675\n",
      "[50]\ttraining's rmse: 0.080425\tvalid_1's rmse: 0.0769228\n",
      "[75]\ttraining's rmse: 0.080322\tvalid_1's rmse: 0.0768836\n",
      "[100]\ttraining's rmse: 0.0802278\tvalid_1's rmse: 0.0768433\n",
      "[125]\ttraining's rmse: 0.0801322\tvalid_1's rmse: 0.0768104\n",
      "[150]\ttraining's rmse: 0.0800436\tvalid_1's rmse: 0.076773\n",
      "[175]\ttraining's rmse: 0.0799696\tvalid_1's rmse: 0.076743\n",
      "[200]\ttraining's rmse: 0.0798889\tvalid_1's rmse: 0.0767124\n",
      "[225]\ttraining's rmse: 0.079811\tvalid_1's rmse: 0.0766836\n",
      "[250]\ttraining's rmse: 0.0797483\tvalid_1's rmse: 0.0766594\n",
      "[275]\ttraining's rmse: 0.0796877\tvalid_1's rmse: 0.0766347\n",
      "[300]\ttraining's rmse: 0.0796261\tvalid_1's rmse: 0.0766119\n",
      "[325]\ttraining's rmse: 0.0795661\tvalid_1's rmse: 0.0765909\n",
      "[350]\ttraining's rmse: 0.0795052\tvalid_1's rmse: 0.0765714\n",
      "[375]\ttraining's rmse: 0.079457\tvalid_1's rmse: 0.0765574\n",
      "[400]\ttraining's rmse: 0.0794041\tvalid_1's rmse: 0.0765419\n",
      "[425]\ttraining's rmse: 0.0793554\tvalid_1's rmse: 0.0765288\n",
      "[450]\ttraining's rmse: 0.0793121\tvalid_1's rmse: 0.076513\n",
      "[475]\ttraining's rmse: 0.0792702\tvalid_1's rmse: 0.0765117\n",
      "[500]\ttraining's rmse: 0.0792373\tvalid_1's rmse: 0.076499\n",
      "[525]\ttraining's rmse: 0.0791903\tvalid_1's rmse: 0.0764937\n",
      "[550]\ttraining's rmse: 0.0791488\tvalid_1's rmse: 0.0764822\n",
      "[575]\ttraining's rmse: 0.0791092\tvalid_1's rmse: 0.0764731\n",
      "[600]\ttraining's rmse: 0.0790714\tvalid_1's rmse: 0.0764677\n",
      "[625]\ttraining's rmse: 0.0790416\tvalid_1's rmse: 0.0764687\n",
      "[650]\ttraining's rmse: 0.0790042\tvalid_1's rmse: 0.0764675\n",
      "Early stopping, best iteration is:\n",
      "[607]\ttraining's rmse: 0.0790638\tvalid_1's rmse: 0.0764652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0811062\tvalid_1's rmse: 0.0831914\n",
      "[50]\ttraining's rmse: 0.0809833\tvalid_1's rmse: 0.0831443\n",
      "[75]\ttraining's rmse: 0.0808607\tvalid_1's rmse: 0.0830946\n",
      "[100]\ttraining's rmse: 0.0807477\tvalid_1's rmse: 0.0830516\n",
      "[125]\ttraining's rmse: 0.0806343\tvalid_1's rmse: 0.0830085\n",
      "[150]\ttraining's rmse: 0.0805302\tvalid_1's rmse: 0.0829702\n",
      "[175]\ttraining's rmse: 0.080442\tvalid_1's rmse: 0.0829371\n",
      "[200]\ttraining's rmse: 0.0803488\tvalid_1's rmse: 0.0829041\n",
      "[225]\ttraining's rmse: 0.080255\tvalid_1's rmse: 0.0828714\n",
      "[250]\ttraining's rmse: 0.0801788\tvalid_1's rmse: 0.0828422\n",
      "[275]\ttraining's rmse: 0.0801091\tvalid_1's rmse: 0.0828176\n",
      "[300]\ttraining's rmse: 0.0800367\tvalid_1's rmse: 0.0827909\n",
      "[325]\ttraining's rmse: 0.0799691\tvalid_1's rmse: 0.0827678\n",
      "[350]\ttraining's rmse: 0.0799027\tvalid_1's rmse: 0.0827455\n",
      "[375]\ttraining's rmse: 0.0798437\tvalid_1's rmse: 0.0827275\n",
      "[400]\ttraining's rmse: 0.0797807\tvalid_1's rmse: 0.0827083\n",
      "[425]\ttraining's rmse: 0.0797247\tvalid_1's rmse: 0.0826922\n",
      "[450]\ttraining's rmse: 0.0796748\tvalid_1's rmse: 0.0826734\n",
      "[475]\ttraining's rmse: 0.0796299\tvalid_1's rmse: 0.0826585\n",
      "[500]\ttraining's rmse: 0.0795921\tvalid_1's rmse: 0.082643\n",
      "[525]\ttraining's rmse: 0.0795408\tvalid_1's rmse: 0.082629\n",
      "[550]\ttraining's rmse: 0.0794936\tvalid_1's rmse: 0.0826151\n",
      "[575]\ttraining's rmse: 0.0794499\tvalid_1's rmse: 0.0826026\n",
      "[600]\ttraining's rmse: 0.0794073\tvalid_1's rmse: 0.0825891\n",
      "[625]\ttraining's rmse: 0.0793742\tvalid_1's rmse: 0.0825796\n",
      "[650]\ttraining's rmse: 0.0793334\tvalid_1's rmse: 0.0825693\n",
      "[675]\ttraining's rmse: 0.0792957\tvalid_1's rmse: 0.0825588\n",
      "[700]\ttraining's rmse: 0.0792595\tvalid_1's rmse: 0.082549\n",
      "[725]\ttraining's rmse: 0.0792256\tvalid_1's rmse: 0.0825403\n",
      "[750]\ttraining's rmse: 0.0791911\tvalid_1's rmse: 0.0825328\n",
      "[775]\ttraining's rmse: 0.0791636\tvalid_1's rmse: 0.0825249\n",
      "[800]\ttraining's rmse: 0.0791295\tvalid_1's rmse: 0.0825175\n",
      "[825]\ttraining's rmse: 0.0791031\tvalid_1's rmse: 0.0825105\n",
      "[850]\ttraining's rmse: 0.0790705\tvalid_1's rmse: 0.0825032\n",
      "[875]\ttraining's rmse: 0.0790453\tvalid_1's rmse: 0.0824968\n",
      "[900]\ttraining's rmse: 0.0790162\tvalid_1's rmse: 0.0824912\n",
      "[925]\ttraining's rmse: 0.0789944\tvalid_1's rmse: 0.0824858\n",
      "[950]\ttraining's rmse: 0.0789697\tvalid_1's rmse: 0.0824798\n",
      "[975]\ttraining's rmse: 0.0789466\tvalid_1's rmse: 0.0824756\n",
      "[1000]\ttraining's rmse: 0.0789269\tvalid_1's rmse: 0.0824713\n",
      "[1025]\ttraining's rmse: 0.0789055\tvalid_1's rmse: 0.0824665\n",
      "[1050]\ttraining's rmse: 0.0788837\tvalid_1's rmse: 0.0824605\n",
      "[1075]\ttraining's rmse: 0.0788643\tvalid_1's rmse: 0.0824558\n",
      "[1100]\ttraining's rmse: 0.0788491\tvalid_1's rmse: 0.0824508\n",
      "[1125]\ttraining's rmse: 0.0788336\tvalid_1's rmse: 0.0824452\n",
      "[1150]\ttraining's rmse: 0.0788156\tvalid_1's rmse: 0.0824415\n",
      "[1175]\ttraining's rmse: 0.0787986\tvalid_1's rmse: 0.0824384\n",
      "[1200]\ttraining's rmse: 0.0787825\tvalid_1's rmse: 0.0824345\n",
      "[1225]\ttraining's rmse: 0.0787669\tvalid_1's rmse: 0.0824309\n",
      "[1250]\ttraining's rmse: 0.0787522\tvalid_1's rmse: 0.0824279\n",
      "[1275]\ttraining's rmse: 0.0787315\tvalid_1's rmse: 0.0824252\n",
      "[1300]\ttraining's rmse: 0.0787196\tvalid_1's rmse: 0.0824223\n",
      "[1325]\ttraining's rmse: 0.0787065\tvalid_1's rmse: 0.0824197\n",
      "[1350]\ttraining's rmse: 0.0786924\tvalid_1's rmse: 0.0824157\n",
      "[1375]\ttraining's rmse: 0.0786773\tvalid_1's rmse: 0.0824118\n",
      "[1400]\ttraining's rmse: 0.0786674\tvalid_1's rmse: 0.0824092\n",
      "[1425]\ttraining's rmse: 0.0786545\tvalid_1's rmse: 0.0824066\n",
      "[1450]\ttraining's rmse: 0.0786417\tvalid_1's rmse: 0.0824046\n",
      "[1475]\ttraining's rmse: 0.0786315\tvalid_1's rmse: 0.0824024\n",
      "[1500]\ttraining's rmse: 0.0786227\tvalid_1's rmse: 0.0823993\n",
      "[1525]\ttraining's rmse: 0.078615\tvalid_1's rmse: 0.0823975\n",
      "[1550]\ttraining's rmse: 0.0786081\tvalid_1's rmse: 0.0823953\n",
      "[1575]\ttraining's rmse: 0.0786002\tvalid_1's rmse: 0.0823926\n",
      "[1600]\ttraining's rmse: 0.0785946\tvalid_1's rmse: 0.0823906\n",
      "[1625]\ttraining's rmse: 0.0785888\tvalid_1's rmse: 0.0823882\n",
      "[1650]\ttraining's rmse: 0.0785824\tvalid_1's rmse: 0.0823864\n",
      "[1675]\ttraining's rmse: 0.0785773\tvalid_1's rmse: 0.0823852\n",
      "[1700]\ttraining's rmse: 0.0785704\tvalid_1's rmse: 0.0823821\n",
      "[1725]\ttraining's rmse: 0.0785654\tvalid_1's rmse: 0.0823803\n",
      "[1750]\ttraining's rmse: 0.0785601\tvalid_1's rmse: 0.0823773\n",
      "[1775]\ttraining's rmse: 0.0785549\tvalid_1's rmse: 0.0823759\n",
      "[1800]\ttraining's rmse: 0.0785501\tvalid_1's rmse: 0.082375\n",
      "[1825]\ttraining's rmse: 0.0785449\tvalid_1's rmse: 0.0823742\n",
      "[1850]\ttraining's rmse: 0.0785393\tvalid_1's rmse: 0.0823719\n",
      "[1875]\ttraining's rmse: 0.078534\tvalid_1's rmse: 0.0823702\n",
      "[1900]\ttraining's rmse: 0.0785298\tvalid_1's rmse: 0.0823691\n",
      "[1925]\ttraining's rmse: 0.078525\tvalid_1's rmse: 0.0823681\n",
      "[1950]\ttraining's rmse: 0.078519\tvalid_1's rmse: 0.0823662\n",
      "[1975]\ttraining's rmse: 0.0785169\tvalid_1's rmse: 0.0823653\n",
      "[2000]\ttraining's rmse: 0.0785135\tvalid_1's rmse: 0.0823639\n",
      "[2025]\ttraining's rmse: 0.0785096\tvalid_1's rmse: 0.0823627\n",
      "[2050]\ttraining's rmse: 0.078506\tvalid_1's rmse: 0.0823611\n",
      "[2075]\ttraining's rmse: 0.0785031\tvalid_1's rmse: 0.0823604\n",
      "[2100]\ttraining's rmse: 0.0784998\tvalid_1's rmse: 0.0823596\n",
      "[2125]\ttraining's rmse: 0.0784973\tvalid_1's rmse: 0.0823591\n",
      "[2150]\ttraining's rmse: 0.0784949\tvalid_1's rmse: 0.0823585\n",
      "[2175]\ttraining's rmse: 0.0784918\tvalid_1's rmse: 0.0823586\n",
      "[2200]\ttraining's rmse: 0.0784892\tvalid_1's rmse: 0.0823584\n",
      "[2225]\ttraining's rmse: 0.0784861\tvalid_1's rmse: 0.0823572\n",
      "[2250]\ttraining's rmse: 0.0784824\tvalid_1's rmse: 0.0823563\n",
      "[2275]\ttraining's rmse: 0.0784795\tvalid_1's rmse: 0.0823561\n",
      "[2300]\ttraining's rmse: 0.0784766\tvalid_1's rmse: 0.082355\n",
      "[2325]\ttraining's rmse: 0.0784741\tvalid_1's rmse: 0.0823548\n",
      "[2350]\ttraining's rmse: 0.0784717\tvalid_1's rmse: 0.0823545\n",
      "[2375]\ttraining's rmse: 0.0784699\tvalid_1's rmse: 0.0823537\n",
      "[2400]\ttraining's rmse: 0.0784677\tvalid_1's rmse: 0.0823532\n",
      "[2425]\ttraining's rmse: 0.0784667\tvalid_1's rmse: 0.0823526\n",
      "[2450]\ttraining's rmse: 0.078465\tvalid_1's rmse: 0.0823525\n",
      "[2475]\ttraining's rmse: 0.0784627\tvalid_1's rmse: 0.0823525\n",
      "Early stopping, best iteration is:\n",
      "[2431]\ttraining's rmse: 0.0784664\tvalid_1's rmse: 0.0823522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0812101\tvalid_1's rmse: 0.0830076\n",
      "[50]\ttraining's rmse: 0.0811002\tvalid_1's rmse: 0.082957\n",
      "[75]\ttraining's rmse: 0.0809864\tvalid_1's rmse: 0.0829059\n",
      "[100]\ttraining's rmse: 0.0808853\tvalid_1's rmse: 0.0828609\n",
      "[125]\ttraining's rmse: 0.0807842\tvalid_1's rmse: 0.0828167\n",
      "[150]\ttraining's rmse: 0.0806885\tvalid_1's rmse: 0.0827748\n",
      "[175]\ttraining's rmse: 0.080609\tvalid_1's rmse: 0.0827404\n",
      "[200]\ttraining's rmse: 0.0805198\tvalid_1's rmse: 0.0827039\n",
      "[225]\ttraining's rmse: 0.0804353\tvalid_1's rmse: 0.0826723\n",
      "[250]\ttraining's rmse: 0.0803664\tvalid_1's rmse: 0.0826439\n",
      "[275]\ttraining's rmse: 0.080301\tvalid_1's rmse: 0.0826174\n",
      "[300]\ttraining's rmse: 0.080237\tvalid_1's rmse: 0.0825925\n",
      "[325]\ttraining's rmse: 0.0801704\tvalid_1's rmse: 0.0825669\n",
      "[350]\ttraining's rmse: 0.0801069\tvalid_1's rmse: 0.0825438\n",
      "[375]\ttraining's rmse: 0.0800542\tvalid_1's rmse: 0.0825234\n",
      "[400]\ttraining's rmse: 0.0799966\tvalid_1's rmse: 0.082503\n",
      "[425]\ttraining's rmse: 0.0799454\tvalid_1's rmse: 0.0824841\n",
      "[450]\ttraining's rmse: 0.0798957\tvalid_1's rmse: 0.0824653\n",
      "[475]\ttraining's rmse: 0.0798492\tvalid_1's rmse: 0.0824492\n",
      "[500]\ttraining's rmse: 0.0798108\tvalid_1's rmse: 0.0824336\n",
      "[525]\ttraining's rmse: 0.0797622\tvalid_1's rmse: 0.0824176\n",
      "[550]\ttraining's rmse: 0.0797156\tvalid_1's rmse: 0.0824028\n",
      "[575]\ttraining's rmse: 0.0796738\tvalid_1's rmse: 0.0823892\n",
      "[600]\ttraining's rmse: 0.079634\tvalid_1's rmse: 0.0823767\n",
      "[625]\ttraining's rmse: 0.0796011\tvalid_1's rmse: 0.0823652\n",
      "[650]\ttraining's rmse: 0.0795641\tvalid_1's rmse: 0.0823528\n",
      "[675]\ttraining's rmse: 0.0795237\tvalid_1's rmse: 0.0823414\n",
      "[700]\ttraining's rmse: 0.0794893\tvalid_1's rmse: 0.0823303\n",
      "[725]\ttraining's rmse: 0.0794581\tvalid_1's rmse: 0.082321\n",
      "[750]\ttraining's rmse: 0.079428\tvalid_1's rmse: 0.082312\n",
      "[775]\ttraining's rmse: 0.0794039\tvalid_1's rmse: 0.0823034\n",
      "[800]\ttraining's rmse: 0.0793712\tvalid_1's rmse: 0.0822957\n",
      "[825]\ttraining's rmse: 0.0793436\tvalid_1's rmse: 0.0822866\n",
      "[850]\ttraining's rmse: 0.0793144\tvalid_1's rmse: 0.0822804\n",
      "[875]\ttraining's rmse: 0.0792908\tvalid_1's rmse: 0.0822736\n",
      "[900]\ttraining's rmse: 0.0792626\tvalid_1's rmse: 0.0822665\n",
      "[925]\ttraining's rmse: 0.0792382\tvalid_1's rmse: 0.0822606\n",
      "[950]\ttraining's rmse: 0.0792155\tvalid_1's rmse: 0.0822553\n",
      "[975]\ttraining's rmse: 0.0791937\tvalid_1's rmse: 0.0822494\n",
      "[1000]\ttraining's rmse: 0.0791722\tvalid_1's rmse: 0.0822434\n",
      "[1025]\ttraining's rmse: 0.0791484\tvalid_1's rmse: 0.0822387\n",
      "[1050]\ttraining's rmse: 0.0791281\tvalid_1's rmse: 0.0822331\n",
      "[1075]\ttraining's rmse: 0.0791105\tvalid_1's rmse: 0.0822298\n",
      "[1100]\ttraining's rmse: 0.0790939\tvalid_1's rmse: 0.082226\n",
      "[1125]\ttraining's rmse: 0.0790775\tvalid_1's rmse: 0.0822219\n",
      "[1150]\ttraining's rmse: 0.0790576\tvalid_1's rmse: 0.0822186\n",
      "[1175]\ttraining's rmse: 0.0790425\tvalid_1's rmse: 0.0822151\n",
      "[1200]\ttraining's rmse: 0.0790268\tvalid_1's rmse: 0.0822113\n",
      "[1225]\ttraining's rmse: 0.0790126\tvalid_1's rmse: 0.0822075\n",
      "[1250]\ttraining's rmse: 0.0790011\tvalid_1's rmse: 0.0822043\n",
      "[1275]\ttraining's rmse: 0.0789859\tvalid_1's rmse: 0.0822017\n",
      "[1300]\ttraining's rmse: 0.0789733\tvalid_1's rmse: 0.082199\n",
      "[1325]\ttraining's rmse: 0.0789614\tvalid_1's rmse: 0.0821966\n",
      "[1350]\ttraining's rmse: 0.0789474\tvalid_1's rmse: 0.0821944\n",
      "[1375]\ttraining's rmse: 0.0789368\tvalid_1's rmse: 0.0821924\n",
      "[1400]\ttraining's rmse: 0.0789272\tvalid_1's rmse: 0.08219\n",
      "[1425]\ttraining's rmse: 0.0789148\tvalid_1's rmse: 0.0821882\n",
      "[1450]\ttraining's rmse: 0.0789046\tvalid_1's rmse: 0.082187\n",
      "[1475]\ttraining's rmse: 0.0788941\tvalid_1's rmse: 0.0821849\n",
      "[1500]\ttraining's rmse: 0.0788863\tvalid_1's rmse: 0.0821832\n",
      "[1525]\ttraining's rmse: 0.0788765\tvalid_1's rmse: 0.0821816\n",
      "[1550]\ttraining's rmse: 0.0788683\tvalid_1's rmse: 0.08218\n",
      "[1575]\ttraining's rmse: 0.0788615\tvalid_1's rmse: 0.0821785\n",
      "[1600]\ttraining's rmse: 0.0788554\tvalid_1's rmse: 0.0821782\n",
      "[1625]\ttraining's rmse: 0.0788486\tvalid_1's rmse: 0.0821768\n",
      "[1650]\ttraining's rmse: 0.0788418\tvalid_1's rmse: 0.0821755\n",
      "[1675]\ttraining's rmse: 0.0788349\tvalid_1's rmse: 0.0821739\n",
      "[1700]\ttraining's rmse: 0.0788291\tvalid_1's rmse: 0.0821723\n",
      "[1725]\ttraining's rmse: 0.0788228\tvalid_1's rmse: 0.0821713\n",
      "[1750]\ttraining's rmse: 0.0788174\tvalid_1's rmse: 0.0821706\n",
      "[1775]\ttraining's rmse: 0.0788129\tvalid_1's rmse: 0.0821695\n",
      "[1800]\ttraining's rmse: 0.078807\tvalid_1's rmse: 0.0821686\n",
      "[1825]\ttraining's rmse: 0.0788018\tvalid_1's rmse: 0.082168\n",
      "[1850]\ttraining's rmse: 0.0787968\tvalid_1's rmse: 0.0821672\n",
      "[1875]\ttraining's rmse: 0.0787915\tvalid_1's rmse: 0.0821663\n",
      "[1900]\ttraining's rmse: 0.0787868\tvalid_1's rmse: 0.0821659\n",
      "[1925]\ttraining's rmse: 0.0787834\tvalid_1's rmse: 0.0821656\n",
      "[1950]\ttraining's rmse: 0.0787802\tvalid_1's rmse: 0.0821644\n",
      "[1975]\ttraining's rmse: 0.0787768\tvalid_1's rmse: 0.0821635\n",
      "[2000]\ttraining's rmse: 0.0787718\tvalid_1's rmse: 0.0821624\n",
      "[2025]\ttraining's rmse: 0.078769\tvalid_1's rmse: 0.0821621\n",
      "[2050]\ttraining's rmse: 0.0787649\tvalid_1's rmse: 0.0821616\n",
      "[2075]\ttraining's rmse: 0.0787608\tvalid_1's rmse: 0.0821608\n",
      "[2100]\ttraining's rmse: 0.0787575\tvalid_1's rmse: 0.08216\n",
      "[2125]\ttraining's rmse: 0.078755\tvalid_1's rmse: 0.08216\n",
      "[2150]\ttraining's rmse: 0.078751\tvalid_1's rmse: 0.0821597\n",
      "[2175]\ttraining's rmse: 0.0787495\tvalid_1's rmse: 0.0821597\n",
      "[2200]\ttraining's rmse: 0.0787471\tvalid_1's rmse: 0.0821596\n",
      "[2225]\ttraining's rmse: 0.0787448\tvalid_1's rmse: 0.0821592\n",
      "[2250]\ttraining's rmse: 0.0787408\tvalid_1's rmse: 0.082159\n",
      "[2275]\ttraining's rmse: 0.0787367\tvalid_1's rmse: 0.0821584\n",
      "[2300]\ttraining's rmse: 0.0787347\tvalid_1's rmse: 0.0821581\n",
      "[2325]\ttraining's rmse: 0.0787316\tvalid_1's rmse: 0.0821584\n",
      "Early stopping, best iteration is:\n",
      "[2293]\ttraining's rmse: 0.0787349\tvalid_1's rmse: 0.082158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0829841\tvalid_1's rmse: 0.0794047\n",
      "[50]\ttraining's rmse: 0.0828791\tvalid_1's rmse: 0.0793558\n",
      "[75]\ttraining's rmse: 0.0827708\tvalid_1's rmse: 0.0793101\n",
      "[100]\ttraining's rmse: 0.0826721\tvalid_1's rmse: 0.0792713\n",
      "[125]\ttraining's rmse: 0.0825708\tvalid_1's rmse: 0.0792333\n",
      "[150]\ttraining's rmse: 0.082477\tvalid_1's rmse: 0.079197\n",
      "[175]\ttraining's rmse: 0.0823988\tvalid_1's rmse: 0.0791652\n",
      "[200]\ttraining's rmse: 0.0823146\tvalid_1's rmse: 0.0791343\n",
      "[225]\ttraining's rmse: 0.082232\tvalid_1's rmse: 0.0791049\n",
      "[250]\ttraining's rmse: 0.0821642\tvalid_1's rmse: 0.0790799\n",
      "[275]\ttraining's rmse: 0.0821017\tvalid_1's rmse: 0.079056\n",
      "[300]\ttraining's rmse: 0.0820379\tvalid_1's rmse: 0.0790337\n",
      "[325]\ttraining's rmse: 0.0819737\tvalid_1's rmse: 0.0790113\n",
      "[350]\ttraining's rmse: 0.0819109\tvalid_1's rmse: 0.0789909\n",
      "[375]\ttraining's rmse: 0.0818583\tvalid_1's rmse: 0.0789745\n",
      "[400]\ttraining's rmse: 0.0818022\tvalid_1's rmse: 0.0789609\n",
      "[425]\ttraining's rmse: 0.0817515\tvalid_1's rmse: 0.0789459\n",
      "[450]\ttraining's rmse: 0.0817047\tvalid_1's rmse: 0.0789318\n",
      "[475]\ttraining's rmse: 0.0816603\tvalid_1's rmse: 0.0789198\n",
      "[500]\ttraining's rmse: 0.081623\tvalid_1's rmse: 0.0789071\n",
      "[525]\ttraining's rmse: 0.0815706\tvalid_1's rmse: 0.078897\n",
      "[550]\ttraining's rmse: 0.0815236\tvalid_1's rmse: 0.0788861\n",
      "[575]\ttraining's rmse: 0.0814828\tvalid_1's rmse: 0.0788757\n",
      "[600]\ttraining's rmse: 0.0814423\tvalid_1's rmse: 0.0788704\n",
      "[625]\ttraining's rmse: 0.0814093\tvalid_1's rmse: 0.0788616\n",
      "[650]\ttraining's rmse: 0.0813697\tvalid_1's rmse: 0.0788548\n",
      "[675]\ttraining's rmse: 0.0813312\tvalid_1's rmse: 0.0788467\n",
      "[700]\ttraining's rmse: 0.0812963\tvalid_1's rmse: 0.0788406\n",
      "[725]\ttraining's rmse: 0.0812624\tvalid_1's rmse: 0.0788378\n",
      "[750]\ttraining's rmse: 0.0812314\tvalid_1's rmse: 0.0788307\n",
      "[775]\ttraining's rmse: 0.081205\tvalid_1's rmse: 0.0788291\n",
      "[800]\ttraining's rmse: 0.0811716\tvalid_1's rmse: 0.0788243\n",
      "[825]\ttraining's rmse: 0.0811456\tvalid_1's rmse: 0.0788215\n",
      "[850]\ttraining's rmse: 0.0811169\tvalid_1's rmse: 0.0788204\n",
      "[875]\ttraining's rmse: 0.0810912\tvalid_1's rmse: 0.0788213\n",
      "[900]\ttraining's rmse: 0.0810612\tvalid_1's rmse: 0.078837\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's rmse: 0.0811101\tvalid_1's rmse: 0.0788191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0792259\tvalid_1's rmse: 0.0816592\n",
      "[50]\ttraining's rmse: 0.0791104\tvalid_1's rmse: 0.0816087\n",
      "[75]\ttraining's rmse: 0.0789952\tvalid_1's rmse: 0.0815593\n",
      "[100]\ttraining's rmse: 0.0788899\tvalid_1's rmse: 0.0815154\n",
      "[125]\ttraining's rmse: 0.0787847\tvalid_1's rmse: 0.0814719\n",
      "[150]\ttraining's rmse: 0.0786898\tvalid_1's rmse: 0.0814326\n",
      "[175]\ttraining's rmse: 0.0786082\tvalid_1's rmse: 0.0813976\n",
      "[200]\ttraining's rmse: 0.0785235\tvalid_1's rmse: 0.0813636\n",
      "[225]\ttraining's rmse: 0.0784421\tvalid_1's rmse: 0.0813304\n",
      "[250]\ttraining's rmse: 0.0783715\tvalid_1's rmse: 0.0812991\n",
      "[275]\ttraining's rmse: 0.0783044\tvalid_1's rmse: 0.081273\n",
      "[300]\ttraining's rmse: 0.0782393\tvalid_1's rmse: 0.0812465\n",
      "[325]\ttraining's rmse: 0.0781697\tvalid_1's rmse: 0.0812215\n",
      "[350]\ttraining's rmse: 0.078107\tvalid_1's rmse: 0.0811975\n",
      "[375]\ttraining's rmse: 0.0780534\tvalid_1's rmse: 0.0811764\n",
      "[400]\ttraining's rmse: 0.077998\tvalid_1's rmse: 0.0811555\n",
      "[425]\ttraining's rmse: 0.0779469\tvalid_1's rmse: 0.0811351\n",
      "[450]\ttraining's rmse: 0.0779005\tvalid_1's rmse: 0.0811165\n",
      "[475]\ttraining's rmse: 0.0778577\tvalid_1's rmse: 0.0810977\n",
      "[500]\ttraining's rmse: 0.0778209\tvalid_1's rmse: 0.0810815\n",
      "[525]\ttraining's rmse: 0.0777727\tvalid_1's rmse: 0.0810664\n",
      "[550]\ttraining's rmse: 0.0777307\tvalid_1's rmse: 0.081053\n",
      "[575]\ttraining's rmse: 0.0776898\tvalid_1's rmse: 0.0810398\n",
      "[600]\ttraining's rmse: 0.0776518\tvalid_1's rmse: 0.0810261\n",
      "[625]\ttraining's rmse: 0.0776216\tvalid_1's rmse: 0.0810154\n",
      "[650]\ttraining's rmse: 0.0775857\tvalid_1's rmse: 0.0810026\n",
      "[675]\ttraining's rmse: 0.0775512\tvalid_1's rmse: 0.0809915\n",
      "[700]\ttraining's rmse: 0.0775179\tvalid_1's rmse: 0.0809799\n",
      "[725]\ttraining's rmse: 0.0774857\tvalid_1's rmse: 0.0809701\n",
      "[750]\ttraining's rmse: 0.0774573\tvalid_1's rmse: 0.0809609\n",
      "[775]\ttraining's rmse: 0.0774345\tvalid_1's rmse: 0.0809527\n",
      "[800]\ttraining's rmse: 0.0774038\tvalid_1's rmse: 0.0809448\n",
      "[825]\ttraining's rmse: 0.0773766\tvalid_1's rmse: 0.0809361\n",
      "[850]\ttraining's rmse: 0.077349\tvalid_1's rmse: 0.0809284\n",
      "[875]\ttraining's rmse: 0.0773239\tvalid_1's rmse: 0.0809221\n",
      "[900]\ttraining's rmse: 0.0772959\tvalid_1's rmse: 0.0809153\n",
      "[925]\ttraining's rmse: 0.0772732\tvalid_1's rmse: 0.0809092\n",
      "[950]\ttraining's rmse: 0.0772494\tvalid_1's rmse: 0.0809031\n",
      "[975]\ttraining's rmse: 0.0772284\tvalid_1's rmse: 0.0808979\n",
      "[1000]\ttraining's rmse: 0.0772082\tvalid_1's rmse: 0.0808906\n",
      "[1025]\ttraining's rmse: 0.0771884\tvalid_1's rmse: 0.0808841\n",
      "[1050]\ttraining's rmse: 0.0771695\tvalid_1's rmse: 0.080878\n",
      "[1075]\ttraining's rmse: 0.0771517\tvalid_1's rmse: 0.0808737\n",
      "[1100]\ttraining's rmse: 0.0771363\tvalid_1's rmse: 0.0808688\n",
      "[1125]\ttraining's rmse: 0.0771186\tvalid_1's rmse: 0.0808627\n",
      "[1150]\ttraining's rmse: 0.0771038\tvalid_1's rmse: 0.0808585\n",
      "[1175]\ttraining's rmse: 0.0770885\tvalid_1's rmse: 0.0808542\n",
      "[1200]\ttraining's rmse: 0.0770758\tvalid_1's rmse: 0.0808509\n",
      "[1225]\ttraining's rmse: 0.0770603\tvalid_1's rmse: 0.0808472\n",
      "[1250]\ttraining's rmse: 0.0770482\tvalid_1's rmse: 0.080844\n",
      "[1275]\ttraining's rmse: 0.0770365\tvalid_1's rmse: 0.0808393\n",
      "[1300]\ttraining's rmse: 0.0770248\tvalid_1's rmse: 0.080836\n",
      "[1325]\ttraining's rmse: 0.0770121\tvalid_1's rmse: 0.0808329\n",
      "[1350]\ttraining's rmse: 0.0770021\tvalid_1's rmse: 0.0808298\n",
      "[1375]\ttraining's rmse: 0.0769877\tvalid_1's rmse: 0.0808272\n",
      "[1400]\ttraining's rmse: 0.0769782\tvalid_1's rmse: 0.0808248\n",
      "[1425]\ttraining's rmse: 0.0769686\tvalid_1's rmse: 0.0808213\n",
      "[1450]\ttraining's rmse: 0.0769569\tvalid_1's rmse: 0.0808202\n",
      "[1475]\ttraining's rmse: 0.0769495\tvalid_1's rmse: 0.0808182\n",
      "[1500]\ttraining's rmse: 0.0769419\tvalid_1's rmse: 0.0808152\n",
      "[1525]\ttraining's rmse: 0.0769313\tvalid_1's rmse: 0.0808124\n",
      "[1550]\ttraining's rmse: 0.0769229\tvalid_1's rmse: 0.0808106\n",
      "[1575]\ttraining's rmse: 0.0769166\tvalid_1's rmse: 0.0808089\n",
      "[1600]\ttraining's rmse: 0.0769114\tvalid_1's rmse: 0.0808065\n",
      "[1625]\ttraining's rmse: 0.0769054\tvalid_1's rmse: 0.0808046\n",
      "[1650]\ttraining's rmse: 0.0768986\tvalid_1's rmse: 0.0808027\n",
      "[1675]\ttraining's rmse: 0.0768921\tvalid_1's rmse: 0.0808007\n",
      "[1700]\ttraining's rmse: 0.0768879\tvalid_1's rmse: 0.0807982\n",
      "[1725]\ttraining's rmse: 0.0768831\tvalid_1's rmse: 0.0807964\n",
      "[1750]\ttraining's rmse: 0.0768774\tvalid_1's rmse: 0.0807943\n",
      "[1775]\ttraining's rmse: 0.0768728\tvalid_1's rmse: 0.0807931\n",
      "[1800]\ttraining's rmse: 0.0768675\tvalid_1's rmse: 0.0807909\n",
      "[1825]\ttraining's rmse: 0.0768625\tvalid_1's rmse: 0.0807895\n",
      "[1850]\ttraining's rmse: 0.0768585\tvalid_1's rmse: 0.0807877\n",
      "[1875]\ttraining's rmse: 0.0768536\tvalid_1's rmse: 0.0807869\n",
      "[1900]\ttraining's rmse: 0.0768503\tvalid_1's rmse: 0.0807862\n",
      "[1925]\ttraining's rmse: 0.0768453\tvalid_1's rmse: 0.0807845\n",
      "[1950]\ttraining's rmse: 0.0768422\tvalid_1's rmse: 0.0807833\n",
      "[1975]\ttraining's rmse: 0.076839\tvalid_1's rmse: 0.0807819\n",
      "[2000]\ttraining's rmse: 0.0768363\tvalid_1's rmse: 0.0807805\n",
      "[2025]\ttraining's rmse: 0.0768334\tvalid_1's rmse: 0.080779\n",
      "[2050]\ttraining's rmse: 0.0768314\tvalid_1's rmse: 0.0807788\n",
      "[2075]\ttraining's rmse: 0.0768282\tvalid_1's rmse: 0.0807775\n",
      "[2100]\ttraining's rmse: 0.0768254\tvalid_1's rmse: 0.0807765\n",
      "[2125]\ttraining's rmse: 0.0768233\tvalid_1's rmse: 0.0807762\n",
      "[2150]\ttraining's rmse: 0.0768202\tvalid_1's rmse: 0.0807762\n",
      "[2175]\ttraining's rmse: 0.0768173\tvalid_1's rmse: 0.0807756\n",
      "[2200]\ttraining's rmse: 0.0768142\tvalid_1's rmse: 0.0807743\n",
      "[2225]\ttraining's rmse: 0.0768117\tvalid_1's rmse: 0.0807736\n",
      "[2250]\ttraining's rmse: 0.0768088\tvalid_1's rmse: 0.0807736\n",
      "[2275]\ttraining's rmse: 0.0768071\tvalid_1's rmse: 0.080773\n",
      "[2300]\ttraining's rmse: 0.0768052\tvalid_1's rmse: 0.0807722\n",
      "[2325]\ttraining's rmse: 0.0768017\tvalid_1's rmse: 0.0807719\n",
      "[2350]\ttraining's rmse: 0.0767998\tvalid_1's rmse: 0.0807712\n",
      "[2375]\ttraining's rmse: 0.076797\tvalid_1's rmse: 0.0807709\n",
      "[2400]\ttraining's rmse: 0.0767939\tvalid_1's rmse: 0.0807709\n",
      "[2425]\ttraining's rmse: 0.0767917\tvalid_1's rmse: 0.0807704\n",
      "[2450]\ttraining's rmse: 0.07679\tvalid_1's rmse: 0.0807695\n",
      "[2475]\ttraining's rmse: 0.0767875\tvalid_1's rmse: 0.0807697\n",
      "[2500]\ttraining's rmse: 0.076786\tvalid_1's rmse: 0.0807694\n",
      "[2525]\ttraining's rmse: 0.0767845\tvalid_1's rmse: 0.0807685\n",
      "[2550]\ttraining's rmse: 0.0767827\tvalid_1's rmse: 0.0807685\n",
      "[2575]\ttraining's rmse: 0.0767799\tvalid_1's rmse: 0.0807682\n",
      "[2600]\ttraining's rmse: 0.0767781\tvalid_1's rmse: 0.0807678\n",
      "[2625]\ttraining's rmse: 0.076777\tvalid_1's rmse: 0.0807675\n",
      "[2650]\ttraining's rmse: 0.0767756\tvalid_1's rmse: 0.0807669\n",
      "[2675]\ttraining's rmse: 0.0767747\tvalid_1's rmse: 0.0807666\n",
      "[2700]\ttraining's rmse: 0.0767727\tvalid_1's rmse: 0.0807664\n",
      "[2725]\ttraining's rmse: 0.0767707\tvalid_1's rmse: 0.0807666\n",
      "[2750]\ttraining's rmse: 0.0767694\tvalid_1's rmse: 0.0807658\n",
      "[2775]\ttraining's rmse: 0.0767681\tvalid_1's rmse: 0.0807655\n",
      "[2800]\ttraining's rmse: 0.0767671\tvalid_1's rmse: 0.0807654\n",
      "[2825]\ttraining's rmse: 0.0767664\tvalid_1's rmse: 0.0807654\n",
      "[2850]\ttraining's rmse: 0.0767651\tvalid_1's rmse: 0.0807657\n",
      "Early stopping, best iteration is:\n",
      "[2809]\ttraining's rmse: 0.0767669\tvalid_1's rmse: 0.0807653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0794928\tvalid_1's rmse: 0.0811418\n",
      "[50]\ttraining's rmse: 0.0793873\tvalid_1's rmse: 0.0810884\n",
      "[75]\ttraining's rmse: 0.0792805\tvalid_1's rmse: 0.0810384\n",
      "[100]\ttraining's rmse: 0.0791836\tvalid_1's rmse: 0.0809925\n",
      "[125]\ttraining's rmse: 0.0790801\tvalid_1's rmse: 0.0809456\n",
      "[150]\ttraining's rmse: 0.07899\tvalid_1's rmse: 0.0809057\n",
      "[175]\ttraining's rmse: 0.0789108\tvalid_1's rmse: 0.0808713\n",
      "[200]\ttraining's rmse: 0.078823\tvalid_1's rmse: 0.0808347\n",
      "[225]\ttraining's rmse: 0.0787428\tvalid_1's rmse: 0.0808019\n",
      "[250]\ttraining's rmse: 0.0786751\tvalid_1's rmse: 0.0807726\n",
      "[275]\ttraining's rmse: 0.0786116\tvalid_1's rmse: 0.0807448\n",
      "[300]\ttraining's rmse: 0.0785469\tvalid_1's rmse: 0.0807192\n",
      "[325]\ttraining's rmse: 0.0784819\tvalid_1's rmse: 0.0806945\n",
      "[350]\ttraining's rmse: 0.0784187\tvalid_1's rmse: 0.0806715\n",
      "[375]\ttraining's rmse: 0.078368\tvalid_1's rmse: 0.0806517\n",
      "[400]\ttraining's rmse: 0.0783119\tvalid_1's rmse: 0.0806316\n",
      "[425]\ttraining's rmse: 0.0782605\tvalid_1's rmse: 0.080613\n",
      "[450]\ttraining's rmse: 0.0782128\tvalid_1's rmse: 0.0805955\n",
      "[475]\ttraining's rmse: 0.0781697\tvalid_1's rmse: 0.0805803\n",
      "[500]\ttraining's rmse: 0.0781304\tvalid_1's rmse: 0.0805648\n",
      "[525]\ttraining's rmse: 0.0780848\tvalid_1's rmse: 0.0805499\n",
      "[550]\ttraining's rmse: 0.078042\tvalid_1's rmse: 0.0805359\n",
      "[575]\ttraining's rmse: 0.0779999\tvalid_1's rmse: 0.0805225\n",
      "[600]\ttraining's rmse: 0.0779602\tvalid_1's rmse: 0.0805096\n",
      "[625]\ttraining's rmse: 0.0779321\tvalid_1's rmse: 0.0804994\n",
      "[650]\ttraining's rmse: 0.0778925\tvalid_1's rmse: 0.0804872\n",
      "[675]\ttraining's rmse: 0.0778528\tvalid_1's rmse: 0.0804754\n",
      "[700]\ttraining's rmse: 0.0778204\tvalid_1's rmse: 0.0804658\n",
      "[725]\ttraining's rmse: 0.0777886\tvalid_1's rmse: 0.0804569\n",
      "[750]\ttraining's rmse: 0.0777584\tvalid_1's rmse: 0.080449\n",
      "[775]\ttraining's rmse: 0.0777327\tvalid_1's rmse: 0.0804412\n",
      "[800]\ttraining's rmse: 0.0777012\tvalid_1's rmse: 0.0804334\n",
      "[825]\ttraining's rmse: 0.077676\tvalid_1's rmse: 0.0804257\n",
      "[850]\ttraining's rmse: 0.07765\tvalid_1's rmse: 0.0804192\n",
      "[875]\ttraining's rmse: 0.0776272\tvalid_1's rmse: 0.0804123\n",
      "[900]\ttraining's rmse: 0.0776032\tvalid_1's rmse: 0.0804065\n",
      "[925]\ttraining's rmse: 0.0775809\tvalid_1's rmse: 0.0804012\n",
      "[950]\ttraining's rmse: 0.0775598\tvalid_1's rmse: 0.0803959\n",
      "[975]\ttraining's rmse: 0.0775394\tvalid_1's rmse: 0.0803908\n",
      "[1000]\ttraining's rmse: 0.0775187\tvalid_1's rmse: 0.0803855\n",
      "[1025]\ttraining's rmse: 0.0774968\tvalid_1's rmse: 0.0803812\n",
      "[1050]\ttraining's rmse: 0.077478\tvalid_1's rmse: 0.0803764\n",
      "[1075]\ttraining's rmse: 0.0774592\tvalid_1's rmse: 0.0803732\n",
      "[1100]\ttraining's rmse: 0.0774453\tvalid_1's rmse: 0.08037\n",
      "[1125]\ttraining's rmse: 0.0774291\tvalid_1's rmse: 0.0803664\n",
      "[1150]\ttraining's rmse: 0.0774117\tvalid_1's rmse: 0.0803629\n",
      "[1175]\ttraining's rmse: 0.0773969\tvalid_1's rmse: 0.0803603\n",
      "[1200]\ttraining's rmse: 0.0773822\tvalid_1's rmse: 0.080357\n",
      "[1225]\ttraining's rmse: 0.0773681\tvalid_1's rmse: 0.0803544\n",
      "[1250]\ttraining's rmse: 0.0773546\tvalid_1's rmse: 0.0803512\n",
      "[1275]\ttraining's rmse: 0.077339\tvalid_1's rmse: 0.0803483\n",
      "[1300]\ttraining's rmse: 0.0773277\tvalid_1's rmse: 0.0803455\n",
      "[1325]\ttraining's rmse: 0.0773149\tvalid_1's rmse: 0.0803433\n",
      "[1350]\ttraining's rmse: 0.0773029\tvalid_1's rmse: 0.0803422\n",
      "[1375]\ttraining's rmse: 0.0772915\tvalid_1's rmse: 0.08034\n",
      "[1400]\ttraining's rmse: 0.0772813\tvalid_1's rmse: 0.0803378\n",
      "[1425]\ttraining's rmse: 0.0772713\tvalid_1's rmse: 0.0803371\n",
      "[1450]\ttraining's rmse: 0.0772615\tvalid_1's rmse: 0.0803356\n",
      "[1475]\ttraining's rmse: 0.0772508\tvalid_1's rmse: 0.0803341\n",
      "[1500]\ttraining's rmse: 0.0772441\tvalid_1's rmse: 0.0803325\n",
      "[1525]\ttraining's rmse: 0.0772358\tvalid_1's rmse: 0.080331\n",
      "[1550]\ttraining's rmse: 0.0772286\tvalid_1's rmse: 0.0803303\n",
      "[1575]\ttraining's rmse: 0.0772195\tvalid_1's rmse: 0.0803291\n",
      "[1600]\ttraining's rmse: 0.0772147\tvalid_1's rmse: 0.0803293\n",
      "[1625]\ttraining's rmse: 0.0772084\tvalid_1's rmse: 0.0803283\n",
      "[1650]\ttraining's rmse: 0.0772017\tvalid_1's rmse: 0.0803275\n",
      "[1675]\ttraining's rmse: 0.0771974\tvalid_1's rmse: 0.0803263\n",
      "[1700]\ttraining's rmse: 0.0771917\tvalid_1's rmse: 0.0803254\n",
      "[1725]\ttraining's rmse: 0.0771872\tvalid_1's rmse: 0.0803248\n",
      "[1750]\ttraining's rmse: 0.0771804\tvalid_1's rmse: 0.0803245\n",
      "[1775]\ttraining's rmse: 0.0771747\tvalid_1's rmse: 0.080324\n",
      "[1800]\ttraining's rmse: 0.077169\tvalid_1's rmse: 0.0803235\n",
      "[1825]\ttraining's rmse: 0.0771638\tvalid_1's rmse: 0.0803223\n",
      "[1850]\ttraining's rmse: 0.0771592\tvalid_1's rmse: 0.0803217\n",
      "[1875]\ttraining's rmse: 0.0771545\tvalid_1's rmse: 0.0803214\n",
      "[1900]\ttraining's rmse: 0.0771508\tvalid_1's rmse: 0.0803212\n",
      "[1925]\ttraining's rmse: 0.0771457\tvalid_1's rmse: 0.0803206\n",
      "[1950]\ttraining's rmse: 0.0771427\tvalid_1's rmse: 0.0803203\n",
      "[1975]\ttraining's rmse: 0.0771393\tvalid_1's rmse: 0.0803196\n",
      "[2000]\ttraining's rmse: 0.0771338\tvalid_1's rmse: 0.0803191\n",
      "[2025]\ttraining's rmse: 0.0771296\tvalid_1's rmse: 0.080318\n",
      "[2050]\ttraining's rmse: 0.0771265\tvalid_1's rmse: 0.0803175\n",
      "[2075]\ttraining's rmse: 0.0771227\tvalid_1's rmse: 0.0803177\n",
      "[2100]\ttraining's rmse: 0.0771205\tvalid_1's rmse: 0.0803176\n",
      "Early stopping, best iteration is:\n",
      "[2053]\ttraining's rmse: 0.077126\tvalid_1's rmse: 0.0803174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0812904\tvalid_1's rmse: 0.0774879\n",
      "[50]\ttraining's rmse: 0.0811876\tvalid_1's rmse: 0.0774416\n",
      "[75]\ttraining's rmse: 0.081083\tvalid_1's rmse: 0.0773968\n",
      "[100]\ttraining's rmse: 0.080988\tvalid_1's rmse: 0.0773568\n",
      "[125]\ttraining's rmse: 0.0808893\tvalid_1's rmse: 0.0773187\n",
      "[150]\ttraining's rmse: 0.0807981\tvalid_1's rmse: 0.0772834\n",
      "[175]\ttraining's rmse: 0.0807247\tvalid_1's rmse: 0.0772534\n",
      "[200]\ttraining's rmse: 0.0806454\tvalid_1's rmse: 0.0772291\n",
      "[225]\ttraining's rmse: 0.0805703\tvalid_1's rmse: 0.0771989\n",
      "[250]\ttraining's rmse: 0.0805047\tvalid_1's rmse: 0.0771741\n",
      "[275]\ttraining's rmse: 0.080444\tvalid_1's rmse: 0.0771503\n",
      "[300]\ttraining's rmse: 0.0803825\tvalid_1's rmse: 0.0771271\n",
      "[325]\ttraining's rmse: 0.0803227\tvalid_1's rmse: 0.0771065\n",
      "[350]\ttraining's rmse: 0.0802626\tvalid_1's rmse: 0.0770857\n",
      "[375]\ttraining's rmse: 0.080213\tvalid_1's rmse: 0.0770691\n",
      "[400]\ttraining's rmse: 0.0801588\tvalid_1's rmse: 0.0770526\n",
      "[425]\ttraining's rmse: 0.0801099\tvalid_1's rmse: 0.0770369\n",
      "[450]\ttraining's rmse: 0.0800676\tvalid_1's rmse: 0.077023\n",
      "[475]\ttraining's rmse: 0.0800254\tvalid_1's rmse: 0.077015\n",
      "[500]\ttraining's rmse: 0.0799905\tvalid_1's rmse: 0.0770041\n",
      "[525]\ttraining's rmse: 0.0799452\tvalid_1's rmse: 0.0769916\n",
      "[550]\ttraining's rmse: 0.0799021\tvalid_1's rmse: 0.076984\n",
      "[575]\ttraining's rmse: 0.0798635\tvalid_1's rmse: 0.0769739\n",
      "[600]\ttraining's rmse: 0.079825\tvalid_1's rmse: 0.0769638\n",
      "[625]\ttraining's rmse: 0.0797959\tvalid_1's rmse: 0.07696\n",
      "[650]\ttraining's rmse: 0.0797584\tvalid_1's rmse: 0.0769578\n",
      "[675]\ttraining's rmse: 0.0797199\tvalid_1's rmse: 0.0769549\n",
      "[700]\ttraining's rmse: 0.079687\tvalid_1's rmse: 0.076952\n",
      "[725]\ttraining's rmse: 0.0796556\tvalid_1's rmse: 0.0769542\n",
      "[750]\ttraining's rmse: 0.0796245\tvalid_1's rmse: 0.0769724\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's rmse: 0.0796617\tvalid_1's rmse: 0.0769504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0819778\tvalid_1's rmse: 0.0840977\n",
      "[50]\ttraining's rmse: 0.0818549\tvalid_1's rmse: 0.0840486\n",
      "[75]\ttraining's rmse: 0.0817323\tvalid_1's rmse: 0.0840008\n",
      "[100]\ttraining's rmse: 0.0816155\tvalid_1's rmse: 0.0839586\n",
      "[125]\ttraining's rmse: 0.0815028\tvalid_1's rmse: 0.0839158\n",
      "[150]\ttraining's rmse: 0.0813965\tvalid_1's rmse: 0.0838777\n",
      "[175]\ttraining's rmse: 0.0813118\tvalid_1's rmse: 0.0838448\n",
      "[200]\ttraining's rmse: 0.0812172\tvalid_1's rmse: 0.0838122\n",
      "[225]\ttraining's rmse: 0.0811248\tvalid_1's rmse: 0.083781\n",
      "[250]\ttraining's rmse: 0.0810477\tvalid_1's rmse: 0.0837505\n",
      "[275]\ttraining's rmse: 0.0809733\tvalid_1's rmse: 0.0837245\n",
      "[300]\ttraining's rmse: 0.0809007\tvalid_1's rmse: 0.0836996\n",
      "[325]\ttraining's rmse: 0.0808266\tvalid_1's rmse: 0.0836758\n",
      "[350]\ttraining's rmse: 0.0807565\tvalid_1's rmse: 0.083653\n",
      "[375]\ttraining's rmse: 0.0806982\tvalid_1's rmse: 0.0836344\n",
      "[400]\ttraining's rmse: 0.0806359\tvalid_1's rmse: 0.083617\n",
      "[425]\ttraining's rmse: 0.0805789\tvalid_1's rmse: 0.0835994\n",
      "[450]\ttraining's rmse: 0.0805275\tvalid_1's rmse: 0.0835807\n",
      "[475]\ttraining's rmse: 0.0804824\tvalid_1's rmse: 0.0835642\n",
      "[500]\ttraining's rmse: 0.080443\tvalid_1's rmse: 0.0835513\n",
      "[525]\ttraining's rmse: 0.0803931\tvalid_1's rmse: 0.0835365\n",
      "[550]\ttraining's rmse: 0.0803468\tvalid_1's rmse: 0.0835232\n",
      "[575]\ttraining's rmse: 0.0803016\tvalid_1's rmse: 0.0835102\n",
      "[600]\ttraining's rmse: 0.0802609\tvalid_1's rmse: 0.0834987\n",
      "[625]\ttraining's rmse: 0.080228\tvalid_1's rmse: 0.0834885\n",
      "[650]\ttraining's rmse: 0.0801865\tvalid_1's rmse: 0.0834769\n",
      "[675]\ttraining's rmse: 0.0801457\tvalid_1's rmse: 0.0834667\n",
      "[700]\ttraining's rmse: 0.0801093\tvalid_1's rmse: 0.083457\n",
      "[725]\ttraining's rmse: 0.0800721\tvalid_1's rmse: 0.0834476\n",
      "[750]\ttraining's rmse: 0.0800385\tvalid_1's rmse: 0.0834394\n",
      "[775]\ttraining's rmse: 0.0800126\tvalid_1's rmse: 0.0834311\n",
      "[800]\ttraining's rmse: 0.0799797\tvalid_1's rmse: 0.0834238\n",
      "[825]\ttraining's rmse: 0.0799523\tvalid_1's rmse: 0.083416\n",
      "[850]\ttraining's rmse: 0.07992\tvalid_1's rmse: 0.0834106\n",
      "[875]\ttraining's rmse: 0.0798935\tvalid_1's rmse: 0.0834041\n",
      "[900]\ttraining's rmse: 0.0798627\tvalid_1's rmse: 0.0833966\n",
      "[925]\ttraining's rmse: 0.0798382\tvalid_1's rmse: 0.0833914\n",
      "[950]\ttraining's rmse: 0.0798146\tvalid_1's rmse: 0.0833866\n",
      "[975]\ttraining's rmse: 0.0797934\tvalid_1's rmse: 0.0833811\n",
      "[1000]\ttraining's rmse: 0.0797722\tvalid_1's rmse: 0.0833756\n",
      "[1025]\ttraining's rmse: 0.0797496\tvalid_1's rmse: 0.08337\n",
      "[1050]\ttraining's rmse: 0.0797282\tvalid_1's rmse: 0.0833641\n",
      "[1075]\ttraining's rmse: 0.079708\tvalid_1's rmse: 0.0833601\n",
      "[1100]\ttraining's rmse: 0.0796928\tvalid_1's rmse: 0.083356\n",
      "[1125]\ttraining's rmse: 0.0796754\tvalid_1's rmse: 0.0833524\n",
      "[1150]\ttraining's rmse: 0.0796574\tvalid_1's rmse: 0.0833493\n",
      "[1175]\ttraining's rmse: 0.079642\tvalid_1's rmse: 0.0833459\n",
      "[1200]\ttraining's rmse: 0.0796283\tvalid_1's rmse: 0.0833414\n",
      "[1225]\ttraining's rmse: 0.0796108\tvalid_1's rmse: 0.0833377\n",
      "[1250]\ttraining's rmse: 0.0795976\tvalid_1's rmse: 0.0833339\n",
      "[1275]\ttraining's rmse: 0.0795834\tvalid_1's rmse: 0.0833304\n",
      "[1300]\ttraining's rmse: 0.0795716\tvalid_1's rmse: 0.0833264\n",
      "[1325]\ttraining's rmse: 0.0795586\tvalid_1's rmse: 0.0833241\n",
      "[1350]\ttraining's rmse: 0.0795476\tvalid_1's rmse: 0.0833218\n",
      "[1375]\ttraining's rmse: 0.0795345\tvalid_1's rmse: 0.0833189\n",
      "[1400]\ttraining's rmse: 0.0795235\tvalid_1's rmse: 0.0833159\n",
      "[1425]\ttraining's rmse: 0.0795081\tvalid_1's rmse: 0.0833131\n",
      "[1450]\ttraining's rmse: 0.0794983\tvalid_1's rmse: 0.0833107\n",
      "[1475]\ttraining's rmse: 0.0794902\tvalid_1's rmse: 0.0833077\n",
      "[1500]\ttraining's rmse: 0.0794823\tvalid_1's rmse: 0.0833048\n",
      "[1525]\ttraining's rmse: 0.0794736\tvalid_1's rmse: 0.0833022\n",
      "[1550]\ttraining's rmse: 0.0794638\tvalid_1's rmse: 0.0833003\n",
      "[1575]\ttraining's rmse: 0.0794541\tvalid_1's rmse: 0.0832984\n",
      "[1600]\ttraining's rmse: 0.0794476\tvalid_1's rmse: 0.0832968\n",
      "[1625]\ttraining's rmse: 0.0794407\tvalid_1's rmse: 0.0832943\n",
      "[1650]\ttraining's rmse: 0.079432\tvalid_1's rmse: 0.083292\n",
      "[1675]\ttraining's rmse: 0.0794266\tvalid_1's rmse: 0.0832895\n",
      "[1700]\ttraining's rmse: 0.0794215\tvalid_1's rmse: 0.0832878\n",
      "[1725]\ttraining's rmse: 0.0794159\tvalid_1's rmse: 0.0832863\n",
      "[1750]\ttraining's rmse: 0.0794095\tvalid_1's rmse: 0.0832843\n",
      "[1775]\ttraining's rmse: 0.0794052\tvalid_1's rmse: 0.083283\n",
      "[1800]\ttraining's rmse: 0.0793978\tvalid_1's rmse: 0.0832817\n",
      "[1825]\ttraining's rmse: 0.0793926\tvalid_1's rmse: 0.083279\n",
      "[1850]\ttraining's rmse: 0.0793875\tvalid_1's rmse: 0.0832767\n",
      "[1875]\ttraining's rmse: 0.0793836\tvalid_1's rmse: 0.0832758\n",
      "[1900]\ttraining's rmse: 0.0793794\tvalid_1's rmse: 0.0832741\n",
      "[1925]\ttraining's rmse: 0.0793745\tvalid_1's rmse: 0.0832726\n",
      "[1950]\ttraining's rmse: 0.0793718\tvalid_1's rmse: 0.0832712\n",
      "[1975]\ttraining's rmse: 0.0793688\tvalid_1's rmse: 0.0832704\n",
      "[2000]\ttraining's rmse: 0.0793647\tvalid_1's rmse: 0.0832694\n",
      "[2025]\ttraining's rmse: 0.0793618\tvalid_1's rmse: 0.0832684\n",
      "[2050]\ttraining's rmse: 0.0793587\tvalid_1's rmse: 0.0832672\n",
      "[2075]\ttraining's rmse: 0.0793548\tvalid_1's rmse: 0.0832667\n",
      "[2100]\ttraining's rmse: 0.0793523\tvalid_1's rmse: 0.0832664\n",
      "[2125]\ttraining's rmse: 0.0793496\tvalid_1's rmse: 0.0832657\n",
      "[2150]\ttraining's rmse: 0.0793461\tvalid_1's rmse: 0.0832643\n",
      "[2175]\ttraining's rmse: 0.0793433\tvalid_1's rmse: 0.0832639\n",
      "[2200]\ttraining's rmse: 0.0793411\tvalid_1's rmse: 0.0832633\n",
      "[2225]\ttraining's rmse: 0.0793383\tvalid_1's rmse: 0.0832626\n",
      "[2250]\ttraining's rmse: 0.0793342\tvalid_1's rmse: 0.083262\n",
      "[2275]\ttraining's rmse: 0.0793314\tvalid_1's rmse: 0.0832612\n",
      "[2300]\ttraining's rmse: 0.0793278\tvalid_1's rmse: 0.0832601\n",
      "[2325]\ttraining's rmse: 0.0793251\tvalid_1's rmse: 0.0832599\n",
      "[2350]\ttraining's rmse: 0.0793225\tvalid_1's rmse: 0.0832598\n",
      "[2375]\ttraining's rmse: 0.0793205\tvalid_1's rmse: 0.0832588\n",
      "[2400]\ttraining's rmse: 0.0793174\tvalid_1's rmse: 0.0832584\n",
      "[2425]\ttraining's rmse: 0.0793159\tvalid_1's rmse: 0.0832582\n",
      "[2450]\ttraining's rmse: 0.0793139\tvalid_1's rmse: 0.083258\n",
      "[2475]\ttraining's rmse: 0.0793115\tvalid_1's rmse: 0.083258\n",
      "[2500]\ttraining's rmse: 0.0793102\tvalid_1's rmse: 0.0832575\n",
      "[2525]\ttraining's rmse: 0.0793081\tvalid_1's rmse: 0.0832572\n",
      "[2550]\ttraining's rmse: 0.0793057\tvalid_1's rmse: 0.0832566\n",
      "[2575]\ttraining's rmse: 0.0793037\tvalid_1's rmse: 0.0832563\n",
      "[2600]\ttraining's rmse: 0.0793022\tvalid_1's rmse: 0.0832561\n",
      "[2625]\ttraining's rmse: 0.079299\tvalid_1's rmse: 0.0832552\n",
      "[2650]\ttraining's rmse: 0.0792959\tvalid_1's rmse: 0.0832543\n",
      "[2675]\ttraining's rmse: 0.0792942\tvalid_1's rmse: 0.0832543\n",
      "[2700]\ttraining's rmse: 0.0792929\tvalid_1's rmse: 0.0832542\n",
      "[2725]\ttraining's rmse: 0.0792919\tvalid_1's rmse: 0.0832537\n",
      "[2750]\ttraining's rmse: 0.0792892\tvalid_1's rmse: 0.0832535\n",
      "[2775]\ttraining's rmse: 0.0792869\tvalid_1's rmse: 0.0832532\n",
      "[2800]\ttraining's rmse: 0.0792855\tvalid_1's rmse: 0.083253\n",
      "[2825]\ttraining's rmse: 0.0792843\tvalid_1's rmse: 0.0832525\n",
      "[2850]\ttraining's rmse: 0.0792824\tvalid_1's rmse: 0.0832523\n",
      "[2875]\ttraining's rmse: 0.0792805\tvalid_1's rmse: 0.0832521\n",
      "[2900]\ttraining's rmse: 0.0792788\tvalid_1's rmse: 0.083252\n",
      "[2925]\ttraining's rmse: 0.0792773\tvalid_1's rmse: 0.0832519\n",
      "[2950]\ttraining's rmse: 0.0792756\tvalid_1's rmse: 0.0832514\n",
      "[2975]\ttraining's rmse: 0.0792743\tvalid_1's rmse: 0.0832513\n",
      "[3000]\ttraining's rmse: 0.0792726\tvalid_1's rmse: 0.0832507\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0792726\tvalid_1's rmse: 0.0832507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0820358\tvalid_1's rmse: 0.0840028\n",
      "[50]\ttraining's rmse: 0.081927\tvalid_1's rmse: 0.0839528\n",
      "[75]\ttraining's rmse: 0.081812\tvalid_1's rmse: 0.0839023\n",
      "[100]\ttraining's rmse: 0.0817091\tvalid_1's rmse: 0.0838579\n",
      "[125]\ttraining's rmse: 0.0816044\tvalid_1's rmse: 0.0838128\n",
      "[150]\ttraining's rmse: 0.0815097\tvalid_1's rmse: 0.0837714\n",
      "[175]\ttraining's rmse: 0.0814276\tvalid_1's rmse: 0.0837363\n",
      "[200]\ttraining's rmse: 0.0813396\tvalid_1's rmse: 0.0836993\n",
      "[225]\ttraining's rmse: 0.0812558\tvalid_1's rmse: 0.0836659\n",
      "[250]\ttraining's rmse: 0.0811853\tvalid_1's rmse: 0.0836352\n",
      "[275]\ttraining's rmse: 0.0811207\tvalid_1's rmse: 0.0836082\n",
      "[300]\ttraining's rmse: 0.0810547\tvalid_1's rmse: 0.0835831\n",
      "[325]\ttraining's rmse: 0.0809853\tvalid_1's rmse: 0.0835573\n",
      "[350]\ttraining's rmse: 0.0809231\tvalid_1's rmse: 0.0835351\n",
      "[375]\ttraining's rmse: 0.0808679\tvalid_1's rmse: 0.0835143\n",
      "[400]\ttraining's rmse: 0.0808099\tvalid_1's rmse: 0.0834942\n",
      "[425]\ttraining's rmse: 0.0807573\tvalid_1's rmse: 0.0834744\n",
      "[450]\ttraining's rmse: 0.080708\tvalid_1's rmse: 0.0834569\n",
      "[475]\ttraining's rmse: 0.0806621\tvalid_1's rmse: 0.08344\n",
      "[500]\ttraining's rmse: 0.0806242\tvalid_1's rmse: 0.0834243\n",
      "[525]\ttraining's rmse: 0.0805721\tvalid_1's rmse: 0.0834077\n",
      "[550]\ttraining's rmse: 0.0805248\tvalid_1's rmse: 0.0833925\n",
      "[575]\ttraining's rmse: 0.0804833\tvalid_1's rmse: 0.0833785\n",
      "[600]\ttraining's rmse: 0.0804433\tvalid_1's rmse: 0.0833666\n",
      "[625]\ttraining's rmse: 0.0804121\tvalid_1's rmse: 0.0833551\n",
      "[650]\ttraining's rmse: 0.0803705\tvalid_1's rmse: 0.083343\n",
      "[675]\ttraining's rmse: 0.0803317\tvalid_1's rmse: 0.0833313\n",
      "[700]\ttraining's rmse: 0.0802966\tvalid_1's rmse: 0.0833203\n",
      "[725]\ttraining's rmse: 0.0802645\tvalid_1's rmse: 0.0833108\n",
      "[750]\ttraining's rmse: 0.0802338\tvalid_1's rmse: 0.0833025\n",
      "[775]\ttraining's rmse: 0.0802087\tvalid_1's rmse: 0.0832938\n",
      "[800]\ttraining's rmse: 0.0801761\tvalid_1's rmse: 0.0832859\n",
      "[825]\ttraining's rmse: 0.0801489\tvalid_1's rmse: 0.0832778\n",
      "[850]\ttraining's rmse: 0.0801204\tvalid_1's rmse: 0.0832705\n",
      "[875]\ttraining's rmse: 0.0800938\tvalid_1's rmse: 0.0832641\n",
      "[900]\ttraining's rmse: 0.0800669\tvalid_1's rmse: 0.0832567\n",
      "[925]\ttraining's rmse: 0.0800424\tvalid_1's rmse: 0.0832517\n",
      "[950]\ttraining's rmse: 0.0800194\tvalid_1's rmse: 0.0832464\n",
      "[975]\ttraining's rmse: 0.079997\tvalid_1's rmse: 0.0832415\n",
      "[1000]\ttraining's rmse: 0.0799786\tvalid_1's rmse: 0.0832369\n",
      "[1025]\ttraining's rmse: 0.0799571\tvalid_1's rmse: 0.0832326\n",
      "[1050]\ttraining's rmse: 0.0799379\tvalid_1's rmse: 0.0832282\n",
      "[1075]\ttraining's rmse: 0.0799161\tvalid_1's rmse: 0.0832248\n",
      "[1100]\ttraining's rmse: 0.0798978\tvalid_1's rmse: 0.0832199\n",
      "[1125]\ttraining's rmse: 0.0798812\tvalid_1's rmse: 0.0832163\n",
      "[1150]\ttraining's rmse: 0.0798643\tvalid_1's rmse: 0.0832131\n",
      "[1175]\ttraining's rmse: 0.0798492\tvalid_1's rmse: 0.0832103\n",
      "[1200]\ttraining's rmse: 0.0798336\tvalid_1's rmse: 0.0832071\n",
      "[1225]\ttraining's rmse: 0.0798185\tvalid_1's rmse: 0.083204\n",
      "[1250]\ttraining's rmse: 0.0798044\tvalid_1's rmse: 0.0832012\n",
      "[1275]\ttraining's rmse: 0.0797886\tvalid_1's rmse: 0.0831989\n",
      "[1300]\ttraining's rmse: 0.079776\tvalid_1's rmse: 0.0831955\n",
      "[1325]\ttraining's rmse: 0.0797623\tvalid_1's rmse: 0.0831929\n",
      "[1350]\ttraining's rmse: 0.0797503\tvalid_1's rmse: 0.0831909\n",
      "[1375]\ttraining's rmse: 0.0797384\tvalid_1's rmse: 0.0831895\n",
      "[1400]\ttraining's rmse: 0.0797307\tvalid_1's rmse: 0.0831869\n",
      "[1425]\ttraining's rmse: 0.0797188\tvalid_1's rmse: 0.0831851\n",
      "[1450]\ttraining's rmse: 0.0797085\tvalid_1's rmse: 0.0831837\n",
      "[1475]\ttraining's rmse: 0.0796997\tvalid_1's rmse: 0.083182\n",
      "[1500]\ttraining's rmse: 0.0796925\tvalid_1's rmse: 0.0831803\n",
      "[1525]\ttraining's rmse: 0.0796848\tvalid_1's rmse: 0.0831791\n",
      "[1550]\ttraining's rmse: 0.0796768\tvalid_1's rmse: 0.0831777\n",
      "[1575]\ttraining's rmse: 0.0796686\tvalid_1's rmse: 0.0831757\n",
      "[1600]\ttraining's rmse: 0.0796618\tvalid_1's rmse: 0.0831748\n",
      "[1625]\ttraining's rmse: 0.0796566\tvalid_1's rmse: 0.0831738\n",
      "[1650]\ttraining's rmse: 0.0796496\tvalid_1's rmse: 0.0831732\n",
      "[1675]\ttraining's rmse: 0.0796446\tvalid_1's rmse: 0.083172\n",
      "[1700]\ttraining's rmse: 0.0796396\tvalid_1's rmse: 0.0831712\n",
      "[1725]\ttraining's rmse: 0.079633\tvalid_1's rmse: 0.0831706\n",
      "[1750]\ttraining's rmse: 0.0796266\tvalid_1's rmse: 0.0831697\n",
      "[1775]\ttraining's rmse: 0.0796216\tvalid_1's rmse: 0.0831692\n",
      "[1800]\ttraining's rmse: 0.0796153\tvalid_1's rmse: 0.0831688\n",
      "[1825]\ttraining's rmse: 0.0796104\tvalid_1's rmse: 0.0831679\n",
      "[1850]\ttraining's rmse: 0.0796044\tvalid_1's rmse: 0.0831664\n",
      "[1875]\ttraining's rmse: 0.0795985\tvalid_1's rmse: 0.0831656\n",
      "[1900]\ttraining's rmse: 0.0795935\tvalid_1's rmse: 0.0831653\n",
      "[1925]\ttraining's rmse: 0.079589\tvalid_1's rmse: 0.0831646\n",
      "[1950]\ttraining's rmse: 0.0795861\tvalid_1's rmse: 0.0831638\n",
      "[1975]\ttraining's rmse: 0.0795818\tvalid_1's rmse: 0.0831629\n",
      "[2000]\ttraining's rmse: 0.0795773\tvalid_1's rmse: 0.0831623\n",
      "[2025]\ttraining's rmse: 0.0795739\tvalid_1's rmse: 0.0831616\n",
      "[2050]\ttraining's rmse: 0.0795692\tvalid_1's rmse: 0.0831613\n",
      "[2075]\ttraining's rmse: 0.0795661\tvalid_1's rmse: 0.0831609\n",
      "[2100]\ttraining's rmse: 0.079564\tvalid_1's rmse: 0.0831608\n",
      "[2125]\ttraining's rmse: 0.0795602\tvalid_1's rmse: 0.0831608\n",
      "[2150]\ttraining's rmse: 0.0795575\tvalid_1's rmse: 0.0831606\n",
      "[2175]\ttraining's rmse: 0.0795552\tvalid_1's rmse: 0.0831602\n",
      "[2200]\ttraining's rmse: 0.0795523\tvalid_1's rmse: 0.0831599\n",
      "[2225]\ttraining's rmse: 0.0795491\tvalid_1's rmse: 0.0831595\n",
      "[2250]\ttraining's rmse: 0.0795464\tvalid_1's rmse: 0.0831596\n",
      "[2275]\ttraining's rmse: 0.0795424\tvalid_1's rmse: 0.0831592\n",
      "[2300]\ttraining's rmse: 0.0795384\tvalid_1's rmse: 0.0831587\n",
      "[2325]\ttraining's rmse: 0.0795361\tvalid_1's rmse: 0.0831584\n",
      "[2350]\ttraining's rmse: 0.079534\tvalid_1's rmse: 0.0831582\n",
      "[2375]\ttraining's rmse: 0.0795322\tvalid_1's rmse: 0.0831579\n",
      "[2400]\ttraining's rmse: 0.0795292\tvalid_1's rmse: 0.0831582\n",
      "[2425]\ttraining's rmse: 0.0795266\tvalid_1's rmse: 0.0831579\n",
      "Early stopping, best iteration is:\n",
      "[2384]\ttraining's rmse: 0.0795309\tvalid_1's rmse: 0.0831578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0839342\tvalid_1's rmse: 0.0801489\n",
      "[50]\ttraining's rmse: 0.0838292\tvalid_1's rmse: 0.0801034\n",
      "[75]\ttraining's rmse: 0.0837172\tvalid_1's rmse: 0.0800572\n",
      "[100]\ttraining's rmse: 0.083618\tvalid_1's rmse: 0.0800161\n",
      "[125]\ttraining's rmse: 0.0835139\tvalid_1's rmse: 0.0799744\n",
      "[150]\ttraining's rmse: 0.0834179\tvalid_1's rmse: 0.079939\n",
      "[175]\ttraining's rmse: 0.0833389\tvalid_1's rmse: 0.079907\n",
      "[200]\ttraining's rmse: 0.0832504\tvalid_1's rmse: 0.0798765\n",
      "[225]\ttraining's rmse: 0.0831652\tvalid_1's rmse: 0.0798468\n",
      "[250]\ttraining's rmse: 0.0830952\tvalid_1's rmse: 0.0798215\n",
      "[275]\ttraining's rmse: 0.0830322\tvalid_1's rmse: 0.0797989\n",
      "[300]\ttraining's rmse: 0.0829673\tvalid_1's rmse: 0.0797762\n",
      "[325]\ttraining's rmse: 0.0829023\tvalid_1's rmse: 0.0797551\n",
      "[350]\ttraining's rmse: 0.0828392\tvalid_1's rmse: 0.0797343\n",
      "[375]\ttraining's rmse: 0.082787\tvalid_1's rmse: 0.079717\n",
      "[400]\ttraining's rmse: 0.0827311\tvalid_1's rmse: 0.0797029\n",
      "[425]\ttraining's rmse: 0.0826797\tvalid_1's rmse: 0.0796894\n",
      "[450]\ttraining's rmse: 0.082631\tvalid_1's rmse: 0.0796758\n",
      "[475]\ttraining's rmse: 0.0825858\tvalid_1's rmse: 0.0796627\n",
      "[500]\ttraining's rmse: 0.082548\tvalid_1's rmse: 0.0796493\n",
      "[525]\ttraining's rmse: 0.0824991\tvalid_1's rmse: 0.0796364\n",
      "[550]\ttraining's rmse: 0.0824538\tvalid_1's rmse: 0.0796302\n",
      "[575]\ttraining's rmse: 0.0824108\tvalid_1's rmse: 0.0796198\n",
      "[600]\ttraining's rmse: 0.0823712\tvalid_1's rmse: 0.0796132\n",
      "[625]\ttraining's rmse: 0.0823378\tvalid_1's rmse: 0.0796078\n",
      "[650]\ttraining's rmse: 0.0822967\tvalid_1's rmse: 0.0795983\n",
      "[675]\ttraining's rmse: 0.0822548\tvalid_1's rmse: 0.0795905\n",
      "[700]\ttraining's rmse: 0.0822197\tvalid_1's rmse: 0.079584\n",
      "[725]\ttraining's rmse: 0.0821858\tvalid_1's rmse: 0.0795867\n",
      "[750]\ttraining's rmse: 0.0821544\tvalid_1's rmse: 0.0795855\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 0.0822069\tvalid_1's rmse: 0.0795827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0796353\tvalid_1's rmse: 0.0820692\n",
      "[50]\ttraining's rmse: 0.0795215\tvalid_1's rmse: 0.0820159\n",
      "[75]\ttraining's rmse: 0.0794053\tvalid_1's rmse: 0.0819641\n",
      "[100]\ttraining's rmse: 0.0792993\tvalid_1's rmse: 0.0819204\n",
      "[125]\ttraining's rmse: 0.0791899\tvalid_1's rmse: 0.0818759\n",
      "[150]\ttraining's rmse: 0.0790941\tvalid_1's rmse: 0.0818365\n",
      "[175]\ttraining's rmse: 0.0790155\tvalid_1's rmse: 0.0818019\n",
      "[200]\ttraining's rmse: 0.0789291\tvalid_1's rmse: 0.0817657\n",
      "[225]\ttraining's rmse: 0.0788467\tvalid_1's rmse: 0.0817318\n",
      "[250]\ttraining's rmse: 0.0787776\tvalid_1's rmse: 0.0817012\n",
      "[275]\ttraining's rmse: 0.078712\tvalid_1's rmse: 0.0816732\n",
      "[300]\ttraining's rmse: 0.0786465\tvalid_1's rmse: 0.0816468\n",
      "[325]\ttraining's rmse: 0.0785781\tvalid_1's rmse: 0.081619\n",
      "[350]\ttraining's rmse: 0.0785158\tvalid_1's rmse: 0.0815942\n",
      "[375]\ttraining's rmse: 0.0784643\tvalid_1's rmse: 0.0815719\n",
      "[400]\ttraining's rmse: 0.0784071\tvalid_1's rmse: 0.0815507\n",
      "[425]\ttraining's rmse: 0.0783572\tvalid_1's rmse: 0.0815324\n",
      "[450]\ttraining's rmse: 0.0783091\tvalid_1's rmse: 0.0815124\n",
      "[475]\ttraining's rmse: 0.0782648\tvalid_1's rmse: 0.0814949\n",
      "[500]\ttraining's rmse: 0.0782274\tvalid_1's rmse: 0.0814792\n",
      "[525]\ttraining's rmse: 0.0781798\tvalid_1's rmse: 0.0814629\n",
      "[550]\ttraining's rmse: 0.078136\tvalid_1's rmse: 0.0814475\n",
      "[575]\ttraining's rmse: 0.0780973\tvalid_1's rmse: 0.0814341\n",
      "[600]\ttraining's rmse: 0.0780587\tvalid_1's rmse: 0.0814205\n",
      "[625]\ttraining's rmse: 0.0780287\tvalid_1's rmse: 0.0814076\n",
      "[650]\ttraining's rmse: 0.077991\tvalid_1's rmse: 0.0813952\n",
      "[675]\ttraining's rmse: 0.0779566\tvalid_1's rmse: 0.0813837\n",
      "[700]\ttraining's rmse: 0.077922\tvalid_1's rmse: 0.0813707\n",
      "[725]\ttraining's rmse: 0.0778879\tvalid_1's rmse: 0.0813599\n",
      "[750]\ttraining's rmse: 0.0778557\tvalid_1's rmse: 0.0813507\n",
      "[775]\ttraining's rmse: 0.0778307\tvalid_1's rmse: 0.0813412\n",
      "[800]\ttraining's rmse: 0.0778014\tvalid_1's rmse: 0.0813322\n",
      "[825]\ttraining's rmse: 0.0777734\tvalid_1's rmse: 0.0813228\n",
      "[850]\ttraining's rmse: 0.0777457\tvalid_1's rmse: 0.0813164\n",
      "[875]\ttraining's rmse: 0.0777237\tvalid_1's rmse: 0.0813094\n",
      "[900]\ttraining's rmse: 0.077697\tvalid_1's rmse: 0.0813013\n",
      "[925]\ttraining's rmse: 0.0776752\tvalid_1's rmse: 0.0812952\n",
      "[950]\ttraining's rmse: 0.0776535\tvalid_1's rmse: 0.0812884\n",
      "[975]\ttraining's rmse: 0.0776335\tvalid_1's rmse: 0.0812835\n",
      "[1000]\ttraining's rmse: 0.0776106\tvalid_1's rmse: 0.0812765\n",
      "[1025]\ttraining's rmse: 0.0775885\tvalid_1's rmse: 0.0812707\n",
      "[1050]\ttraining's rmse: 0.077569\tvalid_1's rmse: 0.0812635\n",
      "[1075]\ttraining's rmse: 0.0775514\tvalid_1's rmse: 0.0812577\n",
      "[1100]\ttraining's rmse: 0.0775365\tvalid_1's rmse: 0.081253\n",
      "[1125]\ttraining's rmse: 0.0775213\tvalid_1's rmse: 0.0812472\n",
      "[1150]\ttraining's rmse: 0.0775075\tvalid_1's rmse: 0.081243\n",
      "[1175]\ttraining's rmse: 0.0774925\tvalid_1's rmse: 0.0812392\n",
      "[1200]\ttraining's rmse: 0.0774801\tvalid_1's rmse: 0.0812341\n",
      "[1225]\ttraining's rmse: 0.0774641\tvalid_1's rmse: 0.0812297\n",
      "[1250]\ttraining's rmse: 0.0774488\tvalid_1's rmse: 0.0812252\n",
      "[1275]\ttraining's rmse: 0.0774332\tvalid_1's rmse: 0.0812221\n",
      "[1300]\ttraining's rmse: 0.0774218\tvalid_1's rmse: 0.0812186\n",
      "[1325]\ttraining's rmse: 0.0774103\tvalid_1's rmse: 0.0812156\n",
      "[1350]\ttraining's rmse: 0.0773969\tvalid_1's rmse: 0.0812118\n",
      "[1375]\ttraining's rmse: 0.0773854\tvalid_1's rmse: 0.0812096\n",
      "[1400]\ttraining's rmse: 0.0773762\tvalid_1's rmse: 0.0812066\n",
      "[1425]\ttraining's rmse: 0.0773655\tvalid_1's rmse: 0.0812044\n",
      "[1450]\ttraining's rmse: 0.0773542\tvalid_1's rmse: 0.0812016\n",
      "[1475]\ttraining's rmse: 0.0773454\tvalid_1's rmse: 0.0811991\n",
      "[1500]\ttraining's rmse: 0.0773382\tvalid_1's rmse: 0.0811964\n",
      "[1525]\ttraining's rmse: 0.0773306\tvalid_1's rmse: 0.0811944\n",
      "[1550]\ttraining's rmse: 0.0773221\tvalid_1's rmse: 0.0811919\n",
      "[1575]\ttraining's rmse: 0.0773144\tvalid_1's rmse: 0.0811889\n",
      "[1600]\ttraining's rmse: 0.0773083\tvalid_1's rmse: 0.0811866\n",
      "[1625]\ttraining's rmse: 0.0773006\tvalid_1's rmse: 0.0811842\n",
      "[1650]\ttraining's rmse: 0.0772935\tvalid_1's rmse: 0.0811817\n",
      "[1675]\ttraining's rmse: 0.0772889\tvalid_1's rmse: 0.081179\n",
      "[1700]\ttraining's rmse: 0.0772846\tvalid_1's rmse: 0.0811783\n",
      "[1725]\ttraining's rmse: 0.0772794\tvalid_1's rmse: 0.0811774\n",
      "[1750]\ttraining's rmse: 0.0772739\tvalid_1's rmse: 0.0811759\n",
      "[1775]\ttraining's rmse: 0.0772675\tvalid_1's rmse: 0.081175\n",
      "[1800]\ttraining's rmse: 0.0772631\tvalid_1's rmse: 0.0811733\n",
      "[1825]\ttraining's rmse: 0.0772597\tvalid_1's rmse: 0.0811723\n",
      "[1850]\ttraining's rmse: 0.0772552\tvalid_1's rmse: 0.0811698\n",
      "[1875]\ttraining's rmse: 0.077249\tvalid_1's rmse: 0.0811685\n",
      "[1900]\ttraining's rmse: 0.0772454\tvalid_1's rmse: 0.0811677\n",
      "[1925]\ttraining's rmse: 0.0772431\tvalid_1's rmse: 0.0811663\n",
      "[1950]\ttraining's rmse: 0.0772394\tvalid_1's rmse: 0.081165\n",
      "[1975]\ttraining's rmse: 0.0772359\tvalid_1's rmse: 0.0811639\n",
      "[2000]\ttraining's rmse: 0.0772308\tvalid_1's rmse: 0.0811631\n",
      "[2025]\ttraining's rmse: 0.0772285\tvalid_1's rmse: 0.0811625\n",
      "[2050]\ttraining's rmse: 0.077225\tvalid_1's rmse: 0.081161\n",
      "[2075]\ttraining's rmse: 0.0772221\tvalid_1's rmse: 0.0811584\n",
      "[2100]\ttraining's rmse: 0.077219\tvalid_1's rmse: 0.0811573\n",
      "[2125]\ttraining's rmse: 0.0772163\tvalid_1's rmse: 0.081157\n",
      "[2150]\ttraining's rmse: 0.077212\tvalid_1's rmse: 0.0811566\n",
      "[2175]\ttraining's rmse: 0.0772105\tvalid_1's rmse: 0.0811565\n",
      "[2200]\ttraining's rmse: 0.0772081\tvalid_1's rmse: 0.0811557\n",
      "[2225]\ttraining's rmse: 0.0772058\tvalid_1's rmse: 0.081155\n",
      "[2250]\ttraining's rmse: 0.0772039\tvalid_1's rmse: 0.0811546\n",
      "[2275]\ttraining's rmse: 0.0772009\tvalid_1's rmse: 0.0811534\n",
      "[2300]\ttraining's rmse: 0.0771989\tvalid_1's rmse: 0.0811532\n",
      "[2325]\ttraining's rmse: 0.077196\tvalid_1's rmse: 0.081152\n",
      "[2350]\ttraining's rmse: 0.0771946\tvalid_1's rmse: 0.0811512\n",
      "[2375]\ttraining's rmse: 0.0771927\tvalid_1's rmse: 0.0811504\n",
      "[2400]\ttraining's rmse: 0.0771909\tvalid_1's rmse: 0.08115\n",
      "[2425]\ttraining's rmse: 0.0771886\tvalid_1's rmse: 0.0811495\n",
      "[2450]\ttraining's rmse: 0.0771866\tvalid_1's rmse: 0.0811485\n",
      "[2475]\ttraining's rmse: 0.0771833\tvalid_1's rmse: 0.0811482\n",
      "[2500]\ttraining's rmse: 0.0771808\tvalid_1's rmse: 0.0811472\n",
      "[2525]\ttraining's rmse: 0.0771786\tvalid_1's rmse: 0.0811471\n",
      "[2550]\ttraining's rmse: 0.077176\tvalid_1's rmse: 0.0811465\n",
      "[2575]\ttraining's rmse: 0.0771735\tvalid_1's rmse: 0.081146\n",
      "[2600]\ttraining's rmse: 0.0771717\tvalid_1's rmse: 0.0811451\n",
      "[2625]\ttraining's rmse: 0.07717\tvalid_1's rmse: 0.0811449\n",
      "[2650]\ttraining's rmse: 0.0771686\tvalid_1's rmse: 0.0811447\n",
      "[2675]\ttraining's rmse: 0.0771664\tvalid_1's rmse: 0.0811436\n",
      "[2700]\ttraining's rmse: 0.0771652\tvalid_1's rmse: 0.0811432\n",
      "[2725]\ttraining's rmse: 0.077163\tvalid_1's rmse: 0.0811431\n",
      "[2750]\ttraining's rmse: 0.0771615\tvalid_1's rmse: 0.0811427\n",
      "[2775]\ttraining's rmse: 0.0771594\tvalid_1's rmse: 0.0811426\n",
      "[2800]\ttraining's rmse: 0.0771583\tvalid_1's rmse: 0.0811424\n",
      "[2825]\ttraining's rmse: 0.0771551\tvalid_1's rmse: 0.0811415\n",
      "[2850]\ttraining's rmse: 0.0771535\tvalid_1's rmse: 0.0811412\n",
      "[2875]\ttraining's rmse: 0.077152\tvalid_1's rmse: 0.0811408\n",
      "[2900]\ttraining's rmse: 0.0771497\tvalid_1's rmse: 0.0811408\n",
      "Early stopping, best iteration is:\n",
      "[2855]\ttraining's rmse: 0.0771531\tvalid_1's rmse: 0.0811408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.07986\tvalid_1's rmse: 0.081626\n",
      "[50]\ttraining's rmse: 0.0797507\tvalid_1's rmse: 0.0815724\n",
      "[75]\ttraining's rmse: 0.0796385\tvalid_1's rmse: 0.0815213\n",
      "[100]\ttraining's rmse: 0.0795413\tvalid_1's rmse: 0.0814762\n",
      "[125]\ttraining's rmse: 0.079438\tvalid_1's rmse: 0.0814296\n",
      "[150]\ttraining's rmse: 0.0793443\tvalid_1's rmse: 0.0813879\n",
      "[175]\ttraining's rmse: 0.079268\tvalid_1's rmse: 0.0813537\n",
      "[200]\ttraining's rmse: 0.079183\tvalid_1's rmse: 0.0813178\n",
      "[225]\ttraining's rmse: 0.0790994\tvalid_1's rmse: 0.0812849\n",
      "[250]\ttraining's rmse: 0.0790294\tvalid_1's rmse: 0.0812547\n",
      "[275]\ttraining's rmse: 0.0789649\tvalid_1's rmse: 0.0812265\n",
      "[300]\ttraining's rmse: 0.0789007\tvalid_1's rmse: 0.0812005\n",
      "[325]\ttraining's rmse: 0.0788335\tvalid_1's rmse: 0.0811749\n",
      "[350]\ttraining's rmse: 0.078768\tvalid_1's rmse: 0.0811503\n",
      "[375]\ttraining's rmse: 0.0787163\tvalid_1's rmse: 0.0811305\n",
      "[400]\ttraining's rmse: 0.0786603\tvalid_1's rmse: 0.081111\n",
      "[425]\ttraining's rmse: 0.0786099\tvalid_1's rmse: 0.0810928\n",
      "[450]\ttraining's rmse: 0.0785632\tvalid_1's rmse: 0.0810742\n",
      "[475]\ttraining's rmse: 0.0785184\tvalid_1's rmse: 0.0810577\n",
      "[500]\ttraining's rmse: 0.0784801\tvalid_1's rmse: 0.0810433\n",
      "[525]\ttraining's rmse: 0.0784315\tvalid_1's rmse: 0.0810277\n",
      "[550]\ttraining's rmse: 0.0783854\tvalid_1's rmse: 0.0810123\n",
      "[575]\ttraining's rmse: 0.0783449\tvalid_1's rmse: 0.0809992\n",
      "[600]\ttraining's rmse: 0.0783056\tvalid_1's rmse: 0.0809879\n",
      "[625]\ttraining's rmse: 0.0782745\tvalid_1's rmse: 0.0809769\n",
      "[650]\ttraining's rmse: 0.0782342\tvalid_1's rmse: 0.0809645\n",
      "[675]\ttraining's rmse: 0.0781972\tvalid_1's rmse: 0.0809537\n",
      "[700]\ttraining's rmse: 0.0781631\tvalid_1's rmse: 0.0809441\n",
      "[725]\ttraining's rmse: 0.0781305\tvalid_1's rmse: 0.0809347\n",
      "[750]\ttraining's rmse: 0.0781\tvalid_1's rmse: 0.0809261\n",
      "[775]\ttraining's rmse: 0.0780741\tvalid_1's rmse: 0.0809183\n",
      "[800]\ttraining's rmse: 0.0780417\tvalid_1's rmse: 0.0809102\n",
      "[825]\ttraining's rmse: 0.0780135\tvalid_1's rmse: 0.0809025\n",
      "[850]\ttraining's rmse: 0.077987\tvalid_1's rmse: 0.0808967\n",
      "[875]\ttraining's rmse: 0.0779637\tvalid_1's rmse: 0.0808905\n",
      "[900]\ttraining's rmse: 0.0779357\tvalid_1's rmse: 0.0808841\n",
      "[925]\ttraining's rmse: 0.0779122\tvalid_1's rmse: 0.080879\n",
      "[950]\ttraining's rmse: 0.0778903\tvalid_1's rmse: 0.080874\n",
      "[975]\ttraining's rmse: 0.0778699\tvalid_1's rmse: 0.0808685\n",
      "[1000]\ttraining's rmse: 0.077852\tvalid_1's rmse: 0.0808638\n",
      "[1025]\ttraining's rmse: 0.0778286\tvalid_1's rmse: 0.0808599\n",
      "[1050]\ttraining's rmse: 0.0778098\tvalid_1's rmse: 0.0808551\n",
      "[1075]\ttraining's rmse: 0.0777907\tvalid_1's rmse: 0.0808519\n",
      "[1100]\ttraining's rmse: 0.0777767\tvalid_1's rmse: 0.0808482\n",
      "[1125]\ttraining's rmse: 0.0777583\tvalid_1's rmse: 0.0808444\n",
      "[1150]\ttraining's rmse: 0.0777408\tvalid_1's rmse: 0.0808415\n",
      "[1175]\ttraining's rmse: 0.0777273\tvalid_1's rmse: 0.0808385\n",
      "[1200]\ttraining's rmse: 0.0777135\tvalid_1's rmse: 0.0808359\n",
      "[1225]\ttraining's rmse: 0.0776993\tvalid_1's rmse: 0.0808329\n",
      "[1250]\ttraining's rmse: 0.0776873\tvalid_1's rmse: 0.0808302\n",
      "[1275]\ttraining's rmse: 0.0776727\tvalid_1's rmse: 0.0808284\n",
      "[1300]\ttraining's rmse: 0.0776624\tvalid_1's rmse: 0.0808266\n",
      "[1325]\ttraining's rmse: 0.0776516\tvalid_1's rmse: 0.0808244\n",
      "[1350]\ttraining's rmse: 0.0776381\tvalid_1's rmse: 0.0808225\n",
      "[1375]\ttraining's rmse: 0.0776286\tvalid_1's rmse: 0.0808206\n",
      "[1400]\ttraining's rmse: 0.0776188\tvalid_1's rmse: 0.0808183\n",
      "[1425]\ttraining's rmse: 0.0776082\tvalid_1's rmse: 0.0808171\n",
      "[1450]\ttraining's rmse: 0.0775977\tvalid_1's rmse: 0.080816\n",
      "[1475]\ttraining's rmse: 0.0775867\tvalid_1's rmse: 0.0808136\n",
      "[1500]\ttraining's rmse: 0.0775792\tvalid_1's rmse: 0.0808118\n",
      "[1525]\ttraining's rmse: 0.0775707\tvalid_1's rmse: 0.0808104\n",
      "[1550]\ttraining's rmse: 0.0775621\tvalid_1's rmse: 0.0808091\n",
      "[1575]\ttraining's rmse: 0.0775539\tvalid_1's rmse: 0.080808\n",
      "[1600]\ttraining's rmse: 0.0775466\tvalid_1's rmse: 0.0808077\n",
      "[1625]\ttraining's rmse: 0.0775404\tvalid_1's rmse: 0.0808068\n",
      "[1650]\ttraining's rmse: 0.077534\tvalid_1's rmse: 0.0808061\n",
      "[1675]\ttraining's rmse: 0.0775294\tvalid_1's rmse: 0.0808049\n",
      "[1700]\ttraining's rmse: 0.0775239\tvalid_1's rmse: 0.0808036\n",
      "[1725]\ttraining's rmse: 0.0775186\tvalid_1's rmse: 0.0808028\n",
      "[1750]\ttraining's rmse: 0.0775108\tvalid_1's rmse: 0.0808019\n",
      "[1775]\ttraining's rmse: 0.0775049\tvalid_1's rmse: 0.0808014\n",
      "[1800]\ttraining's rmse: 0.077499\tvalid_1's rmse: 0.0808006\n",
      "[1825]\ttraining's rmse: 0.0774936\tvalid_1's rmse: 0.0808001\n",
      "[1850]\ttraining's rmse: 0.0774887\tvalid_1's rmse: 0.0807991\n",
      "[1875]\ttraining's rmse: 0.0774839\tvalid_1's rmse: 0.0807987\n",
      "[1900]\ttraining's rmse: 0.077479\tvalid_1's rmse: 0.0807985\n",
      "[1925]\ttraining's rmse: 0.0774754\tvalid_1's rmse: 0.0807983\n",
      "[1950]\ttraining's rmse: 0.0774711\tvalid_1's rmse: 0.0807973\n",
      "[1975]\ttraining's rmse: 0.077467\tvalid_1's rmse: 0.0807969\n",
      "[2000]\ttraining's rmse: 0.0774626\tvalid_1's rmse: 0.0807963\n",
      "[2025]\ttraining's rmse: 0.0774597\tvalid_1's rmse: 0.0807959\n",
      "[2050]\ttraining's rmse: 0.0774552\tvalid_1's rmse: 0.0807956\n",
      "[2075]\ttraining's rmse: 0.0774529\tvalid_1's rmse: 0.0807953\n",
      "[2100]\ttraining's rmse: 0.0774503\tvalid_1's rmse: 0.080795\n",
      "[2125]\ttraining's rmse: 0.0774484\tvalid_1's rmse: 0.0807944\n",
      "[2150]\ttraining's rmse: 0.0774454\tvalid_1's rmse: 0.0807947\n",
      "[2175]\ttraining's rmse: 0.077444\tvalid_1's rmse: 0.0807947\n",
      "Early stopping, best iteration is:\n",
      "[2125]\ttraining's rmse: 0.0774484\tvalid_1's rmse: 0.0807944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.081735\tvalid_1's rmse: 0.0778144\n",
      "[50]\ttraining's rmse: 0.0816308\tvalid_1's rmse: 0.0777679\n",
      "[75]\ttraining's rmse: 0.0815213\tvalid_1's rmse: 0.0777207\n",
      "[100]\ttraining's rmse: 0.0814283\tvalid_1's rmse: 0.0776802\n",
      "[125]\ttraining's rmse: 0.0813304\tvalid_1's rmse: 0.0776406\n",
      "[150]\ttraining's rmse: 0.0812378\tvalid_1's rmse: 0.0776051\n",
      "[175]\ttraining's rmse: 0.0811629\tvalid_1's rmse: 0.0775748\n",
      "[200]\ttraining's rmse: 0.081081\tvalid_1's rmse: 0.0775456\n",
      "[225]\ttraining's rmse: 0.0810013\tvalid_1's rmse: 0.0775155\n",
      "[250]\ttraining's rmse: 0.0809348\tvalid_1's rmse: 0.0774913\n",
      "[275]\ttraining's rmse: 0.0808741\tvalid_1's rmse: 0.0774666\n",
      "[300]\ttraining's rmse: 0.080813\tvalid_1's rmse: 0.0774447\n",
      "[325]\ttraining's rmse: 0.0807507\tvalid_1's rmse: 0.0774219\n",
      "[350]\ttraining's rmse: 0.0806888\tvalid_1's rmse: 0.0774019\n",
      "[375]\ttraining's rmse: 0.0806399\tvalid_1's rmse: 0.0773841\n",
      "[400]\ttraining's rmse: 0.0805859\tvalid_1's rmse: 0.0773679\n",
      "[425]\ttraining's rmse: 0.0805361\tvalid_1's rmse: 0.0773567\n",
      "[450]\ttraining's rmse: 0.0804912\tvalid_1's rmse: 0.0773419\n",
      "[475]\ttraining's rmse: 0.0804498\tvalid_1's rmse: 0.0773344\n",
      "[500]\ttraining's rmse: 0.0804143\tvalid_1's rmse: 0.0773216\n",
      "[525]\ttraining's rmse: 0.0803684\tvalid_1's rmse: 0.0773158\n",
      "[550]\ttraining's rmse: 0.0803254\tvalid_1's rmse: 0.0773036\n",
      "[575]\ttraining's rmse: 0.0802861\tvalid_1's rmse: 0.077293\n",
      "[600]\ttraining's rmse: 0.0802473\tvalid_1's rmse: 0.07729\n",
      "[625]\ttraining's rmse: 0.0802171\tvalid_1's rmse: 0.077281\n",
      "[650]\ttraining's rmse: 0.0801796\tvalid_1's rmse: 0.0772818\n",
      "[675]\ttraining's rmse: 0.08014\tvalid_1's rmse: 0.0772889\n",
      "Early stopping, best iteration is:\n",
      "[643]\ttraining's rmse: 0.0801912\tvalid_1's rmse: 0.0772787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0828799\tvalid_1's rmse: 0.0849762\n",
      "[50]\ttraining's rmse: 0.0827524\tvalid_1's rmse: 0.0849271\n",
      "[75]\ttraining's rmse: 0.0826255\tvalid_1's rmse: 0.084877\n",
      "[100]\ttraining's rmse: 0.0825054\tvalid_1's rmse: 0.0848341\n",
      "[125]\ttraining's rmse: 0.0823865\tvalid_1's rmse: 0.084791\n",
      "[150]\ttraining's rmse: 0.0822792\tvalid_1's rmse: 0.0847506\n",
      "[175]\ttraining's rmse: 0.0821936\tvalid_1's rmse: 0.0847175\n",
      "[200]\ttraining's rmse: 0.0820945\tvalid_1's rmse: 0.0846838\n",
      "[225]\ttraining's rmse: 0.0819977\tvalid_1's rmse: 0.084652\n",
      "[250]\ttraining's rmse: 0.0819189\tvalid_1's rmse: 0.0846232\n",
      "[275]\ttraining's rmse: 0.081842\tvalid_1's rmse: 0.0845964\n",
      "[300]\ttraining's rmse: 0.0817691\tvalid_1's rmse: 0.0845729\n",
      "[325]\ttraining's rmse: 0.0816951\tvalid_1's rmse: 0.0845476\n",
      "[350]\ttraining's rmse: 0.0816237\tvalid_1's rmse: 0.0845262\n",
      "[375]\ttraining's rmse: 0.0815643\tvalid_1's rmse: 0.0845077\n",
      "[400]\ttraining's rmse: 0.0814963\tvalid_1's rmse: 0.0844875\n",
      "[425]\ttraining's rmse: 0.0814357\tvalid_1's rmse: 0.084469\n",
      "[450]\ttraining's rmse: 0.0813843\tvalid_1's rmse: 0.0844518\n",
      "[475]\ttraining's rmse: 0.0813354\tvalid_1's rmse: 0.0844353\n",
      "[500]\ttraining's rmse: 0.0812941\tvalid_1's rmse: 0.0844204\n",
      "[525]\ttraining's rmse: 0.08124\tvalid_1's rmse: 0.0844055\n",
      "[550]\ttraining's rmse: 0.0811923\tvalid_1's rmse: 0.08439\n",
      "[575]\ttraining's rmse: 0.0811437\tvalid_1's rmse: 0.084376\n",
      "[600]\ttraining's rmse: 0.081098\tvalid_1's rmse: 0.084364\n",
      "[625]\ttraining's rmse: 0.0810628\tvalid_1's rmse: 0.0843526\n",
      "[650]\ttraining's rmse: 0.0810211\tvalid_1's rmse: 0.0843417\n",
      "[675]\ttraining's rmse: 0.0809796\tvalid_1's rmse: 0.0843312\n",
      "[700]\ttraining's rmse: 0.0809433\tvalid_1's rmse: 0.0843205\n",
      "[725]\ttraining's rmse: 0.0809075\tvalid_1's rmse: 0.0843106\n",
      "[750]\ttraining's rmse: 0.0808751\tvalid_1's rmse: 0.0843019\n",
      "[775]\ttraining's rmse: 0.0808475\tvalid_1's rmse: 0.0842937\n",
      "[800]\ttraining's rmse: 0.0808115\tvalid_1's rmse: 0.084285\n",
      "[825]\ttraining's rmse: 0.0807817\tvalid_1's rmse: 0.0842783\n",
      "[850]\ttraining's rmse: 0.0807495\tvalid_1's rmse: 0.0842712\n",
      "[875]\ttraining's rmse: 0.0807234\tvalid_1's rmse: 0.0842643\n",
      "[900]\ttraining's rmse: 0.0806955\tvalid_1's rmse: 0.0842578\n",
      "[925]\ttraining's rmse: 0.0806692\tvalid_1's rmse: 0.0842521\n",
      "[950]\ttraining's rmse: 0.0806463\tvalid_1's rmse: 0.0842452\n",
      "[975]\ttraining's rmse: 0.0806255\tvalid_1's rmse: 0.0842396\n",
      "[1000]\ttraining's rmse: 0.0806042\tvalid_1's rmse: 0.0842345\n",
      "[1025]\ttraining's rmse: 0.0805805\tvalid_1's rmse: 0.0842285\n",
      "[1050]\ttraining's rmse: 0.0805587\tvalid_1's rmse: 0.0842242\n",
      "[1075]\ttraining's rmse: 0.0805369\tvalid_1's rmse: 0.0842204\n",
      "[1100]\ttraining's rmse: 0.0805184\tvalid_1's rmse: 0.084217\n",
      "[1125]\ttraining's rmse: 0.0804999\tvalid_1's rmse: 0.0842112\n",
      "[1150]\ttraining's rmse: 0.0804793\tvalid_1's rmse: 0.0842076\n",
      "[1175]\ttraining's rmse: 0.0804625\tvalid_1's rmse: 0.0842047\n",
      "[1200]\ttraining's rmse: 0.0804459\tvalid_1's rmse: 0.0842006\n",
      "[1225]\ttraining's rmse: 0.0804292\tvalid_1's rmse: 0.0841966\n",
      "[1250]\ttraining's rmse: 0.080415\tvalid_1's rmse: 0.0841929\n",
      "[1275]\ttraining's rmse: 0.0803984\tvalid_1's rmse: 0.0841896\n",
      "[1300]\ttraining's rmse: 0.0803854\tvalid_1's rmse: 0.0841848\n",
      "[1325]\ttraining's rmse: 0.0803706\tvalid_1's rmse: 0.084181\n",
      "[1350]\ttraining's rmse: 0.0803559\tvalid_1's rmse: 0.0841775\n",
      "[1375]\ttraining's rmse: 0.0803425\tvalid_1's rmse: 0.084175\n",
      "[1400]\ttraining's rmse: 0.0803288\tvalid_1's rmse: 0.084172\n",
      "[1425]\ttraining's rmse: 0.080316\tvalid_1's rmse: 0.08417\n",
      "[1450]\ttraining's rmse: 0.0803033\tvalid_1's rmse: 0.0841666\n",
      "[1475]\ttraining's rmse: 0.0802931\tvalid_1's rmse: 0.0841636\n",
      "[1500]\ttraining's rmse: 0.0802839\tvalid_1's rmse: 0.0841612\n",
      "[1525]\ttraining's rmse: 0.080275\tvalid_1's rmse: 0.0841595\n",
      "[1550]\ttraining's rmse: 0.0802651\tvalid_1's rmse: 0.0841576\n",
      "[1575]\ttraining's rmse: 0.0802565\tvalid_1's rmse: 0.0841556\n",
      "[1600]\ttraining's rmse: 0.0802503\tvalid_1's rmse: 0.0841536\n",
      "[1625]\ttraining's rmse: 0.0802429\tvalid_1's rmse: 0.0841517\n",
      "[1650]\ttraining's rmse: 0.080234\tvalid_1's rmse: 0.0841493\n",
      "[1675]\ttraining's rmse: 0.0802289\tvalid_1's rmse: 0.0841479\n",
      "[1700]\ttraining's rmse: 0.0802233\tvalid_1's rmse: 0.0841458\n",
      "[1725]\ttraining's rmse: 0.0802169\tvalid_1's rmse: 0.0841436\n",
      "[1750]\ttraining's rmse: 0.0802115\tvalid_1's rmse: 0.0841416\n",
      "[1775]\ttraining's rmse: 0.080206\tvalid_1's rmse: 0.08414\n",
      "[1800]\ttraining's rmse: 0.0801991\tvalid_1's rmse: 0.084139\n",
      "[1825]\ttraining's rmse: 0.0801935\tvalid_1's rmse: 0.0841359\n",
      "[1850]\ttraining's rmse: 0.0801884\tvalid_1's rmse: 0.0841347\n",
      "[1875]\ttraining's rmse: 0.0801829\tvalid_1's rmse: 0.0841337\n",
      "[1900]\ttraining's rmse: 0.080177\tvalid_1's rmse: 0.0841324\n",
      "[1925]\ttraining's rmse: 0.0801745\tvalid_1's rmse: 0.0841309\n",
      "[1950]\ttraining's rmse: 0.080172\tvalid_1's rmse: 0.0841304\n",
      "[1975]\ttraining's rmse: 0.080168\tvalid_1's rmse: 0.084129\n",
      "[2000]\ttraining's rmse: 0.0801647\tvalid_1's rmse: 0.0841291\n",
      "[2025]\ttraining's rmse: 0.0801616\tvalid_1's rmse: 0.0841283\n",
      "[2050]\ttraining's rmse: 0.0801574\tvalid_1's rmse: 0.084126\n",
      "[2075]\ttraining's rmse: 0.0801541\tvalid_1's rmse: 0.0841248\n",
      "[2100]\ttraining's rmse: 0.0801513\tvalid_1's rmse: 0.0841242\n",
      "[2125]\ttraining's rmse: 0.0801481\tvalid_1's rmse: 0.0841234\n",
      "[2150]\ttraining's rmse: 0.0801454\tvalid_1's rmse: 0.0841227\n",
      "[2175]\ttraining's rmse: 0.0801429\tvalid_1's rmse: 0.0841214\n",
      "[2200]\ttraining's rmse: 0.0801409\tvalid_1's rmse: 0.0841209\n",
      "[2225]\ttraining's rmse: 0.0801386\tvalid_1's rmse: 0.0841202\n",
      "[2250]\ttraining's rmse: 0.0801364\tvalid_1's rmse: 0.084119\n",
      "[2275]\ttraining's rmse: 0.080133\tvalid_1's rmse: 0.0841186\n",
      "[2300]\ttraining's rmse: 0.0801309\tvalid_1's rmse: 0.0841178\n",
      "[2325]\ttraining's rmse: 0.0801274\tvalid_1's rmse: 0.0841166\n",
      "[2350]\ttraining's rmse: 0.0801244\tvalid_1's rmse: 0.0841152\n",
      "[2375]\ttraining's rmse: 0.080122\tvalid_1's rmse: 0.0841146\n",
      "[2400]\ttraining's rmse: 0.0801194\tvalid_1's rmse: 0.0841143\n",
      "[2425]\ttraining's rmse: 0.0801159\tvalid_1's rmse: 0.084113\n",
      "[2450]\ttraining's rmse: 0.080114\tvalid_1's rmse: 0.0841127\n",
      "[2475]\ttraining's rmse: 0.0801121\tvalid_1's rmse: 0.0841123\n",
      "[2500]\ttraining's rmse: 0.0801108\tvalid_1's rmse: 0.084112\n",
      "[2525]\ttraining's rmse: 0.0801085\tvalid_1's rmse: 0.0841114\n",
      "[2550]\ttraining's rmse: 0.0801069\tvalid_1's rmse: 0.0841109\n",
      "[2575]\ttraining's rmse: 0.0801048\tvalid_1's rmse: 0.0841102\n",
      "[2600]\ttraining's rmse: 0.0801028\tvalid_1's rmse: 0.0841104\n",
      "[2625]\ttraining's rmse: 0.0801018\tvalid_1's rmse: 0.0841097\n",
      "[2650]\ttraining's rmse: 0.0801004\tvalid_1's rmse: 0.0841088\n",
      "[2675]\ttraining's rmse: 0.0800991\tvalid_1's rmse: 0.0841083\n",
      "[2700]\ttraining's rmse: 0.0800982\tvalid_1's rmse: 0.0841082\n",
      "[2725]\ttraining's rmse: 0.0800968\tvalid_1's rmse: 0.0841083\n",
      "[2750]\ttraining's rmse: 0.0800952\tvalid_1's rmse: 0.0841085\n",
      "Early stopping, best iteration is:\n",
      "[2709]\ttraining's rmse: 0.0800978\tvalid_1's rmse: 0.0841082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0828964\tvalid_1's rmse: 0.0849611\n",
      "[50]\ttraining's rmse: 0.0827807\tvalid_1's rmse: 0.0849089\n",
      "[75]\ttraining's rmse: 0.0826624\tvalid_1's rmse: 0.0848572\n",
      "[100]\ttraining's rmse: 0.0825561\tvalid_1's rmse: 0.0848128\n",
      "[125]\ttraining's rmse: 0.0824457\tvalid_1's rmse: 0.0847669\n",
      "[150]\ttraining's rmse: 0.0823449\tvalid_1's rmse: 0.084725\n",
      "[175]\ttraining's rmse: 0.0822616\tvalid_1's rmse: 0.0846903\n",
      "[200]\ttraining's rmse: 0.0821709\tvalid_1's rmse: 0.084655\n",
      "[225]\ttraining's rmse: 0.0820799\tvalid_1's rmse: 0.084622\n",
      "[250]\ttraining's rmse: 0.0820035\tvalid_1's rmse: 0.0845925\n",
      "[275]\ttraining's rmse: 0.0819338\tvalid_1's rmse: 0.0845652\n",
      "[300]\ttraining's rmse: 0.0818628\tvalid_1's rmse: 0.0845386\n",
      "[325]\ttraining's rmse: 0.081791\tvalid_1's rmse: 0.0845126\n",
      "[350]\ttraining's rmse: 0.0817244\tvalid_1's rmse: 0.08449\n",
      "[375]\ttraining's rmse: 0.0816689\tvalid_1's rmse: 0.0844694\n",
      "[400]\ttraining's rmse: 0.081608\tvalid_1's rmse: 0.0844499\n",
      "[425]\ttraining's rmse: 0.0815541\tvalid_1's rmse: 0.0844314\n",
      "[450]\ttraining's rmse: 0.0815029\tvalid_1's rmse: 0.0844131\n",
      "[475]\ttraining's rmse: 0.0814565\tvalid_1's rmse: 0.0843968\n",
      "[500]\ttraining's rmse: 0.0814173\tvalid_1's rmse: 0.0843794\n",
      "[525]\ttraining's rmse: 0.0813638\tvalid_1's rmse: 0.0843638\n",
      "[550]\ttraining's rmse: 0.0813156\tvalid_1's rmse: 0.0843502\n",
      "[575]\ttraining's rmse: 0.0812719\tvalid_1's rmse: 0.0843379\n",
      "[600]\ttraining's rmse: 0.0812293\tvalid_1's rmse: 0.0843247\n",
      "[625]\ttraining's rmse: 0.0811958\tvalid_1's rmse: 0.0843133\n",
      "[650]\ttraining's rmse: 0.0811548\tvalid_1's rmse: 0.0843005\n",
      "[675]\ttraining's rmse: 0.0811141\tvalid_1's rmse: 0.0842896\n",
      "[700]\ttraining's rmse: 0.0810766\tvalid_1's rmse: 0.0842786\n",
      "[725]\ttraining's rmse: 0.0810439\tvalid_1's rmse: 0.0842698\n",
      "[750]\ttraining's rmse: 0.0810121\tvalid_1's rmse: 0.08426\n",
      "[775]\ttraining's rmse: 0.0809852\tvalid_1's rmse: 0.0842508\n",
      "[800]\ttraining's rmse: 0.0809511\tvalid_1's rmse: 0.0842426\n",
      "[825]\ttraining's rmse: 0.0809244\tvalid_1's rmse: 0.0842342\n",
      "[850]\ttraining's rmse: 0.0808959\tvalid_1's rmse: 0.0842274\n",
      "[875]\ttraining's rmse: 0.0808718\tvalid_1's rmse: 0.0842202\n",
      "[900]\ttraining's rmse: 0.0808433\tvalid_1's rmse: 0.0842133\n",
      "[925]\ttraining's rmse: 0.0808169\tvalid_1's rmse: 0.0842068\n",
      "[950]\ttraining's rmse: 0.0807927\tvalid_1's rmse: 0.0842008\n",
      "[975]\ttraining's rmse: 0.0807713\tvalid_1's rmse: 0.0841959\n",
      "[1000]\ttraining's rmse: 0.0807509\tvalid_1's rmse: 0.0841904\n",
      "[1025]\ttraining's rmse: 0.0807283\tvalid_1's rmse: 0.0841864\n",
      "[1050]\ttraining's rmse: 0.0807086\tvalid_1's rmse: 0.0841811\n",
      "[1075]\ttraining's rmse: 0.0806893\tvalid_1's rmse: 0.0841774\n",
      "[1100]\ttraining's rmse: 0.0806726\tvalid_1's rmse: 0.0841729\n",
      "[1125]\ttraining's rmse: 0.0806537\tvalid_1's rmse: 0.084168\n",
      "[1150]\ttraining's rmse: 0.080636\tvalid_1's rmse: 0.084164\n",
      "[1175]\ttraining's rmse: 0.0806213\tvalid_1's rmse: 0.0841609\n",
      "[1200]\ttraining's rmse: 0.0806031\tvalid_1's rmse: 0.0841576\n",
      "[1225]\ttraining's rmse: 0.0805872\tvalid_1's rmse: 0.0841551\n",
      "[1250]\ttraining's rmse: 0.0805728\tvalid_1's rmse: 0.084152\n",
      "[1275]\ttraining's rmse: 0.0805564\tvalid_1's rmse: 0.0841501\n",
      "[1300]\ttraining's rmse: 0.0805445\tvalid_1's rmse: 0.0841468\n",
      "[1325]\ttraining's rmse: 0.080531\tvalid_1's rmse: 0.0841451\n",
      "[1350]\ttraining's rmse: 0.0805179\tvalid_1's rmse: 0.0841427\n",
      "[1375]\ttraining's rmse: 0.0805065\tvalid_1's rmse: 0.0841406\n",
      "[1400]\ttraining's rmse: 0.0804959\tvalid_1's rmse: 0.084138\n",
      "[1425]\ttraining's rmse: 0.0804853\tvalid_1's rmse: 0.0841371\n",
      "[1450]\ttraining's rmse: 0.0804739\tvalid_1's rmse: 0.0841361\n",
      "[1475]\ttraining's rmse: 0.0804631\tvalid_1's rmse: 0.0841348\n",
      "[1500]\ttraining's rmse: 0.0804551\tvalid_1's rmse: 0.0841334\n",
      "[1525]\ttraining's rmse: 0.0804457\tvalid_1's rmse: 0.0841319\n",
      "[1550]\ttraining's rmse: 0.0804358\tvalid_1's rmse: 0.084131\n",
      "[1575]\ttraining's rmse: 0.0804282\tvalid_1's rmse: 0.0841299\n",
      "[1600]\ttraining's rmse: 0.0804229\tvalid_1's rmse: 0.0841289\n",
      "[1625]\ttraining's rmse: 0.0804159\tvalid_1's rmse: 0.0841279\n",
      "[1650]\ttraining's rmse: 0.0804095\tvalid_1's rmse: 0.0841271\n",
      "[1675]\ttraining's rmse: 0.0804048\tvalid_1's rmse: 0.0841258\n",
      "[1700]\ttraining's rmse: 0.080399\tvalid_1's rmse: 0.0841242\n",
      "[1725]\ttraining's rmse: 0.0803925\tvalid_1's rmse: 0.084123\n",
      "[1750]\ttraining's rmse: 0.0803866\tvalid_1's rmse: 0.0841222\n",
      "[1775]\ttraining's rmse: 0.0803802\tvalid_1's rmse: 0.0841214\n",
      "[1800]\ttraining's rmse: 0.0803755\tvalid_1's rmse: 0.0841207\n",
      "[1825]\ttraining's rmse: 0.0803689\tvalid_1's rmse: 0.08412\n",
      "[1850]\ttraining's rmse: 0.0803627\tvalid_1's rmse: 0.0841194\n",
      "[1875]\ttraining's rmse: 0.0803581\tvalid_1's rmse: 0.0841189\n",
      "[1900]\ttraining's rmse: 0.0803537\tvalid_1's rmse: 0.0841189\n",
      "[1925]\ttraining's rmse: 0.0803484\tvalid_1's rmse: 0.0841186\n",
      "[1950]\ttraining's rmse: 0.0803444\tvalid_1's rmse: 0.0841178\n",
      "[1975]\ttraining's rmse: 0.0803408\tvalid_1's rmse: 0.0841172\n",
      "[2000]\ttraining's rmse: 0.0803364\tvalid_1's rmse: 0.0841164\n",
      "[2025]\ttraining's rmse: 0.0803323\tvalid_1's rmse: 0.0841161\n",
      "[2050]\ttraining's rmse: 0.0803289\tvalid_1's rmse: 0.0841156\n",
      "[2075]\ttraining's rmse: 0.0803265\tvalid_1's rmse: 0.0841151\n",
      "[2100]\ttraining's rmse: 0.0803227\tvalid_1's rmse: 0.0841152\n",
      "[2125]\ttraining's rmse: 0.080318\tvalid_1's rmse: 0.0841146\n",
      "[2150]\ttraining's rmse: 0.0803132\tvalid_1's rmse: 0.084114\n",
      "[2175]\ttraining's rmse: 0.0803109\tvalid_1's rmse: 0.0841136\n",
      "[2200]\ttraining's rmse: 0.0803072\tvalid_1's rmse: 0.084113\n",
      "[2225]\ttraining's rmse: 0.0803051\tvalid_1's rmse: 0.0841127\n",
      "[2250]\ttraining's rmse: 0.0803024\tvalid_1's rmse: 0.0841126\n",
      "[2275]\ttraining's rmse: 0.0802994\tvalid_1's rmse: 0.0841122\n",
      "[2300]\ttraining's rmse: 0.0802966\tvalid_1's rmse: 0.0841122\n",
      "[2325]\ttraining's rmse: 0.0802934\tvalid_1's rmse: 0.0841121\n",
      "[2350]\ttraining's rmse: 0.0802899\tvalid_1's rmse: 0.0841116\n",
      "[2375]\ttraining's rmse: 0.080287\tvalid_1's rmse: 0.0841112\n",
      "[2400]\ttraining's rmse: 0.0802847\tvalid_1's rmse: 0.0841109\n",
      "[2425]\ttraining's rmse: 0.0802819\tvalid_1's rmse: 0.084111\n",
      "[2450]\ttraining's rmse: 0.0802803\tvalid_1's rmse: 0.0841108\n",
      "Early stopping, best iteration is:\n",
      "[2420]\ttraining's rmse: 0.0802828\tvalid_1's rmse: 0.0841107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0848484\tvalid_1's rmse: 0.0809994\n",
      "[50]\ttraining's rmse: 0.0847395\tvalid_1's rmse: 0.0809508\n",
      "[75]\ttraining's rmse: 0.0846269\tvalid_1's rmse: 0.0809032\n",
      "[100]\ttraining's rmse: 0.0845262\tvalid_1's rmse: 0.0808618\n",
      "[125]\ttraining's rmse: 0.0844226\tvalid_1's rmse: 0.0808201\n",
      "[150]\ttraining's rmse: 0.0843265\tvalid_1's rmse: 0.0807828\n",
      "[175]\ttraining's rmse: 0.0842463\tvalid_1's rmse: 0.08075\n",
      "[200]\ttraining's rmse: 0.0841593\tvalid_1's rmse: 0.0807186\n",
      "[225]\ttraining's rmse: 0.0840749\tvalid_1's rmse: 0.0806874\n",
      "[250]\ttraining's rmse: 0.084003\tvalid_1's rmse: 0.0806612\n",
      "[275]\ttraining's rmse: 0.0839373\tvalid_1's rmse: 0.0806355\n",
      "[300]\ttraining's rmse: 0.0838726\tvalid_1's rmse: 0.0806128\n",
      "[325]\ttraining's rmse: 0.0838063\tvalid_1's rmse: 0.0805913\n",
      "[350]\ttraining's rmse: 0.0837423\tvalid_1's rmse: 0.0805698\n",
      "[375]\ttraining's rmse: 0.0836902\tvalid_1's rmse: 0.0805509\n",
      "[400]\ttraining's rmse: 0.0836336\tvalid_1's rmse: 0.0805379\n",
      "[425]\ttraining's rmse: 0.0835805\tvalid_1's rmse: 0.0805209\n",
      "[450]\ttraining's rmse: 0.0835309\tvalid_1's rmse: 0.0805069\n",
      "[475]\ttraining's rmse: 0.0834859\tvalid_1's rmse: 0.0804931\n",
      "[500]\ttraining's rmse: 0.0834476\tvalid_1's rmse: 0.0804798\n",
      "[525]\ttraining's rmse: 0.083396\tvalid_1's rmse: 0.0804683\n",
      "[550]\ttraining's rmse: 0.0833505\tvalid_1's rmse: 0.0804554\n",
      "[575]\ttraining's rmse: 0.0833071\tvalid_1's rmse: 0.0804471\n",
      "[600]\ttraining's rmse: 0.0832645\tvalid_1's rmse: 0.0804374\n",
      "[625]\ttraining's rmse: 0.083231\tvalid_1's rmse: 0.0804277\n",
      "[650]\ttraining's rmse: 0.0831896\tvalid_1's rmse: 0.0804182\n",
      "[675]\ttraining's rmse: 0.0831475\tvalid_1's rmse: 0.0804129\n",
      "[700]\ttraining's rmse: 0.0831135\tvalid_1's rmse: 0.0804073\n",
      "[725]\ttraining's rmse: 0.0830788\tvalid_1's rmse: 0.080402\n",
      "[750]\ttraining's rmse: 0.0830466\tvalid_1's rmse: 0.0804083\n",
      "[775]\ttraining's rmse: 0.0830187\tvalid_1's rmse: 0.0804025\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0830642\tvalid_1's rmse: 0.0803982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0801212\tvalid_1's rmse: 0.0826926\n",
      "[50]\ttraining's rmse: 0.0800022\tvalid_1's rmse: 0.0826404\n",
      "[75]\ttraining's rmse: 0.0798851\tvalid_1's rmse: 0.0825892\n",
      "[100]\ttraining's rmse: 0.0797784\tvalid_1's rmse: 0.0825438\n",
      "[125]\ttraining's rmse: 0.0796712\tvalid_1's rmse: 0.0824976\n",
      "[150]\ttraining's rmse: 0.0795731\tvalid_1's rmse: 0.0824561\n",
      "[175]\ttraining's rmse: 0.079494\tvalid_1's rmse: 0.0824209\n",
      "[200]\ttraining's rmse: 0.0794089\tvalid_1's rmse: 0.0823859\n",
      "[225]\ttraining's rmse: 0.0793232\tvalid_1's rmse: 0.0823508\n",
      "[250]\ttraining's rmse: 0.0792541\tvalid_1's rmse: 0.0823208\n",
      "[275]\ttraining's rmse: 0.0791871\tvalid_1's rmse: 0.0822918\n",
      "[300]\ttraining's rmse: 0.079122\tvalid_1's rmse: 0.0822639\n",
      "[325]\ttraining's rmse: 0.0790556\tvalid_1's rmse: 0.0822356\n",
      "[350]\ttraining's rmse: 0.0789944\tvalid_1's rmse: 0.082211\n",
      "[375]\ttraining's rmse: 0.0789429\tvalid_1's rmse: 0.0821902\n",
      "[400]\ttraining's rmse: 0.0788884\tvalid_1's rmse: 0.0821692\n",
      "[425]\ttraining's rmse: 0.0788353\tvalid_1's rmse: 0.0821494\n",
      "[450]\ttraining's rmse: 0.0787878\tvalid_1's rmse: 0.0821308\n",
      "[475]\ttraining's rmse: 0.0787442\tvalid_1's rmse: 0.0821132\n",
      "[500]\ttraining's rmse: 0.0787076\tvalid_1's rmse: 0.0820952\n",
      "[525]\ttraining's rmse: 0.078661\tvalid_1's rmse: 0.0820792\n",
      "[550]\ttraining's rmse: 0.0786158\tvalid_1's rmse: 0.0820641\n",
      "[575]\ttraining's rmse: 0.0785738\tvalid_1's rmse: 0.08205\n",
      "[600]\ttraining's rmse: 0.0785346\tvalid_1's rmse: 0.0820344\n",
      "[625]\ttraining's rmse: 0.0785022\tvalid_1's rmse: 0.0820225\n",
      "[650]\ttraining's rmse: 0.0784649\tvalid_1's rmse: 0.0820103\n",
      "[675]\ttraining's rmse: 0.0784281\tvalid_1's rmse: 0.081997\n",
      "[700]\ttraining's rmse: 0.0783945\tvalid_1's rmse: 0.0819859\n",
      "[725]\ttraining's rmse: 0.0783647\tvalid_1's rmse: 0.0819755\n",
      "[750]\ttraining's rmse: 0.0783342\tvalid_1's rmse: 0.0819646\n",
      "[775]\ttraining's rmse: 0.0783108\tvalid_1's rmse: 0.0819553\n",
      "[800]\ttraining's rmse: 0.0782815\tvalid_1's rmse: 0.0819471\n",
      "[825]\ttraining's rmse: 0.0782558\tvalid_1's rmse: 0.0819382\n",
      "[850]\ttraining's rmse: 0.0782277\tvalid_1's rmse: 0.0819301\n",
      "[875]\ttraining's rmse: 0.0782038\tvalid_1's rmse: 0.0819217\n",
      "[900]\ttraining's rmse: 0.0781773\tvalid_1's rmse: 0.081915\n",
      "[925]\ttraining's rmse: 0.0781553\tvalid_1's rmse: 0.081909\n",
      "[950]\ttraining's rmse: 0.0781342\tvalid_1's rmse: 0.081902\n",
      "[975]\ttraining's rmse: 0.0781127\tvalid_1's rmse: 0.0818959\n",
      "[1000]\ttraining's rmse: 0.0780926\tvalid_1's rmse: 0.0818902\n",
      "[1025]\ttraining's rmse: 0.0780709\tvalid_1's rmse: 0.081884\n",
      "[1050]\ttraining's rmse: 0.0780522\tvalid_1's rmse: 0.0818767\n",
      "[1075]\ttraining's rmse: 0.0780347\tvalid_1's rmse: 0.0818721\n",
      "[1100]\ttraining's rmse: 0.0780194\tvalid_1's rmse: 0.0818676\n",
      "[1125]\ttraining's rmse: 0.0780051\tvalid_1's rmse: 0.0818625\n",
      "[1150]\ttraining's rmse: 0.077988\tvalid_1's rmse: 0.0818584\n",
      "[1175]\ttraining's rmse: 0.0779728\tvalid_1's rmse: 0.0818552\n",
      "[1200]\ttraining's rmse: 0.0779569\tvalid_1's rmse: 0.0818512\n",
      "[1225]\ttraining's rmse: 0.0779414\tvalid_1's rmse: 0.0818457\n",
      "[1250]\ttraining's rmse: 0.0779283\tvalid_1's rmse: 0.0818418\n",
      "[1275]\ttraining's rmse: 0.0779138\tvalid_1's rmse: 0.081837\n",
      "[1300]\ttraining's rmse: 0.0779032\tvalid_1's rmse: 0.0818326\n",
      "[1325]\ttraining's rmse: 0.0778909\tvalid_1's rmse: 0.0818302\n",
      "[1350]\ttraining's rmse: 0.0778792\tvalid_1's rmse: 0.0818285\n",
      "[1375]\ttraining's rmse: 0.0778693\tvalid_1's rmse: 0.0818255\n",
      "[1400]\ttraining's rmse: 0.0778602\tvalid_1's rmse: 0.0818224\n",
      "[1425]\ttraining's rmse: 0.0778487\tvalid_1's rmse: 0.08182\n",
      "[1450]\ttraining's rmse: 0.07784\tvalid_1's rmse: 0.0818168\n",
      "[1475]\ttraining's rmse: 0.0778304\tvalid_1's rmse: 0.0818142\n",
      "[1500]\ttraining's rmse: 0.0778223\tvalid_1's rmse: 0.0818107\n",
      "[1525]\ttraining's rmse: 0.0778139\tvalid_1's rmse: 0.0818071\n",
      "[1550]\ttraining's rmse: 0.0778031\tvalid_1's rmse: 0.0818052\n",
      "[1575]\ttraining's rmse: 0.0777962\tvalid_1's rmse: 0.0818026\n",
      "[1600]\ttraining's rmse: 0.0777901\tvalid_1's rmse: 0.0818004\n",
      "[1625]\ttraining's rmse: 0.0777844\tvalid_1's rmse: 0.0817975\n",
      "[1650]\ttraining's rmse: 0.0777789\tvalid_1's rmse: 0.0817944\n",
      "[1675]\ttraining's rmse: 0.0777735\tvalid_1's rmse: 0.0817915\n",
      "[1700]\ttraining's rmse: 0.0777683\tvalid_1's rmse: 0.0817893\n",
      "[1725]\ttraining's rmse: 0.0777621\tvalid_1's rmse: 0.081787\n",
      "[1750]\ttraining's rmse: 0.0777568\tvalid_1's rmse: 0.0817862\n",
      "[1775]\ttraining's rmse: 0.0777518\tvalid_1's rmse: 0.0817837\n",
      "[1800]\ttraining's rmse: 0.0777472\tvalid_1's rmse: 0.081783\n",
      "[1825]\ttraining's rmse: 0.0777414\tvalid_1's rmse: 0.0817819\n",
      "[1850]\ttraining's rmse: 0.0777365\tvalid_1's rmse: 0.0817799\n",
      "[1875]\ttraining's rmse: 0.0777317\tvalid_1's rmse: 0.0817782\n",
      "[1900]\ttraining's rmse: 0.0777278\tvalid_1's rmse: 0.0817775\n",
      "[1925]\ttraining's rmse: 0.0777235\tvalid_1's rmse: 0.0817765\n",
      "[1950]\ttraining's rmse: 0.0777198\tvalid_1's rmse: 0.0817741\n",
      "[1975]\ttraining's rmse: 0.0777155\tvalid_1's rmse: 0.0817726\n",
      "[2000]\ttraining's rmse: 0.0777118\tvalid_1's rmse: 0.0817721\n",
      "[2025]\ttraining's rmse: 0.0777093\tvalid_1's rmse: 0.0817701\n",
      "[2050]\ttraining's rmse: 0.0777047\tvalid_1's rmse: 0.0817685\n",
      "[2075]\ttraining's rmse: 0.0777011\tvalid_1's rmse: 0.0817678\n",
      "[2100]\ttraining's rmse: 0.0776983\tvalid_1's rmse: 0.0817672\n",
      "[2125]\ttraining's rmse: 0.0776961\tvalid_1's rmse: 0.0817668\n",
      "[2150]\ttraining's rmse: 0.077692\tvalid_1's rmse: 0.081765\n",
      "[2175]\ttraining's rmse: 0.0776877\tvalid_1's rmse: 0.0817633\n",
      "[2200]\ttraining's rmse: 0.0776851\tvalid_1's rmse: 0.0817627\n",
      "[2225]\ttraining's rmse: 0.0776831\tvalid_1's rmse: 0.0817622\n",
      "[2250]\ttraining's rmse: 0.0776803\tvalid_1's rmse: 0.0817619\n",
      "[2275]\ttraining's rmse: 0.0776774\tvalid_1's rmse: 0.0817604\n",
      "[2300]\ttraining's rmse: 0.0776747\tvalid_1's rmse: 0.0817597\n",
      "[2325]\ttraining's rmse: 0.0776713\tvalid_1's rmse: 0.0817593\n",
      "[2350]\ttraining's rmse: 0.0776683\tvalid_1's rmse: 0.0817583\n",
      "[2375]\ttraining's rmse: 0.0776665\tvalid_1's rmse: 0.0817581\n",
      "[2400]\ttraining's rmse: 0.0776633\tvalid_1's rmse: 0.0817577\n",
      "[2425]\ttraining's rmse: 0.0776622\tvalid_1's rmse: 0.0817572\n",
      "[2450]\ttraining's rmse: 0.0776605\tvalid_1's rmse: 0.0817567\n",
      "[2475]\ttraining's rmse: 0.0776587\tvalid_1's rmse: 0.0817559\n",
      "[2500]\ttraining's rmse: 0.077657\tvalid_1's rmse: 0.0817555\n",
      "[2525]\ttraining's rmse: 0.0776541\tvalid_1's rmse: 0.081755\n",
      "[2550]\ttraining's rmse: 0.0776519\tvalid_1's rmse: 0.0817551\n",
      "[2575]\ttraining's rmse: 0.0776505\tvalid_1's rmse: 0.0817541\n",
      "[2600]\ttraining's rmse: 0.077649\tvalid_1's rmse: 0.0817541\n",
      "[2625]\ttraining's rmse: 0.077648\tvalid_1's rmse: 0.0817537\n",
      "[2650]\ttraining's rmse: 0.077646\tvalid_1's rmse: 0.0817527\n",
      "[2675]\ttraining's rmse: 0.0776446\tvalid_1's rmse: 0.0817522\n",
      "[2700]\ttraining's rmse: 0.077642\tvalid_1's rmse: 0.0817514\n",
      "[2725]\ttraining's rmse: 0.0776407\tvalid_1's rmse: 0.081751\n",
      "[2750]\ttraining's rmse: 0.0776386\tvalid_1's rmse: 0.0817504\n",
      "[2775]\ttraining's rmse: 0.0776366\tvalid_1's rmse: 0.0817505\n",
      "[2800]\ttraining's rmse: 0.0776334\tvalid_1's rmse: 0.0817504\n",
      "[2825]\ttraining's rmse: 0.0776315\tvalid_1's rmse: 0.0817504\n",
      "[2850]\ttraining's rmse: 0.0776306\tvalid_1's rmse: 0.0817504\n",
      "[2875]\ttraining's rmse: 0.0776289\tvalid_1's rmse: 0.0817502\n",
      "[2900]\ttraining's rmse: 0.0776279\tvalid_1's rmse: 0.0817501\n",
      "Early stopping, best iteration is:\n",
      "[2854]\ttraining's rmse: 0.0776305\tvalid_1's rmse: 0.08175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0803485\tvalid_1's rmse: 0.0822409\n",
      "[50]\ttraining's rmse: 0.0802367\tvalid_1's rmse: 0.0821868\n",
      "[75]\ttraining's rmse: 0.0801245\tvalid_1's rmse: 0.0821342\n",
      "[100]\ttraining's rmse: 0.0800227\tvalid_1's rmse: 0.0820869\n",
      "[125]\ttraining's rmse: 0.0799183\tvalid_1's rmse: 0.0820397\n",
      "[150]\ttraining's rmse: 0.0798231\tvalid_1's rmse: 0.0819978\n",
      "[175]\ttraining's rmse: 0.0797449\tvalid_1's rmse: 0.081963\n",
      "[200]\ttraining's rmse: 0.0796586\tvalid_1's rmse: 0.0819286\n",
      "[225]\ttraining's rmse: 0.079578\tvalid_1's rmse: 0.0818956\n",
      "[250]\ttraining's rmse: 0.0795083\tvalid_1's rmse: 0.0818653\n",
      "[275]\ttraining's rmse: 0.079442\tvalid_1's rmse: 0.081837\n",
      "[300]\ttraining's rmse: 0.0793767\tvalid_1's rmse: 0.081811\n",
      "[325]\ttraining's rmse: 0.0793082\tvalid_1's rmse: 0.0817848\n",
      "[350]\ttraining's rmse: 0.0792434\tvalid_1's rmse: 0.0817609\n",
      "[375]\ttraining's rmse: 0.0791893\tvalid_1's rmse: 0.0817407\n",
      "[400]\ttraining's rmse: 0.0791317\tvalid_1's rmse: 0.0817206\n",
      "[425]\ttraining's rmse: 0.0790768\tvalid_1's rmse: 0.0817007\n",
      "[450]\ttraining's rmse: 0.0790297\tvalid_1's rmse: 0.0816836\n",
      "[475]\ttraining's rmse: 0.0789861\tvalid_1's rmse: 0.0816674\n",
      "[500]\ttraining's rmse: 0.0789453\tvalid_1's rmse: 0.0816517\n",
      "[525]\ttraining's rmse: 0.0788953\tvalid_1's rmse: 0.0816369\n",
      "[550]\ttraining's rmse: 0.0788484\tvalid_1's rmse: 0.081622\n",
      "[575]\ttraining's rmse: 0.0788065\tvalid_1's rmse: 0.0816079\n",
      "[600]\ttraining's rmse: 0.0787667\tvalid_1's rmse: 0.0815956\n",
      "[625]\ttraining's rmse: 0.078735\tvalid_1's rmse: 0.0815839\n",
      "[650]\ttraining's rmse: 0.078696\tvalid_1's rmse: 0.0815723\n",
      "[675]\ttraining's rmse: 0.0786571\tvalid_1's rmse: 0.0815616\n",
      "[700]\ttraining's rmse: 0.0786235\tvalid_1's rmse: 0.0815519\n",
      "[725]\ttraining's rmse: 0.0785907\tvalid_1's rmse: 0.0815429\n",
      "[750]\ttraining's rmse: 0.0785601\tvalid_1's rmse: 0.0815348\n",
      "[775]\ttraining's rmse: 0.0785323\tvalid_1's rmse: 0.0815266\n",
      "[800]\ttraining's rmse: 0.0784997\tvalid_1's rmse: 0.081519\n",
      "[825]\ttraining's rmse: 0.0784727\tvalid_1's rmse: 0.0815116\n",
      "[850]\ttraining's rmse: 0.0784449\tvalid_1's rmse: 0.0815054\n",
      "[875]\ttraining's rmse: 0.078421\tvalid_1's rmse: 0.0814998\n",
      "[900]\ttraining's rmse: 0.0783946\tvalid_1's rmse: 0.0814933\n",
      "[925]\ttraining's rmse: 0.0783699\tvalid_1's rmse: 0.0814882\n",
      "[950]\ttraining's rmse: 0.0783474\tvalid_1's rmse: 0.0814832\n",
      "[975]\ttraining's rmse: 0.0783257\tvalid_1's rmse: 0.0814789\n",
      "[1000]\ttraining's rmse: 0.0783048\tvalid_1's rmse: 0.0814737\n",
      "[1025]\ttraining's rmse: 0.0782828\tvalid_1's rmse: 0.0814697\n",
      "[1050]\ttraining's rmse: 0.0782636\tvalid_1's rmse: 0.0814645\n",
      "[1075]\ttraining's rmse: 0.0782456\tvalid_1's rmse: 0.0814615\n",
      "[1100]\ttraining's rmse: 0.0782313\tvalid_1's rmse: 0.0814581\n",
      "[1125]\ttraining's rmse: 0.0782156\tvalid_1's rmse: 0.0814546\n",
      "[1150]\ttraining's rmse: 0.0781976\tvalid_1's rmse: 0.0814517\n",
      "[1175]\ttraining's rmse: 0.0781826\tvalid_1's rmse: 0.081449\n",
      "[1200]\ttraining's rmse: 0.0781672\tvalid_1's rmse: 0.0814462\n",
      "[1225]\ttraining's rmse: 0.0781534\tvalid_1's rmse: 0.0814434\n",
      "[1250]\ttraining's rmse: 0.0781391\tvalid_1's rmse: 0.0814404\n",
      "[1275]\ttraining's rmse: 0.0781238\tvalid_1's rmse: 0.0814379\n",
      "[1300]\ttraining's rmse: 0.078112\tvalid_1's rmse: 0.0814357\n",
      "[1325]\ttraining's rmse: 0.0780993\tvalid_1's rmse: 0.0814336\n",
      "[1350]\ttraining's rmse: 0.0780856\tvalid_1's rmse: 0.0814319\n",
      "[1375]\ttraining's rmse: 0.0780751\tvalid_1's rmse: 0.0814308\n",
      "[1400]\ttraining's rmse: 0.0780668\tvalid_1's rmse: 0.081429\n",
      "[1425]\ttraining's rmse: 0.0780544\tvalid_1's rmse: 0.0814276\n",
      "[1450]\ttraining's rmse: 0.0780419\tvalid_1's rmse: 0.0814261\n",
      "[1475]\ttraining's rmse: 0.0780316\tvalid_1's rmse: 0.0814247\n",
      "[1500]\ttraining's rmse: 0.0780208\tvalid_1's rmse: 0.0814236\n",
      "[1525]\ttraining's rmse: 0.0780116\tvalid_1's rmse: 0.0814219\n",
      "[1550]\ttraining's rmse: 0.0780033\tvalid_1's rmse: 0.0814206\n",
      "[1575]\ttraining's rmse: 0.0779965\tvalid_1's rmse: 0.0814193\n",
      "[1600]\ttraining's rmse: 0.0779901\tvalid_1's rmse: 0.0814186\n",
      "[1625]\ttraining's rmse: 0.0779833\tvalid_1's rmse: 0.0814174\n",
      "[1650]\ttraining's rmse: 0.0779762\tvalid_1's rmse: 0.081417\n",
      "[1675]\ttraining's rmse: 0.0779714\tvalid_1's rmse: 0.0814156\n",
      "[1700]\ttraining's rmse: 0.0779655\tvalid_1's rmse: 0.0814145\n",
      "[1725]\ttraining's rmse: 0.07796\tvalid_1's rmse: 0.0814137\n",
      "[1750]\ttraining's rmse: 0.077955\tvalid_1's rmse: 0.0814131\n",
      "[1775]\ttraining's rmse: 0.07795\tvalid_1's rmse: 0.0814126\n",
      "[1800]\ttraining's rmse: 0.0779461\tvalid_1's rmse: 0.0814124\n",
      "[1825]\ttraining's rmse: 0.0779409\tvalid_1's rmse: 0.0814117\n",
      "[1850]\ttraining's rmse: 0.077937\tvalid_1's rmse: 0.0814115\n",
      "[1875]\ttraining's rmse: 0.0779311\tvalid_1's rmse: 0.0814111\n",
      "[1900]\ttraining's rmse: 0.077928\tvalid_1's rmse: 0.0814107\n",
      "[1925]\ttraining's rmse: 0.0779238\tvalid_1's rmse: 0.0814105\n",
      "[1950]\ttraining's rmse: 0.0779204\tvalid_1's rmse: 0.0814102\n",
      "[1975]\ttraining's rmse: 0.0779163\tvalid_1's rmse: 0.0814096\n",
      "[2000]\ttraining's rmse: 0.0779121\tvalid_1's rmse: 0.0814095\n",
      "[2025]\ttraining's rmse: 0.0779083\tvalid_1's rmse: 0.081409\n",
      "[2050]\ttraining's rmse: 0.077905\tvalid_1's rmse: 0.0814086\n",
      "[2075]\ttraining's rmse: 0.0779031\tvalid_1's rmse: 0.0814086\n",
      "[2100]\ttraining's rmse: 0.0778998\tvalid_1's rmse: 0.0814084\n",
      "[2125]\ttraining's rmse: 0.0778968\tvalid_1's rmse: 0.0814085\n",
      "Early stopping, best iteration is:\n",
      "[2096]\ttraining's rmse: 0.0779004\tvalid_1's rmse: 0.0814084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0823538\tvalid_1's rmse: 0.0781639\n",
      "[50]\ttraining's rmse: 0.0822481\tvalid_1's rmse: 0.0781163\n",
      "[75]\ttraining's rmse: 0.0821389\tvalid_1's rmse: 0.0780694\n",
      "[100]\ttraining's rmse: 0.082041\tvalid_1's rmse: 0.0780273\n",
      "[125]\ttraining's rmse: 0.0819402\tvalid_1's rmse: 0.0779862\n",
      "[150]\ttraining's rmse: 0.0818472\tvalid_1's rmse: 0.0779504\n",
      "[175]\ttraining's rmse: 0.0817717\tvalid_1's rmse: 0.0779202\n",
      "[200]\ttraining's rmse: 0.081692\tvalid_1's rmse: 0.0778897\n",
      "[225]\ttraining's rmse: 0.0816159\tvalid_1's rmse: 0.0778611\n",
      "[250]\ttraining's rmse: 0.081548\tvalid_1's rmse: 0.0778364\n",
      "[275]\ttraining's rmse: 0.081486\tvalid_1's rmse: 0.0778111\n",
      "[300]\ttraining's rmse: 0.0814233\tvalid_1's rmse: 0.0777888\n",
      "[325]\ttraining's rmse: 0.0813619\tvalid_1's rmse: 0.0777672\n",
      "[350]\ttraining's rmse: 0.0812988\tvalid_1's rmse: 0.0777473\n",
      "[375]\ttraining's rmse: 0.0812493\tvalid_1's rmse: 0.0777314\n",
      "[400]\ttraining's rmse: 0.0811938\tvalid_1's rmse: 0.0777256\n",
      "[425]\ttraining's rmse: 0.0811448\tvalid_1's rmse: 0.0777181\n",
      "[450]\ttraining's rmse: 0.0810985\tvalid_1's rmse: 0.0777027\n",
      "[475]\ttraining's rmse: 0.081056\tvalid_1's rmse: 0.0776896\n",
      "[500]\ttraining's rmse: 0.0810203\tvalid_1's rmse: 0.0776772\n",
      "[525]\ttraining's rmse: 0.0809716\tvalid_1's rmse: 0.0776638\n",
      "[550]\ttraining's rmse: 0.0809272\tvalid_1's rmse: 0.0776645\n",
      "[575]\ttraining's rmse: 0.0808868\tvalid_1's rmse: 0.077658\n",
      "[600]\ttraining's rmse: 0.0808456\tvalid_1's rmse: 0.0776548\n",
      "[625]\ttraining's rmse: 0.0808133\tvalid_1's rmse: 0.0776559\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's rmse: 0.0808568\tvalid_1's rmse: 0.0776504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0838213\tvalid_1's rmse: 0.0860253\n",
      "[50]\ttraining's rmse: 0.0836841\tvalid_1's rmse: 0.0859749\n",
      "[75]\ttraining's rmse: 0.0835474\tvalid_1's rmse: 0.085924\n",
      "[100]\ttraining's rmse: 0.0834191\tvalid_1's rmse: 0.0858795\n",
      "[125]\ttraining's rmse: 0.0832928\tvalid_1's rmse: 0.0858362\n",
      "[150]\ttraining's rmse: 0.0831777\tvalid_1's rmse: 0.0857971\n",
      "[175]\ttraining's rmse: 0.08308\tvalid_1's rmse: 0.0857644\n",
      "[200]\ttraining's rmse: 0.0829751\tvalid_1's rmse: 0.085729\n",
      "[225]\ttraining's rmse: 0.0828732\tvalid_1's rmse: 0.0856957\n",
      "[250]\ttraining's rmse: 0.082789\tvalid_1's rmse: 0.0856665\n",
      "[275]\ttraining's rmse: 0.0827111\tvalid_1's rmse: 0.08564\n",
      "[300]\ttraining's rmse: 0.0826317\tvalid_1's rmse: 0.0856139\n",
      "[325]\ttraining's rmse: 0.0825523\tvalid_1's rmse: 0.0855885\n",
      "[350]\ttraining's rmse: 0.0824766\tvalid_1's rmse: 0.0855625\n",
      "[375]\ttraining's rmse: 0.0824111\tvalid_1's rmse: 0.0855429\n",
      "[400]\ttraining's rmse: 0.082341\tvalid_1's rmse: 0.085523\n",
      "[425]\ttraining's rmse: 0.082281\tvalid_1's rmse: 0.0855054\n",
      "[450]\ttraining's rmse: 0.0822232\tvalid_1's rmse: 0.0854865\n",
      "[475]\ttraining's rmse: 0.0821707\tvalid_1's rmse: 0.0854697\n",
      "[500]\ttraining's rmse: 0.0821234\tvalid_1's rmse: 0.0854545\n",
      "[525]\ttraining's rmse: 0.0820666\tvalid_1's rmse: 0.0854404\n",
      "[550]\ttraining's rmse: 0.0820159\tvalid_1's rmse: 0.0854255\n",
      "[575]\ttraining's rmse: 0.081967\tvalid_1's rmse: 0.0854122\n",
      "[600]\ttraining's rmse: 0.08192\tvalid_1's rmse: 0.0853998\n",
      "[625]\ttraining's rmse: 0.081882\tvalid_1's rmse: 0.0853884\n",
      "[650]\ttraining's rmse: 0.0818366\tvalid_1's rmse: 0.0853774\n",
      "[675]\ttraining's rmse: 0.0817929\tvalid_1's rmse: 0.0853665\n",
      "[700]\ttraining's rmse: 0.0817527\tvalid_1's rmse: 0.085356\n",
      "[725]\ttraining's rmse: 0.0817147\tvalid_1's rmse: 0.0853464\n",
      "[750]\ttraining's rmse: 0.0816808\tvalid_1's rmse: 0.0853375\n",
      "[775]\ttraining's rmse: 0.0816535\tvalid_1's rmse: 0.0853294\n",
      "[800]\ttraining's rmse: 0.081619\tvalid_1's rmse: 0.0853216\n",
      "[825]\ttraining's rmse: 0.0815882\tvalid_1's rmse: 0.0853139\n",
      "[850]\ttraining's rmse: 0.081554\tvalid_1's rmse: 0.0853074\n",
      "[875]\ttraining's rmse: 0.0815286\tvalid_1's rmse: 0.0852996\n",
      "[900]\ttraining's rmse: 0.0814972\tvalid_1's rmse: 0.0852927\n",
      "[925]\ttraining's rmse: 0.0814695\tvalid_1's rmse: 0.0852858\n",
      "[950]\ttraining's rmse: 0.081442\tvalid_1's rmse: 0.0852805\n",
      "[975]\ttraining's rmse: 0.0814166\tvalid_1's rmse: 0.0852746\n",
      "[1000]\ttraining's rmse: 0.0813933\tvalid_1's rmse: 0.0852694\n",
      "[1025]\ttraining's rmse: 0.081371\tvalid_1's rmse: 0.0852636\n",
      "[1050]\ttraining's rmse: 0.081351\tvalid_1's rmse: 0.0852575\n",
      "[1075]\ttraining's rmse: 0.0813274\tvalid_1's rmse: 0.0852528\n",
      "[1100]\ttraining's rmse: 0.0813073\tvalid_1's rmse: 0.085249\n",
      "[1125]\ttraining's rmse: 0.0812895\tvalid_1's rmse: 0.0852443\n",
      "[1150]\ttraining's rmse: 0.081271\tvalid_1's rmse: 0.0852403\n",
      "[1175]\ttraining's rmse: 0.0812546\tvalid_1's rmse: 0.0852366\n",
      "[1200]\ttraining's rmse: 0.0812395\tvalid_1's rmse: 0.0852334\n",
      "[1225]\ttraining's rmse: 0.0812208\tvalid_1's rmse: 0.0852302\n",
      "[1250]\ttraining's rmse: 0.0812042\tvalid_1's rmse: 0.0852263\n",
      "[1275]\ttraining's rmse: 0.0811866\tvalid_1's rmse: 0.0852221\n",
      "[1300]\ttraining's rmse: 0.0811711\tvalid_1's rmse: 0.0852177\n",
      "[1325]\ttraining's rmse: 0.0811574\tvalid_1's rmse: 0.0852147\n",
      "[1350]\ttraining's rmse: 0.081143\tvalid_1's rmse: 0.0852115\n",
      "[1375]\ttraining's rmse: 0.0811294\tvalid_1's rmse: 0.0852082\n",
      "[1400]\ttraining's rmse: 0.0811171\tvalid_1's rmse: 0.085205\n",
      "[1425]\ttraining's rmse: 0.0811049\tvalid_1's rmse: 0.0852025\n",
      "[1450]\ttraining's rmse: 0.0810941\tvalid_1's rmse: 0.0851986\n",
      "[1475]\ttraining's rmse: 0.0810844\tvalid_1's rmse: 0.0851965\n",
      "[1500]\ttraining's rmse: 0.0810749\tvalid_1's rmse: 0.0851941\n",
      "[1525]\ttraining's rmse: 0.0810653\tvalid_1's rmse: 0.0851924\n",
      "[1550]\ttraining's rmse: 0.081054\tvalid_1's rmse: 0.0851895\n",
      "[1575]\ttraining's rmse: 0.0810453\tvalid_1's rmse: 0.0851863\n",
      "[1600]\ttraining's rmse: 0.0810379\tvalid_1's rmse: 0.0851835\n",
      "[1625]\ttraining's rmse: 0.0810313\tvalid_1's rmse: 0.0851801\n",
      "[1650]\ttraining's rmse: 0.0810232\tvalid_1's rmse: 0.085177\n",
      "[1675]\ttraining's rmse: 0.0810154\tvalid_1's rmse: 0.0851753\n",
      "[1700]\ttraining's rmse: 0.0810098\tvalid_1's rmse: 0.0851743\n",
      "[1725]\ttraining's rmse: 0.081001\tvalid_1's rmse: 0.0851723\n",
      "[1750]\ttraining's rmse: 0.0809953\tvalid_1's rmse: 0.0851707\n",
      "[1775]\ttraining's rmse: 0.0809884\tvalid_1's rmse: 0.085169\n",
      "[1800]\ttraining's rmse: 0.0809833\tvalid_1's rmse: 0.0851678\n",
      "[1825]\ttraining's rmse: 0.0809776\tvalid_1's rmse: 0.085166\n",
      "[1850]\ttraining's rmse: 0.0809729\tvalid_1's rmse: 0.0851653\n",
      "[1875]\ttraining's rmse: 0.0809656\tvalid_1's rmse: 0.0851645\n",
      "[1900]\ttraining's rmse: 0.0809596\tvalid_1's rmse: 0.0851626\n",
      "[1925]\ttraining's rmse: 0.0809552\tvalid_1's rmse: 0.085162\n",
      "[1950]\ttraining's rmse: 0.0809501\tvalid_1's rmse: 0.0851597\n",
      "[1975]\ttraining's rmse: 0.0809468\tvalid_1's rmse: 0.0851592\n",
      "[2000]\ttraining's rmse: 0.0809417\tvalid_1's rmse: 0.0851583\n",
      "[2025]\ttraining's rmse: 0.0809387\tvalid_1's rmse: 0.0851568\n",
      "[2050]\ttraining's rmse: 0.0809339\tvalid_1's rmse: 0.0851554\n",
      "[2075]\ttraining's rmse: 0.0809301\tvalid_1's rmse: 0.0851543\n",
      "[2100]\ttraining's rmse: 0.0809273\tvalid_1's rmse: 0.0851534\n",
      "[2125]\ttraining's rmse: 0.0809246\tvalid_1's rmse: 0.085153\n",
      "[2150]\ttraining's rmse: 0.0809214\tvalid_1's rmse: 0.0851516\n",
      "[2175]\ttraining's rmse: 0.0809194\tvalid_1's rmse: 0.0851517\n",
      "[2200]\ttraining's rmse: 0.0809145\tvalid_1's rmse: 0.0851497\n",
      "[2225]\ttraining's rmse: 0.0809109\tvalid_1's rmse: 0.0851482\n",
      "[2250]\ttraining's rmse: 0.0809082\tvalid_1's rmse: 0.0851478\n",
      "[2275]\ttraining's rmse: 0.0809057\tvalid_1's rmse: 0.0851473\n",
      "[2300]\ttraining's rmse: 0.0809032\tvalid_1's rmse: 0.0851469\n",
      "[2325]\ttraining's rmse: 0.0809005\tvalid_1's rmse: 0.0851462\n",
      "[2350]\ttraining's rmse: 0.0808973\tvalid_1's rmse: 0.0851461\n",
      "[2375]\ttraining's rmse: 0.0808948\tvalid_1's rmse: 0.0851455\n",
      "[2400]\ttraining's rmse: 0.0808927\tvalid_1's rmse: 0.085145\n",
      "[2425]\ttraining's rmse: 0.0808898\tvalid_1's rmse: 0.0851442\n",
      "[2450]\ttraining's rmse: 0.0808881\tvalid_1's rmse: 0.0851434\n",
      "[2475]\ttraining's rmse: 0.0808827\tvalid_1's rmse: 0.0851427\n",
      "[2500]\ttraining's rmse: 0.0808797\tvalid_1's rmse: 0.0851418\n",
      "[2525]\ttraining's rmse: 0.0808781\tvalid_1's rmse: 0.0851416\n",
      "[2550]\ttraining's rmse: 0.0808754\tvalid_1's rmse: 0.0851411\n",
      "[2575]\ttraining's rmse: 0.0808719\tvalid_1's rmse: 0.0851408\n",
      "[2600]\ttraining's rmse: 0.0808704\tvalid_1's rmse: 0.0851405\n",
      "[2625]\ttraining's rmse: 0.080868\tvalid_1's rmse: 0.0851396\n",
      "[2650]\ttraining's rmse: 0.0808664\tvalid_1's rmse: 0.0851396\n",
      "[2675]\ttraining's rmse: 0.0808644\tvalid_1's rmse: 0.0851397\n",
      "Early stopping, best iteration is:\n",
      "[2632]\ttraining's rmse: 0.0808674\tvalid_1's rmse: 0.0851395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0838377\tvalid_1's rmse: 0.0860269\n",
      "[50]\ttraining's rmse: 0.0837193\tvalid_1's rmse: 0.0859746\n",
      "[75]\ttraining's rmse: 0.0835978\tvalid_1's rmse: 0.0859221\n",
      "[100]\ttraining's rmse: 0.0834863\tvalid_1's rmse: 0.0858756\n",
      "[125]\ttraining's rmse: 0.0833741\tvalid_1's rmse: 0.0858304\n",
      "[150]\ttraining's rmse: 0.0832711\tvalid_1's rmse: 0.0857863\n",
      "[175]\ttraining's rmse: 0.0831842\tvalid_1's rmse: 0.0857509\n",
      "[200]\ttraining's rmse: 0.0830904\tvalid_1's rmse: 0.0857127\n",
      "[225]\ttraining's rmse: 0.0829976\tvalid_1's rmse: 0.0856782\n",
      "[250]\ttraining's rmse: 0.08292\tvalid_1's rmse: 0.0856467\n",
      "[275]\ttraining's rmse: 0.0828493\tvalid_1's rmse: 0.0856196\n",
      "[300]\ttraining's rmse: 0.0827754\tvalid_1's rmse: 0.0855927\n",
      "[325]\ttraining's rmse: 0.0827014\tvalid_1's rmse: 0.0855675\n",
      "[350]\ttraining's rmse: 0.0826342\tvalid_1's rmse: 0.0855433\n",
      "[375]\ttraining's rmse: 0.0825777\tvalid_1's rmse: 0.0855233\n",
      "[400]\ttraining's rmse: 0.0825146\tvalid_1's rmse: 0.0855034\n",
      "[425]\ttraining's rmse: 0.0824595\tvalid_1's rmse: 0.085483\n",
      "[450]\ttraining's rmse: 0.0824067\tvalid_1's rmse: 0.0854642\n",
      "[475]\ttraining's rmse: 0.082359\tvalid_1's rmse: 0.0854486\n",
      "[500]\ttraining's rmse: 0.0823165\tvalid_1's rmse: 0.0854319\n",
      "[525]\ttraining's rmse: 0.0822627\tvalid_1's rmse: 0.0854174\n",
      "[550]\ttraining's rmse: 0.082214\tvalid_1's rmse: 0.0854023\n",
      "[575]\ttraining's rmse: 0.0821687\tvalid_1's rmse: 0.0853881\n",
      "[600]\ttraining's rmse: 0.0821256\tvalid_1's rmse: 0.0853752\n",
      "[625]\ttraining's rmse: 0.0820911\tvalid_1's rmse: 0.085363\n",
      "[650]\ttraining's rmse: 0.0820493\tvalid_1's rmse: 0.0853508\n",
      "[675]\ttraining's rmse: 0.0820074\tvalid_1's rmse: 0.0853398\n",
      "[700]\ttraining's rmse: 0.0819695\tvalid_1's rmse: 0.0853293\n",
      "[725]\ttraining's rmse: 0.0819353\tvalid_1's rmse: 0.0853203\n",
      "[750]\ttraining's rmse: 0.0819021\tvalid_1's rmse: 0.0853102\n",
      "[775]\ttraining's rmse: 0.0818739\tvalid_1's rmse: 0.0853008\n",
      "[800]\ttraining's rmse: 0.0818393\tvalid_1's rmse: 0.0852923\n",
      "[825]\ttraining's rmse: 0.0818115\tvalid_1's rmse: 0.0852841\n",
      "[850]\ttraining's rmse: 0.0817822\tvalid_1's rmse: 0.0852768\n",
      "[875]\ttraining's rmse: 0.0817565\tvalid_1's rmse: 0.085271\n",
      "[900]\ttraining's rmse: 0.0817285\tvalid_1's rmse: 0.085264\n",
      "[925]\ttraining's rmse: 0.0817017\tvalid_1's rmse: 0.0852579\n",
      "[950]\ttraining's rmse: 0.0816764\tvalid_1's rmse: 0.0852529\n",
      "[975]\ttraining's rmse: 0.0816542\tvalid_1's rmse: 0.0852474\n",
      "[1000]\ttraining's rmse: 0.081634\tvalid_1's rmse: 0.0852421\n",
      "[1025]\ttraining's rmse: 0.0816097\tvalid_1's rmse: 0.0852373\n",
      "[1050]\ttraining's rmse: 0.081588\tvalid_1's rmse: 0.0852322\n",
      "[1075]\ttraining's rmse: 0.0815671\tvalid_1's rmse: 0.0852287\n",
      "[1100]\ttraining's rmse: 0.0815511\tvalid_1's rmse: 0.0852246\n",
      "[1125]\ttraining's rmse: 0.0815336\tvalid_1's rmse: 0.0852208\n",
      "[1150]\ttraining's rmse: 0.0815146\tvalid_1's rmse: 0.0852164\n",
      "[1175]\ttraining's rmse: 0.0814989\tvalid_1's rmse: 0.0852132\n",
      "[1200]\ttraining's rmse: 0.0814822\tvalid_1's rmse: 0.0852099\n",
      "[1225]\ttraining's rmse: 0.0814661\tvalid_1's rmse: 0.0852064\n",
      "[1250]\ttraining's rmse: 0.0814506\tvalid_1's rmse: 0.0852034\n",
      "[1275]\ttraining's rmse: 0.081433\tvalid_1's rmse: 0.0852007\n",
      "[1300]\ttraining's rmse: 0.0814214\tvalid_1's rmse: 0.0851982\n",
      "[1325]\ttraining's rmse: 0.081407\tvalid_1's rmse: 0.0851961\n",
      "[1350]\ttraining's rmse: 0.0813941\tvalid_1's rmse: 0.0851943\n",
      "[1375]\ttraining's rmse: 0.0813807\tvalid_1's rmse: 0.0851924\n",
      "[1400]\ttraining's rmse: 0.0813711\tvalid_1's rmse: 0.0851898\n",
      "[1425]\ttraining's rmse: 0.0813575\tvalid_1's rmse: 0.0851883\n",
      "[1450]\ttraining's rmse: 0.0813449\tvalid_1's rmse: 0.0851869\n",
      "[1475]\ttraining's rmse: 0.081334\tvalid_1's rmse: 0.0851846\n",
      "[1500]\ttraining's rmse: 0.081326\tvalid_1's rmse: 0.0851837\n",
      "[1525]\ttraining's rmse: 0.081316\tvalid_1's rmse: 0.085182\n",
      "[1550]\ttraining's rmse: 0.0813058\tvalid_1's rmse: 0.0851808\n",
      "[1575]\ttraining's rmse: 0.0812982\tvalid_1's rmse: 0.0851789\n",
      "[1600]\ttraining's rmse: 0.0812918\tvalid_1's rmse: 0.0851781\n",
      "[1625]\ttraining's rmse: 0.0812855\tvalid_1's rmse: 0.0851771\n",
      "[1650]\ttraining's rmse: 0.0812764\tvalid_1's rmse: 0.0851755\n",
      "[1675]\ttraining's rmse: 0.0812708\tvalid_1's rmse: 0.0851747\n",
      "[1700]\ttraining's rmse: 0.0812652\tvalid_1's rmse: 0.0851739\n",
      "[1725]\ttraining's rmse: 0.0812605\tvalid_1's rmse: 0.0851729\n",
      "[1750]\ttraining's rmse: 0.081255\tvalid_1's rmse: 0.0851724\n",
      "[1775]\ttraining's rmse: 0.0812482\tvalid_1's rmse: 0.0851715\n",
      "[1800]\ttraining's rmse: 0.0812412\tvalid_1's rmse: 0.0851704\n",
      "[1825]\ttraining's rmse: 0.0812361\tvalid_1's rmse: 0.0851693\n",
      "[1850]\ttraining's rmse: 0.0812296\tvalid_1's rmse: 0.0851684\n",
      "[1875]\ttraining's rmse: 0.0812227\tvalid_1's rmse: 0.0851683\n",
      "[1900]\ttraining's rmse: 0.0812186\tvalid_1's rmse: 0.0851687\n",
      "Early stopping, best iteration is:\n",
      "[1860]\ttraining's rmse: 0.0812265\tvalid_1's rmse: 0.0851682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0858972\tvalid_1's rmse: 0.0818317\n",
      "[50]\ttraining's rmse: 0.085783\tvalid_1's rmse: 0.0817825\n",
      "[75]\ttraining's rmse: 0.0856615\tvalid_1's rmse: 0.0817341\n",
      "[100]\ttraining's rmse: 0.0855518\tvalid_1's rmse: 0.0816904\n",
      "[125]\ttraining's rmse: 0.0854375\tvalid_1's rmse: 0.0816499\n",
      "[150]\ttraining's rmse: 0.0853353\tvalid_1's rmse: 0.0816119\n",
      "[175]\ttraining's rmse: 0.0852491\tvalid_1's rmse: 0.0815793\n",
      "[200]\ttraining's rmse: 0.085154\tvalid_1's rmse: 0.0815467\n",
      "[225]\ttraining's rmse: 0.0850632\tvalid_1's rmse: 0.0815147\n",
      "[250]\ttraining's rmse: 0.0849868\tvalid_1's rmse: 0.0814879\n",
      "[275]\ttraining's rmse: 0.0849165\tvalid_1's rmse: 0.0814617\n",
      "[300]\ttraining's rmse: 0.0848456\tvalid_1's rmse: 0.0814373\n",
      "[325]\ttraining's rmse: 0.084775\tvalid_1's rmse: 0.0814147\n",
      "[350]\ttraining's rmse: 0.0847079\tvalid_1's rmse: 0.0813935\n",
      "[375]\ttraining's rmse: 0.0846516\tvalid_1's rmse: 0.0813761\n",
      "[400]\ttraining's rmse: 0.0845899\tvalid_1's rmse: 0.0813657\n",
      "[425]\ttraining's rmse: 0.0845337\tvalid_1's rmse: 0.0813492\n",
      "[450]\ttraining's rmse: 0.0844832\tvalid_1's rmse: 0.0813314\n",
      "[475]\ttraining's rmse: 0.084437\tvalid_1's rmse: 0.0813189\n",
      "[500]\ttraining's rmse: 0.0843962\tvalid_1's rmse: 0.0813053\n",
      "[525]\ttraining's rmse: 0.0843408\tvalid_1's rmse: 0.0812917\n",
      "[550]\ttraining's rmse: 0.0842929\tvalid_1's rmse: 0.0812789\n",
      "[575]\ttraining's rmse: 0.0842464\tvalid_1's rmse: 0.0812676\n",
      "[600]\ttraining's rmse: 0.084201\tvalid_1's rmse: 0.0812579\n",
      "[625]\ttraining's rmse: 0.0841668\tvalid_1's rmse: 0.0812527\n",
      "[650]\ttraining's rmse: 0.0841234\tvalid_1's rmse: 0.0812471\n",
      "[675]\ttraining's rmse: 0.0840783\tvalid_1's rmse: 0.0812386\n",
      "[700]\ttraining's rmse: 0.0840401\tvalid_1's rmse: 0.0812343\n",
      "[725]\ttraining's rmse: 0.0840045\tvalid_1's rmse: 0.081231\n",
      "[750]\ttraining's rmse: 0.0839724\tvalid_1's rmse: 0.0812324\n",
      "[775]\ttraining's rmse: 0.0839449\tvalid_1's rmse: 0.0812314\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0839901\tvalid_1's rmse: 0.0812273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0806182\tvalid_1's rmse: 0.0831864\n",
      "[50]\ttraining's rmse: 0.0805022\tvalid_1's rmse: 0.0831323\n",
      "[75]\ttraining's rmse: 0.0803835\tvalid_1's rmse: 0.0830786\n",
      "[100]\ttraining's rmse: 0.0802761\tvalid_1's rmse: 0.0830311\n",
      "[125]\ttraining's rmse: 0.0801655\tvalid_1's rmse: 0.0829844\n",
      "[150]\ttraining's rmse: 0.0800677\tvalid_1's rmse: 0.0829407\n",
      "[175]\ttraining's rmse: 0.0799867\tvalid_1's rmse: 0.0829034\n",
      "[200]\ttraining's rmse: 0.0799013\tvalid_1's rmse: 0.0828664\n",
      "[225]\ttraining's rmse: 0.0798133\tvalid_1's rmse: 0.0828305\n",
      "[250]\ttraining's rmse: 0.0797406\tvalid_1's rmse: 0.0827968\n",
      "[275]\ttraining's rmse: 0.079669\tvalid_1's rmse: 0.0827666\n",
      "[300]\ttraining's rmse: 0.0796036\tvalid_1's rmse: 0.0827397\n",
      "[325]\ttraining's rmse: 0.0795364\tvalid_1's rmse: 0.082714\n",
      "[350]\ttraining's rmse: 0.0794695\tvalid_1's rmse: 0.0826872\n",
      "[375]\ttraining's rmse: 0.0794172\tvalid_1's rmse: 0.0826648\n",
      "[400]\ttraining's rmse: 0.07936\tvalid_1's rmse: 0.082643\n",
      "[425]\ttraining's rmse: 0.0793078\tvalid_1's rmse: 0.0826212\n",
      "[450]\ttraining's rmse: 0.0792609\tvalid_1's rmse: 0.0826\n",
      "[475]\ttraining's rmse: 0.0792177\tvalid_1's rmse: 0.0825808\n",
      "[500]\ttraining's rmse: 0.0791801\tvalid_1's rmse: 0.0825624\n",
      "[525]\ttraining's rmse: 0.0791324\tvalid_1's rmse: 0.0825446\n",
      "[550]\ttraining's rmse: 0.0790876\tvalid_1's rmse: 0.0825292\n",
      "[575]\ttraining's rmse: 0.0790456\tvalid_1's rmse: 0.0825137\n",
      "[600]\ttraining's rmse: 0.0790063\tvalid_1's rmse: 0.0824999\n",
      "[625]\ttraining's rmse: 0.0789751\tvalid_1's rmse: 0.0824866\n",
      "[650]\ttraining's rmse: 0.0789362\tvalid_1's rmse: 0.0824739\n",
      "[675]\ttraining's rmse: 0.0788993\tvalid_1's rmse: 0.0824628\n",
      "[700]\ttraining's rmse: 0.0788662\tvalid_1's rmse: 0.0824505\n",
      "[725]\ttraining's rmse: 0.0788365\tvalid_1's rmse: 0.082441\n",
      "[750]\ttraining's rmse: 0.0788082\tvalid_1's rmse: 0.082432\n",
      "[775]\ttraining's rmse: 0.0787836\tvalid_1's rmse: 0.0824214\n",
      "[800]\ttraining's rmse: 0.0787538\tvalid_1's rmse: 0.0824135\n",
      "[825]\ttraining's rmse: 0.078728\tvalid_1's rmse: 0.0824031\n",
      "[850]\ttraining's rmse: 0.0786999\tvalid_1's rmse: 0.0823946\n",
      "[875]\ttraining's rmse: 0.0786758\tvalid_1's rmse: 0.0823859\n",
      "[900]\ttraining's rmse: 0.0786504\tvalid_1's rmse: 0.0823784\n",
      "[925]\ttraining's rmse: 0.0786282\tvalid_1's rmse: 0.082371\n",
      "[950]\ttraining's rmse: 0.0786068\tvalid_1's rmse: 0.0823636\n",
      "[975]\ttraining's rmse: 0.078585\tvalid_1's rmse: 0.0823575\n",
      "[1000]\ttraining's rmse: 0.0785631\tvalid_1's rmse: 0.0823499\n",
      "[1025]\ttraining's rmse: 0.0785413\tvalid_1's rmse: 0.0823431\n",
      "[1050]\ttraining's rmse: 0.0785216\tvalid_1's rmse: 0.0823363\n",
      "[1075]\ttraining's rmse: 0.0785022\tvalid_1's rmse: 0.0823325\n",
      "[1100]\ttraining's rmse: 0.0784864\tvalid_1's rmse: 0.0823272\n",
      "[1125]\ttraining's rmse: 0.0784712\tvalid_1's rmse: 0.0823203\n",
      "[1150]\ttraining's rmse: 0.0784543\tvalid_1's rmse: 0.0823158\n",
      "[1175]\ttraining's rmse: 0.0784371\tvalid_1's rmse: 0.082312\n",
      "[1200]\ttraining's rmse: 0.0784232\tvalid_1's rmse: 0.0823079\n",
      "[1225]\ttraining's rmse: 0.0784093\tvalid_1's rmse: 0.0823028\n",
      "[1250]\ttraining's rmse: 0.0783952\tvalid_1's rmse: 0.0823001\n",
      "[1275]\ttraining's rmse: 0.0783789\tvalid_1's rmse: 0.0822971\n",
      "[1300]\ttraining's rmse: 0.0783684\tvalid_1's rmse: 0.0822922\n",
      "[1325]\ttraining's rmse: 0.0783556\tvalid_1's rmse: 0.0822892\n",
      "[1350]\ttraining's rmse: 0.0783439\tvalid_1's rmse: 0.0822868\n",
      "[1375]\ttraining's rmse: 0.0783312\tvalid_1's rmse: 0.0822834\n",
      "[1400]\ttraining's rmse: 0.0783232\tvalid_1's rmse: 0.0822809\n",
      "[1425]\ttraining's rmse: 0.0783106\tvalid_1's rmse: 0.0822783\n",
      "[1450]\ttraining's rmse: 0.0782998\tvalid_1's rmse: 0.0822761\n",
      "[1475]\ttraining's rmse: 0.0782893\tvalid_1's rmse: 0.0822728\n",
      "[1500]\ttraining's rmse: 0.0782802\tvalid_1's rmse: 0.0822699\n",
      "[1525]\ttraining's rmse: 0.0782721\tvalid_1's rmse: 0.0822676\n",
      "[1550]\ttraining's rmse: 0.078264\tvalid_1's rmse: 0.0822656\n",
      "[1575]\ttraining's rmse: 0.0782555\tvalid_1's rmse: 0.0822628\n",
      "[1600]\ttraining's rmse: 0.0782494\tvalid_1's rmse: 0.0822608\n",
      "[1625]\ttraining's rmse: 0.0782431\tvalid_1's rmse: 0.0822587\n",
      "[1650]\ttraining's rmse: 0.078236\tvalid_1's rmse: 0.0822561\n",
      "[1675]\ttraining's rmse: 0.0782317\tvalid_1's rmse: 0.0822537\n",
      "[1700]\ttraining's rmse: 0.0782255\tvalid_1's rmse: 0.0822518\n",
      "[1725]\ttraining's rmse: 0.078221\tvalid_1's rmse: 0.0822509\n",
      "[1750]\ttraining's rmse: 0.0782149\tvalid_1's rmse: 0.0822489\n",
      "[1775]\ttraining's rmse: 0.0782106\tvalid_1's rmse: 0.0822469\n",
      "[1800]\ttraining's rmse: 0.0782057\tvalid_1's rmse: 0.0822457\n",
      "[1825]\ttraining's rmse: 0.0781995\tvalid_1's rmse: 0.0822438\n",
      "[1850]\ttraining's rmse: 0.0781946\tvalid_1's rmse: 0.0822421\n",
      "[1875]\ttraining's rmse: 0.0781909\tvalid_1's rmse: 0.0822415\n",
      "[1900]\ttraining's rmse: 0.0781868\tvalid_1's rmse: 0.0822411\n",
      "[1925]\ttraining's rmse: 0.0781796\tvalid_1's rmse: 0.0822398\n",
      "[1950]\ttraining's rmse: 0.0781765\tvalid_1's rmse: 0.0822385\n",
      "[1975]\ttraining's rmse: 0.0781734\tvalid_1's rmse: 0.0822371\n",
      "[2000]\ttraining's rmse: 0.0781704\tvalid_1's rmse: 0.0822364\n",
      "[2025]\ttraining's rmse: 0.0781669\tvalid_1's rmse: 0.0822347\n",
      "[2050]\ttraining's rmse: 0.0781638\tvalid_1's rmse: 0.0822339\n",
      "[2075]\ttraining's rmse: 0.0781616\tvalid_1's rmse: 0.0822334\n",
      "[2100]\ttraining's rmse: 0.0781589\tvalid_1's rmse: 0.0822319\n",
      "[2125]\ttraining's rmse: 0.0781573\tvalid_1's rmse: 0.0822315\n",
      "[2150]\ttraining's rmse: 0.078154\tvalid_1's rmse: 0.082231\n",
      "[2175]\ttraining's rmse: 0.0781518\tvalid_1's rmse: 0.0822303\n",
      "[2200]\ttraining's rmse: 0.07815\tvalid_1's rmse: 0.0822299\n",
      "[2225]\ttraining's rmse: 0.0781458\tvalid_1's rmse: 0.0822298\n",
      "[2250]\ttraining's rmse: 0.0781434\tvalid_1's rmse: 0.08223\n",
      "Early stopping, best iteration is:\n",
      "[2204]\ttraining's rmse: 0.0781496\tvalid_1's rmse: 0.0822294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0808023\tvalid_1's rmse: 0.0828224\n",
      "[50]\ttraining's rmse: 0.0806896\tvalid_1's rmse: 0.0827671\n",
      "[75]\ttraining's rmse: 0.0805753\tvalid_1's rmse: 0.0827138\n",
      "[100]\ttraining's rmse: 0.080475\tvalid_1's rmse: 0.0826659\n",
      "[125]\ttraining's rmse: 0.0803703\tvalid_1's rmse: 0.0826175\n",
      "[150]\ttraining's rmse: 0.0802733\tvalid_1's rmse: 0.0825741\n",
      "[175]\ttraining's rmse: 0.0801944\tvalid_1's rmse: 0.0825385\n",
      "[200]\ttraining's rmse: 0.080106\tvalid_1's rmse: 0.0825008\n",
      "[225]\ttraining's rmse: 0.0800231\tvalid_1's rmse: 0.0824682\n",
      "[250]\ttraining's rmse: 0.079952\tvalid_1's rmse: 0.0824381\n",
      "[275]\ttraining's rmse: 0.0798843\tvalid_1's rmse: 0.0824096\n",
      "[300]\ttraining's rmse: 0.0798193\tvalid_1's rmse: 0.0823829\n",
      "[325]\ttraining's rmse: 0.0797502\tvalid_1's rmse: 0.0823567\n",
      "[350]\ttraining's rmse: 0.0796836\tvalid_1's rmse: 0.0823317\n",
      "[375]\ttraining's rmse: 0.0796306\tvalid_1's rmse: 0.0823112\n",
      "[400]\ttraining's rmse: 0.079573\tvalid_1's rmse: 0.0822906\n",
      "[425]\ttraining's rmse: 0.0795195\tvalid_1's rmse: 0.0822707\n",
      "[450]\ttraining's rmse: 0.0794712\tvalid_1's rmse: 0.0822521\n",
      "[475]\ttraining's rmse: 0.0794251\tvalid_1's rmse: 0.0822354\n",
      "[500]\ttraining's rmse: 0.0793847\tvalid_1's rmse: 0.0822204\n",
      "[525]\ttraining's rmse: 0.0793351\tvalid_1's rmse: 0.0822058\n",
      "[550]\ttraining's rmse: 0.07929\tvalid_1's rmse: 0.0821918\n",
      "[575]\ttraining's rmse: 0.0792477\tvalid_1's rmse: 0.0821785\n",
      "[600]\ttraining's rmse: 0.0792044\tvalid_1's rmse: 0.082165\n",
      "[625]\ttraining's rmse: 0.079174\tvalid_1's rmse: 0.0821536\n",
      "[650]\ttraining's rmse: 0.0791328\tvalid_1's rmse: 0.0821418\n",
      "[675]\ttraining's rmse: 0.0790927\tvalid_1's rmse: 0.0821306\n",
      "[700]\ttraining's rmse: 0.0790594\tvalid_1's rmse: 0.0821209\n",
      "[725]\ttraining's rmse: 0.0790267\tvalid_1's rmse: 0.0821117\n",
      "[750]\ttraining's rmse: 0.0789944\tvalid_1's rmse: 0.0821039\n",
      "[775]\ttraining's rmse: 0.0789674\tvalid_1's rmse: 0.0820949\n",
      "[800]\ttraining's rmse: 0.0789345\tvalid_1's rmse: 0.0820882\n",
      "[825]\ttraining's rmse: 0.0789055\tvalid_1's rmse: 0.0820804\n",
      "[850]\ttraining's rmse: 0.0788757\tvalid_1's rmse: 0.0820735\n",
      "[875]\ttraining's rmse: 0.0788513\tvalid_1's rmse: 0.082068\n",
      "[900]\ttraining's rmse: 0.0788237\tvalid_1's rmse: 0.0820611\n",
      "[925]\ttraining's rmse: 0.0787983\tvalid_1's rmse: 0.0820553\n",
      "[950]\ttraining's rmse: 0.0787766\tvalid_1's rmse: 0.0820502\n",
      "[975]\ttraining's rmse: 0.0787539\tvalid_1's rmse: 0.082045\n",
      "[1000]\ttraining's rmse: 0.0787324\tvalid_1's rmse: 0.08204\n",
      "[1025]\ttraining's rmse: 0.0787086\tvalid_1's rmse: 0.0820353\n",
      "[1050]\ttraining's rmse: 0.0786891\tvalid_1's rmse: 0.0820309\n",
      "[1075]\ttraining's rmse: 0.0786693\tvalid_1's rmse: 0.0820271\n",
      "[1100]\ttraining's rmse: 0.0786525\tvalid_1's rmse: 0.0820229\n",
      "[1125]\ttraining's rmse: 0.0786357\tvalid_1's rmse: 0.0820192\n",
      "[1150]\ttraining's rmse: 0.0786189\tvalid_1's rmse: 0.0820153\n",
      "[1175]\ttraining's rmse: 0.0786026\tvalid_1's rmse: 0.0820117\n",
      "[1200]\ttraining's rmse: 0.0785872\tvalid_1's rmse: 0.0820083\n",
      "[1225]\ttraining's rmse: 0.0785726\tvalid_1's rmse: 0.0820054\n",
      "[1250]\ttraining's rmse: 0.0785608\tvalid_1's rmse: 0.082003\n",
      "[1275]\ttraining's rmse: 0.0785448\tvalid_1's rmse: 0.0820016\n",
      "[1300]\ttraining's rmse: 0.0785343\tvalid_1's rmse: 0.0819999\n",
      "[1325]\ttraining's rmse: 0.0785216\tvalid_1's rmse: 0.0819976\n",
      "[1350]\ttraining's rmse: 0.0785085\tvalid_1's rmse: 0.0819954\n",
      "[1375]\ttraining's rmse: 0.0784978\tvalid_1's rmse: 0.0819943\n",
      "[1400]\ttraining's rmse: 0.0784887\tvalid_1's rmse: 0.0819922\n",
      "[1425]\ttraining's rmse: 0.0784785\tvalid_1's rmse: 0.0819904\n",
      "[1450]\ttraining's rmse: 0.0784668\tvalid_1's rmse: 0.081989\n",
      "[1475]\ttraining's rmse: 0.0784582\tvalid_1's rmse: 0.0819871\n",
      "[1500]\ttraining's rmse: 0.0784496\tvalid_1's rmse: 0.0819857\n",
      "[1525]\ttraining's rmse: 0.0784395\tvalid_1's rmse: 0.0819847\n",
      "[1550]\ttraining's rmse: 0.0784315\tvalid_1's rmse: 0.0819837\n",
      "[1575]\ttraining's rmse: 0.0784225\tvalid_1's rmse: 0.0819822\n",
      "[1600]\ttraining's rmse: 0.0784144\tvalid_1's rmse: 0.0819812\n",
      "[1625]\ttraining's rmse: 0.0784077\tvalid_1's rmse: 0.0819803\n",
      "[1650]\ttraining's rmse: 0.0784019\tvalid_1's rmse: 0.0819797\n",
      "[1675]\ttraining's rmse: 0.0783962\tvalid_1's rmse: 0.0819785\n",
      "[1700]\ttraining's rmse: 0.0783907\tvalid_1's rmse: 0.0819772\n",
      "[1725]\ttraining's rmse: 0.0783848\tvalid_1's rmse: 0.0819767\n",
      "[1750]\ttraining's rmse: 0.0783774\tvalid_1's rmse: 0.0819765\n",
      "[1775]\ttraining's rmse: 0.0783716\tvalid_1's rmse: 0.081976\n",
      "[1800]\ttraining's rmse: 0.0783659\tvalid_1's rmse: 0.0819754\n",
      "[1825]\ttraining's rmse: 0.0783604\tvalid_1's rmse: 0.0819747\n",
      "[1850]\ttraining's rmse: 0.0783563\tvalid_1's rmse: 0.081974\n",
      "[1875]\ttraining's rmse: 0.0783509\tvalid_1's rmse: 0.0819731\n",
      "[1900]\ttraining's rmse: 0.0783452\tvalid_1's rmse: 0.0819729\n",
      "[1925]\ttraining's rmse: 0.0783411\tvalid_1's rmse: 0.0819723\n",
      "[1950]\ttraining's rmse: 0.0783373\tvalid_1's rmse: 0.0819719\n",
      "[1975]\ttraining's rmse: 0.0783328\tvalid_1's rmse: 0.081971\n",
      "[2000]\ttraining's rmse: 0.0783295\tvalid_1's rmse: 0.0819702\n",
      "[2025]\ttraining's rmse: 0.0783271\tvalid_1's rmse: 0.0819704\n",
      "[2050]\ttraining's rmse: 0.0783234\tvalid_1's rmse: 0.0819699\n",
      "[2075]\ttraining's rmse: 0.0783198\tvalid_1's rmse: 0.0819694\n",
      "[2100]\ttraining's rmse: 0.078317\tvalid_1's rmse: 0.0819687\n",
      "[2125]\ttraining's rmse: 0.0783139\tvalid_1's rmse: 0.0819688\n",
      "[2150]\ttraining's rmse: 0.0783097\tvalid_1's rmse: 0.0819693\n",
      "Early stopping, best iteration is:\n",
      "[2118]\ttraining's rmse: 0.0783143\tvalid_1's rmse: 0.0819686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0828907\tvalid_1's rmse: 0.0785716\n",
      "[50]\ttraining's rmse: 0.0827815\tvalid_1's rmse: 0.0785215\n",
      "[75]\ttraining's rmse: 0.0826703\tvalid_1's rmse: 0.0784738\n",
      "[100]\ttraining's rmse: 0.0825725\tvalid_1's rmse: 0.0784324\n",
      "[125]\ttraining's rmse: 0.0824682\tvalid_1's rmse: 0.0783889\n",
      "[150]\ttraining's rmse: 0.0823711\tvalid_1's rmse: 0.078353\n",
      "[175]\ttraining's rmse: 0.0822932\tvalid_1's rmse: 0.0783228\n",
      "[200]\ttraining's rmse: 0.0822103\tvalid_1's rmse: 0.0782915\n",
      "[225]\ttraining's rmse: 0.0821296\tvalid_1's rmse: 0.078261\n",
      "[250]\ttraining's rmse: 0.0820616\tvalid_1's rmse: 0.0782368\n",
      "[275]\ttraining's rmse: 0.0819962\tvalid_1's rmse: 0.0782115\n",
      "[300]\ttraining's rmse: 0.0819322\tvalid_1's rmse: 0.0781876\n",
      "[325]\ttraining's rmse: 0.0818685\tvalid_1's rmse: 0.0781655\n",
      "[350]\ttraining's rmse: 0.0818046\tvalid_1's rmse: 0.0781458\n",
      "[375]\ttraining's rmse: 0.0817525\tvalid_1's rmse: 0.0781279\n",
      "[400]\ttraining's rmse: 0.0816966\tvalid_1's rmse: 0.0781169\n",
      "[425]\ttraining's rmse: 0.081643\tvalid_1's rmse: 0.0781013\n",
      "[450]\ttraining's rmse: 0.0815956\tvalid_1's rmse: 0.0780871\n",
      "[475]\ttraining's rmse: 0.0815512\tvalid_1's rmse: 0.0780729\n",
      "[500]\ttraining's rmse: 0.0815141\tvalid_1's rmse: 0.078065\n",
      "[525]\ttraining's rmse: 0.0814652\tvalid_1's rmse: 0.0780522\n",
      "[550]\ttraining's rmse: 0.0814199\tvalid_1's rmse: 0.0780388\n",
      "[575]\ttraining's rmse: 0.0813787\tvalid_1's rmse: 0.0780279\n",
      "[600]\ttraining's rmse: 0.0813368\tvalid_1's rmse: 0.0780225\n",
      "[625]\ttraining's rmse: 0.0813059\tvalid_1's rmse: 0.0780207\n",
      "[650]\ttraining's rmse: 0.0812666\tvalid_1's rmse: 0.078014\n",
      "[675]\ttraining's rmse: 0.0812275\tvalid_1's rmse: 0.0780171\n",
      "[700]\ttraining's rmse: 0.0811916\tvalid_1's rmse: 0.0780143\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's rmse: 0.0812357\tvalid_1's rmse: 0.0780111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0846593\tvalid_1's rmse: 0.0867353\n",
      "[50]\ttraining's rmse: 0.0845195\tvalid_1's rmse: 0.0866849\n",
      "[75]\ttraining's rmse: 0.0843791\tvalid_1's rmse: 0.0866367\n",
      "[100]\ttraining's rmse: 0.0842489\tvalid_1's rmse: 0.0865916\n",
      "[125]\ttraining's rmse: 0.0841179\tvalid_1's rmse: 0.0865486\n",
      "[150]\ttraining's rmse: 0.0839967\tvalid_1's rmse: 0.0865081\n",
      "[175]\ttraining's rmse: 0.0838947\tvalid_1's rmse: 0.0864734\n",
      "[200]\ttraining's rmse: 0.0837882\tvalid_1's rmse: 0.086437\n",
      "[225]\ttraining's rmse: 0.0836807\tvalid_1's rmse: 0.0864047\n",
      "[250]\ttraining's rmse: 0.0835931\tvalid_1's rmse: 0.0863754\n",
      "[275]\ttraining's rmse: 0.0835103\tvalid_1's rmse: 0.0863483\n",
      "[300]\ttraining's rmse: 0.0834275\tvalid_1's rmse: 0.0863217\n",
      "[325]\ttraining's rmse: 0.0833446\tvalid_1's rmse: 0.086296\n",
      "[350]\ttraining's rmse: 0.0832687\tvalid_1's rmse: 0.0862732\n",
      "[375]\ttraining's rmse: 0.0832015\tvalid_1's rmse: 0.0862554\n",
      "[400]\ttraining's rmse: 0.0831276\tvalid_1's rmse: 0.0862351\n",
      "[425]\ttraining's rmse: 0.0830647\tvalid_1's rmse: 0.0862153\n",
      "[450]\ttraining's rmse: 0.0830053\tvalid_1's rmse: 0.0861978\n",
      "[475]\ttraining's rmse: 0.0829507\tvalid_1's rmse: 0.0861817\n",
      "[500]\ttraining's rmse: 0.0829035\tvalid_1's rmse: 0.0861658\n",
      "[525]\ttraining's rmse: 0.0828449\tvalid_1's rmse: 0.0861497\n",
      "[550]\ttraining's rmse: 0.0827886\tvalid_1's rmse: 0.0861351\n",
      "[575]\ttraining's rmse: 0.0827352\tvalid_1's rmse: 0.0861223\n",
      "[600]\ttraining's rmse: 0.0826864\tvalid_1's rmse: 0.0861104\n",
      "[625]\ttraining's rmse: 0.0826445\tvalid_1's rmse: 0.0860979\n",
      "[650]\ttraining's rmse: 0.0825973\tvalid_1's rmse: 0.0860852\n",
      "[675]\ttraining's rmse: 0.0825507\tvalid_1's rmse: 0.0860728\n",
      "[700]\ttraining's rmse: 0.0825107\tvalid_1's rmse: 0.0860637\n",
      "[725]\ttraining's rmse: 0.0824724\tvalid_1's rmse: 0.0860539\n",
      "[750]\ttraining's rmse: 0.0824366\tvalid_1's rmse: 0.0860444\n",
      "[775]\ttraining's rmse: 0.0824057\tvalid_1's rmse: 0.0860353\n",
      "[800]\ttraining's rmse: 0.0823719\tvalid_1's rmse: 0.0860272\n",
      "[825]\ttraining's rmse: 0.0823421\tvalid_1's rmse: 0.0860191\n",
      "[850]\ttraining's rmse: 0.082306\tvalid_1's rmse: 0.0860124\n",
      "[875]\ttraining's rmse: 0.0822747\tvalid_1's rmse: 0.086006\n",
      "[900]\ttraining's rmse: 0.0822431\tvalid_1's rmse: 0.0859992\n",
      "[925]\ttraining's rmse: 0.0822144\tvalid_1's rmse: 0.0859917\n",
      "[950]\ttraining's rmse: 0.0821867\tvalid_1's rmse: 0.0859863\n",
      "[975]\ttraining's rmse: 0.082163\tvalid_1's rmse: 0.085981\n",
      "[1000]\ttraining's rmse: 0.0821404\tvalid_1's rmse: 0.0859761\n",
      "[1025]\ttraining's rmse: 0.0821132\tvalid_1's rmse: 0.0859718\n",
      "[1050]\ttraining's rmse: 0.0820914\tvalid_1's rmse: 0.0859656\n",
      "[1075]\ttraining's rmse: 0.082068\tvalid_1's rmse: 0.0859616\n",
      "[1100]\ttraining's rmse: 0.0820483\tvalid_1's rmse: 0.0859573\n",
      "[1125]\ttraining's rmse: 0.0820278\tvalid_1's rmse: 0.0859527\n",
      "[1150]\ttraining's rmse: 0.0820077\tvalid_1's rmse: 0.0859483\n",
      "[1175]\ttraining's rmse: 0.0819902\tvalid_1's rmse: 0.0859447\n",
      "[1200]\ttraining's rmse: 0.0819727\tvalid_1's rmse: 0.0859411\n",
      "[1225]\ttraining's rmse: 0.0819567\tvalid_1's rmse: 0.0859385\n",
      "[1250]\ttraining's rmse: 0.0819423\tvalid_1's rmse: 0.0859357\n",
      "[1275]\ttraining's rmse: 0.081922\tvalid_1's rmse: 0.0859338\n",
      "[1300]\ttraining's rmse: 0.0819071\tvalid_1's rmse: 0.08593\n",
      "[1325]\ttraining's rmse: 0.0818912\tvalid_1's rmse: 0.0859271\n",
      "[1350]\ttraining's rmse: 0.0818749\tvalid_1's rmse: 0.0859239\n",
      "[1375]\ttraining's rmse: 0.0818608\tvalid_1's rmse: 0.0859194\n",
      "[1400]\ttraining's rmse: 0.0818496\tvalid_1's rmse: 0.0859169\n",
      "[1425]\ttraining's rmse: 0.0818353\tvalid_1's rmse: 0.085914\n",
      "[1450]\ttraining's rmse: 0.0818234\tvalid_1's rmse: 0.0859118\n",
      "[1475]\ttraining's rmse: 0.0818119\tvalid_1's rmse: 0.0859086\n",
      "[1500]\ttraining's rmse: 0.0818025\tvalid_1's rmse: 0.0859059\n",
      "[1525]\ttraining's rmse: 0.0817923\tvalid_1's rmse: 0.0859029\n",
      "[1550]\ttraining's rmse: 0.0817822\tvalid_1's rmse: 0.0859003\n",
      "[1575]\ttraining's rmse: 0.0817717\tvalid_1's rmse: 0.085898\n",
      "[1600]\ttraining's rmse: 0.0817643\tvalid_1's rmse: 0.0858968\n",
      "[1625]\ttraining's rmse: 0.0817555\tvalid_1's rmse: 0.0858938\n",
      "[1650]\ttraining's rmse: 0.0817486\tvalid_1's rmse: 0.085892\n",
      "[1675]\ttraining's rmse: 0.0817429\tvalid_1's rmse: 0.0858904\n",
      "[1700]\ttraining's rmse: 0.0817374\tvalid_1's rmse: 0.0858884\n",
      "[1725]\ttraining's rmse: 0.0817318\tvalid_1's rmse: 0.0858876\n",
      "[1750]\ttraining's rmse: 0.0817249\tvalid_1's rmse: 0.0858851\n",
      "[1775]\ttraining's rmse: 0.0817184\tvalid_1's rmse: 0.0858838\n",
      "[1800]\ttraining's rmse: 0.081712\tvalid_1's rmse: 0.0858824\n",
      "[1825]\ttraining's rmse: 0.0817053\tvalid_1's rmse: 0.0858811\n",
      "[1850]\ttraining's rmse: 0.0816986\tvalid_1's rmse: 0.0858798\n",
      "[1875]\ttraining's rmse: 0.0816936\tvalid_1's rmse: 0.0858785\n",
      "[1900]\ttraining's rmse: 0.0816887\tvalid_1's rmse: 0.085877\n",
      "[1925]\ttraining's rmse: 0.0816837\tvalid_1's rmse: 0.0858758\n",
      "[1950]\ttraining's rmse: 0.0816807\tvalid_1's rmse: 0.0858744\n",
      "[1975]\ttraining's rmse: 0.0816771\tvalid_1's rmse: 0.0858732\n",
      "[2000]\ttraining's rmse: 0.0816716\tvalid_1's rmse: 0.0858729\n",
      "[2025]\ttraining's rmse: 0.0816678\tvalid_1's rmse: 0.0858717\n",
      "[2050]\ttraining's rmse: 0.0816637\tvalid_1's rmse: 0.0858708\n",
      "[2075]\ttraining's rmse: 0.0816611\tvalid_1's rmse: 0.0858696\n",
      "[2100]\ttraining's rmse: 0.081658\tvalid_1's rmse: 0.0858688\n",
      "[2125]\ttraining's rmse: 0.081655\tvalid_1's rmse: 0.0858678\n",
      "[2150]\ttraining's rmse: 0.0816521\tvalid_1's rmse: 0.0858665\n",
      "[2175]\ttraining's rmse: 0.0816493\tvalid_1's rmse: 0.0858663\n",
      "[2200]\ttraining's rmse: 0.0816466\tvalid_1's rmse: 0.0858648\n",
      "[2225]\ttraining's rmse: 0.0816424\tvalid_1's rmse: 0.085864\n",
      "[2250]\ttraining's rmse: 0.0816402\tvalid_1's rmse: 0.085863\n",
      "[2275]\ttraining's rmse: 0.0816361\tvalid_1's rmse: 0.0858621\n",
      "[2300]\ttraining's rmse: 0.0816331\tvalid_1's rmse: 0.0858617\n",
      "[2325]\ttraining's rmse: 0.0816303\tvalid_1's rmse: 0.0858606\n",
      "[2350]\ttraining's rmse: 0.0816276\tvalid_1's rmse: 0.0858602\n",
      "[2375]\ttraining's rmse: 0.0816256\tvalid_1's rmse: 0.085859\n",
      "[2400]\ttraining's rmse: 0.081623\tvalid_1's rmse: 0.0858589\n",
      "[2425]\ttraining's rmse: 0.0816215\tvalid_1's rmse: 0.0858589\n",
      "[2450]\ttraining's rmse: 0.0816195\tvalid_1's rmse: 0.0858583\n",
      "[2475]\ttraining's rmse: 0.0816175\tvalid_1's rmse: 0.085858\n",
      "[2500]\ttraining's rmse: 0.0816156\tvalid_1's rmse: 0.0858577\n",
      "[2525]\ttraining's rmse: 0.0816139\tvalid_1's rmse: 0.085857\n",
      "[2550]\ttraining's rmse: 0.0816115\tvalid_1's rmse: 0.0858563\n",
      "[2575]\ttraining's rmse: 0.0816095\tvalid_1's rmse: 0.0858552\n",
      "[2600]\ttraining's rmse: 0.0816073\tvalid_1's rmse: 0.0858541\n",
      "[2625]\ttraining's rmse: 0.0816034\tvalid_1's rmse: 0.0858538\n",
      "[2650]\ttraining's rmse: 0.0816008\tvalid_1's rmse: 0.0858532\n",
      "[2675]\ttraining's rmse: 0.0815988\tvalid_1's rmse: 0.085852\n",
      "[2700]\ttraining's rmse: 0.0815978\tvalid_1's rmse: 0.0858522\n",
      "[2725]\ttraining's rmse: 0.081597\tvalid_1's rmse: 0.0858519\n",
      "[2750]\ttraining's rmse: 0.0815955\tvalid_1's rmse: 0.0858518\n",
      "[2775]\ttraining's rmse: 0.0815941\tvalid_1's rmse: 0.0858511\n",
      "[2800]\ttraining's rmse: 0.0815928\tvalid_1's rmse: 0.085851\n",
      "[2825]\ttraining's rmse: 0.08159\tvalid_1's rmse: 0.0858503\n",
      "[2850]\ttraining's rmse: 0.0815883\tvalid_1's rmse: 0.0858498\n",
      "[2875]\ttraining's rmse: 0.0815857\tvalid_1's rmse: 0.0858498\n",
      "[2900]\ttraining's rmse: 0.0815833\tvalid_1's rmse: 0.0858496\n",
      "[2925]\ttraining's rmse: 0.0815823\tvalid_1's rmse: 0.0858491\n",
      "[2950]\ttraining's rmse: 0.0815802\tvalid_1's rmse: 0.0858493\n",
      "[2975]\ttraining's rmse: 0.0815794\tvalid_1's rmse: 0.0858494\n",
      "Early stopping, best iteration is:\n",
      "[2940]\ttraining's rmse: 0.0815812\tvalid_1's rmse: 0.085849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0846166\tvalid_1's rmse: 0.0868529\n",
      "[50]\ttraining's rmse: 0.0844973\tvalid_1's rmse: 0.0867992\n",
      "[75]\ttraining's rmse: 0.0843702\tvalid_1's rmse: 0.0867415\n",
      "[100]\ttraining's rmse: 0.0842582\tvalid_1's rmse: 0.0866933\n",
      "[125]\ttraining's rmse: 0.0841381\tvalid_1's rmse: 0.0866458\n",
      "[150]\ttraining's rmse: 0.0840303\tvalid_1's rmse: 0.0866004\n",
      "[175]\ttraining's rmse: 0.0839425\tvalid_1's rmse: 0.0865617\n",
      "[200]\ttraining's rmse: 0.083847\tvalid_1's rmse: 0.0865238\n",
      "[225]\ttraining's rmse: 0.0837503\tvalid_1's rmse: 0.086488\n",
      "[250]\ttraining's rmse: 0.083669\tvalid_1's rmse: 0.0864544\n",
      "[275]\ttraining's rmse: 0.083597\tvalid_1's rmse: 0.0864251\n",
      "[300]\ttraining's rmse: 0.0835219\tvalid_1's rmse: 0.0863978\n",
      "[325]\ttraining's rmse: 0.0834461\tvalid_1's rmse: 0.0863713\n",
      "[350]\ttraining's rmse: 0.0833735\tvalid_1's rmse: 0.0863464\n",
      "[375]\ttraining's rmse: 0.0833131\tvalid_1's rmse: 0.0863237\n",
      "[400]\ttraining's rmse: 0.0832489\tvalid_1's rmse: 0.0863038\n",
      "[425]\ttraining's rmse: 0.0831915\tvalid_1's rmse: 0.0862818\n",
      "[450]\ttraining's rmse: 0.0831397\tvalid_1's rmse: 0.0862619\n",
      "[475]\ttraining's rmse: 0.0830903\tvalid_1's rmse: 0.0862429\n",
      "[500]\ttraining's rmse: 0.083048\tvalid_1's rmse: 0.0862258\n",
      "[525]\ttraining's rmse: 0.0829907\tvalid_1's rmse: 0.0862089\n",
      "[550]\ttraining's rmse: 0.0829394\tvalid_1's rmse: 0.0861938\n",
      "[575]\ttraining's rmse: 0.0828927\tvalid_1's rmse: 0.08618\n",
      "[600]\ttraining's rmse: 0.0828495\tvalid_1's rmse: 0.0861655\n",
      "[625]\ttraining's rmse: 0.082815\tvalid_1's rmse: 0.0861529\n",
      "[650]\ttraining's rmse: 0.0827723\tvalid_1's rmse: 0.0861412\n",
      "[675]\ttraining's rmse: 0.0827292\tvalid_1's rmse: 0.0861294\n",
      "[700]\ttraining's rmse: 0.0826905\tvalid_1's rmse: 0.086117\n",
      "[725]\ttraining's rmse: 0.0826569\tvalid_1's rmse: 0.0861076\n",
      "[750]\ttraining's rmse: 0.082623\tvalid_1's rmse: 0.0860982\n",
      "[775]\ttraining's rmse: 0.0825926\tvalid_1's rmse: 0.0860872\n",
      "[800]\ttraining's rmse: 0.0825574\tvalid_1's rmse: 0.0860791\n",
      "[825]\ttraining's rmse: 0.082527\tvalid_1's rmse: 0.0860714\n",
      "[850]\ttraining's rmse: 0.0824989\tvalid_1's rmse: 0.0860651\n",
      "[875]\ttraining's rmse: 0.0824712\tvalid_1's rmse: 0.0860577\n",
      "[900]\ttraining's rmse: 0.0824413\tvalid_1's rmse: 0.0860511\n",
      "[925]\ttraining's rmse: 0.0824154\tvalid_1's rmse: 0.0860453\n",
      "[950]\ttraining's rmse: 0.0823913\tvalid_1's rmse: 0.0860388\n",
      "[975]\ttraining's rmse: 0.0823682\tvalid_1's rmse: 0.0860332\n",
      "[1000]\ttraining's rmse: 0.0823465\tvalid_1's rmse: 0.0860278\n",
      "[1025]\ttraining's rmse: 0.0823211\tvalid_1's rmse: 0.0860232\n",
      "[1050]\ttraining's rmse: 0.0822995\tvalid_1's rmse: 0.0860179\n",
      "[1075]\ttraining's rmse: 0.0822784\tvalid_1's rmse: 0.0860141\n",
      "[1100]\ttraining's rmse: 0.0822592\tvalid_1's rmse: 0.0860091\n",
      "[1125]\ttraining's rmse: 0.08224\tvalid_1's rmse: 0.0860054\n",
      "[1150]\ttraining's rmse: 0.0822175\tvalid_1's rmse: 0.0860018\n",
      "[1175]\ttraining's rmse: 0.0822004\tvalid_1's rmse: 0.085999\n",
      "[1200]\ttraining's rmse: 0.0821828\tvalid_1's rmse: 0.0859964\n",
      "[1225]\ttraining's rmse: 0.0821694\tvalid_1's rmse: 0.0859937\n",
      "[1250]\ttraining's rmse: 0.0821541\tvalid_1's rmse: 0.0859903\n",
      "[1275]\ttraining's rmse: 0.0821362\tvalid_1's rmse: 0.0859885\n",
      "[1300]\ttraining's rmse: 0.0821257\tvalid_1's rmse: 0.0859859\n",
      "[1325]\ttraining's rmse: 0.0821111\tvalid_1's rmse: 0.0859831\n",
      "[1350]\ttraining's rmse: 0.0820987\tvalid_1's rmse: 0.0859808\n",
      "[1375]\ttraining's rmse: 0.0820836\tvalid_1's rmse: 0.0859795\n",
      "[1400]\ttraining's rmse: 0.0820723\tvalid_1's rmse: 0.0859766\n",
      "[1425]\ttraining's rmse: 0.082058\tvalid_1's rmse: 0.0859745\n",
      "[1450]\ttraining's rmse: 0.0820463\tvalid_1's rmse: 0.0859736\n",
      "[1475]\ttraining's rmse: 0.0820368\tvalid_1's rmse: 0.0859713\n",
      "[1500]\ttraining's rmse: 0.0820245\tvalid_1's rmse: 0.0859686\n",
      "[1525]\ttraining's rmse: 0.0820142\tvalid_1's rmse: 0.0859674\n",
      "[1550]\ttraining's rmse: 0.0820061\tvalid_1's rmse: 0.0859666\n",
      "[1575]\ttraining's rmse: 0.0819973\tvalid_1's rmse: 0.0859645\n",
      "[1600]\ttraining's rmse: 0.0819883\tvalid_1's rmse: 0.0859641\n",
      "[1625]\ttraining's rmse: 0.0819807\tvalid_1's rmse: 0.0859624\n",
      "[1650]\ttraining's rmse: 0.0819726\tvalid_1's rmse: 0.0859614\n",
      "[1675]\ttraining's rmse: 0.0819661\tvalid_1's rmse: 0.0859599\n",
      "[1700]\ttraining's rmse: 0.0819604\tvalid_1's rmse: 0.0859584\n",
      "[1725]\ttraining's rmse: 0.0819557\tvalid_1's rmse: 0.0859573\n",
      "[1750]\ttraining's rmse: 0.0819474\tvalid_1's rmse: 0.0859567\n",
      "[1775]\ttraining's rmse: 0.0819393\tvalid_1's rmse: 0.0859557\n",
      "[1800]\ttraining's rmse: 0.0819334\tvalid_1's rmse: 0.0859549\n",
      "[1825]\ttraining's rmse: 0.0819266\tvalid_1's rmse: 0.085954\n",
      "[1850]\ttraining's rmse: 0.0819207\tvalid_1's rmse: 0.085953\n",
      "[1875]\ttraining's rmse: 0.0819152\tvalid_1's rmse: 0.0859523\n",
      "[1900]\ttraining's rmse: 0.0819105\tvalid_1's rmse: 0.0859517\n",
      "[1925]\ttraining's rmse: 0.0819053\tvalid_1's rmse: 0.0859512\n",
      "[1950]\ttraining's rmse: 0.0819014\tvalid_1's rmse: 0.0859502\n",
      "[1975]\ttraining's rmse: 0.0818987\tvalid_1's rmse: 0.0859499\n",
      "[2000]\ttraining's rmse: 0.0818961\tvalid_1's rmse: 0.0859495\n",
      "[2025]\ttraining's rmse: 0.0818915\tvalid_1's rmse: 0.0859486\n",
      "[2050]\ttraining's rmse: 0.0818868\tvalid_1's rmse: 0.085948\n",
      "[2075]\ttraining's rmse: 0.0818827\tvalid_1's rmse: 0.0859475\n",
      "[2100]\ttraining's rmse: 0.081878\tvalid_1's rmse: 0.0859474\n",
      "[2125]\ttraining's rmse: 0.0818748\tvalid_1's rmse: 0.0859473\n",
      "[2150]\ttraining's rmse: 0.0818723\tvalid_1's rmse: 0.0859475\n",
      "Early stopping, best iteration is:\n",
      "[2116]\ttraining's rmse: 0.0818762\tvalid_1's rmse: 0.0859472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0866618\tvalid_1's rmse: 0.0826905\n",
      "[50]\ttraining's rmse: 0.0865433\tvalid_1's rmse: 0.0826417\n",
      "[75]\ttraining's rmse: 0.0864155\tvalid_1's rmse: 0.0825925\n",
      "[100]\ttraining's rmse: 0.0863026\tvalid_1's rmse: 0.0825491\n",
      "[125]\ttraining's rmse: 0.0861858\tvalid_1's rmse: 0.0825058\n",
      "[150]\ttraining's rmse: 0.0860763\tvalid_1's rmse: 0.0824654\n",
      "[175]\ttraining's rmse: 0.0859855\tvalid_1's rmse: 0.0824319\n",
      "[200]\ttraining's rmse: 0.0858867\tvalid_1's rmse: 0.0824\n",
      "[225]\ttraining's rmse: 0.0857886\tvalid_1's rmse: 0.0823685\n",
      "[250]\ttraining's rmse: 0.0857094\tvalid_1's rmse: 0.0823416\n",
      "[275]\ttraining's rmse: 0.0856349\tvalid_1's rmse: 0.0823166\n",
      "[300]\ttraining's rmse: 0.0855621\tvalid_1's rmse: 0.0822925\n",
      "[325]\ttraining's rmse: 0.0854845\tvalid_1's rmse: 0.0822704\n",
      "[350]\ttraining's rmse: 0.0854099\tvalid_1's rmse: 0.0822491\n",
      "[375]\ttraining's rmse: 0.0853517\tvalid_1's rmse: 0.0822341\n",
      "[400]\ttraining's rmse: 0.0852848\tvalid_1's rmse: 0.0822167\n",
      "[425]\ttraining's rmse: 0.0852262\tvalid_1's rmse: 0.0822017\n",
      "[450]\ttraining's rmse: 0.0851698\tvalid_1's rmse: 0.0821868\n",
      "[475]\ttraining's rmse: 0.0851192\tvalid_1's rmse: 0.0821755\n",
      "[500]\ttraining's rmse: 0.0850745\tvalid_1's rmse: 0.0821628\n",
      "[525]\ttraining's rmse: 0.0850176\tvalid_1's rmse: 0.0821526\n",
      "[550]\ttraining's rmse: 0.0849667\tvalid_1's rmse: 0.0821418\n",
      "[575]\ttraining's rmse: 0.0849188\tvalid_1's rmse: 0.0821317\n",
      "[600]\ttraining's rmse: 0.084872\tvalid_1's rmse: 0.0821216\n",
      "[625]\ttraining's rmse: 0.0848339\tvalid_1's rmse: 0.0821125\n",
      "[650]\ttraining's rmse: 0.0847874\tvalid_1's rmse: 0.0821075\n",
      "[675]\ttraining's rmse: 0.084742\tvalid_1's rmse: 0.0820993\n",
      "[700]\ttraining's rmse: 0.0847002\tvalid_1's rmse: 0.0820908\n",
      "[725]\ttraining's rmse: 0.0846614\tvalid_1's rmse: 0.0820907\n",
      "[750]\ttraining's rmse: 0.0846259\tvalid_1's rmse: 0.0820874\n",
      "[775]\ttraining's rmse: 0.0845949\tvalid_1's rmse: 0.0820851\n",
      "[800]\ttraining's rmse: 0.0845557\tvalid_1's rmse: 0.0820807\n",
      "[825]\ttraining's rmse: 0.0845246\tvalid_1's rmse: 0.0820849\n",
      "[850]\ttraining's rmse: 0.0844917\tvalid_1's rmse: 0.0820853\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's rmse: 0.0845436\tvalid_1's rmse: 0.0820791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0810584\tvalid_1's rmse: 0.0838367\n",
      "[50]\ttraining's rmse: 0.0809423\tvalid_1's rmse: 0.0837839\n",
      "[75]\ttraining's rmse: 0.0808267\tvalid_1's rmse: 0.0837311\n",
      "[100]\ttraining's rmse: 0.0807159\tvalid_1's rmse: 0.0836842\n",
      "[125]\ttraining's rmse: 0.0806053\tvalid_1's rmse: 0.083637\n",
      "[150]\ttraining's rmse: 0.0805066\tvalid_1's rmse: 0.0835928\n",
      "[175]\ttraining's rmse: 0.0804228\tvalid_1's rmse: 0.0835538\n",
      "[200]\ttraining's rmse: 0.0803343\tvalid_1's rmse: 0.0835165\n",
      "[225]\ttraining's rmse: 0.0802501\tvalid_1's rmse: 0.0834802\n",
      "[250]\ttraining's rmse: 0.0801767\tvalid_1's rmse: 0.0834474\n",
      "[275]\ttraining's rmse: 0.0801061\tvalid_1's rmse: 0.0834172\n",
      "[300]\ttraining's rmse: 0.0800391\tvalid_1's rmse: 0.0833891\n",
      "[325]\ttraining's rmse: 0.0799712\tvalid_1's rmse: 0.0833621\n",
      "[350]\ttraining's rmse: 0.0799065\tvalid_1's rmse: 0.0833358\n",
      "[375]\ttraining's rmse: 0.0798544\tvalid_1's rmse: 0.0833136\n",
      "[400]\ttraining's rmse: 0.0798004\tvalid_1's rmse: 0.0832929\n",
      "[425]\ttraining's rmse: 0.0797512\tvalid_1's rmse: 0.0832734\n",
      "[450]\ttraining's rmse: 0.0797052\tvalid_1's rmse: 0.0832523\n",
      "[475]\ttraining's rmse: 0.0796616\tvalid_1's rmse: 0.0832322\n",
      "[500]\ttraining's rmse: 0.0796241\tvalid_1's rmse: 0.0832145\n",
      "[525]\ttraining's rmse: 0.079577\tvalid_1's rmse: 0.0831988\n",
      "[550]\ttraining's rmse: 0.0795319\tvalid_1's rmse: 0.0831816\n",
      "[575]\ttraining's rmse: 0.0794923\tvalid_1's rmse: 0.0831667\n",
      "[600]\ttraining's rmse: 0.0794535\tvalid_1's rmse: 0.0831514\n",
      "[625]\ttraining's rmse: 0.0794204\tvalid_1's rmse: 0.0831391\n",
      "[650]\ttraining's rmse: 0.0793842\tvalid_1's rmse: 0.0831265\n",
      "[675]\ttraining's rmse: 0.0793484\tvalid_1's rmse: 0.0831129\n",
      "[700]\ttraining's rmse: 0.0793157\tvalid_1's rmse: 0.0831003\n",
      "[725]\ttraining's rmse: 0.0792842\tvalid_1's rmse: 0.0830893\n",
      "[750]\ttraining's rmse: 0.0792545\tvalid_1's rmse: 0.0830802\n",
      "[775]\ttraining's rmse: 0.0792309\tvalid_1's rmse: 0.0830695\n",
      "[800]\ttraining's rmse: 0.0792007\tvalid_1's rmse: 0.0830603\n",
      "[825]\ttraining's rmse: 0.0791749\tvalid_1's rmse: 0.0830505\n",
      "[850]\ttraining's rmse: 0.0791471\tvalid_1's rmse: 0.0830424\n",
      "[875]\ttraining's rmse: 0.0791231\tvalid_1's rmse: 0.0830331\n",
      "[900]\ttraining's rmse: 0.0790961\tvalid_1's rmse: 0.0830258\n",
      "[925]\ttraining's rmse: 0.0790739\tvalid_1's rmse: 0.0830172\n",
      "[950]\ttraining's rmse: 0.0790525\tvalid_1's rmse: 0.0830102\n",
      "[975]\ttraining's rmse: 0.0790301\tvalid_1's rmse: 0.0830033\n",
      "[1000]\ttraining's rmse: 0.0790095\tvalid_1's rmse: 0.0829979\n",
      "[1025]\ttraining's rmse: 0.0789882\tvalid_1's rmse: 0.0829907\n",
      "[1050]\ttraining's rmse: 0.0789697\tvalid_1's rmse: 0.0829841\n",
      "[1075]\ttraining's rmse: 0.0789512\tvalid_1's rmse: 0.0829807\n",
      "[1100]\ttraining's rmse: 0.0789343\tvalid_1's rmse: 0.0829751\n",
      "[1125]\ttraining's rmse: 0.0789196\tvalid_1's rmse: 0.0829687\n",
      "[1150]\ttraining's rmse: 0.0789058\tvalid_1's rmse: 0.0829648\n",
      "[1175]\ttraining's rmse: 0.0788898\tvalid_1's rmse: 0.0829614\n",
      "[1200]\ttraining's rmse: 0.0788758\tvalid_1's rmse: 0.0829547\n",
      "[1225]\ttraining's rmse: 0.0788625\tvalid_1's rmse: 0.0829511\n",
      "[1250]\ttraining's rmse: 0.0788485\tvalid_1's rmse: 0.0829463\n",
      "[1275]\ttraining's rmse: 0.0788335\tvalid_1's rmse: 0.0829408\n",
      "[1300]\ttraining's rmse: 0.0788218\tvalid_1's rmse: 0.0829362\n",
      "[1325]\ttraining's rmse: 0.078809\tvalid_1's rmse: 0.0829324\n",
      "[1350]\ttraining's rmse: 0.0787947\tvalid_1's rmse: 0.0829304\n",
      "[1375]\ttraining's rmse: 0.0787816\tvalid_1's rmse: 0.0829273\n",
      "[1400]\ttraining's rmse: 0.0787735\tvalid_1's rmse: 0.0829243\n",
      "[1425]\ttraining's rmse: 0.0787629\tvalid_1's rmse: 0.0829222\n",
      "[1450]\ttraining's rmse: 0.0787516\tvalid_1's rmse: 0.0829196\n",
      "[1475]\ttraining's rmse: 0.0787417\tvalid_1's rmse: 0.0829179\n",
      "[1500]\ttraining's rmse: 0.0787336\tvalid_1's rmse: 0.0829159\n",
      "[1525]\ttraining's rmse: 0.0787262\tvalid_1's rmse: 0.0829126\n",
      "[1550]\ttraining's rmse: 0.0787177\tvalid_1's rmse: 0.0829098\n",
      "[1575]\ttraining's rmse: 0.0787102\tvalid_1's rmse: 0.0829075\n",
      "[1600]\ttraining's rmse: 0.0787036\tvalid_1's rmse: 0.082906\n",
      "[1625]\ttraining's rmse: 0.0786969\tvalid_1's rmse: 0.0829023\n",
      "[1650]\ttraining's rmse: 0.078691\tvalid_1's rmse: 0.082899\n",
      "[1675]\ttraining's rmse: 0.0786859\tvalid_1's rmse: 0.0828962\n",
      "[1700]\ttraining's rmse: 0.0786806\tvalid_1's rmse: 0.0828928\n",
      "[1725]\ttraining's rmse: 0.0786747\tvalid_1's rmse: 0.0828907\n",
      "[1750]\ttraining's rmse: 0.0786676\tvalid_1's rmse: 0.0828895\n",
      "[1775]\ttraining's rmse: 0.0786621\tvalid_1's rmse: 0.0828883\n",
      "[1800]\ttraining's rmse: 0.0786574\tvalid_1's rmse: 0.0828878\n",
      "[1825]\ttraining's rmse: 0.0786528\tvalid_1's rmse: 0.0828862\n",
      "[1850]\ttraining's rmse: 0.0786481\tvalid_1's rmse: 0.0828854\n",
      "[1875]\ttraining's rmse: 0.0786448\tvalid_1's rmse: 0.0828835\n",
      "[1900]\ttraining's rmse: 0.0786402\tvalid_1's rmse: 0.0828826\n",
      "[1925]\ttraining's rmse: 0.0786355\tvalid_1's rmse: 0.0828813\n",
      "[1950]\ttraining's rmse: 0.0786326\tvalid_1's rmse: 0.08288\n",
      "[1975]\ttraining's rmse: 0.078629\tvalid_1's rmse: 0.0828792\n",
      "[2000]\ttraining's rmse: 0.0786259\tvalid_1's rmse: 0.0828786\n",
      "[2025]\ttraining's rmse: 0.0786228\tvalid_1's rmse: 0.0828766\n",
      "[2050]\ttraining's rmse: 0.0786197\tvalid_1's rmse: 0.0828747\n",
      "[2075]\ttraining's rmse: 0.0786172\tvalid_1's rmse: 0.0828734\n",
      "[2100]\ttraining's rmse: 0.0786132\tvalid_1's rmse: 0.0828728\n",
      "[2125]\ttraining's rmse: 0.0786106\tvalid_1's rmse: 0.0828716\n",
      "[2150]\ttraining's rmse: 0.0786074\tvalid_1's rmse: 0.0828708\n",
      "[2175]\ttraining's rmse: 0.0786051\tvalid_1's rmse: 0.0828698\n",
      "[2200]\ttraining's rmse: 0.0786029\tvalid_1's rmse: 0.0828692\n",
      "[2225]\ttraining's rmse: 0.0785998\tvalid_1's rmse: 0.0828674\n",
      "[2250]\ttraining's rmse: 0.0785967\tvalid_1's rmse: 0.0828668\n",
      "[2275]\ttraining's rmse: 0.0785928\tvalid_1's rmse: 0.0828658\n",
      "[2300]\ttraining's rmse: 0.0785906\tvalid_1's rmse: 0.0828651\n",
      "[2325]\ttraining's rmse: 0.0785872\tvalid_1's rmse: 0.0828647\n",
      "[2350]\ttraining's rmse: 0.0785854\tvalid_1's rmse: 0.0828645\n",
      "[2375]\ttraining's rmse: 0.0785834\tvalid_1's rmse: 0.0828644\n",
      "[2400]\ttraining's rmse: 0.0785816\tvalid_1's rmse: 0.0828639\n",
      "[2425]\ttraining's rmse: 0.0785797\tvalid_1's rmse: 0.0828638\n",
      "[2450]\ttraining's rmse: 0.0785784\tvalid_1's rmse: 0.0828636\n",
      "[2475]\ttraining's rmse: 0.0785763\tvalid_1's rmse: 0.0828639\n",
      "[2500]\ttraining's rmse: 0.0785744\tvalid_1's rmse: 0.0828631\n",
      "[2525]\ttraining's rmse: 0.0785716\tvalid_1's rmse: 0.0828619\n",
      "[2550]\ttraining's rmse: 0.0785691\tvalid_1's rmse: 0.0828621\n",
      "[2575]\ttraining's rmse: 0.0785671\tvalid_1's rmse: 0.0828611\n",
      "[2600]\ttraining's rmse: 0.078565\tvalid_1's rmse: 0.082861\n",
      "[2625]\ttraining's rmse: 0.0785637\tvalid_1's rmse: 0.0828605\n",
      "[2650]\ttraining's rmse: 0.0785623\tvalid_1's rmse: 0.0828598\n",
      "[2675]\ttraining's rmse: 0.0785606\tvalid_1's rmse: 0.0828599\n",
      "[2700]\ttraining's rmse: 0.0785593\tvalid_1's rmse: 0.0828593\n",
      "[2725]\ttraining's rmse: 0.0785576\tvalid_1's rmse: 0.0828597\n",
      "[2750]\ttraining's rmse: 0.0785562\tvalid_1's rmse: 0.0828597\n",
      "Early stopping, best iteration is:\n",
      "[2700]\ttraining's rmse: 0.0785593\tvalid_1's rmse: 0.0828593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0813445\tvalid_1's rmse: 0.083274\n",
      "[50]\ttraining's rmse: 0.08123\tvalid_1's rmse: 0.0832182\n",
      "[75]\ttraining's rmse: 0.0811126\tvalid_1's rmse: 0.0831644\n",
      "[100]\ttraining's rmse: 0.0810089\tvalid_1's rmse: 0.0831183\n",
      "[125]\ttraining's rmse: 0.0809009\tvalid_1's rmse: 0.0830698\n",
      "[150]\ttraining's rmse: 0.0808049\tvalid_1's rmse: 0.0830267\n",
      "[175]\ttraining's rmse: 0.0807207\tvalid_1's rmse: 0.0829902\n",
      "[200]\ttraining's rmse: 0.0806277\tvalid_1's rmse: 0.0829535\n",
      "[225]\ttraining's rmse: 0.0805417\tvalid_1's rmse: 0.0829193\n",
      "[250]\ttraining's rmse: 0.0804696\tvalid_1's rmse: 0.0828887\n",
      "[275]\ttraining's rmse: 0.0804004\tvalid_1's rmse: 0.082859\n",
      "[300]\ttraining's rmse: 0.0803313\tvalid_1's rmse: 0.0828322\n",
      "[325]\ttraining's rmse: 0.0802615\tvalid_1's rmse: 0.0828071\n",
      "[350]\ttraining's rmse: 0.0801946\tvalid_1's rmse: 0.0827833\n",
      "[375]\ttraining's rmse: 0.0801399\tvalid_1's rmse: 0.0827621\n",
      "[400]\ttraining's rmse: 0.0800807\tvalid_1's rmse: 0.0827418\n",
      "[425]\ttraining's rmse: 0.0800264\tvalid_1's rmse: 0.0827224\n",
      "[450]\ttraining's rmse: 0.0799781\tvalid_1's rmse: 0.0827049\n",
      "[475]\ttraining's rmse: 0.0799311\tvalid_1's rmse: 0.0826878\n",
      "[500]\ttraining's rmse: 0.0798915\tvalid_1's rmse: 0.0826726\n",
      "[525]\ttraining's rmse: 0.0798417\tvalid_1's rmse: 0.0826575\n",
      "[550]\ttraining's rmse: 0.0797945\tvalid_1's rmse: 0.0826431\n",
      "[575]\ttraining's rmse: 0.0797528\tvalid_1's rmse: 0.0826298\n",
      "[600]\ttraining's rmse: 0.0797108\tvalid_1's rmse: 0.0826167\n",
      "[625]\ttraining's rmse: 0.0796779\tvalid_1's rmse: 0.0826051\n",
      "[650]\ttraining's rmse: 0.0796372\tvalid_1's rmse: 0.0825929\n",
      "[675]\ttraining's rmse: 0.0795946\tvalid_1's rmse: 0.0825813\n",
      "[700]\ttraining's rmse: 0.0795584\tvalid_1's rmse: 0.0825706\n",
      "[725]\ttraining's rmse: 0.0795255\tvalid_1's rmse: 0.0825615\n",
      "[750]\ttraining's rmse: 0.0794941\tvalid_1's rmse: 0.0825537\n",
      "[775]\ttraining's rmse: 0.0794689\tvalid_1's rmse: 0.082546\n",
      "[800]\ttraining's rmse: 0.0794365\tvalid_1's rmse: 0.0825384\n",
      "[825]\ttraining's rmse: 0.0794096\tvalid_1's rmse: 0.0825311\n",
      "[850]\ttraining's rmse: 0.079381\tvalid_1's rmse: 0.082525\n",
      "[875]\ttraining's rmse: 0.079355\tvalid_1's rmse: 0.0825193\n",
      "[900]\ttraining's rmse: 0.0793285\tvalid_1's rmse: 0.082513\n",
      "[925]\ttraining's rmse: 0.0793026\tvalid_1's rmse: 0.0825076\n",
      "[950]\ttraining's rmse: 0.0792774\tvalid_1's rmse: 0.0825015\n",
      "[975]\ttraining's rmse: 0.0792555\tvalid_1's rmse: 0.0824959\n",
      "[1000]\ttraining's rmse: 0.0792363\tvalid_1's rmse: 0.082491\n",
      "[1025]\ttraining's rmse: 0.0792133\tvalid_1's rmse: 0.0824868\n",
      "[1050]\ttraining's rmse: 0.0791939\tvalid_1's rmse: 0.0824824\n",
      "[1075]\ttraining's rmse: 0.0791747\tvalid_1's rmse: 0.082479\n",
      "[1100]\ttraining's rmse: 0.0791612\tvalid_1's rmse: 0.082476\n",
      "[1125]\ttraining's rmse: 0.0791431\tvalid_1's rmse: 0.0824729\n",
      "[1150]\ttraining's rmse: 0.079125\tvalid_1's rmse: 0.0824688\n",
      "[1175]\ttraining's rmse: 0.0791108\tvalid_1's rmse: 0.0824662\n",
      "[1200]\ttraining's rmse: 0.0790949\tvalid_1's rmse: 0.0824631\n",
      "[1225]\ttraining's rmse: 0.0790806\tvalid_1's rmse: 0.0824605\n",
      "[1250]\ttraining's rmse: 0.0790661\tvalid_1's rmse: 0.0824578\n",
      "[1275]\ttraining's rmse: 0.0790494\tvalid_1's rmse: 0.082455\n",
      "[1300]\ttraining's rmse: 0.0790394\tvalid_1's rmse: 0.0824529\n",
      "[1325]\ttraining's rmse: 0.0790274\tvalid_1's rmse: 0.0824512\n",
      "[1350]\ttraining's rmse: 0.079013\tvalid_1's rmse: 0.0824494\n",
      "[1375]\ttraining's rmse: 0.0790023\tvalid_1's rmse: 0.0824477\n",
      "[1400]\ttraining's rmse: 0.0789938\tvalid_1's rmse: 0.0824456\n",
      "[1425]\ttraining's rmse: 0.0789834\tvalid_1's rmse: 0.0824441\n",
      "[1450]\ttraining's rmse: 0.0789726\tvalid_1's rmse: 0.0824431\n",
      "[1475]\ttraining's rmse: 0.0789618\tvalid_1's rmse: 0.0824418\n",
      "[1500]\ttraining's rmse: 0.078954\tvalid_1's rmse: 0.0824406\n",
      "[1525]\ttraining's rmse: 0.078946\tvalid_1's rmse: 0.0824394\n",
      "[1550]\ttraining's rmse: 0.0789369\tvalid_1's rmse: 0.0824388\n",
      "[1575]\ttraining's rmse: 0.0789296\tvalid_1's rmse: 0.0824376\n",
      "[1600]\ttraining's rmse: 0.0789236\tvalid_1's rmse: 0.0824368\n",
      "[1625]\ttraining's rmse: 0.078917\tvalid_1's rmse: 0.0824358\n",
      "[1650]\ttraining's rmse: 0.0789104\tvalid_1's rmse: 0.0824346\n",
      "[1675]\ttraining's rmse: 0.0789046\tvalid_1's rmse: 0.0824339\n",
      "[1700]\ttraining's rmse: 0.0788988\tvalid_1's rmse: 0.0824328\n",
      "[1725]\ttraining's rmse: 0.0788928\tvalid_1's rmse: 0.0824319\n",
      "[1750]\ttraining's rmse: 0.0788842\tvalid_1's rmse: 0.0824311\n",
      "[1775]\ttraining's rmse: 0.0788791\tvalid_1's rmse: 0.0824307\n",
      "[1800]\ttraining's rmse: 0.0788734\tvalid_1's rmse: 0.08243\n",
      "[1825]\ttraining's rmse: 0.0788669\tvalid_1's rmse: 0.0824292\n",
      "[1850]\ttraining's rmse: 0.0788624\tvalid_1's rmse: 0.0824285\n",
      "[1875]\ttraining's rmse: 0.0788576\tvalid_1's rmse: 0.0824285\n",
      "[1900]\ttraining's rmse: 0.0788541\tvalid_1's rmse: 0.0824283\n",
      "[1925]\ttraining's rmse: 0.0788494\tvalid_1's rmse: 0.0824277\n",
      "[1950]\ttraining's rmse: 0.0788468\tvalid_1's rmse: 0.0824269\n",
      "[1975]\ttraining's rmse: 0.0788441\tvalid_1's rmse: 0.0824263\n",
      "[2000]\ttraining's rmse: 0.0788401\tvalid_1's rmse: 0.0824262\n",
      "[2025]\ttraining's rmse: 0.0788364\tvalid_1's rmse: 0.0824258\n",
      "[2050]\ttraining's rmse: 0.078832\tvalid_1's rmse: 0.0824249\n",
      "[2075]\ttraining's rmse: 0.0788281\tvalid_1's rmse: 0.0824244\n",
      "[2100]\ttraining's rmse: 0.0788245\tvalid_1's rmse: 0.0824243\n",
      "[2125]\ttraining's rmse: 0.0788201\tvalid_1's rmse: 0.0824239\n",
      "[2150]\ttraining's rmse: 0.0788167\tvalid_1's rmse: 0.0824238\n",
      "[2175]\ttraining's rmse: 0.0788132\tvalid_1's rmse: 0.0824239\n",
      "Early stopping, best iteration is:\n",
      "[2134]\ttraining's rmse: 0.0788186\tvalid_1's rmse: 0.0824236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.083438\tvalid_1's rmse: 0.0790126\n",
      "[50]\ttraining's rmse: 0.0833256\tvalid_1's rmse: 0.0789649\n",
      "[75]\ttraining's rmse: 0.0832093\tvalid_1's rmse: 0.0789187\n",
      "[100]\ttraining's rmse: 0.083109\tvalid_1's rmse: 0.0788786\n",
      "[125]\ttraining's rmse: 0.0830034\tvalid_1's rmse: 0.0788377\n",
      "[150]\ttraining's rmse: 0.0829068\tvalid_1's rmse: 0.078802\n",
      "[175]\ttraining's rmse: 0.082827\tvalid_1's rmse: 0.0787725\n",
      "[200]\ttraining's rmse: 0.0827406\tvalid_1's rmse: 0.0787415\n",
      "[225]\ttraining's rmse: 0.0826584\tvalid_1's rmse: 0.0787107\n",
      "[250]\ttraining's rmse: 0.0825885\tvalid_1's rmse: 0.078685\n",
      "[275]\ttraining's rmse: 0.0825258\tvalid_1's rmse: 0.0786606\n",
      "[300]\ttraining's rmse: 0.0824625\tvalid_1's rmse: 0.0786364\n",
      "[325]\ttraining's rmse: 0.0823993\tvalid_1's rmse: 0.078615\n",
      "[350]\ttraining's rmse: 0.0823357\tvalid_1's rmse: 0.0785925\n",
      "[375]\ttraining's rmse: 0.0822834\tvalid_1's rmse: 0.078576\n",
      "[400]\ttraining's rmse: 0.0822268\tvalid_1's rmse: 0.0785649\n",
      "[425]\ttraining's rmse: 0.0821742\tvalid_1's rmse: 0.0785543\n",
      "[450]\ttraining's rmse: 0.0821281\tvalid_1's rmse: 0.0785385\n",
      "[475]\ttraining's rmse: 0.0820822\tvalid_1's rmse: 0.0785305\n",
      "[500]\ttraining's rmse: 0.0820437\tvalid_1's rmse: 0.0785172\n",
      "[525]\ttraining's rmse: 0.0819946\tvalid_1's rmse: 0.0785036\n",
      "[550]\ttraining's rmse: 0.0819523\tvalid_1's rmse: 0.0784897\n",
      "[575]\ttraining's rmse: 0.0819113\tvalid_1's rmse: 0.07848\n",
      "[600]\ttraining's rmse: 0.081867\tvalid_1's rmse: 0.0784768\n",
      "[625]\ttraining's rmse: 0.0818355\tvalid_1's rmse: 0.0784751\n",
      "[650]\ttraining's rmse: 0.0817942\tvalid_1's rmse: 0.0784845\n",
      "[675]\ttraining's rmse: 0.0817523\tvalid_1's rmse: 0.0784882\n",
      "Early stopping, best iteration is:\n",
      "[627]\ttraining's rmse: 0.0818333\tvalid_1's rmse: 0.0784746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0857373\tvalid_1's rmse: 0.0875481\n",
      "[50]\ttraining's rmse: 0.0855968\tvalid_1's rmse: 0.087498\n",
      "[75]\ttraining's rmse: 0.0854563\tvalid_1's rmse: 0.0874473\n",
      "[100]\ttraining's rmse: 0.0853207\tvalid_1's rmse: 0.087399\n",
      "[125]\ttraining's rmse: 0.0851873\tvalid_1's rmse: 0.087353\n",
      "[150]\ttraining's rmse: 0.0850675\tvalid_1's rmse: 0.0873119\n",
      "[175]\ttraining's rmse: 0.0849646\tvalid_1's rmse: 0.0872755\n",
      "[200]\ttraining's rmse: 0.0848521\tvalid_1's rmse: 0.0872388\n",
      "[225]\ttraining's rmse: 0.0847415\tvalid_1's rmse: 0.0872042\n",
      "[250]\ttraining's rmse: 0.084649\tvalid_1's rmse: 0.0871723\n",
      "[275]\ttraining's rmse: 0.0845651\tvalid_1's rmse: 0.0871447\n",
      "[300]\ttraining's rmse: 0.0844827\tvalid_1's rmse: 0.0871182\n",
      "[325]\ttraining's rmse: 0.0844014\tvalid_1's rmse: 0.087094\n",
      "[350]\ttraining's rmse: 0.0843213\tvalid_1's rmse: 0.0870701\n",
      "[375]\ttraining's rmse: 0.0842525\tvalid_1's rmse: 0.0870507\n",
      "[400]\ttraining's rmse: 0.084183\tvalid_1's rmse: 0.0870302\n",
      "[425]\ttraining's rmse: 0.0841179\tvalid_1's rmse: 0.0870108\n",
      "[450]\ttraining's rmse: 0.0840535\tvalid_1's rmse: 0.0869922\n",
      "[475]\ttraining's rmse: 0.0839958\tvalid_1's rmse: 0.086976\n",
      "[500]\ttraining's rmse: 0.0839488\tvalid_1's rmse: 0.0869625\n",
      "[525]\ttraining's rmse: 0.0838871\tvalid_1's rmse: 0.0869458\n",
      "[550]\ttraining's rmse: 0.0838312\tvalid_1's rmse: 0.086931\n",
      "[575]\ttraining's rmse: 0.0837763\tvalid_1's rmse: 0.0869184\n",
      "[600]\ttraining's rmse: 0.0837255\tvalid_1's rmse: 0.0869066\n",
      "[625]\ttraining's rmse: 0.083688\tvalid_1's rmse: 0.0868941\n",
      "[650]\ttraining's rmse: 0.0836405\tvalid_1's rmse: 0.0868819\n",
      "[675]\ttraining's rmse: 0.0835932\tvalid_1's rmse: 0.08687\n",
      "[700]\ttraining's rmse: 0.0835551\tvalid_1's rmse: 0.0868599\n",
      "[725]\ttraining's rmse: 0.0835141\tvalid_1's rmse: 0.086851\n",
      "[750]\ttraining's rmse: 0.0834771\tvalid_1's rmse: 0.0868422\n",
      "[775]\ttraining's rmse: 0.0834451\tvalid_1's rmse: 0.0868339\n",
      "[800]\ttraining's rmse: 0.0834075\tvalid_1's rmse: 0.0868254\n",
      "[825]\ttraining's rmse: 0.0833776\tvalid_1's rmse: 0.086817\n",
      "[850]\ttraining's rmse: 0.0833436\tvalid_1's rmse: 0.0868092\n",
      "[875]\ttraining's rmse: 0.0833139\tvalid_1's rmse: 0.0868023\n",
      "[900]\ttraining's rmse: 0.0832773\tvalid_1's rmse: 0.0867941\n",
      "[925]\ttraining's rmse: 0.0832457\tvalid_1's rmse: 0.0867867\n",
      "[950]\ttraining's rmse: 0.083217\tvalid_1's rmse: 0.0867796\n",
      "[975]\ttraining's rmse: 0.0831933\tvalid_1's rmse: 0.0867735\n",
      "[1000]\ttraining's rmse: 0.0831684\tvalid_1's rmse: 0.0867682\n",
      "[1025]\ttraining's rmse: 0.0831401\tvalid_1's rmse: 0.0867628\n",
      "[1050]\ttraining's rmse: 0.0831165\tvalid_1's rmse: 0.0867553\n",
      "[1075]\ttraining's rmse: 0.0830934\tvalid_1's rmse: 0.0867526\n",
      "[1100]\ttraining's rmse: 0.0830727\tvalid_1's rmse: 0.0867476\n",
      "[1125]\ttraining's rmse: 0.083051\tvalid_1's rmse: 0.0867426\n",
      "[1150]\ttraining's rmse: 0.0830243\tvalid_1's rmse: 0.0867385\n",
      "[1175]\ttraining's rmse: 0.083006\tvalid_1's rmse: 0.0867354\n",
      "[1200]\ttraining's rmse: 0.0829894\tvalid_1's rmse: 0.086732\n",
      "[1225]\ttraining's rmse: 0.0829717\tvalid_1's rmse: 0.0867281\n",
      "[1250]\ttraining's rmse: 0.0829563\tvalid_1's rmse: 0.0867242\n",
      "[1275]\ttraining's rmse: 0.0829382\tvalid_1's rmse: 0.0867202\n",
      "[1300]\ttraining's rmse: 0.0829237\tvalid_1's rmse: 0.0867153\n",
      "[1325]\ttraining's rmse: 0.0829072\tvalid_1's rmse: 0.0867123\n",
      "[1350]\ttraining's rmse: 0.0828902\tvalid_1's rmse: 0.0867093\n",
      "[1375]\ttraining's rmse: 0.0828771\tvalid_1's rmse: 0.0867064\n",
      "[1400]\ttraining's rmse: 0.0828653\tvalid_1's rmse: 0.0867049\n",
      "[1425]\ttraining's rmse: 0.0828488\tvalid_1's rmse: 0.0867024\n",
      "[1450]\ttraining's rmse: 0.0828357\tvalid_1's rmse: 0.086699\n",
      "[1475]\ttraining's rmse: 0.0828239\tvalid_1's rmse: 0.0866956\n",
      "[1500]\ttraining's rmse: 0.0828155\tvalid_1's rmse: 0.0866937\n",
      "[1525]\ttraining's rmse: 0.082806\tvalid_1's rmse: 0.086692\n",
      "[1550]\ttraining's rmse: 0.0827972\tvalid_1's rmse: 0.0866899\n",
      "[1575]\ttraining's rmse: 0.0827879\tvalid_1's rmse: 0.0866869\n",
      "[1600]\ttraining's rmse: 0.0827789\tvalid_1's rmse: 0.0866856\n",
      "[1625]\ttraining's rmse: 0.0827692\tvalid_1's rmse: 0.0866825\n",
      "[1650]\ttraining's rmse: 0.0827607\tvalid_1's rmse: 0.0866796\n",
      "[1675]\ttraining's rmse: 0.0827535\tvalid_1's rmse: 0.0866774\n",
      "[1700]\ttraining's rmse: 0.0827471\tvalid_1's rmse: 0.0866758\n",
      "[1725]\ttraining's rmse: 0.08274\tvalid_1's rmse: 0.0866742\n",
      "[1750]\ttraining's rmse: 0.0827329\tvalid_1's rmse: 0.0866713\n",
      "[1775]\ttraining's rmse: 0.0827262\tvalid_1's rmse: 0.0866686\n",
      "[1800]\ttraining's rmse: 0.0827198\tvalid_1's rmse: 0.0866665\n",
      "[1825]\ttraining's rmse: 0.0827151\tvalid_1's rmse: 0.0866648\n",
      "[1850]\ttraining's rmse: 0.0827098\tvalid_1's rmse: 0.0866632\n",
      "[1875]\ttraining's rmse: 0.0827041\tvalid_1's rmse: 0.0866615\n",
      "[1900]\ttraining's rmse: 0.0826981\tvalid_1's rmse: 0.0866606\n",
      "[1925]\ttraining's rmse: 0.0826914\tvalid_1's rmse: 0.0866592\n",
      "[1950]\ttraining's rmse: 0.0826877\tvalid_1's rmse: 0.0866568\n",
      "[1975]\ttraining's rmse: 0.0826836\tvalid_1's rmse: 0.0866562\n",
      "[2000]\ttraining's rmse: 0.0826798\tvalid_1's rmse: 0.0866558\n",
      "[2025]\ttraining's rmse: 0.082676\tvalid_1's rmse: 0.0866536\n",
      "[2050]\ttraining's rmse: 0.0826717\tvalid_1's rmse: 0.0866525\n",
      "[2075]\ttraining's rmse: 0.0826674\tvalid_1's rmse: 0.0866511\n",
      "[2100]\ttraining's rmse: 0.0826632\tvalid_1's rmse: 0.0866503\n",
      "[2125]\ttraining's rmse: 0.0826608\tvalid_1's rmse: 0.086649\n",
      "[2150]\ttraining's rmse: 0.0826556\tvalid_1's rmse: 0.0866484\n",
      "[2175]\ttraining's rmse: 0.0826518\tvalid_1's rmse: 0.0866471\n",
      "[2200]\ttraining's rmse: 0.0826484\tvalid_1's rmse: 0.0866467\n",
      "[2225]\ttraining's rmse: 0.0826449\tvalid_1's rmse: 0.0866451\n",
      "[2250]\ttraining's rmse: 0.0826412\tvalid_1's rmse: 0.0866445\n",
      "[2275]\ttraining's rmse: 0.0826376\tvalid_1's rmse: 0.0866435\n",
      "[2300]\ttraining's rmse: 0.0826342\tvalid_1's rmse: 0.0866429\n",
      "[2325]\ttraining's rmse: 0.0826302\tvalid_1's rmse: 0.0866425\n",
      "[2350]\ttraining's rmse: 0.0826289\tvalid_1's rmse: 0.086642\n",
      "[2375]\ttraining's rmse: 0.082624\tvalid_1's rmse: 0.0866401\n",
      "[2400]\ttraining's rmse: 0.0826208\tvalid_1's rmse: 0.0866391\n",
      "[2425]\ttraining's rmse: 0.0826181\tvalid_1's rmse: 0.0866378\n",
      "[2450]\ttraining's rmse: 0.0826165\tvalid_1's rmse: 0.0866378\n",
      "[2475]\ttraining's rmse: 0.0826127\tvalid_1's rmse: 0.0866377\n",
      "[2500]\ttraining's rmse: 0.0826089\tvalid_1's rmse: 0.0866374\n",
      "[2525]\ttraining's rmse: 0.0826064\tvalid_1's rmse: 0.086637\n",
      "[2550]\ttraining's rmse: 0.0826044\tvalid_1's rmse: 0.0866369\n",
      "[2575]\ttraining's rmse: 0.0826015\tvalid_1's rmse: 0.0866366\n",
      "[2600]\ttraining's rmse: 0.0825993\tvalid_1's rmse: 0.0866364\n",
      "[2625]\ttraining's rmse: 0.0825976\tvalid_1's rmse: 0.0866363\n",
      "[2650]\ttraining's rmse: 0.0825954\tvalid_1's rmse: 0.0866355\n",
      "[2675]\ttraining's rmse: 0.0825936\tvalid_1's rmse: 0.0866345\n",
      "[2700]\ttraining's rmse: 0.082592\tvalid_1's rmse: 0.0866344\n",
      "[2725]\ttraining's rmse: 0.0825894\tvalid_1's rmse: 0.0866344\n",
      "[2750]\ttraining's rmse: 0.0825869\tvalid_1's rmse: 0.0866342\n",
      "[2775]\ttraining's rmse: 0.082585\tvalid_1's rmse: 0.0866341\n",
      "[2800]\ttraining's rmse: 0.0825836\tvalid_1's rmse: 0.0866334\n",
      "[2825]\ttraining's rmse: 0.0825809\tvalid_1's rmse: 0.086633\n",
      "[2850]\ttraining's rmse: 0.0825789\tvalid_1's rmse: 0.0866327\n",
      "[2875]\ttraining's rmse: 0.0825777\tvalid_1's rmse: 0.0866322\n",
      "[2900]\ttraining's rmse: 0.0825765\tvalid_1's rmse: 0.086632\n",
      "[2925]\ttraining's rmse: 0.0825747\tvalid_1's rmse: 0.0866319\n",
      "[2950]\ttraining's rmse: 0.0825723\tvalid_1's rmse: 0.0866317\n",
      "[2975]\ttraining's rmse: 0.0825708\tvalid_1's rmse: 0.0866314\n",
      "[3000]\ttraining's rmse: 0.0825686\tvalid_1's rmse: 0.086631\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0825686\tvalid_1's rmse: 0.086631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0856457\tvalid_1's rmse: 0.0877573\n",
      "[50]\ttraining's rmse: 0.0855202\tvalid_1's rmse: 0.0877024\n",
      "[75]\ttraining's rmse: 0.0853906\tvalid_1's rmse: 0.0876482\n",
      "[100]\ttraining's rmse: 0.0852765\tvalid_1's rmse: 0.0876004\n",
      "[125]\ttraining's rmse: 0.0851554\tvalid_1's rmse: 0.0875523\n",
      "[150]\ttraining's rmse: 0.0850455\tvalid_1's rmse: 0.0875058\n",
      "[175]\ttraining's rmse: 0.0849562\tvalid_1's rmse: 0.0874679\n",
      "[200]\ttraining's rmse: 0.084858\tvalid_1's rmse: 0.0874301\n",
      "[225]\ttraining's rmse: 0.0847613\tvalid_1's rmse: 0.0873937\n",
      "[250]\ttraining's rmse: 0.0846797\tvalid_1's rmse: 0.0873598\n",
      "[275]\ttraining's rmse: 0.0846054\tvalid_1's rmse: 0.0873296\n",
      "[300]\ttraining's rmse: 0.0845318\tvalid_1's rmse: 0.0873023\n",
      "[325]\ttraining's rmse: 0.0844528\tvalid_1's rmse: 0.0872751\n",
      "[350]\ttraining's rmse: 0.0843798\tvalid_1's rmse: 0.087248\n",
      "[375]\ttraining's rmse: 0.084321\tvalid_1's rmse: 0.0872268\n",
      "[400]\ttraining's rmse: 0.0842546\tvalid_1's rmse: 0.0872066\n",
      "[425]\ttraining's rmse: 0.0841919\tvalid_1's rmse: 0.0871859\n",
      "[450]\ttraining's rmse: 0.0841368\tvalid_1's rmse: 0.087166\n",
      "[475]\ttraining's rmse: 0.0840867\tvalid_1's rmse: 0.0871479\n",
      "[500]\ttraining's rmse: 0.084045\tvalid_1's rmse: 0.0871303\n",
      "[525]\ttraining's rmse: 0.0839889\tvalid_1's rmse: 0.0871137\n",
      "[550]\ttraining's rmse: 0.0839354\tvalid_1's rmse: 0.0870993\n",
      "[575]\ttraining's rmse: 0.0838886\tvalid_1's rmse: 0.0870849\n",
      "[600]\ttraining's rmse: 0.0838418\tvalid_1's rmse: 0.0870702\n",
      "[625]\ttraining's rmse: 0.0838063\tvalid_1's rmse: 0.0870579\n",
      "[650]\ttraining's rmse: 0.0837628\tvalid_1's rmse: 0.0870454\n",
      "[675]\ttraining's rmse: 0.0837186\tvalid_1's rmse: 0.0870333\n",
      "[700]\ttraining's rmse: 0.0836796\tvalid_1's rmse: 0.0870222\n",
      "[725]\ttraining's rmse: 0.0836428\tvalid_1's rmse: 0.0870125\n",
      "[750]\ttraining's rmse: 0.0836054\tvalid_1's rmse: 0.0870024\n",
      "[775]\ttraining's rmse: 0.0835766\tvalid_1's rmse: 0.0869926\n",
      "[800]\ttraining's rmse: 0.0835421\tvalid_1's rmse: 0.0869851\n",
      "[825]\ttraining's rmse: 0.0835115\tvalid_1's rmse: 0.086976\n",
      "[850]\ttraining's rmse: 0.0834784\tvalid_1's rmse: 0.0869687\n",
      "[875]\ttraining's rmse: 0.0834509\tvalid_1's rmse: 0.0869617\n",
      "[900]\ttraining's rmse: 0.0834208\tvalid_1's rmse: 0.0869546\n",
      "[925]\ttraining's rmse: 0.0833937\tvalid_1's rmse: 0.0869487\n",
      "[950]\ttraining's rmse: 0.0833687\tvalid_1's rmse: 0.0869431\n",
      "[975]\ttraining's rmse: 0.0833448\tvalid_1's rmse: 0.0869376\n",
      "[1000]\ttraining's rmse: 0.0833209\tvalid_1's rmse: 0.0869326\n",
      "[1025]\ttraining's rmse: 0.0832933\tvalid_1's rmse: 0.0869262\n",
      "[1050]\ttraining's rmse: 0.0832721\tvalid_1's rmse: 0.0869207\n",
      "[1075]\ttraining's rmse: 0.0832504\tvalid_1's rmse: 0.0869168\n",
      "[1100]\ttraining's rmse: 0.083232\tvalid_1's rmse: 0.0869126\n",
      "[1125]\ttraining's rmse: 0.0832123\tvalid_1's rmse: 0.0869094\n",
      "[1150]\ttraining's rmse: 0.0831906\tvalid_1's rmse: 0.0869051\n",
      "[1175]\ttraining's rmse: 0.0831758\tvalid_1's rmse: 0.0869015\n",
      "[1200]\ttraining's rmse: 0.0831583\tvalid_1's rmse: 0.086898\n",
      "[1225]\ttraining's rmse: 0.0831412\tvalid_1's rmse: 0.086895\n",
      "[1250]\ttraining's rmse: 0.0831256\tvalid_1's rmse: 0.086892\n",
      "[1275]\ttraining's rmse: 0.083108\tvalid_1's rmse: 0.0868895\n",
      "[1300]\ttraining's rmse: 0.0830952\tvalid_1's rmse: 0.0868865\n",
      "[1325]\ttraining's rmse: 0.0830826\tvalid_1's rmse: 0.0868848\n",
      "[1350]\ttraining's rmse: 0.0830694\tvalid_1's rmse: 0.0868829\n",
      "[1375]\ttraining's rmse: 0.0830572\tvalid_1's rmse: 0.0868807\n",
      "[1400]\ttraining's rmse: 0.0830462\tvalid_1's rmse: 0.086878\n",
      "[1425]\ttraining's rmse: 0.0830321\tvalid_1's rmse: 0.0868766\n",
      "[1450]\ttraining's rmse: 0.0830196\tvalid_1's rmse: 0.0868755\n",
      "[1475]\ttraining's rmse: 0.0830081\tvalid_1's rmse: 0.0868731\n",
      "[1500]\ttraining's rmse: 0.0829971\tvalid_1's rmse: 0.0868716\n",
      "[1525]\ttraining's rmse: 0.0829873\tvalid_1's rmse: 0.08687\n",
      "[1550]\ttraining's rmse: 0.0829782\tvalid_1's rmse: 0.0868689\n",
      "[1575]\ttraining's rmse: 0.0829677\tvalid_1's rmse: 0.0868669\n",
      "[1600]\ttraining's rmse: 0.0829599\tvalid_1's rmse: 0.0868657\n",
      "[1625]\ttraining's rmse: 0.082952\tvalid_1's rmse: 0.0868648\n",
      "[1650]\ttraining's rmse: 0.0829442\tvalid_1's rmse: 0.0868639\n",
      "[1675]\ttraining's rmse: 0.0829356\tvalid_1's rmse: 0.0868629\n",
      "[1700]\ttraining's rmse: 0.0829282\tvalid_1's rmse: 0.086861\n",
      "[1725]\ttraining's rmse: 0.082921\tvalid_1's rmse: 0.0868592\n",
      "[1750]\ttraining's rmse: 0.082915\tvalid_1's rmse: 0.0868582\n",
      "[1775]\ttraining's rmse: 0.0829085\tvalid_1's rmse: 0.0868573\n",
      "[1800]\ttraining's rmse: 0.0829029\tvalid_1's rmse: 0.0868574\n",
      "[1825]\ttraining's rmse: 0.0828963\tvalid_1's rmse: 0.0868569\n",
      "[1850]\ttraining's rmse: 0.0828914\tvalid_1's rmse: 0.0868559\n",
      "[1875]\ttraining's rmse: 0.0828841\tvalid_1's rmse: 0.0868551\n",
      "[1900]\ttraining's rmse: 0.0828779\tvalid_1's rmse: 0.0868544\n",
      "[1925]\ttraining's rmse: 0.0828719\tvalid_1's rmse: 0.0868538\n",
      "[1950]\ttraining's rmse: 0.0828672\tvalid_1's rmse: 0.0868532\n",
      "[1975]\ttraining's rmse: 0.0828634\tvalid_1's rmse: 0.0868525\n",
      "[2000]\ttraining's rmse: 0.0828593\tvalid_1's rmse: 0.086852\n",
      "[2025]\ttraining's rmse: 0.0828553\tvalid_1's rmse: 0.0868507\n",
      "[2050]\ttraining's rmse: 0.0828509\tvalid_1's rmse: 0.0868504\n",
      "[2075]\ttraining's rmse: 0.0828475\tvalid_1's rmse: 0.0868499\n",
      "[2100]\ttraining's rmse: 0.0828447\tvalid_1's rmse: 0.0868499\n",
      "[2125]\ttraining's rmse: 0.0828412\tvalid_1's rmse: 0.0868496\n",
      "[2150]\ttraining's rmse: 0.0828358\tvalid_1's rmse: 0.0868493\n",
      "[2175]\ttraining's rmse: 0.0828329\tvalid_1's rmse: 0.0868491\n",
      "[2200]\ttraining's rmse: 0.0828293\tvalid_1's rmse: 0.0868489\n",
      "[2225]\ttraining's rmse: 0.0828267\tvalid_1's rmse: 0.0868488\n",
      "[2250]\ttraining's rmse: 0.0828238\tvalid_1's rmse: 0.0868485\n",
      "[2275]\ttraining's rmse: 0.0828208\tvalid_1's rmse: 0.0868484\n",
      "[2300]\ttraining's rmse: 0.0828182\tvalid_1's rmse: 0.0868478\n",
      "[2325]\ttraining's rmse: 0.0828143\tvalid_1's rmse: 0.0868477\n",
      "[2350]\ttraining's rmse: 0.0828121\tvalid_1's rmse: 0.086847\n",
      "[2375]\ttraining's rmse: 0.0828099\tvalid_1's rmse: 0.0868467\n",
      "[2400]\ttraining's rmse: 0.0828066\tvalid_1's rmse: 0.086847\n",
      "[2425]\ttraining's rmse: 0.0828023\tvalid_1's rmse: 0.0868462\n",
      "[2450]\ttraining's rmse: 0.0827994\tvalid_1's rmse: 0.086846\n",
      "[2475]\ttraining's rmse: 0.0827971\tvalid_1's rmse: 0.0868458\n",
      "[2500]\ttraining's rmse: 0.0827944\tvalid_1's rmse: 0.0868462\n",
      "[2525]\ttraining's rmse: 0.082792\tvalid_1's rmse: 0.086846\n",
      "Early stopping, best iteration is:\n",
      "[2482]\ttraining's rmse: 0.0827966\tvalid_1's rmse: 0.0868456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0875172\tvalid_1's rmse: 0.0839546\n",
      "[50]\ttraining's rmse: 0.0873922\tvalid_1's rmse: 0.0839049\n",
      "[75]\ttraining's rmse: 0.0872598\tvalid_1's rmse: 0.0838528\n",
      "[100]\ttraining's rmse: 0.0871399\tvalid_1's rmse: 0.0838084\n",
      "[125]\ttraining's rmse: 0.087018\tvalid_1's rmse: 0.0837636\n",
      "[150]\ttraining's rmse: 0.0869053\tvalid_1's rmse: 0.0837247\n",
      "[175]\ttraining's rmse: 0.0868116\tvalid_1's rmse: 0.0836908\n",
      "[200]\ttraining's rmse: 0.0867087\tvalid_1's rmse: 0.0836581\n",
      "[225]\ttraining's rmse: 0.0866098\tvalid_1's rmse: 0.0836264\n",
      "[250]\ttraining's rmse: 0.0865264\tvalid_1's rmse: 0.0835997\n",
      "[275]\ttraining's rmse: 0.0864537\tvalid_1's rmse: 0.0835748\n",
      "[300]\ttraining's rmse: 0.0863804\tvalid_1's rmse: 0.0835503\n",
      "[325]\ttraining's rmse: 0.0863009\tvalid_1's rmse: 0.0835277\n",
      "[350]\ttraining's rmse: 0.0862279\tvalid_1's rmse: 0.083507\n",
      "[375]\ttraining's rmse: 0.086167\tvalid_1's rmse: 0.0834903\n",
      "[400]\ttraining's rmse: 0.0861\tvalid_1's rmse: 0.0834725\n",
      "[425]\ttraining's rmse: 0.0860394\tvalid_1's rmse: 0.0834553\n",
      "[450]\ttraining's rmse: 0.0859832\tvalid_1's rmse: 0.0834389\n",
      "[475]\ttraining's rmse: 0.08593\tvalid_1's rmse: 0.0834249\n",
      "[500]\ttraining's rmse: 0.0858829\tvalid_1's rmse: 0.0834131\n",
      "[525]\ttraining's rmse: 0.0858239\tvalid_1's rmse: 0.0833995\n",
      "[550]\ttraining's rmse: 0.0857692\tvalid_1's rmse: 0.08339\n",
      "[575]\ttraining's rmse: 0.0857202\tvalid_1's rmse: 0.08338\n",
      "[600]\ttraining's rmse: 0.0856731\tvalid_1's rmse: 0.0833703\n",
      "[625]\ttraining's rmse: 0.0856349\tvalid_1's rmse: 0.083365\n",
      "[650]\ttraining's rmse: 0.0855894\tvalid_1's rmse: 0.0833637\n",
      "[675]\ttraining's rmse: 0.0855402\tvalid_1's rmse: 0.083359\n",
      "[700]\ttraining's rmse: 0.0854998\tvalid_1's rmse: 0.0833516\n",
      "[725]\ttraining's rmse: 0.0854606\tvalid_1's rmse: 0.0833496\n",
      "[750]\ttraining's rmse: 0.0854236\tvalid_1's rmse: 0.083355\n",
      "[775]\ttraining's rmse: 0.0853932\tvalid_1's rmse: 0.0833489\n",
      "[800]\ttraining's rmse: 0.0853561\tvalid_1's rmse: 0.083344\n",
      "[825]\ttraining's rmse: 0.0853229\tvalid_1's rmse: 0.0833475\n",
      "[850]\ttraining's rmse: 0.0852894\tvalid_1's rmse: 0.0833416\n",
      "[875]\ttraining's rmse: 0.0852608\tvalid_1's rmse: 0.0833436\n",
      "[900]\ttraining's rmse: 0.0852267\tvalid_1's rmse: 0.0833451\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's rmse: 0.0852809\tvalid_1's rmse: 0.0833406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0816066\tvalid_1's rmse: 0.0842692\n",
      "[50]\ttraining's rmse: 0.081485\tvalid_1's rmse: 0.0842141\n",
      "[75]\ttraining's rmse: 0.0813645\tvalid_1's rmse: 0.0841613\n",
      "[100]\ttraining's rmse: 0.0812539\tvalid_1's rmse: 0.0841145\n",
      "[125]\ttraining's rmse: 0.0811369\tvalid_1's rmse: 0.0840663\n",
      "[150]\ttraining's rmse: 0.0810365\tvalid_1's rmse: 0.0840239\n",
      "[175]\ttraining's rmse: 0.0809514\tvalid_1's rmse: 0.0839863\n",
      "[200]\ttraining's rmse: 0.0808625\tvalid_1's rmse: 0.083948\n",
      "[225]\ttraining's rmse: 0.0807739\tvalid_1's rmse: 0.0839119\n",
      "[250]\ttraining's rmse: 0.0807004\tvalid_1's rmse: 0.0838803\n",
      "[275]\ttraining's rmse: 0.0806287\tvalid_1's rmse: 0.0838493\n",
      "[300]\ttraining's rmse: 0.0805566\tvalid_1's rmse: 0.0838205\n",
      "[325]\ttraining's rmse: 0.0804875\tvalid_1's rmse: 0.083793\n",
      "[350]\ttraining's rmse: 0.0804209\tvalid_1's rmse: 0.0837676\n",
      "[375]\ttraining's rmse: 0.080366\tvalid_1's rmse: 0.0837457\n",
      "[400]\ttraining's rmse: 0.0803062\tvalid_1's rmse: 0.0837243\n",
      "[425]\ttraining's rmse: 0.080254\tvalid_1's rmse: 0.083704\n",
      "[450]\ttraining's rmse: 0.0802018\tvalid_1's rmse: 0.0836837\n",
      "[475]\ttraining's rmse: 0.0801526\tvalid_1's rmse: 0.0836651\n",
      "[500]\ttraining's rmse: 0.0801138\tvalid_1's rmse: 0.083648\n",
      "[525]\ttraining's rmse: 0.0800656\tvalid_1's rmse: 0.0836296\n",
      "[550]\ttraining's rmse: 0.0800179\tvalid_1's rmse: 0.0836132\n",
      "[575]\ttraining's rmse: 0.0799756\tvalid_1's rmse: 0.0835995\n",
      "[600]\ttraining's rmse: 0.0799361\tvalid_1's rmse: 0.083585\n",
      "[625]\ttraining's rmse: 0.0799021\tvalid_1's rmse: 0.0835726\n",
      "[650]\ttraining's rmse: 0.0798621\tvalid_1's rmse: 0.0835592\n",
      "[675]\ttraining's rmse: 0.0798239\tvalid_1's rmse: 0.0835462\n",
      "[700]\ttraining's rmse: 0.0797903\tvalid_1's rmse: 0.0835346\n",
      "[725]\ttraining's rmse: 0.0797586\tvalid_1's rmse: 0.083525\n",
      "[750]\ttraining's rmse: 0.0797278\tvalid_1's rmse: 0.0835144\n",
      "[775]\ttraining's rmse: 0.079703\tvalid_1's rmse: 0.0835035\n",
      "[800]\ttraining's rmse: 0.0796704\tvalid_1's rmse: 0.0834946\n",
      "[825]\ttraining's rmse: 0.0796428\tvalid_1's rmse: 0.0834844\n",
      "[850]\ttraining's rmse: 0.0796135\tvalid_1's rmse: 0.0834761\n",
      "[875]\ttraining's rmse: 0.0795869\tvalid_1's rmse: 0.0834673\n",
      "[900]\ttraining's rmse: 0.0795583\tvalid_1's rmse: 0.0834592\n",
      "[925]\ttraining's rmse: 0.0795338\tvalid_1's rmse: 0.0834526\n",
      "[950]\ttraining's rmse: 0.0795113\tvalid_1's rmse: 0.0834454\n",
      "[975]\ttraining's rmse: 0.0794901\tvalid_1's rmse: 0.0834392\n",
      "[1000]\ttraining's rmse: 0.079468\tvalid_1's rmse: 0.0834338\n",
      "[1025]\ttraining's rmse: 0.0794478\tvalid_1's rmse: 0.083429\n",
      "[1050]\ttraining's rmse: 0.0794284\tvalid_1's rmse: 0.0834231\n",
      "[1075]\ttraining's rmse: 0.0794085\tvalid_1's rmse: 0.0834188\n",
      "[1100]\ttraining's rmse: 0.0793923\tvalid_1's rmse: 0.0834121\n",
      "[1125]\ttraining's rmse: 0.0793751\tvalid_1's rmse: 0.0834063\n",
      "[1150]\ttraining's rmse: 0.0793573\tvalid_1's rmse: 0.0833997\n",
      "[1175]\ttraining's rmse: 0.0793413\tvalid_1's rmse: 0.0833957\n",
      "[1200]\ttraining's rmse: 0.0793258\tvalid_1's rmse: 0.0833908\n",
      "[1225]\ttraining's rmse: 0.0793116\tvalid_1's rmse: 0.0833858\n",
      "[1250]\ttraining's rmse: 0.0792978\tvalid_1's rmse: 0.0833814\n",
      "[1275]\ttraining's rmse: 0.0792803\tvalid_1's rmse: 0.0833777\n",
      "[1300]\ttraining's rmse: 0.0792694\tvalid_1's rmse: 0.0833719\n",
      "[1325]\ttraining's rmse: 0.0792572\tvalid_1's rmse: 0.0833676\n",
      "[1350]\ttraining's rmse: 0.0792481\tvalid_1's rmse: 0.0833654\n",
      "[1375]\ttraining's rmse: 0.079237\tvalid_1's rmse: 0.0833633\n",
      "[1400]\ttraining's rmse: 0.0792283\tvalid_1's rmse: 0.08336\n",
      "[1425]\ttraining's rmse: 0.0792175\tvalid_1's rmse: 0.0833577\n",
      "[1450]\ttraining's rmse: 0.0792045\tvalid_1's rmse: 0.0833548\n",
      "[1475]\ttraining's rmse: 0.0791933\tvalid_1's rmse: 0.0833514\n",
      "[1500]\ttraining's rmse: 0.0791825\tvalid_1's rmse: 0.0833482\n",
      "[1525]\ttraining's rmse: 0.0791742\tvalid_1's rmse: 0.0833452\n",
      "[1550]\ttraining's rmse: 0.0791649\tvalid_1's rmse: 0.0833422\n",
      "[1575]\ttraining's rmse: 0.079158\tvalid_1's rmse: 0.0833385\n",
      "[1600]\ttraining's rmse: 0.0791509\tvalid_1's rmse: 0.0833369\n",
      "[1625]\ttraining's rmse: 0.0791437\tvalid_1's rmse: 0.083335\n",
      "[1650]\ttraining's rmse: 0.0791366\tvalid_1's rmse: 0.083332\n",
      "[1675]\ttraining's rmse: 0.0791324\tvalid_1's rmse: 0.0833303\n",
      "[1700]\ttraining's rmse: 0.0791265\tvalid_1's rmse: 0.0833284\n",
      "[1725]\ttraining's rmse: 0.0791203\tvalid_1's rmse: 0.0833265\n",
      "[1750]\ttraining's rmse: 0.0791125\tvalid_1's rmse: 0.0833246\n",
      "[1775]\ttraining's rmse: 0.0791073\tvalid_1's rmse: 0.0833228\n",
      "[1800]\ttraining's rmse: 0.0791009\tvalid_1's rmse: 0.0833212\n",
      "[1825]\ttraining's rmse: 0.0790949\tvalid_1's rmse: 0.0833196\n",
      "[1850]\ttraining's rmse: 0.079091\tvalid_1's rmse: 0.083318\n",
      "[1875]\ttraining's rmse: 0.0790857\tvalid_1's rmse: 0.0833168\n",
      "[1900]\ttraining's rmse: 0.0790801\tvalid_1's rmse: 0.0833159\n",
      "[1925]\ttraining's rmse: 0.0790763\tvalid_1's rmse: 0.0833146\n",
      "[1950]\ttraining's rmse: 0.0790725\tvalid_1's rmse: 0.0833124\n",
      "[1975]\ttraining's rmse: 0.0790676\tvalid_1's rmse: 0.083311\n",
      "[2000]\ttraining's rmse: 0.0790641\tvalid_1's rmse: 0.0833106\n",
      "[2025]\ttraining's rmse: 0.0790605\tvalid_1's rmse: 0.0833102\n",
      "[2050]\ttraining's rmse: 0.0790562\tvalid_1's rmse: 0.0833094\n",
      "[2075]\ttraining's rmse: 0.0790539\tvalid_1's rmse: 0.0833084\n",
      "[2100]\ttraining's rmse: 0.0790518\tvalid_1's rmse: 0.0833079\n",
      "[2125]\ttraining's rmse: 0.0790486\tvalid_1's rmse: 0.0833067\n",
      "[2150]\ttraining's rmse: 0.0790458\tvalid_1's rmse: 0.0833065\n",
      "[2175]\ttraining's rmse: 0.0790433\tvalid_1's rmse: 0.0833057\n",
      "[2200]\ttraining's rmse: 0.0790408\tvalid_1's rmse: 0.0833054\n",
      "[2225]\ttraining's rmse: 0.079037\tvalid_1's rmse: 0.0833052\n",
      "[2250]\ttraining's rmse: 0.0790351\tvalid_1's rmse: 0.0833049\n",
      "[2275]\ttraining's rmse: 0.0790325\tvalid_1's rmse: 0.0833037\n",
      "[2300]\ttraining's rmse: 0.0790301\tvalid_1's rmse: 0.0833033\n",
      "[2325]\ttraining's rmse: 0.0790264\tvalid_1's rmse: 0.0833026\n",
      "[2350]\ttraining's rmse: 0.0790243\tvalid_1's rmse: 0.0833021\n",
      "[2375]\ttraining's rmse: 0.0790218\tvalid_1's rmse: 0.0833014\n",
      "[2400]\ttraining's rmse: 0.0790188\tvalid_1's rmse: 0.0833014\n",
      "[2425]\ttraining's rmse: 0.0790162\tvalid_1's rmse: 0.0833002\n",
      "[2450]\ttraining's rmse: 0.0790132\tvalid_1's rmse: 0.0832997\n",
      "[2475]\ttraining's rmse: 0.0790111\tvalid_1's rmse: 0.0832995\n",
      "[2500]\ttraining's rmse: 0.0790096\tvalid_1's rmse: 0.0832988\n",
      "[2525]\ttraining's rmse: 0.0790064\tvalid_1's rmse: 0.0832974\n",
      "[2550]\ttraining's rmse: 0.0790051\tvalid_1's rmse: 0.0832972\n",
      "[2575]\ttraining's rmse: 0.0790031\tvalid_1's rmse: 0.083297\n",
      "[2600]\ttraining's rmse: 0.079001\tvalid_1's rmse: 0.0832964\n",
      "[2625]\ttraining's rmse: 0.0789991\tvalid_1's rmse: 0.0832959\n",
      "[2650]\ttraining's rmse: 0.0789981\tvalid_1's rmse: 0.0832955\n",
      "[2675]\ttraining's rmse: 0.0789971\tvalid_1's rmse: 0.0832957\n",
      "[2700]\ttraining's rmse: 0.0789956\tvalid_1's rmse: 0.0832952\n",
      "[2725]\ttraining's rmse: 0.0789929\tvalid_1's rmse: 0.0832945\n",
      "[2750]\ttraining's rmse: 0.0789915\tvalid_1's rmse: 0.0832947\n",
      "[2775]\ttraining's rmse: 0.0789893\tvalid_1's rmse: 0.0832942\n",
      "[2800]\ttraining's rmse: 0.0789884\tvalid_1's rmse: 0.083294\n",
      "[2825]\ttraining's rmse: 0.0789865\tvalid_1's rmse: 0.0832938\n",
      "[2850]\ttraining's rmse: 0.0789851\tvalid_1's rmse: 0.0832939\n",
      "[2875]\ttraining's rmse: 0.0789832\tvalid_1's rmse: 0.0832937\n",
      "[2900]\ttraining's rmse: 0.0789825\tvalid_1's rmse: 0.0832937\n",
      "Early stopping, best iteration is:\n",
      "[2865]\ttraining's rmse: 0.0789835\tvalid_1's rmse: 0.0832936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0819125\tvalid_1's rmse: 0.0836598\n",
      "[50]\ttraining's rmse: 0.0817938\tvalid_1's rmse: 0.0836041\n",
      "[75]\ttraining's rmse: 0.0816723\tvalid_1's rmse: 0.0835488\n",
      "[100]\ttraining's rmse: 0.0815674\tvalid_1's rmse: 0.0834995\n",
      "[125]\ttraining's rmse: 0.081455\tvalid_1's rmse: 0.0834493\n",
      "[150]\ttraining's rmse: 0.0813551\tvalid_1's rmse: 0.0834053\n",
      "[175]\ttraining's rmse: 0.0812702\tvalid_1's rmse: 0.0833674\n",
      "[200]\ttraining's rmse: 0.0811782\tvalid_1's rmse: 0.0833297\n",
      "[225]\ttraining's rmse: 0.0810905\tvalid_1's rmse: 0.0832934\n",
      "[250]\ttraining's rmse: 0.081016\tvalid_1's rmse: 0.0832629\n",
      "[275]\ttraining's rmse: 0.0809436\tvalid_1's rmse: 0.0832341\n",
      "[300]\ttraining's rmse: 0.0808739\tvalid_1's rmse: 0.0832071\n",
      "[325]\ttraining's rmse: 0.0808\tvalid_1's rmse: 0.0831791\n",
      "[350]\ttraining's rmse: 0.0807313\tvalid_1's rmse: 0.0831541\n",
      "[375]\ttraining's rmse: 0.0806775\tvalid_1's rmse: 0.0831333\n",
      "[400]\ttraining's rmse: 0.0806187\tvalid_1's rmse: 0.0831131\n",
      "[425]\ttraining's rmse: 0.0805631\tvalid_1's rmse: 0.0830934\n",
      "[450]\ttraining's rmse: 0.0805118\tvalid_1's rmse: 0.0830745\n",
      "[475]\ttraining's rmse: 0.0804638\tvalid_1's rmse: 0.0830583\n",
      "[500]\ttraining's rmse: 0.0804236\tvalid_1's rmse: 0.0830426\n",
      "[525]\ttraining's rmse: 0.080373\tvalid_1's rmse: 0.0830263\n",
      "[550]\ttraining's rmse: 0.0803241\tvalid_1's rmse: 0.0830117\n",
      "[575]\ttraining's rmse: 0.0802803\tvalid_1's rmse: 0.0829976\n",
      "[600]\ttraining's rmse: 0.0802374\tvalid_1's rmse: 0.0829849\n",
      "[625]\ttraining's rmse: 0.0802045\tvalid_1's rmse: 0.0829741\n",
      "[650]\ttraining's rmse: 0.0801631\tvalid_1's rmse: 0.0829619\n",
      "[675]\ttraining's rmse: 0.0801207\tvalid_1's rmse: 0.0829497\n",
      "[700]\ttraining's rmse: 0.0800839\tvalid_1's rmse: 0.0829391\n",
      "[725]\ttraining's rmse: 0.0800488\tvalid_1's rmse: 0.0829297\n",
      "[750]\ttraining's rmse: 0.0800148\tvalid_1's rmse: 0.0829213\n",
      "[775]\ttraining's rmse: 0.0799879\tvalid_1's rmse: 0.0829131\n",
      "[800]\ttraining's rmse: 0.0799553\tvalid_1's rmse: 0.0829058\n",
      "[825]\ttraining's rmse: 0.0799273\tvalid_1's rmse: 0.0828984\n",
      "[850]\ttraining's rmse: 0.0798996\tvalid_1's rmse: 0.0828919\n",
      "[875]\ttraining's rmse: 0.079873\tvalid_1's rmse: 0.0828857\n",
      "[900]\ttraining's rmse: 0.0798452\tvalid_1's rmse: 0.0828796\n",
      "[925]\ttraining's rmse: 0.0798178\tvalid_1's rmse: 0.0828747\n",
      "[950]\ttraining's rmse: 0.0797946\tvalid_1's rmse: 0.0828698\n",
      "[975]\ttraining's rmse: 0.0797732\tvalid_1's rmse: 0.0828648\n",
      "[1000]\ttraining's rmse: 0.0797522\tvalid_1's rmse: 0.0828603\n",
      "[1025]\ttraining's rmse: 0.0797274\tvalid_1's rmse: 0.0828556\n",
      "[1050]\ttraining's rmse: 0.0797075\tvalid_1's rmse: 0.0828512\n",
      "[1075]\ttraining's rmse: 0.0796875\tvalid_1's rmse: 0.0828479\n",
      "[1100]\ttraining's rmse: 0.0796713\tvalid_1's rmse: 0.082844\n",
      "[1125]\ttraining's rmse: 0.0796531\tvalid_1's rmse: 0.0828404\n",
      "[1150]\ttraining's rmse: 0.0796344\tvalid_1's rmse: 0.0828366\n",
      "[1175]\ttraining's rmse: 0.0796174\tvalid_1's rmse: 0.0828342\n",
      "[1200]\ttraining's rmse: 0.0796016\tvalid_1's rmse: 0.0828312\n",
      "[1225]\ttraining's rmse: 0.0795876\tvalid_1's rmse: 0.0828288\n",
      "[1250]\ttraining's rmse: 0.0795736\tvalid_1's rmse: 0.082826\n",
      "[1275]\ttraining's rmse: 0.0795562\tvalid_1's rmse: 0.0828236\n",
      "[1300]\ttraining's rmse: 0.0795452\tvalid_1's rmse: 0.0828212\n",
      "[1325]\ttraining's rmse: 0.0795325\tvalid_1's rmse: 0.0828192\n",
      "[1350]\ttraining's rmse: 0.0795198\tvalid_1's rmse: 0.0828179\n",
      "[1375]\ttraining's rmse: 0.0795077\tvalid_1's rmse: 0.0828158\n",
      "[1400]\ttraining's rmse: 0.0794985\tvalid_1's rmse: 0.0828138\n",
      "[1425]\ttraining's rmse: 0.0794867\tvalid_1's rmse: 0.0828121\n",
      "[1450]\ttraining's rmse: 0.0794757\tvalid_1's rmse: 0.0828108\n",
      "[1475]\ttraining's rmse: 0.0794661\tvalid_1's rmse: 0.0828094\n",
      "[1500]\ttraining's rmse: 0.0794558\tvalid_1's rmse: 0.0828084\n",
      "[1525]\ttraining's rmse: 0.0794458\tvalid_1's rmse: 0.0828067\n",
      "[1550]\ttraining's rmse: 0.0794379\tvalid_1's rmse: 0.082806\n",
      "[1575]\ttraining's rmse: 0.079429\tvalid_1's rmse: 0.0828049\n",
      "[1600]\ttraining's rmse: 0.0794223\tvalid_1's rmse: 0.0828042\n",
      "[1625]\ttraining's rmse: 0.0794142\tvalid_1's rmse: 0.0828032\n",
      "[1650]\ttraining's rmse: 0.0794068\tvalid_1's rmse: 0.0828028\n",
      "[1675]\ttraining's rmse: 0.0794002\tvalid_1's rmse: 0.082802\n",
      "[1700]\ttraining's rmse: 0.079394\tvalid_1's rmse: 0.0828013\n",
      "[1725]\ttraining's rmse: 0.0793888\tvalid_1's rmse: 0.0828003\n",
      "[1750]\ttraining's rmse: 0.0793825\tvalid_1's rmse: 0.0827991\n",
      "[1775]\ttraining's rmse: 0.0793767\tvalid_1's rmse: 0.0827986\n",
      "[1800]\ttraining's rmse: 0.0793711\tvalid_1's rmse: 0.0827978\n",
      "[1825]\ttraining's rmse: 0.0793649\tvalid_1's rmse: 0.0827973\n",
      "[1850]\ttraining's rmse: 0.0793595\tvalid_1's rmse: 0.082797\n",
      "[1875]\ttraining's rmse: 0.0793537\tvalid_1's rmse: 0.0827964\n",
      "[1900]\ttraining's rmse: 0.0793496\tvalid_1's rmse: 0.0827965\n",
      "Early stopping, best iteration is:\n",
      "[1874]\ttraining's rmse: 0.0793538\tvalid_1's rmse: 0.0827963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0838479\tvalid_1's rmse: 0.0797331\n",
      "[50]\ttraining's rmse: 0.083733\tvalid_1's rmse: 0.0796837\n",
      "[75]\ttraining's rmse: 0.0836175\tvalid_1's rmse: 0.0796369\n",
      "[100]\ttraining's rmse: 0.0835158\tvalid_1's rmse: 0.0795947\n",
      "[125]\ttraining's rmse: 0.0834111\tvalid_1's rmse: 0.0795538\n",
      "[150]\ttraining's rmse: 0.0833126\tvalid_1's rmse: 0.079516\n",
      "[175]\ttraining's rmse: 0.0832319\tvalid_1's rmse: 0.0794864\n",
      "[200]\ttraining's rmse: 0.0831472\tvalid_1's rmse: 0.0794541\n",
      "[225]\ttraining's rmse: 0.0830621\tvalid_1's rmse: 0.0794247\n",
      "[250]\ttraining's rmse: 0.0829919\tvalid_1's rmse: 0.0793996\n",
      "[275]\ttraining's rmse: 0.0829255\tvalid_1's rmse: 0.0793753\n",
      "[300]\ttraining's rmse: 0.0828597\tvalid_1's rmse: 0.0793513\n",
      "[325]\ttraining's rmse: 0.0827961\tvalid_1's rmse: 0.0793302\n",
      "[350]\ttraining's rmse: 0.0827329\tvalid_1's rmse: 0.0793107\n",
      "[375]\ttraining's rmse: 0.0826801\tvalid_1's rmse: 0.0792939\n",
      "[400]\ttraining's rmse: 0.0826212\tvalid_1's rmse: 0.0792764\n",
      "[425]\ttraining's rmse: 0.0825683\tvalid_1's rmse: 0.0792593\n",
      "[450]\ttraining's rmse: 0.082521\tvalid_1's rmse: 0.0792436\n",
      "[475]\ttraining's rmse: 0.0824744\tvalid_1's rmse: 0.0792302\n",
      "[500]\ttraining's rmse: 0.0824365\tvalid_1's rmse: 0.0792162\n",
      "[525]\ttraining's rmse: 0.0823845\tvalid_1's rmse: 0.0792022\n",
      "[550]\ttraining's rmse: 0.082338\tvalid_1's rmse: 0.07919\n",
      "[575]\ttraining's rmse: 0.0822954\tvalid_1's rmse: 0.0791794\n",
      "[600]\ttraining's rmse: 0.0822522\tvalid_1's rmse: 0.07918\n",
      "[625]\ttraining's rmse: 0.0822197\tvalid_1's rmse: 0.0791872\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's rmse: 0.082263\tvalid_1's rmse: 0.0791767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0868779\tvalid_1's rmse: 0.0882512\n",
      "[50]\ttraining's rmse: 0.0866925\tvalid_1's rmse: 0.0881985\n",
      "[75]\ttraining's rmse: 0.0865125\tvalid_1's rmse: 0.0881463\n",
      "[100]\ttraining's rmse: 0.0863445\tvalid_1's rmse: 0.0880995\n",
      "[125]\ttraining's rmse: 0.0861812\tvalid_1's rmse: 0.0880539\n",
      "[150]\ttraining's rmse: 0.086033\tvalid_1's rmse: 0.0880133\n",
      "[175]\ttraining's rmse: 0.0859062\tvalid_1's rmse: 0.0879767\n",
      "[200]\ttraining's rmse: 0.0857672\tvalid_1's rmse: 0.0879403\n",
      "[225]\ttraining's rmse: 0.0856385\tvalid_1's rmse: 0.0879066\n",
      "[250]\ttraining's rmse: 0.0855288\tvalid_1's rmse: 0.0878748\n",
      "[275]\ttraining's rmse: 0.085426\tvalid_1's rmse: 0.0878489\n",
      "[300]\ttraining's rmse: 0.0853273\tvalid_1's rmse: 0.0878232\n",
      "[325]\ttraining's rmse: 0.0852301\tvalid_1's rmse: 0.087798\n",
      "[350]\ttraining's rmse: 0.0851352\tvalid_1's rmse: 0.0877737\n",
      "[375]\ttraining's rmse: 0.0850525\tvalid_1's rmse: 0.0877539\n",
      "[400]\ttraining's rmse: 0.0849627\tvalid_1's rmse: 0.0877318\n",
      "[425]\ttraining's rmse: 0.084881\tvalid_1's rmse: 0.087713\n",
      "[450]\ttraining's rmse: 0.0848141\tvalid_1's rmse: 0.0876935\n",
      "[475]\ttraining's rmse: 0.084748\tvalid_1's rmse: 0.0876765\n",
      "[500]\ttraining's rmse: 0.0846926\tvalid_1's rmse: 0.0876608\n",
      "[525]\ttraining's rmse: 0.0846259\tvalid_1's rmse: 0.0876435\n",
      "[550]\ttraining's rmse: 0.0845644\tvalid_1's rmse: 0.0876288\n",
      "[575]\ttraining's rmse: 0.0845075\tvalid_1's rmse: 0.0876164\n",
      "[600]\ttraining's rmse: 0.0844541\tvalid_1's rmse: 0.087604\n",
      "[625]\ttraining's rmse: 0.0844064\tvalid_1's rmse: 0.087592\n",
      "[650]\ttraining's rmse: 0.0843506\tvalid_1's rmse: 0.0875804\n",
      "[675]\ttraining's rmse: 0.0842969\tvalid_1's rmse: 0.0875676\n",
      "[700]\ttraining's rmse: 0.0842513\tvalid_1's rmse: 0.0875569\n",
      "[725]\ttraining's rmse: 0.0842085\tvalid_1's rmse: 0.0875475\n",
      "[750]\ttraining's rmse: 0.084167\tvalid_1's rmse: 0.0875381\n",
      "[775]\ttraining's rmse: 0.084134\tvalid_1's rmse: 0.0875287\n",
      "[800]\ttraining's rmse: 0.0840928\tvalid_1's rmse: 0.0875191\n",
      "[825]\ttraining's rmse: 0.0840572\tvalid_1's rmse: 0.0875105\n",
      "[850]\ttraining's rmse: 0.084019\tvalid_1's rmse: 0.0875045\n",
      "[875]\ttraining's rmse: 0.0839885\tvalid_1's rmse: 0.0874971\n",
      "[900]\ttraining's rmse: 0.0839551\tvalid_1's rmse: 0.0874894\n",
      "[925]\ttraining's rmse: 0.0839208\tvalid_1's rmse: 0.0874831\n",
      "[950]\ttraining's rmse: 0.0838907\tvalid_1's rmse: 0.0874759\n",
      "[975]\ttraining's rmse: 0.0838633\tvalid_1's rmse: 0.0874694\n",
      "[1000]\ttraining's rmse: 0.0838353\tvalid_1's rmse: 0.0874624\n",
      "[1025]\ttraining's rmse: 0.0838105\tvalid_1's rmse: 0.0874562\n",
      "[1050]\ttraining's rmse: 0.0837884\tvalid_1's rmse: 0.0874492\n",
      "[1075]\ttraining's rmse: 0.0837651\tvalid_1's rmse: 0.0874448\n",
      "[1100]\ttraining's rmse: 0.0837442\tvalid_1's rmse: 0.0874411\n",
      "[1125]\ttraining's rmse: 0.0837231\tvalid_1's rmse: 0.0874359\n",
      "[1150]\ttraining's rmse: 0.0837\tvalid_1's rmse: 0.0874293\n",
      "[1175]\ttraining's rmse: 0.0836807\tvalid_1's rmse: 0.087427\n",
      "[1200]\ttraining's rmse: 0.0836593\tvalid_1's rmse: 0.0874222\n",
      "[1225]\ttraining's rmse: 0.0836409\tvalid_1's rmse: 0.0874166\n",
      "[1250]\ttraining's rmse: 0.0836216\tvalid_1's rmse: 0.0874115\n",
      "[1275]\ttraining's rmse: 0.0836038\tvalid_1's rmse: 0.0874085\n",
      "[1300]\ttraining's rmse: 0.0835904\tvalid_1's rmse: 0.0874048\n",
      "[1325]\ttraining's rmse: 0.0835738\tvalid_1's rmse: 0.0874011\n",
      "[1350]\ttraining's rmse: 0.0835559\tvalid_1's rmse: 0.0873982\n",
      "[1375]\ttraining's rmse: 0.0835388\tvalid_1's rmse: 0.0873946\n",
      "[1400]\ttraining's rmse: 0.0835271\tvalid_1's rmse: 0.0873911\n",
      "[1425]\ttraining's rmse: 0.0835106\tvalid_1's rmse: 0.087389\n",
      "[1450]\ttraining's rmse: 0.0834944\tvalid_1's rmse: 0.0873864\n",
      "[1475]\ttraining's rmse: 0.083481\tvalid_1's rmse: 0.0873844\n",
      "[1500]\ttraining's rmse: 0.0834729\tvalid_1's rmse: 0.0873819\n",
      "[1525]\ttraining's rmse: 0.0834623\tvalid_1's rmse: 0.0873791\n",
      "[1550]\ttraining's rmse: 0.0834495\tvalid_1's rmse: 0.0873779\n",
      "[1575]\ttraining's rmse: 0.0834422\tvalid_1's rmse: 0.087375\n",
      "[1600]\ttraining's rmse: 0.083434\tvalid_1's rmse: 0.0873723\n",
      "[1625]\ttraining's rmse: 0.0834237\tvalid_1's rmse: 0.0873711\n",
      "[1650]\ttraining's rmse: 0.0834151\tvalid_1's rmse: 0.0873686\n",
      "[1675]\ttraining's rmse: 0.0834063\tvalid_1's rmse: 0.0873662\n",
      "[1700]\ttraining's rmse: 0.0833998\tvalid_1's rmse: 0.0873628\n",
      "[1725]\ttraining's rmse: 0.0833918\tvalid_1's rmse: 0.0873614\n",
      "[1750]\ttraining's rmse: 0.0833846\tvalid_1's rmse: 0.0873613\n",
      "[1775]\ttraining's rmse: 0.083379\tvalid_1's rmse: 0.0873593\n",
      "[1800]\ttraining's rmse: 0.0833726\tvalid_1's rmse: 0.0873573\n",
      "[1825]\ttraining's rmse: 0.0833665\tvalid_1's rmse: 0.0873539\n",
      "[1850]\ttraining's rmse: 0.0833615\tvalid_1's rmse: 0.0873522\n",
      "[1875]\ttraining's rmse: 0.0833572\tvalid_1's rmse: 0.0873512\n",
      "[1900]\ttraining's rmse: 0.0833515\tvalid_1's rmse: 0.0873499\n",
      "[1925]\ttraining's rmse: 0.0833472\tvalid_1's rmse: 0.0873482\n",
      "[1950]\ttraining's rmse: 0.0833438\tvalid_1's rmse: 0.0873463\n",
      "[1975]\ttraining's rmse: 0.0833389\tvalid_1's rmse: 0.0873443\n",
      "[2000]\ttraining's rmse: 0.0833347\tvalid_1's rmse: 0.0873433\n",
      "[2025]\ttraining's rmse: 0.0833297\tvalid_1's rmse: 0.0873418\n",
      "[2050]\ttraining's rmse: 0.0833241\tvalid_1's rmse: 0.0873404\n",
      "[2075]\ttraining's rmse: 0.0833204\tvalid_1's rmse: 0.0873384\n",
      "[2100]\ttraining's rmse: 0.0833173\tvalid_1's rmse: 0.0873378\n",
      "[2125]\ttraining's rmse: 0.0833137\tvalid_1's rmse: 0.087337\n",
      "[2150]\ttraining's rmse: 0.0833091\tvalid_1's rmse: 0.0873367\n",
      "[2175]\ttraining's rmse: 0.0833048\tvalid_1's rmse: 0.0873355\n",
      "[2200]\ttraining's rmse: 0.0833016\tvalid_1's rmse: 0.0873343\n",
      "[2225]\ttraining's rmse: 0.0832981\tvalid_1's rmse: 0.0873326\n",
      "[2250]\ttraining's rmse: 0.0832945\tvalid_1's rmse: 0.0873314\n",
      "[2275]\ttraining's rmse: 0.08329\tvalid_1's rmse: 0.0873303\n",
      "[2300]\ttraining's rmse: 0.0832872\tvalid_1's rmse: 0.0873289\n",
      "[2325]\ttraining's rmse: 0.0832832\tvalid_1's rmse: 0.0873278\n",
      "[2350]\ttraining's rmse: 0.0832801\tvalid_1's rmse: 0.0873271\n",
      "[2375]\ttraining's rmse: 0.0832771\tvalid_1's rmse: 0.0873255\n",
      "[2400]\ttraining's rmse: 0.0832752\tvalid_1's rmse: 0.0873256\n",
      "[2425]\ttraining's rmse: 0.0832732\tvalid_1's rmse: 0.0873253\n",
      "[2450]\ttraining's rmse: 0.0832703\tvalid_1's rmse: 0.0873252\n",
      "[2475]\ttraining's rmse: 0.0832683\tvalid_1's rmse: 0.0873253\n",
      "[2500]\ttraining's rmse: 0.0832658\tvalid_1's rmse: 0.0873247\n",
      "[2525]\ttraining's rmse: 0.0832633\tvalid_1's rmse: 0.0873245\n",
      "[2550]\ttraining's rmse: 0.0832618\tvalid_1's rmse: 0.0873245\n",
      "Early stopping, best iteration is:\n",
      "[2505]\ttraining's rmse: 0.0832646\tvalid_1's rmse: 0.0873242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.086794\tvalid_1's rmse: 0.0884322\n",
      "[50]\ttraining's rmse: 0.0866315\tvalid_1's rmse: 0.0883776\n",
      "[75]\ttraining's rmse: 0.0864661\tvalid_1's rmse: 0.088322\n",
      "[100]\ttraining's rmse: 0.0863148\tvalid_1's rmse: 0.0882717\n",
      "[125]\ttraining's rmse: 0.086163\tvalid_1's rmse: 0.0882211\n",
      "[150]\ttraining's rmse: 0.086027\tvalid_1's rmse: 0.0881754\n",
      "[175]\ttraining's rmse: 0.0859079\tvalid_1's rmse: 0.0881386\n",
      "[200]\ttraining's rmse: 0.0857849\tvalid_1's rmse: 0.0880986\n",
      "[225]\ttraining's rmse: 0.0856671\tvalid_1's rmse: 0.088061\n",
      "[250]\ttraining's rmse: 0.0855655\tvalid_1's rmse: 0.0880286\n",
      "[275]\ttraining's rmse: 0.0854722\tvalid_1's rmse: 0.087999\n",
      "[300]\ttraining's rmse: 0.0853783\tvalid_1's rmse: 0.0879718\n",
      "[325]\ttraining's rmse: 0.0852876\tvalid_1's rmse: 0.0879434\n",
      "[350]\ttraining's rmse: 0.0851973\tvalid_1's rmse: 0.0879168\n",
      "[375]\ttraining's rmse: 0.0851251\tvalid_1's rmse: 0.0878947\n",
      "[400]\ttraining's rmse: 0.0850469\tvalid_1's rmse: 0.0878721\n",
      "[425]\ttraining's rmse: 0.0849763\tvalid_1's rmse: 0.08785\n",
      "[450]\ttraining's rmse: 0.0849104\tvalid_1's rmse: 0.0878297\n",
      "[475]\ttraining's rmse: 0.0848545\tvalid_1's rmse: 0.0878119\n",
      "[500]\ttraining's rmse: 0.0848035\tvalid_1's rmse: 0.0877943\n",
      "[525]\ttraining's rmse: 0.0847405\tvalid_1's rmse: 0.0877764\n",
      "[550]\ttraining's rmse: 0.0846817\tvalid_1's rmse: 0.0877604\n",
      "[575]\ttraining's rmse: 0.0846274\tvalid_1's rmse: 0.0877476\n",
      "[600]\ttraining's rmse: 0.0845764\tvalid_1's rmse: 0.0877335\n",
      "[625]\ttraining's rmse: 0.0845348\tvalid_1's rmse: 0.0877213\n",
      "[650]\ttraining's rmse: 0.0844842\tvalid_1's rmse: 0.0877075\n",
      "[675]\ttraining's rmse: 0.0844366\tvalid_1's rmse: 0.0876947\n",
      "[700]\ttraining's rmse: 0.0843939\tvalid_1's rmse: 0.0876836\n",
      "[725]\ttraining's rmse: 0.0843542\tvalid_1's rmse: 0.0876738\n",
      "[750]\ttraining's rmse: 0.084317\tvalid_1's rmse: 0.0876635\n",
      "[775]\ttraining's rmse: 0.0842834\tvalid_1's rmse: 0.0876532\n",
      "[800]\ttraining's rmse: 0.0842429\tvalid_1's rmse: 0.0876446\n",
      "[825]\ttraining's rmse: 0.0842112\tvalid_1's rmse: 0.0876357\n",
      "[850]\ttraining's rmse: 0.0841753\tvalid_1's rmse: 0.0876283\n",
      "[875]\ttraining's rmse: 0.0841451\tvalid_1's rmse: 0.0876207\n",
      "[900]\ttraining's rmse: 0.0841134\tvalid_1's rmse: 0.087613\n",
      "[925]\ttraining's rmse: 0.0840829\tvalid_1's rmse: 0.0876061\n",
      "[950]\ttraining's rmse: 0.0840537\tvalid_1's rmse: 0.0876002\n",
      "[975]\ttraining's rmse: 0.0840278\tvalid_1's rmse: 0.0875943\n",
      "[1000]\ttraining's rmse: 0.0840018\tvalid_1's rmse: 0.0875884\n",
      "[1025]\ttraining's rmse: 0.0839736\tvalid_1's rmse: 0.0875833\n",
      "[1050]\ttraining's rmse: 0.0839511\tvalid_1's rmse: 0.0875787\n",
      "[1075]\ttraining's rmse: 0.083927\tvalid_1's rmse: 0.0875738\n",
      "[1100]\ttraining's rmse: 0.0839088\tvalid_1's rmse: 0.0875682\n",
      "[1125]\ttraining's rmse: 0.0838871\tvalid_1's rmse: 0.0875634\n",
      "[1150]\ttraining's rmse: 0.083866\tvalid_1's rmse: 0.0875604\n",
      "[1175]\ttraining's rmse: 0.0838483\tvalid_1's rmse: 0.0875577\n",
      "[1200]\ttraining's rmse: 0.0838292\tvalid_1's rmse: 0.0875537\n",
      "[1225]\ttraining's rmse: 0.0838112\tvalid_1's rmse: 0.0875502\n",
      "[1250]\ttraining's rmse: 0.0837939\tvalid_1's rmse: 0.0875468\n",
      "[1275]\ttraining's rmse: 0.0837778\tvalid_1's rmse: 0.0875447\n",
      "[1300]\ttraining's rmse: 0.0837629\tvalid_1's rmse: 0.087541\n",
      "[1325]\ttraining's rmse: 0.0837483\tvalid_1's rmse: 0.0875389\n",
      "[1350]\ttraining's rmse: 0.0837309\tvalid_1's rmse: 0.0875362\n",
      "[1375]\ttraining's rmse: 0.0837165\tvalid_1's rmse: 0.0875343\n",
      "[1400]\ttraining's rmse: 0.0837032\tvalid_1's rmse: 0.0875325\n",
      "[1425]\ttraining's rmse: 0.0836895\tvalid_1's rmse: 0.0875304\n",
      "[1450]\ttraining's rmse: 0.0836762\tvalid_1's rmse: 0.0875292\n",
      "[1475]\ttraining's rmse: 0.0836649\tvalid_1's rmse: 0.0875272\n",
      "[1500]\ttraining's rmse: 0.0836544\tvalid_1's rmse: 0.087525\n",
      "[1525]\ttraining's rmse: 0.083645\tvalid_1's rmse: 0.0875232\n",
      "[1550]\ttraining's rmse: 0.0836371\tvalid_1's rmse: 0.0875226\n",
      "[1575]\ttraining's rmse: 0.0836283\tvalid_1's rmse: 0.08752\n",
      "[1600]\ttraining's rmse: 0.0836183\tvalid_1's rmse: 0.0875188\n",
      "[1625]\ttraining's rmse: 0.0836086\tvalid_1's rmse: 0.0875172\n",
      "[1650]\ttraining's rmse: 0.0836\tvalid_1's rmse: 0.0875166\n",
      "[1675]\ttraining's rmse: 0.0835918\tvalid_1's rmse: 0.0875152\n",
      "[1700]\ttraining's rmse: 0.0835851\tvalid_1's rmse: 0.0875138\n",
      "[1725]\ttraining's rmse: 0.0835776\tvalid_1's rmse: 0.0875126\n",
      "[1750]\ttraining's rmse: 0.0835711\tvalid_1's rmse: 0.0875118\n",
      "[1775]\ttraining's rmse: 0.0835651\tvalid_1's rmse: 0.0875115\n",
      "[1800]\ttraining's rmse: 0.0835575\tvalid_1's rmse: 0.0875105\n",
      "[1825]\ttraining's rmse: 0.083551\tvalid_1's rmse: 0.0875097\n",
      "[1850]\ttraining's rmse: 0.0835444\tvalid_1's rmse: 0.0875079\n",
      "[1875]\ttraining's rmse: 0.083538\tvalid_1's rmse: 0.0875079\n",
      "[1900]\ttraining's rmse: 0.0835341\tvalid_1's rmse: 0.0875079\n",
      "[1925]\ttraining's rmse: 0.0835282\tvalid_1's rmse: 0.0875074\n",
      "[1950]\ttraining's rmse: 0.0835242\tvalid_1's rmse: 0.087507\n",
      "[1975]\ttraining's rmse: 0.0835216\tvalid_1's rmse: 0.0875064\n",
      "[2000]\ttraining's rmse: 0.0835175\tvalid_1's rmse: 0.087506\n",
      "[2025]\ttraining's rmse: 0.0835134\tvalid_1's rmse: 0.0875054\n",
      "[2050]\ttraining's rmse: 0.0835082\tvalid_1's rmse: 0.0875052\n",
      "[2075]\ttraining's rmse: 0.0835042\tvalid_1's rmse: 0.0875047\n",
      "[2100]\ttraining's rmse: 0.0835\tvalid_1's rmse: 0.0875045\n",
      "[2125]\ttraining's rmse: 0.0834967\tvalid_1's rmse: 0.0875045\n",
      "[2150]\ttraining's rmse: 0.0834922\tvalid_1's rmse: 0.0875043\n",
      "[2175]\ttraining's rmse: 0.0834886\tvalid_1's rmse: 0.0875044\n",
      "Early stopping, best iteration is:\n",
      "[2136]\ttraining's rmse: 0.0834947\tvalid_1's rmse: 0.0875042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0881999\tvalid_1's rmse: 0.0856571\n",
      "[50]\ttraining's rmse: 0.0880733\tvalid_1's rmse: 0.0856075\n",
      "[75]\ttraining's rmse: 0.0879381\tvalid_1's rmse: 0.0855577\n",
      "[100]\ttraining's rmse: 0.0878183\tvalid_1's rmse: 0.0855137\n",
      "[125]\ttraining's rmse: 0.0876905\tvalid_1's rmse: 0.0854721\n",
      "[150]\ttraining's rmse: 0.087575\tvalid_1's rmse: 0.0854334\n",
      "[175]\ttraining's rmse: 0.0874785\tvalid_1's rmse: 0.0854009\n",
      "[200]\ttraining's rmse: 0.0873733\tvalid_1's rmse: 0.0853693\n",
      "[225]\ttraining's rmse: 0.0872722\tvalid_1's rmse: 0.0853377\n",
      "[250]\ttraining's rmse: 0.0871849\tvalid_1's rmse: 0.0853112\n",
      "[275]\ttraining's rmse: 0.087107\tvalid_1's rmse: 0.0852879\n",
      "[300]\ttraining's rmse: 0.087029\tvalid_1's rmse: 0.085266\n",
      "[325]\ttraining's rmse: 0.086948\tvalid_1's rmse: 0.0852435\n",
      "[350]\ttraining's rmse: 0.0868721\tvalid_1's rmse: 0.0852228\n",
      "[375]\ttraining's rmse: 0.0868091\tvalid_1's rmse: 0.0852077\n",
      "[400]\ttraining's rmse: 0.0867412\tvalid_1's rmse: 0.0851911\n",
      "[425]\ttraining's rmse: 0.0866779\tvalid_1's rmse: 0.0851755\n",
      "[450]\ttraining's rmse: 0.0866194\tvalid_1's rmse: 0.0851614\n",
      "[475]\ttraining's rmse: 0.0865638\tvalid_1's rmse: 0.0851522\n",
      "[500]\ttraining's rmse: 0.086519\tvalid_1's rmse: 0.0851397\n",
      "[525]\ttraining's rmse: 0.0864579\tvalid_1's rmse: 0.0851335\n",
      "[550]\ttraining's rmse: 0.0864022\tvalid_1's rmse: 0.0851225\n",
      "[575]\ttraining's rmse: 0.0863511\tvalid_1's rmse: 0.0851168\n",
      "[600]\ttraining's rmse: 0.0863009\tvalid_1's rmse: 0.0851083\n",
      "[625]\ttraining's rmse: 0.0862602\tvalid_1's rmse: 0.0850998\n",
      "[650]\ttraining's rmse: 0.0862114\tvalid_1's rmse: 0.0850958\n",
      "[675]\ttraining's rmse: 0.086161\tvalid_1's rmse: 0.0850884\n",
      "[700]\ttraining's rmse: 0.0861182\tvalid_1's rmse: 0.0850817\n",
      "[725]\ttraining's rmse: 0.0860779\tvalid_1's rmse: 0.085081\n",
      "[750]\ttraining's rmse: 0.0860409\tvalid_1's rmse: 0.0850807\n",
      "[775]\ttraining's rmse: 0.0860076\tvalid_1's rmse: 0.0850748\n",
      "[800]\ttraining's rmse: 0.085964\tvalid_1's rmse: 0.0850702\n",
      "[825]\ttraining's rmse: 0.0859295\tvalid_1's rmse: 0.0850659\n",
      "[850]\ttraining's rmse: 0.0858937\tvalid_1's rmse: 0.085062\n",
      "[875]\ttraining's rmse: 0.0858641\tvalid_1's rmse: 0.0850685\n",
      "[900]\ttraining's rmse: 0.0858309\tvalid_1's rmse: 0.0850685\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's rmse: 0.0858858\tvalid_1's rmse: 0.0850614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0821183\tvalid_1's rmse: 0.0847101\n",
      "[50]\ttraining's rmse: 0.0819949\tvalid_1's rmse: 0.0846539\n",
      "[75]\ttraining's rmse: 0.0818706\tvalid_1's rmse: 0.0845978\n",
      "[100]\ttraining's rmse: 0.0817552\tvalid_1's rmse: 0.084548\n",
      "[125]\ttraining's rmse: 0.0816363\tvalid_1's rmse: 0.084497\n",
      "[150]\ttraining's rmse: 0.0815317\tvalid_1's rmse: 0.0844538\n",
      "[175]\ttraining's rmse: 0.0814454\tvalid_1's rmse: 0.0844162\n",
      "[200]\ttraining's rmse: 0.0813521\tvalid_1's rmse: 0.084376\n",
      "[225]\ttraining's rmse: 0.0812639\tvalid_1's rmse: 0.0843384\n",
      "[250]\ttraining's rmse: 0.0811882\tvalid_1's rmse: 0.084304\n",
      "[275]\ttraining's rmse: 0.0811149\tvalid_1's rmse: 0.0842724\n",
      "[300]\ttraining's rmse: 0.0810454\tvalid_1's rmse: 0.0842448\n",
      "[325]\ttraining's rmse: 0.0809752\tvalid_1's rmse: 0.0842157\n",
      "[350]\ttraining's rmse: 0.0809075\tvalid_1's rmse: 0.0841892\n",
      "[375]\ttraining's rmse: 0.0808493\tvalid_1's rmse: 0.0841661\n",
      "[400]\ttraining's rmse: 0.0807875\tvalid_1's rmse: 0.0841424\n",
      "[425]\ttraining's rmse: 0.080734\tvalid_1's rmse: 0.0841216\n",
      "[450]\ttraining's rmse: 0.0806839\tvalid_1's rmse: 0.0841014\n",
      "[475]\ttraining's rmse: 0.0806367\tvalid_1's rmse: 0.0840809\n",
      "[500]\ttraining's rmse: 0.0805974\tvalid_1's rmse: 0.0840615\n",
      "[525]\ttraining's rmse: 0.0805482\tvalid_1's rmse: 0.0840443\n",
      "[550]\ttraining's rmse: 0.0805015\tvalid_1's rmse: 0.0840284\n",
      "[575]\ttraining's rmse: 0.0804553\tvalid_1's rmse: 0.0840142\n",
      "[600]\ttraining's rmse: 0.0804137\tvalid_1's rmse: 0.0839989\n",
      "[625]\ttraining's rmse: 0.0803793\tvalid_1's rmse: 0.0839846\n",
      "[650]\ttraining's rmse: 0.0803389\tvalid_1's rmse: 0.0839701\n",
      "[675]\ttraining's rmse: 0.0802973\tvalid_1's rmse: 0.0839569\n",
      "[700]\ttraining's rmse: 0.0802623\tvalid_1's rmse: 0.0839462\n",
      "[725]\ttraining's rmse: 0.0802282\tvalid_1's rmse: 0.0839351\n",
      "[750]\ttraining's rmse: 0.0801953\tvalid_1's rmse: 0.083924\n",
      "[775]\ttraining's rmse: 0.0801699\tvalid_1's rmse: 0.0839138\n",
      "[800]\ttraining's rmse: 0.0801338\tvalid_1's rmse: 0.0839023\n",
      "[825]\ttraining's rmse: 0.0801065\tvalid_1's rmse: 0.0838923\n",
      "[850]\ttraining's rmse: 0.0800771\tvalid_1's rmse: 0.0838845\n",
      "[875]\ttraining's rmse: 0.0800524\tvalid_1's rmse: 0.0838755\n",
      "[900]\ttraining's rmse: 0.080026\tvalid_1's rmse: 0.0838659\n",
      "[925]\ttraining's rmse: 0.0800014\tvalid_1's rmse: 0.0838584\n",
      "[950]\ttraining's rmse: 0.0799773\tvalid_1's rmse: 0.0838527\n",
      "[975]\ttraining's rmse: 0.079954\tvalid_1's rmse: 0.0838458\n",
      "[1000]\ttraining's rmse: 0.0799325\tvalid_1's rmse: 0.0838404\n",
      "[1025]\ttraining's rmse: 0.0799095\tvalid_1's rmse: 0.0838332\n",
      "[1050]\ttraining's rmse: 0.0798902\tvalid_1's rmse: 0.083827\n",
      "[1075]\ttraining's rmse: 0.0798707\tvalid_1's rmse: 0.0838237\n",
      "[1100]\ttraining's rmse: 0.0798547\tvalid_1's rmse: 0.0838179\n",
      "[1125]\ttraining's rmse: 0.0798384\tvalid_1's rmse: 0.0838127\n",
      "[1150]\ttraining's rmse: 0.0798226\tvalid_1's rmse: 0.0838084\n",
      "[1175]\ttraining's rmse: 0.0798063\tvalid_1's rmse: 0.0838044\n",
      "[1200]\ttraining's rmse: 0.0797902\tvalid_1's rmse: 0.0837987\n",
      "[1225]\ttraining's rmse: 0.0797756\tvalid_1's rmse: 0.0837947\n",
      "[1250]\ttraining's rmse: 0.0797613\tvalid_1's rmse: 0.0837902\n",
      "[1275]\ttraining's rmse: 0.0797469\tvalid_1's rmse: 0.0837865\n",
      "[1300]\ttraining's rmse: 0.0797353\tvalid_1's rmse: 0.0837821\n",
      "[1325]\ttraining's rmse: 0.0797233\tvalid_1's rmse: 0.0837786\n",
      "[1350]\ttraining's rmse: 0.0797113\tvalid_1's rmse: 0.0837752\n",
      "[1375]\ttraining's rmse: 0.0796989\tvalid_1's rmse: 0.0837713\n",
      "[1400]\ttraining's rmse: 0.0796889\tvalid_1's rmse: 0.0837675\n",
      "[1425]\ttraining's rmse: 0.0796767\tvalid_1's rmse: 0.0837656\n",
      "[1450]\ttraining's rmse: 0.079668\tvalid_1's rmse: 0.0837627\n",
      "[1475]\ttraining's rmse: 0.0796581\tvalid_1's rmse: 0.0837603\n",
      "[1500]\ttraining's rmse: 0.0796499\tvalid_1's rmse: 0.0837575\n",
      "[1525]\ttraining's rmse: 0.0796415\tvalid_1's rmse: 0.0837545\n",
      "[1550]\ttraining's rmse: 0.079631\tvalid_1's rmse: 0.0837529\n",
      "[1575]\ttraining's rmse: 0.0796229\tvalid_1's rmse: 0.0837496\n",
      "[1600]\ttraining's rmse: 0.0796163\tvalid_1's rmse: 0.083747\n",
      "[1625]\ttraining's rmse: 0.0796077\tvalid_1's rmse: 0.0837438\n",
      "[1650]\ttraining's rmse: 0.0796015\tvalid_1's rmse: 0.0837425\n",
      "[1675]\ttraining's rmse: 0.0795953\tvalid_1's rmse: 0.0837397\n",
      "[1700]\ttraining's rmse: 0.0795899\tvalid_1's rmse: 0.0837371\n",
      "[1725]\ttraining's rmse: 0.0795846\tvalid_1's rmse: 0.0837365\n",
      "[1750]\ttraining's rmse: 0.079578\tvalid_1's rmse: 0.0837345\n",
      "[1775]\ttraining's rmse: 0.0795728\tvalid_1's rmse: 0.0837335\n",
      "[1800]\ttraining's rmse: 0.0795689\tvalid_1's rmse: 0.0837321\n",
      "[1825]\ttraining's rmse: 0.079563\tvalid_1's rmse: 0.0837305\n",
      "[1850]\ttraining's rmse: 0.0795581\tvalid_1's rmse: 0.0837283\n",
      "[1875]\ttraining's rmse: 0.0795526\tvalid_1's rmse: 0.0837265\n",
      "[1900]\ttraining's rmse: 0.0795474\tvalid_1's rmse: 0.083726\n",
      "[1925]\ttraining's rmse: 0.0795424\tvalid_1's rmse: 0.0837243\n",
      "[1950]\ttraining's rmse: 0.0795388\tvalid_1's rmse: 0.083723\n",
      "[1975]\ttraining's rmse: 0.0795326\tvalid_1's rmse: 0.0837215\n",
      "[2000]\ttraining's rmse: 0.0795283\tvalid_1's rmse: 0.0837214\n",
      "[2025]\ttraining's rmse: 0.0795247\tvalid_1's rmse: 0.0837194\n",
      "[2050]\ttraining's rmse: 0.0795216\tvalid_1's rmse: 0.0837178\n",
      "[2075]\ttraining's rmse: 0.0795193\tvalid_1's rmse: 0.0837174\n",
      "[2100]\ttraining's rmse: 0.0795157\tvalid_1's rmse: 0.0837161\n",
      "[2125]\ttraining's rmse: 0.079513\tvalid_1's rmse: 0.0837158\n",
      "[2150]\ttraining's rmse: 0.0795099\tvalid_1's rmse: 0.0837152\n",
      "[2175]\ttraining's rmse: 0.0795065\tvalid_1's rmse: 0.0837147\n",
      "[2200]\ttraining's rmse: 0.0795028\tvalid_1's rmse: 0.0837138\n",
      "[2225]\ttraining's rmse: 0.0794992\tvalid_1's rmse: 0.0837134\n",
      "[2250]\ttraining's rmse: 0.079495\tvalid_1's rmse: 0.0837127\n",
      "[2275]\ttraining's rmse: 0.0794921\tvalid_1's rmse: 0.0837123\n",
      "[2300]\ttraining's rmse: 0.0794882\tvalid_1's rmse: 0.0837113\n",
      "[2325]\ttraining's rmse: 0.0794841\tvalid_1's rmse: 0.0837106\n",
      "[2350]\ttraining's rmse: 0.0794818\tvalid_1's rmse: 0.0837098\n",
      "[2375]\ttraining's rmse: 0.0794796\tvalid_1's rmse: 0.0837088\n",
      "[2400]\ttraining's rmse: 0.0794765\tvalid_1's rmse: 0.0837081\n",
      "[2425]\ttraining's rmse: 0.0794743\tvalid_1's rmse: 0.0837081\n",
      "[2450]\ttraining's rmse: 0.0794727\tvalid_1's rmse: 0.0837077\n",
      "[2475]\ttraining's rmse: 0.0794704\tvalid_1's rmse: 0.0837076\n",
      "[2500]\ttraining's rmse: 0.0794686\tvalid_1's rmse: 0.0837071\n",
      "[2525]\ttraining's rmse: 0.0794655\tvalid_1's rmse: 0.0837073\n",
      "Early stopping, best iteration is:\n",
      "[2495]\ttraining's rmse: 0.0794689\tvalid_1's rmse: 0.0837069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0823539\tvalid_1's rmse: 0.0842359\n",
      "[50]\ttraining's rmse: 0.0822337\tvalid_1's rmse: 0.084177\n",
      "[75]\ttraining's rmse: 0.0821113\tvalid_1's rmse: 0.0841204\n",
      "[100]\ttraining's rmse: 0.0820016\tvalid_1's rmse: 0.0840698\n",
      "[125]\ttraining's rmse: 0.0818852\tvalid_1's rmse: 0.084018\n",
      "[150]\ttraining's rmse: 0.081783\tvalid_1's rmse: 0.0839719\n",
      "[175]\ttraining's rmse: 0.0816984\tvalid_1's rmse: 0.0839342\n",
      "[200]\ttraining's rmse: 0.0816018\tvalid_1's rmse: 0.0838947\n",
      "[225]\ttraining's rmse: 0.0815117\tvalid_1's rmse: 0.0838584\n",
      "[250]\ttraining's rmse: 0.0814368\tvalid_1's rmse: 0.083825\n",
      "[275]\ttraining's rmse: 0.0813633\tvalid_1's rmse: 0.0837946\n",
      "[300]\ttraining's rmse: 0.081293\tvalid_1's rmse: 0.0837667\n",
      "[325]\ttraining's rmse: 0.0812189\tvalid_1's rmse: 0.0837378\n",
      "[350]\ttraining's rmse: 0.0811475\tvalid_1's rmse: 0.0837118\n",
      "[375]\ttraining's rmse: 0.0810914\tvalid_1's rmse: 0.0836899\n",
      "[400]\ttraining's rmse: 0.0810306\tvalid_1's rmse: 0.0836685\n",
      "[425]\ttraining's rmse: 0.0809759\tvalid_1's rmse: 0.0836479\n",
      "[450]\ttraining's rmse: 0.0809231\tvalid_1's rmse: 0.0836281\n",
      "[475]\ttraining's rmse: 0.0808747\tvalid_1's rmse: 0.0836109\n",
      "[500]\ttraining's rmse: 0.0808316\tvalid_1's rmse: 0.083594\n",
      "[525]\ttraining's rmse: 0.0807805\tvalid_1's rmse: 0.0835776\n",
      "[550]\ttraining's rmse: 0.0807288\tvalid_1's rmse: 0.0835611\n",
      "[575]\ttraining's rmse: 0.0806848\tvalid_1's rmse: 0.0835469\n",
      "[600]\ttraining's rmse: 0.080643\tvalid_1's rmse: 0.0835341\n",
      "[625]\ttraining's rmse: 0.0806071\tvalid_1's rmse: 0.0835217\n",
      "[650]\ttraining's rmse: 0.0805663\tvalid_1's rmse: 0.0835093\n",
      "[675]\ttraining's rmse: 0.0805213\tvalid_1's rmse: 0.0834964\n",
      "[700]\ttraining's rmse: 0.0804841\tvalid_1's rmse: 0.0834854\n",
      "[725]\ttraining's rmse: 0.0804496\tvalid_1's rmse: 0.0834752\n",
      "[750]\ttraining's rmse: 0.0804169\tvalid_1's rmse: 0.0834664\n",
      "[775]\ttraining's rmse: 0.0803869\tvalid_1's rmse: 0.083458\n",
      "[800]\ttraining's rmse: 0.0803527\tvalid_1's rmse: 0.0834505\n",
      "[825]\ttraining's rmse: 0.0803219\tvalid_1's rmse: 0.0834427\n",
      "[850]\ttraining's rmse: 0.0802948\tvalid_1's rmse: 0.0834364\n",
      "[875]\ttraining's rmse: 0.0802677\tvalid_1's rmse: 0.0834297\n",
      "[900]\ttraining's rmse: 0.0802393\tvalid_1's rmse: 0.083423\n",
      "[925]\ttraining's rmse: 0.0802132\tvalid_1's rmse: 0.0834172\n",
      "[950]\ttraining's rmse: 0.0801882\tvalid_1's rmse: 0.0834114\n",
      "[975]\ttraining's rmse: 0.0801656\tvalid_1's rmse: 0.083406\n",
      "[1000]\ttraining's rmse: 0.0801443\tvalid_1's rmse: 0.0834012\n",
      "[1025]\ttraining's rmse: 0.0801198\tvalid_1's rmse: 0.0833968\n",
      "[1050]\ttraining's rmse: 0.0801006\tvalid_1's rmse: 0.0833924\n",
      "[1075]\ttraining's rmse: 0.0800816\tvalid_1's rmse: 0.0833897\n",
      "[1100]\ttraining's rmse: 0.0800642\tvalid_1's rmse: 0.0833858\n",
      "[1125]\ttraining's rmse: 0.0800452\tvalid_1's rmse: 0.0833816\n",
      "[1150]\ttraining's rmse: 0.0800273\tvalid_1's rmse: 0.0833777\n",
      "[1175]\ttraining's rmse: 0.0800125\tvalid_1's rmse: 0.0833747\n",
      "[1200]\ttraining's rmse: 0.0799963\tvalid_1's rmse: 0.0833708\n",
      "[1225]\ttraining's rmse: 0.0799818\tvalid_1's rmse: 0.0833684\n",
      "[1250]\ttraining's rmse: 0.0799681\tvalid_1's rmse: 0.083366\n",
      "[1275]\ttraining's rmse: 0.0799528\tvalid_1's rmse: 0.0833643\n",
      "[1300]\ttraining's rmse: 0.0799421\tvalid_1's rmse: 0.0833624\n",
      "[1325]\ttraining's rmse: 0.0799291\tvalid_1's rmse: 0.0833604\n",
      "[1350]\ttraining's rmse: 0.0799158\tvalid_1's rmse: 0.0833587\n",
      "[1375]\ttraining's rmse: 0.0799046\tvalid_1's rmse: 0.0833567\n",
      "[1400]\ttraining's rmse: 0.0798931\tvalid_1's rmse: 0.0833543\n",
      "[1425]\ttraining's rmse: 0.0798827\tvalid_1's rmse: 0.0833525\n",
      "[1450]\ttraining's rmse: 0.0798709\tvalid_1's rmse: 0.0833516\n",
      "[1475]\ttraining's rmse: 0.0798603\tvalid_1's rmse: 0.0833499\n",
      "[1500]\ttraining's rmse: 0.0798523\tvalid_1's rmse: 0.0833484\n",
      "[1525]\ttraining's rmse: 0.0798432\tvalid_1's rmse: 0.0833472\n",
      "[1550]\ttraining's rmse: 0.0798312\tvalid_1's rmse: 0.0833461\n",
      "[1575]\ttraining's rmse: 0.0798236\tvalid_1's rmse: 0.0833451\n",
      "[1600]\ttraining's rmse: 0.0798178\tvalid_1's rmse: 0.0833447\n",
      "[1625]\ttraining's rmse: 0.0798103\tvalid_1's rmse: 0.0833435\n",
      "[1650]\ttraining's rmse: 0.0798028\tvalid_1's rmse: 0.0833426\n",
      "[1675]\ttraining's rmse: 0.0797975\tvalid_1's rmse: 0.0833413\n",
      "[1700]\ttraining's rmse: 0.0797901\tvalid_1's rmse: 0.0833401\n",
      "[1725]\ttraining's rmse: 0.0797848\tvalid_1's rmse: 0.0833393\n",
      "[1750]\ttraining's rmse: 0.0797766\tvalid_1's rmse: 0.0833381\n",
      "[1775]\ttraining's rmse: 0.0797703\tvalid_1's rmse: 0.0833377\n",
      "[1800]\ttraining's rmse: 0.079764\tvalid_1's rmse: 0.0833368\n",
      "[1825]\ttraining's rmse: 0.0797566\tvalid_1's rmse: 0.0833353\n",
      "[1850]\ttraining's rmse: 0.0797508\tvalid_1's rmse: 0.0833342\n",
      "[1875]\ttraining's rmse: 0.0797456\tvalid_1's rmse: 0.0833338\n",
      "[1900]\ttraining's rmse: 0.0797407\tvalid_1's rmse: 0.0833338\n",
      "[1925]\ttraining's rmse: 0.079736\tvalid_1's rmse: 0.0833336\n",
      "[1950]\ttraining's rmse: 0.0797326\tvalid_1's rmse: 0.0833331\n",
      "[1975]\ttraining's rmse: 0.0797291\tvalid_1's rmse: 0.0833326\n",
      "[2000]\ttraining's rmse: 0.0797248\tvalid_1's rmse: 0.0833321\n",
      "[2025]\ttraining's rmse: 0.0797222\tvalid_1's rmse: 0.0833317\n",
      "[2050]\ttraining's rmse: 0.0797191\tvalid_1's rmse: 0.0833316\n",
      "[2075]\ttraining's rmse: 0.0797166\tvalid_1's rmse: 0.0833314\n",
      "[2100]\ttraining's rmse: 0.0797133\tvalid_1's rmse: 0.083331\n",
      "[2125]\ttraining's rmse: 0.0797104\tvalid_1's rmse: 0.0833311\n",
      "[2150]\ttraining's rmse: 0.0797058\tvalid_1's rmse: 0.0833307\n",
      "[2175]\ttraining's rmse: 0.0797023\tvalid_1's rmse: 0.0833307\n",
      "[2200]\ttraining's rmse: 0.0797\tvalid_1's rmse: 0.0833305\n",
      "[2225]\ttraining's rmse: 0.0796976\tvalid_1's rmse: 0.0833301\n",
      "[2250]\ttraining's rmse: 0.0796954\tvalid_1's rmse: 0.08333\n",
      "[2275]\ttraining's rmse: 0.0796926\tvalid_1's rmse: 0.0833296\n",
      "[2300]\ttraining's rmse: 0.0796882\tvalid_1's rmse: 0.0833294\n",
      "[2325]\ttraining's rmse: 0.0796856\tvalid_1's rmse: 0.0833289\n",
      "[2350]\ttraining's rmse: 0.0796817\tvalid_1's rmse: 0.0833287\n",
      "[2375]\ttraining's rmse: 0.0796778\tvalid_1's rmse: 0.0833285\n",
      "[2400]\ttraining's rmse: 0.0796742\tvalid_1's rmse: 0.083329\n",
      "Early stopping, best iteration is:\n",
      "[2367]\ttraining's rmse: 0.0796789\tvalid_1's rmse: 0.0833284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0843549\tvalid_1's rmse: 0.0801773\n",
      "[50]\ttraining's rmse: 0.0842382\tvalid_1's rmse: 0.0801275\n",
      "[75]\ttraining's rmse: 0.0841181\tvalid_1's rmse: 0.0800785\n",
      "[100]\ttraining's rmse: 0.0840133\tvalid_1's rmse: 0.0800366\n",
      "[125]\ttraining's rmse: 0.0839039\tvalid_1's rmse: 0.0799943\n",
      "[150]\ttraining's rmse: 0.0838033\tvalid_1's rmse: 0.0799566\n",
      "[175]\ttraining's rmse: 0.0837197\tvalid_1's rmse: 0.0799242\n",
      "[200]\ttraining's rmse: 0.0836302\tvalid_1's rmse: 0.0798926\n",
      "[225]\ttraining's rmse: 0.0835457\tvalid_1's rmse: 0.0798614\n",
      "[250]\ttraining's rmse: 0.0834741\tvalid_1's rmse: 0.0798356\n",
      "[275]\ttraining's rmse: 0.0834067\tvalid_1's rmse: 0.0798109\n",
      "[300]\ttraining's rmse: 0.0833412\tvalid_1's rmse: 0.079788\n",
      "[325]\ttraining's rmse: 0.0832731\tvalid_1's rmse: 0.0797646\n",
      "[350]\ttraining's rmse: 0.0832072\tvalid_1's rmse: 0.0797439\n",
      "[375]\ttraining's rmse: 0.0831519\tvalid_1's rmse: 0.0797253\n",
      "[400]\ttraining's rmse: 0.083094\tvalid_1's rmse: 0.0797087\n",
      "[425]\ttraining's rmse: 0.0830394\tvalid_1's rmse: 0.0796918\n",
      "[450]\ttraining's rmse: 0.082991\tvalid_1's rmse: 0.0796762\n",
      "[475]\ttraining's rmse: 0.082944\tvalid_1's rmse: 0.0796622\n",
      "[500]\ttraining's rmse: 0.082904\tvalid_1's rmse: 0.0796521\n",
      "[525]\ttraining's rmse: 0.082853\tvalid_1's rmse: 0.0796379\n",
      "[550]\ttraining's rmse: 0.0828058\tvalid_1's rmse: 0.0796352\n",
      "[575]\ttraining's rmse: 0.082764\tvalid_1's rmse: 0.0796336\n",
      "[600]\ttraining's rmse: 0.0827196\tvalid_1's rmse: 0.0796289\n",
      "[625]\ttraining's rmse: 0.0826842\tvalid_1's rmse: 0.0796391\n",
      "Early stopping, best iteration is:\n",
      "[593]\ttraining's rmse: 0.0827341\tvalid_1's rmse: 0.0796255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0875467\tvalid_1's rmse: 0.0888244\n",
      "[50]\ttraining's rmse: 0.0873604\tvalid_1's rmse: 0.0887749\n",
      "[75]\ttraining's rmse: 0.0871706\tvalid_1's rmse: 0.088723\n",
      "[100]\ttraining's rmse: 0.0869975\tvalid_1's rmse: 0.0886766\n",
      "[125]\ttraining's rmse: 0.0868245\tvalid_1's rmse: 0.0886287\n",
      "[150]\ttraining's rmse: 0.0866681\tvalid_1's rmse: 0.0885862\n",
      "[175]\ttraining's rmse: 0.0865379\tvalid_1's rmse: 0.0885496\n",
      "[200]\ttraining's rmse: 0.0863983\tvalid_1's rmse: 0.0885144\n",
      "[225]\ttraining's rmse: 0.0862635\tvalid_1's rmse: 0.0884793\n",
      "[250]\ttraining's rmse: 0.0861492\tvalid_1's rmse: 0.0884471\n",
      "[275]\ttraining's rmse: 0.0860425\tvalid_1's rmse: 0.0884179\n",
      "[300]\ttraining's rmse: 0.085941\tvalid_1's rmse: 0.0883917\n",
      "[325]\ttraining's rmse: 0.0858414\tvalid_1's rmse: 0.0883672\n",
      "[350]\ttraining's rmse: 0.0857422\tvalid_1's rmse: 0.0883433\n",
      "[375]\ttraining's rmse: 0.0856586\tvalid_1's rmse: 0.0883237\n",
      "[400]\ttraining's rmse: 0.0855678\tvalid_1's rmse: 0.0883022\n",
      "[425]\ttraining's rmse: 0.085485\tvalid_1's rmse: 0.088284\n",
      "[450]\ttraining's rmse: 0.0854122\tvalid_1's rmse: 0.0882642\n",
      "[475]\ttraining's rmse: 0.0853426\tvalid_1's rmse: 0.0882469\n",
      "[500]\ttraining's rmse: 0.0852852\tvalid_1's rmse: 0.0882297\n",
      "[525]\ttraining's rmse: 0.0852156\tvalid_1's rmse: 0.0882123\n",
      "[550]\ttraining's rmse: 0.0851524\tvalid_1's rmse: 0.0881972\n",
      "[575]\ttraining's rmse: 0.0850923\tvalid_1's rmse: 0.0881834\n",
      "[600]\ttraining's rmse: 0.0850317\tvalid_1's rmse: 0.0881702\n",
      "[625]\ttraining's rmse: 0.0849848\tvalid_1's rmse: 0.0881586\n",
      "[650]\ttraining's rmse: 0.084933\tvalid_1's rmse: 0.0881459\n",
      "[675]\ttraining's rmse: 0.0848803\tvalid_1's rmse: 0.0881343\n",
      "[700]\ttraining's rmse: 0.0848347\tvalid_1's rmse: 0.0881224\n",
      "[725]\ttraining's rmse: 0.0847903\tvalid_1's rmse: 0.0881126\n",
      "[750]\ttraining's rmse: 0.0847484\tvalid_1's rmse: 0.0881032\n",
      "[775]\ttraining's rmse: 0.0847144\tvalid_1's rmse: 0.0880957\n",
      "[800]\ttraining's rmse: 0.0846715\tvalid_1's rmse: 0.0880862\n",
      "[825]\ttraining's rmse: 0.0846355\tvalid_1's rmse: 0.088078\n",
      "[850]\ttraining's rmse: 0.0845956\tvalid_1's rmse: 0.0880716\n",
      "[875]\ttraining's rmse: 0.0845643\tvalid_1's rmse: 0.0880644\n",
      "[900]\ttraining's rmse: 0.08453\tvalid_1's rmse: 0.0880569\n",
      "[925]\ttraining's rmse: 0.0844986\tvalid_1's rmse: 0.0880487\n",
      "[950]\ttraining's rmse: 0.0844699\tvalid_1's rmse: 0.0880427\n",
      "[975]\ttraining's rmse: 0.084442\tvalid_1's rmse: 0.0880375\n",
      "[1000]\ttraining's rmse: 0.0844135\tvalid_1's rmse: 0.0880327\n",
      "[1025]\ttraining's rmse: 0.0843884\tvalid_1's rmse: 0.088027\n",
      "[1050]\ttraining's rmse: 0.0843609\tvalid_1's rmse: 0.0880206\n",
      "[1075]\ttraining's rmse: 0.0843375\tvalid_1's rmse: 0.0880162\n",
      "[1100]\ttraining's rmse: 0.084315\tvalid_1's rmse: 0.0880121\n",
      "[1125]\ttraining's rmse: 0.084293\tvalid_1's rmse: 0.0880074\n",
      "[1150]\ttraining's rmse: 0.0842705\tvalid_1's rmse: 0.0880015\n",
      "[1175]\ttraining's rmse: 0.0842508\tvalid_1's rmse: 0.0879977\n",
      "[1200]\ttraining's rmse: 0.0842313\tvalid_1's rmse: 0.087993\n",
      "[1225]\ttraining's rmse: 0.0842113\tvalid_1's rmse: 0.0879896\n",
      "[1250]\ttraining's rmse: 0.084191\tvalid_1's rmse: 0.0879852\n",
      "[1275]\ttraining's rmse: 0.0841691\tvalid_1's rmse: 0.0879819\n",
      "[1300]\ttraining's rmse: 0.0841508\tvalid_1's rmse: 0.0879774\n",
      "[1325]\ttraining's rmse: 0.0841352\tvalid_1's rmse: 0.0879741\n",
      "[1350]\ttraining's rmse: 0.0841201\tvalid_1's rmse: 0.0879715\n",
      "[1375]\ttraining's rmse: 0.0841046\tvalid_1's rmse: 0.0879679\n",
      "[1400]\ttraining's rmse: 0.0840889\tvalid_1's rmse: 0.087965\n",
      "[1425]\ttraining's rmse: 0.0840756\tvalid_1's rmse: 0.0879613\n",
      "[1450]\ttraining's rmse: 0.0840589\tvalid_1's rmse: 0.0879569\n",
      "[1475]\ttraining's rmse: 0.0840449\tvalid_1's rmse: 0.0879545\n",
      "[1500]\ttraining's rmse: 0.084035\tvalid_1's rmse: 0.0879524\n",
      "[1525]\ttraining's rmse: 0.0840243\tvalid_1's rmse: 0.0879499\n",
      "[1550]\ttraining's rmse: 0.0840132\tvalid_1's rmse: 0.0879484\n",
      "[1575]\ttraining's rmse: 0.0840032\tvalid_1's rmse: 0.0879456\n",
      "[1600]\ttraining's rmse: 0.0839943\tvalid_1's rmse: 0.0879437\n",
      "[1625]\ttraining's rmse: 0.0839856\tvalid_1's rmse: 0.0879406\n",
      "[1650]\ttraining's rmse: 0.083975\tvalid_1's rmse: 0.0879377\n",
      "[1675]\ttraining's rmse: 0.0839696\tvalid_1's rmse: 0.0879349\n",
      "[1700]\ttraining's rmse: 0.0839638\tvalid_1's rmse: 0.0879329\n",
      "[1725]\ttraining's rmse: 0.0839545\tvalid_1's rmse: 0.0879313\n",
      "[1750]\ttraining's rmse: 0.0839466\tvalid_1's rmse: 0.0879289\n",
      "[1775]\ttraining's rmse: 0.083938\tvalid_1's rmse: 0.0879262\n",
      "[1800]\ttraining's rmse: 0.0839318\tvalid_1's rmse: 0.0879257\n",
      "[1825]\ttraining's rmse: 0.0839238\tvalid_1's rmse: 0.0879234\n",
      "[1850]\ttraining's rmse: 0.0839168\tvalid_1's rmse: 0.0879215\n",
      "[1875]\ttraining's rmse: 0.0839109\tvalid_1's rmse: 0.0879202\n",
      "[1900]\ttraining's rmse: 0.0839049\tvalid_1's rmse: 0.0879184\n",
      "[1925]\ttraining's rmse: 0.0838991\tvalid_1's rmse: 0.0879165\n",
      "[1950]\ttraining's rmse: 0.0838942\tvalid_1's rmse: 0.0879154\n",
      "[1975]\ttraining's rmse: 0.0838898\tvalid_1's rmse: 0.0879133\n",
      "[2000]\ttraining's rmse: 0.0838841\tvalid_1's rmse: 0.0879123\n",
      "[2025]\ttraining's rmse: 0.0838807\tvalid_1's rmse: 0.0879114\n",
      "[2050]\ttraining's rmse: 0.0838766\tvalid_1's rmse: 0.0879097\n",
      "[2075]\ttraining's rmse: 0.0838715\tvalid_1's rmse: 0.0879085\n",
      "[2100]\ttraining's rmse: 0.0838665\tvalid_1's rmse: 0.087907\n",
      "[2125]\ttraining's rmse: 0.0838631\tvalid_1's rmse: 0.0879057\n",
      "[2150]\ttraining's rmse: 0.0838596\tvalid_1's rmse: 0.0879048\n",
      "[2175]\ttraining's rmse: 0.083855\tvalid_1's rmse: 0.0879044\n",
      "[2200]\ttraining's rmse: 0.0838515\tvalid_1's rmse: 0.0879037\n",
      "[2225]\ttraining's rmse: 0.0838482\tvalid_1's rmse: 0.0879025\n",
      "[2250]\ttraining's rmse: 0.0838447\tvalid_1's rmse: 0.0879006\n",
      "[2275]\ttraining's rmse: 0.0838413\tvalid_1's rmse: 0.0878997\n",
      "[2300]\ttraining's rmse: 0.0838378\tvalid_1's rmse: 0.0878994\n",
      "[2325]\ttraining's rmse: 0.0838343\tvalid_1's rmse: 0.087899\n",
      "[2350]\ttraining's rmse: 0.083831\tvalid_1's rmse: 0.0878982\n",
      "[2375]\ttraining's rmse: 0.0838266\tvalid_1's rmse: 0.0878977\n",
      "[2400]\ttraining's rmse: 0.0838245\tvalid_1's rmse: 0.0878964\n",
      "[2425]\ttraining's rmse: 0.0838223\tvalid_1's rmse: 0.0878964\n",
      "[2450]\ttraining's rmse: 0.0838189\tvalid_1's rmse: 0.0878949\n",
      "[2475]\ttraining's rmse: 0.0838152\tvalid_1's rmse: 0.0878944\n",
      "[2500]\ttraining's rmse: 0.0838135\tvalid_1's rmse: 0.0878942\n",
      "[2525]\ttraining's rmse: 0.0838105\tvalid_1's rmse: 0.0878927\n",
      "[2550]\ttraining's rmse: 0.0838079\tvalid_1's rmse: 0.0878927\n",
      "[2575]\ttraining's rmse: 0.0838053\tvalid_1's rmse: 0.087892\n",
      "[2600]\ttraining's rmse: 0.0838028\tvalid_1's rmse: 0.0878906\n",
      "[2625]\ttraining's rmse: 0.0837997\tvalid_1's rmse: 0.0878895\n",
      "[2650]\ttraining's rmse: 0.0837972\tvalid_1's rmse: 0.0878884\n",
      "[2675]\ttraining's rmse: 0.0837945\tvalid_1's rmse: 0.0878875\n",
      "[2700]\ttraining's rmse: 0.0837929\tvalid_1's rmse: 0.0878872\n",
      "[2725]\ttraining's rmse: 0.0837905\tvalid_1's rmse: 0.0878874\n",
      "[2750]\ttraining's rmse: 0.0837894\tvalid_1's rmse: 0.0878867\n",
      "[2775]\ttraining's rmse: 0.0837874\tvalid_1's rmse: 0.0878866\n",
      "[2800]\ttraining's rmse: 0.0837855\tvalid_1's rmse: 0.0878869\n",
      "[2825]\ttraining's rmse: 0.0837832\tvalid_1's rmse: 0.0878866\n",
      "[2850]\ttraining's rmse: 0.0837796\tvalid_1's rmse: 0.0878859\n",
      "[2875]\ttraining's rmse: 0.0837774\tvalid_1's rmse: 0.0878856\n",
      "[2900]\ttraining's rmse: 0.0837757\tvalid_1's rmse: 0.0878854\n",
      "[2925]\ttraining's rmse: 0.0837744\tvalid_1's rmse: 0.0878849\n",
      "[2950]\ttraining's rmse: 0.0837731\tvalid_1's rmse: 0.0878853\n",
      "Early stopping, best iteration is:\n",
      "[2920]\ttraining's rmse: 0.0837745\tvalid_1's rmse: 0.0878848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0873586\tvalid_1's rmse: 0.0892277\n",
      "[50]\ttraining's rmse: 0.0871934\tvalid_1's rmse: 0.0891712\n",
      "[75]\ttraining's rmse: 0.0870238\tvalid_1's rmse: 0.0891152\n",
      "[100]\ttraining's rmse: 0.0868747\tvalid_1's rmse: 0.0890652\n",
      "[125]\ttraining's rmse: 0.0867272\tvalid_1's rmse: 0.089017\n",
      "[150]\ttraining's rmse: 0.0865872\tvalid_1's rmse: 0.0889702\n",
      "[175]\ttraining's rmse: 0.086472\tvalid_1's rmse: 0.0889315\n",
      "[200]\ttraining's rmse: 0.0863499\tvalid_1's rmse: 0.088893\n",
      "[225]\ttraining's rmse: 0.0862322\tvalid_1's rmse: 0.0888565\n",
      "[250]\ttraining's rmse: 0.0861336\tvalid_1's rmse: 0.088824\n",
      "[275]\ttraining's rmse: 0.0860411\tvalid_1's rmse: 0.0887945\n",
      "[300]\ttraining's rmse: 0.0859488\tvalid_1's rmse: 0.0887662\n",
      "[325]\ttraining's rmse: 0.085857\tvalid_1's rmse: 0.0887392\n",
      "[350]\ttraining's rmse: 0.0857706\tvalid_1's rmse: 0.0887135\n",
      "[375]\ttraining's rmse: 0.0856987\tvalid_1's rmse: 0.0886927\n",
      "[400]\ttraining's rmse: 0.0856227\tvalid_1's rmse: 0.088671\n",
      "[425]\ttraining's rmse: 0.0855493\tvalid_1's rmse: 0.0886485\n",
      "[450]\ttraining's rmse: 0.0854854\tvalid_1's rmse: 0.0886286\n",
      "[475]\ttraining's rmse: 0.0854257\tvalid_1's rmse: 0.0886104\n",
      "[500]\ttraining's rmse: 0.0853743\tvalid_1's rmse: 0.0885915\n",
      "[525]\ttraining's rmse: 0.0853105\tvalid_1's rmse: 0.0885733\n",
      "[550]\ttraining's rmse: 0.0852505\tvalid_1's rmse: 0.0885569\n",
      "[575]\ttraining's rmse: 0.0851984\tvalid_1's rmse: 0.0885424\n",
      "[600]\ttraining's rmse: 0.0851465\tvalid_1's rmse: 0.0885277\n",
      "[625]\ttraining's rmse: 0.0851053\tvalid_1's rmse: 0.0885132\n",
      "[650]\ttraining's rmse: 0.0850559\tvalid_1's rmse: 0.0884997\n",
      "[675]\ttraining's rmse: 0.0850086\tvalid_1's rmse: 0.0884867\n",
      "[700]\ttraining's rmse: 0.0849657\tvalid_1's rmse: 0.0884749\n",
      "[725]\ttraining's rmse: 0.0849278\tvalid_1's rmse: 0.0884653\n",
      "[750]\ttraining's rmse: 0.0848914\tvalid_1's rmse: 0.0884551\n",
      "[775]\ttraining's rmse: 0.0848578\tvalid_1's rmse: 0.0884453\n",
      "[800]\ttraining's rmse: 0.0848157\tvalid_1's rmse: 0.0884367\n",
      "[825]\ttraining's rmse: 0.0847834\tvalid_1's rmse: 0.0884282\n",
      "[850]\ttraining's rmse: 0.0847487\tvalid_1's rmse: 0.0884221\n",
      "[875]\ttraining's rmse: 0.0847187\tvalid_1's rmse: 0.0884144\n",
      "[900]\ttraining's rmse: 0.0846862\tvalid_1's rmse: 0.0884057\n",
      "[925]\ttraining's rmse: 0.0846558\tvalid_1's rmse: 0.0883988\n",
      "[950]\ttraining's rmse: 0.084626\tvalid_1's rmse: 0.0883922\n",
      "[975]\ttraining's rmse: 0.0845999\tvalid_1's rmse: 0.0883857\n",
      "[1000]\ttraining's rmse: 0.084575\tvalid_1's rmse: 0.0883801\n",
      "[1025]\ttraining's rmse: 0.0845471\tvalid_1's rmse: 0.0883751\n",
      "[1050]\ttraining's rmse: 0.0845211\tvalid_1's rmse: 0.0883695\n",
      "[1075]\ttraining's rmse: 0.0844968\tvalid_1's rmse: 0.0883653\n",
      "[1100]\ttraining's rmse: 0.0844775\tvalid_1's rmse: 0.0883609\n",
      "[1125]\ttraining's rmse: 0.0844561\tvalid_1's rmse: 0.0883567\n",
      "[1150]\ttraining's rmse: 0.084434\tvalid_1's rmse: 0.0883533\n",
      "[1175]\ttraining's rmse: 0.0844157\tvalid_1's rmse: 0.0883504\n",
      "[1200]\ttraining's rmse: 0.0843969\tvalid_1's rmse: 0.0883461\n",
      "[1225]\ttraining's rmse: 0.0843787\tvalid_1's rmse: 0.0883428\n",
      "[1250]\ttraining's rmse: 0.0843597\tvalid_1's rmse: 0.0883396\n",
      "[1275]\ttraining's rmse: 0.0843412\tvalid_1's rmse: 0.0883376\n",
      "[1300]\ttraining's rmse: 0.0843254\tvalid_1's rmse: 0.0883342\n",
      "[1325]\ttraining's rmse: 0.0843094\tvalid_1's rmse: 0.0883311\n",
      "[1350]\ttraining's rmse: 0.0842932\tvalid_1's rmse: 0.0883288\n",
      "[1375]\ttraining's rmse: 0.0842772\tvalid_1's rmse: 0.0883266\n",
      "[1400]\ttraining's rmse: 0.0842652\tvalid_1's rmse: 0.088324\n",
      "[1425]\ttraining's rmse: 0.0842498\tvalid_1's rmse: 0.0883227\n",
      "[1450]\ttraining's rmse: 0.0842375\tvalid_1's rmse: 0.0883211\n",
      "[1475]\ttraining's rmse: 0.0842236\tvalid_1's rmse: 0.0883189\n",
      "[1500]\ttraining's rmse: 0.0842142\tvalid_1's rmse: 0.0883174\n",
      "[1525]\ttraining's rmse: 0.0842048\tvalid_1's rmse: 0.0883156\n",
      "[1550]\ttraining's rmse: 0.0841918\tvalid_1's rmse: 0.0883144\n",
      "[1575]\ttraining's rmse: 0.0841819\tvalid_1's rmse: 0.0883127\n",
      "[1600]\ttraining's rmse: 0.0841741\tvalid_1's rmse: 0.0883115\n",
      "[1625]\ttraining's rmse: 0.0841648\tvalid_1's rmse: 0.0883099\n",
      "[1650]\ttraining's rmse: 0.0841551\tvalid_1's rmse: 0.0883097\n",
      "[1675]\ttraining's rmse: 0.0841477\tvalid_1's rmse: 0.0883088\n",
      "[1700]\ttraining's rmse: 0.0841407\tvalid_1's rmse: 0.088308\n",
      "[1725]\ttraining's rmse: 0.0841334\tvalid_1's rmse: 0.0883062\n",
      "[1750]\ttraining's rmse: 0.0841252\tvalid_1's rmse: 0.0883054\n",
      "[1775]\ttraining's rmse: 0.0841173\tvalid_1's rmse: 0.0883045\n",
      "[1800]\ttraining's rmse: 0.0841108\tvalid_1's rmse: 0.0883031\n",
      "[1825]\ttraining's rmse: 0.0841048\tvalid_1's rmse: 0.0883022\n",
      "[1850]\ttraining's rmse: 0.0840997\tvalid_1's rmse: 0.0883015\n",
      "[1875]\ttraining's rmse: 0.0840928\tvalid_1's rmse: 0.088301\n",
      "[1900]\ttraining's rmse: 0.0840863\tvalid_1's rmse: 0.088301\n",
      "[1925]\ttraining's rmse: 0.0840802\tvalid_1's rmse: 0.0883002\n",
      "[1950]\ttraining's rmse: 0.084074\tvalid_1's rmse: 0.0882993\n",
      "[1975]\ttraining's rmse: 0.0840702\tvalid_1's rmse: 0.0882985\n",
      "[2000]\ttraining's rmse: 0.0840651\tvalid_1's rmse: 0.0882975\n",
      "[2025]\ttraining's rmse: 0.0840608\tvalid_1's rmse: 0.088297\n",
      "[2050]\ttraining's rmse: 0.0840546\tvalid_1's rmse: 0.0882967\n",
      "[2075]\ttraining's rmse: 0.0840506\tvalid_1's rmse: 0.0882965\n",
      "[2100]\ttraining's rmse: 0.0840472\tvalid_1's rmse: 0.0882961\n",
      "[2125]\ttraining's rmse: 0.0840427\tvalid_1's rmse: 0.0882955\n",
      "[2150]\ttraining's rmse: 0.084038\tvalid_1's rmse: 0.0882949\n",
      "[2175]\ttraining's rmse: 0.0840351\tvalid_1's rmse: 0.0882946\n",
      "[2200]\ttraining's rmse: 0.0840308\tvalid_1's rmse: 0.0882941\n",
      "[2225]\ttraining's rmse: 0.0840268\tvalid_1's rmse: 0.0882938\n",
      "[2250]\ttraining's rmse: 0.0840234\tvalid_1's rmse: 0.0882937\n",
      "[2275]\ttraining's rmse: 0.0840189\tvalid_1's rmse: 0.0882934\n",
      "[2300]\ttraining's rmse: 0.0840168\tvalid_1's rmse: 0.0882934\n",
      "[2325]\ttraining's rmse: 0.0840136\tvalid_1's rmse: 0.0882935\n",
      "Early stopping, best iteration is:\n",
      "[2282]\ttraining's rmse: 0.0840185\tvalid_1's rmse: 0.0882932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0888764\tvalid_1's rmse: 0.086213\n",
      "[50]\ttraining's rmse: 0.0887417\tvalid_1's rmse: 0.0861625\n",
      "[75]\ttraining's rmse: 0.0886013\tvalid_1's rmse: 0.0861113\n",
      "[100]\ttraining's rmse: 0.0884731\tvalid_1's rmse: 0.0860663\n",
      "[125]\ttraining's rmse: 0.0883408\tvalid_1's rmse: 0.086024\n",
      "[150]\ttraining's rmse: 0.0882191\tvalid_1's rmse: 0.0859871\n",
      "[175]\ttraining's rmse: 0.0881176\tvalid_1's rmse: 0.085954\n",
      "[200]\ttraining's rmse: 0.0880064\tvalid_1's rmse: 0.0859205\n",
      "[225]\ttraining's rmse: 0.0878994\tvalid_1's rmse: 0.0858885\n",
      "[250]\ttraining's rmse: 0.0878091\tvalid_1's rmse: 0.0858631\n",
      "[275]\ttraining's rmse: 0.0877266\tvalid_1's rmse: 0.0858388\n",
      "[300]\ttraining's rmse: 0.0876444\tvalid_1's rmse: 0.085816\n",
      "[325]\ttraining's rmse: 0.0875593\tvalid_1's rmse: 0.085794\n",
      "[350]\ttraining's rmse: 0.0874764\tvalid_1's rmse: 0.0857721\n",
      "[375]\ttraining's rmse: 0.0874114\tvalid_1's rmse: 0.085756\n",
      "[400]\ttraining's rmse: 0.0873366\tvalid_1's rmse: 0.0857384\n",
      "[425]\ttraining's rmse: 0.0872694\tvalid_1's rmse: 0.0857258\n",
      "[450]\ttraining's rmse: 0.0872096\tvalid_1's rmse: 0.0857117\n",
      "[475]\ttraining's rmse: 0.0871538\tvalid_1's rmse: 0.0856994\n",
      "[500]\ttraining's rmse: 0.0871055\tvalid_1's rmse: 0.0856876\n",
      "[525]\ttraining's rmse: 0.0870404\tvalid_1's rmse: 0.0856797\n",
      "[550]\ttraining's rmse: 0.0869838\tvalid_1's rmse: 0.08567\n",
      "[575]\ttraining's rmse: 0.0869287\tvalid_1's rmse: 0.0856631\n",
      "[600]\ttraining's rmse: 0.0868775\tvalid_1's rmse: 0.0856552\n",
      "[625]\ttraining's rmse: 0.0868334\tvalid_1's rmse: 0.0856466\n",
      "[650]\ttraining's rmse: 0.0867834\tvalid_1's rmse: 0.085649\n",
      "[675]\ttraining's rmse: 0.0867307\tvalid_1's rmse: 0.0856467\n",
      "[700]\ttraining's rmse: 0.0866874\tvalid_1's rmse: 0.0856401\n",
      "[725]\ttraining's rmse: 0.0866465\tvalid_1's rmse: 0.0856446\n",
      "[750]\ttraining's rmse: 0.0866078\tvalid_1's rmse: 0.0856414\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0866785\tvalid_1's rmse: 0.0856396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0824121\tvalid_1's rmse: 0.0850257\n",
      "[50]\ttraining's rmse: 0.0822888\tvalid_1's rmse: 0.0849678\n",
      "[75]\ttraining's rmse: 0.0821627\tvalid_1's rmse: 0.0849087\n",
      "[100]\ttraining's rmse: 0.0820454\tvalid_1's rmse: 0.08486\n",
      "[125]\ttraining's rmse: 0.0819292\tvalid_1's rmse: 0.0848108\n",
      "[150]\ttraining's rmse: 0.0818259\tvalid_1's rmse: 0.0847661\n",
      "[175]\ttraining's rmse: 0.0817342\tvalid_1's rmse: 0.0847258\n",
      "[200]\ttraining's rmse: 0.0816386\tvalid_1's rmse: 0.0846859\n",
      "[225]\ttraining's rmse: 0.0815472\tvalid_1's rmse: 0.0846494\n",
      "[250]\ttraining's rmse: 0.0814724\tvalid_1's rmse: 0.0846157\n",
      "[275]\ttraining's rmse: 0.0814007\tvalid_1's rmse: 0.0845841\n",
      "[300]\ttraining's rmse: 0.0813291\tvalid_1's rmse: 0.0845551\n",
      "[325]\ttraining's rmse: 0.0812562\tvalid_1's rmse: 0.0845278\n",
      "[350]\ttraining's rmse: 0.0811897\tvalid_1's rmse: 0.0845015\n",
      "[375]\ttraining's rmse: 0.0811334\tvalid_1's rmse: 0.084477\n",
      "[400]\ttraining's rmse: 0.0810721\tvalid_1's rmse: 0.0844536\n",
      "[425]\ttraining's rmse: 0.0810176\tvalid_1's rmse: 0.0844312\n",
      "[450]\ttraining's rmse: 0.0809664\tvalid_1's rmse: 0.0844097\n",
      "[475]\ttraining's rmse: 0.0809181\tvalid_1's rmse: 0.0843876\n",
      "[500]\ttraining's rmse: 0.0808759\tvalid_1's rmse: 0.0843674\n",
      "[525]\ttraining's rmse: 0.0808265\tvalid_1's rmse: 0.0843501\n",
      "[550]\ttraining's rmse: 0.0807801\tvalid_1's rmse: 0.0843339\n",
      "[575]\ttraining's rmse: 0.0807333\tvalid_1's rmse: 0.0843181\n",
      "[600]\ttraining's rmse: 0.0806917\tvalid_1's rmse: 0.0843031\n",
      "[625]\ttraining's rmse: 0.0806566\tvalid_1's rmse: 0.0842904\n",
      "[650]\ttraining's rmse: 0.0806153\tvalid_1's rmse: 0.0842756\n",
      "[675]\ttraining's rmse: 0.0805752\tvalid_1's rmse: 0.0842613\n",
      "[700]\ttraining's rmse: 0.0805415\tvalid_1's rmse: 0.0842489\n",
      "[725]\ttraining's rmse: 0.0805079\tvalid_1's rmse: 0.0842368\n",
      "[750]\ttraining's rmse: 0.0804736\tvalid_1's rmse: 0.0842271\n",
      "[775]\ttraining's rmse: 0.0804485\tvalid_1's rmse: 0.0842142\n",
      "[800]\ttraining's rmse: 0.0804149\tvalid_1's rmse: 0.0842042\n",
      "[825]\ttraining's rmse: 0.0803878\tvalid_1's rmse: 0.0841943\n",
      "[850]\ttraining's rmse: 0.0803604\tvalid_1's rmse: 0.0841851\n",
      "[875]\ttraining's rmse: 0.0803332\tvalid_1's rmse: 0.084176\n",
      "[900]\ttraining's rmse: 0.0803051\tvalid_1's rmse: 0.0841677\n",
      "[925]\ttraining's rmse: 0.0802796\tvalid_1's rmse: 0.0841588\n",
      "[950]\ttraining's rmse: 0.0802569\tvalid_1's rmse: 0.0841522\n",
      "[975]\ttraining's rmse: 0.0802346\tvalid_1's rmse: 0.0841457\n",
      "[1000]\ttraining's rmse: 0.0802147\tvalid_1's rmse: 0.0841395\n",
      "[1025]\ttraining's rmse: 0.0801903\tvalid_1's rmse: 0.0841327\n",
      "[1050]\ttraining's rmse: 0.0801705\tvalid_1's rmse: 0.0841252\n",
      "[1075]\ttraining's rmse: 0.0801515\tvalid_1's rmse: 0.0841216\n",
      "[1100]\ttraining's rmse: 0.0801355\tvalid_1's rmse: 0.0841164\n",
      "[1125]\ttraining's rmse: 0.0801184\tvalid_1's rmse: 0.0841096\n",
      "[1150]\ttraining's rmse: 0.0801008\tvalid_1's rmse: 0.0841041\n",
      "[1175]\ttraining's rmse: 0.0800846\tvalid_1's rmse: 0.0841\n",
      "[1200]\ttraining's rmse: 0.0800699\tvalid_1's rmse: 0.0840966\n",
      "[1225]\ttraining's rmse: 0.0800531\tvalid_1's rmse: 0.0840918\n",
      "[1250]\ttraining's rmse: 0.0800386\tvalid_1's rmse: 0.084088\n",
      "[1275]\ttraining's rmse: 0.0800229\tvalid_1's rmse: 0.0840841\n",
      "[1300]\ttraining's rmse: 0.0800099\tvalid_1's rmse: 0.0840789\n",
      "[1325]\ttraining's rmse: 0.079997\tvalid_1's rmse: 0.0840756\n",
      "[1350]\ttraining's rmse: 0.0799839\tvalid_1's rmse: 0.0840725\n",
      "[1375]\ttraining's rmse: 0.0799737\tvalid_1's rmse: 0.0840693\n",
      "[1400]\ttraining's rmse: 0.0799632\tvalid_1's rmse: 0.0840645\n",
      "[1425]\ttraining's rmse: 0.0799493\tvalid_1's rmse: 0.0840622\n",
      "[1450]\ttraining's rmse: 0.0799379\tvalid_1's rmse: 0.084059\n",
      "[1475]\ttraining's rmse: 0.0799265\tvalid_1's rmse: 0.0840559\n",
      "[1500]\ttraining's rmse: 0.0799185\tvalid_1's rmse: 0.0840536\n",
      "[1525]\ttraining's rmse: 0.0799093\tvalid_1's rmse: 0.0840508\n",
      "[1550]\ttraining's rmse: 0.0798971\tvalid_1's rmse: 0.0840486\n",
      "[1575]\ttraining's rmse: 0.079889\tvalid_1's rmse: 0.084046\n",
      "[1600]\ttraining's rmse: 0.0798819\tvalid_1's rmse: 0.0840443\n",
      "[1625]\ttraining's rmse: 0.0798761\tvalid_1's rmse: 0.0840401\n",
      "[1650]\ttraining's rmse: 0.0798703\tvalid_1's rmse: 0.0840387\n",
      "[1675]\ttraining's rmse: 0.0798644\tvalid_1's rmse: 0.0840354\n",
      "[1700]\ttraining's rmse: 0.0798583\tvalid_1's rmse: 0.0840326\n",
      "[1725]\ttraining's rmse: 0.0798522\tvalid_1's rmse: 0.084031\n",
      "[1750]\ttraining's rmse: 0.0798462\tvalid_1's rmse: 0.0840298\n",
      "[1775]\ttraining's rmse: 0.0798392\tvalid_1's rmse: 0.0840294\n",
      "[1800]\ttraining's rmse: 0.079834\tvalid_1's rmse: 0.0840274\n",
      "[1825]\ttraining's rmse: 0.0798273\tvalid_1's rmse: 0.0840256\n",
      "[1850]\ttraining's rmse: 0.0798219\tvalid_1's rmse: 0.0840246\n",
      "[1875]\ttraining's rmse: 0.0798178\tvalid_1's rmse: 0.084024\n",
      "[1900]\ttraining's rmse: 0.0798131\tvalid_1's rmse: 0.0840234\n",
      "[1925]\ttraining's rmse: 0.079808\tvalid_1's rmse: 0.0840224\n",
      "[1950]\ttraining's rmse: 0.0798049\tvalid_1's rmse: 0.084021\n",
      "[1975]\ttraining's rmse: 0.0797999\tvalid_1's rmse: 0.0840191\n",
      "[2000]\ttraining's rmse: 0.0797946\tvalid_1's rmse: 0.0840184\n",
      "[2025]\ttraining's rmse: 0.0797908\tvalid_1's rmse: 0.0840167\n",
      "[2050]\ttraining's rmse: 0.0797879\tvalid_1's rmse: 0.0840154\n",
      "[2075]\ttraining's rmse: 0.0797851\tvalid_1's rmse: 0.0840153\n",
      "[2100]\ttraining's rmse: 0.0797805\tvalid_1's rmse: 0.0840145\n",
      "[2125]\ttraining's rmse: 0.0797773\tvalid_1's rmse: 0.0840136\n",
      "[2150]\ttraining's rmse: 0.0797733\tvalid_1's rmse: 0.0840127\n",
      "[2175]\ttraining's rmse: 0.0797714\tvalid_1's rmse: 0.0840118\n",
      "[2200]\ttraining's rmse: 0.0797666\tvalid_1's rmse: 0.0840108\n",
      "[2225]\ttraining's rmse: 0.0797623\tvalid_1's rmse: 0.0840093\n",
      "[2250]\ttraining's rmse: 0.0797594\tvalid_1's rmse: 0.0840078\n",
      "[2275]\ttraining's rmse: 0.0797566\tvalid_1's rmse: 0.0840072\n",
      "[2300]\ttraining's rmse: 0.0797544\tvalid_1's rmse: 0.0840069\n",
      "[2325]\ttraining's rmse: 0.0797511\tvalid_1's rmse: 0.0840061\n",
      "[2350]\ttraining's rmse: 0.0797491\tvalid_1's rmse: 0.0840059\n",
      "[2375]\ttraining's rmse: 0.079747\tvalid_1's rmse: 0.0840051\n",
      "[2400]\ttraining's rmse: 0.0797446\tvalid_1's rmse: 0.0840046\n",
      "[2425]\ttraining's rmse: 0.0797427\tvalid_1's rmse: 0.0840039\n",
      "[2450]\ttraining's rmse: 0.0797407\tvalid_1's rmse: 0.0840037\n",
      "[2475]\ttraining's rmse: 0.0797357\tvalid_1's rmse: 0.0840027\n",
      "[2500]\ttraining's rmse: 0.079733\tvalid_1's rmse: 0.084002\n",
      "[2525]\ttraining's rmse: 0.0797297\tvalid_1's rmse: 0.0840018\n",
      "[2550]\ttraining's rmse: 0.079726\tvalid_1's rmse: 0.0840025\n",
      "[2575]\ttraining's rmse: 0.0797237\tvalid_1's rmse: 0.0840015\n",
      "[2600]\ttraining's rmse: 0.0797202\tvalid_1's rmse: 0.0840015\n",
      "[2625]\ttraining's rmse: 0.0797182\tvalid_1's rmse: 0.0840012\n",
      "[2650]\ttraining's rmse: 0.0797158\tvalid_1's rmse: 0.0840009\n",
      "[2675]\ttraining's rmse: 0.0797139\tvalid_1's rmse: 0.0840006\n",
      "[2700]\ttraining's rmse: 0.0797121\tvalid_1's rmse: 0.0839998\n",
      "[2725]\ttraining's rmse: 0.0797109\tvalid_1's rmse: 0.0839997\n",
      "[2750]\ttraining's rmse: 0.0797074\tvalid_1's rmse: 0.0839989\n",
      "[2775]\ttraining's rmse: 0.0797056\tvalid_1's rmse: 0.0839984\n",
      "[2800]\ttraining's rmse: 0.0797036\tvalid_1's rmse: 0.0839982\n",
      "[2825]\ttraining's rmse: 0.0797017\tvalid_1's rmse: 0.0839983\n",
      "[2850]\ttraining's rmse: 0.0796996\tvalid_1's rmse: 0.0839982\n",
      "[2875]\ttraining's rmse: 0.0796996\tvalid_1's rmse: 0.0839982\n",
      "Early stopping, best iteration is:\n",
      "[2830]\ttraining's rmse: 0.079701\tvalid_1's rmse: 0.083998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0826615\tvalid_1's rmse: 0.0845237\n",
      "[50]\ttraining's rmse: 0.0825366\tvalid_1's rmse: 0.0844629\n",
      "[75]\ttraining's rmse: 0.0824146\tvalid_1's rmse: 0.0844053\n",
      "[100]\ttraining's rmse: 0.0823032\tvalid_1's rmse: 0.0843554\n",
      "[125]\ttraining's rmse: 0.082187\tvalid_1's rmse: 0.0843049\n",
      "[150]\ttraining's rmse: 0.0820853\tvalid_1's rmse: 0.0842595\n",
      "[175]\ttraining's rmse: 0.0819974\tvalid_1's rmse: 0.0842196\n",
      "[200]\ttraining's rmse: 0.0819008\tvalid_1's rmse: 0.0841808\n",
      "[225]\ttraining's rmse: 0.0818108\tvalid_1's rmse: 0.0841443\n",
      "[250]\ttraining's rmse: 0.0817349\tvalid_1's rmse: 0.0841117\n",
      "[275]\ttraining's rmse: 0.0816597\tvalid_1's rmse: 0.0840805\n",
      "[300]\ttraining's rmse: 0.0815858\tvalid_1's rmse: 0.0840513\n",
      "[325]\ttraining's rmse: 0.0815116\tvalid_1's rmse: 0.0840223\n",
      "[350]\ttraining's rmse: 0.0814417\tvalid_1's rmse: 0.0839957\n",
      "[375]\ttraining's rmse: 0.0813845\tvalid_1's rmse: 0.0839736\n",
      "[400]\ttraining's rmse: 0.0813202\tvalid_1's rmse: 0.083952\n",
      "[425]\ttraining's rmse: 0.0812639\tvalid_1's rmse: 0.0839311\n",
      "[450]\ttraining's rmse: 0.0812097\tvalid_1's rmse: 0.0839117\n",
      "[475]\ttraining's rmse: 0.0811591\tvalid_1's rmse: 0.0838938\n",
      "[500]\ttraining's rmse: 0.081115\tvalid_1's rmse: 0.0838777\n",
      "[525]\ttraining's rmse: 0.0810614\tvalid_1's rmse: 0.0838615\n",
      "[550]\ttraining's rmse: 0.081011\tvalid_1's rmse: 0.0838455\n",
      "[575]\ttraining's rmse: 0.0809631\tvalid_1's rmse: 0.0838303\n",
      "[600]\ttraining's rmse: 0.0809194\tvalid_1's rmse: 0.083817\n",
      "[625]\ttraining's rmse: 0.0808861\tvalid_1's rmse: 0.0838051\n",
      "[650]\ttraining's rmse: 0.0808428\tvalid_1's rmse: 0.0837926\n",
      "[675]\ttraining's rmse: 0.0807999\tvalid_1's rmse: 0.0837806\n",
      "[700]\ttraining's rmse: 0.0807605\tvalid_1's rmse: 0.0837695\n",
      "[725]\ttraining's rmse: 0.0807258\tvalid_1's rmse: 0.0837602\n",
      "[750]\ttraining's rmse: 0.0806925\tvalid_1's rmse: 0.0837515\n",
      "[775]\ttraining's rmse: 0.0806637\tvalid_1's rmse: 0.0837432\n",
      "[800]\ttraining's rmse: 0.0806297\tvalid_1's rmse: 0.083735\n",
      "[825]\ttraining's rmse: 0.0806019\tvalid_1's rmse: 0.0837269\n",
      "[850]\ttraining's rmse: 0.0805729\tvalid_1's rmse: 0.08372\n",
      "[875]\ttraining's rmse: 0.0805476\tvalid_1's rmse: 0.0837132\n",
      "[900]\ttraining's rmse: 0.0805183\tvalid_1's rmse: 0.0837062\n",
      "[925]\ttraining's rmse: 0.0804905\tvalid_1's rmse: 0.0837007\n",
      "[950]\ttraining's rmse: 0.080466\tvalid_1's rmse: 0.0836963\n",
      "[975]\ttraining's rmse: 0.0804421\tvalid_1's rmse: 0.0836905\n",
      "[1000]\ttraining's rmse: 0.0804213\tvalid_1's rmse: 0.0836863\n",
      "[1025]\ttraining's rmse: 0.0803961\tvalid_1's rmse: 0.083682\n",
      "[1050]\ttraining's rmse: 0.080375\tvalid_1's rmse: 0.0836768\n",
      "[1075]\ttraining's rmse: 0.080352\tvalid_1's rmse: 0.0836733\n",
      "[1100]\ttraining's rmse: 0.0803369\tvalid_1's rmse: 0.0836696\n",
      "[1125]\ttraining's rmse: 0.0803151\tvalid_1's rmse: 0.0836656\n",
      "[1150]\ttraining's rmse: 0.080297\tvalid_1's rmse: 0.0836623\n",
      "[1175]\ttraining's rmse: 0.0802813\tvalid_1's rmse: 0.0836597\n",
      "[1200]\ttraining's rmse: 0.0802651\tvalid_1's rmse: 0.0836569\n",
      "[1225]\ttraining's rmse: 0.0802502\tvalid_1's rmse: 0.083654\n",
      "[1250]\ttraining's rmse: 0.0802363\tvalid_1's rmse: 0.0836516\n",
      "[1275]\ttraining's rmse: 0.0802211\tvalid_1's rmse: 0.0836493\n",
      "[1300]\ttraining's rmse: 0.0802084\tvalid_1's rmse: 0.083647\n",
      "[1325]\ttraining's rmse: 0.0801958\tvalid_1's rmse: 0.0836451\n",
      "[1350]\ttraining's rmse: 0.0801818\tvalid_1's rmse: 0.0836438\n",
      "[1375]\ttraining's rmse: 0.0801694\tvalid_1's rmse: 0.0836424\n",
      "[1400]\ttraining's rmse: 0.0801593\tvalid_1's rmse: 0.0836403\n",
      "[1425]\ttraining's rmse: 0.0801484\tvalid_1's rmse: 0.0836388\n",
      "[1450]\ttraining's rmse: 0.0801382\tvalid_1's rmse: 0.0836376\n",
      "[1475]\ttraining's rmse: 0.0801291\tvalid_1's rmse: 0.0836362\n",
      "[1500]\ttraining's rmse: 0.0801212\tvalid_1's rmse: 0.083635\n",
      "[1525]\ttraining's rmse: 0.0801114\tvalid_1's rmse: 0.0836336\n",
      "[1550]\ttraining's rmse: 0.0801\tvalid_1's rmse: 0.0836327\n",
      "[1575]\ttraining's rmse: 0.080092\tvalid_1's rmse: 0.083631\n",
      "[1600]\ttraining's rmse: 0.0800849\tvalid_1's rmse: 0.0836304\n",
      "[1625]\ttraining's rmse: 0.0800766\tvalid_1's rmse: 0.0836293\n",
      "[1650]\ttraining's rmse: 0.080069\tvalid_1's rmse: 0.0836282\n",
      "[1675]\ttraining's rmse: 0.0800636\tvalid_1's rmse: 0.0836278\n",
      "[1700]\ttraining's rmse: 0.0800554\tvalid_1's rmse: 0.083627\n",
      "[1725]\ttraining's rmse: 0.0800485\tvalid_1's rmse: 0.0836264\n",
      "[1750]\ttraining's rmse: 0.0800414\tvalid_1's rmse: 0.0836259\n",
      "[1775]\ttraining's rmse: 0.0800367\tvalid_1's rmse: 0.0836255\n",
      "[1800]\ttraining's rmse: 0.0800299\tvalid_1's rmse: 0.0836247\n",
      "[1825]\ttraining's rmse: 0.0800225\tvalid_1's rmse: 0.0836237\n",
      "[1850]\ttraining's rmse: 0.0800174\tvalid_1's rmse: 0.0836228\n",
      "[1875]\ttraining's rmse: 0.0800134\tvalid_1's rmse: 0.0836225\n",
      "[1900]\ttraining's rmse: 0.0800096\tvalid_1's rmse: 0.0836223\n",
      "[1925]\ttraining's rmse: 0.0800048\tvalid_1's rmse: 0.0836215\n",
      "[1950]\ttraining's rmse: 0.0800005\tvalid_1's rmse: 0.0836213\n",
      "[1975]\ttraining's rmse: 0.0799958\tvalid_1's rmse: 0.0836209\n",
      "[2000]\ttraining's rmse: 0.0799915\tvalid_1's rmse: 0.0836209\n",
      "[2025]\ttraining's rmse: 0.0799878\tvalid_1's rmse: 0.0836199\n",
      "[2050]\ttraining's rmse: 0.0799834\tvalid_1's rmse: 0.0836198\n",
      "[2075]\ttraining's rmse: 0.0799803\tvalid_1's rmse: 0.0836195\n",
      "[2100]\ttraining's rmse: 0.0799769\tvalid_1's rmse: 0.0836195\n",
      "[2125]\ttraining's rmse: 0.0799743\tvalid_1's rmse: 0.0836196\n",
      "[2150]\ttraining's rmse: 0.07997\tvalid_1's rmse: 0.0836194\n",
      "[2175]\ttraining's rmse: 0.0799679\tvalid_1's rmse: 0.0836198\n",
      "[2200]\ttraining's rmse: 0.0799652\tvalid_1's rmse: 0.0836195\n",
      "Early stopping, best iteration is:\n",
      "[2152]\ttraining's rmse: 0.0799698\tvalid_1's rmse: 0.0836193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0846559\tvalid_1's rmse: 0.0804788\n",
      "[50]\ttraining's rmse: 0.0845375\tvalid_1's rmse: 0.0804274\n",
      "[75]\ttraining's rmse: 0.0844199\tvalid_1's rmse: 0.0803783\n",
      "[100]\ttraining's rmse: 0.0843124\tvalid_1's rmse: 0.0803338\n",
      "[125]\ttraining's rmse: 0.084203\tvalid_1's rmse: 0.0802907\n",
      "[150]\ttraining's rmse: 0.0841017\tvalid_1's rmse: 0.080253\n",
      "[175]\ttraining's rmse: 0.08402\tvalid_1's rmse: 0.0802206\n",
      "[200]\ttraining's rmse: 0.0839325\tvalid_1's rmse: 0.080189\n",
      "[225]\ttraining's rmse: 0.0838463\tvalid_1's rmse: 0.0801583\n",
      "[250]\ttraining's rmse: 0.0837727\tvalid_1's rmse: 0.0801326\n",
      "[275]\ttraining's rmse: 0.0837041\tvalid_1's rmse: 0.0801066\n",
      "[300]\ttraining's rmse: 0.0836357\tvalid_1's rmse: 0.0800827\n",
      "[325]\ttraining's rmse: 0.0835664\tvalid_1's rmse: 0.08006\n",
      "[350]\ttraining's rmse: 0.0834977\tvalid_1's rmse: 0.0800394\n",
      "[375]\ttraining's rmse: 0.0834431\tvalid_1's rmse: 0.0800212\n",
      "[400]\ttraining's rmse: 0.0833845\tvalid_1's rmse: 0.0800032\n",
      "[425]\ttraining's rmse: 0.0833298\tvalid_1's rmse: 0.079986\n",
      "[450]\ttraining's rmse: 0.0832785\tvalid_1's rmse: 0.0799693\n",
      "[475]\ttraining's rmse: 0.08323\tvalid_1's rmse: 0.0799579\n",
      "[500]\ttraining's rmse: 0.0831894\tvalid_1's rmse: 0.079944\n",
      "[525]\ttraining's rmse: 0.0831381\tvalid_1's rmse: 0.0799302\n",
      "[550]\ttraining's rmse: 0.0830899\tvalid_1's rmse: 0.0799168\n",
      "[575]\ttraining's rmse: 0.0830473\tvalid_1's rmse: 0.079906\n",
      "[600]\ttraining's rmse: 0.0830058\tvalid_1's rmse: 0.0798956\n",
      "[625]\ttraining's rmse: 0.0829734\tvalid_1's rmse: 0.0798872\n",
      "[650]\ttraining's rmse: 0.0829312\tvalid_1's rmse: 0.079893\n",
      "[675]\ttraining's rmse: 0.0828885\tvalid_1's rmse: 0.0798847\n",
      "[700]\ttraining's rmse: 0.0828509\tvalid_1's rmse: 0.0798881\n",
      "[725]\ttraining's rmse: 0.0828145\tvalid_1's rmse: 0.079897\n",
      "Early stopping, best iteration is:\n",
      "[684]\ttraining's rmse: 0.0828742\tvalid_1's rmse: 0.0798815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0882917\tvalid_1's rmse: 0.0897473\n",
      "[50]\ttraining's rmse: 0.0881026\tvalid_1's rmse: 0.0896953\n",
      "[75]\ttraining's rmse: 0.0879108\tvalid_1's rmse: 0.0896425\n",
      "[100]\ttraining's rmse: 0.087736\tvalid_1's rmse: 0.0895962\n",
      "[125]\ttraining's rmse: 0.0875642\tvalid_1's rmse: 0.0895506\n",
      "[150]\ttraining's rmse: 0.087407\tvalid_1's rmse: 0.0895085\n",
      "[175]\ttraining's rmse: 0.087269\tvalid_1's rmse: 0.0894712\n",
      "[200]\ttraining's rmse: 0.087127\tvalid_1's rmse: 0.0894339\n",
      "[225]\ttraining's rmse: 0.0869941\tvalid_1's rmse: 0.0894009\n",
      "[250]\ttraining's rmse: 0.0868815\tvalid_1's rmse: 0.0893683\n",
      "[275]\ttraining's rmse: 0.0867717\tvalid_1's rmse: 0.089338\n",
      "[300]\ttraining's rmse: 0.0866649\tvalid_1's rmse: 0.0893099\n",
      "[325]\ttraining's rmse: 0.0865607\tvalid_1's rmse: 0.0892848\n",
      "[350]\ttraining's rmse: 0.086464\tvalid_1's rmse: 0.0892619\n",
      "[375]\ttraining's rmse: 0.086377\tvalid_1's rmse: 0.0892417\n",
      "[400]\ttraining's rmse: 0.0862877\tvalid_1's rmse: 0.0892212\n",
      "[425]\ttraining's rmse: 0.0862055\tvalid_1's rmse: 0.0892\n",
      "[450]\ttraining's rmse: 0.0861311\tvalid_1's rmse: 0.0891818\n",
      "[475]\ttraining's rmse: 0.0860624\tvalid_1's rmse: 0.0891633\n",
      "[500]\ttraining's rmse: 0.0859998\tvalid_1's rmse: 0.0891458\n",
      "[525]\ttraining's rmse: 0.0859243\tvalid_1's rmse: 0.0891294\n",
      "[550]\ttraining's rmse: 0.0858592\tvalid_1's rmse: 0.0891149\n",
      "[575]\ttraining's rmse: 0.085799\tvalid_1's rmse: 0.0891023\n",
      "[600]\ttraining's rmse: 0.0857368\tvalid_1's rmse: 0.0890885\n",
      "[625]\ttraining's rmse: 0.085689\tvalid_1's rmse: 0.089076\n",
      "[650]\ttraining's rmse: 0.085634\tvalid_1's rmse: 0.0890623\n",
      "[675]\ttraining's rmse: 0.0855807\tvalid_1's rmse: 0.0890504\n",
      "[700]\ttraining's rmse: 0.0855344\tvalid_1's rmse: 0.0890399\n",
      "[725]\ttraining's rmse: 0.0854895\tvalid_1's rmse: 0.0890299\n",
      "[750]\ttraining's rmse: 0.0854464\tvalid_1's rmse: 0.0890209\n",
      "[775]\ttraining's rmse: 0.0854114\tvalid_1's rmse: 0.0890122\n",
      "[800]\ttraining's rmse: 0.0853701\tvalid_1's rmse: 0.0890047\n",
      "[825]\ttraining's rmse: 0.0853355\tvalid_1's rmse: 0.0889967\n",
      "[850]\ttraining's rmse: 0.0852956\tvalid_1's rmse: 0.0889887\n",
      "[875]\ttraining's rmse: 0.0852636\tvalid_1's rmse: 0.0889819\n",
      "[900]\ttraining's rmse: 0.0852266\tvalid_1's rmse: 0.088975\n",
      "[925]\ttraining's rmse: 0.0851967\tvalid_1's rmse: 0.0889686\n",
      "[950]\ttraining's rmse: 0.0851659\tvalid_1's rmse: 0.0889623\n",
      "[975]\ttraining's rmse: 0.0851376\tvalid_1's rmse: 0.0889556\n",
      "[1000]\ttraining's rmse: 0.0851094\tvalid_1's rmse: 0.088951\n",
      "[1025]\ttraining's rmse: 0.085081\tvalid_1's rmse: 0.0889452\n",
      "[1050]\ttraining's rmse: 0.0850529\tvalid_1's rmse: 0.0889402\n",
      "[1075]\ttraining's rmse: 0.0850301\tvalid_1's rmse: 0.0889355\n",
      "[1100]\ttraining's rmse: 0.0850059\tvalid_1's rmse: 0.0889306\n",
      "[1125]\ttraining's rmse: 0.0849818\tvalid_1's rmse: 0.0889241\n",
      "[1150]\ttraining's rmse: 0.0849627\tvalid_1's rmse: 0.0889185\n",
      "[1175]\ttraining's rmse: 0.0849405\tvalid_1's rmse: 0.0889153\n",
      "[1200]\ttraining's rmse: 0.0849202\tvalid_1's rmse: 0.0889102\n",
      "[1225]\ttraining's rmse: 0.0849012\tvalid_1's rmse: 0.0889059\n",
      "[1250]\ttraining's rmse: 0.0848826\tvalid_1's rmse: 0.0889035\n",
      "[1275]\ttraining's rmse: 0.0848643\tvalid_1's rmse: 0.0889002\n",
      "[1300]\ttraining's rmse: 0.0848502\tvalid_1's rmse: 0.0888971\n",
      "[1325]\ttraining's rmse: 0.084835\tvalid_1's rmse: 0.0888938\n",
      "[1350]\ttraining's rmse: 0.0848185\tvalid_1's rmse: 0.0888905\n",
      "[1375]\ttraining's rmse: 0.0848029\tvalid_1's rmse: 0.0888879\n",
      "[1400]\ttraining's rmse: 0.0847882\tvalid_1's rmse: 0.0888851\n",
      "[1425]\ttraining's rmse: 0.084773\tvalid_1's rmse: 0.088883\n",
      "[1450]\ttraining's rmse: 0.0847555\tvalid_1's rmse: 0.0888792\n",
      "[1475]\ttraining's rmse: 0.0847433\tvalid_1's rmse: 0.088877\n",
      "[1500]\ttraining's rmse: 0.0847324\tvalid_1's rmse: 0.0888743\n",
      "[1525]\ttraining's rmse: 0.0847206\tvalid_1's rmse: 0.0888709\n",
      "[1550]\ttraining's rmse: 0.0847091\tvalid_1's rmse: 0.0888683\n",
      "[1575]\ttraining's rmse: 0.0846997\tvalid_1's rmse: 0.0888665\n",
      "[1600]\ttraining's rmse: 0.0846879\tvalid_1's rmse: 0.0888642\n",
      "[1625]\ttraining's rmse: 0.0846792\tvalid_1's rmse: 0.0888619\n",
      "[1650]\ttraining's rmse: 0.0846701\tvalid_1's rmse: 0.0888595\n",
      "[1675]\ttraining's rmse: 0.0846626\tvalid_1's rmse: 0.0888562\n",
      "[1700]\ttraining's rmse: 0.0846543\tvalid_1's rmse: 0.0888527\n",
      "[1725]\ttraining's rmse: 0.0846449\tvalid_1's rmse: 0.0888515\n",
      "[1750]\ttraining's rmse: 0.0846374\tvalid_1's rmse: 0.0888495\n",
      "[1775]\ttraining's rmse: 0.0846309\tvalid_1's rmse: 0.0888477\n",
      "[1800]\ttraining's rmse: 0.0846231\tvalid_1's rmse: 0.0888457\n",
      "[1825]\ttraining's rmse: 0.0846167\tvalid_1's rmse: 0.0888448\n",
      "[1850]\ttraining's rmse: 0.0846107\tvalid_1's rmse: 0.0888432\n",
      "[1875]\ttraining's rmse: 0.0846049\tvalid_1's rmse: 0.0888418\n",
      "[1900]\ttraining's rmse: 0.0845997\tvalid_1's rmse: 0.0888408\n",
      "[1925]\ttraining's rmse: 0.0845948\tvalid_1's rmse: 0.0888384\n",
      "[1950]\ttraining's rmse: 0.0845904\tvalid_1's rmse: 0.0888371\n",
      "[1975]\ttraining's rmse: 0.0845849\tvalid_1's rmse: 0.0888364\n",
      "[2000]\ttraining's rmse: 0.0845797\tvalid_1's rmse: 0.088835\n",
      "[2025]\ttraining's rmse: 0.0845749\tvalid_1's rmse: 0.0888338\n",
      "[2050]\ttraining's rmse: 0.08457\tvalid_1's rmse: 0.0888328\n",
      "[2075]\ttraining's rmse: 0.0845667\tvalid_1's rmse: 0.0888313\n",
      "[2100]\ttraining's rmse: 0.0845626\tvalid_1's rmse: 0.08883\n",
      "[2125]\ttraining's rmse: 0.0845591\tvalid_1's rmse: 0.0888285\n",
      "[2150]\ttraining's rmse: 0.0845561\tvalid_1's rmse: 0.0888273\n",
      "[2175]\ttraining's rmse: 0.0845523\tvalid_1's rmse: 0.0888261\n",
      "[2200]\ttraining's rmse: 0.0845487\tvalid_1's rmse: 0.0888238\n",
      "[2225]\ttraining's rmse: 0.084546\tvalid_1's rmse: 0.0888227\n",
      "[2250]\ttraining's rmse: 0.0845425\tvalid_1's rmse: 0.0888226\n",
      "[2275]\ttraining's rmse: 0.0845387\tvalid_1's rmse: 0.0888216\n",
      "[2300]\ttraining's rmse: 0.0845362\tvalid_1's rmse: 0.0888207\n",
      "[2325]\ttraining's rmse: 0.0845328\tvalid_1's rmse: 0.0888193\n",
      "[2350]\ttraining's rmse: 0.0845292\tvalid_1's rmse: 0.0888185\n",
      "[2375]\ttraining's rmse: 0.0845254\tvalid_1's rmse: 0.0888182\n",
      "[2400]\ttraining's rmse: 0.0845219\tvalid_1's rmse: 0.0888182\n",
      "[2425]\ttraining's rmse: 0.0845196\tvalid_1's rmse: 0.0888177\n",
      "[2450]\ttraining's rmse: 0.084516\tvalid_1's rmse: 0.0888163\n",
      "[2475]\ttraining's rmse: 0.0845128\tvalid_1's rmse: 0.0888161\n",
      "[2500]\ttraining's rmse: 0.0845101\tvalid_1's rmse: 0.088816\n",
      "[2525]\ttraining's rmse: 0.0845071\tvalid_1's rmse: 0.088816\n",
      "[2550]\ttraining's rmse: 0.0845045\tvalid_1's rmse: 0.0888153\n",
      "[2575]\ttraining's rmse: 0.0845023\tvalid_1's rmse: 0.0888149\n",
      "[2600]\ttraining's rmse: 0.0845002\tvalid_1's rmse: 0.0888142\n",
      "[2625]\ttraining's rmse: 0.0844988\tvalid_1's rmse: 0.0888142\n",
      "[2650]\ttraining's rmse: 0.0844967\tvalid_1's rmse: 0.0888133\n",
      "[2675]\ttraining's rmse: 0.0844939\tvalid_1's rmse: 0.0888124\n",
      "[2700]\ttraining's rmse: 0.0844919\tvalid_1's rmse: 0.0888117\n",
      "[2725]\ttraining's rmse: 0.0844884\tvalid_1's rmse: 0.0888112\n",
      "[2750]\ttraining's rmse: 0.0844864\tvalid_1's rmse: 0.0888106\n",
      "[2775]\ttraining's rmse: 0.0844832\tvalid_1's rmse: 0.0888109\n",
      "Early stopping, best iteration is:\n",
      "[2747]\ttraining's rmse: 0.0844866\tvalid_1's rmse: 0.0888105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0883337\tvalid_1's rmse: 0.0896957\n",
      "[50]\ttraining's rmse: 0.0881631\tvalid_1's rmse: 0.0896391\n",
      "[75]\ttraining's rmse: 0.0879946\tvalid_1's rmse: 0.0895823\n",
      "[100]\ttraining's rmse: 0.0878411\tvalid_1's rmse: 0.0895326\n",
      "[125]\ttraining's rmse: 0.0876837\tvalid_1's rmse: 0.0894833\n",
      "[150]\ttraining's rmse: 0.0875413\tvalid_1's rmse: 0.0894342\n",
      "[175]\ttraining's rmse: 0.0874208\tvalid_1's rmse: 0.0893952\n",
      "[200]\ttraining's rmse: 0.0872935\tvalid_1's rmse: 0.0893567\n",
      "[225]\ttraining's rmse: 0.0871714\tvalid_1's rmse: 0.0893216\n",
      "[250]\ttraining's rmse: 0.0870683\tvalid_1's rmse: 0.0892867\n",
      "[275]\ttraining's rmse: 0.0869707\tvalid_1's rmse: 0.0892569\n",
      "[300]\ttraining's rmse: 0.0868742\tvalid_1's rmse: 0.0892283\n",
      "[325]\ttraining's rmse: 0.0867804\tvalid_1's rmse: 0.0892005\n",
      "[350]\ttraining's rmse: 0.0866893\tvalid_1's rmse: 0.0891747\n",
      "[375]\ttraining's rmse: 0.0866144\tvalid_1's rmse: 0.0891526\n",
      "[400]\ttraining's rmse: 0.0865333\tvalid_1's rmse: 0.0891288\n",
      "[425]\ttraining's rmse: 0.086458\tvalid_1's rmse: 0.0891068\n",
      "[450]\ttraining's rmse: 0.0863897\tvalid_1's rmse: 0.0890866\n",
      "[475]\ttraining's rmse: 0.086329\tvalid_1's rmse: 0.0890687\n",
      "[500]\ttraining's rmse: 0.0862761\tvalid_1's rmse: 0.0890505\n",
      "[525]\ttraining's rmse: 0.086212\tvalid_1's rmse: 0.0890334\n",
      "[550]\ttraining's rmse: 0.0861513\tvalid_1's rmse: 0.0890182\n",
      "[575]\ttraining's rmse: 0.0860963\tvalid_1's rmse: 0.0890036\n",
      "[600]\ttraining's rmse: 0.0860417\tvalid_1's rmse: 0.0889894\n",
      "[625]\ttraining's rmse: 0.0859979\tvalid_1's rmse: 0.0889756\n",
      "[650]\ttraining's rmse: 0.0859478\tvalid_1's rmse: 0.0889625\n",
      "[675]\ttraining's rmse: 0.0858993\tvalid_1's rmse: 0.0889505\n",
      "[700]\ttraining's rmse: 0.0858567\tvalid_1's rmse: 0.0889386\n",
      "[725]\ttraining's rmse: 0.0858166\tvalid_1's rmse: 0.0889284\n",
      "[750]\ttraining's rmse: 0.0857792\tvalid_1's rmse: 0.088919\n",
      "[775]\ttraining's rmse: 0.0857463\tvalid_1's rmse: 0.0889088\n",
      "[800]\ttraining's rmse: 0.0857049\tvalid_1's rmse: 0.0889\n",
      "[825]\ttraining's rmse: 0.0856734\tvalid_1's rmse: 0.0888922\n",
      "[850]\ttraining's rmse: 0.0856395\tvalid_1's rmse: 0.0888852\n",
      "[875]\ttraining's rmse: 0.0856088\tvalid_1's rmse: 0.0888782\n",
      "[900]\ttraining's rmse: 0.0855769\tvalid_1's rmse: 0.0888707\n",
      "[925]\ttraining's rmse: 0.0855443\tvalid_1's rmse: 0.0888645\n",
      "[950]\ttraining's rmse: 0.0855151\tvalid_1's rmse: 0.0888578\n",
      "[975]\ttraining's rmse: 0.0854874\tvalid_1's rmse: 0.0888518\n",
      "[1000]\ttraining's rmse: 0.0854624\tvalid_1's rmse: 0.0888471\n",
      "[1025]\ttraining's rmse: 0.0854335\tvalid_1's rmse: 0.0888422\n",
      "[1050]\ttraining's rmse: 0.0854093\tvalid_1's rmse: 0.0888379\n",
      "[1075]\ttraining's rmse: 0.0853868\tvalid_1's rmse: 0.0888344\n",
      "[1100]\ttraining's rmse: 0.0853659\tvalid_1's rmse: 0.08883\n",
      "[1125]\ttraining's rmse: 0.0853439\tvalid_1's rmse: 0.0888255\n",
      "[1150]\ttraining's rmse: 0.0853234\tvalid_1's rmse: 0.0888223\n",
      "[1175]\ttraining's rmse: 0.0853064\tvalid_1's rmse: 0.0888194\n",
      "[1200]\ttraining's rmse: 0.0852875\tvalid_1's rmse: 0.0888154\n",
      "[1225]\ttraining's rmse: 0.0852703\tvalid_1's rmse: 0.0888129\n",
      "[1250]\ttraining's rmse: 0.0852532\tvalid_1's rmse: 0.0888102\n",
      "[1275]\ttraining's rmse: 0.0852346\tvalid_1's rmse: 0.0888083\n",
      "[1300]\ttraining's rmse: 0.0852174\tvalid_1's rmse: 0.0888052\n",
      "[1325]\ttraining's rmse: 0.085203\tvalid_1's rmse: 0.0888029\n",
      "[1350]\ttraining's rmse: 0.0851881\tvalid_1's rmse: 0.0888009\n",
      "[1375]\ttraining's rmse: 0.0851711\tvalid_1's rmse: 0.088799\n",
      "[1400]\ttraining's rmse: 0.0851584\tvalid_1's rmse: 0.0887965\n",
      "[1425]\ttraining's rmse: 0.0851416\tvalid_1's rmse: 0.088795\n",
      "[1450]\ttraining's rmse: 0.0851276\tvalid_1's rmse: 0.0887937\n",
      "[1475]\ttraining's rmse: 0.0851148\tvalid_1's rmse: 0.0887917\n",
      "[1500]\ttraining's rmse: 0.0851028\tvalid_1's rmse: 0.0887901\n",
      "[1525]\ttraining's rmse: 0.0850908\tvalid_1's rmse: 0.0887879\n",
      "[1550]\ttraining's rmse: 0.0850771\tvalid_1's rmse: 0.0887875\n",
      "[1575]\ttraining's rmse: 0.0850684\tvalid_1's rmse: 0.0887862\n",
      "[1600]\ttraining's rmse: 0.0850605\tvalid_1's rmse: 0.0887851\n",
      "[1625]\ttraining's rmse: 0.0850519\tvalid_1's rmse: 0.088784\n",
      "[1650]\ttraining's rmse: 0.0850418\tvalid_1's rmse: 0.0887828\n",
      "[1675]\ttraining's rmse: 0.0850355\tvalid_1's rmse: 0.0887816\n",
      "[1700]\ttraining's rmse: 0.0850275\tvalid_1's rmse: 0.08878\n",
      "[1725]\ttraining's rmse: 0.0850194\tvalid_1's rmse: 0.088779\n",
      "[1750]\ttraining's rmse: 0.0850121\tvalid_1's rmse: 0.0887782\n",
      "[1775]\ttraining's rmse: 0.0850043\tvalid_1's rmse: 0.088777\n",
      "[1800]\ttraining's rmse: 0.0849982\tvalid_1's rmse: 0.088776\n",
      "[1825]\ttraining's rmse: 0.0849918\tvalid_1's rmse: 0.0887754\n",
      "[1850]\ttraining's rmse: 0.0849855\tvalid_1's rmse: 0.0887743\n",
      "[1875]\ttraining's rmse: 0.0849794\tvalid_1's rmse: 0.0887744\n",
      "[1900]\ttraining's rmse: 0.0849742\tvalid_1's rmse: 0.0887739\n",
      "[1925]\ttraining's rmse: 0.0849699\tvalid_1's rmse: 0.0887734\n",
      "[1950]\ttraining's rmse: 0.084966\tvalid_1's rmse: 0.088773\n",
      "[1975]\ttraining's rmse: 0.0849616\tvalid_1's rmse: 0.0887723\n",
      "[2000]\ttraining's rmse: 0.0849561\tvalid_1's rmse: 0.0887716\n",
      "[2025]\ttraining's rmse: 0.0849509\tvalid_1's rmse: 0.0887708\n",
      "[2050]\ttraining's rmse: 0.0849465\tvalid_1's rmse: 0.0887701\n",
      "[2075]\ttraining's rmse: 0.0849417\tvalid_1's rmse: 0.0887694\n",
      "[2100]\ttraining's rmse: 0.0849379\tvalid_1's rmse: 0.0887693\n",
      "[2125]\ttraining's rmse: 0.0849354\tvalid_1's rmse: 0.0887694\n",
      "[2150]\ttraining's rmse: 0.0849309\tvalid_1's rmse: 0.088769\n",
      "[2175]\ttraining's rmse: 0.0849269\tvalid_1's rmse: 0.0887689\n",
      "[2200]\ttraining's rmse: 0.0849232\tvalid_1's rmse: 0.0887683\n",
      "[2225]\ttraining's rmse: 0.0849202\tvalid_1's rmse: 0.088768\n",
      "[2250]\ttraining's rmse: 0.0849172\tvalid_1's rmse: 0.0887681\n",
      "[2275]\ttraining's rmse: 0.0849135\tvalid_1's rmse: 0.0887675\n",
      "[2300]\ttraining's rmse: 0.0849086\tvalid_1's rmse: 0.0887674\n",
      "[2325]\ttraining's rmse: 0.0849045\tvalid_1's rmse: 0.0887676\n",
      "[2350]\ttraining's rmse: 0.0849009\tvalid_1's rmse: 0.0887671\n",
      "[2375]\ttraining's rmse: 0.084898\tvalid_1's rmse: 0.0887665\n",
      "[2400]\ttraining's rmse: 0.0848944\tvalid_1's rmse: 0.0887668\n",
      "[2425]\ttraining's rmse: 0.0848926\tvalid_1's rmse: 0.0887671\n",
      "Early stopping, best iteration is:\n",
      "[2389]\ttraining's rmse: 0.0848956\tvalid_1's rmse: 0.0887663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0895726\tvalid_1's rmse: 0.0872501\n",
      "[50]\ttraining's rmse: 0.0894345\tvalid_1's rmse: 0.0871979\n",
      "[75]\ttraining's rmse: 0.0892897\tvalid_1's rmse: 0.0871454\n",
      "[100]\ttraining's rmse: 0.08916\tvalid_1's rmse: 0.0870988\n",
      "[125]\ttraining's rmse: 0.089025\tvalid_1's rmse: 0.0870555\n",
      "[150]\ttraining's rmse: 0.0889054\tvalid_1's rmse: 0.0870159\n",
      "[175]\ttraining's rmse: 0.0888016\tvalid_1's rmse: 0.0869825\n",
      "[200]\ttraining's rmse: 0.0886877\tvalid_1's rmse: 0.0869485\n",
      "[225]\ttraining's rmse: 0.0885786\tvalid_1's rmse: 0.0869151\n",
      "[250]\ttraining's rmse: 0.0884887\tvalid_1's rmse: 0.0868891\n",
      "[275]\ttraining's rmse: 0.0884059\tvalid_1's rmse: 0.0868642\n",
      "[300]\ttraining's rmse: 0.08832\tvalid_1's rmse: 0.086841\n",
      "[325]\ttraining's rmse: 0.0882362\tvalid_1's rmse: 0.0868201\n",
      "[350]\ttraining's rmse: 0.0881534\tvalid_1's rmse: 0.0867992\n",
      "[375]\ttraining's rmse: 0.0880822\tvalid_1's rmse: 0.0867824\n",
      "[400]\ttraining's rmse: 0.0880077\tvalid_1's rmse: 0.0867644\n",
      "[425]\ttraining's rmse: 0.0879409\tvalid_1's rmse: 0.0867491\n",
      "[450]\ttraining's rmse: 0.0878766\tvalid_1's rmse: 0.0867372\n",
      "[475]\ttraining's rmse: 0.0878197\tvalid_1's rmse: 0.0867243\n",
      "[500]\ttraining's rmse: 0.0877702\tvalid_1's rmse: 0.0867117\n",
      "[525]\ttraining's rmse: 0.0877058\tvalid_1's rmse: 0.0866994\n",
      "[550]\ttraining's rmse: 0.0876476\tvalid_1's rmse: 0.0866882\n",
      "[575]\ttraining's rmse: 0.0875933\tvalid_1's rmse: 0.0866789\n",
      "[600]\ttraining's rmse: 0.0875398\tvalid_1's rmse: 0.0866708\n",
      "[625]\ttraining's rmse: 0.0874983\tvalid_1's rmse: 0.0866626\n",
      "[650]\ttraining's rmse: 0.0874477\tvalid_1's rmse: 0.0866557\n",
      "[675]\ttraining's rmse: 0.0873968\tvalid_1's rmse: 0.0866486\n",
      "[700]\ttraining's rmse: 0.0873508\tvalid_1's rmse: 0.0866411\n",
      "[725]\ttraining's rmse: 0.0873121\tvalid_1's rmse: 0.0866413\n",
      "[750]\ttraining's rmse: 0.0872721\tvalid_1's rmse: 0.0866352\n",
      "[775]\ttraining's rmse: 0.0872388\tvalid_1's rmse: 0.0866302\n",
      "[800]\ttraining's rmse: 0.0871936\tvalid_1's rmse: 0.0866272\n",
      "[825]\ttraining's rmse: 0.0871576\tvalid_1's rmse: 0.0866229\n",
      "[850]\ttraining's rmse: 0.0871209\tvalid_1's rmse: 0.0866199\n",
      "[875]\ttraining's rmse: 0.0870899\tvalid_1's rmse: 0.0866208\n",
      "[900]\ttraining's rmse: 0.087054\tvalid_1's rmse: 0.0866224\n",
      "Early stopping, best iteration is:\n",
      "[873]\ttraining's rmse: 0.087091\tvalid_1's rmse: 0.0866177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0827742\tvalid_1's rmse: 0.0855365\n",
      "[50]\ttraining's rmse: 0.0826492\tvalid_1's rmse: 0.0854773\n",
      "[75]\ttraining's rmse: 0.0825215\tvalid_1's rmse: 0.0854197\n",
      "[100]\ttraining's rmse: 0.0824045\tvalid_1's rmse: 0.0853708\n",
      "[125]\ttraining's rmse: 0.0822864\tvalid_1's rmse: 0.0853213\n",
      "[150]\ttraining's rmse: 0.08218\tvalid_1's rmse: 0.0852731\n",
      "[175]\ttraining's rmse: 0.082092\tvalid_1's rmse: 0.0852342\n",
      "[200]\ttraining's rmse: 0.0819969\tvalid_1's rmse: 0.0851952\n",
      "[225]\ttraining's rmse: 0.0819039\tvalid_1's rmse: 0.0851577\n",
      "[250]\ttraining's rmse: 0.0818265\tvalid_1's rmse: 0.0851245\n",
      "[275]\ttraining's rmse: 0.0817546\tvalid_1's rmse: 0.0850919\n",
      "[300]\ttraining's rmse: 0.0816847\tvalid_1's rmse: 0.0850627\n",
      "[325]\ttraining's rmse: 0.0816102\tvalid_1's rmse: 0.085033\n",
      "[350]\ttraining's rmse: 0.0815408\tvalid_1's rmse: 0.0850048\n",
      "[375]\ttraining's rmse: 0.0814826\tvalid_1's rmse: 0.0849798\n",
      "[400]\ttraining's rmse: 0.0814183\tvalid_1's rmse: 0.0849566\n",
      "[425]\ttraining's rmse: 0.0813617\tvalid_1's rmse: 0.0849325\n",
      "[450]\ttraining's rmse: 0.0813109\tvalid_1's rmse: 0.0849101\n",
      "[475]\ttraining's rmse: 0.081265\tvalid_1's rmse: 0.0848888\n",
      "[500]\ttraining's rmse: 0.0812216\tvalid_1's rmse: 0.0848696\n",
      "[525]\ttraining's rmse: 0.0811705\tvalid_1's rmse: 0.0848513\n",
      "[550]\ttraining's rmse: 0.0811234\tvalid_1's rmse: 0.0848346\n",
      "[575]\ttraining's rmse: 0.08108\tvalid_1's rmse: 0.0848207\n",
      "[600]\ttraining's rmse: 0.0810389\tvalid_1's rmse: 0.0848051\n",
      "[625]\ttraining's rmse: 0.0810046\tvalid_1's rmse: 0.0847925\n",
      "[650]\ttraining's rmse: 0.0809651\tvalid_1's rmse: 0.0847779\n",
      "[675]\ttraining's rmse: 0.0809222\tvalid_1's rmse: 0.0847641\n",
      "[700]\ttraining's rmse: 0.0808862\tvalid_1's rmse: 0.0847504\n",
      "[725]\ttraining's rmse: 0.0808507\tvalid_1's rmse: 0.0847382\n",
      "[750]\ttraining's rmse: 0.0808172\tvalid_1's rmse: 0.0847275\n",
      "[775]\ttraining's rmse: 0.08079\tvalid_1's rmse: 0.0847145\n",
      "[800]\ttraining's rmse: 0.0807582\tvalid_1's rmse: 0.0847058\n",
      "[825]\ttraining's rmse: 0.0807283\tvalid_1's rmse: 0.0846957\n",
      "[850]\ttraining's rmse: 0.0806976\tvalid_1's rmse: 0.0846884\n",
      "[875]\ttraining's rmse: 0.0806716\tvalid_1's rmse: 0.0846791\n",
      "[900]\ttraining's rmse: 0.080644\tvalid_1's rmse: 0.084671\n",
      "[925]\ttraining's rmse: 0.0806206\tvalid_1's rmse: 0.0846633\n",
      "[950]\ttraining's rmse: 0.0805971\tvalid_1's rmse: 0.0846552\n",
      "[975]\ttraining's rmse: 0.0805732\tvalid_1's rmse: 0.0846481\n",
      "[1000]\ttraining's rmse: 0.0805496\tvalid_1's rmse: 0.0846412\n",
      "[1025]\ttraining's rmse: 0.0805255\tvalid_1's rmse: 0.084635\n",
      "[1050]\ttraining's rmse: 0.0805061\tvalid_1's rmse: 0.0846269\n",
      "[1075]\ttraining's rmse: 0.080487\tvalid_1's rmse: 0.0846221\n",
      "[1100]\ttraining's rmse: 0.0804704\tvalid_1's rmse: 0.0846147\n",
      "[1125]\ttraining's rmse: 0.080453\tvalid_1's rmse: 0.0846076\n",
      "[1150]\ttraining's rmse: 0.0804364\tvalid_1's rmse: 0.0846032\n",
      "[1175]\ttraining's rmse: 0.0804187\tvalid_1's rmse: 0.0845996\n",
      "[1200]\ttraining's rmse: 0.0804032\tvalid_1's rmse: 0.0845939\n",
      "[1225]\ttraining's rmse: 0.0803912\tvalid_1's rmse: 0.0845885\n",
      "[1250]\ttraining's rmse: 0.0803765\tvalid_1's rmse: 0.0845845\n",
      "[1275]\ttraining's rmse: 0.0803587\tvalid_1's rmse: 0.0845804\n",
      "[1300]\ttraining's rmse: 0.0803422\tvalid_1's rmse: 0.0845752\n",
      "[1325]\ttraining's rmse: 0.0803294\tvalid_1's rmse: 0.0845727\n",
      "[1350]\ttraining's rmse: 0.0803143\tvalid_1's rmse: 0.0845695\n",
      "[1375]\ttraining's rmse: 0.0802979\tvalid_1's rmse: 0.0845661\n",
      "[1400]\ttraining's rmse: 0.0802885\tvalid_1's rmse: 0.0845622\n",
      "[1425]\ttraining's rmse: 0.0802735\tvalid_1's rmse: 0.0845595\n",
      "[1450]\ttraining's rmse: 0.080263\tvalid_1's rmse: 0.0845556\n",
      "[1475]\ttraining's rmse: 0.0802528\tvalid_1's rmse: 0.0845499\n",
      "[1500]\ttraining's rmse: 0.0802445\tvalid_1's rmse: 0.0845476\n",
      "[1525]\ttraining's rmse: 0.0802352\tvalid_1's rmse: 0.0845455\n",
      "[1550]\ttraining's rmse: 0.0802258\tvalid_1's rmse: 0.0845435\n",
      "[1575]\ttraining's rmse: 0.080218\tvalid_1's rmse: 0.0845406\n",
      "[1600]\ttraining's rmse: 0.080212\tvalid_1's rmse: 0.0845383\n",
      "[1625]\ttraining's rmse: 0.0802043\tvalid_1's rmse: 0.0845349\n",
      "[1650]\ttraining's rmse: 0.0801983\tvalid_1's rmse: 0.084532\n",
      "[1675]\ttraining's rmse: 0.0801945\tvalid_1's rmse: 0.0845311\n",
      "[1700]\ttraining's rmse: 0.0801888\tvalid_1's rmse: 0.084529\n",
      "[1725]\ttraining's rmse: 0.0801828\tvalid_1's rmse: 0.0845278\n",
      "[1750]\ttraining's rmse: 0.0801771\tvalid_1's rmse: 0.0845256\n",
      "[1775]\ttraining's rmse: 0.0801707\tvalid_1's rmse: 0.0845243\n",
      "[1800]\ttraining's rmse: 0.0801639\tvalid_1's rmse: 0.0845224\n",
      "[1825]\ttraining's rmse: 0.0801595\tvalid_1's rmse: 0.0845219\n",
      "[1850]\ttraining's rmse: 0.0801558\tvalid_1's rmse: 0.0845206\n",
      "[1875]\ttraining's rmse: 0.0801519\tvalid_1's rmse: 0.0845204\n",
      "[1900]\ttraining's rmse: 0.0801441\tvalid_1's rmse: 0.0845189\n",
      "[1925]\ttraining's rmse: 0.0801403\tvalid_1's rmse: 0.0845182\n",
      "[1950]\ttraining's rmse: 0.0801371\tvalid_1's rmse: 0.0845174\n",
      "[1975]\ttraining's rmse: 0.0801323\tvalid_1's rmse: 0.0845158\n",
      "[2000]\ttraining's rmse: 0.0801273\tvalid_1's rmse: 0.0845143\n",
      "[2025]\ttraining's rmse: 0.0801239\tvalid_1's rmse: 0.0845129\n",
      "[2050]\ttraining's rmse: 0.0801196\tvalid_1's rmse: 0.0845123\n",
      "[2075]\ttraining's rmse: 0.0801169\tvalid_1's rmse: 0.0845117\n",
      "[2100]\ttraining's rmse: 0.080113\tvalid_1's rmse: 0.0845108\n",
      "[2125]\ttraining's rmse: 0.0801096\tvalid_1's rmse: 0.0845103\n",
      "[2150]\ttraining's rmse: 0.0801048\tvalid_1's rmse: 0.0845103\n",
      "[2175]\ttraining's rmse: 0.0801018\tvalid_1's rmse: 0.0845096\n",
      "[2200]\ttraining's rmse: 0.0800988\tvalid_1's rmse: 0.0845093\n",
      "[2225]\ttraining's rmse: 0.0800958\tvalid_1's rmse: 0.0845081\n",
      "[2250]\ttraining's rmse: 0.0800931\tvalid_1's rmse: 0.0845077\n",
      "[2275]\ttraining's rmse: 0.0800882\tvalid_1's rmse: 0.0845071\n",
      "[2300]\ttraining's rmse: 0.0800865\tvalid_1's rmse: 0.0845063\n",
      "[2325]\ttraining's rmse: 0.0800833\tvalid_1's rmse: 0.0845047\n",
      "[2350]\ttraining's rmse: 0.0800806\tvalid_1's rmse: 0.0845046\n",
      "[2375]\ttraining's rmse: 0.0800781\tvalid_1's rmse: 0.084504\n",
      "[2400]\ttraining's rmse: 0.0800758\tvalid_1's rmse: 0.0845038\n",
      "[2425]\ttraining's rmse: 0.0800734\tvalid_1's rmse: 0.0845038\n",
      "[2450]\ttraining's rmse: 0.0800712\tvalid_1's rmse: 0.0845033\n",
      "[2475]\ttraining's rmse: 0.0800686\tvalid_1's rmse: 0.0845026\n",
      "[2500]\ttraining's rmse: 0.0800666\tvalid_1's rmse: 0.0845015\n",
      "[2525]\ttraining's rmse: 0.080065\tvalid_1's rmse: 0.0845004\n",
      "[2550]\ttraining's rmse: 0.0800628\tvalid_1's rmse: 0.0845007\n",
      "[2575]\ttraining's rmse: 0.0800612\tvalid_1's rmse: 0.0845002\n",
      "[2600]\ttraining's rmse: 0.0800597\tvalid_1's rmse: 0.0844998\n",
      "[2625]\ttraining's rmse: 0.080058\tvalid_1's rmse: 0.0844994\n",
      "[2650]\ttraining's rmse: 0.0800558\tvalid_1's rmse: 0.0844992\n",
      "[2675]\ttraining's rmse: 0.0800537\tvalid_1's rmse: 0.0844986\n",
      "[2700]\ttraining's rmse: 0.0800518\tvalid_1's rmse: 0.0844979\n",
      "[2725]\ttraining's rmse: 0.0800509\tvalid_1's rmse: 0.0844982\n",
      "Early stopping, best iteration is:\n",
      "[2697]\ttraining's rmse: 0.080052\tvalid_1's rmse: 0.0844978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0831308\tvalid_1's rmse: 0.0848252\n",
      "[50]\ttraining's rmse: 0.0830058\tvalid_1's rmse: 0.0847654\n",
      "[75]\ttraining's rmse: 0.0828812\tvalid_1's rmse: 0.0847074\n",
      "[100]\ttraining's rmse: 0.0827679\tvalid_1's rmse: 0.0846562\n",
      "[125]\ttraining's rmse: 0.0826501\tvalid_1's rmse: 0.0846044\n",
      "[150]\ttraining's rmse: 0.0825421\tvalid_1's rmse: 0.0845562\n",
      "[175]\ttraining's rmse: 0.0824524\tvalid_1's rmse: 0.0845166\n",
      "[200]\ttraining's rmse: 0.082355\tvalid_1's rmse: 0.084477\n",
      "[225]\ttraining's rmse: 0.0822637\tvalid_1's rmse: 0.0844406\n",
      "[250]\ttraining's rmse: 0.0821869\tvalid_1's rmse: 0.0844073\n",
      "[275]\ttraining's rmse: 0.0821115\tvalid_1's rmse: 0.084376\n",
      "[300]\ttraining's rmse: 0.0820388\tvalid_1's rmse: 0.0843463\n",
      "[325]\ttraining's rmse: 0.0819641\tvalid_1's rmse: 0.0843179\n",
      "[350]\ttraining's rmse: 0.0818896\tvalid_1's rmse: 0.0842912\n",
      "[375]\ttraining's rmse: 0.0818316\tvalid_1's rmse: 0.0842684\n",
      "[400]\ttraining's rmse: 0.0817677\tvalid_1's rmse: 0.0842461\n",
      "[425]\ttraining's rmse: 0.0817097\tvalid_1's rmse: 0.0842249\n",
      "[450]\ttraining's rmse: 0.081656\tvalid_1's rmse: 0.0842038\n",
      "[475]\ttraining's rmse: 0.0816068\tvalid_1's rmse: 0.0841864\n",
      "[500]\ttraining's rmse: 0.0815644\tvalid_1's rmse: 0.0841698\n",
      "[525]\ttraining's rmse: 0.0815139\tvalid_1's rmse: 0.0841539\n",
      "[550]\ttraining's rmse: 0.081464\tvalid_1's rmse: 0.0841386\n",
      "[575]\ttraining's rmse: 0.0814166\tvalid_1's rmse: 0.0841244\n",
      "[600]\ttraining's rmse: 0.0813729\tvalid_1's rmse: 0.0841116\n",
      "[625]\ttraining's rmse: 0.081337\tvalid_1's rmse: 0.0840992\n",
      "[650]\ttraining's rmse: 0.081293\tvalid_1's rmse: 0.0840869\n",
      "[675]\ttraining's rmse: 0.0812466\tvalid_1's rmse: 0.0840751\n",
      "[700]\ttraining's rmse: 0.081208\tvalid_1's rmse: 0.0840649\n",
      "[725]\ttraining's rmse: 0.0811731\tvalid_1's rmse: 0.0840553\n",
      "[750]\ttraining's rmse: 0.0811399\tvalid_1's rmse: 0.0840456\n",
      "[775]\ttraining's rmse: 0.0811107\tvalid_1's rmse: 0.0840368\n",
      "[800]\ttraining's rmse: 0.0810761\tvalid_1's rmse: 0.0840281\n",
      "[825]\ttraining's rmse: 0.0810453\tvalid_1's rmse: 0.0840195\n",
      "[850]\ttraining's rmse: 0.081017\tvalid_1's rmse: 0.0840137\n",
      "[875]\ttraining's rmse: 0.0809883\tvalid_1's rmse: 0.0840067\n",
      "[900]\ttraining's rmse: 0.0809604\tvalid_1's rmse: 0.0840002\n",
      "[925]\ttraining's rmse: 0.0809336\tvalid_1's rmse: 0.0839955\n",
      "[950]\ttraining's rmse: 0.08091\tvalid_1's rmse: 0.0839905\n",
      "[975]\ttraining's rmse: 0.0808853\tvalid_1's rmse: 0.0839853\n",
      "[1000]\ttraining's rmse: 0.0808616\tvalid_1's rmse: 0.0839799\n",
      "[1025]\ttraining's rmse: 0.0808369\tvalid_1's rmse: 0.0839758\n",
      "[1050]\ttraining's rmse: 0.0808139\tvalid_1's rmse: 0.0839712\n",
      "[1075]\ttraining's rmse: 0.0807938\tvalid_1's rmse: 0.0839675\n",
      "[1100]\ttraining's rmse: 0.0807767\tvalid_1's rmse: 0.0839637\n",
      "[1125]\ttraining's rmse: 0.0807565\tvalid_1's rmse: 0.0839598\n",
      "[1150]\ttraining's rmse: 0.0807371\tvalid_1's rmse: 0.0839567\n",
      "[1175]\ttraining's rmse: 0.0807207\tvalid_1's rmse: 0.0839533\n",
      "[1200]\ttraining's rmse: 0.0807051\tvalid_1's rmse: 0.0839507\n",
      "[1225]\ttraining's rmse: 0.0806876\tvalid_1's rmse: 0.0839485\n",
      "[1250]\ttraining's rmse: 0.0806736\tvalid_1's rmse: 0.0839459\n",
      "[1275]\ttraining's rmse: 0.0806558\tvalid_1's rmse: 0.0839437\n",
      "[1300]\ttraining's rmse: 0.080643\tvalid_1's rmse: 0.0839415\n",
      "[1325]\ttraining's rmse: 0.0806295\tvalid_1's rmse: 0.0839393\n",
      "[1350]\ttraining's rmse: 0.0806164\tvalid_1's rmse: 0.0839381\n",
      "[1375]\ttraining's rmse: 0.0806055\tvalid_1's rmse: 0.0839368\n",
      "[1400]\ttraining's rmse: 0.0805948\tvalid_1's rmse: 0.0839347\n",
      "[1425]\ttraining's rmse: 0.0805839\tvalid_1's rmse: 0.083933\n",
      "[1450]\ttraining's rmse: 0.080571\tvalid_1's rmse: 0.0839317\n",
      "[1475]\ttraining's rmse: 0.0805607\tvalid_1's rmse: 0.0839299\n",
      "[1500]\ttraining's rmse: 0.0805507\tvalid_1's rmse: 0.0839291\n",
      "[1525]\ttraining's rmse: 0.0805419\tvalid_1's rmse: 0.0839279\n",
      "[1550]\ttraining's rmse: 0.0805308\tvalid_1's rmse: 0.0839265\n",
      "[1575]\ttraining's rmse: 0.0805214\tvalid_1's rmse: 0.0839248\n",
      "[1600]\ttraining's rmse: 0.0805128\tvalid_1's rmse: 0.0839248\n",
      "[1625]\ttraining's rmse: 0.0805063\tvalid_1's rmse: 0.0839241\n",
      "[1650]\ttraining's rmse: 0.080497\tvalid_1's rmse: 0.0839231\n",
      "[1675]\ttraining's rmse: 0.0804918\tvalid_1's rmse: 0.0839225\n",
      "[1700]\ttraining's rmse: 0.0804858\tvalid_1's rmse: 0.0839216\n",
      "[1725]\ttraining's rmse: 0.0804795\tvalid_1's rmse: 0.0839206\n",
      "[1750]\ttraining's rmse: 0.0804713\tvalid_1's rmse: 0.0839201\n",
      "[1775]\ttraining's rmse: 0.0804656\tvalid_1's rmse: 0.0839199\n",
      "[1800]\ttraining's rmse: 0.0804602\tvalid_1's rmse: 0.0839194\n",
      "[1825]\ttraining's rmse: 0.0804535\tvalid_1's rmse: 0.0839188\n",
      "[1850]\ttraining's rmse: 0.0804486\tvalid_1's rmse: 0.0839185\n",
      "[1875]\ttraining's rmse: 0.0804435\tvalid_1's rmse: 0.0839184\n",
      "[1900]\ttraining's rmse: 0.0804379\tvalid_1's rmse: 0.0839185\n",
      "[1925]\ttraining's rmse: 0.0804319\tvalid_1's rmse: 0.0839185\n",
      "[1950]\ttraining's rmse: 0.0804268\tvalid_1's rmse: 0.0839179\n",
      "[1975]\ttraining's rmse: 0.0804238\tvalid_1's rmse: 0.0839173\n",
      "[2000]\ttraining's rmse: 0.0804194\tvalid_1's rmse: 0.0839172\n",
      "[2025]\ttraining's rmse: 0.0804163\tvalid_1's rmse: 0.0839173\n",
      "[2050]\ttraining's rmse: 0.0804125\tvalid_1's rmse: 0.0839173\n",
      "Early stopping, best iteration is:\n",
      "[2008]\ttraining's rmse: 0.0804185\tvalid_1's rmse: 0.083917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0850605\tvalid_1's rmse: 0.0809097\n",
      "[50]\ttraining's rmse: 0.0849403\tvalid_1's rmse: 0.0808579\n",
      "[75]\ttraining's rmse: 0.0848199\tvalid_1's rmse: 0.0808095\n",
      "[100]\ttraining's rmse: 0.0847135\tvalid_1's rmse: 0.0807638\n",
      "[125]\ttraining's rmse: 0.0846032\tvalid_1's rmse: 0.0807211\n",
      "[150]\ttraining's rmse: 0.0844986\tvalid_1's rmse: 0.0806827\n",
      "[175]\ttraining's rmse: 0.084412\tvalid_1's rmse: 0.080649\n",
      "[200]\ttraining's rmse: 0.0843245\tvalid_1's rmse: 0.0806172\n",
      "[225]\ttraining's rmse: 0.0842377\tvalid_1's rmse: 0.0805862\n",
      "[250]\ttraining's rmse: 0.0841648\tvalid_1's rmse: 0.0805599\n",
      "[275]\ttraining's rmse: 0.0840962\tvalid_1's rmse: 0.0805352\n",
      "[300]\ttraining's rmse: 0.0840277\tvalid_1's rmse: 0.0805102\n",
      "[325]\ttraining's rmse: 0.0839577\tvalid_1's rmse: 0.0804858\n",
      "[350]\ttraining's rmse: 0.0838874\tvalid_1's rmse: 0.0804641\n",
      "[375]\ttraining's rmse: 0.0838322\tvalid_1's rmse: 0.0804462\n",
      "[400]\ttraining's rmse: 0.0837722\tvalid_1's rmse: 0.0804288\n",
      "[425]\ttraining's rmse: 0.0837171\tvalid_1's rmse: 0.0804122\n",
      "[450]\ttraining's rmse: 0.0836652\tvalid_1's rmse: 0.0803994\n",
      "[475]\ttraining's rmse: 0.0836171\tvalid_1's rmse: 0.080385\n",
      "[500]\ttraining's rmse: 0.0835773\tvalid_1's rmse: 0.080372\n",
      "[525]\ttraining's rmse: 0.0835249\tvalid_1's rmse: 0.0803572\n",
      "[550]\ttraining's rmse: 0.0834785\tvalid_1's rmse: 0.080345\n",
      "[575]\ttraining's rmse: 0.0834351\tvalid_1's rmse: 0.0803368\n",
      "[600]\ttraining's rmse: 0.0833911\tvalid_1's rmse: 0.080335\n",
      "[625]\ttraining's rmse: 0.0833569\tvalid_1's rmse: 0.0803397\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's rmse: 0.0834032\tvalid_1's rmse: 0.0803344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0799762\tvalid_1's rmse: 0.0823091\n",
      "[50]\ttraining's rmse: 0.0798551\tvalid_1's rmse: 0.0822593\n",
      "[75]\ttraining's rmse: 0.0797334\tvalid_1's rmse: 0.0822127\n",
      "[100]\ttraining's rmse: 0.0796205\tvalid_1's rmse: 0.0821717\n",
      "[125]\ttraining's rmse: 0.0795086\tvalid_1's rmse: 0.082131\n",
      "[150]\ttraining's rmse: 0.0794068\tvalid_1's rmse: 0.082093\n",
      "[175]\ttraining's rmse: 0.0793219\tvalid_1's rmse: 0.0820605\n",
      "[200]\ttraining's rmse: 0.0792309\tvalid_1's rmse: 0.0820292\n",
      "[225]\ttraining's rmse: 0.0791394\tvalid_1's rmse: 0.0819978\n",
      "[250]\ttraining's rmse: 0.0790627\tvalid_1's rmse: 0.0819695\n",
      "[275]\ttraining's rmse: 0.0789904\tvalid_1's rmse: 0.0819437\n",
      "[300]\ttraining's rmse: 0.0789195\tvalid_1's rmse: 0.0819212\n",
      "[325]\ttraining's rmse: 0.0788488\tvalid_1's rmse: 0.0818973\n",
      "[350]\ttraining's rmse: 0.0787812\tvalid_1's rmse: 0.0818739\n",
      "[375]\ttraining's rmse: 0.0787259\tvalid_1's rmse: 0.0818557\n",
      "[400]\ttraining's rmse: 0.0786656\tvalid_1's rmse: 0.0818373\n",
      "[425]\ttraining's rmse: 0.0786073\tvalid_1's rmse: 0.0818196\n",
      "[450]\ttraining's rmse: 0.0785537\tvalid_1's rmse: 0.0818027\n",
      "[475]\ttraining's rmse: 0.0785083\tvalid_1's rmse: 0.0817875\n",
      "[500]\ttraining's rmse: 0.0784687\tvalid_1's rmse: 0.0817723\n",
      "[525]\ttraining's rmse: 0.078418\tvalid_1's rmse: 0.0817577\n",
      "[550]\ttraining's rmse: 0.0783724\tvalid_1's rmse: 0.0817446\n",
      "[575]\ttraining's rmse: 0.0783291\tvalid_1's rmse: 0.0817321\n",
      "[600]\ttraining's rmse: 0.0782877\tvalid_1's rmse: 0.0817205\n",
      "[625]\ttraining's rmse: 0.0782545\tvalid_1's rmse: 0.0817109\n",
      "[650]\ttraining's rmse: 0.0782158\tvalid_1's rmse: 0.0817002\n",
      "[675]\ttraining's rmse: 0.0781774\tvalid_1's rmse: 0.0816901\n",
      "[700]\ttraining's rmse: 0.0781422\tvalid_1's rmse: 0.0816805\n",
      "[725]\ttraining's rmse: 0.0781058\tvalid_1's rmse: 0.0816721\n",
      "[750]\ttraining's rmse: 0.0780741\tvalid_1's rmse: 0.081664\n",
      "[775]\ttraining's rmse: 0.0780479\tvalid_1's rmse: 0.0816563\n",
      "[800]\ttraining's rmse: 0.0780163\tvalid_1's rmse: 0.0816482\n",
      "[825]\ttraining's rmse: 0.0779867\tvalid_1's rmse: 0.0816398\n",
      "[850]\ttraining's rmse: 0.0779573\tvalid_1's rmse: 0.0816342\n",
      "[875]\ttraining's rmse: 0.077932\tvalid_1's rmse: 0.0816269\n",
      "[900]\ttraining's rmse: 0.0779057\tvalid_1's rmse: 0.08162\n",
      "[925]\ttraining's rmse: 0.077883\tvalid_1's rmse: 0.0816133\n",
      "[950]\ttraining's rmse: 0.0778601\tvalid_1's rmse: 0.081607\n",
      "[975]\ttraining's rmse: 0.0778389\tvalid_1's rmse: 0.0816028\n",
      "[1000]\ttraining's rmse: 0.0778164\tvalid_1's rmse: 0.0815977\n",
      "[1025]\ttraining's rmse: 0.0777953\tvalid_1's rmse: 0.0815927\n",
      "[1050]\ttraining's rmse: 0.0777748\tvalid_1's rmse: 0.081587\n",
      "[1075]\ttraining's rmse: 0.0777559\tvalid_1's rmse: 0.0815818\n",
      "[1100]\ttraining's rmse: 0.0777403\tvalid_1's rmse: 0.0815779\n",
      "[1125]\ttraining's rmse: 0.0777247\tvalid_1's rmse: 0.0815733\n",
      "[1150]\ttraining's rmse: 0.077707\tvalid_1's rmse: 0.0815704\n",
      "[1175]\ttraining's rmse: 0.0776897\tvalid_1's rmse: 0.0815664\n",
      "[1200]\ttraining's rmse: 0.0776755\tvalid_1's rmse: 0.0815628\n",
      "[1225]\ttraining's rmse: 0.0776632\tvalid_1's rmse: 0.0815593\n",
      "[1250]\ttraining's rmse: 0.0776497\tvalid_1's rmse: 0.0815557\n",
      "[1275]\ttraining's rmse: 0.077634\tvalid_1's rmse: 0.0815529\n",
      "[1300]\ttraining's rmse: 0.0776218\tvalid_1's rmse: 0.0815496\n",
      "[1325]\ttraining's rmse: 0.077606\tvalid_1's rmse: 0.0815461\n",
      "[1350]\ttraining's rmse: 0.077595\tvalid_1's rmse: 0.0815432\n",
      "[1375]\ttraining's rmse: 0.0775842\tvalid_1's rmse: 0.0815389\n",
      "[1400]\ttraining's rmse: 0.0775735\tvalid_1's rmse: 0.0815352\n",
      "[1425]\ttraining's rmse: 0.0775621\tvalid_1's rmse: 0.0815327\n",
      "[1450]\ttraining's rmse: 0.0775514\tvalid_1's rmse: 0.0815292\n",
      "[1475]\ttraining's rmse: 0.0775422\tvalid_1's rmse: 0.0815276\n",
      "[1500]\ttraining's rmse: 0.0775347\tvalid_1's rmse: 0.0815253\n",
      "[1525]\ttraining's rmse: 0.0775249\tvalid_1's rmse: 0.0815232\n",
      "[1550]\ttraining's rmse: 0.0775152\tvalid_1's rmse: 0.081522\n",
      "[1575]\ttraining's rmse: 0.0775072\tvalid_1's rmse: 0.0815193\n",
      "[1600]\ttraining's rmse: 0.0775014\tvalid_1's rmse: 0.0815184\n",
      "[1625]\ttraining's rmse: 0.077495\tvalid_1's rmse: 0.0815155\n",
      "[1650]\ttraining's rmse: 0.07749\tvalid_1's rmse: 0.0815139\n",
      "[1675]\ttraining's rmse: 0.0774851\tvalid_1's rmse: 0.0815123\n",
      "[1700]\ttraining's rmse: 0.0774796\tvalid_1's rmse: 0.0815102\n",
      "[1725]\ttraining's rmse: 0.0774733\tvalid_1's rmse: 0.0815078\n",
      "[1750]\ttraining's rmse: 0.0774666\tvalid_1's rmse: 0.0815061\n",
      "[1775]\ttraining's rmse: 0.0774601\tvalid_1's rmse: 0.081504\n",
      "[1800]\ttraining's rmse: 0.0774565\tvalid_1's rmse: 0.0815022\n",
      "[1825]\ttraining's rmse: 0.0774513\tvalid_1's rmse: 0.0815009\n",
      "[1850]\ttraining's rmse: 0.0774447\tvalid_1's rmse: 0.0814983\n",
      "[1875]\ttraining's rmse: 0.0774398\tvalid_1's rmse: 0.081498\n",
      "[1900]\ttraining's rmse: 0.0774366\tvalid_1's rmse: 0.0814966\n",
      "[1925]\ttraining's rmse: 0.0774312\tvalid_1's rmse: 0.0814958\n",
      "[1950]\ttraining's rmse: 0.0774284\tvalid_1's rmse: 0.0814948\n",
      "[1975]\ttraining's rmse: 0.077425\tvalid_1's rmse: 0.0814948\n",
      "[2000]\ttraining's rmse: 0.0774212\tvalid_1's rmse: 0.0814941\n",
      "[2025]\ttraining's rmse: 0.0774172\tvalid_1's rmse: 0.0814925\n",
      "[2050]\ttraining's rmse: 0.0774149\tvalid_1's rmse: 0.0814918\n",
      "[2075]\ttraining's rmse: 0.0774123\tvalid_1's rmse: 0.0814913\n",
      "[2100]\ttraining's rmse: 0.0774092\tvalid_1's rmse: 0.0814902\n",
      "[2125]\ttraining's rmse: 0.0774062\tvalid_1's rmse: 0.081489\n",
      "[2150]\ttraining's rmse: 0.0774031\tvalid_1's rmse: 0.0814891\n",
      "[2175]\ttraining's rmse: 0.0774008\tvalid_1's rmse: 0.0814891\n",
      "[2200]\ttraining's rmse: 0.0773981\tvalid_1's rmse: 0.0814883\n",
      "[2225]\ttraining's rmse: 0.0773952\tvalid_1's rmse: 0.0814875\n",
      "[2250]\ttraining's rmse: 0.0773933\tvalid_1's rmse: 0.0814876\n",
      "[2275]\ttraining's rmse: 0.0773906\tvalid_1's rmse: 0.0814873\n",
      "[2300]\ttraining's rmse: 0.0773881\tvalid_1's rmse: 0.0814867\n",
      "[2325]\ttraining's rmse: 0.0773852\tvalid_1's rmse: 0.0814859\n",
      "[2350]\ttraining's rmse: 0.0773839\tvalid_1's rmse: 0.0814855\n",
      "[2375]\ttraining's rmse: 0.0773813\tvalid_1's rmse: 0.0814855\n",
      "[2400]\ttraining's rmse: 0.0773791\tvalid_1's rmse: 0.0814852\n",
      "[2425]\ttraining's rmse: 0.077377\tvalid_1's rmse: 0.0814844\n",
      "[2450]\ttraining's rmse: 0.0773753\tvalid_1's rmse: 0.0814838\n",
      "[2475]\ttraining's rmse: 0.0773731\tvalid_1's rmse: 0.0814838\n",
      "[2500]\ttraining's rmse: 0.0773708\tvalid_1's rmse: 0.0814825\n",
      "[2525]\ttraining's rmse: 0.0773687\tvalid_1's rmse: 0.0814819\n",
      "[2550]\ttraining's rmse: 0.0773672\tvalid_1's rmse: 0.0814817\n",
      "[2575]\ttraining's rmse: 0.0773659\tvalid_1's rmse: 0.0814811\n",
      "[2600]\ttraining's rmse: 0.0773637\tvalid_1's rmse: 0.0814806\n",
      "[2625]\ttraining's rmse: 0.0773622\tvalid_1's rmse: 0.0814798\n",
      "[2650]\ttraining's rmse: 0.0773609\tvalid_1's rmse: 0.0814785\n",
      "[2675]\ttraining's rmse: 0.0773595\tvalid_1's rmse: 0.0814786\n",
      "[2700]\ttraining's rmse: 0.0773581\tvalid_1's rmse: 0.0814788\n",
      "Early stopping, best iteration is:\n",
      "[2650]\ttraining's rmse: 0.0773609\tvalid_1's rmse: 0.0814785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0803649\tvalid_1's rmse: 0.0815694\n",
      "[50]\ttraining's rmse: 0.080257\tvalid_1's rmse: 0.0815182\n",
      "[75]\ttraining's rmse: 0.0801471\tvalid_1's rmse: 0.0814679\n",
      "[100]\ttraining's rmse: 0.0800505\tvalid_1's rmse: 0.0814225\n",
      "[125]\ttraining's rmse: 0.0799475\tvalid_1's rmse: 0.0813763\n",
      "[150]\ttraining's rmse: 0.0798557\tvalid_1's rmse: 0.0813337\n",
      "[175]\ttraining's rmse: 0.0797766\tvalid_1's rmse: 0.0812986\n",
      "[200]\ttraining's rmse: 0.0796914\tvalid_1's rmse: 0.0812626\n",
      "[225]\ttraining's rmse: 0.0796098\tvalid_1's rmse: 0.0812301\n",
      "[250]\ttraining's rmse: 0.0795384\tvalid_1's rmse: 0.0812004\n",
      "[275]\ttraining's rmse: 0.0794743\tvalid_1's rmse: 0.0811728\n",
      "[300]\ttraining's rmse: 0.0794084\tvalid_1's rmse: 0.0811466\n",
      "[325]\ttraining's rmse: 0.0793436\tvalid_1's rmse: 0.081121\n",
      "[350]\ttraining's rmse: 0.0792807\tvalid_1's rmse: 0.0810975\n",
      "[375]\ttraining's rmse: 0.0792285\tvalid_1's rmse: 0.0810769\n",
      "[400]\ttraining's rmse: 0.079173\tvalid_1's rmse: 0.0810578\n",
      "[425]\ttraining's rmse: 0.0791231\tvalid_1's rmse: 0.0810384\n",
      "[450]\ttraining's rmse: 0.079076\tvalid_1's rmse: 0.0810206\n",
      "[475]\ttraining's rmse: 0.0790332\tvalid_1's rmse: 0.0810034\n",
      "[500]\ttraining's rmse: 0.0789963\tvalid_1's rmse: 0.0809871\n",
      "[525]\ttraining's rmse: 0.0789487\tvalid_1's rmse: 0.0809718\n",
      "[550]\ttraining's rmse: 0.0789037\tvalid_1's rmse: 0.0809573\n",
      "[575]\ttraining's rmse: 0.0788649\tvalid_1's rmse: 0.0809434\n",
      "[600]\ttraining's rmse: 0.0788253\tvalid_1's rmse: 0.0809302\n",
      "[625]\ttraining's rmse: 0.0787951\tvalid_1's rmse: 0.0809187\n",
      "[650]\ttraining's rmse: 0.0787554\tvalid_1's rmse: 0.0809059\n",
      "[675]\ttraining's rmse: 0.0787188\tvalid_1's rmse: 0.0808943\n",
      "[700]\ttraining's rmse: 0.078684\tvalid_1's rmse: 0.0808837\n",
      "[725]\ttraining's rmse: 0.0786519\tvalid_1's rmse: 0.0808736\n",
      "[750]\ttraining's rmse: 0.0786194\tvalid_1's rmse: 0.0808638\n",
      "[775]\ttraining's rmse: 0.0785945\tvalid_1's rmse: 0.0808551\n",
      "[800]\ttraining's rmse: 0.0785614\tvalid_1's rmse: 0.0808472\n",
      "[825]\ttraining's rmse: 0.078534\tvalid_1's rmse: 0.0808387\n",
      "[850]\ttraining's rmse: 0.0785096\tvalid_1's rmse: 0.080833\n",
      "[875]\ttraining's rmse: 0.0784847\tvalid_1's rmse: 0.0808261\n",
      "[900]\ttraining's rmse: 0.0784589\tvalid_1's rmse: 0.0808191\n",
      "[925]\ttraining's rmse: 0.0784335\tvalid_1's rmse: 0.0808135\n",
      "[950]\ttraining's rmse: 0.0784121\tvalid_1's rmse: 0.080808\n",
      "[975]\ttraining's rmse: 0.0783911\tvalid_1's rmse: 0.0808018\n",
      "[1000]\ttraining's rmse: 0.078371\tvalid_1's rmse: 0.0807965\n",
      "[1025]\ttraining's rmse: 0.0783462\tvalid_1's rmse: 0.0807911\n",
      "[1050]\ttraining's rmse: 0.0783287\tvalid_1's rmse: 0.0807862\n",
      "[1075]\ttraining's rmse: 0.0783119\tvalid_1's rmse: 0.0807825\n",
      "[1100]\ttraining's rmse: 0.0782964\tvalid_1's rmse: 0.0807779\n",
      "[1125]\ttraining's rmse: 0.0782784\tvalid_1's rmse: 0.0807737\n",
      "[1150]\ttraining's rmse: 0.0782605\tvalid_1's rmse: 0.0807701\n",
      "[1175]\ttraining's rmse: 0.0782448\tvalid_1's rmse: 0.080767\n",
      "[1200]\ttraining's rmse: 0.0782289\tvalid_1's rmse: 0.0807626\n",
      "[1225]\ttraining's rmse: 0.0782158\tvalid_1's rmse: 0.0807598\n",
      "[1250]\ttraining's rmse: 0.0782013\tvalid_1's rmse: 0.0807566\n",
      "[1275]\ttraining's rmse: 0.078183\tvalid_1's rmse: 0.0807531\n",
      "[1300]\ttraining's rmse: 0.0781709\tvalid_1's rmse: 0.0807499\n",
      "[1325]\ttraining's rmse: 0.0781585\tvalid_1's rmse: 0.0807477\n",
      "[1350]\ttraining's rmse: 0.0781472\tvalid_1's rmse: 0.080745\n",
      "[1375]\ttraining's rmse: 0.0781349\tvalid_1's rmse: 0.0807429\n",
      "[1400]\ttraining's rmse: 0.078126\tvalid_1's rmse: 0.0807406\n",
      "[1425]\ttraining's rmse: 0.0781143\tvalid_1's rmse: 0.0807395\n",
      "[1450]\ttraining's rmse: 0.0781041\tvalid_1's rmse: 0.0807379\n",
      "[1475]\ttraining's rmse: 0.0780933\tvalid_1's rmse: 0.0807358\n",
      "[1500]\ttraining's rmse: 0.0780854\tvalid_1's rmse: 0.0807342\n",
      "[1525]\ttraining's rmse: 0.0780756\tvalid_1's rmse: 0.0807329\n",
      "[1550]\ttraining's rmse: 0.0780671\tvalid_1's rmse: 0.0807319\n",
      "[1575]\ttraining's rmse: 0.0780598\tvalid_1's rmse: 0.0807299\n",
      "[1600]\ttraining's rmse: 0.0780541\tvalid_1's rmse: 0.0807284\n",
      "[1625]\ttraining's rmse: 0.0780475\tvalid_1's rmse: 0.080727\n",
      "[1650]\ttraining's rmse: 0.07804\tvalid_1's rmse: 0.0807257\n",
      "[1675]\ttraining's rmse: 0.0780345\tvalid_1's rmse: 0.0807243\n",
      "[1700]\ttraining's rmse: 0.0780291\tvalid_1's rmse: 0.0807229\n",
      "[1725]\ttraining's rmse: 0.0780233\tvalid_1's rmse: 0.0807214\n",
      "[1750]\ttraining's rmse: 0.0780164\tvalid_1's rmse: 0.0807202\n",
      "[1775]\ttraining's rmse: 0.0780105\tvalid_1's rmse: 0.0807198\n",
      "[1800]\ttraining's rmse: 0.0780052\tvalid_1's rmse: 0.080719\n",
      "[1825]\ttraining's rmse: 0.0779995\tvalid_1's rmse: 0.0807179\n",
      "[1850]\ttraining's rmse: 0.0779951\tvalid_1's rmse: 0.0807172\n",
      "[1875]\ttraining's rmse: 0.0779893\tvalid_1's rmse: 0.080716\n",
      "[1900]\ttraining's rmse: 0.0779857\tvalid_1's rmse: 0.0807158\n",
      "[1925]\ttraining's rmse: 0.0779825\tvalid_1's rmse: 0.0807153\n",
      "[1950]\ttraining's rmse: 0.0779796\tvalid_1's rmse: 0.0807143\n",
      "[1975]\ttraining's rmse: 0.077977\tvalid_1's rmse: 0.0807138\n",
      "[2000]\ttraining's rmse: 0.0779732\tvalid_1's rmse: 0.0807125\n",
      "[2025]\ttraining's rmse: 0.077969\tvalid_1's rmse: 0.0807121\n",
      "[2050]\ttraining's rmse: 0.0779659\tvalid_1's rmse: 0.0807119\n",
      "[2075]\ttraining's rmse: 0.0779616\tvalid_1's rmse: 0.0807112\n",
      "[2100]\ttraining's rmse: 0.0779587\tvalid_1's rmse: 0.0807101\n",
      "[2125]\ttraining's rmse: 0.0779558\tvalid_1's rmse: 0.0807098\n",
      "[2150]\ttraining's rmse: 0.0779526\tvalid_1's rmse: 0.0807097\n",
      "[2175]\ttraining's rmse: 0.0779501\tvalid_1's rmse: 0.0807097\n",
      "[2200]\ttraining's rmse: 0.0779476\tvalid_1's rmse: 0.0807095\n",
      "[2225]\ttraining's rmse: 0.0779446\tvalid_1's rmse: 0.0807091\n",
      "[2250]\ttraining's rmse: 0.0779423\tvalid_1's rmse: 0.080709\n",
      "[2275]\ttraining's rmse: 0.07794\tvalid_1's rmse: 0.0807089\n",
      "[2300]\ttraining's rmse: 0.0779368\tvalid_1's rmse: 0.0807088\n",
      "[2325]\ttraining's rmse: 0.0779337\tvalid_1's rmse: 0.0807085\n",
      "[2350]\ttraining's rmse: 0.077932\tvalid_1's rmse: 0.0807085\n",
      "[2375]\ttraining's rmse: 0.0779293\tvalid_1's rmse: 0.080708\n",
      "[2400]\ttraining's rmse: 0.0779258\tvalid_1's rmse: 0.080708\n",
      "[2425]\ttraining's rmse: 0.0779238\tvalid_1's rmse: 0.0807081\n",
      "Early stopping, best iteration is:\n",
      "[2386]\ttraining's rmse: 0.077928\tvalid_1's rmse: 0.0807078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0818248\tvalid_1's rmse: 0.078589\n",
      "[50]\ttraining's rmse: 0.0817206\tvalid_1's rmse: 0.0785433\n",
      "[75]\ttraining's rmse: 0.0816129\tvalid_1's rmse: 0.0784977\n",
      "[100]\ttraining's rmse: 0.0815182\tvalid_1's rmse: 0.0784576\n",
      "[125]\ttraining's rmse: 0.0814181\tvalid_1's rmse: 0.0784159\n",
      "[150]\ttraining's rmse: 0.0813276\tvalid_1's rmse: 0.0783788\n",
      "[175]\ttraining's rmse: 0.0812534\tvalid_1's rmse: 0.0783472\n",
      "[200]\ttraining's rmse: 0.0811709\tvalid_1's rmse: 0.0783169\n",
      "[225]\ttraining's rmse: 0.0810922\tvalid_1's rmse: 0.0782874\n",
      "[250]\ttraining's rmse: 0.081027\tvalid_1's rmse: 0.0782632\n",
      "[275]\ttraining's rmse: 0.0809641\tvalid_1's rmse: 0.0782389\n",
      "[300]\ttraining's rmse: 0.0809022\tvalid_1's rmse: 0.0782173\n",
      "[325]\ttraining's rmse: 0.0808371\tvalid_1's rmse: 0.0781991\n",
      "[350]\ttraining's rmse: 0.0807744\tvalid_1's rmse: 0.0781771\n",
      "[375]\ttraining's rmse: 0.0807234\tvalid_1's rmse: 0.0781617\n",
      "[400]\ttraining's rmse: 0.0806689\tvalid_1's rmse: 0.0781442\n",
      "[425]\ttraining's rmse: 0.0806204\tvalid_1's rmse: 0.0781338\n",
      "[450]\ttraining's rmse: 0.0805745\tvalid_1's rmse: 0.0781178\n",
      "[475]\ttraining's rmse: 0.0805303\tvalid_1's rmse: 0.0781073\n",
      "[500]\ttraining's rmse: 0.0804947\tvalid_1's rmse: 0.0780956\n",
      "[525]\ttraining's rmse: 0.0804467\tvalid_1's rmse: 0.0780862\n",
      "[550]\ttraining's rmse: 0.0804043\tvalid_1's rmse: 0.0780736\n",
      "[575]\ttraining's rmse: 0.0803645\tvalid_1's rmse: 0.0780631\n",
      "[600]\ttraining's rmse: 0.0803236\tvalid_1's rmse: 0.0780592\n",
      "[625]\ttraining's rmse: 0.0802926\tvalid_1's rmse: 0.0780512\n",
      "[650]\ttraining's rmse: 0.0802541\tvalid_1's rmse: 0.0780462\n",
      "[675]\ttraining's rmse: 0.0802158\tvalid_1's rmse: 0.0780436\n",
      "[700]\ttraining's rmse: 0.0801831\tvalid_1's rmse: 0.0780362\n",
      "[725]\ttraining's rmse: 0.0801485\tvalid_1's rmse: 0.0780486\n",
      "[750]\ttraining's rmse: 0.0801185\tvalid_1's rmse: 0.0780512\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's rmse: 0.0801831\tvalid_1's rmse: 0.0780362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0796182\tvalid_1's rmse: 0.0816696\n",
      "[50]\ttraining's rmse: 0.0794977\tvalid_1's rmse: 0.0816218\n",
      "[75]\ttraining's rmse: 0.0793764\tvalid_1's rmse: 0.0815735\n",
      "[100]\ttraining's rmse: 0.079264\tvalid_1's rmse: 0.0815308\n",
      "[125]\ttraining's rmse: 0.0791502\tvalid_1's rmse: 0.0814878\n",
      "[150]\ttraining's rmse: 0.0790507\tvalid_1's rmse: 0.0814497\n",
      "[175]\ttraining's rmse: 0.0789651\tvalid_1's rmse: 0.0814153\n",
      "[200]\ttraining's rmse: 0.0788755\tvalid_1's rmse: 0.0813818\n",
      "[225]\ttraining's rmse: 0.0787837\tvalid_1's rmse: 0.0813498\n",
      "[250]\ttraining's rmse: 0.0787106\tvalid_1's rmse: 0.0813198\n",
      "[275]\ttraining's rmse: 0.0786392\tvalid_1's rmse: 0.0812931\n",
      "[300]\ttraining's rmse: 0.0785696\tvalid_1's rmse: 0.0812673\n",
      "[325]\ttraining's rmse: 0.0784986\tvalid_1's rmse: 0.0812432\n",
      "[350]\ttraining's rmse: 0.0784308\tvalid_1's rmse: 0.0812189\n",
      "[375]\ttraining's rmse: 0.0783741\tvalid_1's rmse: 0.0811993\n",
      "[400]\ttraining's rmse: 0.0783109\tvalid_1's rmse: 0.0811797\n",
      "[425]\ttraining's rmse: 0.0782558\tvalid_1's rmse: 0.0811612\n",
      "[450]\ttraining's rmse: 0.0782044\tvalid_1's rmse: 0.0811423\n",
      "[475]\ttraining's rmse: 0.0781595\tvalid_1's rmse: 0.0811252\n",
      "[500]\ttraining's rmse: 0.078117\tvalid_1's rmse: 0.0811095\n",
      "[525]\ttraining's rmse: 0.0780638\tvalid_1's rmse: 0.0810939\n",
      "[550]\ttraining's rmse: 0.0780168\tvalid_1's rmse: 0.0810807\n",
      "[575]\ttraining's rmse: 0.0779751\tvalid_1's rmse: 0.0810692\n",
      "[600]\ttraining's rmse: 0.0779342\tvalid_1's rmse: 0.0810556\n",
      "[625]\ttraining's rmse: 0.0778997\tvalid_1's rmse: 0.0810442\n",
      "[650]\ttraining's rmse: 0.0778616\tvalid_1's rmse: 0.0810338\n",
      "[675]\ttraining's rmse: 0.0778212\tvalid_1's rmse: 0.0810228\n",
      "[700]\ttraining's rmse: 0.0777873\tvalid_1's rmse: 0.0810133\n",
      "[725]\ttraining's rmse: 0.0777545\tvalid_1's rmse: 0.0810031\n",
      "[750]\ttraining's rmse: 0.0777228\tvalid_1's rmse: 0.0809937\n",
      "[775]\ttraining's rmse: 0.0776979\tvalid_1's rmse: 0.0809855\n",
      "[800]\ttraining's rmse: 0.0776676\tvalid_1's rmse: 0.0809776\n",
      "[825]\ttraining's rmse: 0.0776398\tvalid_1's rmse: 0.0809699\n",
      "[850]\ttraining's rmse: 0.077613\tvalid_1's rmse: 0.0809646\n",
      "[875]\ttraining's rmse: 0.0775886\tvalid_1's rmse: 0.0809571\n",
      "[900]\ttraining's rmse: 0.077561\tvalid_1's rmse: 0.0809511\n",
      "[925]\ttraining's rmse: 0.0775356\tvalid_1's rmse: 0.0809433\n",
      "[950]\ttraining's rmse: 0.0775137\tvalid_1's rmse: 0.0809382\n",
      "[975]\ttraining's rmse: 0.0774927\tvalid_1's rmse: 0.0809334\n",
      "[1000]\ttraining's rmse: 0.0774685\tvalid_1's rmse: 0.0809276\n",
      "[1025]\ttraining's rmse: 0.077446\tvalid_1's rmse: 0.0809227\n",
      "[1050]\ttraining's rmse: 0.077428\tvalid_1's rmse: 0.0809186\n",
      "[1075]\ttraining's rmse: 0.0774092\tvalid_1's rmse: 0.0809155\n",
      "[1100]\ttraining's rmse: 0.0773915\tvalid_1's rmse: 0.0809121\n",
      "[1125]\ttraining's rmse: 0.0773765\tvalid_1's rmse: 0.0809078\n",
      "[1150]\ttraining's rmse: 0.0773606\tvalid_1's rmse: 0.0809037\n",
      "[1175]\ttraining's rmse: 0.0773458\tvalid_1's rmse: 0.0809002\n",
      "[1200]\ttraining's rmse: 0.0773313\tvalid_1's rmse: 0.0808951\n",
      "[1225]\ttraining's rmse: 0.0773169\tvalid_1's rmse: 0.0808927\n",
      "[1250]\ttraining's rmse: 0.0773024\tvalid_1's rmse: 0.0808888\n",
      "[1275]\ttraining's rmse: 0.0772873\tvalid_1's rmse: 0.0808861\n",
      "[1300]\ttraining's rmse: 0.0772778\tvalid_1's rmse: 0.0808821\n",
      "[1325]\ttraining's rmse: 0.0772643\tvalid_1's rmse: 0.0808796\n",
      "[1350]\ttraining's rmse: 0.0772522\tvalid_1's rmse: 0.0808766\n",
      "[1375]\ttraining's rmse: 0.0772419\tvalid_1's rmse: 0.0808746\n",
      "[1400]\ttraining's rmse: 0.0772312\tvalid_1's rmse: 0.0808712\n",
      "[1425]\ttraining's rmse: 0.077217\tvalid_1's rmse: 0.0808683\n",
      "[1450]\ttraining's rmse: 0.0772065\tvalid_1's rmse: 0.0808673\n",
      "[1475]\ttraining's rmse: 0.0771982\tvalid_1's rmse: 0.0808641\n",
      "[1500]\ttraining's rmse: 0.0771912\tvalid_1's rmse: 0.0808624\n",
      "[1525]\ttraining's rmse: 0.0771836\tvalid_1's rmse: 0.0808589\n",
      "[1550]\ttraining's rmse: 0.077175\tvalid_1's rmse: 0.0808564\n",
      "[1575]\ttraining's rmse: 0.0771685\tvalid_1's rmse: 0.0808547\n",
      "[1600]\ttraining's rmse: 0.0771617\tvalid_1's rmse: 0.0808531\n",
      "[1625]\ttraining's rmse: 0.0771548\tvalid_1's rmse: 0.0808504\n",
      "[1650]\ttraining's rmse: 0.077147\tvalid_1's rmse: 0.080848\n",
      "[1675]\ttraining's rmse: 0.0771405\tvalid_1's rmse: 0.0808457\n",
      "[1700]\ttraining's rmse: 0.0771355\tvalid_1's rmse: 0.0808434\n",
      "[1725]\ttraining's rmse: 0.0771292\tvalid_1's rmse: 0.0808426\n",
      "[1750]\ttraining's rmse: 0.0771226\tvalid_1's rmse: 0.0808401\n",
      "[1775]\ttraining's rmse: 0.0771172\tvalid_1's rmse: 0.0808385\n",
      "[1800]\ttraining's rmse: 0.0771124\tvalid_1's rmse: 0.0808371\n",
      "[1825]\ttraining's rmse: 0.0771072\tvalid_1's rmse: 0.0808358\n",
      "[1850]\ttraining's rmse: 0.0771032\tvalid_1's rmse: 0.0808347\n",
      "[1875]\ttraining's rmse: 0.0770993\tvalid_1's rmse: 0.0808342\n",
      "[1900]\ttraining's rmse: 0.0770959\tvalid_1's rmse: 0.0808333\n",
      "[1925]\ttraining's rmse: 0.0770925\tvalid_1's rmse: 0.0808332\n",
      "[1950]\ttraining's rmse: 0.0770883\tvalid_1's rmse: 0.0808325\n",
      "[1975]\ttraining's rmse: 0.0770851\tvalid_1's rmse: 0.0808311\n",
      "[2000]\ttraining's rmse: 0.0770807\tvalid_1's rmse: 0.0808308\n",
      "[2025]\ttraining's rmse: 0.0770778\tvalid_1's rmse: 0.0808291\n",
      "[2050]\ttraining's rmse: 0.0770744\tvalid_1's rmse: 0.0808289\n",
      "[2075]\ttraining's rmse: 0.0770717\tvalid_1's rmse: 0.080829\n",
      "[2100]\ttraining's rmse: 0.0770695\tvalid_1's rmse: 0.0808278\n",
      "[2125]\ttraining's rmse: 0.0770672\tvalid_1's rmse: 0.0808279\n",
      "[2150]\ttraining's rmse: 0.0770625\tvalid_1's rmse: 0.0808268\n",
      "[2175]\ttraining's rmse: 0.077061\tvalid_1's rmse: 0.0808268\n",
      "[2200]\ttraining's rmse: 0.0770583\tvalid_1's rmse: 0.080826\n",
      "[2225]\ttraining's rmse: 0.0770551\tvalid_1's rmse: 0.0808256\n",
      "[2250]\ttraining's rmse: 0.0770532\tvalid_1's rmse: 0.0808247\n",
      "[2275]\ttraining's rmse: 0.0770501\tvalid_1's rmse: 0.0808238\n",
      "[2300]\ttraining's rmse: 0.077048\tvalid_1's rmse: 0.0808236\n",
      "[2325]\ttraining's rmse: 0.0770441\tvalid_1's rmse: 0.0808229\n",
      "[2350]\ttraining's rmse: 0.0770414\tvalid_1's rmse: 0.0808224\n",
      "[2375]\ttraining's rmse: 0.0770394\tvalid_1's rmse: 0.0808219\n",
      "[2400]\ttraining's rmse: 0.0770378\tvalid_1's rmse: 0.0808222\n",
      "[2425]\ttraining's rmse: 0.0770364\tvalid_1's rmse: 0.080822\n",
      "[2450]\ttraining's rmse: 0.0770334\tvalid_1's rmse: 0.0808209\n",
      "[2475]\ttraining's rmse: 0.0770308\tvalid_1's rmse: 0.0808203\n",
      "[2500]\ttraining's rmse: 0.0770275\tvalid_1's rmse: 0.0808193\n",
      "[2525]\ttraining's rmse: 0.0770259\tvalid_1's rmse: 0.0808196\n",
      "Early stopping, best iteration is:\n",
      "[2496]\ttraining's rmse: 0.0770278\tvalid_1's rmse: 0.0808192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0796983\tvalid_1's rmse: 0.0815249\n",
      "[50]\ttraining's rmse: 0.0795922\tvalid_1's rmse: 0.081473\n",
      "[75]\ttraining's rmse: 0.0794826\tvalid_1's rmse: 0.081423\n",
      "[100]\ttraining's rmse: 0.0793844\tvalid_1's rmse: 0.0813781\n",
      "[125]\ttraining's rmse: 0.0792825\tvalid_1's rmse: 0.0813339\n",
      "[150]\ttraining's rmse: 0.0791896\tvalid_1's rmse: 0.0812926\n",
      "[175]\ttraining's rmse: 0.0791162\tvalid_1's rmse: 0.0812595\n",
      "[200]\ttraining's rmse: 0.0790334\tvalid_1's rmse: 0.0812247\n",
      "[225]\ttraining's rmse: 0.0789496\tvalid_1's rmse: 0.0811923\n",
      "[250]\ttraining's rmse: 0.0788812\tvalid_1's rmse: 0.0811617\n",
      "[275]\ttraining's rmse: 0.0788166\tvalid_1's rmse: 0.081133\n",
      "[300]\ttraining's rmse: 0.0787523\tvalid_1's rmse: 0.0811069\n",
      "[325]\ttraining's rmse: 0.0786876\tvalid_1's rmse: 0.0810816\n",
      "[350]\ttraining's rmse: 0.0786239\tvalid_1's rmse: 0.0810585\n",
      "[375]\ttraining's rmse: 0.0785716\tvalid_1's rmse: 0.081038\n",
      "[400]\ttraining's rmse: 0.078513\tvalid_1's rmse: 0.081018\n",
      "[425]\ttraining's rmse: 0.0784615\tvalid_1's rmse: 0.0809988\n",
      "[450]\ttraining's rmse: 0.0784136\tvalid_1's rmse: 0.0809806\n",
      "[475]\ttraining's rmse: 0.0783684\tvalid_1's rmse: 0.0809636\n",
      "[500]\ttraining's rmse: 0.0783318\tvalid_1's rmse: 0.0809479\n",
      "[525]\ttraining's rmse: 0.0782846\tvalid_1's rmse: 0.080932\n",
      "[550]\ttraining's rmse: 0.0782395\tvalid_1's rmse: 0.0809173\n",
      "[575]\ttraining's rmse: 0.0781987\tvalid_1's rmse: 0.0809039\n",
      "[600]\ttraining's rmse: 0.0781595\tvalid_1's rmse: 0.0808919\n",
      "[625]\ttraining's rmse: 0.0781281\tvalid_1's rmse: 0.0808802\n",
      "[650]\ttraining's rmse: 0.0780906\tvalid_1's rmse: 0.0808687\n",
      "[675]\ttraining's rmse: 0.0780515\tvalid_1's rmse: 0.0808577\n",
      "[700]\ttraining's rmse: 0.0780169\tvalid_1's rmse: 0.0808473\n",
      "[725]\ttraining's rmse: 0.0779848\tvalid_1's rmse: 0.0808376\n",
      "[750]\ttraining's rmse: 0.0779557\tvalid_1's rmse: 0.0808292\n",
      "[775]\ttraining's rmse: 0.07793\tvalid_1's rmse: 0.0808208\n",
      "[800]\ttraining's rmse: 0.0778993\tvalid_1's rmse: 0.080813\n",
      "[825]\ttraining's rmse: 0.0778725\tvalid_1's rmse: 0.0808053\n",
      "[850]\ttraining's rmse: 0.0778465\tvalid_1's rmse: 0.0807988\n",
      "[875]\ttraining's rmse: 0.0778208\tvalid_1's rmse: 0.0807926\n",
      "[900]\ttraining's rmse: 0.0777948\tvalid_1's rmse: 0.0807858\n",
      "[925]\ttraining's rmse: 0.0777701\tvalid_1's rmse: 0.0807795\n",
      "[950]\ttraining's rmse: 0.0777479\tvalid_1's rmse: 0.0807734\n",
      "[975]\ttraining's rmse: 0.0777246\tvalid_1's rmse: 0.0807676\n",
      "[1000]\ttraining's rmse: 0.077705\tvalid_1's rmse: 0.0807625\n",
      "[1025]\ttraining's rmse: 0.077682\tvalid_1's rmse: 0.0807578\n",
      "[1050]\ttraining's rmse: 0.0776637\tvalid_1's rmse: 0.080753\n",
      "[1075]\ttraining's rmse: 0.0776451\tvalid_1's rmse: 0.0807486\n",
      "[1100]\ttraining's rmse: 0.0776295\tvalid_1's rmse: 0.0807452\n",
      "[1125]\ttraining's rmse: 0.0776123\tvalid_1's rmse: 0.0807406\n",
      "[1150]\ttraining's rmse: 0.0775955\tvalid_1's rmse: 0.0807367\n",
      "[1175]\ttraining's rmse: 0.0775806\tvalid_1's rmse: 0.0807333\n",
      "[1200]\ttraining's rmse: 0.0775635\tvalid_1's rmse: 0.0807297\n",
      "[1225]\ttraining's rmse: 0.0775489\tvalid_1's rmse: 0.0807268\n",
      "[1250]\ttraining's rmse: 0.077536\tvalid_1's rmse: 0.080723\n",
      "[1275]\ttraining's rmse: 0.0775198\tvalid_1's rmse: 0.0807204\n",
      "[1300]\ttraining's rmse: 0.0775077\tvalid_1's rmse: 0.0807172\n",
      "[1325]\ttraining's rmse: 0.077497\tvalid_1's rmse: 0.0807149\n",
      "[1350]\ttraining's rmse: 0.0774836\tvalid_1's rmse: 0.0807128\n",
      "[1375]\ttraining's rmse: 0.0774739\tvalid_1's rmse: 0.0807108\n",
      "[1400]\ttraining's rmse: 0.0774653\tvalid_1's rmse: 0.0807076\n",
      "[1425]\ttraining's rmse: 0.0774549\tvalid_1's rmse: 0.080706\n",
      "[1450]\ttraining's rmse: 0.0774447\tvalid_1's rmse: 0.0807048\n",
      "[1475]\ttraining's rmse: 0.0774365\tvalid_1's rmse: 0.0807033\n",
      "[1500]\ttraining's rmse: 0.077428\tvalid_1's rmse: 0.0807014\n",
      "[1525]\ttraining's rmse: 0.0774209\tvalid_1's rmse: 0.0806996\n",
      "[1550]\ttraining's rmse: 0.0774123\tvalid_1's rmse: 0.0806988\n",
      "[1575]\ttraining's rmse: 0.0774046\tvalid_1's rmse: 0.0806971\n",
      "[1600]\ttraining's rmse: 0.0773978\tvalid_1's rmse: 0.080696\n",
      "[1625]\ttraining's rmse: 0.0773897\tvalid_1's rmse: 0.0806945\n",
      "[1650]\ttraining's rmse: 0.0773836\tvalid_1's rmse: 0.0806934\n",
      "[1675]\ttraining's rmse: 0.0773784\tvalid_1's rmse: 0.0806918\n",
      "[1700]\ttraining's rmse: 0.0773744\tvalid_1's rmse: 0.0806904\n",
      "[1725]\ttraining's rmse: 0.0773673\tvalid_1's rmse: 0.0806894\n",
      "[1750]\ttraining's rmse: 0.0773604\tvalid_1's rmse: 0.0806886\n",
      "[1775]\ttraining's rmse: 0.0773555\tvalid_1's rmse: 0.0806876\n",
      "[1800]\ttraining's rmse: 0.077349\tvalid_1's rmse: 0.0806867\n",
      "[1825]\ttraining's rmse: 0.0773436\tvalid_1's rmse: 0.0806855\n",
      "[1850]\ttraining's rmse: 0.0773389\tvalid_1's rmse: 0.0806843\n",
      "[1875]\ttraining's rmse: 0.077334\tvalid_1's rmse: 0.0806836\n",
      "[1900]\ttraining's rmse: 0.0773299\tvalid_1's rmse: 0.0806833\n",
      "[1925]\ttraining's rmse: 0.0773245\tvalid_1's rmse: 0.0806827\n",
      "[1950]\ttraining's rmse: 0.0773212\tvalid_1's rmse: 0.0806816\n",
      "[1975]\ttraining's rmse: 0.0773177\tvalid_1's rmse: 0.080681\n",
      "[2000]\ttraining's rmse: 0.0773135\tvalid_1's rmse: 0.08068\n",
      "[2025]\ttraining's rmse: 0.0773093\tvalid_1's rmse: 0.0806792\n",
      "[2050]\ttraining's rmse: 0.0773068\tvalid_1's rmse: 0.0806789\n",
      "[2075]\ttraining's rmse: 0.0773047\tvalid_1's rmse: 0.0806788\n",
      "[2100]\ttraining's rmse: 0.0773018\tvalid_1's rmse: 0.0806782\n",
      "[2125]\ttraining's rmse: 0.0772992\tvalid_1's rmse: 0.0806779\n",
      "[2150]\ttraining's rmse: 0.0772966\tvalid_1's rmse: 0.0806777\n",
      "[2175]\ttraining's rmse: 0.0772934\tvalid_1's rmse: 0.080678\n",
      "[2200]\ttraining's rmse: 0.0772908\tvalid_1's rmse: 0.0806777\n",
      "[2225]\ttraining's rmse: 0.0772883\tvalid_1's rmse: 0.0806772\n",
      "[2250]\ttraining's rmse: 0.0772863\tvalid_1's rmse: 0.0806768\n",
      "[2275]\ttraining's rmse: 0.0772826\tvalid_1's rmse: 0.0806764\n",
      "[2300]\ttraining's rmse: 0.07728\tvalid_1's rmse: 0.0806761\n",
      "[2325]\ttraining's rmse: 0.0772758\tvalid_1's rmse: 0.0806758\n",
      "[2350]\ttraining's rmse: 0.0772739\tvalid_1's rmse: 0.0806754\n",
      "[2375]\ttraining's rmse: 0.0772723\tvalid_1's rmse: 0.080675\n",
      "[2400]\ttraining's rmse: 0.0772695\tvalid_1's rmse: 0.080675\n",
      "[2425]\ttraining's rmse: 0.0772663\tvalid_1's rmse: 0.0806749\n",
      "[2450]\ttraining's rmse: 0.0772641\tvalid_1's rmse: 0.0806746\n",
      "[2475]\ttraining's rmse: 0.0772623\tvalid_1's rmse: 0.0806745\n",
      "[2500]\ttraining's rmse: 0.0772601\tvalid_1's rmse: 0.080675\n",
      "Early stopping, best iteration is:\n",
      "[2466]\ttraining's rmse: 0.0772627\tvalid_1's rmse: 0.0806744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0814828\tvalid_1's rmse: 0.0779003\n",
      "[50]\ttraining's rmse: 0.0813805\tvalid_1's rmse: 0.0778583\n",
      "[75]\ttraining's rmse: 0.081273\tvalid_1's rmse: 0.077812\n",
      "[100]\ttraining's rmse: 0.0811796\tvalid_1's rmse: 0.077772\n",
      "[125]\ttraining's rmse: 0.0810801\tvalid_1's rmse: 0.0777355\n",
      "[150]\ttraining's rmse: 0.0809886\tvalid_1's rmse: 0.0776994\n",
      "[175]\ttraining's rmse: 0.0809141\tvalid_1's rmse: 0.0776682\n",
      "[200]\ttraining's rmse: 0.0808308\tvalid_1's rmse: 0.0776427\n",
      "[225]\ttraining's rmse: 0.0807507\tvalid_1's rmse: 0.0776128\n",
      "[250]\ttraining's rmse: 0.0806841\tvalid_1's rmse: 0.0775864\n",
      "[275]\ttraining's rmse: 0.0806226\tvalid_1's rmse: 0.0775617\n",
      "[300]\ttraining's rmse: 0.0805604\tvalid_1's rmse: 0.0775387\n",
      "[325]\ttraining's rmse: 0.0804985\tvalid_1's rmse: 0.0775169\n",
      "[350]\ttraining's rmse: 0.0804366\tvalid_1's rmse: 0.0774944\n",
      "[375]\ttraining's rmse: 0.0803844\tvalid_1's rmse: 0.0774771\n",
      "[400]\ttraining's rmse: 0.0803309\tvalid_1's rmse: 0.077463\n",
      "[425]\ttraining's rmse: 0.0802824\tvalid_1's rmse: 0.0774552\n",
      "[450]\ttraining's rmse: 0.0802357\tvalid_1's rmse: 0.0774388\n",
      "[475]\ttraining's rmse: 0.0801933\tvalid_1's rmse: 0.0774365\n",
      "[500]\ttraining's rmse: 0.0801565\tvalid_1's rmse: 0.0774236\n",
      "[525]\ttraining's rmse: 0.0801091\tvalid_1's rmse: 0.0774098\n",
      "[550]\ttraining's rmse: 0.0800675\tvalid_1's rmse: 0.0774038\n",
      "[575]\ttraining's rmse: 0.0800276\tvalid_1's rmse: 0.0773994\n",
      "[600]\ttraining's rmse: 0.0799864\tvalid_1's rmse: 0.0773948\n",
      "[625]\ttraining's rmse: 0.0799543\tvalid_1's rmse: 0.0773968\n",
      "[650]\ttraining's rmse: 0.0799135\tvalid_1's rmse: 0.0774038\n",
      "Early stopping, best iteration is:\n",
      "[618]\ttraining's rmse: 0.0799636\tvalid_1's rmse: 0.077394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0809815\tvalid_1's rmse: 0.0834827\n",
      "[50]\ttraining's rmse: 0.0808589\tvalid_1's rmse: 0.0834342\n",
      "[75]\ttraining's rmse: 0.0807316\tvalid_1's rmse: 0.0833859\n",
      "[100]\ttraining's rmse: 0.0806178\tvalid_1's rmse: 0.0833433\n",
      "[125]\ttraining's rmse: 0.0804996\tvalid_1's rmse: 0.0833009\n",
      "[150]\ttraining's rmse: 0.0803945\tvalid_1's rmse: 0.08326\n",
      "[175]\ttraining's rmse: 0.0803078\tvalid_1's rmse: 0.0832272\n",
      "[200]\ttraining's rmse: 0.0802115\tvalid_1's rmse: 0.0831922\n",
      "[225]\ttraining's rmse: 0.0801173\tvalid_1's rmse: 0.0831598\n",
      "[250]\ttraining's rmse: 0.080035\tvalid_1's rmse: 0.0831298\n",
      "[275]\ttraining's rmse: 0.0799626\tvalid_1's rmse: 0.083102\n",
      "[300]\ttraining's rmse: 0.0798888\tvalid_1's rmse: 0.0830773\n",
      "[325]\ttraining's rmse: 0.0798167\tvalid_1's rmse: 0.0830535\n",
      "[350]\ttraining's rmse: 0.079748\tvalid_1's rmse: 0.0830304\n",
      "[375]\ttraining's rmse: 0.0796902\tvalid_1's rmse: 0.0830114\n",
      "[400]\ttraining's rmse: 0.0796264\tvalid_1's rmse: 0.0829922\n",
      "[425]\ttraining's rmse: 0.079569\tvalid_1's rmse: 0.0829721\n",
      "[450]\ttraining's rmse: 0.0795164\tvalid_1's rmse: 0.082953\n",
      "[475]\ttraining's rmse: 0.0794725\tvalid_1's rmse: 0.0829366\n",
      "[500]\ttraining's rmse: 0.0794306\tvalid_1's rmse: 0.0829222\n",
      "[525]\ttraining's rmse: 0.0793797\tvalid_1's rmse: 0.0829079\n",
      "[550]\ttraining's rmse: 0.079334\tvalid_1's rmse: 0.0828939\n",
      "[575]\ttraining's rmse: 0.0792912\tvalid_1's rmse: 0.0828807\n",
      "[600]\ttraining's rmse: 0.0792505\tvalid_1's rmse: 0.082868\n",
      "[625]\ttraining's rmse: 0.0792172\tvalid_1's rmse: 0.0828573\n",
      "[650]\ttraining's rmse: 0.0791759\tvalid_1's rmse: 0.0828453\n",
      "[675]\ttraining's rmse: 0.0791345\tvalid_1's rmse: 0.0828345\n",
      "[700]\ttraining's rmse: 0.0790989\tvalid_1's rmse: 0.0828248\n",
      "[725]\ttraining's rmse: 0.0790606\tvalid_1's rmse: 0.0828157\n",
      "[750]\ttraining's rmse: 0.0790279\tvalid_1's rmse: 0.0828081\n",
      "[775]\ttraining's rmse: 0.0789988\tvalid_1's rmse: 0.0827993\n",
      "[800]\ttraining's rmse: 0.078965\tvalid_1's rmse: 0.0827918\n",
      "[825]\ttraining's rmse: 0.0789372\tvalid_1's rmse: 0.0827838\n",
      "[850]\ttraining's rmse: 0.0789051\tvalid_1's rmse: 0.0827768\n",
      "[875]\ttraining's rmse: 0.078878\tvalid_1's rmse: 0.0827706\n",
      "[900]\ttraining's rmse: 0.0788469\tvalid_1's rmse: 0.0827642\n",
      "[925]\ttraining's rmse: 0.0788233\tvalid_1's rmse: 0.0827579\n",
      "[950]\ttraining's rmse: 0.078801\tvalid_1's rmse: 0.0827516\n",
      "[975]\ttraining's rmse: 0.078779\tvalid_1's rmse: 0.0827473\n",
      "[1000]\ttraining's rmse: 0.0787559\tvalid_1's rmse: 0.0827412\n",
      "[1025]\ttraining's rmse: 0.078734\tvalid_1's rmse: 0.0827356\n",
      "[1050]\ttraining's rmse: 0.0787129\tvalid_1's rmse: 0.0827306\n",
      "[1075]\ttraining's rmse: 0.0786929\tvalid_1's rmse: 0.0827272\n",
      "[1100]\ttraining's rmse: 0.0786763\tvalid_1's rmse: 0.0827234\n",
      "[1125]\ttraining's rmse: 0.0786594\tvalid_1's rmse: 0.0827187\n",
      "[1150]\ttraining's rmse: 0.0786445\tvalid_1's rmse: 0.0827151\n",
      "[1175]\ttraining's rmse: 0.0786263\tvalid_1's rmse: 0.0827121\n",
      "[1200]\ttraining's rmse: 0.0786104\tvalid_1's rmse: 0.0827072\n",
      "[1225]\ttraining's rmse: 0.0785946\tvalid_1's rmse: 0.0827033\n",
      "[1250]\ttraining's rmse: 0.0785803\tvalid_1's rmse: 0.0826992\n",
      "[1275]\ttraining's rmse: 0.0785634\tvalid_1's rmse: 0.0826953\n",
      "[1300]\ttraining's rmse: 0.0785496\tvalid_1's rmse: 0.0826926\n",
      "[1325]\ttraining's rmse: 0.0785369\tvalid_1's rmse: 0.0826895\n",
      "[1350]\ttraining's rmse: 0.0785217\tvalid_1's rmse: 0.0826867\n",
      "[1375]\ttraining's rmse: 0.0785105\tvalid_1's rmse: 0.0826849\n",
      "[1400]\ttraining's rmse: 0.0785012\tvalid_1's rmse: 0.0826822\n",
      "[1425]\ttraining's rmse: 0.078489\tvalid_1's rmse: 0.0826807\n",
      "[1450]\ttraining's rmse: 0.0784764\tvalid_1's rmse: 0.0826777\n",
      "[1475]\ttraining's rmse: 0.078468\tvalid_1's rmse: 0.0826759\n",
      "[1500]\ttraining's rmse: 0.078458\tvalid_1's rmse: 0.0826729\n",
      "[1525]\ttraining's rmse: 0.0784476\tvalid_1's rmse: 0.0826704\n",
      "[1550]\ttraining's rmse: 0.0784378\tvalid_1's rmse: 0.0826677\n",
      "[1575]\ttraining's rmse: 0.078429\tvalid_1's rmse: 0.0826654\n",
      "[1600]\ttraining's rmse: 0.0784216\tvalid_1's rmse: 0.0826639\n",
      "[1625]\ttraining's rmse: 0.0784148\tvalid_1's rmse: 0.0826618\n",
      "[1650]\ttraining's rmse: 0.0784083\tvalid_1's rmse: 0.0826592\n",
      "[1675]\ttraining's rmse: 0.078402\tvalid_1's rmse: 0.0826564\n",
      "[1700]\ttraining's rmse: 0.0783979\tvalid_1's rmse: 0.0826539\n",
      "[1725]\ttraining's rmse: 0.0783915\tvalid_1's rmse: 0.0826525\n",
      "[1750]\ttraining's rmse: 0.0783864\tvalid_1's rmse: 0.0826508\n",
      "[1775]\ttraining's rmse: 0.0783807\tvalid_1's rmse: 0.0826502\n",
      "[1800]\ttraining's rmse: 0.0783757\tvalid_1's rmse: 0.0826481\n",
      "[1825]\ttraining's rmse: 0.0783692\tvalid_1's rmse: 0.0826476\n",
      "[1850]\ttraining's rmse: 0.0783633\tvalid_1's rmse: 0.082646\n",
      "[1875]\ttraining's rmse: 0.0783584\tvalid_1's rmse: 0.0826458\n",
      "[1900]\ttraining's rmse: 0.0783533\tvalid_1's rmse: 0.0826445\n",
      "[1925]\ttraining's rmse: 0.0783489\tvalid_1's rmse: 0.0826435\n",
      "[1950]\ttraining's rmse: 0.0783463\tvalid_1's rmse: 0.0826424\n",
      "[1975]\ttraining's rmse: 0.0783432\tvalid_1's rmse: 0.0826411\n",
      "[2000]\ttraining's rmse: 0.0783391\tvalid_1's rmse: 0.0826405\n",
      "[2025]\ttraining's rmse: 0.0783359\tvalid_1's rmse: 0.0826399\n",
      "[2050]\ttraining's rmse: 0.0783319\tvalid_1's rmse: 0.082639\n",
      "[2075]\ttraining's rmse: 0.0783285\tvalid_1's rmse: 0.0826383\n",
      "[2100]\ttraining's rmse: 0.0783259\tvalid_1's rmse: 0.0826379\n",
      "[2125]\ttraining's rmse: 0.0783225\tvalid_1's rmse: 0.0826367\n",
      "[2150]\ttraining's rmse: 0.0783192\tvalid_1's rmse: 0.0826365\n",
      "[2175]\ttraining's rmse: 0.0783172\tvalid_1's rmse: 0.0826363\n",
      "[2200]\ttraining's rmse: 0.0783146\tvalid_1's rmse: 0.0826357\n",
      "[2225]\ttraining's rmse: 0.0783113\tvalid_1's rmse: 0.0826343\n",
      "[2250]\ttraining's rmse: 0.0783101\tvalid_1's rmse: 0.0826338\n",
      "[2275]\ttraining's rmse: 0.0783071\tvalid_1's rmse: 0.0826325\n",
      "[2300]\ttraining's rmse: 0.0783047\tvalid_1's rmse: 0.082632\n",
      "[2325]\ttraining's rmse: 0.0783018\tvalid_1's rmse: 0.0826315\n",
      "[2350]\ttraining's rmse: 0.0782995\tvalid_1's rmse: 0.082631\n",
      "[2375]\ttraining's rmse: 0.0782971\tvalid_1's rmse: 0.0826306\n",
      "[2400]\ttraining's rmse: 0.078294\tvalid_1's rmse: 0.08263\n",
      "[2425]\ttraining's rmse: 0.0782909\tvalid_1's rmse: 0.0826284\n",
      "[2450]\ttraining's rmse: 0.0782883\tvalid_1's rmse: 0.0826281\n",
      "[2475]\ttraining's rmse: 0.0782859\tvalid_1's rmse: 0.0826278\n",
      "[2500]\ttraining's rmse: 0.0782838\tvalid_1's rmse: 0.0826268\n",
      "[2525]\ttraining's rmse: 0.0782813\tvalid_1's rmse: 0.0826271\n",
      "[2550]\ttraining's rmse: 0.0782788\tvalid_1's rmse: 0.0826261\n",
      "[2575]\ttraining's rmse: 0.0782773\tvalid_1's rmse: 0.0826262\n",
      "[2600]\ttraining's rmse: 0.0782752\tvalid_1's rmse: 0.0826261\n",
      "[2625]\ttraining's rmse: 0.0782739\tvalid_1's rmse: 0.0826257\n",
      "[2650]\ttraining's rmse: 0.0782728\tvalid_1's rmse: 0.0826247\n",
      "[2675]\ttraining's rmse: 0.0782716\tvalid_1's rmse: 0.0826246\n",
      "[2700]\ttraining's rmse: 0.0782703\tvalid_1's rmse: 0.082624\n",
      "[2725]\ttraining's rmse: 0.0782686\tvalid_1's rmse: 0.0826237\n",
      "[2750]\ttraining's rmse: 0.0782676\tvalid_1's rmse: 0.0826233\n",
      "[2775]\ttraining's rmse: 0.0782655\tvalid_1's rmse: 0.0826232\n",
      "[2800]\ttraining's rmse: 0.078264\tvalid_1's rmse: 0.0826235\n",
      "Early stopping, best iteration is:\n",
      "[2771]\ttraining's rmse: 0.0782659\tvalid_1's rmse: 0.0826231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0814214\tvalid_1's rmse: 0.0826463\n",
      "[50]\ttraining's rmse: 0.0813103\tvalid_1's rmse: 0.0825948\n",
      "[75]\ttraining's rmse: 0.081196\tvalid_1's rmse: 0.082544\n",
      "[100]\ttraining's rmse: 0.0810929\tvalid_1's rmse: 0.0824994\n",
      "[125]\ttraining's rmse: 0.0809877\tvalid_1's rmse: 0.0824528\n",
      "[150]\ttraining's rmse: 0.0808936\tvalid_1's rmse: 0.082411\n",
      "[175]\ttraining's rmse: 0.0808123\tvalid_1's rmse: 0.0823758\n",
      "[200]\ttraining's rmse: 0.0807242\tvalid_1's rmse: 0.08234\n",
      "[225]\ttraining's rmse: 0.080638\tvalid_1's rmse: 0.0823058\n",
      "[250]\ttraining's rmse: 0.080566\tvalid_1's rmse: 0.0822745\n",
      "[275]\ttraining's rmse: 0.0804974\tvalid_1's rmse: 0.0822469\n",
      "[300]\ttraining's rmse: 0.0804322\tvalid_1's rmse: 0.082221\n",
      "[325]\ttraining's rmse: 0.080363\tvalid_1's rmse: 0.0821947\n",
      "[350]\ttraining's rmse: 0.0802976\tvalid_1's rmse: 0.0821714\n",
      "[375]\ttraining's rmse: 0.0802435\tvalid_1's rmse: 0.0821501\n",
      "[400]\ttraining's rmse: 0.080183\tvalid_1's rmse: 0.0821291\n",
      "[425]\ttraining's rmse: 0.0801326\tvalid_1's rmse: 0.0821099\n",
      "[450]\ttraining's rmse: 0.0800848\tvalid_1's rmse: 0.0820918\n",
      "[475]\ttraining's rmse: 0.0800386\tvalid_1's rmse: 0.0820749\n",
      "[500]\ttraining's rmse: 0.0799989\tvalid_1's rmse: 0.0820583\n",
      "[525]\ttraining's rmse: 0.0799506\tvalid_1's rmse: 0.0820431\n",
      "[550]\ttraining's rmse: 0.0799043\tvalid_1's rmse: 0.0820284\n",
      "[575]\ttraining's rmse: 0.0798619\tvalid_1's rmse: 0.0820139\n",
      "[600]\ttraining's rmse: 0.0798215\tvalid_1's rmse: 0.0820013\n",
      "[625]\ttraining's rmse: 0.0797887\tvalid_1's rmse: 0.0819885\n",
      "[650]\ttraining's rmse: 0.0797496\tvalid_1's rmse: 0.0819767\n",
      "[675]\ttraining's rmse: 0.0797091\tvalid_1's rmse: 0.0819648\n",
      "[700]\ttraining's rmse: 0.0796742\tvalid_1's rmse: 0.081953\n",
      "[725]\ttraining's rmse: 0.0796415\tvalid_1's rmse: 0.0819439\n",
      "[750]\ttraining's rmse: 0.0796112\tvalid_1's rmse: 0.0819343\n",
      "[775]\ttraining's rmse: 0.0795853\tvalid_1's rmse: 0.0819254\n",
      "[800]\ttraining's rmse: 0.0795507\tvalid_1's rmse: 0.0819167\n",
      "[825]\ttraining's rmse: 0.0795236\tvalid_1's rmse: 0.0819078\n",
      "[850]\ttraining's rmse: 0.0794936\tvalid_1's rmse: 0.0819011\n",
      "[875]\ttraining's rmse: 0.0794679\tvalid_1's rmse: 0.0818944\n",
      "[900]\ttraining's rmse: 0.0794406\tvalid_1's rmse: 0.0818873\n",
      "[925]\ttraining's rmse: 0.0794147\tvalid_1's rmse: 0.0818812\n",
      "[950]\ttraining's rmse: 0.0793915\tvalid_1's rmse: 0.0818752\n",
      "[975]\ttraining's rmse: 0.079369\tvalid_1's rmse: 0.0818706\n",
      "[1000]\ttraining's rmse: 0.0793478\tvalid_1's rmse: 0.0818656\n",
      "[1025]\ttraining's rmse: 0.0793229\tvalid_1's rmse: 0.0818608\n",
      "[1050]\ttraining's rmse: 0.079303\tvalid_1's rmse: 0.0818551\n",
      "[1075]\ttraining's rmse: 0.0792842\tvalid_1's rmse: 0.0818511\n",
      "[1100]\ttraining's rmse: 0.0792693\tvalid_1's rmse: 0.0818465\n",
      "[1125]\ttraining's rmse: 0.0792501\tvalid_1's rmse: 0.0818426\n",
      "[1150]\ttraining's rmse: 0.0792341\tvalid_1's rmse: 0.0818388\n",
      "[1175]\ttraining's rmse: 0.0792177\tvalid_1's rmse: 0.0818351\n",
      "[1200]\ttraining's rmse: 0.0792008\tvalid_1's rmse: 0.0818317\n",
      "[1225]\ttraining's rmse: 0.0791845\tvalid_1's rmse: 0.0818282\n",
      "[1250]\ttraining's rmse: 0.0791712\tvalid_1's rmse: 0.081825\n",
      "[1275]\ttraining's rmse: 0.0791557\tvalid_1's rmse: 0.0818225\n",
      "[1300]\ttraining's rmse: 0.0791433\tvalid_1's rmse: 0.0818198\n",
      "[1325]\ttraining's rmse: 0.0791292\tvalid_1's rmse: 0.0818173\n",
      "[1350]\ttraining's rmse: 0.0791167\tvalid_1's rmse: 0.0818154\n",
      "[1375]\ttraining's rmse: 0.0791044\tvalid_1's rmse: 0.0818139\n",
      "[1400]\ttraining's rmse: 0.0790936\tvalid_1's rmse: 0.0818115\n",
      "[1425]\ttraining's rmse: 0.0790839\tvalid_1's rmse: 0.0818103\n",
      "[1450]\ttraining's rmse: 0.0790714\tvalid_1's rmse: 0.0818085\n",
      "[1475]\ttraining's rmse: 0.0790622\tvalid_1's rmse: 0.0818065\n",
      "[1500]\ttraining's rmse: 0.0790528\tvalid_1's rmse: 0.0818048\n",
      "[1525]\ttraining's rmse: 0.0790445\tvalid_1's rmse: 0.0818035\n",
      "[1550]\ttraining's rmse: 0.0790363\tvalid_1's rmse: 0.0818018\n",
      "[1575]\ttraining's rmse: 0.0790281\tvalid_1's rmse: 0.0818\n",
      "[1600]\ttraining's rmse: 0.0790231\tvalid_1's rmse: 0.081799\n",
      "[1625]\ttraining's rmse: 0.0790168\tvalid_1's rmse: 0.0817977\n",
      "[1650]\ttraining's rmse: 0.0790089\tvalid_1's rmse: 0.0817965\n",
      "[1675]\ttraining's rmse: 0.0790044\tvalid_1's rmse: 0.0817955\n",
      "[1700]\ttraining's rmse: 0.0789988\tvalid_1's rmse: 0.0817935\n",
      "[1725]\ttraining's rmse: 0.0789932\tvalid_1's rmse: 0.081792\n",
      "[1750]\ttraining's rmse: 0.0789873\tvalid_1's rmse: 0.0817911\n",
      "[1775]\ttraining's rmse: 0.0789824\tvalid_1's rmse: 0.0817907\n",
      "[1800]\ttraining's rmse: 0.0789763\tvalid_1's rmse: 0.0817897\n",
      "[1825]\ttraining's rmse: 0.0789716\tvalid_1's rmse: 0.0817888\n",
      "[1850]\ttraining's rmse: 0.0789663\tvalid_1's rmse: 0.0817879\n",
      "[1875]\ttraining's rmse: 0.0789616\tvalid_1's rmse: 0.081787\n",
      "[1900]\ttraining's rmse: 0.0789585\tvalid_1's rmse: 0.0817868\n",
      "[1925]\ttraining's rmse: 0.0789549\tvalid_1's rmse: 0.0817866\n",
      "[1950]\ttraining's rmse: 0.0789506\tvalid_1's rmse: 0.0817856\n",
      "[1975]\ttraining's rmse: 0.0789469\tvalid_1's rmse: 0.0817848\n",
      "[2000]\ttraining's rmse: 0.0789408\tvalid_1's rmse: 0.081784\n",
      "[2025]\ttraining's rmse: 0.0789376\tvalid_1's rmse: 0.0817837\n",
      "[2050]\ttraining's rmse: 0.0789333\tvalid_1's rmse: 0.0817833\n",
      "[2075]\ttraining's rmse: 0.0789295\tvalid_1's rmse: 0.0817829\n",
      "[2100]\ttraining's rmse: 0.078927\tvalid_1's rmse: 0.0817826\n",
      "[2125]\ttraining's rmse: 0.0789239\tvalid_1's rmse: 0.081782\n",
      "[2150]\ttraining's rmse: 0.0789211\tvalid_1's rmse: 0.0817817\n",
      "[2175]\ttraining's rmse: 0.0789191\tvalid_1's rmse: 0.0817816\n",
      "[2200]\ttraining's rmse: 0.0789168\tvalid_1's rmse: 0.0817811\n",
      "[2225]\ttraining's rmse: 0.0789139\tvalid_1's rmse: 0.0817809\n",
      "[2250]\ttraining's rmse: 0.0789112\tvalid_1's rmse: 0.0817807\n",
      "[2275]\ttraining's rmse: 0.0789081\tvalid_1's rmse: 0.0817804\n",
      "[2300]\ttraining's rmse: 0.0789052\tvalid_1's rmse: 0.0817797\n",
      "[2325]\ttraining's rmse: 0.0789026\tvalid_1's rmse: 0.0817794\n",
      "[2350]\ttraining's rmse: 0.0789007\tvalid_1's rmse: 0.0817793\n",
      "[2375]\ttraining's rmse: 0.0788981\tvalid_1's rmse: 0.0817788\n",
      "[2400]\ttraining's rmse: 0.0788955\tvalid_1's rmse: 0.0817791\n",
      "[2425]\ttraining's rmse: 0.0788938\tvalid_1's rmse: 0.0817789\n",
      "[2450]\ttraining's rmse: 0.0788918\tvalid_1's rmse: 0.081779\n",
      "Early stopping, best iteration is:\n",
      "[2422]\ttraining's rmse: 0.0788939\tvalid_1's rmse: 0.0817787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0829489\tvalid_1's rmse: 0.0795325\n",
      "[50]\ttraining's rmse: 0.0828432\tvalid_1's rmse: 0.0794854\n",
      "[75]\ttraining's rmse: 0.0827349\tvalid_1's rmse: 0.0794407\n",
      "[100]\ttraining's rmse: 0.0826364\tvalid_1's rmse: 0.079399\n",
      "[125]\ttraining's rmse: 0.0825367\tvalid_1's rmse: 0.0793588\n",
      "[150]\ttraining's rmse: 0.0824431\tvalid_1's rmse: 0.0793226\n",
      "[175]\ttraining's rmse: 0.0823636\tvalid_1's rmse: 0.0792922\n",
      "[200]\ttraining's rmse: 0.0822783\tvalid_1's rmse: 0.0792614\n",
      "[225]\ttraining's rmse: 0.082195\tvalid_1's rmse: 0.0792344\n",
      "[250]\ttraining's rmse: 0.0821259\tvalid_1's rmse: 0.0792097\n",
      "[275]\ttraining's rmse: 0.0820612\tvalid_1's rmse: 0.0791862\n",
      "[300]\ttraining's rmse: 0.0819963\tvalid_1's rmse: 0.079169\n",
      "[325]\ttraining's rmse: 0.0819325\tvalid_1's rmse: 0.0791468\n",
      "[350]\ttraining's rmse: 0.08187\tvalid_1's rmse: 0.0791262\n",
      "[375]\ttraining's rmse: 0.0818194\tvalid_1's rmse: 0.0791135\n",
      "[400]\ttraining's rmse: 0.0817614\tvalid_1's rmse: 0.0790956\n",
      "[425]\ttraining's rmse: 0.0817103\tvalid_1's rmse: 0.0790838\n",
      "[450]\ttraining's rmse: 0.0816634\tvalid_1's rmse: 0.0790693\n",
      "[475]\ttraining's rmse: 0.0816202\tvalid_1's rmse: 0.079056\n",
      "[500]\ttraining's rmse: 0.0815814\tvalid_1's rmse: 0.0790419\n",
      "[525]\ttraining's rmse: 0.081531\tvalid_1's rmse: 0.079033\n",
      "[550]\ttraining's rmse: 0.0814852\tvalid_1's rmse: 0.079024\n",
      "[575]\ttraining's rmse: 0.0814434\tvalid_1's rmse: 0.0790131\n",
      "[600]\ttraining's rmse: 0.0814016\tvalid_1's rmse: 0.0790067\n",
      "[625]\ttraining's rmse: 0.0813697\tvalid_1's rmse: 0.0790038\n",
      "[650]\ttraining's rmse: 0.0813311\tvalid_1's rmse: 0.0789982\n",
      "[675]\ttraining's rmse: 0.0812896\tvalid_1's rmse: 0.0790049\n",
      "[700]\ttraining's rmse: 0.0812518\tvalid_1's rmse: 0.0790021\n",
      "Early stopping, best iteration is:\n",
      "[657]\ttraining's rmse: 0.08132\tvalid_1's rmse: 0.0789954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0801644\tvalid_1's rmse: 0.082408\n",
      "[50]\ttraining's rmse: 0.0800436\tvalid_1's rmse: 0.0823579\n",
      "[75]\ttraining's rmse: 0.079924\tvalid_1's rmse: 0.0823094\n",
      "[100]\ttraining's rmse: 0.0798117\tvalid_1's rmse: 0.082266\n",
      "[125]\ttraining's rmse: 0.0797005\tvalid_1's rmse: 0.082223\n",
      "[150]\ttraining's rmse: 0.0795987\tvalid_1's rmse: 0.0821825\n",
      "[175]\ttraining's rmse: 0.0795136\tvalid_1's rmse: 0.082147\n",
      "[200]\ttraining's rmse: 0.0794241\tvalid_1's rmse: 0.0821135\n",
      "[225]\ttraining's rmse: 0.0793345\tvalid_1's rmse: 0.082082\n",
      "[250]\ttraining's rmse: 0.0792613\tvalid_1's rmse: 0.0820544\n",
      "[275]\ttraining's rmse: 0.07919\tvalid_1's rmse: 0.0820283\n",
      "[300]\ttraining's rmse: 0.0791199\tvalid_1's rmse: 0.082003\n",
      "[325]\ttraining's rmse: 0.0790478\tvalid_1's rmse: 0.0819796\n",
      "[350]\ttraining's rmse: 0.0789811\tvalid_1's rmse: 0.0819567\n",
      "[375]\ttraining's rmse: 0.0789256\tvalid_1's rmse: 0.081936\n",
      "[400]\ttraining's rmse: 0.0788648\tvalid_1's rmse: 0.081916\n",
      "[425]\ttraining's rmse: 0.0788088\tvalid_1's rmse: 0.0818978\n",
      "[450]\ttraining's rmse: 0.0787581\tvalid_1's rmse: 0.0818803\n",
      "[475]\ttraining's rmse: 0.0787121\tvalid_1's rmse: 0.0818626\n",
      "[500]\ttraining's rmse: 0.0786705\tvalid_1's rmse: 0.081847\n",
      "[525]\ttraining's rmse: 0.0786216\tvalid_1's rmse: 0.0818327\n",
      "[550]\ttraining's rmse: 0.0785787\tvalid_1's rmse: 0.0818199\n",
      "[575]\ttraining's rmse: 0.078536\tvalid_1's rmse: 0.0818079\n",
      "[600]\ttraining's rmse: 0.0784957\tvalid_1's rmse: 0.0817953\n",
      "[625]\ttraining's rmse: 0.078464\tvalid_1's rmse: 0.0817832\n",
      "[650]\ttraining's rmse: 0.0784233\tvalid_1's rmse: 0.0817714\n",
      "[675]\ttraining's rmse: 0.078383\tvalid_1's rmse: 0.0817607\n",
      "[700]\ttraining's rmse: 0.0783485\tvalid_1's rmse: 0.0817508\n",
      "[725]\ttraining's rmse: 0.0783123\tvalid_1's rmse: 0.0817412\n",
      "[750]\ttraining's rmse: 0.0782815\tvalid_1's rmse: 0.081733\n",
      "[775]\ttraining's rmse: 0.078257\tvalid_1's rmse: 0.0817237\n",
      "[800]\ttraining's rmse: 0.0782253\tvalid_1's rmse: 0.0817157\n",
      "[825]\ttraining's rmse: 0.0781973\tvalid_1's rmse: 0.0817087\n",
      "[850]\ttraining's rmse: 0.0781668\tvalid_1's rmse: 0.0817014\n",
      "[875]\ttraining's rmse: 0.0781413\tvalid_1's rmse: 0.0816946\n",
      "[900]\ttraining's rmse: 0.0781149\tvalid_1's rmse: 0.0816879\n",
      "[925]\ttraining's rmse: 0.0780886\tvalid_1's rmse: 0.0816804\n",
      "[950]\ttraining's rmse: 0.0780668\tvalid_1's rmse: 0.0816738\n",
      "[975]\ttraining's rmse: 0.0780467\tvalid_1's rmse: 0.0816686\n",
      "[1000]\ttraining's rmse: 0.0780233\tvalid_1's rmse: 0.0816621\n",
      "[1025]\ttraining's rmse: 0.0780009\tvalid_1's rmse: 0.0816573\n",
      "[1050]\ttraining's rmse: 0.0779805\tvalid_1's rmse: 0.0816514\n",
      "[1075]\ttraining's rmse: 0.0779631\tvalid_1's rmse: 0.0816479\n",
      "[1100]\ttraining's rmse: 0.0779471\tvalid_1's rmse: 0.0816434\n",
      "[1125]\ttraining's rmse: 0.0779294\tvalid_1's rmse: 0.0816382\n",
      "[1150]\ttraining's rmse: 0.0779106\tvalid_1's rmse: 0.081634\n",
      "[1175]\ttraining's rmse: 0.0778939\tvalid_1's rmse: 0.0816309\n",
      "[1200]\ttraining's rmse: 0.0778772\tvalid_1's rmse: 0.0816257\n",
      "[1225]\ttraining's rmse: 0.0778614\tvalid_1's rmse: 0.0816228\n",
      "[1250]\ttraining's rmse: 0.0778468\tvalid_1's rmse: 0.0816202\n",
      "[1275]\ttraining's rmse: 0.0778303\tvalid_1's rmse: 0.0816163\n",
      "[1300]\ttraining's rmse: 0.077817\tvalid_1's rmse: 0.0816124\n",
      "[1325]\ttraining's rmse: 0.0778025\tvalid_1's rmse: 0.0816083\n",
      "[1350]\ttraining's rmse: 0.0777892\tvalid_1's rmse: 0.0816061\n",
      "[1375]\ttraining's rmse: 0.0777761\tvalid_1's rmse: 0.0816039\n",
      "[1400]\ttraining's rmse: 0.077767\tvalid_1's rmse: 0.0816004\n",
      "[1425]\ttraining's rmse: 0.0777554\tvalid_1's rmse: 0.0815982\n",
      "[1450]\ttraining's rmse: 0.0777453\tvalid_1's rmse: 0.0815955\n",
      "[1475]\ttraining's rmse: 0.077736\tvalid_1's rmse: 0.0815934\n",
      "[1500]\ttraining's rmse: 0.0777283\tvalid_1's rmse: 0.0815911\n",
      "[1525]\ttraining's rmse: 0.0777192\tvalid_1's rmse: 0.0815882\n",
      "[1550]\ttraining's rmse: 0.0777101\tvalid_1's rmse: 0.0815876\n",
      "[1575]\ttraining's rmse: 0.0777041\tvalid_1's rmse: 0.0815859\n",
      "[1600]\ttraining's rmse: 0.0776982\tvalid_1's rmse: 0.0815844\n",
      "[1625]\ttraining's rmse: 0.0776919\tvalid_1's rmse: 0.0815813\n",
      "[1650]\ttraining's rmse: 0.0776851\tvalid_1's rmse: 0.0815788\n",
      "[1675]\ttraining's rmse: 0.0776795\tvalid_1's rmse: 0.0815773\n",
      "[1700]\ttraining's rmse: 0.0776748\tvalid_1's rmse: 0.0815762\n",
      "[1725]\ttraining's rmse: 0.0776701\tvalid_1's rmse: 0.0815751\n",
      "[1750]\ttraining's rmse: 0.0776636\tvalid_1's rmse: 0.0815724\n",
      "[1775]\ttraining's rmse: 0.0776575\tvalid_1's rmse: 0.0815701\n",
      "[1800]\ttraining's rmse: 0.0776535\tvalid_1's rmse: 0.0815691\n",
      "[1825]\ttraining's rmse: 0.0776494\tvalid_1's rmse: 0.0815687\n",
      "[1850]\ttraining's rmse: 0.0776439\tvalid_1's rmse: 0.0815679\n",
      "[1875]\ttraining's rmse: 0.0776387\tvalid_1's rmse: 0.0815659\n",
      "[1900]\ttraining's rmse: 0.0776354\tvalid_1's rmse: 0.0815648\n",
      "[1925]\ttraining's rmse: 0.0776314\tvalid_1's rmse: 0.0815641\n",
      "[1950]\ttraining's rmse: 0.0776287\tvalid_1's rmse: 0.0815638\n",
      "[1975]\ttraining's rmse: 0.0776252\tvalid_1's rmse: 0.0815631\n",
      "[2000]\ttraining's rmse: 0.0776213\tvalid_1's rmse: 0.0815627\n",
      "[2025]\ttraining's rmse: 0.077618\tvalid_1's rmse: 0.0815608\n",
      "[2050]\ttraining's rmse: 0.0776146\tvalid_1's rmse: 0.0815605\n",
      "[2075]\ttraining's rmse: 0.0776118\tvalid_1's rmse: 0.0815594\n",
      "[2100]\ttraining's rmse: 0.0776093\tvalid_1's rmse: 0.0815577\n",
      "[2125]\ttraining's rmse: 0.0776059\tvalid_1's rmse: 0.0815578\n",
      "[2150]\ttraining's rmse: 0.0776022\tvalid_1's rmse: 0.0815575\n",
      "[2175]\ttraining's rmse: 0.0776\tvalid_1's rmse: 0.0815573\n",
      "[2200]\ttraining's rmse: 0.0775971\tvalid_1's rmse: 0.0815556\n",
      "[2225]\ttraining's rmse: 0.0775944\tvalid_1's rmse: 0.081555\n",
      "[2250]\ttraining's rmse: 0.0775918\tvalid_1's rmse: 0.0815538\n",
      "[2275]\ttraining's rmse: 0.0775885\tvalid_1's rmse: 0.0815528\n",
      "[2300]\ttraining's rmse: 0.0775861\tvalid_1's rmse: 0.0815518\n",
      "[2325]\ttraining's rmse: 0.0775837\tvalid_1's rmse: 0.0815512\n",
      "[2350]\ttraining's rmse: 0.0775805\tvalid_1's rmse: 0.08155\n",
      "[2375]\ttraining's rmse: 0.0775763\tvalid_1's rmse: 0.0815493\n",
      "[2400]\ttraining's rmse: 0.0775737\tvalid_1's rmse: 0.0815488\n",
      "[2425]\ttraining's rmse: 0.0775721\tvalid_1's rmse: 0.0815482\n",
      "[2450]\ttraining's rmse: 0.0775701\tvalid_1's rmse: 0.0815475\n",
      "[2475]\ttraining's rmse: 0.0775675\tvalid_1's rmse: 0.0815472\n",
      "[2500]\ttraining's rmse: 0.0775656\tvalid_1's rmse: 0.0815465\n",
      "[2525]\ttraining's rmse: 0.0775626\tvalid_1's rmse: 0.0815458\n",
      "[2550]\ttraining's rmse: 0.0775609\tvalid_1's rmse: 0.081546\n",
      "[2575]\ttraining's rmse: 0.077559\tvalid_1's rmse: 0.0815452\n",
      "[2600]\ttraining's rmse: 0.0775573\tvalid_1's rmse: 0.0815449\n",
      "[2625]\ttraining's rmse: 0.0775561\tvalid_1's rmse: 0.0815446\n",
      "[2650]\ttraining's rmse: 0.0775553\tvalid_1's rmse: 0.0815446\n",
      "[2675]\ttraining's rmse: 0.0775532\tvalid_1's rmse: 0.0815438\n",
      "[2700]\ttraining's rmse: 0.0775525\tvalid_1's rmse: 0.0815439\n",
      "[2725]\ttraining's rmse: 0.077551\tvalid_1's rmse: 0.0815439\n",
      "[2750]\ttraining's rmse: 0.0775493\tvalid_1's rmse: 0.0815433\n",
      "[2775]\ttraining's rmse: 0.077548\tvalid_1's rmse: 0.081543\n",
      "[2800]\ttraining's rmse: 0.0775465\tvalid_1's rmse: 0.0815426\n",
      "[2825]\ttraining's rmse: 0.0775448\tvalid_1's rmse: 0.0815428\n",
      "[2850]\ttraining's rmse: 0.0775435\tvalid_1's rmse: 0.0815429\n",
      "Early stopping, best iteration is:\n",
      "[2814]\ttraining's rmse: 0.0775456\tvalid_1's rmse: 0.0815426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0803349\tvalid_1's rmse: 0.0820785\n",
      "[50]\ttraining's rmse: 0.0802278\tvalid_1's rmse: 0.0820255\n",
      "[75]\ttraining's rmse: 0.0801174\tvalid_1's rmse: 0.0819745\n",
      "[100]\ttraining's rmse: 0.0800182\tvalid_1's rmse: 0.081928\n",
      "[125]\ttraining's rmse: 0.0799134\tvalid_1's rmse: 0.0818832\n",
      "[150]\ttraining's rmse: 0.07982\tvalid_1's rmse: 0.0818407\n",
      "[175]\ttraining's rmse: 0.079743\tvalid_1's rmse: 0.081806\n",
      "[200]\ttraining's rmse: 0.0796577\tvalid_1's rmse: 0.0817707\n",
      "[225]\ttraining's rmse: 0.0795739\tvalid_1's rmse: 0.0817382\n",
      "[250]\ttraining's rmse: 0.0795054\tvalid_1's rmse: 0.0817082\n",
      "[275]\ttraining's rmse: 0.0794423\tvalid_1's rmse: 0.0816804\n",
      "[300]\ttraining's rmse: 0.0793778\tvalid_1's rmse: 0.0816541\n",
      "[325]\ttraining's rmse: 0.0793121\tvalid_1's rmse: 0.0816282\n",
      "[350]\ttraining's rmse: 0.0792479\tvalid_1's rmse: 0.0816046\n",
      "[375]\ttraining's rmse: 0.0791975\tvalid_1's rmse: 0.0815836\n",
      "[400]\ttraining's rmse: 0.079143\tvalid_1's rmse: 0.0815641\n",
      "[425]\ttraining's rmse: 0.0790895\tvalid_1's rmse: 0.0815451\n",
      "[450]\ttraining's rmse: 0.0790413\tvalid_1's rmse: 0.081528\n",
      "[475]\ttraining's rmse: 0.0789972\tvalid_1's rmse: 0.0815116\n",
      "[500]\ttraining's rmse: 0.0789596\tvalid_1's rmse: 0.0814963\n",
      "[525]\ttraining's rmse: 0.0789098\tvalid_1's rmse: 0.0814806\n",
      "[550]\ttraining's rmse: 0.0788654\tvalid_1's rmse: 0.0814655\n",
      "[575]\ttraining's rmse: 0.0788225\tvalid_1's rmse: 0.0814521\n",
      "[600]\ttraining's rmse: 0.0787802\tvalid_1's rmse: 0.0814394\n",
      "[625]\ttraining's rmse: 0.0787496\tvalid_1's rmse: 0.0814287\n",
      "[650]\ttraining's rmse: 0.0787105\tvalid_1's rmse: 0.0814168\n",
      "[675]\ttraining's rmse: 0.0786739\tvalid_1's rmse: 0.0814063\n",
      "[700]\ttraining's rmse: 0.0786394\tvalid_1's rmse: 0.0813956\n",
      "[725]\ttraining's rmse: 0.0786061\tvalid_1's rmse: 0.0813857\n",
      "[750]\ttraining's rmse: 0.0785768\tvalid_1's rmse: 0.0813764\n",
      "[775]\ttraining's rmse: 0.0785517\tvalid_1's rmse: 0.0813674\n",
      "[800]\ttraining's rmse: 0.078518\tvalid_1's rmse: 0.0813595\n",
      "[825]\ttraining's rmse: 0.0784916\tvalid_1's rmse: 0.0813519\n",
      "[850]\ttraining's rmse: 0.0784653\tvalid_1's rmse: 0.0813454\n",
      "[875]\ttraining's rmse: 0.0784413\tvalid_1's rmse: 0.0813394\n",
      "[900]\ttraining's rmse: 0.0784147\tvalid_1's rmse: 0.0813324\n",
      "[925]\ttraining's rmse: 0.0783895\tvalid_1's rmse: 0.0813269\n",
      "[950]\ttraining's rmse: 0.0783666\tvalid_1's rmse: 0.0813214\n",
      "[975]\ttraining's rmse: 0.0783464\tvalid_1's rmse: 0.0813151\n",
      "[1000]\ttraining's rmse: 0.0783267\tvalid_1's rmse: 0.0813094\n",
      "[1025]\ttraining's rmse: 0.0783042\tvalid_1's rmse: 0.081304\n",
      "[1050]\ttraining's rmse: 0.0782854\tvalid_1's rmse: 0.0812984\n",
      "[1075]\ttraining's rmse: 0.0782663\tvalid_1's rmse: 0.0812943\n",
      "[1100]\ttraining's rmse: 0.0782508\tvalid_1's rmse: 0.0812898\n",
      "[1125]\ttraining's rmse: 0.0782338\tvalid_1's rmse: 0.0812855\n",
      "[1150]\ttraining's rmse: 0.0782155\tvalid_1's rmse: 0.0812817\n",
      "[1175]\ttraining's rmse: 0.0782022\tvalid_1's rmse: 0.0812786\n",
      "[1200]\ttraining's rmse: 0.0781858\tvalid_1's rmse: 0.081275\n",
      "[1225]\ttraining's rmse: 0.078172\tvalid_1's rmse: 0.0812716\n",
      "[1250]\ttraining's rmse: 0.0781593\tvalid_1's rmse: 0.0812685\n",
      "[1275]\ttraining's rmse: 0.0781435\tvalid_1's rmse: 0.0812661\n",
      "[1300]\ttraining's rmse: 0.0781318\tvalid_1's rmse: 0.0812635\n",
      "[1325]\ttraining's rmse: 0.07812\tvalid_1's rmse: 0.0812605\n",
      "[1350]\ttraining's rmse: 0.078107\tvalid_1's rmse: 0.0812588\n",
      "[1375]\ttraining's rmse: 0.0780952\tvalid_1's rmse: 0.0812568\n",
      "[1400]\ttraining's rmse: 0.0780853\tvalid_1's rmse: 0.0812541\n",
      "[1425]\ttraining's rmse: 0.0780749\tvalid_1's rmse: 0.0812523\n",
      "[1450]\ttraining's rmse: 0.0780629\tvalid_1's rmse: 0.081251\n",
      "[1475]\ttraining's rmse: 0.0780547\tvalid_1's rmse: 0.0812496\n",
      "[1500]\ttraining's rmse: 0.0780466\tvalid_1's rmse: 0.0812482\n",
      "[1525]\ttraining's rmse: 0.0780371\tvalid_1's rmse: 0.0812453\n",
      "[1550]\ttraining's rmse: 0.078028\tvalid_1's rmse: 0.081244\n",
      "[1575]\ttraining's rmse: 0.078019\tvalid_1's rmse: 0.0812423\n",
      "[1600]\ttraining's rmse: 0.078013\tvalid_1's rmse: 0.0812414\n",
      "[1625]\ttraining's rmse: 0.0780069\tvalid_1's rmse: 0.08124\n",
      "[1650]\ttraining's rmse: 0.0780007\tvalid_1's rmse: 0.0812388\n",
      "[1675]\ttraining's rmse: 0.0779934\tvalid_1's rmse: 0.0812378\n",
      "[1700]\ttraining's rmse: 0.0779885\tvalid_1's rmse: 0.0812363\n",
      "[1725]\ttraining's rmse: 0.0779837\tvalid_1's rmse: 0.0812344\n",
      "[1750]\ttraining's rmse: 0.0779774\tvalid_1's rmse: 0.0812333\n",
      "[1775]\ttraining's rmse: 0.0779727\tvalid_1's rmse: 0.0812325\n",
      "[1800]\ttraining's rmse: 0.0779678\tvalid_1's rmse: 0.0812318\n",
      "[1825]\ttraining's rmse: 0.0779633\tvalid_1's rmse: 0.0812311\n",
      "[1850]\ttraining's rmse: 0.0779583\tvalid_1's rmse: 0.0812301\n",
      "[1875]\ttraining's rmse: 0.0779553\tvalid_1's rmse: 0.0812299\n",
      "[1900]\ttraining's rmse: 0.077952\tvalid_1's rmse: 0.0812295\n",
      "[1925]\ttraining's rmse: 0.0779474\tvalid_1's rmse: 0.081229\n",
      "[1950]\ttraining's rmse: 0.0779439\tvalid_1's rmse: 0.0812281\n",
      "[1975]\ttraining's rmse: 0.0779407\tvalid_1's rmse: 0.0812274\n",
      "[2000]\ttraining's rmse: 0.077936\tvalid_1's rmse: 0.0812268\n",
      "[2025]\ttraining's rmse: 0.0779331\tvalid_1's rmse: 0.0812263\n",
      "[2050]\ttraining's rmse: 0.0779303\tvalid_1's rmse: 0.081226\n",
      "[2075]\ttraining's rmse: 0.0779266\tvalid_1's rmse: 0.0812252\n",
      "[2100]\ttraining's rmse: 0.0779225\tvalid_1's rmse: 0.0812247\n",
      "[2125]\ttraining's rmse: 0.0779196\tvalid_1's rmse: 0.0812245\n",
      "[2150]\ttraining's rmse: 0.0779169\tvalid_1's rmse: 0.0812245\n",
      "[2175]\ttraining's rmse: 0.0779121\tvalid_1's rmse: 0.0812241\n",
      "[2200]\ttraining's rmse: 0.0779094\tvalid_1's rmse: 0.0812238\n",
      "[2225]\ttraining's rmse: 0.077907\tvalid_1's rmse: 0.0812238\n",
      "[2250]\ttraining's rmse: 0.0779057\tvalid_1's rmse: 0.0812236\n",
      "[2275]\ttraining's rmse: 0.0779019\tvalid_1's rmse: 0.0812235\n",
      "[2300]\ttraining's rmse: 0.0778998\tvalid_1's rmse: 0.0812231\n",
      "[2325]\ttraining's rmse: 0.0778973\tvalid_1's rmse: 0.081223\n",
      "[2350]\ttraining's rmse: 0.0778949\tvalid_1's rmse: 0.0812228\n",
      "[2375]\ttraining's rmse: 0.0778924\tvalid_1's rmse: 0.0812223\n",
      "[2400]\ttraining's rmse: 0.0778907\tvalid_1's rmse: 0.081222\n",
      "[2425]\ttraining's rmse: 0.0778879\tvalid_1's rmse: 0.0812218\n",
      "[2450]\ttraining's rmse: 0.0778858\tvalid_1's rmse: 0.0812214\n",
      "[2475]\ttraining's rmse: 0.0778839\tvalid_1's rmse: 0.0812218\n",
      "[2500]\ttraining's rmse: 0.0778815\tvalid_1's rmse: 0.0812216\n",
      "Early stopping, best iteration is:\n",
      "[2451]\ttraining's rmse: 0.0778855\tvalid_1's rmse: 0.0812214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0821279\tvalid_1's rmse: 0.0784356\n",
      "[50]\ttraining's rmse: 0.0820212\tvalid_1's rmse: 0.0783884\n",
      "[75]\ttraining's rmse: 0.0819123\tvalid_1's rmse: 0.0783435\n",
      "[100]\ttraining's rmse: 0.081816\tvalid_1's rmse: 0.0783023\n",
      "[125]\ttraining's rmse: 0.0817189\tvalid_1's rmse: 0.0782686\n",
      "[150]\ttraining's rmse: 0.081627\tvalid_1's rmse: 0.0782325\n",
      "[175]\ttraining's rmse: 0.0815504\tvalid_1's rmse: 0.0782034\n",
      "[200]\ttraining's rmse: 0.0814683\tvalid_1's rmse: 0.0781714\n",
      "[225]\ttraining's rmse: 0.0813878\tvalid_1's rmse: 0.0781477\n",
      "[250]\ttraining's rmse: 0.0813217\tvalid_1's rmse: 0.0781229\n",
      "[275]\ttraining's rmse: 0.0812613\tvalid_1's rmse: 0.0780983\n",
      "[300]\ttraining's rmse: 0.0811993\tvalid_1's rmse: 0.0780767\n",
      "[325]\ttraining's rmse: 0.0811369\tvalid_1's rmse: 0.0780544\n",
      "[350]\ttraining's rmse: 0.0810754\tvalid_1's rmse: 0.0780346\n",
      "[375]\ttraining's rmse: 0.0810274\tvalid_1's rmse: 0.0780178\n",
      "[400]\ttraining's rmse: 0.08097\tvalid_1's rmse: 0.0780063\n",
      "[425]\ttraining's rmse: 0.0809216\tvalid_1's rmse: 0.0779952\n",
      "[450]\ttraining's rmse: 0.0808773\tvalid_1's rmse: 0.0779851\n",
      "[475]\ttraining's rmse: 0.0808341\tvalid_1's rmse: 0.0779719\n",
      "[500]\ttraining's rmse: 0.0807974\tvalid_1's rmse: 0.0779588\n",
      "[525]\ttraining's rmse: 0.0807494\tvalid_1's rmse: 0.0779528\n",
      "[550]\ttraining's rmse: 0.0807054\tvalid_1's rmse: 0.0779505\n",
      "[575]\ttraining's rmse: 0.0806663\tvalid_1's rmse: 0.0779459\n",
      "[600]\ttraining's rmse: 0.0806259\tvalid_1's rmse: 0.0779477\n",
      "[625]\ttraining's rmse: 0.0805944\tvalid_1's rmse: 0.077949\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's rmse: 0.0806363\tvalid_1's rmse: 0.0779425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0819863\tvalid_1's rmse: 0.0843013\n",
      "[50]\ttraining's rmse: 0.0818626\tvalid_1's rmse: 0.084252\n",
      "[75]\ttraining's rmse: 0.0817359\tvalid_1's rmse: 0.0842027\n",
      "[100]\ttraining's rmse: 0.0816222\tvalid_1's rmse: 0.0841605\n",
      "[125]\ttraining's rmse: 0.0815039\tvalid_1's rmse: 0.0841169\n",
      "[150]\ttraining's rmse: 0.0813976\tvalid_1's rmse: 0.0840752\n",
      "[175]\ttraining's rmse: 0.0813104\tvalid_1's rmse: 0.0840419\n",
      "[200]\ttraining's rmse: 0.0812155\tvalid_1's rmse: 0.0840075\n",
      "[225]\ttraining's rmse: 0.0811212\tvalid_1's rmse: 0.0839742\n",
      "[250]\ttraining's rmse: 0.0810397\tvalid_1's rmse: 0.0839444\n",
      "[275]\ttraining's rmse: 0.0809639\tvalid_1's rmse: 0.0839173\n",
      "[300]\ttraining's rmse: 0.0808926\tvalid_1's rmse: 0.0838911\n",
      "[325]\ttraining's rmse: 0.0808178\tvalid_1's rmse: 0.0838664\n",
      "[350]\ttraining's rmse: 0.0807515\tvalid_1's rmse: 0.083844\n",
      "[375]\ttraining's rmse: 0.0806936\tvalid_1's rmse: 0.0838256\n",
      "[400]\ttraining's rmse: 0.0806301\tvalid_1's rmse: 0.0838052\n",
      "[425]\ttraining's rmse: 0.0805701\tvalid_1's rmse: 0.083788\n",
      "[450]\ttraining's rmse: 0.080519\tvalid_1's rmse: 0.083769\n",
      "[475]\ttraining's rmse: 0.0804699\tvalid_1's rmse: 0.0837531\n",
      "[500]\ttraining's rmse: 0.0804283\tvalid_1's rmse: 0.083738\n",
      "[525]\ttraining's rmse: 0.0803748\tvalid_1's rmse: 0.0837234\n",
      "[550]\ttraining's rmse: 0.0803285\tvalid_1's rmse: 0.0837079\n",
      "[575]\ttraining's rmse: 0.0802851\tvalid_1's rmse: 0.0836944\n",
      "[600]\ttraining's rmse: 0.0802422\tvalid_1's rmse: 0.0836828\n",
      "[625]\ttraining's rmse: 0.0802052\tvalid_1's rmse: 0.0836718\n",
      "[650]\ttraining's rmse: 0.0801635\tvalid_1's rmse: 0.0836601\n",
      "[675]\ttraining's rmse: 0.0801236\tvalid_1's rmse: 0.0836491\n",
      "[700]\ttraining's rmse: 0.0800878\tvalid_1's rmse: 0.083639\n",
      "[725]\ttraining's rmse: 0.0800496\tvalid_1's rmse: 0.0836298\n",
      "[750]\ttraining's rmse: 0.0800164\tvalid_1's rmse: 0.0836218\n",
      "[775]\ttraining's rmse: 0.0799903\tvalid_1's rmse: 0.0836149\n",
      "[800]\ttraining's rmse: 0.0799566\tvalid_1's rmse: 0.0836069\n",
      "[825]\ttraining's rmse: 0.0799254\tvalid_1's rmse: 0.0835987\n",
      "[850]\ttraining's rmse: 0.0798952\tvalid_1's rmse: 0.0835925\n",
      "[875]\ttraining's rmse: 0.0798673\tvalid_1's rmse: 0.0835859\n",
      "[900]\ttraining's rmse: 0.0798373\tvalid_1's rmse: 0.0835795\n",
      "[925]\ttraining's rmse: 0.0798124\tvalid_1's rmse: 0.0835738\n",
      "[950]\ttraining's rmse: 0.0797883\tvalid_1's rmse: 0.0835688\n",
      "[975]\ttraining's rmse: 0.0797645\tvalid_1's rmse: 0.0835633\n",
      "[1000]\ttraining's rmse: 0.079744\tvalid_1's rmse: 0.0835591\n",
      "[1025]\ttraining's rmse: 0.0797209\tvalid_1's rmse: 0.083553\n",
      "[1050]\ttraining's rmse: 0.0797008\tvalid_1's rmse: 0.0835475\n",
      "[1075]\ttraining's rmse: 0.0796809\tvalid_1's rmse: 0.0835439\n",
      "[1100]\ttraining's rmse: 0.0796649\tvalid_1's rmse: 0.0835396\n",
      "[1125]\ttraining's rmse: 0.0796471\tvalid_1's rmse: 0.0835347\n",
      "[1150]\ttraining's rmse: 0.0796273\tvalid_1's rmse: 0.0835315\n",
      "[1175]\ttraining's rmse: 0.0796093\tvalid_1's rmse: 0.0835288\n",
      "[1200]\ttraining's rmse: 0.0795938\tvalid_1's rmse: 0.0835249\n",
      "[1225]\ttraining's rmse: 0.079579\tvalid_1's rmse: 0.0835208\n",
      "[1250]\ttraining's rmse: 0.079565\tvalid_1's rmse: 0.0835175\n",
      "[1275]\ttraining's rmse: 0.0795483\tvalid_1's rmse: 0.0835134\n",
      "[1300]\ttraining's rmse: 0.079536\tvalid_1's rmse: 0.0835099\n",
      "[1325]\ttraining's rmse: 0.0795213\tvalid_1's rmse: 0.0835058\n",
      "[1350]\ttraining's rmse: 0.0795086\tvalid_1's rmse: 0.0835023\n",
      "[1375]\ttraining's rmse: 0.0794963\tvalid_1's rmse: 0.0834997\n",
      "[1400]\ttraining's rmse: 0.0794841\tvalid_1's rmse: 0.0834966\n",
      "[1425]\ttraining's rmse: 0.0794728\tvalid_1's rmse: 0.0834939\n",
      "[1450]\ttraining's rmse: 0.0794599\tvalid_1's rmse: 0.0834929\n",
      "[1475]\ttraining's rmse: 0.0794496\tvalid_1's rmse: 0.0834904\n",
      "[1500]\ttraining's rmse: 0.079442\tvalid_1's rmse: 0.0834881\n",
      "[1525]\ttraining's rmse: 0.079432\tvalid_1's rmse: 0.0834852\n",
      "[1550]\ttraining's rmse: 0.0794219\tvalid_1's rmse: 0.0834839\n",
      "[1575]\ttraining's rmse: 0.0794125\tvalid_1's rmse: 0.0834809\n",
      "[1600]\ttraining's rmse: 0.0794072\tvalid_1's rmse: 0.0834794\n",
      "[1625]\ttraining's rmse: 0.0794007\tvalid_1's rmse: 0.0834775\n",
      "[1650]\ttraining's rmse: 0.0793926\tvalid_1's rmse: 0.0834744\n",
      "[1675]\ttraining's rmse: 0.0793867\tvalid_1's rmse: 0.0834735\n",
      "[1700]\ttraining's rmse: 0.079381\tvalid_1's rmse: 0.0834714\n",
      "[1725]\ttraining's rmse: 0.0793745\tvalid_1's rmse: 0.0834695\n",
      "[1750]\ttraining's rmse: 0.0793681\tvalid_1's rmse: 0.0834678\n",
      "[1775]\ttraining's rmse: 0.0793629\tvalid_1's rmse: 0.0834663\n",
      "[1800]\ttraining's rmse: 0.0793577\tvalid_1's rmse: 0.0834634\n",
      "[1825]\ttraining's rmse: 0.0793524\tvalid_1's rmse: 0.083463\n",
      "[1850]\ttraining's rmse: 0.0793481\tvalid_1's rmse: 0.0834621\n",
      "[1875]\ttraining's rmse: 0.079344\tvalid_1's rmse: 0.0834603\n",
      "[1900]\ttraining's rmse: 0.0793415\tvalid_1's rmse: 0.0834584\n",
      "[1925]\ttraining's rmse: 0.0793374\tvalid_1's rmse: 0.0834582\n",
      "[1950]\ttraining's rmse: 0.0793339\tvalid_1's rmse: 0.0834569\n",
      "[1975]\ttraining's rmse: 0.0793289\tvalid_1's rmse: 0.0834555\n",
      "[2000]\ttraining's rmse: 0.0793245\tvalid_1's rmse: 0.0834543\n",
      "[2025]\ttraining's rmse: 0.0793199\tvalid_1's rmse: 0.0834534\n",
      "[2050]\ttraining's rmse: 0.0793157\tvalid_1's rmse: 0.0834518\n",
      "[2075]\ttraining's rmse: 0.0793141\tvalid_1's rmse: 0.0834513\n",
      "[2100]\ttraining's rmse: 0.0793115\tvalid_1's rmse: 0.0834509\n",
      "[2125]\ttraining's rmse: 0.0793073\tvalid_1's rmse: 0.0834491\n",
      "[2150]\ttraining's rmse: 0.0793021\tvalid_1's rmse: 0.0834485\n",
      "[2175]\ttraining's rmse: 0.0792992\tvalid_1's rmse: 0.0834481\n",
      "[2200]\ttraining's rmse: 0.0792965\tvalid_1's rmse: 0.0834473\n",
      "[2225]\ttraining's rmse: 0.0792934\tvalid_1's rmse: 0.083446\n",
      "[2250]\ttraining's rmse: 0.0792904\tvalid_1's rmse: 0.083445\n",
      "[2275]\ttraining's rmse: 0.0792885\tvalid_1's rmse: 0.0834447\n",
      "[2300]\ttraining's rmse: 0.0792862\tvalid_1's rmse: 0.0834433\n",
      "[2325]\ttraining's rmse: 0.0792833\tvalid_1's rmse: 0.0834416\n",
      "[2350]\ttraining's rmse: 0.079281\tvalid_1's rmse: 0.0834409\n",
      "[2375]\ttraining's rmse: 0.0792793\tvalid_1's rmse: 0.0834398\n",
      "[2400]\ttraining's rmse: 0.0792767\tvalid_1's rmse: 0.0834396\n",
      "[2425]\ttraining's rmse: 0.079275\tvalid_1's rmse: 0.0834391\n",
      "[2450]\ttraining's rmse: 0.0792721\tvalid_1's rmse: 0.0834388\n",
      "[2475]\ttraining's rmse: 0.0792693\tvalid_1's rmse: 0.0834383\n",
      "[2500]\ttraining's rmse: 0.0792675\tvalid_1's rmse: 0.083438\n",
      "[2525]\ttraining's rmse: 0.0792641\tvalid_1's rmse: 0.0834382\n",
      "Early stopping, best iteration is:\n",
      "[2497]\ttraining's rmse: 0.0792676\tvalid_1's rmse: 0.0834379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.082221\tvalid_1's rmse: 0.0838697\n",
      "[50]\ttraining's rmse: 0.0821095\tvalid_1's rmse: 0.0838177\n",
      "[75]\ttraining's rmse: 0.0819942\tvalid_1's rmse: 0.0837674\n",
      "[100]\ttraining's rmse: 0.0818929\tvalid_1's rmse: 0.0837228\n",
      "[125]\ttraining's rmse: 0.0817856\tvalid_1's rmse: 0.0836766\n",
      "[150]\ttraining's rmse: 0.0816883\tvalid_1's rmse: 0.0836348\n",
      "[175]\ttraining's rmse: 0.0816098\tvalid_1's rmse: 0.0835998\n",
      "[200]\ttraining's rmse: 0.0815199\tvalid_1's rmse: 0.0835627\n",
      "[225]\ttraining's rmse: 0.0814346\tvalid_1's rmse: 0.0835288\n",
      "[250]\ttraining's rmse: 0.0813597\tvalid_1's rmse: 0.0834975\n",
      "[275]\ttraining's rmse: 0.0812921\tvalid_1's rmse: 0.0834707\n",
      "[300]\ttraining's rmse: 0.081224\tvalid_1's rmse: 0.0834437\n",
      "[325]\ttraining's rmse: 0.0811562\tvalid_1's rmse: 0.0834177\n",
      "[350]\ttraining's rmse: 0.0810938\tvalid_1's rmse: 0.0833935\n",
      "[375]\ttraining's rmse: 0.0810411\tvalid_1's rmse: 0.0833734\n",
      "[400]\ttraining's rmse: 0.0809836\tvalid_1's rmse: 0.083354\n",
      "[425]\ttraining's rmse: 0.080929\tvalid_1's rmse: 0.0833339\n",
      "[450]\ttraining's rmse: 0.0808782\tvalid_1's rmse: 0.0833156\n",
      "[475]\ttraining's rmse: 0.0808311\tvalid_1's rmse: 0.0832987\n",
      "[500]\ttraining's rmse: 0.0807899\tvalid_1's rmse: 0.0832815\n",
      "[525]\ttraining's rmse: 0.0807389\tvalid_1's rmse: 0.0832644\n",
      "[550]\ttraining's rmse: 0.0806923\tvalid_1's rmse: 0.08325\n",
      "[575]\ttraining's rmse: 0.0806491\tvalid_1's rmse: 0.0832363\n",
      "[600]\ttraining's rmse: 0.0806082\tvalid_1's rmse: 0.0832231\n",
      "[625]\ttraining's rmse: 0.0805757\tvalid_1's rmse: 0.0832114\n",
      "[650]\ttraining's rmse: 0.080536\tvalid_1's rmse: 0.0831995\n",
      "[675]\ttraining's rmse: 0.0804968\tvalid_1's rmse: 0.0831887\n",
      "[700]\ttraining's rmse: 0.0804612\tvalid_1's rmse: 0.0831777\n",
      "[725]\ttraining's rmse: 0.080429\tvalid_1's rmse: 0.0831681\n",
      "[750]\ttraining's rmse: 0.0803987\tvalid_1's rmse: 0.0831585\n",
      "[775]\ttraining's rmse: 0.0803719\tvalid_1's rmse: 0.0831494\n",
      "[800]\ttraining's rmse: 0.0803378\tvalid_1's rmse: 0.0831404\n",
      "[825]\ttraining's rmse: 0.0803091\tvalid_1's rmse: 0.0831313\n",
      "[850]\ttraining's rmse: 0.0802797\tvalid_1's rmse: 0.0831245\n",
      "[875]\ttraining's rmse: 0.0802537\tvalid_1's rmse: 0.083118\n",
      "[900]\ttraining's rmse: 0.0802263\tvalid_1's rmse: 0.0831103\n",
      "[925]\ttraining's rmse: 0.0802006\tvalid_1's rmse: 0.0831035\n",
      "[950]\ttraining's rmse: 0.0801773\tvalid_1's rmse: 0.0830975\n",
      "[975]\ttraining's rmse: 0.0801548\tvalid_1's rmse: 0.0830915\n",
      "[1000]\ttraining's rmse: 0.0801334\tvalid_1's rmse: 0.0830855\n",
      "[1025]\ttraining's rmse: 0.0801097\tvalid_1's rmse: 0.0830807\n",
      "[1050]\ttraining's rmse: 0.0800908\tvalid_1's rmse: 0.0830765\n",
      "[1075]\ttraining's rmse: 0.0800709\tvalid_1's rmse: 0.0830718\n",
      "[1100]\ttraining's rmse: 0.0800554\tvalid_1's rmse: 0.0830668\n",
      "[1125]\ttraining's rmse: 0.0800378\tvalid_1's rmse: 0.0830627\n",
      "[1150]\ttraining's rmse: 0.0800188\tvalid_1's rmse: 0.0830589\n",
      "[1175]\ttraining's rmse: 0.0800033\tvalid_1's rmse: 0.0830554\n",
      "[1200]\ttraining's rmse: 0.079987\tvalid_1's rmse: 0.0830517\n",
      "[1225]\ttraining's rmse: 0.0799721\tvalid_1's rmse: 0.0830478\n",
      "[1250]\ttraining's rmse: 0.0799571\tvalid_1's rmse: 0.0830447\n",
      "[1275]\ttraining's rmse: 0.0799388\tvalid_1's rmse: 0.0830427\n",
      "[1300]\ttraining's rmse: 0.0799251\tvalid_1's rmse: 0.0830387\n",
      "[1325]\ttraining's rmse: 0.0799113\tvalid_1's rmse: 0.0830361\n",
      "[1350]\ttraining's rmse: 0.0798998\tvalid_1's rmse: 0.083034\n",
      "[1375]\ttraining's rmse: 0.0798861\tvalid_1's rmse: 0.083032\n",
      "[1400]\ttraining's rmse: 0.0798768\tvalid_1's rmse: 0.0830296\n",
      "[1425]\ttraining's rmse: 0.0798641\tvalid_1's rmse: 0.0830275\n",
      "[1450]\ttraining's rmse: 0.0798547\tvalid_1's rmse: 0.0830258\n",
      "[1475]\ttraining's rmse: 0.0798464\tvalid_1's rmse: 0.083024\n",
      "[1500]\ttraining's rmse: 0.0798379\tvalid_1's rmse: 0.0830222\n",
      "[1525]\ttraining's rmse: 0.0798275\tvalid_1's rmse: 0.0830207\n",
      "[1550]\ttraining's rmse: 0.0798192\tvalid_1's rmse: 0.0830194\n",
      "[1575]\ttraining's rmse: 0.0798113\tvalid_1's rmse: 0.0830175\n",
      "[1600]\ttraining's rmse: 0.0798045\tvalid_1's rmse: 0.0830168\n",
      "[1625]\ttraining's rmse: 0.0797965\tvalid_1's rmse: 0.0830151\n",
      "[1650]\ttraining's rmse: 0.0797895\tvalid_1's rmse: 0.0830145\n",
      "[1675]\ttraining's rmse: 0.0797831\tvalid_1's rmse: 0.083013\n",
      "[1700]\ttraining's rmse: 0.0797772\tvalid_1's rmse: 0.0830117\n",
      "[1725]\ttraining's rmse: 0.0797715\tvalid_1's rmse: 0.0830106\n",
      "[1750]\ttraining's rmse: 0.079766\tvalid_1's rmse: 0.08301\n",
      "[1775]\ttraining's rmse: 0.0797606\tvalid_1's rmse: 0.0830093\n",
      "[1800]\ttraining's rmse: 0.0797538\tvalid_1's rmse: 0.083008\n",
      "[1825]\ttraining's rmse: 0.0797498\tvalid_1's rmse: 0.0830074\n",
      "[1850]\ttraining's rmse: 0.0797436\tvalid_1's rmse: 0.0830058\n",
      "[1875]\ttraining's rmse: 0.0797387\tvalid_1's rmse: 0.0830051\n",
      "[1900]\ttraining's rmse: 0.0797345\tvalid_1's rmse: 0.0830048\n",
      "[1925]\ttraining's rmse: 0.0797301\tvalid_1's rmse: 0.0830046\n",
      "[1950]\ttraining's rmse: 0.079727\tvalid_1's rmse: 0.0830038\n",
      "[1975]\ttraining's rmse: 0.0797234\tvalid_1's rmse: 0.0830032\n",
      "[2000]\ttraining's rmse: 0.0797189\tvalid_1's rmse: 0.0830024\n",
      "[2025]\ttraining's rmse: 0.0797153\tvalid_1's rmse: 0.0830016\n",
      "[2050]\ttraining's rmse: 0.0797102\tvalid_1's rmse: 0.0830011\n",
      "[2075]\ttraining's rmse: 0.0797064\tvalid_1's rmse: 0.0830009\n",
      "[2100]\ttraining's rmse: 0.0797022\tvalid_1's rmse: 0.0830002\n",
      "[2125]\ttraining's rmse: 0.0796991\tvalid_1's rmse: 0.0829999\n",
      "[2150]\ttraining's rmse: 0.079696\tvalid_1's rmse: 0.0829998\n",
      "[2175]\ttraining's rmse: 0.0796927\tvalid_1's rmse: 0.0829994\n",
      "[2200]\ttraining's rmse: 0.0796902\tvalid_1's rmse: 0.0829987\n",
      "[2225]\ttraining's rmse: 0.0796886\tvalid_1's rmse: 0.0829986\n",
      "[2250]\ttraining's rmse: 0.079686\tvalid_1's rmse: 0.0829984\n",
      "[2275]\ttraining's rmse: 0.079683\tvalid_1's rmse: 0.0829981\n",
      "[2300]\ttraining's rmse: 0.0796801\tvalid_1's rmse: 0.0829976\n",
      "[2325]\ttraining's rmse: 0.0796777\tvalid_1's rmse: 0.0829973\n",
      "[2350]\ttraining's rmse: 0.0796756\tvalid_1's rmse: 0.0829971\n",
      "[2375]\ttraining's rmse: 0.0796732\tvalid_1's rmse: 0.0829969\n",
      "[2400]\ttraining's rmse: 0.0796709\tvalid_1's rmse: 0.082997\n",
      "[2425]\ttraining's rmse: 0.079668\tvalid_1's rmse: 0.0829968\n",
      "[2450]\ttraining's rmse: 0.0796658\tvalid_1's rmse: 0.0829968\n",
      "[2475]\ttraining's rmse: 0.0796643\tvalid_1's rmse: 0.0829969\n",
      "[2500]\ttraining's rmse: 0.0796619\tvalid_1's rmse: 0.0829971\n",
      "Early stopping, best iteration is:\n",
      "[2458]\ttraining's rmse: 0.0796651\tvalid_1's rmse: 0.0829965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0839626\tvalid_1's rmse: 0.0803148\n",
      "[50]\ttraining's rmse: 0.0838553\tvalid_1's rmse: 0.0802686\n",
      "[75]\ttraining's rmse: 0.0837429\tvalid_1's rmse: 0.080222\n",
      "[100]\ttraining's rmse: 0.0836433\tvalid_1's rmse: 0.0801801\n",
      "[125]\ttraining's rmse: 0.0835392\tvalid_1's rmse: 0.0801408\n",
      "[150]\ttraining's rmse: 0.0834441\tvalid_1's rmse: 0.0801044\n",
      "[175]\ttraining's rmse: 0.083366\tvalid_1's rmse: 0.0800735\n",
      "[200]\ttraining's rmse: 0.0832789\tvalid_1's rmse: 0.0800427\n",
      "[225]\ttraining's rmse: 0.0831941\tvalid_1's rmse: 0.0800134\n",
      "[250]\ttraining's rmse: 0.0831247\tvalid_1's rmse: 0.0799877\n",
      "[275]\ttraining's rmse: 0.0830583\tvalid_1's rmse: 0.0799636\n",
      "[300]\ttraining's rmse: 0.0829923\tvalid_1's rmse: 0.0799403\n",
      "[325]\ttraining's rmse: 0.0829262\tvalid_1's rmse: 0.0799185\n",
      "[350]\ttraining's rmse: 0.0828626\tvalid_1's rmse: 0.0798981\n",
      "[375]\ttraining's rmse: 0.0828077\tvalid_1's rmse: 0.0798828\n",
      "[400]\ttraining's rmse: 0.0827512\tvalid_1's rmse: 0.0798711\n",
      "[425]\ttraining's rmse: 0.0826991\tvalid_1's rmse: 0.0798599\n",
      "[450]\ttraining's rmse: 0.0826508\tvalid_1's rmse: 0.0798476\n",
      "[475]\ttraining's rmse: 0.0826072\tvalid_1's rmse: 0.0798381\n",
      "[500]\ttraining's rmse: 0.0825691\tvalid_1's rmse: 0.0798253\n",
      "[525]\ttraining's rmse: 0.0825194\tvalid_1's rmse: 0.0798157\n",
      "[550]\ttraining's rmse: 0.0824753\tvalid_1's rmse: 0.0798034\n",
      "[575]\ttraining's rmse: 0.0824337\tvalid_1's rmse: 0.0797933\n",
      "[600]\ttraining's rmse: 0.0823902\tvalid_1's rmse: 0.0797829\n",
      "[625]\ttraining's rmse: 0.0823568\tvalid_1's rmse: 0.079783\n",
      "[650]\ttraining's rmse: 0.0823145\tvalid_1's rmse: 0.0797823\n",
      "[675]\ttraining's rmse: 0.0822729\tvalid_1's rmse: 0.0797739\n",
      "[700]\ttraining's rmse: 0.082236\tvalid_1's rmse: 0.0797648\n",
      "[725]\ttraining's rmse: 0.0822016\tvalid_1's rmse: 0.0797659\n",
      "[750]\ttraining's rmse: 0.0821703\tvalid_1's rmse: 0.0797729\n",
      "[775]\ttraining's rmse: 0.082145\tvalid_1's rmse: 0.0797675\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0821877\tvalid_1's rmse: 0.0797622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0808161\tvalid_1's rmse: 0.0831244\n",
      "[50]\ttraining's rmse: 0.0806911\tvalid_1's rmse: 0.0830725\n",
      "[75]\ttraining's rmse: 0.08057\tvalid_1's rmse: 0.0830218\n",
      "[100]\ttraining's rmse: 0.0804579\tvalid_1's rmse: 0.0829793\n",
      "[125]\ttraining's rmse: 0.0803443\tvalid_1's rmse: 0.0829344\n",
      "[150]\ttraining's rmse: 0.0802411\tvalid_1's rmse: 0.0828943\n",
      "[175]\ttraining's rmse: 0.0801564\tvalid_1's rmse: 0.0828609\n",
      "[200]\ttraining's rmse: 0.0800644\tvalid_1's rmse: 0.0828246\n",
      "[225]\ttraining's rmse: 0.0799735\tvalid_1's rmse: 0.0827901\n",
      "[250]\ttraining's rmse: 0.079898\tvalid_1's rmse: 0.0827586\n",
      "[275]\ttraining's rmse: 0.079828\tvalid_1's rmse: 0.0827305\n",
      "[300]\ttraining's rmse: 0.0797583\tvalid_1's rmse: 0.082704\n",
      "[325]\ttraining's rmse: 0.079686\tvalid_1's rmse: 0.0826779\n",
      "[350]\ttraining's rmse: 0.0796195\tvalid_1's rmse: 0.0826551\n",
      "[375]\ttraining's rmse: 0.0795645\tvalid_1's rmse: 0.0826333\n",
      "[400]\ttraining's rmse: 0.0795032\tvalid_1's rmse: 0.0826126\n",
      "[425]\ttraining's rmse: 0.0794484\tvalid_1's rmse: 0.0825938\n",
      "[450]\ttraining's rmse: 0.0793975\tvalid_1's rmse: 0.0825748\n",
      "[475]\ttraining's rmse: 0.0793527\tvalid_1's rmse: 0.0825571\n",
      "[500]\ttraining's rmse: 0.0793104\tvalid_1's rmse: 0.0825421\n",
      "[525]\ttraining's rmse: 0.0792592\tvalid_1's rmse: 0.0825265\n",
      "[550]\ttraining's rmse: 0.0792119\tvalid_1's rmse: 0.0825108\n",
      "[575]\ttraining's rmse: 0.07917\tvalid_1's rmse: 0.0824977\n",
      "[600]\ttraining's rmse: 0.0791291\tvalid_1's rmse: 0.0824846\n",
      "[625]\ttraining's rmse: 0.0790964\tvalid_1's rmse: 0.0824726\n",
      "[650]\ttraining's rmse: 0.0790582\tvalid_1's rmse: 0.0824615\n",
      "[675]\ttraining's rmse: 0.0790179\tvalid_1's rmse: 0.0824497\n",
      "[700]\ttraining's rmse: 0.0789804\tvalid_1's rmse: 0.0824392\n",
      "[725]\ttraining's rmse: 0.0789484\tvalid_1's rmse: 0.0824302\n",
      "[750]\ttraining's rmse: 0.0789178\tvalid_1's rmse: 0.08242\n",
      "[775]\ttraining's rmse: 0.0788916\tvalid_1's rmse: 0.08241\n",
      "[800]\ttraining's rmse: 0.0788601\tvalid_1's rmse: 0.0824022\n",
      "[825]\ttraining's rmse: 0.0788358\tvalid_1's rmse: 0.0823941\n",
      "[850]\ttraining's rmse: 0.0788077\tvalid_1's rmse: 0.0823881\n",
      "[875]\ttraining's rmse: 0.0787815\tvalid_1's rmse: 0.0823799\n",
      "[900]\ttraining's rmse: 0.0787536\tvalid_1's rmse: 0.0823739\n",
      "[925]\ttraining's rmse: 0.07873\tvalid_1's rmse: 0.0823657\n",
      "[950]\ttraining's rmse: 0.0787073\tvalid_1's rmse: 0.0823609\n",
      "[975]\ttraining's rmse: 0.0786854\tvalid_1's rmse: 0.082355\n",
      "[1000]\ttraining's rmse: 0.0786617\tvalid_1's rmse: 0.08235\n",
      "[1025]\ttraining's rmse: 0.078638\tvalid_1's rmse: 0.0823446\n",
      "[1050]\ttraining's rmse: 0.0786185\tvalid_1's rmse: 0.0823401\n",
      "[1075]\ttraining's rmse: 0.0786004\tvalid_1's rmse: 0.082335\n",
      "[1100]\ttraining's rmse: 0.0785841\tvalid_1's rmse: 0.0823306\n",
      "[1125]\ttraining's rmse: 0.0785689\tvalid_1's rmse: 0.0823264\n",
      "[1150]\ttraining's rmse: 0.0785521\tvalid_1's rmse: 0.082323\n",
      "[1175]\ttraining's rmse: 0.0785342\tvalid_1's rmse: 0.0823198\n",
      "[1200]\ttraining's rmse: 0.0785187\tvalid_1's rmse: 0.0823139\n",
      "[1225]\ttraining's rmse: 0.0785032\tvalid_1's rmse: 0.0823092\n",
      "[1250]\ttraining's rmse: 0.0784901\tvalid_1's rmse: 0.0823049\n",
      "[1275]\ttraining's rmse: 0.0784755\tvalid_1's rmse: 0.0823013\n",
      "[1300]\ttraining's rmse: 0.078463\tvalid_1's rmse: 0.0822972\n",
      "[1325]\ttraining's rmse: 0.0784525\tvalid_1's rmse: 0.0822943\n",
      "[1350]\ttraining's rmse: 0.0784395\tvalid_1's rmse: 0.082292\n",
      "[1375]\ttraining's rmse: 0.0784259\tvalid_1's rmse: 0.0822882\n",
      "[1400]\ttraining's rmse: 0.0784154\tvalid_1's rmse: 0.0822856\n",
      "[1425]\ttraining's rmse: 0.0784034\tvalid_1's rmse: 0.0822834\n",
      "[1450]\ttraining's rmse: 0.0783926\tvalid_1's rmse: 0.0822808\n",
      "[1475]\ttraining's rmse: 0.0783834\tvalid_1's rmse: 0.0822778\n",
      "[1500]\ttraining's rmse: 0.0783748\tvalid_1's rmse: 0.0822755\n",
      "[1525]\ttraining's rmse: 0.078368\tvalid_1's rmse: 0.0822725\n",
      "[1550]\ttraining's rmse: 0.0783596\tvalid_1's rmse: 0.0822689\n",
      "[1575]\ttraining's rmse: 0.078353\tvalid_1's rmse: 0.0822669\n",
      "[1600]\ttraining's rmse: 0.078344\tvalid_1's rmse: 0.0822649\n",
      "[1625]\ttraining's rmse: 0.0783366\tvalid_1's rmse: 0.0822626\n",
      "[1650]\ttraining's rmse: 0.0783295\tvalid_1's rmse: 0.0822607\n",
      "[1675]\ttraining's rmse: 0.0783232\tvalid_1's rmse: 0.0822582\n",
      "[1700]\ttraining's rmse: 0.0783169\tvalid_1's rmse: 0.0822564\n",
      "[1725]\ttraining's rmse: 0.0783107\tvalid_1's rmse: 0.082255\n",
      "[1750]\ttraining's rmse: 0.0783046\tvalid_1's rmse: 0.0822551\n",
      "[1775]\ttraining's rmse: 0.0782978\tvalid_1's rmse: 0.0822534\n",
      "[1800]\ttraining's rmse: 0.0782934\tvalid_1's rmse: 0.0822514\n",
      "[1825]\ttraining's rmse: 0.0782884\tvalid_1's rmse: 0.0822496\n",
      "[1850]\ttraining's rmse: 0.0782829\tvalid_1's rmse: 0.0822476\n",
      "[1875]\ttraining's rmse: 0.0782783\tvalid_1's rmse: 0.0822455\n",
      "[1900]\ttraining's rmse: 0.078274\tvalid_1's rmse: 0.0822444\n",
      "[1925]\ttraining's rmse: 0.0782713\tvalid_1's rmse: 0.0822433\n",
      "[1950]\ttraining's rmse: 0.0782687\tvalid_1's rmse: 0.0822426\n",
      "[1975]\ttraining's rmse: 0.0782648\tvalid_1's rmse: 0.0822416\n",
      "[2000]\ttraining's rmse: 0.07826\tvalid_1's rmse: 0.0822405\n",
      "[2025]\ttraining's rmse: 0.0782558\tvalid_1's rmse: 0.0822393\n",
      "[2050]\ttraining's rmse: 0.0782515\tvalid_1's rmse: 0.0822376\n",
      "[2075]\ttraining's rmse: 0.0782485\tvalid_1's rmse: 0.0822367\n",
      "[2100]\ttraining's rmse: 0.0782463\tvalid_1's rmse: 0.0822359\n",
      "[2125]\ttraining's rmse: 0.0782419\tvalid_1's rmse: 0.0822355\n",
      "[2150]\ttraining's rmse: 0.078238\tvalid_1's rmse: 0.082235\n",
      "[2175]\ttraining's rmse: 0.0782361\tvalid_1's rmse: 0.0822349\n",
      "[2200]\ttraining's rmse: 0.0782338\tvalid_1's rmse: 0.0822337\n",
      "[2225]\ttraining's rmse: 0.0782314\tvalid_1's rmse: 0.0822332\n",
      "[2250]\ttraining's rmse: 0.0782288\tvalid_1's rmse: 0.0822319\n",
      "[2275]\ttraining's rmse: 0.0782268\tvalid_1's rmse: 0.0822312\n",
      "[2300]\ttraining's rmse: 0.0782242\tvalid_1's rmse: 0.0822311\n",
      "[2325]\ttraining's rmse: 0.0782214\tvalid_1's rmse: 0.0822307\n",
      "[2350]\ttraining's rmse: 0.0782189\tvalid_1's rmse: 0.0822302\n",
      "[2375]\ttraining's rmse: 0.0782165\tvalid_1's rmse: 0.0822291\n",
      "[2400]\ttraining's rmse: 0.0782136\tvalid_1's rmse: 0.0822284\n",
      "[2425]\ttraining's rmse: 0.0782107\tvalid_1's rmse: 0.0822273\n",
      "[2450]\ttraining's rmse: 0.0782091\tvalid_1's rmse: 0.0822272\n",
      "[2475]\ttraining's rmse: 0.078206\tvalid_1's rmse: 0.0822275\n",
      "Early stopping, best iteration is:\n",
      "[2430]\ttraining's rmse: 0.0782104\tvalid_1's rmse: 0.0822271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0809484\tvalid_1's rmse: 0.0828745\n",
      "[50]\ttraining's rmse: 0.0808369\tvalid_1's rmse: 0.0828208\n",
      "[75]\ttraining's rmse: 0.0807251\tvalid_1's rmse: 0.0827701\n",
      "[100]\ttraining's rmse: 0.0806266\tvalid_1's rmse: 0.0827239\n",
      "[125]\ttraining's rmse: 0.0805212\tvalid_1's rmse: 0.082678\n",
      "[150]\ttraining's rmse: 0.0804262\tvalid_1's rmse: 0.0826359\n",
      "[175]\ttraining's rmse: 0.0803474\tvalid_1's rmse: 0.0826025\n",
      "[200]\ttraining's rmse: 0.0802609\tvalid_1's rmse: 0.0825674\n",
      "[225]\ttraining's rmse: 0.0801758\tvalid_1's rmse: 0.0825339\n",
      "[250]\ttraining's rmse: 0.0801025\tvalid_1's rmse: 0.0825038\n",
      "[275]\ttraining's rmse: 0.0800375\tvalid_1's rmse: 0.0824758\n",
      "[300]\ttraining's rmse: 0.0799713\tvalid_1's rmse: 0.0824494\n",
      "[325]\ttraining's rmse: 0.0799061\tvalid_1's rmse: 0.0824241\n",
      "[350]\ttraining's rmse: 0.0798432\tvalid_1's rmse: 0.082401\n",
      "[375]\ttraining's rmse: 0.0797903\tvalid_1's rmse: 0.0823806\n",
      "[400]\ttraining's rmse: 0.079731\tvalid_1's rmse: 0.0823602\n",
      "[425]\ttraining's rmse: 0.0796798\tvalid_1's rmse: 0.0823409\n",
      "[450]\ttraining's rmse: 0.0796316\tvalid_1's rmse: 0.0823226\n",
      "[475]\ttraining's rmse: 0.0795862\tvalid_1's rmse: 0.0823063\n",
      "[500]\ttraining's rmse: 0.0795464\tvalid_1's rmse: 0.0822905\n",
      "[525]\ttraining's rmse: 0.0794977\tvalid_1's rmse: 0.082275\n",
      "[550]\ttraining's rmse: 0.0794516\tvalid_1's rmse: 0.0822612\n",
      "[575]\ttraining's rmse: 0.0794086\tvalid_1's rmse: 0.0822467\n",
      "[600]\ttraining's rmse: 0.0793682\tvalid_1's rmse: 0.0822332\n",
      "[625]\ttraining's rmse: 0.0793366\tvalid_1's rmse: 0.0822215\n",
      "[650]\ttraining's rmse: 0.0792971\tvalid_1's rmse: 0.08221\n",
      "[675]\ttraining's rmse: 0.0792577\tvalid_1's rmse: 0.0822001\n",
      "[700]\ttraining's rmse: 0.0792231\tvalid_1's rmse: 0.0821899\n",
      "[725]\ttraining's rmse: 0.0791917\tvalid_1's rmse: 0.0821802\n",
      "[750]\ttraining's rmse: 0.0791612\tvalid_1's rmse: 0.0821714\n",
      "[775]\ttraining's rmse: 0.079136\tvalid_1's rmse: 0.0821626\n",
      "[800]\ttraining's rmse: 0.0791046\tvalid_1's rmse: 0.0821549\n",
      "[825]\ttraining's rmse: 0.0790791\tvalid_1's rmse: 0.0821473\n",
      "[850]\ttraining's rmse: 0.0790526\tvalid_1's rmse: 0.0821413\n",
      "[875]\ttraining's rmse: 0.0790294\tvalid_1's rmse: 0.0821346\n",
      "[900]\ttraining's rmse: 0.079\tvalid_1's rmse: 0.0821274\n",
      "[925]\ttraining's rmse: 0.0789747\tvalid_1's rmse: 0.0821212\n",
      "[950]\ttraining's rmse: 0.078951\tvalid_1's rmse: 0.0821158\n",
      "[975]\ttraining's rmse: 0.0789286\tvalid_1's rmse: 0.0821098\n",
      "[1000]\ttraining's rmse: 0.0789093\tvalid_1's rmse: 0.082104\n",
      "[1025]\ttraining's rmse: 0.0788874\tvalid_1's rmse: 0.0820991\n",
      "[1050]\ttraining's rmse: 0.0788691\tvalid_1's rmse: 0.0820949\n",
      "[1075]\ttraining's rmse: 0.0788474\tvalid_1's rmse: 0.0820912\n",
      "[1100]\ttraining's rmse: 0.0788329\tvalid_1's rmse: 0.0820868\n",
      "[1125]\ttraining's rmse: 0.0788171\tvalid_1's rmse: 0.0820833\n",
      "[1150]\ttraining's rmse: 0.0788014\tvalid_1's rmse: 0.0820804\n",
      "[1175]\ttraining's rmse: 0.0787839\tvalid_1's rmse: 0.0820767\n",
      "[1200]\ttraining's rmse: 0.0787691\tvalid_1's rmse: 0.0820731\n",
      "[1225]\ttraining's rmse: 0.0787541\tvalid_1's rmse: 0.08207\n",
      "[1250]\ttraining's rmse: 0.0787403\tvalid_1's rmse: 0.0820679\n",
      "[1275]\ttraining's rmse: 0.0787256\tvalid_1's rmse: 0.082066\n",
      "[1300]\ttraining's rmse: 0.0787142\tvalid_1's rmse: 0.0820634\n",
      "[1325]\ttraining's rmse: 0.0787025\tvalid_1's rmse: 0.0820612\n",
      "[1350]\ttraining's rmse: 0.0786894\tvalid_1's rmse: 0.0820597\n",
      "[1375]\ttraining's rmse: 0.0786789\tvalid_1's rmse: 0.0820572\n",
      "[1400]\ttraining's rmse: 0.0786697\tvalid_1's rmse: 0.0820549\n",
      "[1425]\ttraining's rmse: 0.0786596\tvalid_1's rmse: 0.0820532\n",
      "[1450]\ttraining's rmse: 0.0786464\tvalid_1's rmse: 0.0820514\n",
      "[1475]\ttraining's rmse: 0.0786347\tvalid_1's rmse: 0.0820492\n",
      "[1500]\ttraining's rmse: 0.0786265\tvalid_1's rmse: 0.082048\n",
      "[1525]\ttraining's rmse: 0.0786177\tvalid_1's rmse: 0.0820463\n",
      "[1550]\ttraining's rmse: 0.0786104\tvalid_1's rmse: 0.0820453\n",
      "[1575]\ttraining's rmse: 0.0786016\tvalid_1's rmse: 0.0820434\n",
      "[1600]\ttraining's rmse: 0.0785953\tvalid_1's rmse: 0.0820425\n",
      "[1625]\ttraining's rmse: 0.0785867\tvalid_1's rmse: 0.0820411\n",
      "[1650]\ttraining's rmse: 0.0785777\tvalid_1's rmse: 0.0820398\n",
      "[1675]\ttraining's rmse: 0.0785735\tvalid_1's rmse: 0.0820387\n",
      "[1700]\ttraining's rmse: 0.0785674\tvalid_1's rmse: 0.0820373\n",
      "[1725]\ttraining's rmse: 0.0785624\tvalid_1's rmse: 0.0820365\n",
      "[1750]\ttraining's rmse: 0.0785556\tvalid_1's rmse: 0.0820356\n",
      "[1775]\ttraining's rmse: 0.07855\tvalid_1's rmse: 0.0820349\n",
      "[1800]\ttraining's rmse: 0.0785451\tvalid_1's rmse: 0.0820342\n",
      "[1825]\ttraining's rmse: 0.0785391\tvalid_1's rmse: 0.0820332\n",
      "[1850]\ttraining's rmse: 0.0785345\tvalid_1's rmse: 0.082032\n",
      "[1875]\ttraining's rmse: 0.0785291\tvalid_1's rmse: 0.0820311\n",
      "[1900]\ttraining's rmse: 0.078526\tvalid_1's rmse: 0.0820306\n",
      "[1925]\ttraining's rmse: 0.0785218\tvalid_1's rmse: 0.0820297\n",
      "[1950]\ttraining's rmse: 0.078517\tvalid_1's rmse: 0.0820287\n",
      "[1975]\ttraining's rmse: 0.0785134\tvalid_1's rmse: 0.0820279\n",
      "[2000]\ttraining's rmse: 0.0785089\tvalid_1's rmse: 0.0820272\n",
      "[2025]\ttraining's rmse: 0.0785057\tvalid_1's rmse: 0.0820269\n",
      "[2050]\ttraining's rmse: 0.0785012\tvalid_1's rmse: 0.0820261\n",
      "[2075]\ttraining's rmse: 0.0784976\tvalid_1's rmse: 0.0820255\n",
      "[2100]\ttraining's rmse: 0.0784951\tvalid_1's rmse: 0.0820252\n",
      "[2125]\ttraining's rmse: 0.0784905\tvalid_1's rmse: 0.082025\n",
      "[2150]\ttraining's rmse: 0.0784869\tvalid_1's rmse: 0.0820248\n",
      "[2175]\ttraining's rmse: 0.0784847\tvalid_1's rmse: 0.0820247\n",
      "[2200]\ttraining's rmse: 0.0784814\tvalid_1's rmse: 0.0820242\n",
      "[2225]\ttraining's rmse: 0.0784777\tvalid_1's rmse: 0.0820238\n",
      "[2250]\ttraining's rmse: 0.0784757\tvalid_1's rmse: 0.0820236\n",
      "[2275]\ttraining's rmse: 0.0784737\tvalid_1's rmse: 0.0820234\n",
      "[2300]\ttraining's rmse: 0.0784715\tvalid_1's rmse: 0.082023\n",
      "[2325]\ttraining's rmse: 0.078469\tvalid_1's rmse: 0.0820229\n",
      "[2350]\ttraining's rmse: 0.078465\tvalid_1's rmse: 0.0820223\n",
      "[2375]\ttraining's rmse: 0.0784625\tvalid_1's rmse: 0.0820224\n",
      "[2400]\ttraining's rmse: 0.0784591\tvalid_1's rmse: 0.0820219\n",
      "[2425]\ttraining's rmse: 0.0784566\tvalid_1's rmse: 0.082022\n",
      "[2450]\ttraining's rmse: 0.0784525\tvalid_1's rmse: 0.0820212\n",
      "[2475]\ttraining's rmse: 0.0784498\tvalid_1's rmse: 0.0820214\n",
      "[2500]\ttraining's rmse: 0.0784473\tvalid_1's rmse: 0.0820212\n",
      "[2525]\ttraining's rmse: 0.0784453\tvalid_1's rmse: 0.0820214\n",
      "Early stopping, best iteration is:\n",
      "[2496]\ttraining's rmse: 0.0784476\tvalid_1's rmse: 0.0820212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.082883\tvalid_1's rmse: 0.0789408\n",
      "[50]\ttraining's rmse: 0.0827775\tvalid_1's rmse: 0.0788939\n",
      "[75]\ttraining's rmse: 0.0826675\tvalid_1's rmse: 0.0788472\n",
      "[100]\ttraining's rmse: 0.0825669\tvalid_1's rmse: 0.0788076\n",
      "[125]\ttraining's rmse: 0.0824647\tvalid_1's rmse: 0.0787673\n",
      "[150]\ttraining's rmse: 0.0823725\tvalid_1's rmse: 0.0787307\n",
      "[175]\ttraining's rmse: 0.0822974\tvalid_1's rmse: 0.0787005\n",
      "[200]\ttraining's rmse: 0.0822141\tvalid_1's rmse: 0.0786697\n",
      "[225]\ttraining's rmse: 0.0821345\tvalid_1's rmse: 0.0786396\n",
      "[250]\ttraining's rmse: 0.0820665\tvalid_1's rmse: 0.0786134\n",
      "[275]\ttraining's rmse: 0.0820032\tvalid_1's rmse: 0.0785896\n",
      "[300]\ttraining's rmse: 0.0819412\tvalid_1's rmse: 0.078567\n",
      "[325]\ttraining's rmse: 0.0818786\tvalid_1's rmse: 0.078546\n",
      "[350]\ttraining's rmse: 0.0818165\tvalid_1's rmse: 0.0785257\n",
      "[375]\ttraining's rmse: 0.0817656\tvalid_1's rmse: 0.0785092\n",
      "[400]\ttraining's rmse: 0.0817097\tvalid_1's rmse: 0.078492\n",
      "[425]\ttraining's rmse: 0.0816606\tvalid_1's rmse: 0.078477\n",
      "[450]\ttraining's rmse: 0.0816132\tvalid_1's rmse: 0.0784621\n",
      "[475]\ttraining's rmse: 0.0815687\tvalid_1's rmse: 0.0784572\n",
      "[500]\ttraining's rmse: 0.0815325\tvalid_1's rmse: 0.0784452\n",
      "[525]\ttraining's rmse: 0.0814839\tvalid_1's rmse: 0.0784387\n",
      "[550]\ttraining's rmse: 0.081439\tvalid_1's rmse: 0.078435\n",
      "[575]\ttraining's rmse: 0.0813987\tvalid_1's rmse: 0.0784306\n",
      "[600]\ttraining's rmse: 0.0813605\tvalid_1's rmse: 0.0784272\n",
      "[625]\ttraining's rmse: 0.0813277\tvalid_1's rmse: 0.078418\n",
      "[650]\ttraining's rmse: 0.0812894\tvalid_1's rmse: 0.0784143\n",
      "[675]\ttraining's rmse: 0.08125\tvalid_1's rmse: 0.0784191\n",
      "[700]\ttraining's rmse: 0.0812155\tvalid_1's rmse: 0.0784304\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's rmse: 0.0812576\tvalid_1's rmse: 0.0784097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0828457\tvalid_1's rmse: 0.0851979\n",
      "[50]\ttraining's rmse: 0.0827188\tvalid_1's rmse: 0.0851497\n",
      "[75]\ttraining's rmse: 0.0825946\tvalid_1's rmse: 0.0851018\n",
      "[100]\ttraining's rmse: 0.0824789\tvalid_1's rmse: 0.0850585\n",
      "[125]\ttraining's rmse: 0.0823607\tvalid_1's rmse: 0.0850138\n",
      "[150]\ttraining's rmse: 0.0822528\tvalid_1's rmse: 0.084973\n",
      "[175]\ttraining's rmse: 0.082165\tvalid_1's rmse: 0.0849393\n",
      "[200]\ttraining's rmse: 0.0820663\tvalid_1's rmse: 0.0849037\n",
      "[225]\ttraining's rmse: 0.0819714\tvalid_1's rmse: 0.0848707\n",
      "[250]\ttraining's rmse: 0.0818904\tvalid_1's rmse: 0.0848399\n",
      "[275]\ttraining's rmse: 0.0818156\tvalid_1's rmse: 0.0848136\n",
      "[300]\ttraining's rmse: 0.0817438\tvalid_1's rmse: 0.0847886\n",
      "[325]\ttraining's rmse: 0.0816685\tvalid_1's rmse: 0.0847651\n",
      "[350]\ttraining's rmse: 0.0815995\tvalid_1's rmse: 0.084742\n",
      "[375]\ttraining's rmse: 0.0815437\tvalid_1's rmse: 0.0847221\n",
      "[400]\ttraining's rmse: 0.0814786\tvalid_1's rmse: 0.0847026\n",
      "[425]\ttraining's rmse: 0.0814231\tvalid_1's rmse: 0.0846842\n",
      "[450]\ttraining's rmse: 0.0813691\tvalid_1's rmse: 0.084666\n",
      "[475]\ttraining's rmse: 0.0813195\tvalid_1's rmse: 0.0846503\n",
      "[500]\ttraining's rmse: 0.0812785\tvalid_1's rmse: 0.0846357\n",
      "[525]\ttraining's rmse: 0.0812264\tvalid_1's rmse: 0.0846204\n",
      "[550]\ttraining's rmse: 0.0811771\tvalid_1's rmse: 0.0846056\n",
      "[575]\ttraining's rmse: 0.0811312\tvalid_1's rmse: 0.0845912\n",
      "[600]\ttraining's rmse: 0.0810867\tvalid_1's rmse: 0.0845794\n",
      "[625]\ttraining's rmse: 0.08105\tvalid_1's rmse: 0.0845686\n",
      "[650]\ttraining's rmse: 0.0810081\tvalid_1's rmse: 0.084557\n",
      "[675]\ttraining's rmse: 0.080967\tvalid_1's rmse: 0.0845455\n",
      "[700]\ttraining's rmse: 0.080931\tvalid_1's rmse: 0.084535\n",
      "[725]\ttraining's rmse: 0.0808939\tvalid_1's rmse: 0.0845262\n",
      "[750]\ttraining's rmse: 0.0808587\tvalid_1's rmse: 0.0845184\n",
      "[775]\ttraining's rmse: 0.0808305\tvalid_1's rmse: 0.0845095\n",
      "[800]\ttraining's rmse: 0.0807956\tvalid_1's rmse: 0.0845014\n",
      "[825]\ttraining's rmse: 0.080768\tvalid_1's rmse: 0.0844933\n",
      "[850]\ttraining's rmse: 0.0807348\tvalid_1's rmse: 0.0844869\n",
      "[875]\ttraining's rmse: 0.0807089\tvalid_1's rmse: 0.0844802\n",
      "[900]\ttraining's rmse: 0.0806811\tvalid_1's rmse: 0.0844741\n",
      "[925]\ttraining's rmse: 0.0806544\tvalid_1's rmse: 0.0844675\n",
      "[950]\ttraining's rmse: 0.0806302\tvalid_1's rmse: 0.0844613\n",
      "[975]\ttraining's rmse: 0.0806072\tvalid_1's rmse: 0.0844553\n",
      "[1000]\ttraining's rmse: 0.0805867\tvalid_1's rmse: 0.0844514\n",
      "[1025]\ttraining's rmse: 0.0805636\tvalid_1's rmse: 0.0844474\n",
      "[1050]\ttraining's rmse: 0.0805426\tvalid_1's rmse: 0.0844411\n",
      "[1075]\ttraining's rmse: 0.0805202\tvalid_1's rmse: 0.0844375\n",
      "[1100]\ttraining's rmse: 0.0805021\tvalid_1's rmse: 0.0844331\n",
      "[1125]\ttraining's rmse: 0.0804854\tvalid_1's rmse: 0.0844287\n",
      "[1150]\ttraining's rmse: 0.0804659\tvalid_1's rmse: 0.0844245\n",
      "[1175]\ttraining's rmse: 0.080451\tvalid_1's rmse: 0.0844223\n",
      "[1200]\ttraining's rmse: 0.0804343\tvalid_1's rmse: 0.0844185\n",
      "[1225]\ttraining's rmse: 0.0804193\tvalid_1's rmse: 0.0844134\n",
      "[1250]\ttraining's rmse: 0.0804036\tvalid_1's rmse: 0.0844086\n",
      "[1275]\ttraining's rmse: 0.0803856\tvalid_1's rmse: 0.0844054\n",
      "[1300]\ttraining's rmse: 0.0803724\tvalid_1's rmse: 0.0844013\n",
      "[1325]\ttraining's rmse: 0.0803586\tvalid_1's rmse: 0.0843977\n",
      "[1350]\ttraining's rmse: 0.0803427\tvalid_1's rmse: 0.0843955\n",
      "[1375]\ttraining's rmse: 0.0803291\tvalid_1's rmse: 0.0843929\n",
      "[1400]\ttraining's rmse: 0.0803205\tvalid_1's rmse: 0.0843899\n",
      "[1425]\ttraining's rmse: 0.0803085\tvalid_1's rmse: 0.0843875\n",
      "[1450]\ttraining's rmse: 0.0802942\tvalid_1's rmse: 0.084384\n",
      "[1475]\ttraining's rmse: 0.0802835\tvalid_1's rmse: 0.0843811\n",
      "[1500]\ttraining's rmse: 0.0802747\tvalid_1's rmse: 0.0843791\n",
      "[1525]\ttraining's rmse: 0.0802628\tvalid_1's rmse: 0.0843771\n",
      "[1550]\ttraining's rmse: 0.0802526\tvalid_1's rmse: 0.0843748\n",
      "[1575]\ttraining's rmse: 0.0802444\tvalid_1's rmse: 0.084372\n",
      "[1600]\ttraining's rmse: 0.0802373\tvalid_1's rmse: 0.08437\n",
      "[1625]\ttraining's rmse: 0.0802297\tvalid_1's rmse: 0.084368\n",
      "[1650]\ttraining's rmse: 0.0802206\tvalid_1's rmse: 0.0843657\n",
      "[1675]\ttraining's rmse: 0.0802139\tvalid_1's rmse: 0.0843639\n",
      "[1700]\ttraining's rmse: 0.0802081\tvalid_1's rmse: 0.0843606\n",
      "[1725]\ttraining's rmse: 0.0802021\tvalid_1's rmse: 0.0843591\n",
      "[1750]\ttraining's rmse: 0.0801966\tvalid_1's rmse: 0.0843579\n",
      "[1775]\ttraining's rmse: 0.0801884\tvalid_1's rmse: 0.0843561\n",
      "[1800]\ttraining's rmse: 0.0801836\tvalid_1's rmse: 0.0843549\n",
      "[1825]\ttraining's rmse: 0.0801789\tvalid_1's rmse: 0.0843532\n",
      "[1850]\ttraining's rmse: 0.0801746\tvalid_1's rmse: 0.0843514\n",
      "[1875]\ttraining's rmse: 0.08017\tvalid_1's rmse: 0.0843511\n",
      "[1900]\ttraining's rmse: 0.0801662\tvalid_1's rmse: 0.084349\n",
      "[1925]\ttraining's rmse: 0.0801615\tvalid_1's rmse: 0.0843481\n",
      "[1950]\ttraining's rmse: 0.0801579\tvalid_1's rmse: 0.0843466\n",
      "[1975]\ttraining's rmse: 0.0801542\tvalid_1's rmse: 0.0843452\n",
      "[2000]\ttraining's rmse: 0.0801497\tvalid_1's rmse: 0.0843443\n",
      "[2025]\ttraining's rmse: 0.080146\tvalid_1's rmse: 0.0843427\n",
      "[2050]\ttraining's rmse: 0.0801413\tvalid_1's rmse: 0.084342\n",
      "[2075]\ttraining's rmse: 0.0801385\tvalid_1's rmse: 0.0843416\n",
      "[2100]\ttraining's rmse: 0.0801343\tvalid_1's rmse: 0.0843404\n",
      "[2125]\ttraining's rmse: 0.0801311\tvalid_1's rmse: 0.0843396\n",
      "[2150]\ttraining's rmse: 0.0801257\tvalid_1's rmse: 0.0843386\n",
      "[2175]\ttraining's rmse: 0.0801236\tvalid_1's rmse: 0.0843381\n",
      "[2200]\ttraining's rmse: 0.0801194\tvalid_1's rmse: 0.0843371\n",
      "[2225]\ttraining's rmse: 0.0801169\tvalid_1's rmse: 0.0843358\n",
      "[2250]\ttraining's rmse: 0.0801156\tvalid_1's rmse: 0.0843357\n",
      "[2275]\ttraining's rmse: 0.0801119\tvalid_1's rmse: 0.0843346\n",
      "[2300]\ttraining's rmse: 0.0801092\tvalid_1's rmse: 0.0843332\n",
      "[2325]\ttraining's rmse: 0.0801065\tvalid_1's rmse: 0.0843333\n",
      "[2350]\ttraining's rmse: 0.0801041\tvalid_1's rmse: 0.0843333\n",
      "[2375]\ttraining's rmse: 0.0801012\tvalid_1's rmse: 0.0843329\n",
      "[2400]\ttraining's rmse: 0.0800997\tvalid_1's rmse: 0.0843325\n",
      "[2425]\ttraining's rmse: 0.0800975\tvalid_1's rmse: 0.0843321\n",
      "[2450]\ttraining's rmse: 0.0800966\tvalid_1's rmse: 0.0843322\n",
      "Early stopping, best iteration is:\n",
      "[2420]\ttraining's rmse: 0.080098\tvalid_1's rmse: 0.084332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0830353\tvalid_1's rmse: 0.0848546\n",
      "[50]\ttraining's rmse: 0.0829225\tvalid_1's rmse: 0.0848028\n",
      "[75]\ttraining's rmse: 0.082807\tvalid_1's rmse: 0.0847513\n",
      "[100]\ttraining's rmse: 0.0827044\tvalid_1's rmse: 0.0847048\n",
      "[125]\ttraining's rmse: 0.0825977\tvalid_1's rmse: 0.0846597\n",
      "[150]\ttraining's rmse: 0.082501\tvalid_1's rmse: 0.0846178\n",
      "[175]\ttraining's rmse: 0.0824168\tvalid_1's rmse: 0.0845811\n",
      "[200]\ttraining's rmse: 0.0823256\tvalid_1's rmse: 0.0845436\n",
      "[225]\ttraining's rmse: 0.082241\tvalid_1's rmse: 0.0845111\n",
      "[250]\ttraining's rmse: 0.0821677\tvalid_1's rmse: 0.0844801\n",
      "[275]\ttraining's rmse: 0.0820999\tvalid_1's rmse: 0.0844525\n",
      "[300]\ttraining's rmse: 0.0820304\tvalid_1's rmse: 0.0844263\n",
      "[325]\ttraining's rmse: 0.0819601\tvalid_1's rmse: 0.0843994\n",
      "[350]\ttraining's rmse: 0.081892\tvalid_1's rmse: 0.0843738\n",
      "[375]\ttraining's rmse: 0.0818369\tvalid_1's rmse: 0.0843514\n",
      "[400]\ttraining's rmse: 0.0817788\tvalid_1's rmse: 0.0843318\n",
      "[425]\ttraining's rmse: 0.0817236\tvalid_1's rmse: 0.0843122\n",
      "[450]\ttraining's rmse: 0.0816755\tvalid_1's rmse: 0.0842936\n",
      "[475]\ttraining's rmse: 0.0816306\tvalid_1's rmse: 0.0842777\n",
      "[500]\ttraining's rmse: 0.0815906\tvalid_1's rmse: 0.0842611\n",
      "[525]\ttraining's rmse: 0.0815388\tvalid_1's rmse: 0.0842456\n",
      "[550]\ttraining's rmse: 0.0814897\tvalid_1's rmse: 0.0842321\n",
      "[575]\ttraining's rmse: 0.0814445\tvalid_1's rmse: 0.0842169\n",
      "[600]\ttraining's rmse: 0.0814039\tvalid_1's rmse: 0.0842034\n",
      "[625]\ttraining's rmse: 0.081372\tvalid_1's rmse: 0.0841919\n",
      "[650]\ttraining's rmse: 0.0813317\tvalid_1's rmse: 0.08418\n",
      "[675]\ttraining's rmse: 0.0812912\tvalid_1's rmse: 0.0841677\n",
      "[700]\ttraining's rmse: 0.0812529\tvalid_1's rmse: 0.0841557\n",
      "[725]\ttraining's rmse: 0.0812194\tvalid_1's rmse: 0.0841455\n",
      "[750]\ttraining's rmse: 0.081188\tvalid_1's rmse: 0.0841368\n",
      "[775]\ttraining's rmse: 0.0811624\tvalid_1's rmse: 0.0841278\n",
      "[800]\ttraining's rmse: 0.0811279\tvalid_1's rmse: 0.0841191\n",
      "[825]\ttraining's rmse: 0.0810993\tvalid_1's rmse: 0.0841108\n",
      "[850]\ttraining's rmse: 0.0810709\tvalid_1's rmse: 0.0841042\n",
      "[875]\ttraining's rmse: 0.0810464\tvalid_1's rmse: 0.0840975\n",
      "[900]\ttraining's rmse: 0.0810196\tvalid_1's rmse: 0.08409\n",
      "[925]\ttraining's rmse: 0.0809951\tvalid_1's rmse: 0.0840841\n",
      "[950]\ttraining's rmse: 0.0809701\tvalid_1's rmse: 0.0840778\n",
      "[975]\ttraining's rmse: 0.0809485\tvalid_1's rmse: 0.084072\n",
      "[1000]\ttraining's rmse: 0.0809296\tvalid_1's rmse: 0.0840672\n",
      "[1025]\ttraining's rmse: 0.0809057\tvalid_1's rmse: 0.0840627\n",
      "[1050]\ttraining's rmse: 0.0808851\tvalid_1's rmse: 0.0840574\n",
      "[1075]\ttraining's rmse: 0.0808619\tvalid_1's rmse: 0.0840538\n",
      "[1100]\ttraining's rmse: 0.0808459\tvalid_1's rmse: 0.0840496\n",
      "[1125]\ttraining's rmse: 0.0808276\tvalid_1's rmse: 0.0840456\n",
      "[1150]\ttraining's rmse: 0.080811\tvalid_1's rmse: 0.0840416\n",
      "[1175]\ttraining's rmse: 0.080795\tvalid_1's rmse: 0.0840385\n",
      "[1200]\ttraining's rmse: 0.080778\tvalid_1's rmse: 0.0840346\n",
      "[1225]\ttraining's rmse: 0.0807621\tvalid_1's rmse: 0.0840317\n",
      "[1250]\ttraining's rmse: 0.0807494\tvalid_1's rmse: 0.0840285\n",
      "[1275]\ttraining's rmse: 0.080734\tvalid_1's rmse: 0.0840265\n",
      "[1300]\ttraining's rmse: 0.0807197\tvalid_1's rmse: 0.084024\n",
      "[1325]\ttraining's rmse: 0.0807079\tvalid_1's rmse: 0.0840216\n",
      "[1350]\ttraining's rmse: 0.080694\tvalid_1's rmse: 0.0840193\n",
      "[1375]\ttraining's rmse: 0.0806827\tvalid_1's rmse: 0.0840167\n",
      "[1400]\ttraining's rmse: 0.0806718\tvalid_1's rmse: 0.0840138\n",
      "[1425]\ttraining's rmse: 0.0806604\tvalid_1's rmse: 0.0840133\n",
      "[1450]\ttraining's rmse: 0.0806482\tvalid_1's rmse: 0.084012\n",
      "[1475]\ttraining's rmse: 0.0806383\tvalid_1's rmse: 0.0840101\n",
      "[1500]\ttraining's rmse: 0.0806281\tvalid_1's rmse: 0.084009\n",
      "[1525]\ttraining's rmse: 0.0806179\tvalid_1's rmse: 0.0840074\n",
      "[1550]\ttraining's rmse: 0.0806101\tvalid_1's rmse: 0.0840064\n",
      "[1575]\ttraining's rmse: 0.0806028\tvalid_1's rmse: 0.0840045\n",
      "[1600]\ttraining's rmse: 0.0805948\tvalid_1's rmse: 0.084004\n",
      "[1625]\ttraining's rmse: 0.0805865\tvalid_1's rmse: 0.084003\n",
      "[1650]\ttraining's rmse: 0.0805796\tvalid_1's rmse: 0.0840021\n",
      "[1675]\ttraining's rmse: 0.0805746\tvalid_1's rmse: 0.0840007\n",
      "[1700]\ttraining's rmse: 0.0805673\tvalid_1's rmse: 0.0839991\n",
      "[1725]\ttraining's rmse: 0.0805615\tvalid_1's rmse: 0.083998\n",
      "[1750]\ttraining's rmse: 0.0805537\tvalid_1's rmse: 0.0839972\n",
      "[1775]\ttraining's rmse: 0.0805492\tvalid_1's rmse: 0.0839968\n",
      "[1800]\ttraining's rmse: 0.0805437\tvalid_1's rmse: 0.0839957\n",
      "[1825]\ttraining's rmse: 0.0805384\tvalid_1's rmse: 0.0839943\n",
      "[1850]\ttraining's rmse: 0.0805348\tvalid_1's rmse: 0.0839934\n",
      "[1875]\ttraining's rmse: 0.0805306\tvalid_1's rmse: 0.0839931\n",
      "[1900]\ttraining's rmse: 0.080527\tvalid_1's rmse: 0.0839931\n",
      "[1925]\ttraining's rmse: 0.0805233\tvalid_1's rmse: 0.0839923\n",
      "[1950]\ttraining's rmse: 0.08052\tvalid_1's rmse: 0.0839916\n",
      "[1975]\ttraining's rmse: 0.0805159\tvalid_1's rmse: 0.0839907\n",
      "[2000]\ttraining's rmse: 0.0805101\tvalid_1's rmse: 0.0839899\n",
      "[2025]\ttraining's rmse: 0.0805068\tvalid_1's rmse: 0.0839891\n",
      "[2050]\ttraining's rmse: 0.0805028\tvalid_1's rmse: 0.0839885\n",
      "[2075]\ttraining's rmse: 0.0804993\tvalid_1's rmse: 0.0839878\n",
      "[2100]\ttraining's rmse: 0.0804957\tvalid_1's rmse: 0.0839877\n",
      "[2125]\ttraining's rmse: 0.0804932\tvalid_1's rmse: 0.0839876\n",
      "[2150]\ttraining's rmse: 0.0804902\tvalid_1's rmse: 0.0839877\n",
      "Early stopping, best iteration is:\n",
      "[2124]\ttraining's rmse: 0.0804932\tvalid_1's rmse: 0.0839876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0849041\tvalid_1's rmse: 0.0810454\n",
      "[50]\ttraining's rmse: 0.0847971\tvalid_1's rmse: 0.0809986\n",
      "[75]\ttraining's rmse: 0.0846816\tvalid_1's rmse: 0.0809503\n",
      "[100]\ttraining's rmse: 0.0845782\tvalid_1's rmse: 0.080909\n",
      "[125]\ttraining's rmse: 0.0844717\tvalid_1's rmse: 0.0808674\n",
      "[150]\ttraining's rmse: 0.0843751\tvalid_1's rmse: 0.0808309\n",
      "[175]\ttraining's rmse: 0.0842944\tvalid_1's rmse: 0.0808001\n",
      "[200]\ttraining's rmse: 0.0842067\tvalid_1's rmse: 0.0807695\n",
      "[225]\ttraining's rmse: 0.0841225\tvalid_1's rmse: 0.0807394\n",
      "[250]\ttraining's rmse: 0.0840521\tvalid_1's rmse: 0.0807133\n",
      "[275]\ttraining's rmse: 0.0839857\tvalid_1's rmse: 0.0806882\n",
      "[300]\ttraining's rmse: 0.08392\tvalid_1's rmse: 0.0806668\n",
      "[325]\ttraining's rmse: 0.0838535\tvalid_1's rmse: 0.0806452\n",
      "[350]\ttraining's rmse: 0.083788\tvalid_1's rmse: 0.0806236\n",
      "[375]\ttraining's rmse: 0.0837347\tvalid_1's rmse: 0.0806081\n",
      "[400]\ttraining's rmse: 0.0836763\tvalid_1's rmse: 0.080594\n",
      "[425]\ttraining's rmse: 0.0836245\tvalid_1's rmse: 0.0805807\n",
      "[450]\ttraining's rmse: 0.0835735\tvalid_1's rmse: 0.0805692\n",
      "[475]\ttraining's rmse: 0.0835283\tvalid_1's rmse: 0.0805611\n",
      "[500]\ttraining's rmse: 0.0834898\tvalid_1's rmse: 0.0805496\n",
      "[525]\ttraining's rmse: 0.0834399\tvalid_1's rmse: 0.0805363\n",
      "[550]\ttraining's rmse: 0.0833946\tvalid_1's rmse: 0.080524\n",
      "[575]\ttraining's rmse: 0.0833529\tvalid_1's rmse: 0.0805137\n",
      "[600]\ttraining's rmse: 0.0833099\tvalid_1's rmse: 0.0805039\n",
      "[625]\ttraining's rmse: 0.0832768\tvalid_1's rmse: 0.0804985\n",
      "[650]\ttraining's rmse: 0.0832354\tvalid_1's rmse: 0.0804893\n",
      "[675]\ttraining's rmse: 0.0831949\tvalid_1's rmse: 0.0804869\n",
      "[700]\ttraining's rmse: 0.0831582\tvalid_1's rmse: 0.0804793\n",
      "[725]\ttraining's rmse: 0.0831231\tvalid_1's rmse: 0.0804768\n",
      "[750]\ttraining's rmse: 0.083091\tvalid_1's rmse: 0.0804779\n",
      "[775]\ttraining's rmse: 0.0830646\tvalid_1's rmse: 0.0804751\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 0.0830995\tvalid_1's rmse: 0.0804717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0812136\tvalid_1's rmse: 0.0835249\n",
      "[50]\ttraining's rmse: 0.08109\tvalid_1's rmse: 0.0834741\n",
      "[75]\ttraining's rmse: 0.0809687\tvalid_1's rmse: 0.0834231\n",
      "[100]\ttraining's rmse: 0.0808537\tvalid_1's rmse: 0.0833776\n",
      "[125]\ttraining's rmse: 0.0807379\tvalid_1's rmse: 0.0833331\n",
      "[150]\ttraining's rmse: 0.080635\tvalid_1's rmse: 0.0832914\n",
      "[175]\ttraining's rmse: 0.0805482\tvalid_1's rmse: 0.0832554\n",
      "[200]\ttraining's rmse: 0.0804578\tvalid_1's rmse: 0.08322\n",
      "[225]\ttraining's rmse: 0.0803644\tvalid_1's rmse: 0.0831849\n",
      "[250]\ttraining's rmse: 0.0802881\tvalid_1's rmse: 0.0831541\n",
      "[275]\ttraining's rmse: 0.0802155\tvalid_1's rmse: 0.083125\n",
      "[300]\ttraining's rmse: 0.0801434\tvalid_1's rmse: 0.0830974\n",
      "[325]\ttraining's rmse: 0.0800731\tvalid_1's rmse: 0.0830726\n",
      "[350]\ttraining's rmse: 0.0800039\tvalid_1's rmse: 0.0830476\n",
      "[375]\ttraining's rmse: 0.0799487\tvalid_1's rmse: 0.0830273\n",
      "[400]\ttraining's rmse: 0.079888\tvalid_1's rmse: 0.0830061\n",
      "[425]\ttraining's rmse: 0.0798344\tvalid_1's rmse: 0.0829864\n",
      "[450]\ttraining's rmse: 0.0797848\tvalid_1's rmse: 0.0829687\n",
      "[475]\ttraining's rmse: 0.0797414\tvalid_1's rmse: 0.0829507\n",
      "[500]\ttraining's rmse: 0.0797005\tvalid_1's rmse: 0.0829323\n",
      "[525]\ttraining's rmse: 0.0796512\tvalid_1's rmse: 0.0829178\n",
      "[550]\ttraining's rmse: 0.0796036\tvalid_1's rmse: 0.0829017\n",
      "[575]\ttraining's rmse: 0.0795607\tvalid_1's rmse: 0.0828877\n",
      "[600]\ttraining's rmse: 0.079519\tvalid_1's rmse: 0.082874\n",
      "[625]\ttraining's rmse: 0.0794865\tvalid_1's rmse: 0.0828621\n",
      "[650]\ttraining's rmse: 0.0794474\tvalid_1's rmse: 0.0828504\n",
      "[675]\ttraining's rmse: 0.0794064\tvalid_1's rmse: 0.0828385\n",
      "[700]\ttraining's rmse: 0.0793719\tvalid_1's rmse: 0.0828275\n",
      "[725]\ttraining's rmse: 0.079339\tvalid_1's rmse: 0.0828173\n",
      "[750]\ttraining's rmse: 0.0793084\tvalid_1's rmse: 0.0828073\n",
      "[775]\ttraining's rmse: 0.0792828\tvalid_1's rmse: 0.0827974\n",
      "[800]\ttraining's rmse: 0.0792484\tvalid_1's rmse: 0.0827887\n",
      "[825]\ttraining's rmse: 0.0792235\tvalid_1's rmse: 0.0827808\n",
      "[850]\ttraining's rmse: 0.0791948\tvalid_1's rmse: 0.0827739\n",
      "[875]\ttraining's rmse: 0.0791706\tvalid_1's rmse: 0.0827668\n",
      "[900]\ttraining's rmse: 0.0791434\tvalid_1's rmse: 0.0827596\n",
      "[925]\ttraining's rmse: 0.0791196\tvalid_1's rmse: 0.0827521\n",
      "[950]\ttraining's rmse: 0.0790977\tvalid_1's rmse: 0.082745\n",
      "[975]\ttraining's rmse: 0.079074\tvalid_1's rmse: 0.0827393\n",
      "[1000]\ttraining's rmse: 0.0790509\tvalid_1's rmse: 0.0827339\n",
      "[1025]\ttraining's rmse: 0.079028\tvalid_1's rmse: 0.0827287\n",
      "[1050]\ttraining's rmse: 0.0790089\tvalid_1's rmse: 0.0827219\n",
      "[1075]\ttraining's rmse: 0.078989\tvalid_1's rmse: 0.0827167\n",
      "[1100]\ttraining's rmse: 0.0789712\tvalid_1's rmse: 0.0827122\n",
      "[1125]\ttraining's rmse: 0.0789551\tvalid_1's rmse: 0.0827063\n",
      "[1150]\ttraining's rmse: 0.0789362\tvalid_1's rmse: 0.0827029\n",
      "[1175]\ttraining's rmse: 0.0789213\tvalid_1's rmse: 0.0827004\n",
      "[1200]\ttraining's rmse: 0.0789047\tvalid_1's rmse: 0.0826962\n",
      "[1225]\ttraining's rmse: 0.0788903\tvalid_1's rmse: 0.0826914\n",
      "[1250]\ttraining's rmse: 0.0788778\tvalid_1's rmse: 0.0826869\n",
      "[1275]\ttraining's rmse: 0.0788592\tvalid_1's rmse: 0.0826831\n",
      "[1300]\ttraining's rmse: 0.0788476\tvalid_1's rmse: 0.0826789\n",
      "[1325]\ttraining's rmse: 0.0788356\tvalid_1's rmse: 0.0826742\n",
      "[1350]\ttraining's rmse: 0.0788248\tvalid_1's rmse: 0.0826721\n",
      "[1375]\ttraining's rmse: 0.0788133\tvalid_1's rmse: 0.0826689\n",
      "[1400]\ttraining's rmse: 0.0788037\tvalid_1's rmse: 0.0826651\n",
      "[1425]\ttraining's rmse: 0.0787927\tvalid_1's rmse: 0.0826632\n",
      "[1450]\ttraining's rmse: 0.0787818\tvalid_1's rmse: 0.0826611\n",
      "[1475]\ttraining's rmse: 0.0787737\tvalid_1's rmse: 0.0826582\n",
      "[1500]\ttraining's rmse: 0.0787634\tvalid_1's rmse: 0.0826567\n",
      "[1525]\ttraining's rmse: 0.0787554\tvalid_1's rmse: 0.0826538\n",
      "[1550]\ttraining's rmse: 0.0787454\tvalid_1's rmse: 0.0826527\n",
      "[1575]\ttraining's rmse: 0.0787365\tvalid_1's rmse: 0.0826503\n",
      "[1600]\ttraining's rmse: 0.0787304\tvalid_1's rmse: 0.0826472\n",
      "[1625]\ttraining's rmse: 0.0787243\tvalid_1's rmse: 0.0826445\n",
      "[1650]\ttraining's rmse: 0.0787166\tvalid_1's rmse: 0.0826428\n",
      "[1675]\ttraining's rmse: 0.0787113\tvalid_1's rmse: 0.0826405\n",
      "[1700]\ttraining's rmse: 0.0787049\tvalid_1's rmse: 0.0826382\n",
      "[1725]\ttraining's rmse: 0.078698\tvalid_1's rmse: 0.0826353\n",
      "[1750]\ttraining's rmse: 0.0786927\tvalid_1's rmse: 0.082633\n",
      "[1775]\ttraining's rmse: 0.0786871\tvalid_1's rmse: 0.0826319\n",
      "[1800]\ttraining's rmse: 0.0786824\tvalid_1's rmse: 0.0826309\n",
      "[1825]\ttraining's rmse: 0.0786781\tvalid_1's rmse: 0.082629\n",
      "[1850]\ttraining's rmse: 0.0786746\tvalid_1's rmse: 0.0826278\n",
      "[1875]\ttraining's rmse: 0.0786703\tvalid_1's rmse: 0.0826277\n",
      "[1900]\ttraining's rmse: 0.0786656\tvalid_1's rmse: 0.0826259\n",
      "[1925]\ttraining's rmse: 0.0786621\tvalid_1's rmse: 0.0826246\n",
      "[1950]\ttraining's rmse: 0.0786594\tvalid_1's rmse: 0.0826233\n",
      "[1975]\ttraining's rmse: 0.0786556\tvalid_1's rmse: 0.0826212\n",
      "[2000]\ttraining's rmse: 0.0786509\tvalid_1's rmse: 0.08262\n",
      "[2025]\ttraining's rmse: 0.0786473\tvalid_1's rmse: 0.0826185\n",
      "[2050]\ttraining's rmse: 0.078644\tvalid_1's rmse: 0.0826173\n",
      "[2075]\ttraining's rmse: 0.0786399\tvalid_1's rmse: 0.0826162\n",
      "[2100]\ttraining's rmse: 0.0786375\tvalid_1's rmse: 0.082615\n",
      "[2125]\ttraining's rmse: 0.0786359\tvalid_1's rmse: 0.0826138\n",
      "[2150]\ttraining's rmse: 0.0786327\tvalid_1's rmse: 0.0826131\n",
      "[2175]\ttraining's rmse: 0.07863\tvalid_1's rmse: 0.0826125\n",
      "[2200]\ttraining's rmse: 0.0786261\tvalid_1's rmse: 0.0826115\n",
      "[2225]\ttraining's rmse: 0.0786243\tvalid_1's rmse: 0.0826104\n",
      "[2250]\ttraining's rmse: 0.0786212\tvalid_1's rmse: 0.08261\n",
      "[2275]\ttraining's rmse: 0.0786191\tvalid_1's rmse: 0.0826089\n",
      "[2300]\ttraining's rmse: 0.0786166\tvalid_1's rmse: 0.0826087\n",
      "[2325]\ttraining's rmse: 0.0786149\tvalid_1's rmse: 0.0826084\n",
      "[2350]\ttraining's rmse: 0.0786131\tvalid_1's rmse: 0.0826076\n",
      "[2375]\ttraining's rmse: 0.0786118\tvalid_1's rmse: 0.0826075\n",
      "[2400]\ttraining's rmse: 0.0786081\tvalid_1's rmse: 0.0826072\n",
      "[2425]\ttraining's rmse: 0.0786059\tvalid_1's rmse: 0.0826065\n",
      "[2450]\ttraining's rmse: 0.0786032\tvalid_1's rmse: 0.0826061\n",
      "[2475]\ttraining's rmse: 0.0786006\tvalid_1's rmse: 0.0826055\n",
      "[2500]\ttraining's rmse: 0.078598\tvalid_1's rmse: 0.0826048\n",
      "[2525]\ttraining's rmse: 0.078596\tvalid_1's rmse: 0.0826043\n",
      "[2550]\ttraining's rmse: 0.0785935\tvalid_1's rmse: 0.0826048\n",
      "[2575]\ttraining's rmse: 0.078592\tvalid_1's rmse: 0.0826042\n",
      "[2600]\ttraining's rmse: 0.0785904\tvalid_1's rmse: 0.082604\n",
      "[2625]\ttraining's rmse: 0.0785895\tvalid_1's rmse: 0.0826042\n",
      "[2650]\ttraining's rmse: 0.0785883\tvalid_1's rmse: 0.0826037\n",
      "[2675]\ttraining's rmse: 0.0785855\tvalid_1's rmse: 0.0826029\n",
      "[2700]\ttraining's rmse: 0.0785841\tvalid_1's rmse: 0.0826025\n",
      "[2725]\ttraining's rmse: 0.0785825\tvalid_1's rmse: 0.0826022\n",
      "[2750]\ttraining's rmse: 0.0785805\tvalid_1's rmse: 0.0826016\n",
      "[2775]\ttraining's rmse: 0.0785782\tvalid_1's rmse: 0.0826009\n",
      "[2800]\ttraining's rmse: 0.0785769\tvalid_1's rmse: 0.082601\n",
      "[2825]\ttraining's rmse: 0.0785754\tvalid_1's rmse: 0.0826004\n",
      "[2850]\ttraining's rmse: 0.0785739\tvalid_1's rmse: 0.0825997\n",
      "[2875]\ttraining's rmse: 0.0785728\tvalid_1's rmse: 0.0825997\n",
      "[2900]\ttraining's rmse: 0.0785718\tvalid_1's rmse: 0.0825992\n",
      "[2925]\ttraining's rmse: 0.078571\tvalid_1's rmse: 0.0825991\n",
      "[2950]\ttraining's rmse: 0.0785703\tvalid_1's rmse: 0.0825993\n",
      "Early stopping, best iteration is:\n",
      "[2919]\ttraining's rmse: 0.0785714\tvalid_1's rmse: 0.0825991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0813112\tvalid_1's rmse: 0.0833498\n",
      "[50]\ttraining's rmse: 0.0811992\tvalid_1's rmse: 0.0832968\n",
      "[75]\ttraining's rmse: 0.0810835\tvalid_1's rmse: 0.0832451\n",
      "[100]\ttraining's rmse: 0.080984\tvalid_1's rmse: 0.0831981\n",
      "[125]\ttraining's rmse: 0.0808775\tvalid_1's rmse: 0.083151\n",
      "[150]\ttraining's rmse: 0.0807814\tvalid_1's rmse: 0.0831084\n",
      "[175]\ttraining's rmse: 0.0807022\tvalid_1's rmse: 0.0830736\n",
      "[200]\ttraining's rmse: 0.0806129\tvalid_1's rmse: 0.0830371\n",
      "[225]\ttraining's rmse: 0.080528\tvalid_1's rmse: 0.0830045\n",
      "[250]\ttraining's rmse: 0.0804557\tvalid_1's rmse: 0.0829742\n",
      "[275]\ttraining's rmse: 0.0803879\tvalid_1's rmse: 0.0829452\n",
      "[300]\ttraining's rmse: 0.0803216\tvalid_1's rmse: 0.0829183\n",
      "[325]\ttraining's rmse: 0.0802536\tvalid_1's rmse: 0.0828924\n",
      "[350]\ttraining's rmse: 0.0801879\tvalid_1's rmse: 0.0828687\n",
      "[375]\ttraining's rmse: 0.0801366\tvalid_1's rmse: 0.082849\n",
      "[400]\ttraining's rmse: 0.0800775\tvalid_1's rmse: 0.0828283\n",
      "[425]\ttraining's rmse: 0.0800232\tvalid_1's rmse: 0.0828092\n",
      "[450]\ttraining's rmse: 0.0799745\tvalid_1's rmse: 0.0827916\n",
      "[475]\ttraining's rmse: 0.0799288\tvalid_1's rmse: 0.0827755\n",
      "[500]\ttraining's rmse: 0.0798899\tvalid_1's rmse: 0.0827591\n",
      "[525]\ttraining's rmse: 0.0798402\tvalid_1's rmse: 0.082743\n",
      "[550]\ttraining's rmse: 0.0797923\tvalid_1's rmse: 0.0827283\n",
      "[575]\ttraining's rmse: 0.0797504\tvalid_1's rmse: 0.0827154\n",
      "[600]\ttraining's rmse: 0.0797079\tvalid_1's rmse: 0.0827023\n",
      "[625]\ttraining's rmse: 0.0796763\tvalid_1's rmse: 0.0826911\n",
      "[650]\ttraining's rmse: 0.0796357\tvalid_1's rmse: 0.0826793\n",
      "[675]\ttraining's rmse: 0.0795939\tvalid_1's rmse: 0.0826686\n",
      "[700]\ttraining's rmse: 0.079559\tvalid_1's rmse: 0.082658\n",
      "[725]\ttraining's rmse: 0.0795255\tvalid_1's rmse: 0.0826486\n",
      "[750]\ttraining's rmse: 0.0794947\tvalid_1's rmse: 0.0826394\n",
      "[775]\ttraining's rmse: 0.079468\tvalid_1's rmse: 0.0826302\n",
      "[800]\ttraining's rmse: 0.0794341\tvalid_1's rmse: 0.0826219\n",
      "[825]\ttraining's rmse: 0.0794051\tvalid_1's rmse: 0.0826132\n",
      "[850]\ttraining's rmse: 0.0793764\tvalid_1's rmse: 0.0826064\n",
      "[875]\ttraining's rmse: 0.0793536\tvalid_1's rmse: 0.0826004\n",
      "[900]\ttraining's rmse: 0.0793256\tvalid_1's rmse: 0.0825931\n",
      "[925]\ttraining's rmse: 0.0793004\tvalid_1's rmse: 0.0825874\n",
      "[950]\ttraining's rmse: 0.0792783\tvalid_1's rmse: 0.0825822\n",
      "[975]\ttraining's rmse: 0.0792568\tvalid_1's rmse: 0.0825769\n",
      "[1000]\ttraining's rmse: 0.0792367\tvalid_1's rmse: 0.0825719\n",
      "[1025]\ttraining's rmse: 0.079215\tvalid_1's rmse: 0.082567\n",
      "[1050]\ttraining's rmse: 0.0791961\tvalid_1's rmse: 0.0825628\n",
      "[1075]\ttraining's rmse: 0.0791747\tvalid_1's rmse: 0.0825582\n",
      "[1100]\ttraining's rmse: 0.0791591\tvalid_1's rmse: 0.0825543\n",
      "[1125]\ttraining's rmse: 0.0791434\tvalid_1's rmse: 0.0825508\n",
      "[1150]\ttraining's rmse: 0.0791245\tvalid_1's rmse: 0.082547\n",
      "[1175]\ttraining's rmse: 0.0791103\tvalid_1's rmse: 0.0825437\n",
      "[1200]\ttraining's rmse: 0.0790948\tvalid_1's rmse: 0.0825402\n",
      "[1225]\ttraining's rmse: 0.0790801\tvalid_1's rmse: 0.0825369\n",
      "[1250]\ttraining's rmse: 0.0790671\tvalid_1's rmse: 0.0825334\n",
      "[1275]\ttraining's rmse: 0.079051\tvalid_1's rmse: 0.0825313\n",
      "[1300]\ttraining's rmse: 0.0790383\tvalid_1's rmse: 0.0825279\n",
      "[1325]\ttraining's rmse: 0.0790273\tvalid_1's rmse: 0.0825259\n",
      "[1350]\ttraining's rmse: 0.0790144\tvalid_1's rmse: 0.082524\n",
      "[1375]\ttraining's rmse: 0.0790037\tvalid_1's rmse: 0.0825217\n",
      "[1400]\ttraining's rmse: 0.0789953\tvalid_1's rmse: 0.0825195\n",
      "[1425]\ttraining's rmse: 0.0789852\tvalid_1's rmse: 0.0825184\n",
      "[1450]\ttraining's rmse: 0.0789722\tvalid_1's rmse: 0.0825168\n",
      "[1475]\ttraining's rmse: 0.0789617\tvalid_1's rmse: 0.0825144\n",
      "[1500]\ttraining's rmse: 0.0789525\tvalid_1's rmse: 0.0825126\n",
      "[1525]\ttraining's rmse: 0.0789433\tvalid_1's rmse: 0.0825111\n",
      "[1550]\ttraining's rmse: 0.0789348\tvalid_1's rmse: 0.08251\n",
      "[1575]\ttraining's rmse: 0.0789276\tvalid_1's rmse: 0.0825081\n",
      "[1600]\ttraining's rmse: 0.0789221\tvalid_1's rmse: 0.0825068\n",
      "[1625]\ttraining's rmse: 0.0789152\tvalid_1's rmse: 0.082505\n",
      "[1650]\ttraining's rmse: 0.0789085\tvalid_1's rmse: 0.0825042\n",
      "[1675]\ttraining's rmse: 0.0789032\tvalid_1's rmse: 0.0825033\n",
      "[1700]\ttraining's rmse: 0.0788981\tvalid_1's rmse: 0.0825021\n",
      "[1725]\ttraining's rmse: 0.0788933\tvalid_1's rmse: 0.0825011\n",
      "[1750]\ttraining's rmse: 0.0788875\tvalid_1's rmse: 0.0825002\n",
      "[1775]\ttraining's rmse: 0.0788815\tvalid_1's rmse: 0.0824998\n",
      "[1800]\ttraining's rmse: 0.0788763\tvalid_1's rmse: 0.0824988\n",
      "[1825]\ttraining's rmse: 0.078871\tvalid_1's rmse: 0.0824977\n",
      "[1850]\ttraining's rmse: 0.0788657\tvalid_1's rmse: 0.0824966\n",
      "[1875]\ttraining's rmse: 0.0788616\tvalid_1's rmse: 0.0824959\n",
      "[1900]\ttraining's rmse: 0.0788569\tvalid_1's rmse: 0.0824957\n",
      "[1925]\ttraining's rmse: 0.0788518\tvalid_1's rmse: 0.0824951\n",
      "[1950]\ttraining's rmse: 0.0788479\tvalid_1's rmse: 0.0824938\n",
      "[1975]\ttraining's rmse: 0.0788448\tvalid_1's rmse: 0.0824929\n",
      "[2000]\ttraining's rmse: 0.0788392\tvalid_1's rmse: 0.0824916\n",
      "[2025]\ttraining's rmse: 0.0788358\tvalid_1's rmse: 0.0824911\n",
      "[2050]\ttraining's rmse: 0.0788327\tvalid_1's rmse: 0.0824908\n",
      "[2075]\ttraining's rmse: 0.0788287\tvalid_1's rmse: 0.0824906\n",
      "[2100]\ttraining's rmse: 0.0788259\tvalid_1's rmse: 0.0824901\n",
      "[2125]\ttraining's rmse: 0.0788227\tvalid_1's rmse: 0.0824899\n",
      "[2150]\ttraining's rmse: 0.0788188\tvalid_1's rmse: 0.0824896\n",
      "[2175]\ttraining's rmse: 0.0788165\tvalid_1's rmse: 0.0824897\n",
      "[2200]\ttraining's rmse: 0.078814\tvalid_1's rmse: 0.0824893\n",
      "[2225]\ttraining's rmse: 0.0788117\tvalid_1's rmse: 0.0824893\n",
      "[2250]\ttraining's rmse: 0.0788074\tvalid_1's rmse: 0.0824889\n",
      "[2275]\ttraining's rmse: 0.0788035\tvalid_1's rmse: 0.0824884\n",
      "[2300]\ttraining's rmse: 0.0788017\tvalid_1's rmse: 0.0824886\n",
      "[2325]\ttraining's rmse: 0.0787984\tvalid_1's rmse: 0.0824884\n",
      "[2350]\ttraining's rmse: 0.0787965\tvalid_1's rmse: 0.0824882\n",
      "[2375]\ttraining's rmse: 0.0787944\tvalid_1's rmse: 0.0824878\n",
      "[2400]\ttraining's rmse: 0.0787919\tvalid_1's rmse: 0.0824877\n",
      "[2425]\ttraining's rmse: 0.0787898\tvalid_1's rmse: 0.0824876\n",
      "[2450]\ttraining's rmse: 0.0787875\tvalid_1's rmse: 0.0824877\n",
      "Early stopping, best iteration is:\n",
      "[2420]\ttraining's rmse: 0.0787902\tvalid_1's rmse: 0.0824874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0833187\tvalid_1's rmse: 0.0792597\n",
      "[50]\ttraining's rmse: 0.0832098\tvalid_1's rmse: 0.0792132\n",
      "[75]\ttraining's rmse: 0.0830969\tvalid_1's rmse: 0.0791653\n",
      "[100]\ttraining's rmse: 0.0829973\tvalid_1's rmse: 0.0791243\n",
      "[125]\ttraining's rmse: 0.0828932\tvalid_1's rmse: 0.0790835\n",
      "[150]\ttraining's rmse: 0.0828001\tvalid_1's rmse: 0.0790458\n",
      "[175]\ttraining's rmse: 0.082721\tvalid_1's rmse: 0.0790154\n",
      "[200]\ttraining's rmse: 0.0826364\tvalid_1's rmse: 0.0789841\n",
      "[225]\ttraining's rmse: 0.0825545\tvalid_1's rmse: 0.0789544\n",
      "[250]\ttraining's rmse: 0.0824884\tvalid_1's rmse: 0.0789309\n",
      "[275]\ttraining's rmse: 0.0824257\tvalid_1's rmse: 0.0789062\n",
      "[300]\ttraining's rmse: 0.0823628\tvalid_1's rmse: 0.0788855\n",
      "[325]\ttraining's rmse: 0.0822987\tvalid_1's rmse: 0.0788631\n",
      "[350]\ttraining's rmse: 0.0822354\tvalid_1's rmse: 0.0788424\n",
      "[375]\ttraining's rmse: 0.0821848\tvalid_1's rmse: 0.0788245\n",
      "[400]\ttraining's rmse: 0.082127\tvalid_1's rmse: 0.0788115\n",
      "[425]\ttraining's rmse: 0.0820763\tvalid_1's rmse: 0.0788046\n",
      "[450]\ttraining's rmse: 0.0820292\tvalid_1's rmse: 0.0787928\n",
      "[475]\ttraining's rmse: 0.0819829\tvalid_1's rmse: 0.0787902\n",
      "[500]\ttraining's rmse: 0.0819461\tvalid_1's rmse: 0.0787785\n",
      "[525]\ttraining's rmse: 0.0818967\tvalid_1's rmse: 0.0787639\n",
      "[550]\ttraining's rmse: 0.0818523\tvalid_1's rmse: 0.078751\n",
      "[575]\ttraining's rmse: 0.0818103\tvalid_1's rmse: 0.0787392\n",
      "[600]\ttraining's rmse: 0.0817706\tvalid_1's rmse: 0.0787412\n",
      "[625]\ttraining's rmse: 0.0817402\tvalid_1's rmse: 0.0787405\n",
      "[650]\ttraining's rmse: 0.0816997\tvalid_1's rmse: 0.0787374\n",
      "[675]\ttraining's rmse: 0.0816581\tvalid_1's rmse: 0.0787321\n",
      "[700]\ttraining's rmse: 0.0816228\tvalid_1's rmse: 0.0787329\n",
      "[725]\ttraining's rmse: 0.081589\tvalid_1's rmse: 0.0787406\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0816322\tvalid_1's rmse: 0.0787265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0837386\tvalid_1's rmse: 0.0860637\n",
      "[50]\ttraining's rmse: 0.0836101\tvalid_1's rmse: 0.0860136\n",
      "[75]\ttraining's rmse: 0.083481\tvalid_1's rmse: 0.0859639\n",
      "[100]\ttraining's rmse: 0.0833602\tvalid_1's rmse: 0.0859207\n",
      "[125]\ttraining's rmse: 0.0832385\tvalid_1's rmse: 0.0858752\n",
      "[150]\ttraining's rmse: 0.0831279\tvalid_1's rmse: 0.085833\n",
      "[175]\ttraining's rmse: 0.0830365\tvalid_1's rmse: 0.0858007\n",
      "[200]\ttraining's rmse: 0.0829373\tvalid_1's rmse: 0.0857636\n",
      "[225]\ttraining's rmse: 0.0828392\tvalid_1's rmse: 0.0857328\n",
      "[250]\ttraining's rmse: 0.0827555\tvalid_1's rmse: 0.0857009\n",
      "[275]\ttraining's rmse: 0.0826805\tvalid_1's rmse: 0.0856728\n",
      "[300]\ttraining's rmse: 0.0826038\tvalid_1's rmse: 0.0856473\n",
      "[325]\ttraining's rmse: 0.0825264\tvalid_1's rmse: 0.0856219\n",
      "[350]\ttraining's rmse: 0.0824533\tvalid_1's rmse: 0.0855978\n",
      "[375]\ttraining's rmse: 0.082393\tvalid_1's rmse: 0.0855789\n",
      "[400]\ttraining's rmse: 0.0823215\tvalid_1's rmse: 0.0855585\n",
      "[425]\ttraining's rmse: 0.0822616\tvalid_1's rmse: 0.0855395\n",
      "[450]\ttraining's rmse: 0.0822058\tvalid_1's rmse: 0.0855206\n",
      "[475]\ttraining's rmse: 0.0821532\tvalid_1's rmse: 0.0855041\n",
      "[500]\ttraining's rmse: 0.0821073\tvalid_1's rmse: 0.085487\n",
      "[525]\ttraining's rmse: 0.0820525\tvalid_1's rmse: 0.085471\n",
      "[550]\ttraining's rmse: 0.0820011\tvalid_1's rmse: 0.0854561\n",
      "[575]\ttraining's rmse: 0.0819545\tvalid_1's rmse: 0.085442\n",
      "[600]\ttraining's rmse: 0.0819098\tvalid_1's rmse: 0.0854305\n",
      "[625]\ttraining's rmse: 0.0818742\tvalid_1's rmse: 0.0854196\n",
      "[650]\ttraining's rmse: 0.0818254\tvalid_1's rmse: 0.0854073\n",
      "[675]\ttraining's rmse: 0.0817856\tvalid_1's rmse: 0.085396\n",
      "[700]\ttraining's rmse: 0.0817468\tvalid_1's rmse: 0.0853849\n",
      "[725]\ttraining's rmse: 0.0817105\tvalid_1's rmse: 0.0853757\n",
      "[750]\ttraining's rmse: 0.0816765\tvalid_1's rmse: 0.085367\n",
      "[775]\ttraining's rmse: 0.0816477\tvalid_1's rmse: 0.0853582\n",
      "[800]\ttraining's rmse: 0.0816132\tvalid_1's rmse: 0.0853506\n",
      "[825]\ttraining's rmse: 0.081582\tvalid_1's rmse: 0.0853431\n",
      "[850]\ttraining's rmse: 0.0815509\tvalid_1's rmse: 0.0853365\n",
      "[875]\ttraining's rmse: 0.0815238\tvalid_1's rmse: 0.0853299\n",
      "[900]\ttraining's rmse: 0.0814956\tvalid_1's rmse: 0.0853231\n",
      "[925]\ttraining's rmse: 0.081469\tvalid_1's rmse: 0.0853166\n",
      "[950]\ttraining's rmse: 0.0814432\tvalid_1's rmse: 0.0853108\n",
      "[975]\ttraining's rmse: 0.0814199\tvalid_1's rmse: 0.0853055\n",
      "[1000]\ttraining's rmse: 0.0813944\tvalid_1's rmse: 0.0853004\n",
      "[1025]\ttraining's rmse: 0.0813717\tvalid_1's rmse: 0.0852941\n",
      "[1050]\ttraining's rmse: 0.0813514\tvalid_1's rmse: 0.0852888\n",
      "[1075]\ttraining's rmse: 0.0813302\tvalid_1's rmse: 0.0852844\n",
      "[1100]\ttraining's rmse: 0.0813113\tvalid_1's rmse: 0.08528\n",
      "[1125]\ttraining's rmse: 0.0812914\tvalid_1's rmse: 0.085275\n",
      "[1150]\ttraining's rmse: 0.0812717\tvalid_1's rmse: 0.0852696\n",
      "[1175]\ttraining's rmse: 0.0812528\tvalid_1's rmse: 0.0852672\n",
      "[1200]\ttraining's rmse: 0.0812377\tvalid_1's rmse: 0.0852628\n",
      "[1225]\ttraining's rmse: 0.0812221\tvalid_1's rmse: 0.0852589\n",
      "[1250]\ttraining's rmse: 0.0812073\tvalid_1's rmse: 0.0852558\n",
      "[1275]\ttraining's rmse: 0.0811883\tvalid_1's rmse: 0.0852527\n",
      "[1300]\ttraining's rmse: 0.0811739\tvalid_1's rmse: 0.0852482\n",
      "[1325]\ttraining's rmse: 0.0811563\tvalid_1's rmse: 0.0852436\n",
      "[1350]\ttraining's rmse: 0.0811405\tvalid_1's rmse: 0.0852414\n",
      "[1375]\ttraining's rmse: 0.0811277\tvalid_1's rmse: 0.085239\n",
      "[1400]\ttraining's rmse: 0.0811161\tvalid_1's rmse: 0.085237\n",
      "[1425]\ttraining's rmse: 0.0811034\tvalid_1's rmse: 0.085235\n",
      "[1450]\ttraining's rmse: 0.0810922\tvalid_1's rmse: 0.0852333\n",
      "[1475]\ttraining's rmse: 0.0810814\tvalid_1's rmse: 0.0852311\n",
      "[1500]\ttraining's rmse: 0.0810709\tvalid_1's rmse: 0.085228\n",
      "[1525]\ttraining's rmse: 0.0810606\tvalid_1's rmse: 0.0852256\n",
      "[1550]\ttraining's rmse: 0.0810509\tvalid_1's rmse: 0.0852246\n",
      "[1575]\ttraining's rmse: 0.0810404\tvalid_1's rmse: 0.0852224\n",
      "[1600]\ttraining's rmse: 0.0810328\tvalid_1's rmse: 0.0852205\n",
      "[1625]\ttraining's rmse: 0.0810267\tvalid_1's rmse: 0.0852182\n",
      "[1650]\ttraining's rmse: 0.0810189\tvalid_1's rmse: 0.0852152\n",
      "[1675]\ttraining's rmse: 0.0810126\tvalid_1's rmse: 0.0852137\n",
      "[1700]\ttraining's rmse: 0.0810068\tvalid_1's rmse: 0.0852117\n",
      "[1725]\ttraining's rmse: 0.081\tvalid_1's rmse: 0.0852098\n",
      "[1750]\ttraining's rmse: 0.0809924\tvalid_1's rmse: 0.0852068\n",
      "[1775]\ttraining's rmse: 0.080987\tvalid_1's rmse: 0.0852055\n",
      "[1800]\ttraining's rmse: 0.0809817\tvalid_1's rmse: 0.0852035\n",
      "[1825]\ttraining's rmse: 0.0809745\tvalid_1's rmse: 0.0852022\n",
      "[1850]\ttraining's rmse: 0.0809695\tvalid_1's rmse: 0.0852005\n",
      "[1875]\ttraining's rmse: 0.0809657\tvalid_1's rmse: 0.0851994\n",
      "[1900]\ttraining's rmse: 0.0809623\tvalid_1's rmse: 0.0851982\n",
      "[1925]\ttraining's rmse: 0.0809574\tvalid_1's rmse: 0.0851968\n",
      "[1950]\ttraining's rmse: 0.0809541\tvalid_1's rmse: 0.0851955\n",
      "[1975]\ttraining's rmse: 0.0809496\tvalid_1's rmse: 0.0851945\n",
      "[2000]\ttraining's rmse: 0.0809447\tvalid_1's rmse: 0.085193\n",
      "[2025]\ttraining's rmse: 0.0809413\tvalid_1's rmse: 0.0851911\n",
      "[2050]\ttraining's rmse: 0.0809366\tvalid_1's rmse: 0.0851901\n",
      "[2075]\ttraining's rmse: 0.0809338\tvalid_1's rmse: 0.0851886\n",
      "[2100]\ttraining's rmse: 0.080929\tvalid_1's rmse: 0.0851876\n",
      "[2125]\ttraining's rmse: 0.0809263\tvalid_1's rmse: 0.085186\n",
      "[2150]\ttraining's rmse: 0.0809242\tvalid_1's rmse: 0.0851859\n",
      "[2175]\ttraining's rmse: 0.0809213\tvalid_1's rmse: 0.0851849\n",
      "[2200]\ttraining's rmse: 0.0809186\tvalid_1's rmse: 0.0851844\n",
      "[2225]\ttraining's rmse: 0.0809146\tvalid_1's rmse: 0.0851838\n",
      "[2250]\ttraining's rmse: 0.0809112\tvalid_1's rmse: 0.0851831\n",
      "[2275]\ttraining's rmse: 0.0809075\tvalid_1's rmse: 0.0851821\n",
      "[2300]\ttraining's rmse: 0.0809044\tvalid_1's rmse: 0.0851815\n",
      "[2325]\ttraining's rmse: 0.0809024\tvalid_1's rmse: 0.0851804\n",
      "[2350]\ttraining's rmse: 0.0809\tvalid_1's rmse: 0.0851795\n",
      "[2375]\ttraining's rmse: 0.0808967\tvalid_1's rmse: 0.0851791\n",
      "[2400]\ttraining's rmse: 0.0808936\tvalid_1's rmse: 0.0851789\n",
      "[2425]\ttraining's rmse: 0.0808892\tvalid_1's rmse: 0.0851778\n",
      "[2450]\ttraining's rmse: 0.0808871\tvalid_1's rmse: 0.0851778\n",
      "[2475]\ttraining's rmse: 0.0808848\tvalid_1's rmse: 0.0851774\n",
      "[2500]\ttraining's rmse: 0.0808818\tvalid_1's rmse: 0.085177\n",
      "[2525]\ttraining's rmse: 0.0808796\tvalid_1's rmse: 0.085177\n",
      "Early stopping, best iteration is:\n",
      "[2492]\ttraining's rmse: 0.0808829\tvalid_1's rmse: 0.0851768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0838826\tvalid_1's rmse: 0.0858046\n",
      "[50]\ttraining's rmse: 0.0837651\tvalid_1's rmse: 0.0857527\n",
      "[75]\ttraining's rmse: 0.0836444\tvalid_1's rmse: 0.0857012\n",
      "[100]\ttraining's rmse: 0.0835367\tvalid_1's rmse: 0.0856556\n",
      "[125]\ttraining's rmse: 0.083425\tvalid_1's rmse: 0.0856105\n",
      "[150]\ttraining's rmse: 0.0833246\tvalid_1's rmse: 0.0855674\n",
      "[175]\ttraining's rmse: 0.0832372\tvalid_1's rmse: 0.0855322\n",
      "[200]\ttraining's rmse: 0.083143\tvalid_1's rmse: 0.0854959\n",
      "[225]\ttraining's rmse: 0.0830537\tvalid_1's rmse: 0.0854622\n",
      "[250]\ttraining's rmse: 0.0829774\tvalid_1's rmse: 0.0854321\n",
      "[275]\ttraining's rmse: 0.0829049\tvalid_1's rmse: 0.0854032\n",
      "[300]\ttraining's rmse: 0.0828357\tvalid_1's rmse: 0.0853767\n",
      "[325]\ttraining's rmse: 0.0827637\tvalid_1's rmse: 0.0853512\n",
      "[350]\ttraining's rmse: 0.0826941\tvalid_1's rmse: 0.0853259\n",
      "[375]\ttraining's rmse: 0.0826361\tvalid_1's rmse: 0.0853048\n",
      "[400]\ttraining's rmse: 0.0825749\tvalid_1's rmse: 0.0852853\n",
      "[425]\ttraining's rmse: 0.0825194\tvalid_1's rmse: 0.0852665\n",
      "[450]\ttraining's rmse: 0.0824674\tvalid_1's rmse: 0.0852477\n",
      "[475]\ttraining's rmse: 0.0824167\tvalid_1's rmse: 0.085231\n",
      "[500]\ttraining's rmse: 0.0823743\tvalid_1's rmse: 0.0852153\n",
      "[525]\ttraining's rmse: 0.0823211\tvalid_1's rmse: 0.085199\n",
      "[550]\ttraining's rmse: 0.0822718\tvalid_1's rmse: 0.0851851\n",
      "[575]\ttraining's rmse: 0.0822287\tvalid_1's rmse: 0.0851713\n",
      "[600]\ttraining's rmse: 0.0821862\tvalid_1's rmse: 0.0851588\n",
      "[625]\ttraining's rmse: 0.0821514\tvalid_1's rmse: 0.0851474\n",
      "[650]\ttraining's rmse: 0.0821087\tvalid_1's rmse: 0.0851349\n",
      "[675]\ttraining's rmse: 0.0820664\tvalid_1's rmse: 0.0851229\n",
      "[700]\ttraining's rmse: 0.0820283\tvalid_1's rmse: 0.0851112\n",
      "[725]\ttraining's rmse: 0.0819927\tvalid_1's rmse: 0.0851009\n",
      "[750]\ttraining's rmse: 0.0819593\tvalid_1's rmse: 0.0850922\n",
      "[775]\ttraining's rmse: 0.0819335\tvalid_1's rmse: 0.0850839\n",
      "[800]\ttraining's rmse: 0.0818981\tvalid_1's rmse: 0.0850759\n",
      "[825]\ttraining's rmse: 0.0818694\tvalid_1's rmse: 0.0850677\n",
      "[850]\ttraining's rmse: 0.0818411\tvalid_1's rmse: 0.085061\n",
      "[875]\ttraining's rmse: 0.0818137\tvalid_1's rmse: 0.085054\n",
      "[900]\ttraining's rmse: 0.0817862\tvalid_1's rmse: 0.0850466\n",
      "[925]\ttraining's rmse: 0.0817595\tvalid_1's rmse: 0.0850404\n",
      "[950]\ttraining's rmse: 0.0817335\tvalid_1's rmse: 0.0850347\n",
      "[975]\ttraining's rmse: 0.0817103\tvalid_1's rmse: 0.0850286\n",
      "[1000]\ttraining's rmse: 0.081688\tvalid_1's rmse: 0.0850229\n",
      "[1025]\ttraining's rmse: 0.0816616\tvalid_1's rmse: 0.085017\n",
      "[1050]\ttraining's rmse: 0.0816419\tvalid_1's rmse: 0.0850118\n",
      "[1075]\ttraining's rmse: 0.0816194\tvalid_1's rmse: 0.0850084\n",
      "[1100]\ttraining's rmse: 0.0816023\tvalid_1's rmse: 0.0850037\n",
      "[1125]\ttraining's rmse: 0.081583\tvalid_1's rmse: 0.0850004\n",
      "[1150]\ttraining's rmse: 0.0815629\tvalid_1's rmse: 0.0849962\n",
      "[1175]\ttraining's rmse: 0.0815466\tvalid_1's rmse: 0.0849926\n",
      "[1200]\ttraining's rmse: 0.0815297\tvalid_1's rmse: 0.0849887\n",
      "[1225]\ttraining's rmse: 0.0815147\tvalid_1's rmse: 0.0849863\n",
      "[1250]\ttraining's rmse: 0.0815011\tvalid_1's rmse: 0.0849842\n",
      "[1275]\ttraining's rmse: 0.0814843\tvalid_1's rmse: 0.0849819\n",
      "[1300]\ttraining's rmse: 0.0814712\tvalid_1's rmse: 0.0849792\n",
      "[1325]\ttraining's rmse: 0.0814593\tvalid_1's rmse: 0.0849778\n",
      "[1350]\ttraining's rmse: 0.0814446\tvalid_1's rmse: 0.0849758\n",
      "[1375]\ttraining's rmse: 0.0814329\tvalid_1's rmse: 0.0849748\n",
      "[1400]\ttraining's rmse: 0.0814214\tvalid_1's rmse: 0.0849717\n",
      "[1425]\ttraining's rmse: 0.0814107\tvalid_1's rmse: 0.0849702\n",
      "[1450]\ttraining's rmse: 0.0814003\tvalid_1's rmse: 0.0849687\n",
      "[1475]\ttraining's rmse: 0.0813905\tvalid_1's rmse: 0.084967\n",
      "[1500]\ttraining's rmse: 0.081382\tvalid_1's rmse: 0.0849657\n",
      "[1525]\ttraining's rmse: 0.0813744\tvalid_1's rmse: 0.0849642\n",
      "[1550]\ttraining's rmse: 0.0813667\tvalid_1's rmse: 0.084964\n",
      "[1575]\ttraining's rmse: 0.0813577\tvalid_1's rmse: 0.0849625\n",
      "[1600]\ttraining's rmse: 0.08135\tvalid_1's rmse: 0.0849614\n",
      "[1625]\ttraining's rmse: 0.0813426\tvalid_1's rmse: 0.08496\n",
      "[1650]\ttraining's rmse: 0.0813353\tvalid_1's rmse: 0.0849589\n",
      "[1675]\ttraining's rmse: 0.0813287\tvalid_1's rmse: 0.0849575\n",
      "[1700]\ttraining's rmse: 0.0813227\tvalid_1's rmse: 0.0849559\n",
      "[1725]\ttraining's rmse: 0.081316\tvalid_1's rmse: 0.0849545\n",
      "[1750]\ttraining's rmse: 0.0813089\tvalid_1's rmse: 0.0849538\n",
      "[1775]\ttraining's rmse: 0.0813039\tvalid_1's rmse: 0.0849535\n",
      "[1800]\ttraining's rmse: 0.0812986\tvalid_1's rmse: 0.0849529\n",
      "[1825]\ttraining's rmse: 0.0812931\tvalid_1's rmse: 0.0849521\n",
      "[1850]\ttraining's rmse: 0.0812873\tvalid_1's rmse: 0.0849515\n",
      "[1875]\ttraining's rmse: 0.0812823\tvalid_1's rmse: 0.084951\n",
      "[1900]\ttraining's rmse: 0.0812781\tvalid_1's rmse: 0.0849504\n",
      "[1925]\ttraining's rmse: 0.0812742\tvalid_1's rmse: 0.0849502\n",
      "[1950]\ttraining's rmse: 0.0812698\tvalid_1's rmse: 0.0849493\n",
      "[1975]\ttraining's rmse: 0.0812656\tvalid_1's rmse: 0.0849486\n",
      "[2000]\ttraining's rmse: 0.0812615\tvalid_1's rmse: 0.0849478\n",
      "[2025]\ttraining's rmse: 0.0812564\tvalid_1's rmse: 0.0849468\n",
      "[2050]\ttraining's rmse: 0.0812527\tvalid_1's rmse: 0.0849467\n",
      "[2075]\ttraining's rmse: 0.0812492\tvalid_1's rmse: 0.0849457\n",
      "[2100]\ttraining's rmse: 0.0812458\tvalid_1's rmse: 0.0849453\n",
      "[2125]\ttraining's rmse: 0.0812428\tvalid_1's rmse: 0.0849448\n",
      "[2150]\ttraining's rmse: 0.0812387\tvalid_1's rmse: 0.0849447\n",
      "[2175]\ttraining's rmse: 0.081235\tvalid_1's rmse: 0.0849446\n",
      "[2200]\ttraining's rmse: 0.0812314\tvalid_1's rmse: 0.084944\n",
      "[2225]\ttraining's rmse: 0.0812282\tvalid_1's rmse: 0.0849434\n",
      "[2250]\ttraining's rmse: 0.0812251\tvalid_1's rmse: 0.0849435\n",
      "Early stopping, best iteration is:\n",
      "[2215]\ttraining's rmse: 0.0812291\tvalid_1's rmse: 0.0849432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0858129\tvalid_1's rmse: 0.0818865\n",
      "[50]\ttraining's rmse: 0.0857053\tvalid_1's rmse: 0.0818385\n",
      "[75]\ttraining's rmse: 0.0855912\tvalid_1's rmse: 0.0817912\n",
      "[100]\ttraining's rmse: 0.085489\tvalid_1's rmse: 0.0817507\n",
      "[125]\ttraining's rmse: 0.0853837\tvalid_1's rmse: 0.081709\n",
      "[150]\ttraining's rmse: 0.0852858\tvalid_1's rmse: 0.0816704\n",
      "[175]\ttraining's rmse: 0.0852025\tvalid_1's rmse: 0.0816358\n",
      "[200]\ttraining's rmse: 0.0851134\tvalid_1's rmse: 0.081605\n",
      "[225]\ttraining's rmse: 0.0850266\tvalid_1's rmse: 0.0815735\n",
      "[250]\ttraining's rmse: 0.0849548\tvalid_1's rmse: 0.0815447\n",
      "[275]\ttraining's rmse: 0.0848871\tvalid_1's rmse: 0.0815216\n",
      "[300]\ttraining's rmse: 0.084821\tvalid_1's rmse: 0.0814975\n",
      "[325]\ttraining's rmse: 0.0847527\tvalid_1's rmse: 0.0814786\n",
      "[350]\ttraining's rmse: 0.0846873\tvalid_1's rmse: 0.0814574\n",
      "[375]\ttraining's rmse: 0.084633\tvalid_1's rmse: 0.0814405\n",
      "[400]\ttraining's rmse: 0.0845763\tvalid_1's rmse: 0.0814266\n",
      "[425]\ttraining's rmse: 0.0845239\tvalid_1's rmse: 0.0814112\n",
      "[450]\ttraining's rmse: 0.0844728\tvalid_1's rmse: 0.0813966\n",
      "[475]\ttraining's rmse: 0.0844249\tvalid_1's rmse: 0.0813862\n",
      "[500]\ttraining's rmse: 0.0843858\tvalid_1's rmse: 0.0813725\n",
      "[525]\ttraining's rmse: 0.0843337\tvalid_1's rmse: 0.0813587\n",
      "[550]\ttraining's rmse: 0.0842869\tvalid_1's rmse: 0.0813451\n",
      "[575]\ttraining's rmse: 0.0842436\tvalid_1's rmse: 0.0813341\n",
      "[600]\ttraining's rmse: 0.084201\tvalid_1's rmse: 0.0813283\n",
      "[625]\ttraining's rmse: 0.0841686\tvalid_1's rmse: 0.0813189\n",
      "[650]\ttraining's rmse: 0.0841269\tvalid_1's rmse: 0.0813128\n",
      "[675]\ttraining's rmse: 0.0840832\tvalid_1's rmse: 0.0813155\n",
      "[700]\ttraining's rmse: 0.0840455\tvalid_1's rmse: 0.0813064\n",
      "[725]\ttraining's rmse: 0.0840106\tvalid_1's rmse: 0.0813105\n",
      "[750]\ttraining's rmse: 0.0839764\tvalid_1's rmse: 0.0813086\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 0.0840316\tvalid_1's rmse: 0.0813039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0816924\tvalid_1's rmse: 0.0841384\n",
      "[50]\ttraining's rmse: 0.0815688\tvalid_1's rmse: 0.0840852\n",
      "[75]\ttraining's rmse: 0.0814451\tvalid_1's rmse: 0.0840331\n",
      "[100]\ttraining's rmse: 0.081333\tvalid_1's rmse: 0.0839897\n",
      "[125]\ttraining's rmse: 0.0812191\tvalid_1's rmse: 0.0839449\n",
      "[150]\ttraining's rmse: 0.0811182\tvalid_1's rmse: 0.0839035\n",
      "[175]\ttraining's rmse: 0.0810334\tvalid_1's rmse: 0.0838667\n",
      "[200]\ttraining's rmse: 0.0809401\tvalid_1's rmse: 0.0838291\n",
      "[225]\ttraining's rmse: 0.0808514\tvalid_1's rmse: 0.083794\n",
      "[250]\ttraining's rmse: 0.0807784\tvalid_1's rmse: 0.083764\n",
      "[275]\ttraining's rmse: 0.0807061\tvalid_1's rmse: 0.0837353\n",
      "[300]\ttraining's rmse: 0.0806348\tvalid_1's rmse: 0.083709\n",
      "[325]\ttraining's rmse: 0.0805617\tvalid_1's rmse: 0.0836822\n",
      "[350]\ttraining's rmse: 0.0804923\tvalid_1's rmse: 0.0836573\n",
      "[375]\ttraining's rmse: 0.0804365\tvalid_1's rmse: 0.0836364\n",
      "[400]\ttraining's rmse: 0.0803774\tvalid_1's rmse: 0.0836158\n",
      "[425]\ttraining's rmse: 0.0803214\tvalid_1's rmse: 0.0835945\n",
      "[450]\ttraining's rmse: 0.0802729\tvalid_1's rmse: 0.0835756\n",
      "[475]\ttraining's rmse: 0.0802288\tvalid_1's rmse: 0.0835566\n",
      "[500]\ttraining's rmse: 0.0801855\tvalid_1's rmse: 0.0835394\n",
      "[525]\ttraining's rmse: 0.0801355\tvalid_1's rmse: 0.083524\n",
      "[550]\ttraining's rmse: 0.080088\tvalid_1's rmse: 0.083509\n",
      "[575]\ttraining's rmse: 0.0800434\tvalid_1's rmse: 0.0834953\n",
      "[600]\ttraining's rmse: 0.0800015\tvalid_1's rmse: 0.0834814\n",
      "[625]\ttraining's rmse: 0.0799678\tvalid_1's rmse: 0.0834697\n",
      "[650]\ttraining's rmse: 0.0799287\tvalid_1's rmse: 0.0834564\n",
      "[675]\ttraining's rmse: 0.0798873\tvalid_1's rmse: 0.0834435\n",
      "[700]\ttraining's rmse: 0.0798526\tvalid_1's rmse: 0.0834321\n",
      "[725]\ttraining's rmse: 0.0798196\tvalid_1's rmse: 0.0834227\n",
      "[750]\ttraining's rmse: 0.0797867\tvalid_1's rmse: 0.0834136\n",
      "[775]\ttraining's rmse: 0.0797611\tvalid_1's rmse: 0.0834038\n",
      "[800]\ttraining's rmse: 0.0797292\tvalid_1's rmse: 0.0833952\n",
      "[825]\ttraining's rmse: 0.0797001\tvalid_1's rmse: 0.0833857\n",
      "[850]\ttraining's rmse: 0.0796709\tvalid_1's rmse: 0.0833785\n",
      "[875]\ttraining's rmse: 0.079646\tvalid_1's rmse: 0.0833713\n",
      "[900]\ttraining's rmse: 0.0796179\tvalid_1's rmse: 0.0833639\n",
      "[925]\ttraining's rmse: 0.0795937\tvalid_1's rmse: 0.0833568\n",
      "[950]\ttraining's rmse: 0.0795691\tvalid_1's rmse: 0.0833501\n",
      "[975]\ttraining's rmse: 0.0795469\tvalid_1's rmse: 0.0833437\n",
      "[1000]\ttraining's rmse: 0.0795255\tvalid_1's rmse: 0.0833376\n",
      "[1025]\ttraining's rmse: 0.0795021\tvalid_1's rmse: 0.0833307\n",
      "[1050]\ttraining's rmse: 0.0794841\tvalid_1's rmse: 0.0833243\n",
      "[1075]\ttraining's rmse: 0.0794639\tvalid_1's rmse: 0.0833193\n",
      "[1100]\ttraining's rmse: 0.0794477\tvalid_1's rmse: 0.0833138\n",
      "[1125]\ttraining's rmse: 0.0794314\tvalid_1's rmse: 0.0833076\n",
      "[1150]\ttraining's rmse: 0.079417\tvalid_1's rmse: 0.0833027\n",
      "[1175]\ttraining's rmse: 0.0794036\tvalid_1's rmse: 0.0832979\n",
      "[1200]\ttraining's rmse: 0.0793887\tvalid_1's rmse: 0.0832922\n",
      "[1225]\ttraining's rmse: 0.0793747\tvalid_1's rmse: 0.0832882\n",
      "[1250]\ttraining's rmse: 0.0793623\tvalid_1's rmse: 0.0832845\n",
      "[1275]\ttraining's rmse: 0.079347\tvalid_1's rmse: 0.0832812\n",
      "[1300]\ttraining's rmse: 0.0793343\tvalid_1's rmse: 0.0832762\n",
      "[1325]\ttraining's rmse: 0.0793203\tvalid_1's rmse: 0.0832731\n",
      "[1350]\ttraining's rmse: 0.0793076\tvalid_1's rmse: 0.0832715\n",
      "[1375]\ttraining's rmse: 0.0792948\tvalid_1's rmse: 0.0832686\n",
      "[1400]\ttraining's rmse: 0.0792855\tvalid_1's rmse: 0.0832649\n",
      "[1425]\ttraining's rmse: 0.0792697\tvalid_1's rmse: 0.0832625\n",
      "[1450]\ttraining's rmse: 0.0792588\tvalid_1's rmse: 0.083261\n",
      "[1475]\ttraining's rmse: 0.0792513\tvalid_1's rmse: 0.0832592\n",
      "[1500]\ttraining's rmse: 0.0792437\tvalid_1's rmse: 0.0832572\n",
      "[1525]\ttraining's rmse: 0.0792358\tvalid_1's rmse: 0.0832552\n",
      "[1550]\ttraining's rmse: 0.0792264\tvalid_1's rmse: 0.083253\n",
      "[1575]\ttraining's rmse: 0.0792186\tvalid_1's rmse: 0.0832511\n",
      "[1600]\ttraining's rmse: 0.0792117\tvalid_1's rmse: 0.0832476\n",
      "[1625]\ttraining's rmse: 0.0792048\tvalid_1's rmse: 0.083245\n",
      "[1650]\ttraining's rmse: 0.0791982\tvalid_1's rmse: 0.0832429\n",
      "[1675]\ttraining's rmse: 0.0791938\tvalid_1's rmse: 0.0832416\n",
      "[1700]\ttraining's rmse: 0.0791884\tvalid_1's rmse: 0.083239\n",
      "[1725]\ttraining's rmse: 0.0791834\tvalid_1's rmse: 0.0832373\n",
      "[1750]\ttraining's rmse: 0.0791744\tvalid_1's rmse: 0.0832349\n",
      "[1775]\ttraining's rmse: 0.0791673\tvalid_1's rmse: 0.0832335\n",
      "[1800]\ttraining's rmse: 0.0791623\tvalid_1's rmse: 0.0832311\n",
      "[1825]\ttraining's rmse: 0.0791584\tvalid_1's rmse: 0.083229\n",
      "[1850]\ttraining's rmse: 0.079154\tvalid_1's rmse: 0.0832267\n",
      "[1875]\ttraining's rmse: 0.0791493\tvalid_1's rmse: 0.0832261\n",
      "[1900]\ttraining's rmse: 0.0791454\tvalid_1's rmse: 0.0832246\n",
      "[1925]\ttraining's rmse: 0.07914\tvalid_1's rmse: 0.0832234\n",
      "[1950]\ttraining's rmse: 0.0791368\tvalid_1's rmse: 0.0832212\n",
      "[1975]\ttraining's rmse: 0.0791335\tvalid_1's rmse: 0.08322\n",
      "[2000]\ttraining's rmse: 0.07913\tvalid_1's rmse: 0.0832177\n",
      "[2025]\ttraining's rmse: 0.0791257\tvalid_1's rmse: 0.0832162\n",
      "[2050]\ttraining's rmse: 0.079122\tvalid_1's rmse: 0.0832141\n",
      "[2075]\ttraining's rmse: 0.0791198\tvalid_1's rmse: 0.0832132\n",
      "[2100]\ttraining's rmse: 0.0791163\tvalid_1's rmse: 0.0832117\n",
      "[2125]\ttraining's rmse: 0.0791134\tvalid_1's rmse: 0.0832116\n",
      "[2150]\ttraining's rmse: 0.07911\tvalid_1's rmse: 0.0832112\n",
      "[2175]\ttraining's rmse: 0.0791073\tvalid_1's rmse: 0.0832111\n",
      "[2200]\ttraining's rmse: 0.0791046\tvalid_1's rmse: 0.0832107\n",
      "[2225]\ttraining's rmse: 0.0791023\tvalid_1's rmse: 0.08321\n",
      "[2250]\ttraining's rmse: 0.0790993\tvalid_1's rmse: 0.0832087\n",
      "[2275]\ttraining's rmse: 0.0790966\tvalid_1's rmse: 0.0832074\n",
      "[2300]\ttraining's rmse: 0.0790939\tvalid_1's rmse: 0.0832068\n",
      "[2325]\ttraining's rmse: 0.0790904\tvalid_1's rmse: 0.0832056\n",
      "[2350]\ttraining's rmse: 0.0790872\tvalid_1's rmse: 0.0832046\n",
      "[2375]\ttraining's rmse: 0.0790847\tvalid_1's rmse: 0.0832041\n",
      "[2400]\ttraining's rmse: 0.0790821\tvalid_1's rmse: 0.0832034\n",
      "[2425]\ttraining's rmse: 0.0790808\tvalid_1's rmse: 0.0832028\n",
      "[2450]\ttraining's rmse: 0.0790793\tvalid_1's rmse: 0.0832023\n",
      "[2475]\ttraining's rmse: 0.0790768\tvalid_1's rmse: 0.0832019\n",
      "[2500]\ttraining's rmse: 0.0790754\tvalid_1's rmse: 0.0832018\n",
      "[2525]\ttraining's rmse: 0.0790738\tvalid_1's rmse: 0.0832011\n",
      "[2550]\ttraining's rmse: 0.0790712\tvalid_1's rmse: 0.0832008\n",
      "[2575]\ttraining's rmse: 0.0790684\tvalid_1's rmse: 0.0832003\n",
      "[2600]\ttraining's rmse: 0.0790663\tvalid_1's rmse: 0.0831999\n",
      "[2625]\ttraining's rmse: 0.0790649\tvalid_1's rmse: 0.0831987\n",
      "[2650]\ttraining's rmse: 0.0790618\tvalid_1's rmse: 0.0831983\n",
      "[2675]\ttraining's rmse: 0.07906\tvalid_1's rmse: 0.0831984\n",
      "Early stopping, best iteration is:\n",
      "[2633]\ttraining's rmse: 0.0790639\tvalid_1's rmse: 0.0831981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0817914\tvalid_1's rmse: 0.0839459\n",
      "[50]\ttraining's rmse: 0.0816795\tvalid_1's rmse: 0.0838925\n",
      "[75]\ttraining's rmse: 0.0815649\tvalid_1's rmse: 0.0838393\n",
      "[100]\ttraining's rmse: 0.0814638\tvalid_1's rmse: 0.0837923\n",
      "[125]\ttraining's rmse: 0.0813561\tvalid_1's rmse: 0.0837458\n",
      "[150]\ttraining's rmse: 0.0812603\tvalid_1's rmse: 0.0837035\n",
      "[175]\ttraining's rmse: 0.0811791\tvalid_1's rmse: 0.0836684\n",
      "[200]\ttraining's rmse: 0.0810901\tvalid_1's rmse: 0.0836331\n",
      "[225]\ttraining's rmse: 0.081004\tvalid_1's rmse: 0.0835993\n",
      "[250]\ttraining's rmse: 0.0809328\tvalid_1's rmse: 0.0835686\n",
      "[275]\ttraining's rmse: 0.0808641\tvalid_1's rmse: 0.0835403\n",
      "[300]\ttraining's rmse: 0.0807962\tvalid_1's rmse: 0.0835143\n",
      "[325]\ttraining's rmse: 0.0807237\tvalid_1's rmse: 0.0834871\n",
      "[350]\ttraining's rmse: 0.0806543\tvalid_1's rmse: 0.0834625\n",
      "[375]\ttraining's rmse: 0.0806002\tvalid_1's rmse: 0.0834415\n",
      "[400]\ttraining's rmse: 0.0805415\tvalid_1's rmse: 0.0834226\n",
      "[425]\ttraining's rmse: 0.0804867\tvalid_1's rmse: 0.083403\n",
      "[450]\ttraining's rmse: 0.0804372\tvalid_1's rmse: 0.0833849\n",
      "[475]\ttraining's rmse: 0.0803897\tvalid_1's rmse: 0.0833675\n",
      "[500]\ttraining's rmse: 0.0803495\tvalid_1's rmse: 0.0833523\n",
      "[525]\ttraining's rmse: 0.0802994\tvalid_1's rmse: 0.0833371\n",
      "[550]\ttraining's rmse: 0.0802506\tvalid_1's rmse: 0.0833228\n",
      "[575]\ttraining's rmse: 0.0802068\tvalid_1's rmse: 0.0833092\n",
      "[600]\ttraining's rmse: 0.0801642\tvalid_1's rmse: 0.0832973\n",
      "[625]\ttraining's rmse: 0.0801313\tvalid_1's rmse: 0.0832855\n",
      "[650]\ttraining's rmse: 0.0800884\tvalid_1's rmse: 0.0832734\n",
      "[675]\ttraining's rmse: 0.0800473\tvalid_1's rmse: 0.0832621\n",
      "[700]\ttraining's rmse: 0.0800112\tvalid_1's rmse: 0.0832531\n",
      "[725]\ttraining's rmse: 0.0799784\tvalid_1's rmse: 0.083244\n",
      "[750]\ttraining's rmse: 0.0799446\tvalid_1's rmse: 0.0832349\n",
      "[775]\ttraining's rmse: 0.0799187\tvalid_1's rmse: 0.0832266\n",
      "[800]\ttraining's rmse: 0.0798855\tvalid_1's rmse: 0.0832193\n",
      "[825]\ttraining's rmse: 0.0798576\tvalid_1's rmse: 0.0832111\n",
      "[850]\ttraining's rmse: 0.0798301\tvalid_1's rmse: 0.0832045\n",
      "[875]\ttraining's rmse: 0.0798051\tvalid_1's rmse: 0.0831984\n",
      "[900]\ttraining's rmse: 0.0797772\tvalid_1's rmse: 0.0831915\n",
      "[925]\ttraining's rmse: 0.0797514\tvalid_1's rmse: 0.0831862\n",
      "[950]\ttraining's rmse: 0.0797281\tvalid_1's rmse: 0.0831804\n",
      "[975]\ttraining's rmse: 0.0797057\tvalid_1's rmse: 0.0831751\n",
      "[1000]\ttraining's rmse: 0.0796862\tvalid_1's rmse: 0.0831705\n",
      "[1025]\ttraining's rmse: 0.079663\tvalid_1's rmse: 0.0831656\n",
      "[1050]\ttraining's rmse: 0.0796436\tvalid_1's rmse: 0.0831617\n",
      "[1075]\ttraining's rmse: 0.0796236\tvalid_1's rmse: 0.0831579\n",
      "[1100]\ttraining's rmse: 0.079608\tvalid_1's rmse: 0.0831536\n",
      "[1125]\ttraining's rmse: 0.0795895\tvalid_1's rmse: 0.0831501\n",
      "[1150]\ttraining's rmse: 0.079572\tvalid_1's rmse: 0.0831461\n",
      "[1175]\ttraining's rmse: 0.0795551\tvalid_1's rmse: 0.0831428\n",
      "[1200]\ttraining's rmse: 0.0795385\tvalid_1's rmse: 0.0831396\n",
      "[1225]\ttraining's rmse: 0.079522\tvalid_1's rmse: 0.0831368\n",
      "[1250]\ttraining's rmse: 0.0795083\tvalid_1's rmse: 0.0831342\n",
      "[1275]\ttraining's rmse: 0.0794926\tvalid_1's rmse: 0.0831316\n",
      "[1300]\ttraining's rmse: 0.0794793\tvalid_1's rmse: 0.0831281\n",
      "[1325]\ttraining's rmse: 0.0794646\tvalid_1's rmse: 0.0831257\n",
      "[1350]\ttraining's rmse: 0.0794517\tvalid_1's rmse: 0.0831237\n",
      "[1375]\ttraining's rmse: 0.0794406\tvalid_1's rmse: 0.083122\n",
      "[1400]\ttraining's rmse: 0.0794314\tvalid_1's rmse: 0.0831194\n",
      "[1425]\ttraining's rmse: 0.0794206\tvalid_1's rmse: 0.0831181\n",
      "[1450]\ttraining's rmse: 0.0794112\tvalid_1's rmse: 0.0831171\n",
      "[1475]\ttraining's rmse: 0.0794005\tvalid_1's rmse: 0.0831151\n",
      "[1500]\ttraining's rmse: 0.0793929\tvalid_1's rmse: 0.0831137\n",
      "[1525]\ttraining's rmse: 0.0793834\tvalid_1's rmse: 0.083112\n",
      "[1550]\ttraining's rmse: 0.0793736\tvalid_1's rmse: 0.0831108\n",
      "[1575]\ttraining's rmse: 0.079367\tvalid_1's rmse: 0.0831093\n",
      "[1600]\ttraining's rmse: 0.0793595\tvalid_1's rmse: 0.0831087\n",
      "[1625]\ttraining's rmse: 0.079352\tvalid_1's rmse: 0.0831077\n",
      "[1650]\ttraining's rmse: 0.0793468\tvalid_1's rmse: 0.0831069\n",
      "[1675]\ttraining's rmse: 0.079341\tvalid_1's rmse: 0.0831053\n",
      "[1700]\ttraining's rmse: 0.0793337\tvalid_1's rmse: 0.0831041\n",
      "[1725]\ttraining's rmse: 0.0793278\tvalid_1's rmse: 0.0831029\n",
      "[1750]\ttraining's rmse: 0.0793213\tvalid_1's rmse: 0.0831016\n",
      "[1775]\ttraining's rmse: 0.0793147\tvalid_1's rmse: 0.0831007\n",
      "[1800]\ttraining's rmse: 0.079309\tvalid_1's rmse: 0.0831001\n",
      "[1825]\ttraining's rmse: 0.0793044\tvalid_1's rmse: 0.0830992\n",
      "[1850]\ttraining's rmse: 0.0792988\tvalid_1's rmse: 0.0830987\n",
      "[1875]\ttraining's rmse: 0.0792944\tvalid_1's rmse: 0.0830984\n",
      "[1900]\ttraining's rmse: 0.0792895\tvalid_1's rmse: 0.0830983\n",
      "[1925]\ttraining's rmse: 0.0792859\tvalid_1's rmse: 0.0830975\n",
      "[1950]\ttraining's rmse: 0.0792818\tvalid_1's rmse: 0.0830967\n",
      "[1975]\ttraining's rmse: 0.0792778\tvalid_1's rmse: 0.0830956\n",
      "[2000]\ttraining's rmse: 0.0792721\tvalid_1's rmse: 0.083095\n",
      "[2025]\ttraining's rmse: 0.0792691\tvalid_1's rmse: 0.0830945\n",
      "[2050]\ttraining's rmse: 0.0792656\tvalid_1's rmse: 0.083094\n",
      "[2075]\ttraining's rmse: 0.0792626\tvalid_1's rmse: 0.0830935\n",
      "[2100]\ttraining's rmse: 0.0792595\tvalid_1's rmse: 0.0830938\n",
      "Early stopping, best iteration is:\n",
      "[2072]\ttraining's rmse: 0.0792628\tvalid_1's rmse: 0.0830935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0839234\tvalid_1's rmse: 0.0796083\n",
      "[50]\ttraining's rmse: 0.0838136\tvalid_1's rmse: 0.0795601\n",
      "[75]\ttraining's rmse: 0.0837011\tvalid_1's rmse: 0.079512\n",
      "[100]\ttraining's rmse: 0.0835997\tvalid_1's rmse: 0.0794707\n",
      "[125]\ttraining's rmse: 0.0834977\tvalid_1's rmse: 0.0794301\n",
      "[150]\ttraining's rmse: 0.0834028\tvalid_1's rmse: 0.0793943\n",
      "[175]\ttraining's rmse: 0.0833247\tvalid_1's rmse: 0.0793634\n",
      "[200]\ttraining's rmse: 0.0832377\tvalid_1's rmse: 0.0793316\n",
      "[225]\ttraining's rmse: 0.0831558\tvalid_1's rmse: 0.0793017\n",
      "[250]\ttraining's rmse: 0.0830871\tvalid_1's rmse: 0.0792748\n",
      "[275]\ttraining's rmse: 0.0830223\tvalid_1's rmse: 0.0792494\n",
      "[300]\ttraining's rmse: 0.0829582\tvalid_1's rmse: 0.0792254\n",
      "[325]\ttraining's rmse: 0.0828946\tvalid_1's rmse: 0.0792044\n",
      "[350]\ttraining's rmse: 0.0828285\tvalid_1's rmse: 0.0791829\n",
      "[375]\ttraining's rmse: 0.0827763\tvalid_1's rmse: 0.0791651\n",
      "[400]\ttraining's rmse: 0.0827199\tvalid_1's rmse: 0.0791575\n",
      "[425]\ttraining's rmse: 0.0826672\tvalid_1's rmse: 0.0791409\n",
      "[450]\ttraining's rmse: 0.0826201\tvalid_1's rmse: 0.0791255\n",
      "[475]\ttraining's rmse: 0.0825747\tvalid_1's rmse: 0.0791172\n",
      "[500]\ttraining's rmse: 0.0825356\tvalid_1's rmse: 0.0791057\n",
      "[525]\ttraining's rmse: 0.0824855\tvalid_1's rmse: 0.0791041\n",
      "[550]\ttraining's rmse: 0.0824414\tvalid_1's rmse: 0.0790912\n",
      "[575]\ttraining's rmse: 0.0823996\tvalid_1's rmse: 0.0790898\n",
      "[600]\ttraining's rmse: 0.0823574\tvalid_1's rmse: 0.0790858\n",
      "[625]\ttraining's rmse: 0.0823247\tvalid_1's rmse: 0.0790838\n",
      "[650]\ttraining's rmse: 0.0822857\tvalid_1's rmse: 0.0790819\n",
      "Early stopping, best iteration is:\n",
      "[618]\ttraining's rmse: 0.0823338\tvalid_1's rmse: 0.079079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0846724\tvalid_1's rmse: 0.0871036\n",
      "[50]\ttraining's rmse: 0.0845332\tvalid_1's rmse: 0.0870536\n",
      "[75]\ttraining's rmse: 0.0843914\tvalid_1's rmse: 0.0870012\n",
      "[100]\ttraining's rmse: 0.0842626\tvalid_1's rmse: 0.0869571\n",
      "[125]\ttraining's rmse: 0.0841336\tvalid_1's rmse: 0.0869105\n",
      "[150]\ttraining's rmse: 0.0840174\tvalid_1's rmse: 0.0868698\n",
      "[175]\ttraining's rmse: 0.083919\tvalid_1's rmse: 0.0868363\n",
      "[200]\ttraining's rmse: 0.0838104\tvalid_1's rmse: 0.0867994\n",
      "[225]\ttraining's rmse: 0.0837033\tvalid_1's rmse: 0.0867644\n",
      "[250]\ttraining's rmse: 0.083613\tvalid_1's rmse: 0.0867323\n",
      "[275]\ttraining's rmse: 0.083533\tvalid_1's rmse: 0.0867031\n",
      "[300]\ttraining's rmse: 0.0834537\tvalid_1's rmse: 0.0866764\n",
      "[325]\ttraining's rmse: 0.0833704\tvalid_1's rmse: 0.0866496\n",
      "[350]\ttraining's rmse: 0.0832893\tvalid_1's rmse: 0.0866248\n",
      "[375]\ttraining's rmse: 0.0832238\tvalid_1's rmse: 0.0866043\n",
      "[400]\ttraining's rmse: 0.0831531\tvalid_1's rmse: 0.0865827\n",
      "[425]\ttraining's rmse: 0.0830891\tvalid_1's rmse: 0.0865652\n",
      "[450]\ttraining's rmse: 0.0830316\tvalid_1's rmse: 0.086545\n",
      "[475]\ttraining's rmse: 0.0829783\tvalid_1's rmse: 0.0865296\n",
      "[500]\ttraining's rmse: 0.0829322\tvalid_1's rmse: 0.0865146\n",
      "[525]\ttraining's rmse: 0.0828763\tvalid_1's rmse: 0.0864979\n",
      "[550]\ttraining's rmse: 0.0828233\tvalid_1's rmse: 0.0864835\n",
      "[575]\ttraining's rmse: 0.082775\tvalid_1's rmse: 0.08647\n",
      "[600]\ttraining's rmse: 0.0827274\tvalid_1's rmse: 0.0864563\n",
      "[625]\ttraining's rmse: 0.0826875\tvalid_1's rmse: 0.0864431\n",
      "[650]\ttraining's rmse: 0.0826391\tvalid_1's rmse: 0.0864307\n",
      "[675]\ttraining's rmse: 0.0825927\tvalid_1's rmse: 0.0864197\n",
      "[700]\ttraining's rmse: 0.0825545\tvalid_1's rmse: 0.0864085\n",
      "[725]\ttraining's rmse: 0.0825157\tvalid_1's rmse: 0.086398\n",
      "[750]\ttraining's rmse: 0.0824819\tvalid_1's rmse: 0.0863879\n",
      "[775]\ttraining's rmse: 0.0824534\tvalid_1's rmse: 0.0863775\n",
      "[800]\ttraining's rmse: 0.0824166\tvalid_1's rmse: 0.0863697\n",
      "[825]\ttraining's rmse: 0.0823841\tvalid_1's rmse: 0.0863608\n",
      "[850]\ttraining's rmse: 0.0823503\tvalid_1's rmse: 0.0863521\n",
      "[875]\ttraining's rmse: 0.0823213\tvalid_1's rmse: 0.0863455\n",
      "[900]\ttraining's rmse: 0.0822935\tvalid_1's rmse: 0.0863383\n",
      "[925]\ttraining's rmse: 0.0822661\tvalid_1's rmse: 0.0863305\n",
      "[950]\ttraining's rmse: 0.0822418\tvalid_1's rmse: 0.0863244\n",
      "[975]\ttraining's rmse: 0.082218\tvalid_1's rmse: 0.0863183\n",
      "[1000]\ttraining's rmse: 0.082194\tvalid_1's rmse: 0.0863132\n",
      "[1025]\ttraining's rmse: 0.0821687\tvalid_1's rmse: 0.0863075\n",
      "[1050]\ttraining's rmse: 0.082147\tvalid_1's rmse: 0.0863025\n",
      "[1075]\ttraining's rmse: 0.0821249\tvalid_1's rmse: 0.0862984\n",
      "[1100]\ttraining's rmse: 0.0821074\tvalid_1's rmse: 0.0862935\n",
      "[1125]\ttraining's rmse: 0.0820885\tvalid_1's rmse: 0.086289\n",
      "[1150]\ttraining's rmse: 0.0820695\tvalid_1's rmse: 0.0862849\n",
      "[1175]\ttraining's rmse: 0.0820483\tvalid_1's rmse: 0.086282\n",
      "[1200]\ttraining's rmse: 0.0820313\tvalid_1's rmse: 0.0862776\n",
      "[1225]\ttraining's rmse: 0.0820149\tvalid_1's rmse: 0.0862739\n",
      "[1250]\ttraining's rmse: 0.0819998\tvalid_1's rmse: 0.0862695\n",
      "[1275]\ttraining's rmse: 0.0819822\tvalid_1's rmse: 0.0862673\n",
      "[1300]\ttraining's rmse: 0.0819684\tvalid_1's rmse: 0.0862625\n",
      "[1325]\ttraining's rmse: 0.0819506\tvalid_1's rmse: 0.0862586\n",
      "[1350]\ttraining's rmse: 0.0819355\tvalid_1's rmse: 0.0862554\n",
      "[1375]\ttraining's rmse: 0.0819211\tvalid_1's rmse: 0.0862537\n",
      "[1400]\ttraining's rmse: 0.0819085\tvalid_1's rmse: 0.08625\n",
      "[1425]\ttraining's rmse: 0.0818915\tvalid_1's rmse: 0.0862473\n",
      "[1450]\ttraining's rmse: 0.0818756\tvalid_1's rmse: 0.086244\n",
      "[1475]\ttraining's rmse: 0.0818667\tvalid_1's rmse: 0.086241\n",
      "[1500]\ttraining's rmse: 0.0818575\tvalid_1's rmse: 0.0862379\n",
      "[1525]\ttraining's rmse: 0.0818475\tvalid_1's rmse: 0.0862357\n",
      "[1550]\ttraining's rmse: 0.081835\tvalid_1's rmse: 0.0862341\n",
      "[1575]\ttraining's rmse: 0.0818251\tvalid_1's rmse: 0.0862323\n",
      "[1600]\ttraining's rmse: 0.0818173\tvalid_1's rmse: 0.0862308\n",
      "[1625]\ttraining's rmse: 0.0818047\tvalid_1's rmse: 0.0862281\n",
      "[1650]\ttraining's rmse: 0.0817975\tvalid_1's rmse: 0.0862265\n",
      "[1675]\ttraining's rmse: 0.0817896\tvalid_1's rmse: 0.0862243\n",
      "[1700]\ttraining's rmse: 0.0817823\tvalid_1's rmse: 0.0862234\n",
      "[1725]\ttraining's rmse: 0.081775\tvalid_1's rmse: 0.0862223\n",
      "[1750]\ttraining's rmse: 0.0817681\tvalid_1's rmse: 0.0862209\n",
      "[1775]\ttraining's rmse: 0.0817615\tvalid_1's rmse: 0.0862197\n",
      "[1800]\ttraining's rmse: 0.0817553\tvalid_1's rmse: 0.0862179\n",
      "[1825]\ttraining's rmse: 0.0817491\tvalid_1's rmse: 0.0862159\n",
      "[1850]\ttraining's rmse: 0.0817442\tvalid_1's rmse: 0.0862147\n",
      "[1875]\ttraining's rmse: 0.0817377\tvalid_1's rmse: 0.0862128\n",
      "[1900]\ttraining's rmse: 0.0817313\tvalid_1's rmse: 0.0862109\n",
      "[1925]\ttraining's rmse: 0.0817268\tvalid_1's rmse: 0.0862104\n",
      "[1950]\ttraining's rmse: 0.0817226\tvalid_1's rmse: 0.0862092\n",
      "[1975]\ttraining's rmse: 0.0817194\tvalid_1's rmse: 0.0862084\n",
      "[2000]\ttraining's rmse: 0.0817137\tvalid_1's rmse: 0.0862078\n",
      "[2025]\ttraining's rmse: 0.0817105\tvalid_1's rmse: 0.0862062\n",
      "[2050]\ttraining's rmse: 0.0817067\tvalid_1's rmse: 0.0862054\n",
      "[2075]\ttraining's rmse: 0.0817046\tvalid_1's rmse: 0.0862044\n",
      "[2100]\ttraining's rmse: 0.0817004\tvalid_1's rmse: 0.0862034\n",
      "[2125]\ttraining's rmse: 0.0816972\tvalid_1's rmse: 0.0862013\n",
      "[2150]\ttraining's rmse: 0.0816922\tvalid_1's rmse: 0.0862003\n",
      "[2175]\ttraining's rmse: 0.0816898\tvalid_1's rmse: 0.0861998\n",
      "[2200]\ttraining's rmse: 0.0816857\tvalid_1's rmse: 0.0861988\n",
      "[2225]\ttraining's rmse: 0.0816835\tvalid_1's rmse: 0.0861979\n",
      "[2250]\ttraining's rmse: 0.0816807\tvalid_1's rmse: 0.0861969\n",
      "[2275]\ttraining's rmse: 0.0816764\tvalid_1's rmse: 0.0861968\n",
      "[2300]\ttraining's rmse: 0.0816739\tvalid_1's rmse: 0.086195\n",
      "[2325]\ttraining's rmse: 0.0816717\tvalid_1's rmse: 0.0861936\n",
      "[2350]\ttraining's rmse: 0.0816699\tvalid_1's rmse: 0.0861923\n",
      "[2375]\ttraining's rmse: 0.0816676\tvalid_1's rmse: 0.0861924\n",
      "[2400]\ttraining's rmse: 0.0816648\tvalid_1's rmse: 0.0861922\n",
      "[2425]\ttraining's rmse: 0.0816628\tvalid_1's rmse: 0.0861914\n",
      "[2450]\ttraining's rmse: 0.0816605\tvalid_1's rmse: 0.0861904\n",
      "[2475]\ttraining's rmse: 0.0816587\tvalid_1's rmse: 0.0861903\n",
      "[2500]\ttraining's rmse: 0.0816556\tvalid_1's rmse: 0.0861887\n",
      "[2525]\ttraining's rmse: 0.0816519\tvalid_1's rmse: 0.086188\n",
      "[2550]\ttraining's rmse: 0.0816502\tvalid_1's rmse: 0.0861874\n",
      "[2575]\ttraining's rmse: 0.0816472\tvalid_1's rmse: 0.0861866\n",
      "[2600]\ttraining's rmse: 0.0816449\tvalid_1's rmse: 0.0861862\n",
      "[2625]\ttraining's rmse: 0.0816437\tvalid_1's rmse: 0.0861855\n",
      "[2650]\ttraining's rmse: 0.0816407\tvalid_1's rmse: 0.086185\n",
      "[2675]\ttraining's rmse: 0.0816385\tvalid_1's rmse: 0.0861844\n",
      "[2700]\ttraining's rmse: 0.0816359\tvalid_1's rmse: 0.086184\n",
      "[2725]\ttraining's rmse: 0.0816323\tvalid_1's rmse: 0.0861836\n",
      "[2750]\ttraining's rmse: 0.0816306\tvalid_1's rmse: 0.0861827\n",
      "[2775]\ttraining's rmse: 0.0816277\tvalid_1's rmse: 0.0861826\n",
      "[2800]\ttraining's rmse: 0.0816263\tvalid_1's rmse: 0.0861821\n",
      "[2825]\ttraining's rmse: 0.0816246\tvalid_1's rmse: 0.0861819\n",
      "[2850]\ttraining's rmse: 0.0816224\tvalid_1's rmse: 0.0861814\n",
      "[2875]\ttraining's rmse: 0.081621\tvalid_1's rmse: 0.0861816\n",
      "[2900]\ttraining's rmse: 0.0816195\tvalid_1's rmse: 0.0861816\n",
      "Early stopping, best iteration is:\n",
      "[2850]\ttraining's rmse: 0.0816224\tvalid_1's rmse: 0.0861814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0848162\tvalid_1's rmse: 0.0868573\n",
      "[50]\ttraining's rmse: 0.0846953\tvalid_1's rmse: 0.0868057\n",
      "[75]\ttraining's rmse: 0.0845725\tvalid_1's rmse: 0.0867529\n",
      "[100]\ttraining's rmse: 0.0844616\tvalid_1's rmse: 0.0867085\n",
      "[125]\ttraining's rmse: 0.084345\tvalid_1's rmse: 0.0866626\n",
      "[150]\ttraining's rmse: 0.084239\tvalid_1's rmse: 0.0866194\n",
      "[175]\ttraining's rmse: 0.0841524\tvalid_1's rmse: 0.0865849\n",
      "[200]\ttraining's rmse: 0.0840554\tvalid_1's rmse: 0.0865466\n",
      "[225]\ttraining's rmse: 0.0839607\tvalid_1's rmse: 0.0865118\n",
      "[250]\ttraining's rmse: 0.0838808\tvalid_1's rmse: 0.0864803\n",
      "[275]\ttraining's rmse: 0.0838075\tvalid_1's rmse: 0.0864521\n",
      "[300]\ttraining's rmse: 0.0837355\tvalid_1's rmse: 0.0864258\n",
      "[325]\ttraining's rmse: 0.0836611\tvalid_1's rmse: 0.0864002\n",
      "[350]\ttraining's rmse: 0.0835882\tvalid_1's rmse: 0.0863755\n",
      "[375]\ttraining's rmse: 0.0835293\tvalid_1's rmse: 0.0863547\n",
      "[400]\ttraining's rmse: 0.0834664\tvalid_1's rmse: 0.0863338\n",
      "[425]\ttraining's rmse: 0.0834086\tvalid_1's rmse: 0.0863131\n",
      "[450]\ttraining's rmse: 0.083352\tvalid_1's rmse: 0.0862939\n",
      "[475]\ttraining's rmse: 0.0833008\tvalid_1's rmse: 0.0862764\n",
      "[500]\ttraining's rmse: 0.0832578\tvalid_1's rmse: 0.0862595\n",
      "[525]\ttraining's rmse: 0.0832009\tvalid_1's rmse: 0.0862421\n",
      "[550]\ttraining's rmse: 0.0831512\tvalid_1's rmse: 0.0862277\n",
      "[575]\ttraining's rmse: 0.0831064\tvalid_1's rmse: 0.086214\n",
      "[600]\ttraining's rmse: 0.0830611\tvalid_1's rmse: 0.0862008\n",
      "[625]\ttraining's rmse: 0.083026\tvalid_1's rmse: 0.0861887\n",
      "[650]\ttraining's rmse: 0.0829845\tvalid_1's rmse: 0.0861751\n",
      "[675]\ttraining's rmse: 0.0829395\tvalid_1's rmse: 0.086164\n",
      "[700]\ttraining's rmse: 0.0828998\tvalid_1's rmse: 0.086153\n",
      "[725]\ttraining's rmse: 0.0828665\tvalid_1's rmse: 0.0861435\n",
      "[750]\ttraining's rmse: 0.0828328\tvalid_1's rmse: 0.0861348\n",
      "[775]\ttraining's rmse: 0.0828047\tvalid_1's rmse: 0.0861264\n",
      "[800]\ttraining's rmse: 0.0827687\tvalid_1's rmse: 0.0861186\n",
      "[825]\ttraining's rmse: 0.082739\tvalid_1's rmse: 0.0861099\n",
      "[850]\ttraining's rmse: 0.0827053\tvalid_1's rmse: 0.0861025\n",
      "[875]\ttraining's rmse: 0.0826776\tvalid_1's rmse: 0.0860952\n",
      "[900]\ttraining's rmse: 0.082647\tvalid_1's rmse: 0.0860879\n",
      "[925]\ttraining's rmse: 0.0826187\tvalid_1's rmse: 0.0860817\n",
      "[950]\ttraining's rmse: 0.0825927\tvalid_1's rmse: 0.0860759\n",
      "[975]\ttraining's rmse: 0.0825682\tvalid_1's rmse: 0.08607\n",
      "[1000]\ttraining's rmse: 0.0825448\tvalid_1's rmse: 0.0860645\n",
      "[1025]\ttraining's rmse: 0.0825198\tvalid_1's rmse: 0.0860601\n",
      "[1050]\ttraining's rmse: 0.0824975\tvalid_1's rmse: 0.0860547\n",
      "[1075]\ttraining's rmse: 0.0824755\tvalid_1's rmse: 0.0860509\n",
      "[1100]\ttraining's rmse: 0.0824563\tvalid_1's rmse: 0.0860459\n",
      "[1125]\ttraining's rmse: 0.082437\tvalid_1's rmse: 0.0860425\n",
      "[1150]\ttraining's rmse: 0.0824173\tvalid_1's rmse: 0.0860397\n",
      "[1175]\ttraining's rmse: 0.0824006\tvalid_1's rmse: 0.0860368\n",
      "[1200]\ttraining's rmse: 0.0823838\tvalid_1's rmse: 0.0860336\n",
      "[1225]\ttraining's rmse: 0.0823688\tvalid_1's rmse: 0.0860298\n",
      "[1250]\ttraining's rmse: 0.0823537\tvalid_1's rmse: 0.0860267\n",
      "[1275]\ttraining's rmse: 0.0823368\tvalid_1's rmse: 0.0860246\n",
      "[1300]\ttraining's rmse: 0.0823215\tvalid_1's rmse: 0.0860217\n",
      "[1325]\ttraining's rmse: 0.0823056\tvalid_1's rmse: 0.0860192\n",
      "[1350]\ttraining's rmse: 0.0822911\tvalid_1's rmse: 0.0860176\n",
      "[1375]\ttraining's rmse: 0.0822775\tvalid_1's rmse: 0.0860157\n",
      "[1400]\ttraining's rmse: 0.0822658\tvalid_1's rmse: 0.0860131\n",
      "[1425]\ttraining's rmse: 0.082253\tvalid_1's rmse: 0.0860115\n",
      "[1450]\ttraining's rmse: 0.0822386\tvalid_1's rmse: 0.08601\n",
      "[1475]\ttraining's rmse: 0.0822283\tvalid_1's rmse: 0.0860079\n",
      "[1500]\ttraining's rmse: 0.0822198\tvalid_1's rmse: 0.0860059\n",
      "[1525]\ttraining's rmse: 0.0822094\tvalid_1's rmse: 0.0860046\n",
      "[1550]\ttraining's rmse: 0.0822006\tvalid_1's rmse: 0.0860039\n",
      "[1575]\ttraining's rmse: 0.0821919\tvalid_1's rmse: 0.086002\n",
      "[1600]\ttraining's rmse: 0.0821848\tvalid_1's rmse: 0.0860014\n",
      "[1625]\ttraining's rmse: 0.0821769\tvalid_1's rmse: 0.0859997\n",
      "[1650]\ttraining's rmse: 0.0821706\tvalid_1's rmse: 0.0859986\n",
      "[1675]\ttraining's rmse: 0.0821656\tvalid_1's rmse: 0.0859974\n",
      "[1700]\ttraining's rmse: 0.0821585\tvalid_1's rmse: 0.085996\n",
      "[1725]\ttraining's rmse: 0.0821514\tvalid_1's rmse: 0.0859944\n",
      "[1750]\ttraining's rmse: 0.0821433\tvalid_1's rmse: 0.0859934\n",
      "[1775]\ttraining's rmse: 0.082137\tvalid_1's rmse: 0.0859928\n",
      "[1800]\ttraining's rmse: 0.0821308\tvalid_1's rmse: 0.0859923\n",
      "[1825]\ttraining's rmse: 0.0821242\tvalid_1's rmse: 0.0859911\n",
      "[1850]\ttraining's rmse: 0.0821171\tvalid_1's rmse: 0.0859902\n",
      "[1875]\ttraining's rmse: 0.0821115\tvalid_1's rmse: 0.0859897\n",
      "[1900]\ttraining's rmse: 0.0821074\tvalid_1's rmse: 0.0859896\n",
      "[1925]\ttraining's rmse: 0.0821032\tvalid_1's rmse: 0.0859891\n",
      "[1950]\ttraining's rmse: 0.0820993\tvalid_1's rmse: 0.085989\n",
      "[1975]\ttraining's rmse: 0.0820954\tvalid_1's rmse: 0.0859883\n",
      "[2000]\ttraining's rmse: 0.0820915\tvalid_1's rmse: 0.0859878\n",
      "[2025]\ttraining's rmse: 0.0820874\tvalid_1's rmse: 0.0859873\n",
      "[2050]\ttraining's rmse: 0.0820837\tvalid_1's rmse: 0.085987\n",
      "[2075]\ttraining's rmse: 0.0820804\tvalid_1's rmse: 0.0859867\n",
      "[2100]\ttraining's rmse: 0.0820773\tvalid_1's rmse: 0.0859861\n",
      "[2125]\ttraining's rmse: 0.0820726\tvalid_1's rmse: 0.0859862\n",
      "[2150]\ttraining's rmse: 0.0820698\tvalid_1's rmse: 0.0859864\n",
      "Early stopping, best iteration is:\n",
      "[2106]\ttraining's rmse: 0.0820764\tvalid_1's rmse: 0.085986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0868491\tvalid_1's rmse: 0.0827106\n",
      "[50]\ttraining's rmse: 0.0867341\tvalid_1's rmse: 0.0826626\n",
      "[75]\ttraining's rmse: 0.0866117\tvalid_1's rmse: 0.0826134\n",
      "[100]\ttraining's rmse: 0.0865013\tvalid_1's rmse: 0.0825692\n",
      "[125]\ttraining's rmse: 0.0863863\tvalid_1's rmse: 0.0825264\n",
      "[150]\ttraining's rmse: 0.0862811\tvalid_1's rmse: 0.0824872\n",
      "[175]\ttraining's rmse: 0.0861936\tvalid_1's rmse: 0.0824553\n",
      "[200]\ttraining's rmse: 0.0860976\tvalid_1's rmse: 0.0824244\n",
      "[225]\ttraining's rmse: 0.0860056\tvalid_1's rmse: 0.0823919\n",
      "[250]\ttraining's rmse: 0.0859267\tvalid_1's rmse: 0.0823633\n",
      "[275]\ttraining's rmse: 0.0858562\tvalid_1's rmse: 0.0823396\n",
      "[300]\ttraining's rmse: 0.0857853\tvalid_1's rmse: 0.0823166\n",
      "[325]\ttraining's rmse: 0.0857142\tvalid_1's rmse: 0.0822923\n",
      "[350]\ttraining's rmse: 0.0856447\tvalid_1's rmse: 0.0822676\n",
      "[375]\ttraining's rmse: 0.0855875\tvalid_1's rmse: 0.082255\n",
      "[400]\ttraining's rmse: 0.0855254\tvalid_1's rmse: 0.0822381\n",
      "[425]\ttraining's rmse: 0.0854693\tvalid_1's rmse: 0.0822206\n",
      "[450]\ttraining's rmse: 0.0854175\tvalid_1's rmse: 0.0822045\n",
      "[475]\ttraining's rmse: 0.0853694\tvalid_1's rmse: 0.0821902\n",
      "[500]\ttraining's rmse: 0.085329\tvalid_1's rmse: 0.082177\n",
      "[525]\ttraining's rmse: 0.085273\tvalid_1's rmse: 0.0821661\n",
      "[550]\ttraining's rmse: 0.0852243\tvalid_1's rmse: 0.0821532\n",
      "[575]\ttraining's rmse: 0.0851782\tvalid_1's rmse: 0.082141\n",
      "[600]\ttraining's rmse: 0.0851317\tvalid_1's rmse: 0.0821309\n",
      "[625]\ttraining's rmse: 0.0850952\tvalid_1's rmse: 0.0821255\n",
      "[650]\ttraining's rmse: 0.085049\tvalid_1's rmse: 0.0821216\n",
      "[675]\ttraining's rmse: 0.085004\tvalid_1's rmse: 0.0821203\n",
      "[700]\ttraining's rmse: 0.0849666\tvalid_1's rmse: 0.0821123\n",
      "[725]\ttraining's rmse: 0.0849302\tvalid_1's rmse: 0.082113\n",
      "[750]\ttraining's rmse: 0.0848956\tvalid_1's rmse: 0.0821109\n",
      "[775]\ttraining's rmse: 0.0848688\tvalid_1's rmse: 0.0821055\n",
      "[800]\ttraining's rmse: 0.0848318\tvalid_1's rmse: 0.0821059\n",
      "[825]\ttraining's rmse: 0.0847996\tvalid_1's rmse: 0.082118\n",
      "Early stopping, best iteration is:\n",
      "[776]\ttraining's rmse: 0.0848681\tvalid_1's rmse: 0.0821052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0821772\tvalid_1's rmse: 0.0846248\n",
      "[50]\ttraining's rmse: 0.0820508\tvalid_1's rmse: 0.0845705\n",
      "[75]\ttraining's rmse: 0.0819256\tvalid_1's rmse: 0.0845161\n",
      "[100]\ttraining's rmse: 0.0818074\tvalid_1's rmse: 0.084471\n",
      "[125]\ttraining's rmse: 0.0816895\tvalid_1's rmse: 0.0844239\n",
      "[150]\ttraining's rmse: 0.0815823\tvalid_1's rmse: 0.0843813\n",
      "[175]\ttraining's rmse: 0.0814937\tvalid_1's rmse: 0.0843425\n",
      "[200]\ttraining's rmse: 0.0813985\tvalid_1's rmse: 0.0843057\n",
      "[225]\ttraining's rmse: 0.0813056\tvalid_1's rmse: 0.0842694\n",
      "[250]\ttraining's rmse: 0.0812312\tvalid_1's rmse: 0.0842367\n",
      "[275]\ttraining's rmse: 0.0811596\tvalid_1's rmse: 0.084206\n",
      "[300]\ttraining's rmse: 0.0810873\tvalid_1's rmse: 0.0841766\n",
      "[325]\ttraining's rmse: 0.0810153\tvalid_1's rmse: 0.084148\n",
      "[350]\ttraining's rmse: 0.0809458\tvalid_1's rmse: 0.0841227\n",
      "[375]\ttraining's rmse: 0.0808878\tvalid_1's rmse: 0.0841005\n",
      "[400]\ttraining's rmse: 0.0808266\tvalid_1's rmse: 0.0840781\n",
      "[425]\ttraining's rmse: 0.0807696\tvalid_1's rmse: 0.0840577\n",
      "[450]\ttraining's rmse: 0.080718\tvalid_1's rmse: 0.0840377\n",
      "[475]\ttraining's rmse: 0.0806726\tvalid_1's rmse: 0.0840205\n",
      "[500]\ttraining's rmse: 0.0806294\tvalid_1's rmse: 0.0840037\n",
      "[525]\ttraining's rmse: 0.0805775\tvalid_1's rmse: 0.0839865\n",
      "[550]\ttraining's rmse: 0.0805308\tvalid_1's rmse: 0.0839697\n",
      "[575]\ttraining's rmse: 0.0804867\tvalid_1's rmse: 0.0839554\n",
      "[600]\ttraining's rmse: 0.0804445\tvalid_1's rmse: 0.0839419\n",
      "[625]\ttraining's rmse: 0.0804104\tvalid_1's rmse: 0.083929\n",
      "[650]\ttraining's rmse: 0.0803718\tvalid_1's rmse: 0.0839174\n",
      "[675]\ttraining's rmse: 0.0803305\tvalid_1's rmse: 0.0839042\n",
      "[700]\ttraining's rmse: 0.0802939\tvalid_1's rmse: 0.083892\n",
      "[725]\ttraining's rmse: 0.0802579\tvalid_1's rmse: 0.0838819\n",
      "[750]\ttraining's rmse: 0.0802268\tvalid_1's rmse: 0.083872\n",
      "[775]\ttraining's rmse: 0.080203\tvalid_1's rmse: 0.0838618\n",
      "[800]\ttraining's rmse: 0.0801718\tvalid_1's rmse: 0.0838532\n",
      "[825]\ttraining's rmse: 0.0801435\tvalid_1's rmse: 0.0838433\n",
      "[850]\ttraining's rmse: 0.0801142\tvalid_1's rmse: 0.0838362\n",
      "[875]\ttraining's rmse: 0.0800879\tvalid_1's rmse: 0.0838284\n",
      "[900]\ttraining's rmse: 0.0800596\tvalid_1's rmse: 0.0838218\n",
      "[925]\ttraining's rmse: 0.0800333\tvalid_1's rmse: 0.0838145\n",
      "[950]\ttraining's rmse: 0.0800122\tvalid_1's rmse: 0.0838077\n",
      "[975]\ttraining's rmse: 0.0799874\tvalid_1's rmse: 0.0838017\n",
      "[1000]\ttraining's rmse: 0.0799653\tvalid_1's rmse: 0.083796\n",
      "[1025]\ttraining's rmse: 0.0799438\tvalid_1's rmse: 0.0837891\n",
      "[1050]\ttraining's rmse: 0.0799253\tvalid_1's rmse: 0.0837828\n",
      "[1075]\ttraining's rmse: 0.0799057\tvalid_1's rmse: 0.0837779\n",
      "[1100]\ttraining's rmse: 0.0798896\tvalid_1's rmse: 0.0837731\n",
      "[1125]\ttraining's rmse: 0.0798734\tvalid_1's rmse: 0.0837683\n",
      "[1150]\ttraining's rmse: 0.0798545\tvalid_1's rmse: 0.0837628\n",
      "[1175]\ttraining's rmse: 0.0798397\tvalid_1's rmse: 0.0837578\n",
      "[1200]\ttraining's rmse: 0.0798254\tvalid_1's rmse: 0.0837532\n",
      "[1225]\ttraining's rmse: 0.0798098\tvalid_1's rmse: 0.0837489\n",
      "[1250]\ttraining's rmse: 0.079796\tvalid_1's rmse: 0.083745\n",
      "[1275]\ttraining's rmse: 0.0797806\tvalid_1's rmse: 0.0837418\n",
      "[1300]\ttraining's rmse: 0.0797689\tvalid_1's rmse: 0.0837381\n",
      "[1325]\ttraining's rmse: 0.0797539\tvalid_1's rmse: 0.0837347\n",
      "[1350]\ttraining's rmse: 0.079741\tvalid_1's rmse: 0.0837317\n",
      "[1375]\ttraining's rmse: 0.0797299\tvalid_1's rmse: 0.0837294\n",
      "[1400]\ttraining's rmse: 0.0797194\tvalid_1's rmse: 0.0837265\n",
      "[1425]\ttraining's rmse: 0.0797076\tvalid_1's rmse: 0.0837252\n",
      "[1450]\ttraining's rmse: 0.0796958\tvalid_1's rmse: 0.0837227\n",
      "[1475]\ttraining's rmse: 0.0796865\tvalid_1's rmse: 0.0837202\n",
      "[1500]\ttraining's rmse: 0.0796772\tvalid_1's rmse: 0.0837169\n",
      "[1525]\ttraining's rmse: 0.0796678\tvalid_1's rmse: 0.0837141\n",
      "[1550]\ttraining's rmse: 0.079656\tvalid_1's rmse: 0.0837112\n",
      "[1575]\ttraining's rmse: 0.0796476\tvalid_1's rmse: 0.0837096\n",
      "[1600]\ttraining's rmse: 0.0796417\tvalid_1's rmse: 0.083708\n",
      "[1625]\ttraining's rmse: 0.0796331\tvalid_1's rmse: 0.0837056\n",
      "[1650]\ttraining's rmse: 0.0796238\tvalid_1's rmse: 0.0837014\n",
      "[1675]\ttraining's rmse: 0.0796187\tvalid_1's rmse: 0.0836988\n",
      "[1700]\ttraining's rmse: 0.0796137\tvalid_1's rmse: 0.0836966\n",
      "[1725]\ttraining's rmse: 0.0796076\tvalid_1's rmse: 0.0836942\n",
      "[1750]\ttraining's rmse: 0.0796004\tvalid_1's rmse: 0.083691\n",
      "[1775]\ttraining's rmse: 0.0795936\tvalid_1's rmse: 0.0836898\n",
      "[1800]\ttraining's rmse: 0.0795861\tvalid_1's rmse: 0.0836877\n",
      "[1825]\ttraining's rmse: 0.0795808\tvalid_1's rmse: 0.0836866\n",
      "[1850]\ttraining's rmse: 0.0795755\tvalid_1's rmse: 0.0836846\n",
      "[1875]\ttraining's rmse: 0.0795709\tvalid_1's rmse: 0.0836842\n",
      "[1900]\ttraining's rmse: 0.079567\tvalid_1's rmse: 0.0836827\n",
      "[1925]\ttraining's rmse: 0.0795622\tvalid_1's rmse: 0.0836819\n",
      "[1950]\ttraining's rmse: 0.0795585\tvalid_1's rmse: 0.0836808\n",
      "[1975]\ttraining's rmse: 0.0795554\tvalid_1's rmse: 0.0836796\n",
      "[2000]\ttraining's rmse: 0.0795512\tvalid_1's rmse: 0.0836788\n",
      "[2025]\ttraining's rmse: 0.0795481\tvalid_1's rmse: 0.0836782\n",
      "[2050]\ttraining's rmse: 0.0795453\tvalid_1's rmse: 0.0836767\n",
      "[2075]\ttraining's rmse: 0.0795421\tvalid_1's rmse: 0.0836761\n",
      "[2100]\ttraining's rmse: 0.0795382\tvalid_1's rmse: 0.0836755\n",
      "[2125]\ttraining's rmse: 0.0795356\tvalid_1's rmse: 0.0836753\n",
      "[2150]\ttraining's rmse: 0.0795321\tvalid_1's rmse: 0.0836751\n",
      "[2175]\ttraining's rmse: 0.0795302\tvalid_1's rmse: 0.0836748\n",
      "[2200]\ttraining's rmse: 0.079528\tvalid_1's rmse: 0.0836741\n",
      "[2225]\ttraining's rmse: 0.0795258\tvalid_1's rmse: 0.0836735\n",
      "[2250]\ttraining's rmse: 0.0795218\tvalid_1's rmse: 0.0836726\n",
      "[2275]\ttraining's rmse: 0.079519\tvalid_1's rmse: 0.0836709\n",
      "[2300]\ttraining's rmse: 0.0795173\tvalid_1's rmse: 0.0836697\n",
      "[2325]\ttraining's rmse: 0.0795145\tvalid_1's rmse: 0.0836692\n",
      "[2350]\ttraining's rmse: 0.0795129\tvalid_1's rmse: 0.0836686\n",
      "[2375]\ttraining's rmse: 0.0795104\tvalid_1's rmse: 0.0836678\n",
      "[2400]\ttraining's rmse: 0.0795079\tvalid_1's rmse: 0.0836673\n",
      "[2425]\ttraining's rmse: 0.0795041\tvalid_1's rmse: 0.0836665\n",
      "[2450]\ttraining's rmse: 0.0795019\tvalid_1's rmse: 0.0836654\n",
      "[2475]\ttraining's rmse: 0.0795003\tvalid_1's rmse: 0.0836653\n",
      "[2500]\ttraining's rmse: 0.0794987\tvalid_1's rmse: 0.0836653\n",
      "[2525]\ttraining's rmse: 0.0794971\tvalid_1's rmse: 0.0836653\n",
      "[2550]\ttraining's rmse: 0.0794946\tvalid_1's rmse: 0.0836644\n",
      "[2575]\ttraining's rmse: 0.0794922\tvalid_1's rmse: 0.0836644\n",
      "[2600]\ttraining's rmse: 0.079491\tvalid_1's rmse: 0.0836638\n",
      "[2625]\ttraining's rmse: 0.0794893\tvalid_1's rmse: 0.083663\n",
      "[2650]\ttraining's rmse: 0.0794875\tvalid_1's rmse: 0.0836626\n",
      "[2675]\ttraining's rmse: 0.0794849\tvalid_1's rmse: 0.0836616\n",
      "[2700]\ttraining's rmse: 0.0794824\tvalid_1's rmse: 0.0836604\n",
      "[2725]\ttraining's rmse: 0.0794785\tvalid_1's rmse: 0.0836605\n",
      "[2750]\ttraining's rmse: 0.0794771\tvalid_1's rmse: 0.08366\n",
      "[2775]\ttraining's rmse: 0.0794754\tvalid_1's rmse: 0.0836597\n",
      "[2800]\ttraining's rmse: 0.079473\tvalid_1's rmse: 0.0836597\n",
      "[2825]\ttraining's rmse: 0.0794711\tvalid_1's rmse: 0.0836599\n",
      "Early stopping, best iteration is:\n",
      "[2786]\ttraining's rmse: 0.0794737\tvalid_1's rmse: 0.0836596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0822363\tvalid_1's rmse: 0.0845161\n",
      "[50]\ttraining's rmse: 0.0821234\tvalid_1's rmse: 0.0844612\n",
      "[75]\ttraining's rmse: 0.0820067\tvalid_1's rmse: 0.0844074\n",
      "[100]\ttraining's rmse: 0.081906\tvalid_1's rmse: 0.0843617\n",
      "[125]\ttraining's rmse: 0.0817976\tvalid_1's rmse: 0.0843141\n",
      "[150]\ttraining's rmse: 0.0816977\tvalid_1's rmse: 0.0842719\n",
      "[175]\ttraining's rmse: 0.0816157\tvalid_1's rmse: 0.0842364\n",
      "[200]\ttraining's rmse: 0.0815222\tvalid_1's rmse: 0.0841997\n",
      "[225]\ttraining's rmse: 0.0814365\tvalid_1's rmse: 0.084165\n",
      "[250]\ttraining's rmse: 0.0813648\tvalid_1's rmse: 0.0841338\n",
      "[275]\ttraining's rmse: 0.0812943\tvalid_1's rmse: 0.0841049\n",
      "[300]\ttraining's rmse: 0.0812247\tvalid_1's rmse: 0.0840765\n",
      "[325]\ttraining's rmse: 0.0811529\tvalid_1's rmse: 0.0840491\n",
      "[350]\ttraining's rmse: 0.0810839\tvalid_1's rmse: 0.0840245\n",
      "[375]\ttraining's rmse: 0.0810281\tvalid_1's rmse: 0.0840034\n",
      "[400]\ttraining's rmse: 0.0809668\tvalid_1's rmse: 0.0839839\n",
      "[425]\ttraining's rmse: 0.0809088\tvalid_1's rmse: 0.0839644\n",
      "[450]\ttraining's rmse: 0.0808552\tvalid_1's rmse: 0.0839465\n",
      "[475]\ttraining's rmse: 0.080809\tvalid_1's rmse: 0.08393\n",
      "[500]\ttraining's rmse: 0.080767\tvalid_1's rmse: 0.083913\n",
      "[525]\ttraining's rmse: 0.0807138\tvalid_1's rmse: 0.0838971\n",
      "[550]\ttraining's rmse: 0.0806662\tvalid_1's rmse: 0.0838822\n",
      "[575]\ttraining's rmse: 0.080623\tvalid_1's rmse: 0.0838686\n",
      "[600]\ttraining's rmse: 0.0805792\tvalid_1's rmse: 0.0838557\n",
      "[625]\ttraining's rmse: 0.0805464\tvalid_1's rmse: 0.0838443\n",
      "[650]\ttraining's rmse: 0.0805048\tvalid_1's rmse: 0.0838317\n",
      "[675]\ttraining's rmse: 0.0804661\tvalid_1's rmse: 0.0838209\n",
      "[700]\ttraining's rmse: 0.0804279\tvalid_1's rmse: 0.08381\n",
      "[725]\ttraining's rmse: 0.0803921\tvalid_1's rmse: 0.0837999\n",
      "[750]\ttraining's rmse: 0.0803586\tvalid_1's rmse: 0.0837896\n",
      "[775]\ttraining's rmse: 0.0803315\tvalid_1's rmse: 0.0837814\n",
      "[800]\ttraining's rmse: 0.0802963\tvalid_1's rmse: 0.0837731\n",
      "[825]\ttraining's rmse: 0.0802669\tvalid_1's rmse: 0.0837649\n",
      "[850]\ttraining's rmse: 0.0802378\tvalid_1's rmse: 0.0837577\n",
      "[875]\ttraining's rmse: 0.0802123\tvalid_1's rmse: 0.0837512\n",
      "[900]\ttraining's rmse: 0.0801857\tvalid_1's rmse: 0.0837453\n",
      "[925]\ttraining's rmse: 0.0801609\tvalid_1's rmse: 0.0837401\n",
      "[950]\ttraining's rmse: 0.0801374\tvalid_1's rmse: 0.0837342\n",
      "[975]\ttraining's rmse: 0.0801152\tvalid_1's rmse: 0.0837278\n",
      "[1000]\ttraining's rmse: 0.0800945\tvalid_1's rmse: 0.0837233\n",
      "[1025]\ttraining's rmse: 0.0800711\tvalid_1's rmse: 0.0837183\n",
      "[1050]\ttraining's rmse: 0.080052\tvalid_1's rmse: 0.0837138\n",
      "[1075]\ttraining's rmse: 0.0800329\tvalid_1's rmse: 0.0837096\n",
      "[1100]\ttraining's rmse: 0.0800179\tvalid_1's rmse: 0.0837052\n",
      "[1125]\ttraining's rmse: 0.0800001\tvalid_1's rmse: 0.0837013\n",
      "[1150]\ttraining's rmse: 0.0799813\tvalid_1's rmse: 0.0836976\n",
      "[1175]\ttraining's rmse: 0.0799669\tvalid_1's rmse: 0.0836939\n",
      "[1200]\ttraining's rmse: 0.0799518\tvalid_1's rmse: 0.0836902\n",
      "[1225]\ttraining's rmse: 0.0799376\tvalid_1's rmse: 0.0836876\n",
      "[1250]\ttraining's rmse: 0.0799244\tvalid_1's rmse: 0.0836848\n",
      "[1275]\ttraining's rmse: 0.0799073\tvalid_1's rmse: 0.0836823\n",
      "[1300]\ttraining's rmse: 0.0798955\tvalid_1's rmse: 0.0836798\n",
      "[1325]\ttraining's rmse: 0.0798827\tvalid_1's rmse: 0.0836774\n",
      "[1350]\ttraining's rmse: 0.0798695\tvalid_1's rmse: 0.0836752\n",
      "[1375]\ttraining's rmse: 0.0798584\tvalid_1's rmse: 0.0836734\n",
      "[1400]\ttraining's rmse: 0.0798493\tvalid_1's rmse: 0.0836712\n",
      "[1425]\ttraining's rmse: 0.0798377\tvalid_1's rmse: 0.0836692\n",
      "[1450]\ttraining's rmse: 0.0798254\tvalid_1's rmse: 0.0836677\n",
      "[1475]\ttraining's rmse: 0.0798141\tvalid_1's rmse: 0.0836654\n",
      "[1500]\ttraining's rmse: 0.0798069\tvalid_1's rmse: 0.0836638\n",
      "[1525]\ttraining's rmse: 0.0797987\tvalid_1's rmse: 0.0836622\n",
      "[1550]\ttraining's rmse: 0.0797905\tvalid_1's rmse: 0.0836611\n",
      "[1575]\ttraining's rmse: 0.0797823\tvalid_1's rmse: 0.0836598\n",
      "[1600]\ttraining's rmse: 0.0797756\tvalid_1's rmse: 0.083659\n",
      "[1625]\ttraining's rmse: 0.0797677\tvalid_1's rmse: 0.0836583\n",
      "[1650]\ttraining's rmse: 0.0797596\tvalid_1's rmse: 0.0836571\n",
      "[1675]\ttraining's rmse: 0.0797536\tvalid_1's rmse: 0.0836557\n",
      "[1700]\ttraining's rmse: 0.0797481\tvalid_1's rmse: 0.0836547\n",
      "[1725]\ttraining's rmse: 0.0797433\tvalid_1's rmse: 0.0836539\n",
      "[1750]\ttraining's rmse: 0.0797352\tvalid_1's rmse: 0.0836529\n",
      "[1775]\ttraining's rmse: 0.0797289\tvalid_1's rmse: 0.0836524\n",
      "[1800]\ttraining's rmse: 0.0797225\tvalid_1's rmse: 0.0836513\n",
      "[1825]\ttraining's rmse: 0.0797179\tvalid_1's rmse: 0.0836504\n",
      "[1850]\ttraining's rmse: 0.0797135\tvalid_1's rmse: 0.0836498\n",
      "[1875]\ttraining's rmse: 0.0797082\tvalid_1's rmse: 0.0836497\n",
      "[1900]\ttraining's rmse: 0.0797026\tvalid_1's rmse: 0.0836493\n",
      "[1925]\ttraining's rmse: 0.0796989\tvalid_1's rmse: 0.083649\n",
      "[1950]\ttraining's rmse: 0.079696\tvalid_1's rmse: 0.0836483\n",
      "[1975]\ttraining's rmse: 0.0796932\tvalid_1's rmse: 0.0836478\n",
      "[2000]\ttraining's rmse: 0.0796892\tvalid_1's rmse: 0.0836472\n",
      "[2025]\ttraining's rmse: 0.0796842\tvalid_1's rmse: 0.0836464\n",
      "[2050]\ttraining's rmse: 0.0796808\tvalid_1's rmse: 0.0836462\n",
      "[2075]\ttraining's rmse: 0.0796788\tvalid_1's rmse: 0.0836459\n",
      "[2100]\ttraining's rmse: 0.0796755\tvalid_1's rmse: 0.0836454\n",
      "[2125]\ttraining's rmse: 0.0796717\tvalid_1's rmse: 0.0836452\n",
      "[2150]\ttraining's rmse: 0.0796672\tvalid_1's rmse: 0.083645\n",
      "[2175]\ttraining's rmse: 0.0796636\tvalid_1's rmse: 0.0836453\n",
      "[2200]\ttraining's rmse: 0.0796616\tvalid_1's rmse: 0.0836454\n",
      "Early stopping, best iteration is:\n",
      "[2160]\ttraining's rmse: 0.0796658\tvalid_1's rmse: 0.083645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0844507\tvalid_1's rmse: 0.080009\n",
      "[50]\ttraining's rmse: 0.0843372\tvalid_1's rmse: 0.0799589\n",
      "[75]\ttraining's rmse: 0.0842219\tvalid_1's rmse: 0.0799106\n",
      "[100]\ttraining's rmse: 0.0841189\tvalid_1's rmse: 0.0798691\n",
      "[125]\ttraining's rmse: 0.0840124\tvalid_1's rmse: 0.0798267\n",
      "[150]\ttraining's rmse: 0.0839126\tvalid_1's rmse: 0.0797878\n",
      "[175]\ttraining's rmse: 0.0838314\tvalid_1's rmse: 0.0797582\n",
      "[200]\ttraining's rmse: 0.0837456\tvalid_1's rmse: 0.0797272\n",
      "[225]\ttraining's rmse: 0.0836623\tvalid_1's rmse: 0.0796971\n",
      "[250]\ttraining's rmse: 0.0835926\tvalid_1's rmse: 0.0796717\n",
      "[275]\ttraining's rmse: 0.0835275\tvalid_1's rmse: 0.0796477\n",
      "[300]\ttraining's rmse: 0.083462\tvalid_1's rmse: 0.0796236\n",
      "[325]\ttraining's rmse: 0.0833973\tvalid_1's rmse: 0.0796016\n",
      "[350]\ttraining's rmse: 0.0833315\tvalid_1's rmse: 0.0795804\n",
      "[375]\ttraining's rmse: 0.0832766\tvalid_1's rmse: 0.079564\n",
      "[400]\ttraining's rmse: 0.0832175\tvalid_1's rmse: 0.0795576\n",
      "[425]\ttraining's rmse: 0.083164\tvalid_1's rmse: 0.0795478\n",
      "[450]\ttraining's rmse: 0.0831153\tvalid_1's rmse: 0.0795358\n",
      "[475]\ttraining's rmse: 0.0830702\tvalid_1's rmse: 0.079523\n",
      "[500]\ttraining's rmse: 0.0830312\tvalid_1's rmse: 0.0795118\n",
      "[525]\ttraining's rmse: 0.0829803\tvalid_1's rmse: 0.0794975\n",
      "[550]\ttraining's rmse: 0.0829362\tvalid_1's rmse: 0.0794904\n",
      "[575]\ttraining's rmse: 0.0828926\tvalid_1's rmse: 0.0794839\n",
      "[600]\ttraining's rmse: 0.0828496\tvalid_1's rmse: 0.0794761\n",
      "[625]\ttraining's rmse: 0.0828172\tvalid_1's rmse: 0.0794831\n",
      "[650]\ttraining's rmse: 0.082775\tvalid_1's rmse: 0.0794864\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's rmse: 0.0828496\tvalid_1's rmse: 0.0794761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0855022\tvalid_1's rmse: 0.0878022\n",
      "[50]\ttraining's rmse: 0.085361\tvalid_1's rmse: 0.0877506\n",
      "[75]\ttraining's rmse: 0.0852169\tvalid_1's rmse: 0.0876992\n",
      "[100]\ttraining's rmse: 0.0850819\tvalid_1's rmse: 0.0876549\n",
      "[125]\ttraining's rmse: 0.0849454\tvalid_1's rmse: 0.087611\n",
      "[150]\ttraining's rmse: 0.0848205\tvalid_1's rmse: 0.0875697\n",
      "[175]\ttraining's rmse: 0.0847151\tvalid_1's rmse: 0.0875355\n",
      "[200]\ttraining's rmse: 0.0846052\tvalid_1's rmse: 0.0875004\n",
      "[225]\ttraining's rmse: 0.0844982\tvalid_1's rmse: 0.0874657\n",
      "[250]\ttraining's rmse: 0.0844057\tvalid_1's rmse: 0.0874338\n",
      "[275]\ttraining's rmse: 0.0843189\tvalid_1's rmse: 0.0874063\n",
      "[300]\ttraining's rmse: 0.0842316\tvalid_1's rmse: 0.0873794\n",
      "[325]\ttraining's rmse: 0.0841461\tvalid_1's rmse: 0.0873547\n",
      "[350]\ttraining's rmse: 0.0840664\tvalid_1's rmse: 0.0873292\n",
      "[375]\ttraining's rmse: 0.0839938\tvalid_1's rmse: 0.0873105\n",
      "[400]\ttraining's rmse: 0.0839232\tvalid_1's rmse: 0.087291\n",
      "[425]\ttraining's rmse: 0.0838588\tvalid_1's rmse: 0.0872716\n",
      "[450]\ttraining's rmse: 0.0837999\tvalid_1's rmse: 0.0872518\n",
      "[475]\ttraining's rmse: 0.0837464\tvalid_1's rmse: 0.0872348\n",
      "[500]\ttraining's rmse: 0.0836984\tvalid_1's rmse: 0.0872183\n",
      "[525]\ttraining's rmse: 0.083641\tvalid_1's rmse: 0.0872015\n",
      "[550]\ttraining's rmse: 0.0835888\tvalid_1's rmse: 0.0871861\n",
      "[575]\ttraining's rmse: 0.0835355\tvalid_1's rmse: 0.0871721\n",
      "[600]\ttraining's rmse: 0.0834838\tvalid_1's rmse: 0.08716\n",
      "[625]\ttraining's rmse: 0.0834437\tvalid_1's rmse: 0.0871478\n",
      "[650]\ttraining's rmse: 0.0833975\tvalid_1's rmse: 0.0871361\n",
      "[675]\ttraining's rmse: 0.0833471\tvalid_1's rmse: 0.0871237\n",
      "[700]\ttraining's rmse: 0.0833051\tvalid_1's rmse: 0.0871122\n",
      "[725]\ttraining's rmse: 0.0832661\tvalid_1's rmse: 0.0871018\n",
      "[750]\ttraining's rmse: 0.0832285\tvalid_1's rmse: 0.0870921\n",
      "[775]\ttraining's rmse: 0.0831984\tvalid_1's rmse: 0.0870837\n",
      "[800]\ttraining's rmse: 0.0831591\tvalid_1's rmse: 0.0870767\n",
      "[825]\ttraining's rmse: 0.0831308\tvalid_1's rmse: 0.0870688\n",
      "[850]\ttraining's rmse: 0.0830977\tvalid_1's rmse: 0.0870625\n",
      "[875]\ttraining's rmse: 0.0830694\tvalid_1's rmse: 0.0870564\n",
      "[900]\ttraining's rmse: 0.08304\tvalid_1's rmse: 0.0870498\n",
      "[925]\ttraining's rmse: 0.0830093\tvalid_1's rmse: 0.0870442\n",
      "[950]\ttraining's rmse: 0.0829811\tvalid_1's rmse: 0.0870371\n",
      "[975]\ttraining's rmse: 0.0829563\tvalid_1's rmse: 0.0870305\n",
      "[1000]\ttraining's rmse: 0.0829331\tvalid_1's rmse: 0.0870258\n",
      "[1025]\ttraining's rmse: 0.0829063\tvalid_1's rmse: 0.0870206\n",
      "[1050]\ttraining's rmse: 0.0828823\tvalid_1's rmse: 0.0870148\n",
      "[1075]\ttraining's rmse: 0.0828573\tvalid_1's rmse: 0.0870097\n",
      "[1100]\ttraining's rmse: 0.0828371\tvalid_1's rmse: 0.0870045\n",
      "[1125]\ttraining's rmse: 0.0828162\tvalid_1's rmse: 0.0869994\n",
      "[1150]\ttraining's rmse: 0.0827954\tvalid_1's rmse: 0.0869948\n",
      "[1175]\ttraining's rmse: 0.0827745\tvalid_1's rmse: 0.0869911\n",
      "[1200]\ttraining's rmse: 0.0827566\tvalid_1's rmse: 0.0869877\n",
      "[1225]\ttraining's rmse: 0.0827387\tvalid_1's rmse: 0.0869843\n",
      "[1250]\ttraining's rmse: 0.082721\tvalid_1's rmse: 0.0869812\n",
      "[1275]\ttraining's rmse: 0.0827017\tvalid_1's rmse: 0.0869787\n",
      "[1300]\ttraining's rmse: 0.0826873\tvalid_1's rmse: 0.0869759\n",
      "[1325]\ttraining's rmse: 0.0826726\tvalid_1's rmse: 0.0869726\n",
      "[1350]\ttraining's rmse: 0.0826585\tvalid_1's rmse: 0.0869703\n",
      "[1375]\ttraining's rmse: 0.0826419\tvalid_1's rmse: 0.0869672\n",
      "[1400]\ttraining's rmse: 0.0826278\tvalid_1's rmse: 0.0869632\n",
      "[1425]\ttraining's rmse: 0.0826153\tvalid_1's rmse: 0.0869596\n",
      "[1450]\ttraining's rmse: 0.0826011\tvalid_1's rmse: 0.0869563\n",
      "[1475]\ttraining's rmse: 0.0825868\tvalid_1's rmse: 0.086953\n",
      "[1500]\ttraining's rmse: 0.082575\tvalid_1's rmse: 0.0869502\n",
      "[1525]\ttraining's rmse: 0.0825649\tvalid_1's rmse: 0.0869469\n",
      "[1550]\ttraining's rmse: 0.0825535\tvalid_1's rmse: 0.0869451\n",
      "[1575]\ttraining's rmse: 0.0825444\tvalid_1's rmse: 0.0869422\n",
      "[1600]\ttraining's rmse: 0.0825375\tvalid_1's rmse: 0.0869396\n",
      "[1625]\ttraining's rmse: 0.0825278\tvalid_1's rmse: 0.0869372\n",
      "[1650]\ttraining's rmse: 0.0825212\tvalid_1's rmse: 0.0869349\n",
      "[1675]\ttraining's rmse: 0.082515\tvalid_1's rmse: 0.0869323\n",
      "[1700]\ttraining's rmse: 0.0825073\tvalid_1's rmse: 0.0869294\n",
      "[1725]\ttraining's rmse: 0.0825006\tvalid_1's rmse: 0.0869279\n",
      "[1750]\ttraining's rmse: 0.0824932\tvalid_1's rmse: 0.0869262\n",
      "[1775]\ttraining's rmse: 0.0824861\tvalid_1's rmse: 0.0869253\n",
      "[1800]\ttraining's rmse: 0.0824797\tvalid_1's rmse: 0.0869233\n",
      "[1825]\ttraining's rmse: 0.0824746\tvalid_1's rmse: 0.0869217\n",
      "[1850]\ttraining's rmse: 0.0824696\tvalid_1's rmse: 0.0869195\n",
      "[1875]\ttraining's rmse: 0.0824658\tvalid_1's rmse: 0.0869185\n",
      "[1900]\ttraining's rmse: 0.0824604\tvalid_1's rmse: 0.0869181\n",
      "[1925]\ttraining's rmse: 0.0824555\tvalid_1's rmse: 0.086917\n",
      "[1950]\ttraining's rmse: 0.0824517\tvalid_1's rmse: 0.0869153\n",
      "[1975]\ttraining's rmse: 0.0824465\tvalid_1's rmse: 0.0869142\n",
      "[2000]\ttraining's rmse: 0.0824422\tvalid_1's rmse: 0.0869132\n",
      "[2025]\ttraining's rmse: 0.0824379\tvalid_1's rmse: 0.0869119\n",
      "[2050]\ttraining's rmse: 0.0824339\tvalid_1's rmse: 0.0869111\n",
      "[2075]\ttraining's rmse: 0.0824297\tvalid_1's rmse: 0.0869093\n",
      "[2100]\ttraining's rmse: 0.0824259\tvalid_1's rmse: 0.0869072\n",
      "[2125]\ttraining's rmse: 0.0824235\tvalid_1's rmse: 0.0869058\n",
      "[2150]\ttraining's rmse: 0.0824192\tvalid_1's rmse: 0.0869051\n",
      "[2175]\ttraining's rmse: 0.0824156\tvalid_1's rmse: 0.0869044\n",
      "[2200]\ttraining's rmse: 0.0824117\tvalid_1's rmse: 0.0869033\n",
      "[2225]\ttraining's rmse: 0.0824081\tvalid_1's rmse: 0.0869024\n",
      "[2250]\ttraining's rmse: 0.0824042\tvalid_1's rmse: 0.0869019\n",
      "[2275]\ttraining's rmse: 0.0824015\tvalid_1's rmse: 0.0869014\n",
      "[2300]\ttraining's rmse: 0.0823984\tvalid_1's rmse: 0.0869003\n",
      "[2325]\ttraining's rmse: 0.0823951\tvalid_1's rmse: 0.0869004\n",
      "[2350]\ttraining's rmse: 0.082393\tvalid_1's rmse: 0.0868999\n",
      "[2375]\ttraining's rmse: 0.0823882\tvalid_1's rmse: 0.0868985\n",
      "[2400]\ttraining's rmse: 0.0823857\tvalid_1's rmse: 0.086898\n",
      "[2425]\ttraining's rmse: 0.0823824\tvalid_1's rmse: 0.0868973\n",
      "[2450]\ttraining's rmse: 0.0823787\tvalid_1's rmse: 0.0868961\n",
      "[2475]\ttraining's rmse: 0.0823761\tvalid_1's rmse: 0.0868953\n",
      "[2500]\ttraining's rmse: 0.0823744\tvalid_1's rmse: 0.0868941\n",
      "[2525]\ttraining's rmse: 0.0823721\tvalid_1's rmse: 0.0868933\n",
      "[2550]\ttraining's rmse: 0.0823694\tvalid_1's rmse: 0.0868933\n",
      "[2575]\ttraining's rmse: 0.0823662\tvalid_1's rmse: 0.0868923\n",
      "[2600]\ttraining's rmse: 0.0823648\tvalid_1's rmse: 0.0868921\n",
      "[2625]\ttraining's rmse: 0.0823622\tvalid_1's rmse: 0.086891\n",
      "[2650]\ttraining's rmse: 0.0823589\tvalid_1's rmse: 0.0868899\n",
      "[2675]\ttraining's rmse: 0.0823561\tvalid_1's rmse: 0.086889\n",
      "[2700]\ttraining's rmse: 0.0823524\tvalid_1's rmse: 0.0868885\n",
      "[2725]\ttraining's rmse: 0.0823506\tvalid_1's rmse: 0.0868878\n",
      "[2750]\ttraining's rmse: 0.0823488\tvalid_1's rmse: 0.0868876\n",
      "[2775]\ttraining's rmse: 0.0823467\tvalid_1's rmse: 0.0868877\n",
      "[2800]\ttraining's rmse: 0.0823445\tvalid_1's rmse: 0.0868871\n",
      "[2825]\ttraining's rmse: 0.0823423\tvalid_1's rmse: 0.0868871\n",
      "[2850]\ttraining's rmse: 0.0823402\tvalid_1's rmse: 0.0868876\n",
      "Early stopping, best iteration is:\n",
      "[2815]\ttraining's rmse: 0.0823427\tvalid_1's rmse: 0.0868869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.085586\tvalid_1's rmse: 0.0876769\n",
      "[50]\ttraining's rmse: 0.0854637\tvalid_1's rmse: 0.0876227\n",
      "[75]\ttraining's rmse: 0.0853356\tvalid_1's rmse: 0.0875694\n",
      "[100]\ttraining's rmse: 0.0852212\tvalid_1's rmse: 0.0875234\n",
      "[125]\ttraining's rmse: 0.0851025\tvalid_1's rmse: 0.0874761\n",
      "[150]\ttraining's rmse: 0.0849909\tvalid_1's rmse: 0.0874301\n",
      "[175]\ttraining's rmse: 0.0849007\tvalid_1's rmse: 0.0873937\n",
      "[200]\ttraining's rmse: 0.0848028\tvalid_1's rmse: 0.0873545\n",
      "[225]\ttraining's rmse: 0.0847081\tvalid_1's rmse: 0.0873182\n",
      "[250]\ttraining's rmse: 0.0846251\tvalid_1's rmse: 0.0872853\n",
      "[275]\ttraining's rmse: 0.0845492\tvalid_1's rmse: 0.0872555\n",
      "[300]\ttraining's rmse: 0.084473\tvalid_1's rmse: 0.087227\n",
      "[325]\ttraining's rmse: 0.0843959\tvalid_1's rmse: 0.0871999\n",
      "[350]\ttraining's rmse: 0.0843206\tvalid_1's rmse: 0.0871734\n",
      "[375]\ttraining's rmse: 0.0842621\tvalid_1's rmse: 0.0871503\n",
      "[400]\ttraining's rmse: 0.0841959\tvalid_1's rmse: 0.0871277\n",
      "[425]\ttraining's rmse: 0.084138\tvalid_1's rmse: 0.087107\n",
      "[450]\ttraining's rmse: 0.0840812\tvalid_1's rmse: 0.0870867\n",
      "[475]\ttraining's rmse: 0.0840283\tvalid_1's rmse: 0.0870691\n",
      "[500]\ttraining's rmse: 0.0839842\tvalid_1's rmse: 0.0870533\n",
      "[525]\ttraining's rmse: 0.0839273\tvalid_1's rmse: 0.0870354\n",
      "[550]\ttraining's rmse: 0.0838757\tvalid_1's rmse: 0.0870201\n",
      "[575]\ttraining's rmse: 0.0838271\tvalid_1's rmse: 0.087006\n",
      "[600]\ttraining's rmse: 0.0837812\tvalid_1's rmse: 0.0869923\n",
      "[625]\ttraining's rmse: 0.0837451\tvalid_1's rmse: 0.0869797\n",
      "[650]\ttraining's rmse: 0.0836991\tvalid_1's rmse: 0.0869665\n",
      "[675]\ttraining's rmse: 0.0836551\tvalid_1's rmse: 0.0869547\n",
      "[700]\ttraining's rmse: 0.0836165\tvalid_1's rmse: 0.0869432\n",
      "[725]\ttraining's rmse: 0.0835804\tvalid_1's rmse: 0.0869327\n",
      "[750]\ttraining's rmse: 0.0835436\tvalid_1's rmse: 0.0869233\n",
      "[775]\ttraining's rmse: 0.0835156\tvalid_1's rmse: 0.0869139\n",
      "[800]\ttraining's rmse: 0.0834801\tvalid_1's rmse: 0.0869049\n",
      "[825]\ttraining's rmse: 0.0834478\tvalid_1's rmse: 0.0868961\n",
      "[850]\ttraining's rmse: 0.0834171\tvalid_1's rmse: 0.0868896\n",
      "[875]\ttraining's rmse: 0.0833898\tvalid_1's rmse: 0.0868827\n",
      "[900]\ttraining's rmse: 0.0833606\tvalid_1's rmse: 0.0868753\n",
      "[925]\ttraining's rmse: 0.083331\tvalid_1's rmse: 0.0868692\n",
      "[950]\ttraining's rmse: 0.0833028\tvalid_1's rmse: 0.0868627\n",
      "[975]\ttraining's rmse: 0.0832778\tvalid_1's rmse: 0.0868572\n",
      "[1000]\ttraining's rmse: 0.0832553\tvalid_1's rmse: 0.0868526\n",
      "[1025]\ttraining's rmse: 0.0832298\tvalid_1's rmse: 0.0868476\n",
      "[1050]\ttraining's rmse: 0.083207\tvalid_1's rmse: 0.0868424\n",
      "[1075]\ttraining's rmse: 0.0831851\tvalid_1's rmse: 0.0868391\n",
      "[1100]\ttraining's rmse: 0.0831678\tvalid_1's rmse: 0.0868345\n",
      "[1125]\ttraining's rmse: 0.0831458\tvalid_1's rmse: 0.0868307\n",
      "[1150]\ttraining's rmse: 0.0831261\tvalid_1's rmse: 0.0868263\n",
      "[1175]\ttraining's rmse: 0.0831096\tvalid_1's rmse: 0.0868229\n",
      "[1200]\ttraining's rmse: 0.0830918\tvalid_1's rmse: 0.0868191\n",
      "[1225]\ttraining's rmse: 0.083074\tvalid_1's rmse: 0.086816\n",
      "[1250]\ttraining's rmse: 0.083061\tvalid_1's rmse: 0.0868136\n",
      "[1275]\ttraining's rmse: 0.0830437\tvalid_1's rmse: 0.0868113\n",
      "[1300]\ttraining's rmse: 0.0830287\tvalid_1's rmse: 0.0868081\n",
      "[1325]\ttraining's rmse: 0.0830131\tvalid_1's rmse: 0.0868054\n",
      "[1350]\ttraining's rmse: 0.0829996\tvalid_1's rmse: 0.0868033\n",
      "[1375]\ttraining's rmse: 0.0829868\tvalid_1's rmse: 0.0868014\n",
      "[1400]\ttraining's rmse: 0.0829755\tvalid_1's rmse: 0.0867984\n",
      "[1425]\ttraining's rmse: 0.0829633\tvalid_1's rmse: 0.0867962\n",
      "[1450]\ttraining's rmse: 0.0829497\tvalid_1's rmse: 0.0867944\n",
      "[1475]\ttraining's rmse: 0.0829365\tvalid_1's rmse: 0.0867919\n",
      "[1500]\ttraining's rmse: 0.0829276\tvalid_1's rmse: 0.0867903\n",
      "[1525]\ttraining's rmse: 0.0829165\tvalid_1's rmse: 0.0867888\n",
      "[1550]\ttraining's rmse: 0.0829066\tvalid_1's rmse: 0.0867876\n",
      "[1575]\ttraining's rmse: 0.0828964\tvalid_1's rmse: 0.0867862\n",
      "[1600]\ttraining's rmse: 0.0828883\tvalid_1's rmse: 0.0867859\n",
      "[1625]\ttraining's rmse: 0.0828781\tvalid_1's rmse: 0.0867846\n",
      "[1650]\ttraining's rmse: 0.0828689\tvalid_1's rmse: 0.0867837\n",
      "[1675]\ttraining's rmse: 0.0828624\tvalid_1's rmse: 0.0867819\n",
      "[1700]\ttraining's rmse: 0.082854\tvalid_1's rmse: 0.0867807\n",
      "[1725]\ttraining's rmse: 0.0828478\tvalid_1's rmse: 0.0867798\n",
      "[1750]\ttraining's rmse: 0.08284\tvalid_1's rmse: 0.0867788\n",
      "[1775]\ttraining's rmse: 0.0828333\tvalid_1's rmse: 0.0867782\n",
      "[1800]\ttraining's rmse: 0.0828267\tvalid_1's rmse: 0.0867778\n",
      "[1825]\ttraining's rmse: 0.0828196\tvalid_1's rmse: 0.0867776\n",
      "[1850]\ttraining's rmse: 0.082813\tvalid_1's rmse: 0.0867767\n",
      "[1875]\ttraining's rmse: 0.0828071\tvalid_1's rmse: 0.0867761\n",
      "[1900]\ttraining's rmse: 0.0828025\tvalid_1's rmse: 0.0867755\n",
      "[1925]\ttraining's rmse: 0.0827973\tvalid_1's rmse: 0.0867754\n",
      "[1950]\ttraining's rmse: 0.0827926\tvalid_1's rmse: 0.086775\n",
      "[1975]\ttraining's rmse: 0.0827879\tvalid_1's rmse: 0.0867745\n",
      "[2000]\ttraining's rmse: 0.0827837\tvalid_1's rmse: 0.086774\n",
      "[2025]\ttraining's rmse: 0.0827794\tvalid_1's rmse: 0.0867729\n",
      "[2050]\ttraining's rmse: 0.0827751\tvalid_1's rmse: 0.0867727\n",
      "[2075]\ttraining's rmse: 0.082771\tvalid_1's rmse: 0.0867718\n",
      "[2100]\ttraining's rmse: 0.082766\tvalid_1's rmse: 0.0867709\n",
      "[2125]\ttraining's rmse: 0.0827625\tvalid_1's rmse: 0.0867707\n",
      "[2150]\ttraining's rmse: 0.0827592\tvalid_1's rmse: 0.0867706\n",
      "[2175]\ttraining's rmse: 0.0827565\tvalid_1's rmse: 0.0867704\n",
      "[2200]\ttraining's rmse: 0.0827523\tvalid_1's rmse: 0.0867703\n",
      "[2225]\ttraining's rmse: 0.0827494\tvalid_1's rmse: 0.0867699\n",
      "[2250]\ttraining's rmse: 0.0827456\tvalid_1's rmse: 0.0867695\n",
      "[2275]\ttraining's rmse: 0.082742\tvalid_1's rmse: 0.0867691\n",
      "[2300]\ttraining's rmse: 0.0827371\tvalid_1's rmse: 0.0867685\n",
      "[2325]\ttraining's rmse: 0.0827339\tvalid_1's rmse: 0.0867683\n",
      "[2350]\ttraining's rmse: 0.0827319\tvalid_1's rmse: 0.0867681\n",
      "[2375]\ttraining's rmse: 0.082728\tvalid_1's rmse: 0.0867675\n",
      "[2400]\ttraining's rmse: 0.0827246\tvalid_1's rmse: 0.0867676\n",
      "[2425]\ttraining's rmse: 0.0827208\tvalid_1's rmse: 0.0867672\n",
      "[2450]\ttraining's rmse: 0.0827174\tvalid_1's rmse: 0.0867669\n",
      "[2475]\ttraining's rmse: 0.0827142\tvalid_1's rmse: 0.0867671\n",
      "[2500]\ttraining's rmse: 0.0827116\tvalid_1's rmse: 0.0867673\n",
      "Early stopping, best iteration is:\n",
      "[2451]\ttraining's rmse: 0.0827172\tvalid_1's rmse: 0.0867668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876039\tvalid_1's rmse: 0.0835624\n",
      "[50]\ttraining's rmse: 0.0874818\tvalid_1's rmse: 0.0835172\n",
      "[75]\ttraining's rmse: 0.0873516\tvalid_1's rmse: 0.0834665\n",
      "[100]\ttraining's rmse: 0.087236\tvalid_1's rmse: 0.0834233\n",
      "[125]\ttraining's rmse: 0.0871175\tvalid_1's rmse: 0.0833816\n",
      "[150]\ttraining's rmse: 0.0870074\tvalid_1's rmse: 0.0833439\n",
      "[175]\ttraining's rmse: 0.0869174\tvalid_1's rmse: 0.0833121\n",
      "[200]\ttraining's rmse: 0.0868161\tvalid_1's rmse: 0.0832805\n",
      "[225]\ttraining's rmse: 0.0867191\tvalid_1's rmse: 0.0832475\n",
      "[250]\ttraining's rmse: 0.0866367\tvalid_1's rmse: 0.0832208\n",
      "[275]\ttraining's rmse: 0.0865616\tvalid_1's rmse: 0.083195\n",
      "[300]\ttraining's rmse: 0.0864865\tvalid_1's rmse: 0.0831715\n",
      "[325]\ttraining's rmse: 0.0864096\tvalid_1's rmse: 0.0831493\n",
      "[350]\ttraining's rmse: 0.0863363\tvalid_1's rmse: 0.0831281\n",
      "[375]\ttraining's rmse: 0.0862748\tvalid_1's rmse: 0.0831109\n",
      "[400]\ttraining's rmse: 0.0862079\tvalid_1's rmse: 0.0830938\n",
      "[425]\ttraining's rmse: 0.0861473\tvalid_1's rmse: 0.0830816\n",
      "[450]\ttraining's rmse: 0.0860931\tvalid_1's rmse: 0.0830649\n",
      "[475]\ttraining's rmse: 0.086042\tvalid_1's rmse: 0.083054\n",
      "[500]\ttraining's rmse: 0.0859981\tvalid_1's rmse: 0.083041\n",
      "[525]\ttraining's rmse: 0.0859382\tvalid_1's rmse: 0.0830311\n",
      "[550]\ttraining's rmse: 0.0858855\tvalid_1's rmse: 0.0830176\n",
      "[575]\ttraining's rmse: 0.0858371\tvalid_1's rmse: 0.0830098\n",
      "[600]\ttraining's rmse: 0.0857914\tvalid_1's rmse: 0.0830097\n",
      "[625]\ttraining's rmse: 0.0857518\tvalid_1's rmse: 0.083001\n",
      "[650]\ttraining's rmse: 0.0857054\tvalid_1's rmse: 0.0830008\n",
      "[675]\ttraining's rmse: 0.085658\tvalid_1's rmse: 0.0829937\n",
      "[700]\ttraining's rmse: 0.0856169\tvalid_1's rmse: 0.0829864\n",
      "[725]\ttraining's rmse: 0.0855793\tvalid_1's rmse: 0.0829849\n",
      "[750]\ttraining's rmse: 0.0855431\tvalid_1's rmse: 0.0829816\n",
      "[775]\ttraining's rmse: 0.0855151\tvalid_1's rmse: 0.0829802\n",
      "Early stopping, best iteration is:\n",
      "[747]\ttraining's rmse: 0.0855488\tvalid_1's rmse: 0.0829768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0826085\tvalid_1's rmse: 0.0852646\n",
      "[50]\ttraining's rmse: 0.0824809\tvalid_1's rmse: 0.0852091\n",
      "[75]\ttraining's rmse: 0.0823573\tvalid_1's rmse: 0.0851552\n",
      "[100]\ttraining's rmse: 0.0822414\tvalid_1's rmse: 0.0851102\n",
      "[125]\ttraining's rmse: 0.0821255\tvalid_1's rmse: 0.085063\n",
      "[150]\ttraining's rmse: 0.0820211\tvalid_1's rmse: 0.0850205\n",
      "[175]\ttraining's rmse: 0.0819329\tvalid_1's rmse: 0.0849818\n",
      "[200]\ttraining's rmse: 0.0818392\tvalid_1's rmse: 0.0849433\n",
      "[225]\ttraining's rmse: 0.0817464\tvalid_1's rmse: 0.0849085\n",
      "[250]\ttraining's rmse: 0.081671\tvalid_1's rmse: 0.0848757\n",
      "[275]\ttraining's rmse: 0.0815946\tvalid_1's rmse: 0.0848455\n",
      "[300]\ttraining's rmse: 0.081525\tvalid_1's rmse: 0.0848174\n",
      "[325]\ttraining's rmse: 0.0814564\tvalid_1's rmse: 0.0847919\n",
      "[350]\ttraining's rmse: 0.0813892\tvalid_1's rmse: 0.0847654\n",
      "[375]\ttraining's rmse: 0.0813308\tvalid_1's rmse: 0.0847441\n",
      "[400]\ttraining's rmse: 0.0812703\tvalid_1's rmse: 0.0847228\n",
      "[425]\ttraining's rmse: 0.0812159\tvalid_1's rmse: 0.084702\n",
      "[450]\ttraining's rmse: 0.0811634\tvalid_1's rmse: 0.0846815\n",
      "[475]\ttraining's rmse: 0.0811164\tvalid_1's rmse: 0.0846635\n",
      "[500]\ttraining's rmse: 0.0810763\tvalid_1's rmse: 0.0846469\n",
      "[525]\ttraining's rmse: 0.0810262\tvalid_1's rmse: 0.0846293\n",
      "[550]\ttraining's rmse: 0.08098\tvalid_1's rmse: 0.0846125\n",
      "[575]\ttraining's rmse: 0.0809348\tvalid_1's rmse: 0.0845971\n",
      "[600]\ttraining's rmse: 0.0808926\tvalid_1's rmse: 0.0845823\n",
      "[625]\ttraining's rmse: 0.0808597\tvalid_1's rmse: 0.08457\n",
      "[650]\ttraining's rmse: 0.0808203\tvalid_1's rmse: 0.0845562\n",
      "[675]\ttraining's rmse: 0.0807818\tvalid_1's rmse: 0.0845436\n",
      "[700]\ttraining's rmse: 0.0807436\tvalid_1's rmse: 0.0845323\n",
      "[725]\ttraining's rmse: 0.0807101\tvalid_1's rmse: 0.0845218\n",
      "[750]\ttraining's rmse: 0.0806776\tvalid_1's rmse: 0.0845109\n",
      "[775]\ttraining's rmse: 0.0806528\tvalid_1's rmse: 0.0844989\n",
      "[800]\ttraining's rmse: 0.0806177\tvalid_1's rmse: 0.0844907\n",
      "[825]\ttraining's rmse: 0.0805896\tvalid_1's rmse: 0.0844817\n",
      "[850]\ttraining's rmse: 0.0805585\tvalid_1's rmse: 0.0844735\n",
      "[875]\ttraining's rmse: 0.080532\tvalid_1's rmse: 0.0844655\n",
      "[900]\ttraining's rmse: 0.0805035\tvalid_1's rmse: 0.0844582\n",
      "[925]\ttraining's rmse: 0.0804797\tvalid_1's rmse: 0.0844501\n",
      "[950]\ttraining's rmse: 0.0804569\tvalid_1's rmse: 0.0844433\n",
      "[975]\ttraining's rmse: 0.0804341\tvalid_1's rmse: 0.0844372\n",
      "[1000]\ttraining's rmse: 0.0804123\tvalid_1's rmse: 0.0844304\n",
      "[1025]\ttraining's rmse: 0.0803902\tvalid_1's rmse: 0.084424\n",
      "[1050]\ttraining's rmse: 0.0803706\tvalid_1's rmse: 0.0844173\n",
      "[1075]\ttraining's rmse: 0.0803497\tvalid_1's rmse: 0.0844124\n",
      "[1100]\ttraining's rmse: 0.0803344\tvalid_1's rmse: 0.0844081\n",
      "[1125]\ttraining's rmse: 0.0803197\tvalid_1's rmse: 0.0844028\n",
      "[1150]\ttraining's rmse: 0.0803023\tvalid_1's rmse: 0.0843989\n",
      "[1175]\ttraining's rmse: 0.0802866\tvalid_1's rmse: 0.084395\n",
      "[1200]\ttraining's rmse: 0.0802685\tvalid_1's rmse: 0.0843905\n",
      "[1225]\ttraining's rmse: 0.0802522\tvalid_1's rmse: 0.0843858\n",
      "[1250]\ttraining's rmse: 0.0802405\tvalid_1's rmse: 0.0843803\n",
      "[1275]\ttraining's rmse: 0.080224\tvalid_1's rmse: 0.0843756\n",
      "[1300]\ttraining's rmse: 0.0802119\tvalid_1's rmse: 0.084371\n",
      "[1325]\ttraining's rmse: 0.0801986\tvalid_1's rmse: 0.0843669\n",
      "[1350]\ttraining's rmse: 0.0801872\tvalid_1's rmse: 0.0843646\n",
      "[1375]\ttraining's rmse: 0.0801738\tvalid_1's rmse: 0.0843614\n",
      "[1400]\ttraining's rmse: 0.0801644\tvalid_1's rmse: 0.0843574\n",
      "[1425]\ttraining's rmse: 0.0801517\tvalid_1's rmse: 0.0843552\n",
      "[1450]\ttraining's rmse: 0.0801418\tvalid_1's rmse: 0.0843529\n",
      "[1475]\ttraining's rmse: 0.0801343\tvalid_1's rmse: 0.0843504\n",
      "[1500]\ttraining's rmse: 0.0801258\tvalid_1's rmse: 0.0843469\n",
      "[1525]\ttraining's rmse: 0.080118\tvalid_1's rmse: 0.0843459\n",
      "[1550]\ttraining's rmse: 0.0801079\tvalid_1's rmse: 0.0843437\n",
      "[1575]\ttraining's rmse: 0.0801013\tvalid_1's rmse: 0.0843399\n",
      "[1600]\ttraining's rmse: 0.0800945\tvalid_1's rmse: 0.0843381\n",
      "[1625]\ttraining's rmse: 0.0800872\tvalid_1's rmse: 0.0843347\n",
      "[1650]\ttraining's rmse: 0.0800812\tvalid_1's rmse: 0.0843332\n",
      "[1675]\ttraining's rmse: 0.080076\tvalid_1's rmse: 0.0843305\n",
      "[1700]\ttraining's rmse: 0.0800689\tvalid_1's rmse: 0.0843279\n",
      "[1725]\ttraining's rmse: 0.0800631\tvalid_1's rmse: 0.084327\n",
      "[1750]\ttraining's rmse: 0.0800554\tvalid_1's rmse: 0.0843252\n",
      "[1775]\ttraining's rmse: 0.0800503\tvalid_1's rmse: 0.0843243\n",
      "[1800]\ttraining's rmse: 0.0800441\tvalid_1's rmse: 0.0843215\n",
      "[1825]\ttraining's rmse: 0.0800381\tvalid_1's rmse: 0.0843212\n",
      "[1850]\ttraining's rmse: 0.0800331\tvalid_1's rmse: 0.0843193\n",
      "[1875]\ttraining's rmse: 0.0800281\tvalid_1's rmse: 0.0843172\n",
      "[1900]\ttraining's rmse: 0.080024\tvalid_1's rmse: 0.0843161\n",
      "[1925]\ttraining's rmse: 0.0800195\tvalid_1's rmse: 0.0843157\n",
      "[1950]\ttraining's rmse: 0.0800161\tvalid_1's rmse: 0.0843138\n",
      "[1975]\ttraining's rmse: 0.080013\tvalid_1's rmse: 0.084313\n",
      "[2000]\ttraining's rmse: 0.0800092\tvalid_1's rmse: 0.0843124\n",
      "[2025]\ttraining's rmse: 0.0800065\tvalid_1's rmse: 0.0843106\n",
      "[2050]\ttraining's rmse: 0.080003\tvalid_1's rmse: 0.0843093\n",
      "[2075]\ttraining's rmse: 0.0800001\tvalid_1's rmse: 0.0843077\n",
      "[2100]\ttraining's rmse: 0.0799974\tvalid_1's rmse: 0.0843065\n",
      "[2125]\ttraining's rmse: 0.079995\tvalid_1's rmse: 0.0843064\n",
      "[2150]\ttraining's rmse: 0.0799909\tvalid_1's rmse: 0.0843058\n",
      "[2175]\ttraining's rmse: 0.0799888\tvalid_1's rmse: 0.0843057\n",
      "[2200]\ttraining's rmse: 0.0799861\tvalid_1's rmse: 0.084305\n",
      "[2225]\ttraining's rmse: 0.0799833\tvalid_1's rmse: 0.084304\n",
      "[2250]\ttraining's rmse: 0.07998\tvalid_1's rmse: 0.0843029\n",
      "[2275]\ttraining's rmse: 0.0799761\tvalid_1's rmse: 0.0843022\n",
      "[2300]\ttraining's rmse: 0.0799733\tvalid_1's rmse: 0.0843018\n",
      "[2325]\ttraining's rmse: 0.0799712\tvalid_1's rmse: 0.0843007\n",
      "[2350]\ttraining's rmse: 0.0799677\tvalid_1's rmse: 0.0843001\n",
      "[2375]\ttraining's rmse: 0.0799647\tvalid_1's rmse: 0.0842995\n",
      "[2400]\ttraining's rmse: 0.0799619\tvalid_1's rmse: 0.0842995\n",
      "[2425]\ttraining's rmse: 0.0799602\tvalid_1's rmse: 0.0842993\n",
      "[2450]\ttraining's rmse: 0.0799588\tvalid_1's rmse: 0.0842992\n",
      "[2475]\ttraining's rmse: 0.0799554\tvalid_1's rmse: 0.0842984\n",
      "[2500]\ttraining's rmse: 0.079953\tvalid_1's rmse: 0.0842979\n",
      "[2525]\ttraining's rmse: 0.0799502\tvalid_1's rmse: 0.084297\n",
      "[2550]\ttraining's rmse: 0.0799481\tvalid_1's rmse: 0.0842968\n",
      "[2575]\ttraining's rmse: 0.0799462\tvalid_1's rmse: 0.0842958\n",
      "[2600]\ttraining's rmse: 0.079944\tvalid_1's rmse: 0.0842956\n",
      "[2625]\ttraining's rmse: 0.0799424\tvalid_1's rmse: 0.0842952\n",
      "[2650]\ttraining's rmse: 0.0799412\tvalid_1's rmse: 0.0842949\n",
      "[2675]\ttraining's rmse: 0.0799403\tvalid_1's rmse: 0.0842948\n",
      "[2700]\ttraining's rmse: 0.0799393\tvalid_1's rmse: 0.0842945\n",
      "[2725]\ttraining's rmse: 0.0799372\tvalid_1's rmse: 0.0842947\n",
      "[2750]\ttraining's rmse: 0.0799352\tvalid_1's rmse: 0.0842942\n",
      "[2775]\ttraining's rmse: 0.079933\tvalid_1's rmse: 0.084294\n",
      "[2800]\ttraining's rmse: 0.0799318\tvalid_1's rmse: 0.084294\n",
      "[2825]\ttraining's rmse: 0.079929\tvalid_1's rmse: 0.0842936\n",
      "[2850]\ttraining's rmse: 0.0799279\tvalid_1's rmse: 0.0842939\n",
      "Early stopping, best iteration is:\n",
      "[2815]\ttraining's rmse: 0.0799293\tvalid_1's rmse: 0.0842934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0827661\tvalid_1's rmse: 0.0849548\n",
      "[50]\ttraining's rmse: 0.0826513\tvalid_1's rmse: 0.0848979\n",
      "[75]\ttraining's rmse: 0.082532\tvalid_1's rmse: 0.0848426\n",
      "[100]\ttraining's rmse: 0.0824258\tvalid_1's rmse: 0.0847949\n",
      "[125]\ttraining's rmse: 0.0823139\tvalid_1's rmse: 0.0847461\n",
      "[150]\ttraining's rmse: 0.0822124\tvalid_1's rmse: 0.0847019\n",
      "[175]\ttraining's rmse: 0.0821303\tvalid_1's rmse: 0.0846655\n",
      "[200]\ttraining's rmse: 0.0820396\tvalid_1's rmse: 0.0846289\n",
      "[225]\ttraining's rmse: 0.0819521\tvalid_1's rmse: 0.0845933\n",
      "[250]\ttraining's rmse: 0.0818781\tvalid_1's rmse: 0.0845623\n",
      "[275]\ttraining's rmse: 0.0818067\tvalid_1's rmse: 0.0845331\n",
      "[300]\ttraining's rmse: 0.0817369\tvalid_1's rmse: 0.084507\n",
      "[325]\ttraining's rmse: 0.081666\tvalid_1's rmse: 0.0844809\n",
      "[350]\ttraining's rmse: 0.0815967\tvalid_1's rmse: 0.0844565\n",
      "[375]\ttraining's rmse: 0.0815418\tvalid_1's rmse: 0.084436\n",
      "[400]\ttraining's rmse: 0.0814794\tvalid_1's rmse: 0.084415\n",
      "[425]\ttraining's rmse: 0.0814239\tvalid_1's rmse: 0.084395\n",
      "[450]\ttraining's rmse: 0.0813725\tvalid_1's rmse: 0.0843764\n",
      "[475]\ttraining's rmse: 0.0813266\tvalid_1's rmse: 0.0843611\n",
      "[500]\ttraining's rmse: 0.081284\tvalid_1's rmse: 0.0843449\n",
      "[525]\ttraining's rmse: 0.0812298\tvalid_1's rmse: 0.0843285\n",
      "[550]\ttraining's rmse: 0.0811816\tvalid_1's rmse: 0.0843141\n",
      "[575]\ttraining's rmse: 0.0811374\tvalid_1's rmse: 0.0843002\n",
      "[600]\ttraining's rmse: 0.0810926\tvalid_1's rmse: 0.0842872\n",
      "[625]\ttraining's rmse: 0.081059\tvalid_1's rmse: 0.0842753\n",
      "[650]\ttraining's rmse: 0.0810153\tvalid_1's rmse: 0.0842634\n",
      "[675]\ttraining's rmse: 0.0809731\tvalid_1's rmse: 0.0842518\n",
      "[700]\ttraining's rmse: 0.0809371\tvalid_1's rmse: 0.084241\n",
      "[725]\ttraining's rmse: 0.0809016\tvalid_1's rmse: 0.0842315\n",
      "[750]\ttraining's rmse: 0.0808691\tvalid_1's rmse: 0.0842221\n",
      "[775]\ttraining's rmse: 0.0808397\tvalid_1's rmse: 0.084213\n",
      "[800]\ttraining's rmse: 0.0808054\tvalid_1's rmse: 0.0842054\n",
      "[825]\ttraining's rmse: 0.0807764\tvalid_1's rmse: 0.0841969\n",
      "[850]\ttraining's rmse: 0.0807483\tvalid_1's rmse: 0.0841897\n",
      "[875]\ttraining's rmse: 0.0807213\tvalid_1's rmse: 0.0841829\n",
      "[900]\ttraining's rmse: 0.0806922\tvalid_1's rmse: 0.0841761\n",
      "[925]\ttraining's rmse: 0.0806682\tvalid_1's rmse: 0.0841707\n",
      "[950]\ttraining's rmse: 0.0806448\tvalid_1's rmse: 0.0841653\n",
      "[975]\ttraining's rmse: 0.0806211\tvalid_1's rmse: 0.0841599\n",
      "[1000]\ttraining's rmse: 0.0805987\tvalid_1's rmse: 0.0841543\n",
      "[1025]\ttraining's rmse: 0.080573\tvalid_1's rmse: 0.0841492\n",
      "[1050]\ttraining's rmse: 0.0805525\tvalid_1's rmse: 0.0841445\n",
      "[1075]\ttraining's rmse: 0.080532\tvalid_1's rmse: 0.0841408\n",
      "[1100]\ttraining's rmse: 0.0805139\tvalid_1's rmse: 0.0841364\n",
      "[1125]\ttraining's rmse: 0.0804951\tvalid_1's rmse: 0.0841331\n",
      "[1150]\ttraining's rmse: 0.0804789\tvalid_1's rmse: 0.0841294\n",
      "[1175]\ttraining's rmse: 0.0804645\tvalid_1's rmse: 0.0841259\n",
      "[1200]\ttraining's rmse: 0.0804463\tvalid_1's rmse: 0.0841223\n",
      "[1225]\ttraining's rmse: 0.0804308\tvalid_1's rmse: 0.0841201\n",
      "[1250]\ttraining's rmse: 0.0804156\tvalid_1's rmse: 0.0841164\n",
      "[1275]\ttraining's rmse: 0.0804011\tvalid_1's rmse: 0.0841145\n",
      "[1300]\ttraining's rmse: 0.0803898\tvalid_1's rmse: 0.0841117\n",
      "[1325]\ttraining's rmse: 0.0803757\tvalid_1's rmse: 0.0841092\n",
      "[1350]\ttraining's rmse: 0.0803641\tvalid_1's rmse: 0.0841073\n",
      "[1375]\ttraining's rmse: 0.0803524\tvalid_1's rmse: 0.0841055\n",
      "[1400]\ttraining's rmse: 0.0803427\tvalid_1's rmse: 0.084103\n",
      "[1425]\ttraining's rmse: 0.0803323\tvalid_1's rmse: 0.0841015\n",
      "[1450]\ttraining's rmse: 0.0803221\tvalid_1's rmse: 0.0841004\n",
      "[1475]\ttraining's rmse: 0.0803123\tvalid_1's rmse: 0.0840984\n",
      "[1500]\ttraining's rmse: 0.0803027\tvalid_1's rmse: 0.0840967\n",
      "[1525]\ttraining's rmse: 0.080294\tvalid_1's rmse: 0.0840947\n",
      "[1550]\ttraining's rmse: 0.0802853\tvalid_1's rmse: 0.0840934\n",
      "[1575]\ttraining's rmse: 0.0802777\tvalid_1's rmse: 0.0840917\n",
      "[1600]\ttraining's rmse: 0.0802676\tvalid_1's rmse: 0.084091\n",
      "[1625]\ttraining's rmse: 0.0802592\tvalid_1's rmse: 0.0840892\n",
      "[1650]\ttraining's rmse: 0.0802517\tvalid_1's rmse: 0.0840886\n",
      "[1675]\ttraining's rmse: 0.0802461\tvalid_1's rmse: 0.0840877\n",
      "[1700]\ttraining's rmse: 0.0802395\tvalid_1's rmse: 0.0840862\n",
      "[1725]\ttraining's rmse: 0.0802333\tvalid_1's rmse: 0.0840851\n",
      "[1750]\ttraining's rmse: 0.0802269\tvalid_1's rmse: 0.0840841\n",
      "[1775]\ttraining's rmse: 0.0802211\tvalid_1's rmse: 0.0840836\n",
      "[1800]\ttraining's rmse: 0.0802152\tvalid_1's rmse: 0.084083\n",
      "[1825]\ttraining's rmse: 0.0802104\tvalid_1's rmse: 0.0840819\n",
      "[1850]\ttraining's rmse: 0.0802036\tvalid_1's rmse: 0.0840812\n",
      "[1875]\ttraining's rmse: 0.080199\tvalid_1's rmse: 0.0840808\n",
      "[1900]\ttraining's rmse: 0.080196\tvalid_1's rmse: 0.0840808\n",
      "[1925]\ttraining's rmse: 0.0801929\tvalid_1's rmse: 0.0840806\n",
      "[1950]\ttraining's rmse: 0.0801889\tvalid_1's rmse: 0.08408\n",
      "[1975]\ttraining's rmse: 0.0801862\tvalid_1's rmse: 0.0840798\n",
      "[2000]\ttraining's rmse: 0.0801825\tvalid_1's rmse: 0.0840797\n",
      "[2025]\ttraining's rmse: 0.0801801\tvalid_1's rmse: 0.0840791\n",
      "[2050]\ttraining's rmse: 0.0801752\tvalid_1's rmse: 0.0840786\n",
      "[2075]\ttraining's rmse: 0.0801726\tvalid_1's rmse: 0.0840782\n",
      "[2100]\ttraining's rmse: 0.0801694\tvalid_1's rmse: 0.0840778\n",
      "[2125]\ttraining's rmse: 0.0801665\tvalid_1's rmse: 0.0840777\n",
      "[2150]\ttraining's rmse: 0.0801626\tvalid_1's rmse: 0.0840776\n",
      "[2175]\ttraining's rmse: 0.0801599\tvalid_1's rmse: 0.0840772\n",
      "[2200]\ttraining's rmse: 0.0801578\tvalid_1's rmse: 0.084077\n",
      "[2225]\ttraining's rmse: 0.0801547\tvalid_1's rmse: 0.0840767\n",
      "[2250]\ttraining's rmse: 0.080152\tvalid_1's rmse: 0.0840763\n",
      "[2275]\ttraining's rmse: 0.0801487\tvalid_1's rmse: 0.0840758\n",
      "[2300]\ttraining's rmse: 0.0801465\tvalid_1's rmse: 0.0840756\n",
      "[2325]\ttraining's rmse: 0.080144\tvalid_1's rmse: 0.0840759\n",
      "Early stopping, best iteration is:\n",
      "[2294]\ttraining's rmse: 0.0801473\tvalid_1's rmse: 0.0840755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0849873\tvalid_1's rmse: 0.0804419\n",
      "[50]\ttraining's rmse: 0.0848745\tvalid_1's rmse: 0.0803928\n",
      "[75]\ttraining's rmse: 0.0847548\tvalid_1's rmse: 0.0803436\n",
      "[100]\ttraining's rmse: 0.0846493\tvalid_1's rmse: 0.0803005\n",
      "[125]\ttraining's rmse: 0.0845417\tvalid_1's rmse: 0.0802591\n",
      "[150]\ttraining's rmse: 0.0844424\tvalid_1's rmse: 0.0802212\n",
      "[175]\ttraining's rmse: 0.0843591\tvalid_1's rmse: 0.0801885\n",
      "[200]\ttraining's rmse: 0.0842701\tvalid_1's rmse: 0.0801578\n",
      "[225]\ttraining's rmse: 0.0841854\tvalid_1's rmse: 0.080127\n",
      "[250]\ttraining's rmse: 0.0841117\tvalid_1's rmse: 0.0801024\n",
      "[275]\ttraining's rmse: 0.0840448\tvalid_1's rmse: 0.0800772\n",
      "[300]\ttraining's rmse: 0.0839763\tvalid_1's rmse: 0.080054\n",
      "[325]\ttraining's rmse: 0.0839095\tvalid_1's rmse: 0.0800319\n",
      "[350]\ttraining's rmse: 0.0838431\tvalid_1's rmse: 0.0800095\n",
      "[375]\ttraining's rmse: 0.0837881\tvalid_1's rmse: 0.0799947\n",
      "[400]\ttraining's rmse: 0.0837284\tvalid_1's rmse: 0.0799765\n",
      "[425]\ttraining's rmse: 0.0836751\tvalid_1's rmse: 0.0799632\n",
      "[450]\ttraining's rmse: 0.0836246\tvalid_1's rmse: 0.0799472\n",
      "[475]\ttraining's rmse: 0.0835791\tvalid_1's rmse: 0.0799332\n",
      "[500]\ttraining's rmse: 0.0835395\tvalid_1's rmse: 0.079923\n",
      "[525]\ttraining's rmse: 0.0834862\tvalid_1's rmse: 0.0799118\n",
      "[550]\ttraining's rmse: 0.0834387\tvalid_1's rmse: 0.0799053\n",
      "[575]\ttraining's rmse: 0.0833968\tvalid_1's rmse: 0.0798944\n",
      "[600]\ttraining's rmse: 0.0833532\tvalid_1's rmse: 0.0798964\n",
      "[625]\ttraining's rmse: 0.0833197\tvalid_1's rmse: 0.0799003\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's rmse: 0.0833644\tvalid_1's rmse: 0.0798925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0865745\tvalid_1's rmse: 0.0886085\n",
      "[50]\ttraining's rmse: 0.0864304\tvalid_1's rmse: 0.088555\n",
      "[75]\ttraining's rmse: 0.0862842\tvalid_1's rmse: 0.088503\n",
      "[100]\ttraining's rmse: 0.0861491\tvalid_1's rmse: 0.088457\n",
      "[125]\ttraining's rmse: 0.0860124\tvalid_1's rmse: 0.0884099\n",
      "[150]\ttraining's rmse: 0.0858885\tvalid_1's rmse: 0.0883668\n",
      "[175]\ttraining's rmse: 0.0857874\tvalid_1's rmse: 0.088331\n",
      "[200]\ttraining's rmse: 0.0856732\tvalid_1's rmse: 0.088293\n",
      "[225]\ttraining's rmse: 0.0855607\tvalid_1's rmse: 0.0882575\n",
      "[250]\ttraining's rmse: 0.0854683\tvalid_1's rmse: 0.0882257\n",
      "[275]\ttraining's rmse: 0.0853836\tvalid_1's rmse: 0.0881969\n",
      "[300]\ttraining's rmse: 0.0852973\tvalid_1's rmse: 0.0881683\n",
      "[325]\ttraining's rmse: 0.0852133\tvalid_1's rmse: 0.0881435\n",
      "[350]\ttraining's rmse: 0.0851333\tvalid_1's rmse: 0.0881176\n",
      "[375]\ttraining's rmse: 0.0850661\tvalid_1's rmse: 0.0880962\n",
      "[400]\ttraining's rmse: 0.0849909\tvalid_1's rmse: 0.0880749\n",
      "[425]\ttraining's rmse: 0.0849257\tvalid_1's rmse: 0.0880552\n",
      "[450]\ttraining's rmse: 0.0848659\tvalid_1's rmse: 0.0880365\n",
      "[475]\ttraining's rmse: 0.0848118\tvalid_1's rmse: 0.0880187\n",
      "[500]\ttraining's rmse: 0.0847629\tvalid_1's rmse: 0.0880035\n",
      "[525]\ttraining's rmse: 0.0846988\tvalid_1's rmse: 0.0879874\n",
      "[550]\ttraining's rmse: 0.084644\tvalid_1's rmse: 0.0879724\n",
      "[575]\ttraining's rmse: 0.0845919\tvalid_1's rmse: 0.0879591\n",
      "[600]\ttraining's rmse: 0.0845374\tvalid_1's rmse: 0.0879445\n",
      "[625]\ttraining's rmse: 0.0844971\tvalid_1's rmse: 0.087932\n",
      "[650]\ttraining's rmse: 0.0844495\tvalid_1's rmse: 0.087919\n",
      "[675]\ttraining's rmse: 0.0844015\tvalid_1's rmse: 0.0879063\n",
      "[700]\ttraining's rmse: 0.084358\tvalid_1's rmse: 0.0878959\n",
      "[725]\ttraining's rmse: 0.0843172\tvalid_1's rmse: 0.0878859\n",
      "[750]\ttraining's rmse: 0.0842786\tvalid_1's rmse: 0.0878764\n",
      "[775]\ttraining's rmse: 0.084248\tvalid_1's rmse: 0.087867\n",
      "[800]\ttraining's rmse: 0.0842087\tvalid_1's rmse: 0.087859\n",
      "[825]\ttraining's rmse: 0.0841777\tvalid_1's rmse: 0.0878507\n",
      "[850]\ttraining's rmse: 0.084139\tvalid_1's rmse: 0.0878443\n",
      "[875]\ttraining's rmse: 0.0841094\tvalid_1's rmse: 0.0878383\n",
      "[900]\ttraining's rmse: 0.0840765\tvalid_1's rmse: 0.0878307\n",
      "[925]\ttraining's rmse: 0.0840465\tvalid_1's rmse: 0.0878238\n",
      "[950]\ttraining's rmse: 0.0840169\tvalid_1's rmse: 0.0878167\n",
      "[975]\ttraining's rmse: 0.0839903\tvalid_1's rmse: 0.0878105\n",
      "[1000]\ttraining's rmse: 0.0839654\tvalid_1's rmse: 0.0878041\n",
      "[1025]\ttraining's rmse: 0.083938\tvalid_1's rmse: 0.0877981\n",
      "[1050]\ttraining's rmse: 0.0839157\tvalid_1's rmse: 0.0877917\n",
      "[1075]\ttraining's rmse: 0.0838903\tvalid_1's rmse: 0.0877877\n",
      "[1100]\ttraining's rmse: 0.0838677\tvalid_1's rmse: 0.0877823\n",
      "[1125]\ttraining's rmse: 0.0838453\tvalid_1's rmse: 0.0877775\n",
      "[1150]\ttraining's rmse: 0.0838225\tvalid_1's rmse: 0.0877737\n",
      "[1175]\ttraining's rmse: 0.0838038\tvalid_1's rmse: 0.0877712\n",
      "[1200]\ttraining's rmse: 0.083787\tvalid_1's rmse: 0.0877659\n",
      "[1225]\ttraining's rmse: 0.0837704\tvalid_1's rmse: 0.087763\n",
      "[1250]\ttraining's rmse: 0.0837549\tvalid_1's rmse: 0.0877596\n",
      "[1275]\ttraining's rmse: 0.083735\tvalid_1's rmse: 0.0877559\n",
      "[1300]\ttraining's rmse: 0.0837206\tvalid_1's rmse: 0.0877525\n",
      "[1325]\ttraining's rmse: 0.0837034\tvalid_1's rmse: 0.0877494\n",
      "[1350]\ttraining's rmse: 0.0836885\tvalid_1's rmse: 0.0877469\n",
      "[1375]\ttraining's rmse: 0.0836719\tvalid_1's rmse: 0.0877427\n",
      "[1400]\ttraining's rmse: 0.0836596\tvalid_1's rmse: 0.0877392\n",
      "[1425]\ttraining's rmse: 0.0836444\tvalid_1's rmse: 0.0877369\n",
      "[1450]\ttraining's rmse: 0.0836292\tvalid_1's rmse: 0.0877354\n",
      "[1475]\ttraining's rmse: 0.0836166\tvalid_1's rmse: 0.087732\n",
      "[1500]\ttraining's rmse: 0.0836053\tvalid_1's rmse: 0.0877285\n",
      "[1525]\ttraining's rmse: 0.0835952\tvalid_1's rmse: 0.0877261\n",
      "[1550]\ttraining's rmse: 0.0835842\tvalid_1's rmse: 0.0877246\n",
      "[1575]\ttraining's rmse: 0.0835742\tvalid_1's rmse: 0.0877217\n",
      "[1600]\ttraining's rmse: 0.0835656\tvalid_1's rmse: 0.087719\n",
      "[1625]\ttraining's rmse: 0.0835571\tvalid_1's rmse: 0.0877161\n",
      "[1650]\ttraining's rmse: 0.0835486\tvalid_1's rmse: 0.0877138\n",
      "[1675]\ttraining's rmse: 0.0835429\tvalid_1's rmse: 0.0877118\n",
      "[1700]\ttraining's rmse: 0.083537\tvalid_1's rmse: 0.08771\n",
      "[1725]\ttraining's rmse: 0.0835319\tvalid_1's rmse: 0.087708\n",
      "[1750]\ttraining's rmse: 0.0835235\tvalid_1's rmse: 0.0877055\n",
      "[1775]\ttraining's rmse: 0.0835158\tvalid_1's rmse: 0.0877037\n",
      "[1800]\ttraining's rmse: 0.0835106\tvalid_1's rmse: 0.0877015\n",
      "[1825]\ttraining's rmse: 0.0835047\tvalid_1's rmse: 0.0876999\n",
      "[1850]\ttraining's rmse: 0.0834995\tvalid_1's rmse: 0.0876982\n",
      "[1875]\ttraining's rmse: 0.0834953\tvalid_1's rmse: 0.0876971\n",
      "[1900]\ttraining's rmse: 0.0834888\tvalid_1's rmse: 0.0876955\n",
      "[1925]\ttraining's rmse: 0.0834835\tvalid_1's rmse: 0.0876938\n",
      "[1950]\ttraining's rmse: 0.0834786\tvalid_1's rmse: 0.087692\n",
      "[1975]\ttraining's rmse: 0.0834755\tvalid_1's rmse: 0.0876908\n",
      "[2000]\ttraining's rmse: 0.0834706\tvalid_1's rmse: 0.0876898\n",
      "[2025]\ttraining's rmse: 0.0834668\tvalid_1's rmse: 0.0876886\n",
      "[2050]\ttraining's rmse: 0.083464\tvalid_1's rmse: 0.087688\n",
      "[2075]\ttraining's rmse: 0.0834591\tvalid_1's rmse: 0.0876873\n",
      "[2100]\ttraining's rmse: 0.0834555\tvalid_1's rmse: 0.0876863\n",
      "[2125]\ttraining's rmse: 0.0834521\tvalid_1's rmse: 0.0876849\n",
      "[2150]\ttraining's rmse: 0.0834486\tvalid_1's rmse: 0.0876832\n",
      "[2175]\ttraining's rmse: 0.0834456\tvalid_1's rmse: 0.0876827\n",
      "[2200]\ttraining's rmse: 0.0834417\tvalid_1's rmse: 0.0876816\n",
      "[2225]\ttraining's rmse: 0.0834385\tvalid_1's rmse: 0.087681\n",
      "[2250]\ttraining's rmse: 0.0834355\tvalid_1's rmse: 0.0876796\n",
      "[2275]\ttraining's rmse: 0.0834323\tvalid_1's rmse: 0.0876785\n",
      "[2300]\ttraining's rmse: 0.0834296\tvalid_1's rmse: 0.0876769\n",
      "[2325]\ttraining's rmse: 0.0834269\tvalid_1's rmse: 0.0876752\n",
      "[2350]\ttraining's rmse: 0.0834235\tvalid_1's rmse: 0.0876748\n",
      "[2375]\ttraining's rmse: 0.0834211\tvalid_1's rmse: 0.0876739\n",
      "[2400]\ttraining's rmse: 0.0834184\tvalid_1's rmse: 0.0876735\n",
      "[2425]\ttraining's rmse: 0.0834155\tvalid_1's rmse: 0.0876726\n",
      "[2450]\ttraining's rmse: 0.0834131\tvalid_1's rmse: 0.0876716\n",
      "[2475]\ttraining's rmse: 0.0834099\tvalid_1's rmse: 0.08767\n",
      "[2500]\ttraining's rmse: 0.0834078\tvalid_1's rmse: 0.087669\n",
      "[2525]\ttraining's rmse: 0.0834053\tvalid_1's rmse: 0.0876678\n",
      "[2550]\ttraining's rmse: 0.0834014\tvalid_1's rmse: 0.0876676\n",
      "[2575]\ttraining's rmse: 0.0834006\tvalid_1's rmse: 0.0876674\n",
      "[2600]\ttraining's rmse: 0.0833972\tvalid_1's rmse: 0.0876667\n",
      "[2625]\ttraining's rmse: 0.0833963\tvalid_1's rmse: 0.0876665\n",
      "[2650]\ttraining's rmse: 0.0833926\tvalid_1's rmse: 0.0876662\n",
      "[2675]\ttraining's rmse: 0.0833912\tvalid_1's rmse: 0.0876657\n",
      "[2700]\ttraining's rmse: 0.0833889\tvalid_1's rmse: 0.087664\n",
      "[2725]\ttraining's rmse: 0.0833862\tvalid_1's rmse: 0.0876635\n",
      "[2750]\ttraining's rmse: 0.0833838\tvalid_1's rmse: 0.0876635\n",
      "[2775]\ttraining's rmse: 0.083382\tvalid_1's rmse: 0.0876629\n",
      "[2800]\ttraining's rmse: 0.0833808\tvalid_1's rmse: 0.087663\n",
      "[2825]\ttraining's rmse: 0.0833789\tvalid_1's rmse: 0.0876632\n",
      "[2850]\ttraining's rmse: 0.0833768\tvalid_1's rmse: 0.0876633\n",
      "Early stopping, best iteration is:\n",
      "[2807]\ttraining's rmse: 0.0833806\tvalid_1's rmse: 0.0876627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0866038\tvalid_1's rmse: 0.0885752\n",
      "[50]\ttraining's rmse: 0.0864768\tvalid_1's rmse: 0.088521\n",
      "[75]\ttraining's rmse: 0.0863445\tvalid_1's rmse: 0.088466\n",
      "[100]\ttraining's rmse: 0.0862249\tvalid_1's rmse: 0.0884173\n",
      "[125]\ttraining's rmse: 0.0861029\tvalid_1's rmse: 0.0883691\n",
      "[150]\ttraining's rmse: 0.085994\tvalid_1's rmse: 0.088324\n",
      "[175]\ttraining's rmse: 0.0859026\tvalid_1's rmse: 0.0882859\n",
      "[200]\ttraining's rmse: 0.0858013\tvalid_1's rmse: 0.0882469\n",
      "[225]\ttraining's rmse: 0.0856999\tvalid_1's rmse: 0.0882096\n",
      "[250]\ttraining's rmse: 0.0856135\tvalid_1's rmse: 0.0881757\n",
      "[275]\ttraining's rmse: 0.085535\tvalid_1's rmse: 0.088145\n",
      "[300]\ttraining's rmse: 0.0854563\tvalid_1's rmse: 0.088117\n",
      "[325]\ttraining's rmse: 0.0853787\tvalid_1's rmse: 0.0880898\n",
      "[350]\ttraining's rmse: 0.0853046\tvalid_1's rmse: 0.0880643\n",
      "[375]\ttraining's rmse: 0.0852435\tvalid_1's rmse: 0.0880429\n",
      "[400]\ttraining's rmse: 0.0851765\tvalid_1's rmse: 0.0880213\n",
      "[425]\ttraining's rmse: 0.0851159\tvalid_1's rmse: 0.0880009\n",
      "[450]\ttraining's rmse: 0.0850614\tvalid_1's rmse: 0.0879813\n",
      "[475]\ttraining's rmse: 0.0850113\tvalid_1's rmse: 0.0879632\n",
      "[500]\ttraining's rmse: 0.0849673\tvalid_1's rmse: 0.087946\n",
      "[525]\ttraining's rmse: 0.0849104\tvalid_1's rmse: 0.0879287\n",
      "[550]\ttraining's rmse: 0.0848549\tvalid_1's rmse: 0.0879129\n",
      "[575]\ttraining's rmse: 0.084807\tvalid_1's rmse: 0.0878976\n",
      "[600]\ttraining's rmse: 0.0847596\tvalid_1's rmse: 0.0878834\n",
      "[625]\ttraining's rmse: 0.084723\tvalid_1's rmse: 0.0878708\n",
      "[650]\ttraining's rmse: 0.0846764\tvalid_1's rmse: 0.0878574\n",
      "[675]\ttraining's rmse: 0.0846288\tvalid_1's rmse: 0.0878443\n",
      "[700]\ttraining's rmse: 0.084589\tvalid_1's rmse: 0.0878327\n",
      "[725]\ttraining's rmse: 0.0845507\tvalid_1's rmse: 0.0878221\n",
      "[750]\ttraining's rmse: 0.0845142\tvalid_1's rmse: 0.0878131\n",
      "[775]\ttraining's rmse: 0.0844836\tvalid_1's rmse: 0.0878041\n",
      "[800]\ttraining's rmse: 0.0844478\tvalid_1's rmse: 0.0877959\n",
      "[825]\ttraining's rmse: 0.0844166\tvalid_1's rmse: 0.0877874\n",
      "[850]\ttraining's rmse: 0.0843846\tvalid_1's rmse: 0.0877802\n",
      "[875]\ttraining's rmse: 0.0843566\tvalid_1's rmse: 0.0877735\n",
      "[900]\ttraining's rmse: 0.0843242\tvalid_1's rmse: 0.0877653\n",
      "[925]\ttraining's rmse: 0.0842953\tvalid_1's rmse: 0.0877586\n",
      "[950]\ttraining's rmse: 0.0842678\tvalid_1's rmse: 0.0877524\n",
      "[975]\ttraining's rmse: 0.0842413\tvalid_1's rmse: 0.087747\n",
      "[1000]\ttraining's rmse: 0.0842188\tvalid_1's rmse: 0.0877424\n",
      "[1025]\ttraining's rmse: 0.0841916\tvalid_1's rmse: 0.0877366\n",
      "[1050]\ttraining's rmse: 0.0841684\tvalid_1's rmse: 0.0877311\n",
      "[1075]\ttraining's rmse: 0.0841447\tvalid_1's rmse: 0.0877274\n",
      "[1100]\ttraining's rmse: 0.0841255\tvalid_1's rmse: 0.0877226\n",
      "[1125]\ttraining's rmse: 0.0841058\tvalid_1's rmse: 0.0877186\n",
      "[1150]\ttraining's rmse: 0.084086\tvalid_1's rmse: 0.0877155\n",
      "[1175]\ttraining's rmse: 0.084069\tvalid_1's rmse: 0.0877133\n",
      "[1200]\ttraining's rmse: 0.0840499\tvalid_1's rmse: 0.0877103\n",
      "[1225]\ttraining's rmse: 0.0840335\tvalid_1's rmse: 0.0877072\n",
      "[1250]\ttraining's rmse: 0.0840179\tvalid_1's rmse: 0.0877039\n",
      "[1275]\ttraining's rmse: 0.0839992\tvalid_1's rmse: 0.0877019\n",
      "[1300]\ttraining's rmse: 0.0839856\tvalid_1's rmse: 0.0876993\n",
      "[1325]\ttraining's rmse: 0.0839688\tvalid_1's rmse: 0.0876965\n",
      "[1350]\ttraining's rmse: 0.0839507\tvalid_1's rmse: 0.0876945\n",
      "[1375]\ttraining's rmse: 0.0839352\tvalid_1's rmse: 0.0876925\n",
      "[1400]\ttraining's rmse: 0.0839235\tvalid_1's rmse: 0.0876903\n",
      "[1425]\ttraining's rmse: 0.0839092\tvalid_1's rmse: 0.0876888\n",
      "[1450]\ttraining's rmse: 0.0838937\tvalid_1's rmse: 0.0876873\n",
      "[1475]\ttraining's rmse: 0.0838838\tvalid_1's rmse: 0.0876859\n",
      "[1500]\ttraining's rmse: 0.0838738\tvalid_1's rmse: 0.0876842\n",
      "[1525]\ttraining's rmse: 0.0838612\tvalid_1's rmse: 0.0876829\n",
      "[1550]\ttraining's rmse: 0.083851\tvalid_1's rmse: 0.0876814\n",
      "[1575]\ttraining's rmse: 0.0838413\tvalid_1's rmse: 0.0876797\n",
      "[1600]\ttraining's rmse: 0.0838327\tvalid_1's rmse: 0.087679\n",
      "[1625]\ttraining's rmse: 0.083824\tvalid_1's rmse: 0.0876775\n",
      "[1650]\ttraining's rmse: 0.0838147\tvalid_1's rmse: 0.087677\n",
      "[1675]\ttraining's rmse: 0.0838066\tvalid_1's rmse: 0.0876754\n",
      "[1700]\ttraining's rmse: 0.0837997\tvalid_1's rmse: 0.0876742\n",
      "[1725]\ttraining's rmse: 0.0837936\tvalid_1's rmse: 0.0876728\n",
      "[1750]\ttraining's rmse: 0.0837853\tvalid_1's rmse: 0.0876714\n",
      "[1775]\ttraining's rmse: 0.0837785\tvalid_1's rmse: 0.0876708\n",
      "[1800]\ttraining's rmse: 0.0837712\tvalid_1's rmse: 0.08767\n",
      "[1825]\ttraining's rmse: 0.0837646\tvalid_1's rmse: 0.0876696\n",
      "[1850]\ttraining's rmse: 0.0837582\tvalid_1's rmse: 0.0876687\n",
      "[1875]\ttraining's rmse: 0.0837519\tvalid_1's rmse: 0.0876679\n",
      "[1900]\ttraining's rmse: 0.083746\tvalid_1's rmse: 0.0876675\n",
      "[1925]\ttraining's rmse: 0.0837411\tvalid_1's rmse: 0.0876667\n",
      "[1950]\ttraining's rmse: 0.083737\tvalid_1's rmse: 0.0876658\n",
      "[1975]\ttraining's rmse: 0.0837327\tvalid_1's rmse: 0.087665\n",
      "[2000]\ttraining's rmse: 0.0837271\tvalid_1's rmse: 0.0876643\n",
      "[2025]\ttraining's rmse: 0.0837224\tvalid_1's rmse: 0.0876635\n",
      "[2050]\ttraining's rmse: 0.0837195\tvalid_1's rmse: 0.0876631\n",
      "[2075]\ttraining's rmse: 0.0837158\tvalid_1's rmse: 0.0876626\n",
      "[2100]\ttraining's rmse: 0.0837126\tvalid_1's rmse: 0.0876625\n",
      "[2125]\ttraining's rmse: 0.0837088\tvalid_1's rmse: 0.0876625\n",
      "[2150]\ttraining's rmse: 0.0837035\tvalid_1's rmse: 0.0876618\n",
      "[2175]\ttraining's rmse: 0.0837013\tvalid_1's rmse: 0.0876618\n",
      "[2200]\ttraining's rmse: 0.0836983\tvalid_1's rmse: 0.0876612\n",
      "[2225]\ttraining's rmse: 0.0836945\tvalid_1's rmse: 0.0876604\n",
      "[2250]\ttraining's rmse: 0.0836913\tvalid_1's rmse: 0.0876603\n",
      "[2275]\ttraining's rmse: 0.0836879\tvalid_1's rmse: 0.0876601\n",
      "[2300]\ttraining's rmse: 0.0836853\tvalid_1's rmse: 0.0876596\n",
      "[2325]\ttraining's rmse: 0.0836828\tvalid_1's rmse: 0.0876599\n",
      "Early stopping, best iteration is:\n",
      "[2290]\ttraining's rmse: 0.0836865\tvalid_1's rmse: 0.0876595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0884512\tvalid_1's rmse: 0.0848116\n",
      "[50]\ttraining's rmse: 0.0883291\tvalid_1's rmse: 0.0847636\n",
      "[75]\ttraining's rmse: 0.0881945\tvalid_1's rmse: 0.0847128\n",
      "[100]\ttraining's rmse: 0.0880741\tvalid_1's rmse: 0.08467\n",
      "[125]\ttraining's rmse: 0.0879532\tvalid_1's rmse: 0.0846262\n",
      "[150]\ttraining's rmse: 0.0878423\tvalid_1's rmse: 0.0845871\n",
      "[175]\ttraining's rmse: 0.0877502\tvalid_1's rmse: 0.0845565\n",
      "[200]\ttraining's rmse: 0.0876481\tvalid_1's rmse: 0.0845241\n",
      "[225]\ttraining's rmse: 0.0875494\tvalid_1's rmse: 0.0844924\n",
      "[250]\ttraining's rmse: 0.0874661\tvalid_1's rmse: 0.0844648\n",
      "[275]\ttraining's rmse: 0.0873887\tvalid_1's rmse: 0.0844395\n",
      "[300]\ttraining's rmse: 0.0873113\tvalid_1's rmse: 0.0844144\n",
      "[325]\ttraining's rmse: 0.0872303\tvalid_1's rmse: 0.0843908\n",
      "[350]\ttraining's rmse: 0.0871555\tvalid_1's rmse: 0.0843685\n",
      "[375]\ttraining's rmse: 0.0870941\tvalid_1's rmse: 0.0843515\n",
      "[400]\ttraining's rmse: 0.0870251\tvalid_1's rmse: 0.084338\n",
      "[425]\ttraining's rmse: 0.086963\tvalid_1's rmse: 0.0843216\n",
      "[450]\ttraining's rmse: 0.0869067\tvalid_1's rmse: 0.0843087\n",
      "[475]\ttraining's rmse: 0.0868515\tvalid_1's rmse: 0.0842955\n",
      "[500]\ttraining's rmse: 0.0868076\tvalid_1's rmse: 0.0842822\n",
      "[525]\ttraining's rmse: 0.086748\tvalid_1's rmse: 0.0842726\n",
      "[550]\ttraining's rmse: 0.086696\tvalid_1's rmse: 0.0842611\n",
      "[575]\ttraining's rmse: 0.086647\tvalid_1's rmse: 0.0842506\n",
      "[600]\ttraining's rmse: 0.0865983\tvalid_1's rmse: 0.0842402\n",
      "[625]\ttraining's rmse: 0.0865584\tvalid_1's rmse: 0.0842309\n",
      "[650]\ttraining's rmse: 0.0865086\tvalid_1's rmse: 0.0842229\n",
      "[675]\ttraining's rmse: 0.0864612\tvalid_1's rmse: 0.0842178\n",
      "[700]\ttraining's rmse: 0.086419\tvalid_1's rmse: 0.0842101\n",
      "[725]\ttraining's rmse: 0.0863779\tvalid_1's rmse: 0.0842073\n",
      "[750]\ttraining's rmse: 0.086339\tvalid_1's rmse: 0.0842139\n",
      "[775]\ttraining's rmse: 0.0863089\tvalid_1's rmse: 0.0842126\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0863605\tvalid_1's rmse: 0.0842042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0831481\tvalid_1's rmse: 0.0856927\n",
      "[50]\ttraining's rmse: 0.0830183\tvalid_1's rmse: 0.085636\n",
      "[75]\ttraining's rmse: 0.0828848\tvalid_1's rmse: 0.0855806\n",
      "[100]\ttraining's rmse: 0.0827676\tvalid_1's rmse: 0.0855334\n",
      "[125]\ttraining's rmse: 0.0826466\tvalid_1's rmse: 0.0854845\n",
      "[150]\ttraining's rmse: 0.0825397\tvalid_1's rmse: 0.0854417\n",
      "[175]\ttraining's rmse: 0.0824466\tvalid_1's rmse: 0.0854025\n",
      "[200]\ttraining's rmse: 0.0823508\tvalid_1's rmse: 0.0853659\n",
      "[225]\ttraining's rmse: 0.0822563\tvalid_1's rmse: 0.0853314\n",
      "[250]\ttraining's rmse: 0.0821764\tvalid_1's rmse: 0.0853\n",
      "[275]\ttraining's rmse: 0.0821024\tvalid_1's rmse: 0.08527\n",
      "[300]\ttraining's rmse: 0.0820281\tvalid_1's rmse: 0.0852399\n",
      "[325]\ttraining's rmse: 0.0819558\tvalid_1's rmse: 0.085213\n",
      "[350]\ttraining's rmse: 0.0818854\tvalid_1's rmse: 0.0851879\n",
      "[375]\ttraining's rmse: 0.0818237\tvalid_1's rmse: 0.085166\n",
      "[400]\ttraining's rmse: 0.0817599\tvalid_1's rmse: 0.0851441\n",
      "[425]\ttraining's rmse: 0.0817039\tvalid_1's rmse: 0.0851234\n",
      "[450]\ttraining's rmse: 0.0816507\tvalid_1's rmse: 0.0851033\n",
      "[475]\ttraining's rmse: 0.0816021\tvalid_1's rmse: 0.085083\n",
      "[500]\ttraining's rmse: 0.0815595\tvalid_1's rmse: 0.0850656\n",
      "[525]\ttraining's rmse: 0.0815091\tvalid_1's rmse: 0.0850485\n",
      "[550]\ttraining's rmse: 0.0814606\tvalid_1's rmse: 0.0850336\n",
      "[575]\ttraining's rmse: 0.0814127\tvalid_1's rmse: 0.0850199\n",
      "[600]\ttraining's rmse: 0.0813702\tvalid_1's rmse: 0.0850054\n",
      "[625]\ttraining's rmse: 0.0813353\tvalid_1's rmse: 0.0849919\n",
      "[650]\ttraining's rmse: 0.0812933\tvalid_1's rmse: 0.084979\n",
      "[675]\ttraining's rmse: 0.081251\tvalid_1's rmse: 0.0849654\n",
      "[700]\ttraining's rmse: 0.0812146\tvalid_1's rmse: 0.0849541\n",
      "[725]\ttraining's rmse: 0.0811805\tvalid_1's rmse: 0.0849446\n",
      "[750]\ttraining's rmse: 0.0811464\tvalid_1's rmse: 0.0849335\n",
      "[775]\ttraining's rmse: 0.0811214\tvalid_1's rmse: 0.0849237\n",
      "[800]\ttraining's rmse: 0.0810863\tvalid_1's rmse: 0.0849157\n",
      "[825]\ttraining's rmse: 0.0810562\tvalid_1's rmse: 0.0849064\n",
      "[850]\ttraining's rmse: 0.0810253\tvalid_1's rmse: 0.0848997\n",
      "[875]\ttraining's rmse: 0.0809992\tvalid_1's rmse: 0.0848914\n",
      "[900]\ttraining's rmse: 0.0809684\tvalid_1's rmse: 0.0848843\n",
      "[925]\ttraining's rmse: 0.0809409\tvalid_1's rmse: 0.0848764\n",
      "[950]\ttraining's rmse: 0.0809159\tvalid_1's rmse: 0.0848694\n",
      "[975]\ttraining's rmse: 0.0808929\tvalid_1's rmse: 0.0848636\n",
      "[1000]\ttraining's rmse: 0.0808727\tvalid_1's rmse: 0.0848582\n",
      "[1025]\ttraining's rmse: 0.0808473\tvalid_1's rmse: 0.0848507\n",
      "[1050]\ttraining's rmse: 0.0808257\tvalid_1's rmse: 0.0848438\n",
      "[1075]\ttraining's rmse: 0.0808057\tvalid_1's rmse: 0.0848389\n",
      "[1100]\ttraining's rmse: 0.0807887\tvalid_1's rmse: 0.084834\n",
      "[1125]\ttraining's rmse: 0.0807718\tvalid_1's rmse: 0.0848294\n",
      "[1150]\ttraining's rmse: 0.0807516\tvalid_1's rmse: 0.0848241\n",
      "[1175]\ttraining's rmse: 0.080736\tvalid_1's rmse: 0.0848209\n",
      "[1200]\ttraining's rmse: 0.0807221\tvalid_1's rmse: 0.0848169\n",
      "[1225]\ttraining's rmse: 0.0807045\tvalid_1's rmse: 0.0848115\n",
      "[1250]\ttraining's rmse: 0.0806882\tvalid_1's rmse: 0.0848084\n",
      "[1275]\ttraining's rmse: 0.0806696\tvalid_1's rmse: 0.0848058\n",
      "[1300]\ttraining's rmse: 0.0806578\tvalid_1's rmse: 0.0848025\n",
      "[1325]\ttraining's rmse: 0.0806461\tvalid_1's rmse: 0.0847995\n",
      "[1350]\ttraining's rmse: 0.0806331\tvalid_1's rmse: 0.0847956\n",
      "[1375]\ttraining's rmse: 0.0806201\tvalid_1's rmse: 0.0847922\n",
      "[1400]\ttraining's rmse: 0.0806107\tvalid_1's rmse: 0.0847883\n",
      "[1425]\ttraining's rmse: 0.0805995\tvalid_1's rmse: 0.0847861\n",
      "[1450]\ttraining's rmse: 0.0805888\tvalid_1's rmse: 0.0847841\n",
      "[1475]\ttraining's rmse: 0.0805798\tvalid_1's rmse: 0.084781\n",
      "[1500]\ttraining's rmse: 0.0805709\tvalid_1's rmse: 0.0847787\n",
      "[1525]\ttraining's rmse: 0.0805604\tvalid_1's rmse: 0.0847766\n",
      "[1550]\ttraining's rmse: 0.0805483\tvalid_1's rmse: 0.0847741\n",
      "[1575]\ttraining's rmse: 0.0805379\tvalid_1's rmse: 0.084772\n",
      "[1600]\ttraining's rmse: 0.0805308\tvalid_1's rmse: 0.0847705\n",
      "[1625]\ttraining's rmse: 0.0805224\tvalid_1's rmse: 0.0847686\n",
      "[1650]\ttraining's rmse: 0.0805156\tvalid_1's rmse: 0.084767\n",
      "[1675]\ttraining's rmse: 0.0805098\tvalid_1's rmse: 0.0847644\n",
      "[1700]\ttraining's rmse: 0.0805045\tvalid_1's rmse: 0.0847617\n",
      "[1725]\ttraining's rmse: 0.0805003\tvalid_1's rmse: 0.0847603\n",
      "[1750]\ttraining's rmse: 0.0804931\tvalid_1's rmse: 0.0847575\n",
      "[1775]\ttraining's rmse: 0.0804863\tvalid_1's rmse: 0.0847549\n",
      "[1800]\ttraining's rmse: 0.0804807\tvalid_1's rmse: 0.0847535\n",
      "[1825]\ttraining's rmse: 0.0804751\tvalid_1's rmse: 0.0847521\n",
      "[1850]\ttraining's rmse: 0.0804706\tvalid_1's rmse: 0.0847505\n",
      "[1875]\ttraining's rmse: 0.0804662\tvalid_1's rmse: 0.0847495\n",
      "[1900]\ttraining's rmse: 0.0804609\tvalid_1's rmse: 0.0847474\n",
      "[1925]\ttraining's rmse: 0.0804568\tvalid_1's rmse: 0.0847467\n",
      "[1950]\ttraining's rmse: 0.0804522\tvalid_1's rmse: 0.0847451\n",
      "[1975]\ttraining's rmse: 0.0804484\tvalid_1's rmse: 0.0847445\n",
      "[2000]\ttraining's rmse: 0.0804439\tvalid_1's rmse: 0.0847436\n",
      "[2025]\ttraining's rmse: 0.08044\tvalid_1's rmse: 0.0847422\n",
      "[2050]\ttraining's rmse: 0.0804342\tvalid_1's rmse: 0.0847412\n",
      "[2075]\ttraining's rmse: 0.0804315\tvalid_1's rmse: 0.0847404\n",
      "[2100]\ttraining's rmse: 0.0804277\tvalid_1's rmse: 0.0847385\n",
      "[2125]\ttraining's rmse: 0.0804243\tvalid_1's rmse: 0.0847375\n",
      "[2150]\ttraining's rmse: 0.0804214\tvalid_1's rmse: 0.084737\n",
      "[2175]\ttraining's rmse: 0.0804181\tvalid_1's rmse: 0.0847361\n",
      "[2200]\ttraining's rmse: 0.080415\tvalid_1's rmse: 0.0847353\n",
      "[2225]\ttraining's rmse: 0.0804114\tvalid_1's rmse: 0.0847347\n",
      "[2250]\ttraining's rmse: 0.0804084\tvalid_1's rmse: 0.0847331\n",
      "[2275]\ttraining's rmse: 0.0804065\tvalid_1's rmse: 0.0847329\n",
      "[2300]\ttraining's rmse: 0.0804023\tvalid_1's rmse: 0.0847318\n",
      "[2325]\ttraining's rmse: 0.0803993\tvalid_1's rmse: 0.0847303\n",
      "[2350]\ttraining's rmse: 0.0803964\tvalid_1's rmse: 0.0847302\n",
      "[2375]\ttraining's rmse: 0.0803921\tvalid_1's rmse: 0.0847295\n",
      "[2400]\ttraining's rmse: 0.0803891\tvalid_1's rmse: 0.0847291\n",
      "[2425]\ttraining's rmse: 0.0803863\tvalid_1's rmse: 0.0847283\n",
      "[2450]\ttraining's rmse: 0.0803842\tvalid_1's rmse: 0.0847285\n",
      "Early stopping, best iteration is:\n",
      "[2420]\ttraining's rmse: 0.0803866\tvalid_1's rmse: 0.0847281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0833279\tvalid_1's rmse: 0.0853377\n",
      "[50]\ttraining's rmse: 0.0832105\tvalid_1's rmse: 0.0852822\n",
      "[75]\ttraining's rmse: 0.0830866\tvalid_1's rmse: 0.0852262\n",
      "[100]\ttraining's rmse: 0.0829794\tvalid_1's rmse: 0.0851774\n",
      "[125]\ttraining's rmse: 0.0828634\tvalid_1's rmse: 0.0851281\n",
      "[150]\ttraining's rmse: 0.0827589\tvalid_1's rmse: 0.0850839\n",
      "[175]\ttraining's rmse: 0.0826744\tvalid_1's rmse: 0.0850467\n",
      "[200]\ttraining's rmse: 0.0825787\tvalid_1's rmse: 0.0850101\n",
      "[225]\ttraining's rmse: 0.0824872\tvalid_1's rmse: 0.0849743\n",
      "[250]\ttraining's rmse: 0.0824109\tvalid_1's rmse: 0.0849435\n",
      "[275]\ttraining's rmse: 0.0823376\tvalid_1's rmse: 0.0849136\n",
      "[300]\ttraining's rmse: 0.0822657\tvalid_1's rmse: 0.0848863\n",
      "[325]\ttraining's rmse: 0.082193\tvalid_1's rmse: 0.0848594\n",
      "[350]\ttraining's rmse: 0.082122\tvalid_1's rmse: 0.0848338\n",
      "[375]\ttraining's rmse: 0.0820648\tvalid_1's rmse: 0.0848126\n",
      "[400]\ttraining's rmse: 0.0820011\tvalid_1's rmse: 0.0847909\n",
      "[425]\ttraining's rmse: 0.0819439\tvalid_1's rmse: 0.0847714\n",
      "[450]\ttraining's rmse: 0.0818893\tvalid_1's rmse: 0.0847529\n",
      "[475]\ttraining's rmse: 0.081839\tvalid_1's rmse: 0.0847359\n",
      "[500]\ttraining's rmse: 0.0817968\tvalid_1's rmse: 0.0847204\n",
      "[525]\ttraining's rmse: 0.081743\tvalid_1's rmse: 0.0847048\n",
      "[550]\ttraining's rmse: 0.0816922\tvalid_1's rmse: 0.0846894\n",
      "[575]\ttraining's rmse: 0.0816484\tvalid_1's rmse: 0.0846756\n",
      "[600]\ttraining's rmse: 0.0816052\tvalid_1's rmse: 0.0846632\n",
      "[625]\ttraining's rmse: 0.081569\tvalid_1's rmse: 0.0846514\n",
      "[650]\ttraining's rmse: 0.0815265\tvalid_1's rmse: 0.0846385\n",
      "[675]\ttraining's rmse: 0.0814814\tvalid_1's rmse: 0.0846265\n",
      "[700]\ttraining's rmse: 0.0814442\tvalid_1's rmse: 0.0846166\n",
      "[725]\ttraining's rmse: 0.0814091\tvalid_1's rmse: 0.0846062\n",
      "[750]\ttraining's rmse: 0.0813754\tvalid_1's rmse: 0.0845966\n",
      "[775]\ttraining's rmse: 0.0813471\tvalid_1's rmse: 0.084588\n",
      "[800]\ttraining's rmse: 0.0813108\tvalid_1's rmse: 0.0845797\n",
      "[825]\ttraining's rmse: 0.0812808\tvalid_1's rmse: 0.084571\n",
      "[850]\ttraining's rmse: 0.0812529\tvalid_1's rmse: 0.0845644\n",
      "[875]\ttraining's rmse: 0.0812255\tvalid_1's rmse: 0.0845575\n",
      "[900]\ttraining's rmse: 0.0811982\tvalid_1's rmse: 0.0845507\n",
      "[925]\ttraining's rmse: 0.0811721\tvalid_1's rmse: 0.084545\n",
      "[950]\ttraining's rmse: 0.0811481\tvalid_1's rmse: 0.0845398\n",
      "[975]\ttraining's rmse: 0.0811248\tvalid_1's rmse: 0.0845341\n",
      "[1000]\ttraining's rmse: 0.0811032\tvalid_1's rmse: 0.0845293\n",
      "[1025]\ttraining's rmse: 0.0810792\tvalid_1's rmse: 0.0845246\n",
      "[1050]\ttraining's rmse: 0.0810581\tvalid_1's rmse: 0.0845195\n",
      "[1075]\ttraining's rmse: 0.0810389\tvalid_1's rmse: 0.0845161\n",
      "[1100]\ttraining's rmse: 0.0810237\tvalid_1's rmse: 0.0845124\n",
      "[1125]\ttraining's rmse: 0.0810061\tvalid_1's rmse: 0.0845089\n",
      "[1150]\ttraining's rmse: 0.0809877\tvalid_1's rmse: 0.0845045\n",
      "[1175]\ttraining's rmse: 0.0809717\tvalid_1's rmse: 0.0845015\n",
      "[1200]\ttraining's rmse: 0.0809558\tvalid_1's rmse: 0.0844991\n",
      "[1225]\ttraining's rmse: 0.0809396\tvalid_1's rmse: 0.0844965\n",
      "[1250]\ttraining's rmse: 0.0809248\tvalid_1's rmse: 0.0844939\n",
      "[1275]\ttraining's rmse: 0.0809086\tvalid_1's rmse: 0.0844921\n",
      "[1300]\ttraining's rmse: 0.0808963\tvalid_1's rmse: 0.0844892\n",
      "[1325]\ttraining's rmse: 0.0808795\tvalid_1's rmse: 0.0844872\n",
      "[1350]\ttraining's rmse: 0.0808654\tvalid_1's rmse: 0.0844855\n",
      "[1375]\ttraining's rmse: 0.0808523\tvalid_1's rmse: 0.0844835\n",
      "[1400]\ttraining's rmse: 0.0808439\tvalid_1's rmse: 0.0844813\n",
      "[1425]\ttraining's rmse: 0.0808334\tvalid_1's rmse: 0.0844801\n",
      "[1450]\ttraining's rmse: 0.0808226\tvalid_1's rmse: 0.0844785\n",
      "[1475]\ttraining's rmse: 0.0808109\tvalid_1's rmse: 0.0844761\n",
      "[1500]\ttraining's rmse: 0.0807997\tvalid_1's rmse: 0.0844749\n",
      "[1525]\ttraining's rmse: 0.0807885\tvalid_1's rmse: 0.0844729\n",
      "[1550]\ttraining's rmse: 0.0807808\tvalid_1's rmse: 0.0844716\n",
      "[1575]\ttraining's rmse: 0.0807722\tvalid_1's rmse: 0.0844699\n",
      "[1600]\ttraining's rmse: 0.0807635\tvalid_1's rmse: 0.0844685\n",
      "[1625]\ttraining's rmse: 0.0807557\tvalid_1's rmse: 0.0844668\n",
      "[1650]\ttraining's rmse: 0.0807486\tvalid_1's rmse: 0.0844658\n",
      "[1675]\ttraining's rmse: 0.0807431\tvalid_1's rmse: 0.0844648\n",
      "[1700]\ttraining's rmse: 0.0807368\tvalid_1's rmse: 0.0844636\n",
      "[1725]\ttraining's rmse: 0.0807294\tvalid_1's rmse: 0.0844622\n",
      "[1750]\ttraining's rmse: 0.0807218\tvalid_1's rmse: 0.0844614\n",
      "[1775]\ttraining's rmse: 0.0807163\tvalid_1's rmse: 0.0844609\n",
      "[1800]\ttraining's rmse: 0.0807098\tvalid_1's rmse: 0.0844595\n",
      "[1825]\ttraining's rmse: 0.080702\tvalid_1's rmse: 0.0844584\n",
      "[1850]\ttraining's rmse: 0.0806972\tvalid_1's rmse: 0.0844577\n",
      "[1875]\ttraining's rmse: 0.0806926\tvalid_1's rmse: 0.0844569\n",
      "[1900]\ttraining's rmse: 0.0806882\tvalid_1's rmse: 0.0844562\n",
      "[1925]\ttraining's rmse: 0.0806839\tvalid_1's rmse: 0.084456\n",
      "[1950]\ttraining's rmse: 0.0806801\tvalid_1's rmse: 0.0844552\n",
      "[1975]\ttraining's rmse: 0.0806761\tvalid_1's rmse: 0.0844548\n",
      "[2000]\ttraining's rmse: 0.080671\tvalid_1's rmse: 0.0844545\n",
      "[2025]\ttraining's rmse: 0.0806679\tvalid_1's rmse: 0.0844541\n",
      "[2050]\ttraining's rmse: 0.0806632\tvalid_1's rmse: 0.0844538\n",
      "[2075]\ttraining's rmse: 0.0806588\tvalid_1's rmse: 0.084453\n",
      "[2100]\ttraining's rmse: 0.0806554\tvalid_1's rmse: 0.0844528\n",
      "[2125]\ttraining's rmse: 0.0806516\tvalid_1's rmse: 0.0844525\n",
      "[2150]\ttraining's rmse: 0.0806473\tvalid_1's rmse: 0.0844523\n",
      "[2175]\ttraining's rmse: 0.0806448\tvalid_1's rmse: 0.0844519\n",
      "[2200]\ttraining's rmse: 0.0806417\tvalid_1's rmse: 0.0844521\n",
      "[2225]\ttraining's rmse: 0.0806388\tvalid_1's rmse: 0.0844518\n",
      "[2250]\ttraining's rmse: 0.0806362\tvalid_1's rmse: 0.0844514\n",
      "[2275]\ttraining's rmse: 0.0806334\tvalid_1's rmse: 0.0844511\n",
      "[2300]\ttraining's rmse: 0.08063\tvalid_1's rmse: 0.0844504\n",
      "[2325]\ttraining's rmse: 0.0806263\tvalid_1's rmse: 0.0844503\n",
      "[2350]\ttraining's rmse: 0.080624\tvalid_1's rmse: 0.0844501\n",
      "[2375]\ttraining's rmse: 0.0806207\tvalid_1's rmse: 0.0844497\n",
      "[2400]\ttraining's rmse: 0.0806183\tvalid_1's rmse: 0.0844498\n",
      "[2425]\ttraining's rmse: 0.080617\tvalid_1's rmse: 0.0844499\n",
      "Early stopping, best iteration is:\n",
      "[2384]\ttraining's rmse: 0.0806199\tvalid_1's rmse: 0.0844495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0853937\tvalid_1's rmse: 0.0811514\n",
      "[50]\ttraining's rmse: 0.0852793\tvalid_1's rmse: 0.0811026\n",
      "[75]\ttraining's rmse: 0.0851621\tvalid_1's rmse: 0.0810554\n",
      "[100]\ttraining's rmse: 0.0850571\tvalid_1's rmse: 0.0810126\n",
      "[125]\ttraining's rmse: 0.0849476\tvalid_1's rmse: 0.0809693\n",
      "[150]\ttraining's rmse: 0.0848453\tvalid_1's rmse: 0.0809317\n",
      "[175]\ttraining's rmse: 0.0847607\tvalid_1's rmse: 0.0809014\n",
      "[200]\ttraining's rmse: 0.084671\tvalid_1's rmse: 0.0808704\n",
      "[225]\ttraining's rmse: 0.0845854\tvalid_1's rmse: 0.0808401\n",
      "[250]\ttraining's rmse: 0.0845121\tvalid_1's rmse: 0.0808139\n",
      "[275]\ttraining's rmse: 0.0844471\tvalid_1's rmse: 0.0807895\n",
      "[300]\ttraining's rmse: 0.0843786\tvalid_1's rmse: 0.0807647\n",
      "[325]\ttraining's rmse: 0.0843107\tvalid_1's rmse: 0.080742\n",
      "[350]\ttraining's rmse: 0.0842423\tvalid_1's rmse: 0.0807213\n",
      "[375]\ttraining's rmse: 0.0841869\tvalid_1's rmse: 0.0807044\n",
      "[400]\ttraining's rmse: 0.0841274\tvalid_1's rmse: 0.080689\n",
      "[425]\ttraining's rmse: 0.0840725\tvalid_1's rmse: 0.0806809\n",
      "[450]\ttraining's rmse: 0.0840198\tvalid_1's rmse: 0.0806647\n",
      "[475]\ttraining's rmse: 0.0839713\tvalid_1's rmse: 0.0806547\n",
      "[500]\ttraining's rmse: 0.0839307\tvalid_1's rmse: 0.080642\n",
      "[525]\ttraining's rmse: 0.0838796\tvalid_1's rmse: 0.0806342\n",
      "[550]\ttraining's rmse: 0.0838334\tvalid_1's rmse: 0.0806206\n",
      "[575]\ttraining's rmse: 0.0837907\tvalid_1's rmse: 0.0806093\n",
      "[600]\ttraining's rmse: 0.0837467\tvalid_1's rmse: 0.0806071\n",
      "[625]\ttraining's rmse: 0.083713\tvalid_1's rmse: 0.0806039\n",
      "[650]\ttraining's rmse: 0.0836709\tvalid_1's rmse: 0.0805928\n",
      "[675]\ttraining's rmse: 0.083627\tvalid_1's rmse: 0.0805833\n",
      "[700]\ttraining's rmse: 0.0835888\tvalid_1's rmse: 0.0805742\n",
      "[725]\ttraining's rmse: 0.0835527\tvalid_1's rmse: 0.0805719\n",
      "[750]\ttraining's rmse: 0.0835185\tvalid_1's rmse: 0.0805719\n",
      "[775]\ttraining's rmse: 0.0834899\tvalid_1's rmse: 0.0805761\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 0.0835265\tvalid_1's rmse: 0.0805658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876987\tvalid_1's rmse: 0.0893031\n",
      "[50]\ttraining's rmse: 0.0875131\tvalid_1's rmse: 0.0892538\n",
      "[75]\ttraining's rmse: 0.0873299\tvalid_1's rmse: 0.0891993\n",
      "[100]\ttraining's rmse: 0.0871588\tvalid_1's rmse: 0.0891533\n",
      "[125]\ttraining's rmse: 0.0869943\tvalid_1's rmse: 0.0891083\n",
      "[150]\ttraining's rmse: 0.0868434\tvalid_1's rmse: 0.0890658\n",
      "[175]\ttraining's rmse: 0.0867147\tvalid_1's rmse: 0.0890279\n",
      "[200]\ttraining's rmse: 0.086579\tvalid_1's rmse: 0.0889911\n",
      "[225]\ttraining's rmse: 0.0864495\tvalid_1's rmse: 0.0889586\n",
      "[250]\ttraining's rmse: 0.0863408\tvalid_1's rmse: 0.0889277\n",
      "[275]\ttraining's rmse: 0.0862394\tvalid_1's rmse: 0.0888998\n",
      "[300]\ttraining's rmse: 0.0861366\tvalid_1's rmse: 0.0888707\n",
      "[325]\ttraining's rmse: 0.0860359\tvalid_1's rmse: 0.0888457\n",
      "[350]\ttraining's rmse: 0.0859407\tvalid_1's rmse: 0.0888216\n",
      "[375]\ttraining's rmse: 0.0858562\tvalid_1's rmse: 0.0887993\n",
      "[400]\ttraining's rmse: 0.0857733\tvalid_1's rmse: 0.0887775\n",
      "[425]\ttraining's rmse: 0.0856962\tvalid_1's rmse: 0.0887588\n",
      "[450]\ttraining's rmse: 0.0856257\tvalid_1's rmse: 0.0887394\n",
      "[475]\ttraining's rmse: 0.0855566\tvalid_1's rmse: 0.0887215\n",
      "[500]\ttraining's rmse: 0.0854996\tvalid_1's rmse: 0.0887053\n",
      "[525]\ttraining's rmse: 0.0854316\tvalid_1's rmse: 0.0886887\n",
      "[550]\ttraining's rmse: 0.085368\tvalid_1's rmse: 0.0886731\n",
      "[575]\ttraining's rmse: 0.0853042\tvalid_1's rmse: 0.0886577\n",
      "[600]\ttraining's rmse: 0.085247\tvalid_1's rmse: 0.0886436\n",
      "[625]\ttraining's rmse: 0.0851984\tvalid_1's rmse: 0.0886324\n",
      "[650]\ttraining's rmse: 0.0851436\tvalid_1's rmse: 0.0886201\n",
      "[675]\ttraining's rmse: 0.0850947\tvalid_1's rmse: 0.0886079\n",
      "[700]\ttraining's rmse: 0.0850471\tvalid_1's rmse: 0.0885946\n",
      "[725]\ttraining's rmse: 0.0849989\tvalid_1's rmse: 0.0885835\n",
      "[750]\ttraining's rmse: 0.0849561\tvalid_1's rmse: 0.0885718\n",
      "[775]\ttraining's rmse: 0.0849237\tvalid_1's rmse: 0.0885626\n",
      "[800]\ttraining's rmse: 0.0848782\tvalid_1's rmse: 0.0885541\n",
      "[825]\ttraining's rmse: 0.0848432\tvalid_1's rmse: 0.0885446\n",
      "[850]\ttraining's rmse: 0.084803\tvalid_1's rmse: 0.0885385\n",
      "[875]\ttraining's rmse: 0.0847725\tvalid_1's rmse: 0.0885305\n",
      "[900]\ttraining's rmse: 0.0847368\tvalid_1's rmse: 0.0885225\n",
      "[925]\ttraining's rmse: 0.0847039\tvalid_1's rmse: 0.0885152\n",
      "[950]\ttraining's rmse: 0.0846765\tvalid_1's rmse: 0.0885089\n",
      "[975]\ttraining's rmse: 0.0846487\tvalid_1's rmse: 0.0885028\n",
      "[1000]\ttraining's rmse: 0.0846209\tvalid_1's rmse: 0.088497\n",
      "[1025]\ttraining's rmse: 0.0845912\tvalid_1's rmse: 0.088491\n",
      "[1050]\ttraining's rmse: 0.0845659\tvalid_1's rmse: 0.0884845\n",
      "[1075]\ttraining's rmse: 0.0845407\tvalid_1's rmse: 0.0884801\n",
      "[1100]\ttraining's rmse: 0.0845189\tvalid_1's rmse: 0.0884745\n",
      "[1125]\ttraining's rmse: 0.0844972\tvalid_1's rmse: 0.0884696\n",
      "[1150]\ttraining's rmse: 0.0844764\tvalid_1's rmse: 0.0884646\n",
      "[1175]\ttraining's rmse: 0.0844581\tvalid_1's rmse: 0.0884604\n",
      "[1200]\ttraining's rmse: 0.0844424\tvalid_1's rmse: 0.0884552\n",
      "[1225]\ttraining's rmse: 0.0844244\tvalid_1's rmse: 0.0884512\n",
      "[1250]\ttraining's rmse: 0.0844071\tvalid_1's rmse: 0.0884464\n",
      "[1275]\ttraining's rmse: 0.084388\tvalid_1's rmse: 0.0884439\n",
      "[1300]\ttraining's rmse: 0.0843752\tvalid_1's rmse: 0.0884387\n",
      "[1325]\ttraining's rmse: 0.0843592\tvalid_1's rmse: 0.0884352\n",
      "[1350]\ttraining's rmse: 0.084343\tvalid_1's rmse: 0.0884324\n",
      "[1375]\ttraining's rmse: 0.0843265\tvalid_1's rmse: 0.088429\n",
      "[1400]\ttraining's rmse: 0.0843144\tvalid_1's rmse: 0.0884266\n",
      "[1425]\ttraining's rmse: 0.084301\tvalid_1's rmse: 0.0884242\n",
      "[1450]\ttraining's rmse: 0.0842844\tvalid_1's rmse: 0.0884212\n",
      "[1475]\ttraining's rmse: 0.084272\tvalid_1's rmse: 0.0884179\n",
      "[1500]\ttraining's rmse: 0.0842604\tvalid_1's rmse: 0.0884145\n",
      "[1525]\ttraining's rmse: 0.0842484\tvalid_1's rmse: 0.0884125\n",
      "[1550]\ttraining's rmse: 0.0842345\tvalid_1's rmse: 0.0884103\n",
      "[1575]\ttraining's rmse: 0.0842226\tvalid_1's rmse: 0.0884073\n",
      "[1600]\ttraining's rmse: 0.0842141\tvalid_1's rmse: 0.0884053\n",
      "[1625]\ttraining's rmse: 0.0842043\tvalid_1's rmse: 0.0884033\n",
      "[1650]\ttraining's rmse: 0.0841959\tvalid_1's rmse: 0.0884008\n",
      "[1675]\ttraining's rmse: 0.084189\tvalid_1's rmse: 0.0883977\n",
      "[1700]\ttraining's rmse: 0.0841815\tvalid_1's rmse: 0.0883966\n",
      "[1725]\ttraining's rmse: 0.0841749\tvalid_1's rmse: 0.0883947\n",
      "[1750]\ttraining's rmse: 0.0841666\tvalid_1's rmse: 0.0883923\n",
      "[1775]\ttraining's rmse: 0.0841575\tvalid_1's rmse: 0.0883908\n",
      "[1800]\ttraining's rmse: 0.0841501\tvalid_1's rmse: 0.088389\n",
      "[1825]\ttraining's rmse: 0.084144\tvalid_1's rmse: 0.0883871\n",
      "[1850]\ttraining's rmse: 0.0841394\tvalid_1's rmse: 0.0883856\n",
      "[1875]\ttraining's rmse: 0.0841334\tvalid_1's rmse: 0.0883843\n",
      "[1900]\ttraining's rmse: 0.0841284\tvalid_1's rmse: 0.088383\n",
      "[1925]\ttraining's rmse: 0.0841235\tvalid_1's rmse: 0.0883823\n",
      "[1950]\ttraining's rmse: 0.0841185\tvalid_1's rmse: 0.0883801\n",
      "[1975]\ttraining's rmse: 0.0841143\tvalid_1's rmse: 0.0883779\n",
      "[2000]\ttraining's rmse: 0.0841085\tvalid_1's rmse: 0.0883775\n",
      "[2025]\ttraining's rmse: 0.0841048\tvalid_1's rmse: 0.0883755\n",
      "[2050]\ttraining's rmse: 0.0841006\tvalid_1's rmse: 0.0883741\n",
      "[2075]\ttraining's rmse: 0.0840975\tvalid_1's rmse: 0.0883732\n",
      "[2100]\ttraining's rmse: 0.0840925\tvalid_1's rmse: 0.0883723\n",
      "[2125]\ttraining's rmse: 0.0840891\tvalid_1's rmse: 0.0883714\n",
      "[2150]\ttraining's rmse: 0.0840848\tvalid_1's rmse: 0.0883694\n",
      "[2175]\ttraining's rmse: 0.0840812\tvalid_1's rmse: 0.088369\n",
      "[2200]\ttraining's rmse: 0.0840777\tvalid_1's rmse: 0.0883675\n",
      "[2225]\ttraining's rmse: 0.0840741\tvalid_1's rmse: 0.0883668\n",
      "[2250]\ttraining's rmse: 0.084069\tvalid_1's rmse: 0.0883662\n",
      "[2275]\ttraining's rmse: 0.0840649\tvalid_1's rmse: 0.0883652\n",
      "[2300]\ttraining's rmse: 0.0840622\tvalid_1's rmse: 0.0883645\n",
      "[2325]\ttraining's rmse: 0.0840568\tvalid_1's rmse: 0.088363\n",
      "[2350]\ttraining's rmse: 0.0840543\tvalid_1's rmse: 0.0883619\n",
      "[2375]\ttraining's rmse: 0.0840506\tvalid_1's rmse: 0.0883606\n",
      "[2400]\ttraining's rmse: 0.0840463\tvalid_1's rmse: 0.0883603\n",
      "[2425]\ttraining's rmse: 0.0840439\tvalid_1's rmse: 0.0883599\n",
      "[2450]\ttraining's rmse: 0.0840415\tvalid_1's rmse: 0.0883591\n",
      "[2475]\ttraining's rmse: 0.0840391\tvalid_1's rmse: 0.0883585\n",
      "[2500]\ttraining's rmse: 0.0840356\tvalid_1's rmse: 0.0883575\n",
      "[2525]\ttraining's rmse: 0.0840326\tvalid_1's rmse: 0.0883562\n",
      "[2550]\ttraining's rmse: 0.0840295\tvalid_1's rmse: 0.0883561\n",
      "[2575]\ttraining's rmse: 0.0840257\tvalid_1's rmse: 0.0883548\n",
      "[2600]\ttraining's rmse: 0.0840223\tvalid_1's rmse: 0.0883546\n",
      "[2625]\ttraining's rmse: 0.0840206\tvalid_1's rmse: 0.0883534\n",
      "[2650]\ttraining's rmse: 0.084019\tvalid_1's rmse: 0.0883521\n",
      "[2675]\ttraining's rmse: 0.084016\tvalid_1's rmse: 0.0883505\n",
      "[2700]\ttraining's rmse: 0.0840142\tvalid_1's rmse: 0.08835\n",
      "[2725]\ttraining's rmse: 0.0840116\tvalid_1's rmse: 0.0883495\n",
      "[2750]\ttraining's rmse: 0.0840107\tvalid_1's rmse: 0.0883491\n",
      "[2775]\ttraining's rmse: 0.0840082\tvalid_1's rmse: 0.0883484\n",
      "[2800]\ttraining's rmse: 0.0840063\tvalid_1's rmse: 0.088348\n",
      "[2825]\ttraining's rmse: 0.0840035\tvalid_1's rmse: 0.0883478\n",
      "[2850]\ttraining's rmse: 0.0840015\tvalid_1's rmse: 0.0883469\n",
      "[2875]\ttraining's rmse: 0.0839994\tvalid_1's rmse: 0.0883473\n",
      "[2900]\ttraining's rmse: 0.0839977\tvalid_1's rmse: 0.0883467\n",
      "[2925]\ttraining's rmse: 0.0839961\tvalid_1's rmse: 0.0883463\n",
      "[2950]\ttraining's rmse: 0.0839951\tvalid_1's rmse: 0.0883461\n",
      "[2975]\ttraining's rmse: 0.0839939\tvalid_1's rmse: 0.0883459\n",
      "[3000]\ttraining's rmse: 0.0839916\tvalid_1's rmse: 0.0883456\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0839916\tvalid_1's rmse: 0.0883456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.08774\tvalid_1's rmse: 0.0892411\n",
      "[50]\ttraining's rmse: 0.0875745\tvalid_1's rmse: 0.0891863\n",
      "[75]\ttraining's rmse: 0.0874063\tvalid_1's rmse: 0.0891318\n",
      "[100]\ttraining's rmse: 0.0872538\tvalid_1's rmse: 0.0890804\n",
      "[125]\ttraining's rmse: 0.0870991\tvalid_1's rmse: 0.0890306\n",
      "[150]\ttraining's rmse: 0.0869594\tvalid_1's rmse: 0.0889836\n",
      "[175]\ttraining's rmse: 0.0868417\tvalid_1's rmse: 0.088946\n",
      "[200]\ttraining's rmse: 0.0867141\tvalid_1's rmse: 0.0889057\n",
      "[225]\ttraining's rmse: 0.0865978\tvalid_1's rmse: 0.088869\n",
      "[250]\ttraining's rmse: 0.0864942\tvalid_1's rmse: 0.0888345\n",
      "[275]\ttraining's rmse: 0.0863967\tvalid_1's rmse: 0.0888027\n",
      "[300]\ttraining's rmse: 0.0863014\tvalid_1's rmse: 0.0887734\n",
      "[325]\ttraining's rmse: 0.0862076\tvalid_1's rmse: 0.0887442\n",
      "[350]\ttraining's rmse: 0.0861213\tvalid_1's rmse: 0.088718\n",
      "[375]\ttraining's rmse: 0.0860477\tvalid_1's rmse: 0.0886946\n",
      "[400]\ttraining's rmse: 0.0859714\tvalid_1's rmse: 0.088673\n",
      "[425]\ttraining's rmse: 0.0859\tvalid_1's rmse: 0.0886524\n",
      "[450]\ttraining's rmse: 0.0858339\tvalid_1's rmse: 0.0886317\n",
      "[475]\ttraining's rmse: 0.0857755\tvalid_1's rmse: 0.0886129\n",
      "[500]\ttraining's rmse: 0.0857229\tvalid_1's rmse: 0.0885955\n",
      "[525]\ttraining's rmse: 0.0856575\tvalid_1's rmse: 0.088578\n",
      "[550]\ttraining's rmse: 0.085598\tvalid_1's rmse: 0.0885624\n",
      "[575]\ttraining's rmse: 0.0855458\tvalid_1's rmse: 0.0885485\n",
      "[600]\ttraining's rmse: 0.0854938\tvalid_1's rmse: 0.0885332\n",
      "[625]\ttraining's rmse: 0.0854486\tvalid_1's rmse: 0.0885194\n",
      "[650]\ttraining's rmse: 0.0853966\tvalid_1's rmse: 0.0885043\n",
      "[675]\ttraining's rmse: 0.0853483\tvalid_1's rmse: 0.0884917\n",
      "[700]\ttraining's rmse: 0.0853033\tvalid_1's rmse: 0.08848\n",
      "[725]\ttraining's rmse: 0.0852634\tvalid_1's rmse: 0.0884704\n",
      "[750]\ttraining's rmse: 0.0852258\tvalid_1's rmse: 0.0884595\n",
      "[775]\ttraining's rmse: 0.085193\tvalid_1's rmse: 0.0884493\n",
      "[800]\ttraining's rmse: 0.0851531\tvalid_1's rmse: 0.0884417\n",
      "[825]\ttraining's rmse: 0.0851184\tvalid_1's rmse: 0.0884329\n",
      "[850]\ttraining's rmse: 0.0850842\tvalid_1's rmse: 0.0884249\n",
      "[875]\ttraining's rmse: 0.0850529\tvalid_1's rmse: 0.0884176\n",
      "[900]\ttraining's rmse: 0.0850192\tvalid_1's rmse: 0.0884102\n",
      "[925]\ttraining's rmse: 0.0849873\tvalid_1's rmse: 0.0884032\n",
      "[950]\ttraining's rmse: 0.0849603\tvalid_1's rmse: 0.0883963\n",
      "[975]\ttraining's rmse: 0.084933\tvalid_1's rmse: 0.0883898\n",
      "[1000]\ttraining's rmse: 0.0849055\tvalid_1's rmse: 0.0883844\n",
      "[1025]\ttraining's rmse: 0.0848761\tvalid_1's rmse: 0.0883786\n",
      "[1050]\ttraining's rmse: 0.0848528\tvalid_1's rmse: 0.088374\n",
      "[1075]\ttraining's rmse: 0.0848283\tvalid_1's rmse: 0.0883701\n",
      "[1100]\ttraining's rmse: 0.0848072\tvalid_1's rmse: 0.0883655\n",
      "[1125]\ttraining's rmse: 0.0847851\tvalid_1's rmse: 0.0883611\n",
      "[1150]\ttraining's rmse: 0.0847649\tvalid_1's rmse: 0.0883572\n",
      "[1175]\ttraining's rmse: 0.0847458\tvalid_1's rmse: 0.0883538\n",
      "[1200]\ttraining's rmse: 0.0847273\tvalid_1's rmse: 0.0883497\n",
      "[1225]\ttraining's rmse: 0.0847117\tvalid_1's rmse: 0.0883466\n",
      "[1250]\ttraining's rmse: 0.0846947\tvalid_1's rmse: 0.0883429\n",
      "[1275]\ttraining's rmse: 0.0846728\tvalid_1's rmse: 0.0883403\n",
      "[1300]\ttraining's rmse: 0.0846577\tvalid_1's rmse: 0.0883376\n",
      "[1325]\ttraining's rmse: 0.0846387\tvalid_1's rmse: 0.0883355\n",
      "[1350]\ttraining's rmse: 0.0846214\tvalid_1's rmse: 0.0883331\n",
      "[1375]\ttraining's rmse: 0.084604\tvalid_1's rmse: 0.0883295\n",
      "[1400]\ttraining's rmse: 0.0845911\tvalid_1's rmse: 0.0883277\n",
      "[1425]\ttraining's rmse: 0.0845752\tvalid_1's rmse: 0.0883263\n",
      "[1450]\ttraining's rmse: 0.084562\tvalid_1's rmse: 0.0883249\n",
      "[1475]\ttraining's rmse: 0.0845479\tvalid_1's rmse: 0.088322\n",
      "[1500]\ttraining's rmse: 0.0845365\tvalid_1's rmse: 0.0883202\n",
      "[1525]\ttraining's rmse: 0.0845244\tvalid_1's rmse: 0.0883186\n",
      "[1550]\ttraining's rmse: 0.0845132\tvalid_1's rmse: 0.0883174\n",
      "[1575]\ttraining's rmse: 0.0845036\tvalid_1's rmse: 0.0883155\n",
      "[1600]\ttraining's rmse: 0.0844949\tvalid_1's rmse: 0.0883149\n",
      "[1625]\ttraining's rmse: 0.0844851\tvalid_1's rmse: 0.0883128\n",
      "[1650]\ttraining's rmse: 0.0844761\tvalid_1's rmse: 0.0883115\n",
      "[1675]\ttraining's rmse: 0.0844679\tvalid_1's rmse: 0.0883102\n",
      "[1700]\ttraining's rmse: 0.0844592\tvalid_1's rmse: 0.0883094\n",
      "[1725]\ttraining's rmse: 0.0844537\tvalid_1's rmse: 0.088308\n",
      "[1750]\ttraining's rmse: 0.0844457\tvalid_1's rmse: 0.0883069\n",
      "[1775]\ttraining's rmse: 0.0844401\tvalid_1's rmse: 0.0883063\n",
      "[1800]\ttraining's rmse: 0.0844324\tvalid_1's rmse: 0.0883052\n",
      "[1825]\ttraining's rmse: 0.0844264\tvalid_1's rmse: 0.088304\n",
      "[1850]\ttraining's rmse: 0.0844211\tvalid_1's rmse: 0.088303\n",
      "[1875]\ttraining's rmse: 0.0844165\tvalid_1's rmse: 0.0883022\n",
      "[1900]\ttraining's rmse: 0.0844126\tvalid_1's rmse: 0.0883017\n",
      "[1925]\ttraining's rmse: 0.0844068\tvalid_1's rmse: 0.0883008\n",
      "[1950]\ttraining's rmse: 0.0844024\tvalid_1's rmse: 0.0882999\n",
      "[1975]\ttraining's rmse: 0.0843974\tvalid_1's rmse: 0.0882995\n",
      "[2000]\ttraining's rmse: 0.0843916\tvalid_1's rmse: 0.0882985\n",
      "[2025]\ttraining's rmse: 0.0843872\tvalid_1's rmse: 0.0882973\n",
      "[2050]\ttraining's rmse: 0.0843821\tvalid_1's rmse: 0.088297\n",
      "[2075]\ttraining's rmse: 0.0843774\tvalid_1's rmse: 0.0882958\n",
      "[2100]\ttraining's rmse: 0.084372\tvalid_1's rmse: 0.0882954\n",
      "[2125]\ttraining's rmse: 0.0843689\tvalid_1's rmse: 0.0882953\n",
      "[2150]\ttraining's rmse: 0.0843658\tvalid_1's rmse: 0.0882952\n",
      "[2175]\ttraining's rmse: 0.0843628\tvalid_1's rmse: 0.0882952\n",
      "[2200]\ttraining's rmse: 0.0843593\tvalid_1's rmse: 0.0882951\n",
      "[2225]\ttraining's rmse: 0.0843558\tvalid_1's rmse: 0.0882947\n",
      "[2250]\ttraining's rmse: 0.084352\tvalid_1's rmse: 0.0882943\n",
      "[2275]\ttraining's rmse: 0.0843495\tvalid_1's rmse: 0.0882942\n",
      "Early stopping, best iteration is:\n",
      "[2231]\ttraining's rmse: 0.0843545\tvalid_1's rmse: 0.0882941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.08913\tvalid_1's rmse: 0.0864961\n",
      "[50]\ttraining's rmse: 0.0890043\tvalid_1's rmse: 0.0864464\n",
      "[75]\ttraining's rmse: 0.0888695\tvalid_1's rmse: 0.0863967\n",
      "[100]\ttraining's rmse: 0.0887457\tvalid_1's rmse: 0.0863511\n",
      "[125]\ttraining's rmse: 0.0886208\tvalid_1's rmse: 0.0863096\n",
      "[150]\ttraining's rmse: 0.0885057\tvalid_1's rmse: 0.0862708\n",
      "[175]\ttraining's rmse: 0.0884089\tvalid_1's rmse: 0.0862388\n",
      "[200]\ttraining's rmse: 0.0883043\tvalid_1's rmse: 0.0862081\n",
      "[225]\ttraining's rmse: 0.088202\tvalid_1's rmse: 0.0861783\n",
      "[250]\ttraining's rmse: 0.0881127\tvalid_1's rmse: 0.0861508\n",
      "[275]\ttraining's rmse: 0.0880345\tvalid_1's rmse: 0.0861253\n",
      "[300]\ttraining's rmse: 0.0879536\tvalid_1's rmse: 0.0861017\n",
      "[325]\ttraining's rmse: 0.0878733\tvalid_1's rmse: 0.0860806\n",
      "[350]\ttraining's rmse: 0.0877971\tvalid_1's rmse: 0.0860589\n",
      "[375]\ttraining's rmse: 0.087733\tvalid_1's rmse: 0.0860421\n",
      "[400]\ttraining's rmse: 0.0876612\tvalid_1's rmse: 0.0860251\n",
      "[425]\ttraining's rmse: 0.0875979\tvalid_1's rmse: 0.086014\n",
      "[450]\ttraining's rmse: 0.0875412\tvalid_1's rmse: 0.0859992\n",
      "[475]\ttraining's rmse: 0.0874859\tvalid_1's rmse: 0.085987\n",
      "[500]\ttraining's rmse: 0.0874381\tvalid_1's rmse: 0.0859751\n",
      "[525]\ttraining's rmse: 0.0873758\tvalid_1's rmse: 0.0859609\n",
      "[550]\ttraining's rmse: 0.0873214\tvalid_1's rmse: 0.0859542\n",
      "[575]\ttraining's rmse: 0.08727\tvalid_1's rmse: 0.085948\n",
      "[600]\ttraining's rmse: 0.0872186\tvalid_1's rmse: 0.0859435\n",
      "[625]\ttraining's rmse: 0.0871778\tvalid_1's rmse: 0.0859392\n",
      "[650]\ttraining's rmse: 0.0871265\tvalid_1's rmse: 0.0859343\n",
      "[675]\ttraining's rmse: 0.087078\tvalid_1's rmse: 0.0859264\n",
      "[700]\ttraining's rmse: 0.0870354\tvalid_1's rmse: 0.0859182\n",
      "[725]\ttraining's rmse: 0.0869965\tvalid_1's rmse: 0.0859274\n",
      "[750]\ttraining's rmse: 0.0869575\tvalid_1's rmse: 0.0859275\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's rmse: 0.0870304\tvalid_1's rmse: 0.0859178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0836498\tvalid_1's rmse: 0.0861218\n",
      "[50]\ttraining's rmse: 0.0835161\tvalid_1's rmse: 0.0860647\n",
      "[75]\ttraining's rmse: 0.0833847\tvalid_1's rmse: 0.086008\n",
      "[100]\ttraining's rmse: 0.0832618\tvalid_1's rmse: 0.0859595\n",
      "[125]\ttraining's rmse: 0.0831369\tvalid_1's rmse: 0.0859106\n",
      "[150]\ttraining's rmse: 0.0830255\tvalid_1's rmse: 0.0858657\n",
      "[175]\ttraining's rmse: 0.0829329\tvalid_1's rmse: 0.0858249\n",
      "[200]\ttraining's rmse: 0.0828345\tvalid_1's rmse: 0.0857863\n",
      "[225]\ttraining's rmse: 0.0827374\tvalid_1's rmse: 0.0857494\n",
      "[250]\ttraining's rmse: 0.0826567\tvalid_1's rmse: 0.0857169\n",
      "[275]\ttraining's rmse: 0.0825795\tvalid_1's rmse: 0.0856854\n",
      "[300]\ttraining's rmse: 0.0825054\tvalid_1's rmse: 0.0856565\n",
      "[325]\ttraining's rmse: 0.0824318\tvalid_1's rmse: 0.0856286\n",
      "[350]\ttraining's rmse: 0.0823591\tvalid_1's rmse: 0.0856015\n",
      "[375]\ttraining's rmse: 0.0822995\tvalid_1's rmse: 0.0855795\n",
      "[400]\ttraining's rmse: 0.0822334\tvalid_1's rmse: 0.0855579\n",
      "[425]\ttraining's rmse: 0.0821752\tvalid_1's rmse: 0.0855374\n",
      "[450]\ttraining's rmse: 0.0821213\tvalid_1's rmse: 0.0855164\n",
      "[475]\ttraining's rmse: 0.0820722\tvalid_1's rmse: 0.0854969\n",
      "[500]\ttraining's rmse: 0.082028\tvalid_1's rmse: 0.0854786\n",
      "[525]\ttraining's rmse: 0.0819762\tvalid_1's rmse: 0.08546\n",
      "[550]\ttraining's rmse: 0.081926\tvalid_1's rmse: 0.0854458\n",
      "[575]\ttraining's rmse: 0.0818791\tvalid_1's rmse: 0.0854316\n",
      "[600]\ttraining's rmse: 0.081836\tvalid_1's rmse: 0.0854176\n",
      "[625]\ttraining's rmse: 0.0818008\tvalid_1's rmse: 0.0854023\n",
      "[650]\ttraining's rmse: 0.0817585\tvalid_1's rmse: 0.0853891\n",
      "[675]\ttraining's rmse: 0.0817157\tvalid_1's rmse: 0.0853758\n",
      "[700]\ttraining's rmse: 0.0816773\tvalid_1's rmse: 0.0853655\n",
      "[725]\ttraining's rmse: 0.0816402\tvalid_1's rmse: 0.0853536\n",
      "[750]\ttraining's rmse: 0.0816045\tvalid_1's rmse: 0.0853434\n",
      "[775]\ttraining's rmse: 0.0815778\tvalid_1's rmse: 0.0853337\n",
      "[800]\ttraining's rmse: 0.0815393\tvalid_1's rmse: 0.0853245\n",
      "[825]\ttraining's rmse: 0.0815103\tvalid_1's rmse: 0.0853149\n",
      "[850]\ttraining's rmse: 0.0814799\tvalid_1's rmse: 0.0853072\n",
      "[875]\ttraining's rmse: 0.0814524\tvalid_1's rmse: 0.0852982\n",
      "[900]\ttraining's rmse: 0.0814218\tvalid_1's rmse: 0.0852903\n",
      "[925]\ttraining's rmse: 0.081396\tvalid_1's rmse: 0.0852827\n",
      "[950]\ttraining's rmse: 0.0813724\tvalid_1's rmse: 0.0852757\n",
      "[975]\ttraining's rmse: 0.0813479\tvalid_1's rmse: 0.0852683\n",
      "[1000]\ttraining's rmse: 0.0813264\tvalid_1's rmse: 0.0852621\n",
      "[1025]\ttraining's rmse: 0.0813037\tvalid_1's rmse: 0.0852542\n",
      "[1050]\ttraining's rmse: 0.0812821\tvalid_1's rmse: 0.0852469\n",
      "[1075]\ttraining's rmse: 0.0812601\tvalid_1's rmse: 0.0852408\n",
      "[1100]\ttraining's rmse: 0.0812423\tvalid_1's rmse: 0.0852354\n",
      "[1125]\ttraining's rmse: 0.0812243\tvalid_1's rmse: 0.0852298\n",
      "[1150]\ttraining's rmse: 0.0812053\tvalid_1's rmse: 0.0852253\n",
      "[1175]\ttraining's rmse: 0.0811898\tvalid_1's rmse: 0.085222\n",
      "[1200]\ttraining's rmse: 0.0811732\tvalid_1's rmse: 0.0852162\n",
      "[1225]\ttraining's rmse: 0.0811546\tvalid_1's rmse: 0.0852123\n",
      "[1250]\ttraining's rmse: 0.0811406\tvalid_1's rmse: 0.0852088\n",
      "[1275]\ttraining's rmse: 0.081121\tvalid_1's rmse: 0.085205\n",
      "[1300]\ttraining's rmse: 0.0811084\tvalid_1's rmse: 0.0852016\n",
      "[1325]\ttraining's rmse: 0.0810956\tvalid_1's rmse: 0.0851989\n",
      "[1350]\ttraining's rmse: 0.0810836\tvalid_1's rmse: 0.0851958\n",
      "[1375]\ttraining's rmse: 0.0810695\tvalid_1's rmse: 0.0851934\n",
      "[1400]\ttraining's rmse: 0.081058\tvalid_1's rmse: 0.0851903\n",
      "[1425]\ttraining's rmse: 0.0810449\tvalid_1's rmse: 0.0851873\n",
      "[1450]\ttraining's rmse: 0.0810333\tvalid_1's rmse: 0.0851843\n",
      "[1475]\ttraining's rmse: 0.0810219\tvalid_1's rmse: 0.0851819\n",
      "[1500]\ttraining's rmse: 0.0810131\tvalid_1's rmse: 0.0851792\n",
      "[1525]\ttraining's rmse: 0.0810037\tvalid_1's rmse: 0.0851761\n",
      "[1550]\ttraining's rmse: 0.0809941\tvalid_1's rmse: 0.0851742\n",
      "[1575]\ttraining's rmse: 0.080985\tvalid_1's rmse: 0.0851714\n",
      "[1600]\ttraining's rmse: 0.0809774\tvalid_1's rmse: 0.0851694\n",
      "[1625]\ttraining's rmse: 0.0809706\tvalid_1's rmse: 0.0851679\n",
      "[1650]\ttraining's rmse: 0.0809619\tvalid_1's rmse: 0.0851657\n",
      "[1675]\ttraining's rmse: 0.0809562\tvalid_1's rmse: 0.085164\n",
      "[1700]\ttraining's rmse: 0.0809509\tvalid_1's rmse: 0.0851611\n",
      "[1725]\ttraining's rmse: 0.0809442\tvalid_1's rmse: 0.0851603\n",
      "[1750]\ttraining's rmse: 0.0809364\tvalid_1's rmse: 0.0851573\n",
      "[1775]\ttraining's rmse: 0.0809308\tvalid_1's rmse: 0.0851547\n",
      "[1800]\ttraining's rmse: 0.0809246\tvalid_1's rmse: 0.0851528\n",
      "[1825]\ttraining's rmse: 0.0809178\tvalid_1's rmse: 0.0851509\n",
      "[1850]\ttraining's rmse: 0.080911\tvalid_1's rmse: 0.0851492\n",
      "[1875]\ttraining's rmse: 0.0809047\tvalid_1's rmse: 0.0851478\n",
      "[1900]\ttraining's rmse: 0.0808994\tvalid_1's rmse: 0.085147\n",
      "[1925]\ttraining's rmse: 0.0808956\tvalid_1's rmse: 0.0851464\n",
      "[1950]\ttraining's rmse: 0.0808925\tvalid_1's rmse: 0.0851453\n",
      "[1975]\ttraining's rmse: 0.0808894\tvalid_1's rmse: 0.0851446\n",
      "[2000]\ttraining's rmse: 0.0808842\tvalid_1's rmse: 0.0851438\n",
      "[2025]\ttraining's rmse: 0.0808799\tvalid_1's rmse: 0.0851416\n",
      "[2050]\ttraining's rmse: 0.0808757\tvalid_1's rmse: 0.085141\n",
      "[2075]\ttraining's rmse: 0.080871\tvalid_1's rmse: 0.0851395\n",
      "[2100]\ttraining's rmse: 0.0808674\tvalid_1's rmse: 0.0851388\n",
      "[2125]\ttraining's rmse: 0.0808629\tvalid_1's rmse: 0.0851381\n",
      "[2150]\ttraining's rmse: 0.0808595\tvalid_1's rmse: 0.0851375\n",
      "[2175]\ttraining's rmse: 0.0808559\tvalid_1's rmse: 0.0851378\n",
      "[2200]\ttraining's rmse: 0.080852\tvalid_1's rmse: 0.0851362\n",
      "[2225]\ttraining's rmse: 0.0808491\tvalid_1's rmse: 0.0851356\n",
      "[2250]\ttraining's rmse: 0.0808463\tvalid_1's rmse: 0.0851349\n",
      "[2275]\ttraining's rmse: 0.0808432\tvalid_1's rmse: 0.0851347\n",
      "[2300]\ttraining's rmse: 0.0808406\tvalid_1's rmse: 0.0851339\n",
      "[2325]\ttraining's rmse: 0.0808364\tvalid_1's rmse: 0.0851319\n",
      "[2350]\ttraining's rmse: 0.0808339\tvalid_1's rmse: 0.0851311\n",
      "[2375]\ttraining's rmse: 0.0808315\tvalid_1's rmse: 0.0851305\n",
      "[2400]\ttraining's rmse: 0.080829\tvalid_1's rmse: 0.0851306\n",
      "[2425]\ttraining's rmse: 0.0808267\tvalid_1's rmse: 0.0851297\n",
      "[2450]\ttraining's rmse: 0.0808251\tvalid_1's rmse: 0.0851289\n",
      "[2475]\ttraining's rmse: 0.0808224\tvalid_1's rmse: 0.0851288\n",
      "[2500]\ttraining's rmse: 0.0808203\tvalid_1's rmse: 0.0851279\n",
      "[2525]\ttraining's rmse: 0.0808175\tvalid_1's rmse: 0.0851267\n",
      "[2550]\ttraining's rmse: 0.080815\tvalid_1's rmse: 0.0851273\n",
      "Early stopping, best iteration is:\n",
      "[2518]\ttraining's rmse: 0.0808178\tvalid_1's rmse: 0.0851267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0837617\tvalid_1's rmse: 0.0859\n",
      "[50]\ttraining's rmse: 0.0836392\tvalid_1's rmse: 0.0858414\n",
      "[75]\ttraining's rmse: 0.0835155\tvalid_1's rmse: 0.0857848\n",
      "[100]\ttraining's rmse: 0.0834048\tvalid_1's rmse: 0.085734\n",
      "[125]\ttraining's rmse: 0.0832864\tvalid_1's rmse: 0.0856828\n",
      "[150]\ttraining's rmse: 0.0831798\tvalid_1's rmse: 0.0856363\n",
      "[175]\ttraining's rmse: 0.0830909\tvalid_1's rmse: 0.0855974\n",
      "[200]\ttraining's rmse: 0.0829949\tvalid_1's rmse: 0.0855583\n",
      "[225]\ttraining's rmse: 0.0829029\tvalid_1's rmse: 0.0855228\n",
      "[250]\ttraining's rmse: 0.0828245\tvalid_1's rmse: 0.0854904\n",
      "[275]\ttraining's rmse: 0.0827486\tvalid_1's rmse: 0.0854592\n",
      "[300]\ttraining's rmse: 0.0826754\tvalid_1's rmse: 0.0854306\n",
      "[325]\ttraining's rmse: 0.0826039\tvalid_1's rmse: 0.0854037\n",
      "[350]\ttraining's rmse: 0.0825315\tvalid_1's rmse: 0.0853782\n",
      "[375]\ttraining's rmse: 0.0824721\tvalid_1's rmse: 0.085356\n",
      "[400]\ttraining's rmse: 0.0824099\tvalid_1's rmse: 0.0853348\n",
      "[425]\ttraining's rmse: 0.0823536\tvalid_1's rmse: 0.0853136\n",
      "[450]\ttraining's rmse: 0.0822997\tvalid_1's rmse: 0.0852947\n",
      "[475]\ttraining's rmse: 0.0822499\tvalid_1's rmse: 0.0852769\n",
      "[500]\ttraining's rmse: 0.0822062\tvalid_1's rmse: 0.0852602\n",
      "[525]\ttraining's rmse: 0.0821527\tvalid_1's rmse: 0.0852432\n",
      "[550]\ttraining's rmse: 0.0821011\tvalid_1's rmse: 0.0852269\n",
      "[575]\ttraining's rmse: 0.0820549\tvalid_1's rmse: 0.0852129\n",
      "[600]\ttraining's rmse: 0.08201\tvalid_1's rmse: 0.0851999\n",
      "[625]\ttraining's rmse: 0.0819743\tvalid_1's rmse: 0.0851875\n",
      "[650]\ttraining's rmse: 0.08193\tvalid_1's rmse: 0.0851751\n",
      "[675]\ttraining's rmse: 0.0818861\tvalid_1's rmse: 0.0851626\n",
      "[700]\ttraining's rmse: 0.0818484\tvalid_1's rmse: 0.085152\n",
      "[725]\ttraining's rmse: 0.0818108\tvalid_1's rmse: 0.0851419\n",
      "[750]\ttraining's rmse: 0.0817756\tvalid_1's rmse: 0.0851321\n",
      "[775]\ttraining's rmse: 0.081746\tvalid_1's rmse: 0.0851227\n",
      "[800]\ttraining's rmse: 0.081711\tvalid_1's rmse: 0.0851143\n",
      "[825]\ttraining's rmse: 0.0816819\tvalid_1's rmse: 0.085106\n",
      "[850]\ttraining's rmse: 0.081652\tvalid_1's rmse: 0.0850996\n",
      "[875]\ttraining's rmse: 0.0816231\tvalid_1's rmse: 0.085093\n",
      "[900]\ttraining's rmse: 0.0815933\tvalid_1's rmse: 0.0850864\n",
      "[925]\ttraining's rmse: 0.0815664\tvalid_1's rmse: 0.0850803\n",
      "[950]\ttraining's rmse: 0.0815419\tvalid_1's rmse: 0.0850752\n",
      "[975]\ttraining's rmse: 0.0815181\tvalid_1's rmse: 0.0850698\n",
      "[1000]\ttraining's rmse: 0.0814961\tvalid_1's rmse: 0.0850648\n",
      "[1025]\ttraining's rmse: 0.0814721\tvalid_1's rmse: 0.0850611\n",
      "[1050]\ttraining's rmse: 0.081452\tvalid_1's rmse: 0.0850565\n",
      "[1075]\ttraining's rmse: 0.0814326\tvalid_1's rmse: 0.0850528\n",
      "[1100]\ttraining's rmse: 0.0814148\tvalid_1's rmse: 0.085049\n",
      "[1125]\ttraining's rmse: 0.081396\tvalid_1's rmse: 0.0850449\n",
      "[1150]\ttraining's rmse: 0.0813777\tvalid_1's rmse: 0.0850408\n",
      "[1175]\ttraining's rmse: 0.0813602\tvalid_1's rmse: 0.0850377\n",
      "[1200]\ttraining's rmse: 0.0813432\tvalid_1's rmse: 0.0850352\n",
      "[1225]\ttraining's rmse: 0.0813272\tvalid_1's rmse: 0.0850323\n",
      "[1250]\ttraining's rmse: 0.0813123\tvalid_1's rmse: 0.0850291\n",
      "[1275]\ttraining's rmse: 0.0812944\tvalid_1's rmse: 0.0850268\n",
      "[1300]\ttraining's rmse: 0.0812827\tvalid_1's rmse: 0.0850241\n",
      "[1325]\ttraining's rmse: 0.0812689\tvalid_1's rmse: 0.085022\n",
      "[1350]\ttraining's rmse: 0.0812564\tvalid_1's rmse: 0.0850197\n",
      "[1375]\ttraining's rmse: 0.0812434\tvalid_1's rmse: 0.0850181\n",
      "[1400]\ttraining's rmse: 0.0812353\tvalid_1's rmse: 0.0850156\n",
      "[1425]\ttraining's rmse: 0.0812259\tvalid_1's rmse: 0.0850143\n",
      "[1450]\ttraining's rmse: 0.0812117\tvalid_1's rmse: 0.0850119\n",
      "[1475]\ttraining's rmse: 0.0811993\tvalid_1's rmse: 0.0850102\n",
      "[1500]\ttraining's rmse: 0.081188\tvalid_1's rmse: 0.0850078\n",
      "[1525]\ttraining's rmse: 0.0811777\tvalid_1's rmse: 0.0850066\n",
      "[1550]\ttraining's rmse: 0.0811678\tvalid_1's rmse: 0.0850052\n",
      "[1575]\ttraining's rmse: 0.0811586\tvalid_1's rmse: 0.0850034\n",
      "[1600]\ttraining's rmse: 0.0811508\tvalid_1's rmse: 0.0850026\n",
      "[1625]\ttraining's rmse: 0.0811441\tvalid_1's rmse: 0.0850013\n",
      "[1650]\ttraining's rmse: 0.0811366\tvalid_1's rmse: 0.0850004\n",
      "[1675]\ttraining's rmse: 0.0811304\tvalid_1's rmse: 0.084999\n",
      "[1700]\ttraining's rmse: 0.081124\tvalid_1's rmse: 0.0849982\n",
      "[1725]\ttraining's rmse: 0.0811165\tvalid_1's rmse: 0.0849971\n",
      "[1750]\ttraining's rmse: 0.0811085\tvalid_1's rmse: 0.0849959\n",
      "[1775]\ttraining's rmse: 0.0811034\tvalid_1's rmse: 0.084995\n",
      "[1800]\ttraining's rmse: 0.0810959\tvalid_1's rmse: 0.0849941\n",
      "[1825]\ttraining's rmse: 0.0810891\tvalid_1's rmse: 0.0849929\n",
      "[1850]\ttraining's rmse: 0.0810828\tvalid_1's rmse: 0.0849919\n",
      "[1875]\ttraining's rmse: 0.0810773\tvalid_1's rmse: 0.0849914\n",
      "[1900]\ttraining's rmse: 0.0810723\tvalid_1's rmse: 0.0849909\n",
      "[1925]\ttraining's rmse: 0.0810687\tvalid_1's rmse: 0.0849905\n",
      "[1950]\ttraining's rmse: 0.0810657\tvalid_1's rmse: 0.0849899\n",
      "[1975]\ttraining's rmse: 0.0810613\tvalid_1's rmse: 0.0849897\n",
      "[2000]\ttraining's rmse: 0.0810567\tvalid_1's rmse: 0.0849891\n",
      "[2025]\ttraining's rmse: 0.0810531\tvalid_1's rmse: 0.0849885\n",
      "[2050]\ttraining's rmse: 0.0810479\tvalid_1's rmse: 0.0849876\n",
      "[2075]\ttraining's rmse: 0.0810444\tvalid_1's rmse: 0.0849868\n",
      "[2100]\ttraining's rmse: 0.0810411\tvalid_1's rmse: 0.0849866\n",
      "[2125]\ttraining's rmse: 0.0810384\tvalid_1's rmse: 0.0849866\n",
      "[2150]\ttraining's rmse: 0.0810342\tvalid_1's rmse: 0.0849864\n",
      "[2175]\ttraining's rmse: 0.0810318\tvalid_1's rmse: 0.0849868\n",
      "[2200]\ttraining's rmse: 0.0810289\tvalid_1's rmse: 0.0849866\n",
      "Early stopping, best iteration is:\n",
      "[2150]\ttraining's rmse: 0.0810342\tvalid_1's rmse: 0.0849864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0858847\tvalid_1's rmse: 0.0815841\n",
      "[50]\ttraining's rmse: 0.0857645\tvalid_1's rmse: 0.0815327\n",
      "[75]\ttraining's rmse: 0.0856431\tvalid_1's rmse: 0.0814825\n",
      "[100]\ttraining's rmse: 0.0855358\tvalid_1's rmse: 0.0814434\n",
      "[125]\ttraining's rmse: 0.0854247\tvalid_1's rmse: 0.0814023\n",
      "[150]\ttraining's rmse: 0.0853197\tvalid_1's rmse: 0.0813644\n",
      "[175]\ttraining's rmse: 0.0852343\tvalid_1's rmse: 0.0813326\n",
      "[200]\ttraining's rmse: 0.085143\tvalid_1's rmse: 0.0813014\n",
      "[225]\ttraining's rmse: 0.085055\tvalid_1's rmse: 0.0812708\n",
      "[250]\ttraining's rmse: 0.084981\tvalid_1's rmse: 0.0812434\n",
      "[275]\ttraining's rmse: 0.0849108\tvalid_1's rmse: 0.0812162\n",
      "[300]\ttraining's rmse: 0.0848409\tvalid_1's rmse: 0.0811927\n",
      "[325]\ttraining's rmse: 0.084769\tvalid_1's rmse: 0.0811688\n",
      "[350]\ttraining's rmse: 0.0847014\tvalid_1's rmse: 0.0811472\n",
      "[375]\ttraining's rmse: 0.0846447\tvalid_1's rmse: 0.0811277\n",
      "[400]\ttraining's rmse: 0.0845829\tvalid_1's rmse: 0.0811133\n",
      "[425]\ttraining's rmse: 0.0845275\tvalid_1's rmse: 0.0811028\n",
      "[450]\ttraining's rmse: 0.0844769\tvalid_1's rmse: 0.081088\n",
      "[475]\ttraining's rmse: 0.0844286\tvalid_1's rmse: 0.0810739\n",
      "[500]\ttraining's rmse: 0.084387\tvalid_1's rmse: 0.0810601\n",
      "[525]\ttraining's rmse: 0.0843335\tvalid_1's rmse: 0.081051\n",
      "[550]\ttraining's rmse: 0.0842832\tvalid_1's rmse: 0.0810384\n",
      "[575]\ttraining's rmse: 0.0842376\tvalid_1's rmse: 0.0810319\n",
      "[600]\ttraining's rmse: 0.0841922\tvalid_1's rmse: 0.0810277\n",
      "[625]\ttraining's rmse: 0.0841596\tvalid_1's rmse: 0.0810283\n",
      "[650]\ttraining's rmse: 0.0841173\tvalid_1's rmse: 0.0810219\n",
      "[675]\ttraining's rmse: 0.0840722\tvalid_1's rmse: 0.0810323\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttraining's rmse: 0.0841193\tvalid_1's rmse: 0.0810181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0883548\tvalid_1's rmse: 0.0898717\n",
      "[50]\ttraining's rmse: 0.0881654\tvalid_1's rmse: 0.0898204\n",
      "[75]\ttraining's rmse: 0.0879781\tvalid_1's rmse: 0.0897676\n",
      "[100]\ttraining's rmse: 0.0878049\tvalid_1's rmse: 0.0897198\n",
      "[125]\ttraining's rmse: 0.0876374\tvalid_1's rmse: 0.0896734\n",
      "[150]\ttraining's rmse: 0.0874794\tvalid_1's rmse: 0.0896285\n",
      "[175]\ttraining's rmse: 0.0873428\tvalid_1's rmse: 0.0895913\n",
      "[200]\ttraining's rmse: 0.0872029\tvalid_1's rmse: 0.0895545\n",
      "[225]\ttraining's rmse: 0.0870653\tvalid_1's rmse: 0.0895218\n",
      "[250]\ttraining's rmse: 0.0869499\tvalid_1's rmse: 0.0894904\n",
      "[275]\ttraining's rmse: 0.0868434\tvalid_1's rmse: 0.089462\n",
      "[300]\ttraining's rmse: 0.0867397\tvalid_1's rmse: 0.0894351\n",
      "[325]\ttraining's rmse: 0.0866361\tvalid_1's rmse: 0.0894089\n",
      "[350]\ttraining's rmse: 0.0865355\tvalid_1's rmse: 0.0893835\n",
      "[375]\ttraining's rmse: 0.0864521\tvalid_1's rmse: 0.089363\n",
      "[400]\ttraining's rmse: 0.0863632\tvalid_1's rmse: 0.0893419\n",
      "[425]\ttraining's rmse: 0.0862821\tvalid_1's rmse: 0.0893223\n",
      "[450]\ttraining's rmse: 0.0862096\tvalid_1's rmse: 0.0893021\n",
      "[475]\ttraining's rmse: 0.086142\tvalid_1's rmse: 0.089283\n",
      "[500]\ttraining's rmse: 0.0860802\tvalid_1's rmse: 0.0892649\n",
      "[525]\ttraining's rmse: 0.0860086\tvalid_1's rmse: 0.0892468\n",
      "[550]\ttraining's rmse: 0.085947\tvalid_1's rmse: 0.0892311\n",
      "[575]\ttraining's rmse: 0.0858851\tvalid_1's rmse: 0.0892171\n",
      "[600]\ttraining's rmse: 0.0858267\tvalid_1's rmse: 0.0892036\n",
      "[625]\ttraining's rmse: 0.0857777\tvalid_1's rmse: 0.089191\n",
      "[650]\ttraining's rmse: 0.0857215\tvalid_1's rmse: 0.089179\n",
      "[675]\ttraining's rmse: 0.0856669\tvalid_1's rmse: 0.089167\n",
      "[700]\ttraining's rmse: 0.0856188\tvalid_1's rmse: 0.0891552\n",
      "[725]\ttraining's rmse: 0.0855727\tvalid_1's rmse: 0.0891447\n",
      "[750]\ttraining's rmse: 0.0855319\tvalid_1's rmse: 0.0891348\n",
      "[775]\ttraining's rmse: 0.0854957\tvalid_1's rmse: 0.089125\n",
      "[800]\ttraining's rmse: 0.0854518\tvalid_1's rmse: 0.0891169\n",
      "[825]\ttraining's rmse: 0.0854161\tvalid_1's rmse: 0.089109\n",
      "[850]\ttraining's rmse: 0.0853764\tvalid_1's rmse: 0.0891023\n",
      "[875]\ttraining's rmse: 0.0853433\tvalid_1's rmse: 0.0890952\n",
      "[900]\ttraining's rmse: 0.0853059\tvalid_1's rmse: 0.0890876\n",
      "[925]\ttraining's rmse: 0.0852741\tvalid_1's rmse: 0.0890799\n",
      "[950]\ttraining's rmse: 0.085244\tvalid_1's rmse: 0.0890711\n",
      "[975]\ttraining's rmse: 0.085216\tvalid_1's rmse: 0.0890638\n",
      "[1000]\ttraining's rmse: 0.0851873\tvalid_1's rmse: 0.0890585\n",
      "[1025]\ttraining's rmse: 0.0851589\tvalid_1's rmse: 0.0890519\n",
      "[1050]\ttraining's rmse: 0.0851338\tvalid_1's rmse: 0.0890463\n",
      "[1075]\ttraining's rmse: 0.0851073\tvalid_1's rmse: 0.089041\n",
      "[1100]\ttraining's rmse: 0.0850855\tvalid_1's rmse: 0.0890371\n",
      "[1125]\ttraining's rmse: 0.0850618\tvalid_1's rmse: 0.0890312\n",
      "[1150]\ttraining's rmse: 0.0850403\tvalid_1's rmse: 0.0890264\n",
      "[1175]\ttraining's rmse: 0.0850158\tvalid_1's rmse: 0.0890234\n",
      "[1200]\ttraining's rmse: 0.0849987\tvalid_1's rmse: 0.0890186\n",
      "[1225]\ttraining's rmse: 0.0849781\tvalid_1's rmse: 0.0890139\n",
      "[1250]\ttraining's rmse: 0.0849594\tvalid_1's rmse: 0.0890091\n",
      "[1275]\ttraining's rmse: 0.0849393\tvalid_1's rmse: 0.0890049\n",
      "[1300]\ttraining's rmse: 0.0849238\tvalid_1's rmse: 0.0890011\n",
      "[1325]\ttraining's rmse: 0.0849066\tvalid_1's rmse: 0.0889974\n",
      "[1350]\ttraining's rmse: 0.084893\tvalid_1's rmse: 0.0889946\n",
      "[1375]\ttraining's rmse: 0.0848765\tvalid_1's rmse: 0.0889921\n",
      "[1400]\ttraining's rmse: 0.084863\tvalid_1's rmse: 0.0889879\n",
      "[1425]\ttraining's rmse: 0.0848454\tvalid_1's rmse: 0.088986\n",
      "[1450]\ttraining's rmse: 0.0848325\tvalid_1's rmse: 0.088983\n",
      "[1475]\ttraining's rmse: 0.0848185\tvalid_1's rmse: 0.0889791\n",
      "[1500]\ttraining's rmse: 0.0848093\tvalid_1's rmse: 0.0889772\n",
      "[1525]\ttraining's rmse: 0.0847982\tvalid_1's rmse: 0.0889749\n",
      "[1550]\ttraining's rmse: 0.0847854\tvalid_1's rmse: 0.0889723\n",
      "[1575]\ttraining's rmse: 0.0847744\tvalid_1's rmse: 0.0889688\n",
      "[1600]\ttraining's rmse: 0.0847648\tvalid_1's rmse: 0.0889675\n",
      "[1625]\ttraining's rmse: 0.0847556\tvalid_1's rmse: 0.0889642\n",
      "[1650]\ttraining's rmse: 0.0847473\tvalid_1's rmse: 0.0889614\n",
      "[1675]\ttraining's rmse: 0.0847412\tvalid_1's rmse: 0.0889586\n",
      "[1700]\ttraining's rmse: 0.0847333\tvalid_1's rmse: 0.0889563\n",
      "[1725]\ttraining's rmse: 0.084726\tvalid_1's rmse: 0.0889547\n",
      "[1750]\ttraining's rmse: 0.0847171\tvalid_1's rmse: 0.0889528\n",
      "[1775]\ttraining's rmse: 0.0847091\tvalid_1's rmse: 0.0889516\n",
      "[1800]\ttraining's rmse: 0.0847019\tvalid_1's rmse: 0.0889488\n",
      "[1825]\ttraining's rmse: 0.0846962\tvalid_1's rmse: 0.0889482\n",
      "[1850]\ttraining's rmse: 0.0846892\tvalid_1's rmse: 0.0889467\n",
      "[1875]\ttraining's rmse: 0.0846822\tvalid_1's rmse: 0.0889461\n",
      "[1900]\ttraining's rmse: 0.0846762\tvalid_1's rmse: 0.0889441\n",
      "[1925]\ttraining's rmse: 0.0846715\tvalid_1's rmse: 0.0889438\n",
      "[1950]\ttraining's rmse: 0.0846661\tvalid_1's rmse: 0.0889417\n",
      "[1975]\ttraining's rmse: 0.0846613\tvalid_1's rmse: 0.08894\n",
      "[2000]\ttraining's rmse: 0.0846545\tvalid_1's rmse: 0.0889391\n",
      "[2025]\ttraining's rmse: 0.0846494\tvalid_1's rmse: 0.0889371\n",
      "[2050]\ttraining's rmse: 0.0846458\tvalid_1's rmse: 0.0889365\n",
      "[2075]\ttraining's rmse: 0.0846429\tvalid_1's rmse: 0.0889361\n",
      "[2100]\ttraining's rmse: 0.0846393\tvalid_1's rmse: 0.0889348\n",
      "[2125]\ttraining's rmse: 0.0846345\tvalid_1's rmse: 0.0889334\n",
      "[2150]\ttraining's rmse: 0.0846289\tvalid_1's rmse: 0.0889316\n",
      "[2175]\ttraining's rmse: 0.0846237\tvalid_1's rmse: 0.0889299\n",
      "[2200]\ttraining's rmse: 0.0846206\tvalid_1's rmse: 0.0889291\n",
      "[2225]\ttraining's rmse: 0.0846164\tvalid_1's rmse: 0.0889276\n",
      "[2250]\ttraining's rmse: 0.084614\tvalid_1's rmse: 0.0889264\n",
      "[2275]\ttraining's rmse: 0.0846092\tvalid_1's rmse: 0.0889259\n",
      "[2300]\ttraining's rmse: 0.0846064\tvalid_1's rmse: 0.0889243\n",
      "[2325]\ttraining's rmse: 0.0846018\tvalid_1's rmse: 0.0889235\n",
      "[2350]\ttraining's rmse: 0.084597\tvalid_1's rmse: 0.0889229\n",
      "[2375]\ttraining's rmse: 0.0845943\tvalid_1's rmse: 0.0889218\n",
      "[2400]\ttraining's rmse: 0.0845916\tvalid_1's rmse: 0.0889208\n",
      "[2425]\ttraining's rmse: 0.0845889\tvalid_1's rmse: 0.0889207\n",
      "[2450]\ttraining's rmse: 0.0845862\tvalid_1's rmse: 0.0889197\n",
      "[2475]\ttraining's rmse: 0.0845835\tvalid_1's rmse: 0.0889196\n",
      "[2500]\ttraining's rmse: 0.0845819\tvalid_1's rmse: 0.0889193\n",
      "[2525]\ttraining's rmse: 0.0845797\tvalid_1's rmse: 0.0889188\n",
      "[2550]\ttraining's rmse: 0.0845782\tvalid_1's rmse: 0.0889186\n",
      "[2575]\ttraining's rmse: 0.0845746\tvalid_1's rmse: 0.0889182\n",
      "[2600]\ttraining's rmse: 0.0845731\tvalid_1's rmse: 0.0889175\n",
      "[2625]\ttraining's rmse: 0.0845712\tvalid_1's rmse: 0.0889172\n",
      "[2650]\ttraining's rmse: 0.0845688\tvalid_1's rmse: 0.0889165\n",
      "[2675]\ttraining's rmse: 0.0845671\tvalid_1's rmse: 0.0889155\n",
      "[2700]\ttraining's rmse: 0.0845653\tvalid_1's rmse: 0.0889152\n",
      "[2725]\ttraining's rmse: 0.0845632\tvalid_1's rmse: 0.0889149\n",
      "[2750]\ttraining's rmse: 0.084561\tvalid_1's rmse: 0.0889136\n",
      "[2775]\ttraining's rmse: 0.0845595\tvalid_1's rmse: 0.0889129\n",
      "[2800]\ttraining's rmse: 0.0845586\tvalid_1's rmse: 0.088913\n",
      "[2825]\ttraining's rmse: 0.0845565\tvalid_1's rmse: 0.0889131\n",
      "[2850]\ttraining's rmse: 0.0845541\tvalid_1's rmse: 0.088913\n",
      "Early stopping, best iteration is:\n",
      "[2810]\ttraining's rmse: 0.0845578\tvalid_1's rmse: 0.0889127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0883007\tvalid_1's rmse: 0.0900252\n",
      "[50]\ttraining's rmse: 0.0881343\tvalid_1's rmse: 0.08997\n",
      "[75]\ttraining's rmse: 0.0879657\tvalid_1's rmse: 0.0899132\n",
      "[100]\ttraining's rmse: 0.0878146\tvalid_1's rmse: 0.0898627\n",
      "[125]\ttraining's rmse: 0.0876627\tvalid_1's rmse: 0.0898139\n",
      "[150]\ttraining's rmse: 0.0875206\tvalid_1's rmse: 0.0897692\n",
      "[175]\ttraining's rmse: 0.0874042\tvalid_1's rmse: 0.0897309\n",
      "[200]\ttraining's rmse: 0.0872808\tvalid_1's rmse: 0.0896902\n",
      "[225]\ttraining's rmse: 0.0871618\tvalid_1's rmse: 0.0896528\n",
      "[250]\ttraining's rmse: 0.08706\tvalid_1's rmse: 0.0896196\n",
      "[275]\ttraining's rmse: 0.086961\tvalid_1's rmse: 0.089588\n",
      "[300]\ttraining's rmse: 0.0868682\tvalid_1's rmse: 0.0895582\n",
      "[325]\ttraining's rmse: 0.0867752\tvalid_1's rmse: 0.0895301\n",
      "[350]\ttraining's rmse: 0.0866864\tvalid_1's rmse: 0.0895042\n",
      "[375]\ttraining's rmse: 0.0866131\tvalid_1's rmse: 0.0894811\n",
      "[400]\ttraining's rmse: 0.0865342\tvalid_1's rmse: 0.0894596\n",
      "[425]\ttraining's rmse: 0.0864622\tvalid_1's rmse: 0.0894388\n",
      "[450]\ttraining's rmse: 0.086397\tvalid_1's rmse: 0.0894185\n",
      "[475]\ttraining's rmse: 0.0863364\tvalid_1's rmse: 0.0893999\n",
      "[500]\ttraining's rmse: 0.0862827\tvalid_1's rmse: 0.0893826\n",
      "[525]\ttraining's rmse: 0.0862193\tvalid_1's rmse: 0.0893652\n",
      "[550]\ttraining's rmse: 0.0861583\tvalid_1's rmse: 0.0893497\n",
      "[575]\ttraining's rmse: 0.0861035\tvalid_1's rmse: 0.0893346\n",
      "[600]\ttraining's rmse: 0.0860512\tvalid_1's rmse: 0.0893202\n",
      "[625]\ttraining's rmse: 0.0860094\tvalid_1's rmse: 0.0893064\n",
      "[650]\ttraining's rmse: 0.0859582\tvalid_1's rmse: 0.0892926\n",
      "[675]\ttraining's rmse: 0.0859102\tvalid_1's rmse: 0.0892802\n",
      "[700]\ttraining's rmse: 0.0858669\tvalid_1's rmse: 0.0892681\n",
      "[725]\ttraining's rmse: 0.0858284\tvalid_1's rmse: 0.0892578\n",
      "[750]\ttraining's rmse: 0.0857877\tvalid_1's rmse: 0.0892469\n",
      "[775]\ttraining's rmse: 0.085755\tvalid_1's rmse: 0.0892367\n",
      "[800]\ttraining's rmse: 0.0857144\tvalid_1's rmse: 0.0892284\n",
      "[825]\ttraining's rmse: 0.0856781\tvalid_1's rmse: 0.089219\n",
      "[850]\ttraining's rmse: 0.0856435\tvalid_1's rmse: 0.0892119\n",
      "[875]\ttraining's rmse: 0.0856127\tvalid_1's rmse: 0.0892049\n",
      "[900]\ttraining's rmse: 0.0855785\tvalid_1's rmse: 0.0891963\n",
      "[925]\ttraining's rmse: 0.0855479\tvalid_1's rmse: 0.0891893\n",
      "[950]\ttraining's rmse: 0.0855169\tvalid_1's rmse: 0.0891833\n",
      "[975]\ttraining's rmse: 0.0854896\tvalid_1's rmse: 0.0891768\n",
      "[1000]\ttraining's rmse: 0.0854663\tvalid_1's rmse: 0.089172\n",
      "[1025]\ttraining's rmse: 0.0854368\tvalid_1's rmse: 0.0891669\n",
      "[1050]\ttraining's rmse: 0.0854123\tvalid_1's rmse: 0.0891613\n",
      "[1075]\ttraining's rmse: 0.0853862\tvalid_1's rmse: 0.0891569\n",
      "[1100]\ttraining's rmse: 0.0853666\tvalid_1's rmse: 0.0891518\n",
      "[1125]\ttraining's rmse: 0.0853444\tvalid_1's rmse: 0.0891469\n",
      "[1150]\ttraining's rmse: 0.0853212\tvalid_1's rmse: 0.0891431\n",
      "[1175]\ttraining's rmse: 0.0853023\tvalid_1's rmse: 0.0891394\n",
      "[1200]\ttraining's rmse: 0.0852832\tvalid_1's rmse: 0.0891358\n",
      "[1225]\ttraining's rmse: 0.0852641\tvalid_1's rmse: 0.0891325\n",
      "[1250]\ttraining's rmse: 0.0852477\tvalid_1's rmse: 0.0891297\n",
      "[1275]\ttraining's rmse: 0.0852251\tvalid_1's rmse: 0.089126\n",
      "[1300]\ttraining's rmse: 0.0852089\tvalid_1's rmse: 0.0891233\n",
      "[1325]\ttraining's rmse: 0.0851911\tvalid_1's rmse: 0.0891204\n",
      "[1350]\ttraining's rmse: 0.0851763\tvalid_1's rmse: 0.0891184\n",
      "[1375]\ttraining's rmse: 0.0851612\tvalid_1's rmse: 0.0891161\n",
      "[1400]\ttraining's rmse: 0.0851473\tvalid_1's rmse: 0.0891131\n",
      "[1425]\ttraining's rmse: 0.0851311\tvalid_1's rmse: 0.0891118\n",
      "[1450]\ttraining's rmse: 0.0851183\tvalid_1's rmse: 0.0891098\n",
      "[1475]\ttraining's rmse: 0.0851066\tvalid_1's rmse: 0.0891067\n",
      "[1500]\ttraining's rmse: 0.0850944\tvalid_1's rmse: 0.0891047\n",
      "[1525]\ttraining's rmse: 0.0850823\tvalid_1's rmse: 0.0891031\n",
      "[1550]\ttraining's rmse: 0.0850702\tvalid_1's rmse: 0.089102\n",
      "[1575]\ttraining's rmse: 0.0850607\tvalid_1's rmse: 0.0891002\n",
      "[1600]\ttraining's rmse: 0.0850503\tvalid_1's rmse: 0.0890993\n",
      "[1625]\ttraining's rmse: 0.0850408\tvalid_1's rmse: 0.0890975\n",
      "[1650]\ttraining's rmse: 0.0850326\tvalid_1's rmse: 0.0890966\n",
      "[1675]\ttraining's rmse: 0.0850269\tvalid_1's rmse: 0.0890956\n",
      "[1700]\ttraining's rmse: 0.0850202\tvalid_1's rmse: 0.0890945\n",
      "[1725]\ttraining's rmse: 0.0850137\tvalid_1's rmse: 0.0890931\n",
      "[1750]\ttraining's rmse: 0.0850061\tvalid_1's rmse: 0.0890924\n",
      "[1775]\ttraining's rmse: 0.0849991\tvalid_1's rmse: 0.0890915\n",
      "[1800]\ttraining's rmse: 0.0849912\tvalid_1's rmse: 0.0890909\n",
      "[1825]\ttraining's rmse: 0.0849839\tvalid_1's rmse: 0.0890898\n",
      "[1850]\ttraining's rmse: 0.084976\tvalid_1's rmse: 0.0890877\n",
      "[1875]\ttraining's rmse: 0.0849699\tvalid_1's rmse: 0.0890873\n",
      "[1900]\ttraining's rmse: 0.0849655\tvalid_1's rmse: 0.0890869\n",
      "[1925]\ttraining's rmse: 0.0849593\tvalid_1's rmse: 0.0890864\n",
      "[1950]\ttraining's rmse: 0.0849551\tvalid_1's rmse: 0.0890853\n",
      "[1975]\ttraining's rmse: 0.0849511\tvalid_1's rmse: 0.0890846\n",
      "[2000]\ttraining's rmse: 0.0849455\tvalid_1's rmse: 0.0890843\n",
      "[2025]\ttraining's rmse: 0.0849412\tvalid_1's rmse: 0.0890836\n",
      "[2050]\ttraining's rmse: 0.0849365\tvalid_1's rmse: 0.0890835\n",
      "[2075]\ttraining's rmse: 0.084933\tvalid_1's rmse: 0.0890825\n",
      "[2100]\ttraining's rmse: 0.0849303\tvalid_1's rmse: 0.0890823\n",
      "[2125]\ttraining's rmse: 0.0849258\tvalid_1's rmse: 0.0890822\n",
      "[2150]\ttraining's rmse: 0.0849223\tvalid_1's rmse: 0.0890825\n",
      "Early stopping, best iteration is:\n",
      "[2113]\ttraining's rmse: 0.0849272\tvalid_1's rmse: 0.089082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0897955\tvalid_1's rmse: 0.0870496\n",
      "[50]\ttraining's rmse: 0.0896606\tvalid_1's rmse: 0.0870005\n",
      "[75]\ttraining's rmse: 0.0895194\tvalid_1's rmse: 0.0869511\n",
      "[100]\ttraining's rmse: 0.0893897\tvalid_1's rmse: 0.0869075\n",
      "[125]\ttraining's rmse: 0.0892572\tvalid_1's rmse: 0.0868645\n",
      "[150]\ttraining's rmse: 0.0891367\tvalid_1's rmse: 0.0868267\n",
      "[175]\ttraining's rmse: 0.0890343\tvalid_1's rmse: 0.0867947\n",
      "[200]\ttraining's rmse: 0.0889221\tvalid_1's rmse: 0.0867622\n",
      "[225]\ttraining's rmse: 0.0888152\tvalid_1's rmse: 0.0867324\n",
      "[250]\ttraining's rmse: 0.0887234\tvalid_1's rmse: 0.086705\n",
      "[275]\ttraining's rmse: 0.0886397\tvalid_1's rmse: 0.0866799\n",
      "[300]\ttraining's rmse: 0.0885564\tvalid_1's rmse: 0.0866559\n",
      "[325]\ttraining's rmse: 0.0884719\tvalid_1's rmse: 0.0866352\n",
      "[350]\ttraining's rmse: 0.088388\tvalid_1's rmse: 0.0866156\n",
      "[375]\ttraining's rmse: 0.0883243\tvalid_1's rmse: 0.0866052\n",
      "[400]\ttraining's rmse: 0.0882518\tvalid_1's rmse: 0.0865878\n",
      "[425]\ttraining's rmse: 0.0881858\tvalid_1's rmse: 0.0865711\n",
      "[450]\ttraining's rmse: 0.0881238\tvalid_1's rmse: 0.0865587\n",
      "[475]\ttraining's rmse: 0.0880673\tvalid_1's rmse: 0.0865461\n",
      "[500]\ttraining's rmse: 0.0880187\tvalid_1's rmse: 0.0865336\n",
      "[525]\ttraining's rmse: 0.0879548\tvalid_1's rmse: 0.0865217\n",
      "[550]\ttraining's rmse: 0.0878965\tvalid_1's rmse: 0.0865096\n",
      "[575]\ttraining's rmse: 0.0878431\tvalid_1's rmse: 0.0865011\n",
      "[600]\ttraining's rmse: 0.0877917\tvalid_1's rmse: 0.0864921\n",
      "[625]\ttraining's rmse: 0.0877499\tvalid_1's rmse: 0.0864839\n",
      "[650]\ttraining's rmse: 0.0877\tvalid_1's rmse: 0.0864786\n",
      "[675]\ttraining's rmse: 0.087649\tvalid_1's rmse: 0.0864717\n",
      "[700]\ttraining's rmse: 0.0876033\tvalid_1's rmse: 0.0864638\n",
      "[725]\ttraining's rmse: 0.0875604\tvalid_1's rmse: 0.0864611\n",
      "[750]\ttraining's rmse: 0.0875195\tvalid_1's rmse: 0.0864581\n",
      "[775]\ttraining's rmse: 0.0874865\tvalid_1's rmse: 0.0864557\n",
      "[800]\ttraining's rmse: 0.0874428\tvalid_1's rmse: 0.0864557\n",
      "[825]\ttraining's rmse: 0.0874064\tvalid_1's rmse: 0.0864622\n",
      "Early stopping, best iteration is:\n",
      "[797]\ttraining's rmse: 0.0874468\tvalid_1's rmse: 0.0864527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0839353\tvalid_1's rmse: 0.0864324\n",
      "[50]\ttraining's rmse: 0.0838032\tvalid_1's rmse: 0.0863743\n",
      "[75]\ttraining's rmse: 0.0836718\tvalid_1's rmse: 0.0863199\n",
      "[100]\ttraining's rmse: 0.0835512\tvalid_1's rmse: 0.0862698\n",
      "[125]\ttraining's rmse: 0.0834307\tvalid_1's rmse: 0.0862192\n",
      "[150]\ttraining's rmse: 0.0833184\tvalid_1's rmse: 0.0861734\n",
      "[175]\ttraining's rmse: 0.0832232\tvalid_1's rmse: 0.0861332\n",
      "[200]\ttraining's rmse: 0.0831227\tvalid_1's rmse: 0.0860934\n",
      "[225]\ttraining's rmse: 0.0830265\tvalid_1's rmse: 0.0860568\n",
      "[250]\ttraining's rmse: 0.0829439\tvalid_1's rmse: 0.0860216\n",
      "[275]\ttraining's rmse: 0.0828691\tvalid_1's rmse: 0.0859919\n",
      "[300]\ttraining's rmse: 0.0827941\tvalid_1's rmse: 0.0859613\n",
      "[325]\ttraining's rmse: 0.0827154\tvalid_1's rmse: 0.0859333\n",
      "[350]\ttraining's rmse: 0.0826425\tvalid_1's rmse: 0.0859065\n",
      "[375]\ttraining's rmse: 0.0825806\tvalid_1's rmse: 0.0858841\n",
      "[400]\ttraining's rmse: 0.0825136\tvalid_1's rmse: 0.0858615\n",
      "[425]\ttraining's rmse: 0.0824577\tvalid_1's rmse: 0.0858394\n",
      "[450]\ttraining's rmse: 0.0823989\tvalid_1's rmse: 0.0858178\n",
      "[475]\ttraining's rmse: 0.0823487\tvalid_1's rmse: 0.0857976\n",
      "[500]\ttraining's rmse: 0.0823031\tvalid_1's rmse: 0.0857771\n",
      "[525]\ttraining's rmse: 0.0822505\tvalid_1's rmse: 0.0857608\n",
      "[550]\ttraining's rmse: 0.082201\tvalid_1's rmse: 0.0857453\n",
      "[575]\ttraining's rmse: 0.082155\tvalid_1's rmse: 0.0857295\n",
      "[600]\ttraining's rmse: 0.0821089\tvalid_1's rmse: 0.0857136\n",
      "[625]\ttraining's rmse: 0.0820752\tvalid_1's rmse: 0.0857003\n",
      "[650]\ttraining's rmse: 0.0820337\tvalid_1's rmse: 0.085686\n",
      "[675]\ttraining's rmse: 0.0819892\tvalid_1's rmse: 0.0856728\n",
      "[700]\ttraining's rmse: 0.081954\tvalid_1's rmse: 0.0856606\n",
      "[725]\ttraining's rmse: 0.0819177\tvalid_1's rmse: 0.0856493\n",
      "[750]\ttraining's rmse: 0.0818837\tvalid_1's rmse: 0.0856398\n",
      "[775]\ttraining's rmse: 0.0818583\tvalid_1's rmse: 0.0856293\n",
      "[800]\ttraining's rmse: 0.0818231\tvalid_1's rmse: 0.0856205\n",
      "[825]\ttraining's rmse: 0.081793\tvalid_1's rmse: 0.0856126\n",
      "[850]\ttraining's rmse: 0.0817621\tvalid_1's rmse: 0.0856043\n",
      "[875]\ttraining's rmse: 0.0817386\tvalid_1's rmse: 0.085597\n",
      "[900]\ttraining's rmse: 0.0817092\tvalid_1's rmse: 0.0855898\n",
      "[925]\ttraining's rmse: 0.0816844\tvalid_1's rmse: 0.0855829\n",
      "[950]\ttraining's rmse: 0.0816606\tvalid_1's rmse: 0.0855755\n",
      "[975]\ttraining's rmse: 0.0816375\tvalid_1's rmse: 0.0855685\n",
      "[1000]\ttraining's rmse: 0.0816148\tvalid_1's rmse: 0.0855628\n",
      "[1025]\ttraining's rmse: 0.0815904\tvalid_1's rmse: 0.085556\n",
      "[1050]\ttraining's rmse: 0.081567\tvalid_1's rmse: 0.0855485\n",
      "[1075]\ttraining's rmse: 0.081546\tvalid_1's rmse: 0.0855442\n",
      "[1100]\ttraining's rmse: 0.0815279\tvalid_1's rmse: 0.0855383\n",
      "[1125]\ttraining's rmse: 0.0815089\tvalid_1's rmse: 0.085532\n",
      "[1150]\ttraining's rmse: 0.0814887\tvalid_1's rmse: 0.0855261\n",
      "[1175]\ttraining's rmse: 0.0814706\tvalid_1's rmse: 0.0855216\n",
      "[1200]\ttraining's rmse: 0.0814549\tvalid_1's rmse: 0.085515\n",
      "[1225]\ttraining's rmse: 0.0814377\tvalid_1's rmse: 0.0855094\n",
      "[1250]\ttraining's rmse: 0.081421\tvalid_1's rmse: 0.0855039\n",
      "[1275]\ttraining's rmse: 0.0814066\tvalid_1's rmse: 0.0855005\n",
      "[1300]\ttraining's rmse: 0.0813947\tvalid_1's rmse: 0.0854965\n",
      "[1325]\ttraining's rmse: 0.0813821\tvalid_1's rmse: 0.0854927\n",
      "[1350]\ttraining's rmse: 0.081368\tvalid_1's rmse: 0.0854895\n",
      "[1375]\ttraining's rmse: 0.0813563\tvalid_1's rmse: 0.0854867\n",
      "[1400]\ttraining's rmse: 0.0813456\tvalid_1's rmse: 0.0854835\n",
      "[1425]\ttraining's rmse: 0.0813334\tvalid_1's rmse: 0.0854804\n",
      "[1450]\ttraining's rmse: 0.0813218\tvalid_1's rmse: 0.0854771\n",
      "[1475]\ttraining's rmse: 0.0813114\tvalid_1's rmse: 0.0854739\n",
      "[1500]\ttraining's rmse: 0.0813031\tvalid_1's rmse: 0.0854712\n",
      "[1525]\ttraining's rmse: 0.0812956\tvalid_1's rmse: 0.0854684\n",
      "[1550]\ttraining's rmse: 0.0812832\tvalid_1's rmse: 0.0854658\n",
      "[1575]\ttraining's rmse: 0.0812755\tvalid_1's rmse: 0.0854638\n",
      "[1600]\ttraining's rmse: 0.0812669\tvalid_1's rmse: 0.0854617\n",
      "[1625]\ttraining's rmse: 0.0812612\tvalid_1's rmse: 0.0854587\n",
      "[1650]\ttraining's rmse: 0.0812538\tvalid_1's rmse: 0.0854566\n",
      "[1675]\ttraining's rmse: 0.0812484\tvalid_1's rmse: 0.0854546\n",
      "[1700]\ttraining's rmse: 0.0812425\tvalid_1's rmse: 0.0854515\n",
      "[1725]\ttraining's rmse: 0.0812359\tvalid_1's rmse: 0.0854494\n",
      "[1750]\ttraining's rmse: 0.0812266\tvalid_1's rmse: 0.0854467\n",
      "[1775]\ttraining's rmse: 0.0812206\tvalid_1's rmse: 0.0854441\n",
      "[1800]\ttraining's rmse: 0.0812158\tvalid_1's rmse: 0.0854427\n",
      "[1825]\ttraining's rmse: 0.0812091\tvalid_1's rmse: 0.0854411\n",
      "[1850]\ttraining's rmse: 0.0812047\tvalid_1's rmse: 0.0854397\n",
      "[1875]\ttraining's rmse: 0.0811994\tvalid_1's rmse: 0.085438\n",
      "[1900]\ttraining's rmse: 0.0811953\tvalid_1's rmse: 0.0854374\n",
      "[1925]\ttraining's rmse: 0.0811904\tvalid_1's rmse: 0.0854369\n",
      "[1950]\ttraining's rmse: 0.0811865\tvalid_1's rmse: 0.0854356\n",
      "[1975]\ttraining's rmse: 0.0811821\tvalid_1's rmse: 0.0854346\n",
      "[2000]\ttraining's rmse: 0.0811774\tvalid_1's rmse: 0.0854329\n",
      "[2025]\ttraining's rmse: 0.0811743\tvalid_1's rmse: 0.0854308\n",
      "[2050]\ttraining's rmse: 0.0811712\tvalid_1's rmse: 0.0854301\n",
      "[2075]\ttraining's rmse: 0.0811668\tvalid_1's rmse: 0.0854297\n",
      "[2100]\ttraining's rmse: 0.0811639\tvalid_1's rmse: 0.0854297\n",
      "[2125]\ttraining's rmse: 0.0811598\tvalid_1's rmse: 0.0854288\n",
      "[2150]\ttraining's rmse: 0.0811566\tvalid_1's rmse: 0.0854287\n",
      "[2175]\ttraining's rmse: 0.0811539\tvalid_1's rmse: 0.0854278\n",
      "[2200]\ttraining's rmse: 0.0811498\tvalid_1's rmse: 0.0854272\n",
      "[2225]\ttraining's rmse: 0.081146\tvalid_1's rmse: 0.0854266\n",
      "[2250]\ttraining's rmse: 0.0811433\tvalid_1's rmse: 0.085425\n",
      "[2275]\ttraining's rmse: 0.0811385\tvalid_1's rmse: 0.0854246\n",
      "[2300]\ttraining's rmse: 0.0811354\tvalid_1's rmse: 0.0854244\n",
      "[2325]\ttraining's rmse: 0.0811325\tvalid_1's rmse: 0.0854233\n",
      "[2350]\ttraining's rmse: 0.0811303\tvalid_1's rmse: 0.0854225\n",
      "[2375]\ttraining's rmse: 0.0811264\tvalid_1's rmse: 0.0854225\n",
      "[2400]\ttraining's rmse: 0.0811222\tvalid_1's rmse: 0.0854219\n",
      "[2425]\ttraining's rmse: 0.0811197\tvalid_1's rmse: 0.0854219\n",
      "[2450]\ttraining's rmse: 0.0811184\tvalid_1's rmse: 0.085422\n",
      "[2475]\ttraining's rmse: 0.081116\tvalid_1's rmse: 0.0854211\n",
      "[2500]\ttraining's rmse: 0.0811144\tvalid_1's rmse: 0.0854205\n",
      "[2525]\ttraining's rmse: 0.0811111\tvalid_1's rmse: 0.0854205\n",
      "[2550]\ttraining's rmse: 0.0811092\tvalid_1's rmse: 0.0854199\n",
      "[2575]\ttraining's rmse: 0.0811078\tvalid_1's rmse: 0.0854197\n",
      "[2600]\ttraining's rmse: 0.0811065\tvalid_1's rmse: 0.0854199\n",
      "Early stopping, best iteration is:\n",
      "[2564]\ttraining's rmse: 0.0811084\tvalid_1's rmse: 0.0854193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0840623\tvalid_1's rmse: 0.0861802\n",
      "[50]\ttraining's rmse: 0.0839384\tvalid_1's rmse: 0.0861206\n",
      "[75]\ttraining's rmse: 0.0838109\tvalid_1's rmse: 0.0860626\n",
      "[100]\ttraining's rmse: 0.0836968\tvalid_1's rmse: 0.0860116\n",
      "[125]\ttraining's rmse: 0.0835806\tvalid_1's rmse: 0.0859614\n",
      "[150]\ttraining's rmse: 0.083473\tvalid_1's rmse: 0.0859146\n",
      "[175]\ttraining's rmse: 0.0833861\tvalid_1's rmse: 0.0858755\n",
      "[200]\ttraining's rmse: 0.0832871\tvalid_1's rmse: 0.0858374\n",
      "[225]\ttraining's rmse: 0.0831966\tvalid_1's rmse: 0.0858031\n",
      "[250]\ttraining's rmse: 0.0831171\tvalid_1's rmse: 0.0857705\n",
      "[275]\ttraining's rmse: 0.0830443\tvalid_1's rmse: 0.0857404\n",
      "[300]\ttraining's rmse: 0.0829684\tvalid_1's rmse: 0.0857114\n",
      "[325]\ttraining's rmse: 0.0828939\tvalid_1's rmse: 0.0856841\n",
      "[350]\ttraining's rmse: 0.0828195\tvalid_1's rmse: 0.0856584\n",
      "[375]\ttraining's rmse: 0.0827614\tvalid_1's rmse: 0.0856369\n",
      "[400]\ttraining's rmse: 0.0826985\tvalid_1's rmse: 0.0856161\n",
      "[425]\ttraining's rmse: 0.0826408\tvalid_1's rmse: 0.0855961\n",
      "[450]\ttraining's rmse: 0.0825846\tvalid_1's rmse: 0.0855763\n",
      "[475]\ttraining's rmse: 0.0825338\tvalid_1's rmse: 0.0855588\n",
      "[500]\ttraining's rmse: 0.0824911\tvalid_1's rmse: 0.0855431\n",
      "[525]\ttraining's rmse: 0.0824369\tvalid_1's rmse: 0.0855269\n",
      "[550]\ttraining's rmse: 0.082382\tvalid_1's rmse: 0.0855102\n",
      "[575]\ttraining's rmse: 0.0823351\tvalid_1's rmse: 0.0854955\n",
      "[600]\ttraining's rmse: 0.0822906\tvalid_1's rmse: 0.0854833\n",
      "[625]\ttraining's rmse: 0.0822562\tvalid_1's rmse: 0.0854715\n",
      "[650]\ttraining's rmse: 0.0822118\tvalid_1's rmse: 0.0854593\n",
      "[675]\ttraining's rmse: 0.0821661\tvalid_1's rmse: 0.0854475\n",
      "[700]\ttraining's rmse: 0.0821259\tvalid_1's rmse: 0.0854351\n",
      "[725]\ttraining's rmse: 0.08209\tvalid_1's rmse: 0.0854258\n",
      "[750]\ttraining's rmse: 0.0820557\tvalid_1's rmse: 0.0854164\n",
      "[775]\ttraining's rmse: 0.0820249\tvalid_1's rmse: 0.0854071\n",
      "[800]\ttraining's rmse: 0.0819883\tvalid_1's rmse: 0.0853991\n",
      "[825]\ttraining's rmse: 0.0819569\tvalid_1's rmse: 0.0853906\n",
      "[850]\ttraining's rmse: 0.0819257\tvalid_1's rmse: 0.0853842\n",
      "[875]\ttraining's rmse: 0.0818998\tvalid_1's rmse: 0.0853774\n",
      "[900]\ttraining's rmse: 0.0818709\tvalid_1's rmse: 0.08537\n",
      "[925]\ttraining's rmse: 0.081843\tvalid_1's rmse: 0.0853641\n",
      "[950]\ttraining's rmse: 0.0818172\tvalid_1's rmse: 0.085358\n",
      "[975]\ttraining's rmse: 0.0817934\tvalid_1's rmse: 0.085353\n",
      "[1000]\ttraining's rmse: 0.08177\tvalid_1's rmse: 0.0853476\n",
      "[1025]\ttraining's rmse: 0.0817439\tvalid_1's rmse: 0.0853432\n",
      "[1050]\ttraining's rmse: 0.0817236\tvalid_1's rmse: 0.0853387\n",
      "[1075]\ttraining's rmse: 0.0817029\tvalid_1's rmse: 0.0853345\n",
      "[1100]\ttraining's rmse: 0.0816848\tvalid_1's rmse: 0.085331\n",
      "[1125]\ttraining's rmse: 0.0816644\tvalid_1's rmse: 0.0853274\n",
      "[1150]\ttraining's rmse: 0.0816426\tvalid_1's rmse: 0.0853235\n",
      "[1175]\ttraining's rmse: 0.0816255\tvalid_1's rmse: 0.0853206\n",
      "[1200]\ttraining's rmse: 0.0816072\tvalid_1's rmse: 0.0853173\n",
      "[1225]\ttraining's rmse: 0.0815906\tvalid_1's rmse: 0.0853143\n",
      "[1250]\ttraining's rmse: 0.0815761\tvalid_1's rmse: 0.0853111\n",
      "[1275]\ttraining's rmse: 0.0815603\tvalid_1's rmse: 0.0853092\n",
      "[1300]\ttraining's rmse: 0.0815477\tvalid_1's rmse: 0.0853063\n",
      "[1325]\ttraining's rmse: 0.0815343\tvalid_1's rmse: 0.0853035\n",
      "[1350]\ttraining's rmse: 0.08152\tvalid_1's rmse: 0.0853015\n",
      "[1375]\ttraining's rmse: 0.0815076\tvalid_1's rmse: 0.0853003\n",
      "[1400]\ttraining's rmse: 0.0814979\tvalid_1's rmse: 0.0852982\n",
      "[1425]\ttraining's rmse: 0.0814871\tvalid_1's rmse: 0.0852965\n",
      "[1450]\ttraining's rmse: 0.0814762\tvalid_1's rmse: 0.0852945\n",
      "[1475]\ttraining's rmse: 0.0814662\tvalid_1's rmse: 0.0852925\n",
      "[1500]\ttraining's rmse: 0.0814556\tvalid_1's rmse: 0.0852905\n",
      "[1525]\ttraining's rmse: 0.0814457\tvalid_1's rmse: 0.0852894\n",
      "[1550]\ttraining's rmse: 0.0814373\tvalid_1's rmse: 0.0852883\n",
      "[1575]\ttraining's rmse: 0.0814277\tvalid_1's rmse: 0.0852863\n",
      "[1600]\ttraining's rmse: 0.0814205\tvalid_1's rmse: 0.0852857\n",
      "[1625]\ttraining's rmse: 0.0814112\tvalid_1's rmse: 0.0852838\n",
      "[1650]\ttraining's rmse: 0.0814027\tvalid_1's rmse: 0.0852824\n",
      "[1675]\ttraining's rmse: 0.0813968\tvalid_1's rmse: 0.0852807\n",
      "[1700]\ttraining's rmse: 0.0813912\tvalid_1's rmse: 0.0852798\n",
      "[1725]\ttraining's rmse: 0.0813849\tvalid_1's rmse: 0.0852787\n",
      "[1750]\ttraining's rmse: 0.0813752\tvalid_1's rmse: 0.0852778\n",
      "[1775]\ttraining's rmse: 0.0813689\tvalid_1's rmse: 0.0852778\n",
      "[1800]\ttraining's rmse: 0.0813631\tvalid_1's rmse: 0.0852773\n",
      "[1825]\ttraining's rmse: 0.0813563\tvalid_1's rmse: 0.0852765\n",
      "[1850]\ttraining's rmse: 0.0813514\tvalid_1's rmse: 0.085276\n",
      "[1875]\ttraining's rmse: 0.0813465\tvalid_1's rmse: 0.0852756\n",
      "[1900]\ttraining's rmse: 0.0813419\tvalid_1's rmse: 0.0852753\n",
      "[1925]\ttraining's rmse: 0.0813363\tvalid_1's rmse: 0.0852745\n",
      "[1950]\ttraining's rmse: 0.0813326\tvalid_1's rmse: 0.0852738\n",
      "[1975]\ttraining's rmse: 0.0813299\tvalid_1's rmse: 0.0852735\n",
      "[2000]\ttraining's rmse: 0.0813249\tvalid_1's rmse: 0.0852725\n",
      "[2025]\ttraining's rmse: 0.0813204\tvalid_1's rmse: 0.0852721\n",
      "[2050]\ttraining's rmse: 0.0813165\tvalid_1's rmse: 0.0852717\n",
      "[2075]\ttraining's rmse: 0.0813126\tvalid_1's rmse: 0.0852709\n",
      "[2100]\ttraining's rmse: 0.0813095\tvalid_1's rmse: 0.0852708\n",
      "[2125]\ttraining's rmse: 0.0813067\tvalid_1's rmse: 0.0852704\n",
      "[2150]\ttraining's rmse: 0.0813041\tvalid_1's rmse: 0.0852704\n",
      "[2175]\ttraining's rmse: 0.0813\tvalid_1's rmse: 0.0852704\n",
      "[2200]\ttraining's rmse: 0.081297\tvalid_1's rmse: 0.0852701\n",
      "[2225]\ttraining's rmse: 0.081294\tvalid_1's rmse: 0.0852698\n",
      "[2250]\ttraining's rmse: 0.0812899\tvalid_1's rmse: 0.0852697\n",
      "[2275]\ttraining's rmse: 0.0812872\tvalid_1's rmse: 0.0852694\n",
      "[2300]\ttraining's rmse: 0.0812844\tvalid_1's rmse: 0.0852688\n",
      "[2325]\ttraining's rmse: 0.081281\tvalid_1's rmse: 0.0852683\n",
      "[2350]\ttraining's rmse: 0.0812768\tvalid_1's rmse: 0.0852675\n",
      "[2375]\ttraining's rmse: 0.081274\tvalid_1's rmse: 0.0852675\n",
      "[2400]\ttraining's rmse: 0.0812706\tvalid_1's rmse: 0.0852679\n",
      "[2425]\ttraining's rmse: 0.0812677\tvalid_1's rmse: 0.0852678\n",
      "Early stopping, best iteration is:\n",
      "[2384]\ttraining's rmse: 0.0812719\tvalid_1's rmse: 0.0852672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0861814\tvalid_1's rmse: 0.0818836\n",
      "[50]\ttraining's rmse: 0.0860633\tvalid_1's rmse: 0.0818374\n",
      "[75]\ttraining's rmse: 0.0859389\tvalid_1's rmse: 0.0817861\n",
      "[100]\ttraining's rmse: 0.0858296\tvalid_1's rmse: 0.0817415\n",
      "[125]\ttraining's rmse: 0.085717\tvalid_1's rmse: 0.0816984\n",
      "[150]\ttraining's rmse: 0.0856131\tvalid_1's rmse: 0.0816592\n",
      "[175]\ttraining's rmse: 0.0855275\tvalid_1's rmse: 0.0816259\n",
      "[200]\ttraining's rmse: 0.0854378\tvalid_1's rmse: 0.0815971\n",
      "[225]\ttraining's rmse: 0.0853514\tvalid_1's rmse: 0.0815673\n",
      "[250]\ttraining's rmse: 0.0852749\tvalid_1's rmse: 0.0815407\n",
      "[275]\ttraining's rmse: 0.085206\tvalid_1's rmse: 0.081515\n",
      "[300]\ttraining's rmse: 0.0851361\tvalid_1's rmse: 0.0814914\n",
      "[325]\ttraining's rmse: 0.0850661\tvalid_1's rmse: 0.0814675\n",
      "[350]\ttraining's rmse: 0.0849994\tvalid_1's rmse: 0.0814465\n",
      "[375]\ttraining's rmse: 0.0849432\tvalid_1's rmse: 0.0814271\n",
      "[400]\ttraining's rmse: 0.0848814\tvalid_1's rmse: 0.0814139\n",
      "[425]\ttraining's rmse: 0.0848259\tvalid_1's rmse: 0.0813985\n",
      "[450]\ttraining's rmse: 0.084772\tvalid_1's rmse: 0.0813841\n",
      "[475]\ttraining's rmse: 0.0847253\tvalid_1's rmse: 0.0813695\n",
      "[500]\ttraining's rmse: 0.0846842\tvalid_1's rmse: 0.0813579\n",
      "[525]\ttraining's rmse: 0.0846302\tvalid_1's rmse: 0.0813481\n",
      "[550]\ttraining's rmse: 0.0845797\tvalid_1's rmse: 0.0813497\n",
      "[575]\ttraining's rmse: 0.0845337\tvalid_1's rmse: 0.0813381\n",
      "[600]\ttraining's rmse: 0.0844886\tvalid_1's rmse: 0.0813333\n",
      "[625]\ttraining's rmse: 0.0844545\tvalid_1's rmse: 0.0813279\n",
      "[650]\ttraining's rmse: 0.08441\tvalid_1's rmse: 0.0813259\n",
      "[675]\ttraining's rmse: 0.0843646\tvalid_1's rmse: 0.0813245\n",
      "[700]\ttraining's rmse: 0.0843266\tvalid_1's rmse: 0.0813187\n",
      "[725]\ttraining's rmse: 0.0842898\tvalid_1's rmse: 0.0813184\n",
      "[750]\ttraining's rmse: 0.0842561\tvalid_1's rmse: 0.0813268\n",
      "[775]\ttraining's rmse: 0.084228\tvalid_1's rmse: 0.0813321\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 0.084265\tvalid_1's rmse: 0.0813123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0890982\tvalid_1's rmse: 0.0907804\n",
      "[50]\ttraining's rmse: 0.0889001\tvalid_1's rmse: 0.0907267\n",
      "[75]\ttraining's rmse: 0.0887068\tvalid_1's rmse: 0.090674\n",
      "[100]\ttraining's rmse: 0.088531\tvalid_1's rmse: 0.0906272\n",
      "[125]\ttraining's rmse: 0.0883594\tvalid_1's rmse: 0.0905797\n",
      "[150]\ttraining's rmse: 0.0882026\tvalid_1's rmse: 0.0905386\n",
      "[175]\ttraining's rmse: 0.0880683\tvalid_1's rmse: 0.0905004\n",
      "[200]\ttraining's rmse: 0.0879262\tvalid_1's rmse: 0.0904632\n",
      "[225]\ttraining's rmse: 0.0877905\tvalid_1's rmse: 0.090429\n",
      "[250]\ttraining's rmse: 0.0876758\tvalid_1's rmse: 0.0903973\n",
      "[275]\ttraining's rmse: 0.0875664\tvalid_1's rmse: 0.0903677\n",
      "[300]\ttraining's rmse: 0.0874583\tvalid_1's rmse: 0.0903409\n",
      "[325]\ttraining's rmse: 0.0873546\tvalid_1's rmse: 0.0903171\n",
      "[350]\ttraining's rmse: 0.0872556\tvalid_1's rmse: 0.0902935\n",
      "[375]\ttraining's rmse: 0.0871667\tvalid_1's rmse: 0.0902744\n",
      "[400]\ttraining's rmse: 0.087074\tvalid_1's rmse: 0.0902512\n",
      "[425]\ttraining's rmse: 0.0869925\tvalid_1's rmse: 0.0902324\n",
      "[450]\ttraining's rmse: 0.0869191\tvalid_1's rmse: 0.090213\n",
      "[475]\ttraining's rmse: 0.086848\tvalid_1's rmse: 0.0901941\n",
      "[500]\ttraining's rmse: 0.0867872\tvalid_1's rmse: 0.0901758\n",
      "[525]\ttraining's rmse: 0.0867168\tvalid_1's rmse: 0.0901589\n",
      "[550]\ttraining's rmse: 0.0866493\tvalid_1's rmse: 0.090142\n",
      "[575]\ttraining's rmse: 0.0865897\tvalid_1's rmse: 0.0901303\n",
      "[600]\ttraining's rmse: 0.0865288\tvalid_1's rmse: 0.0901165\n",
      "[625]\ttraining's rmse: 0.0864798\tvalid_1's rmse: 0.0901039\n",
      "[650]\ttraining's rmse: 0.0864229\tvalid_1's rmse: 0.0900912\n",
      "[675]\ttraining's rmse: 0.0863688\tvalid_1's rmse: 0.0900787\n",
      "[700]\ttraining's rmse: 0.08632\tvalid_1's rmse: 0.0900678\n",
      "[725]\ttraining's rmse: 0.0862766\tvalid_1's rmse: 0.0900571\n",
      "[750]\ttraining's rmse: 0.0862344\tvalid_1's rmse: 0.0900481\n",
      "[775]\ttraining's rmse: 0.0861979\tvalid_1's rmse: 0.0900385\n",
      "[800]\ttraining's rmse: 0.0861541\tvalid_1's rmse: 0.090031\n",
      "[825]\ttraining's rmse: 0.086115\tvalid_1's rmse: 0.0900242\n",
      "[850]\ttraining's rmse: 0.0860745\tvalid_1's rmse: 0.0900168\n",
      "[875]\ttraining's rmse: 0.0860394\tvalid_1's rmse: 0.0900088\n",
      "[900]\ttraining's rmse: 0.0860037\tvalid_1's rmse: 0.0900007\n",
      "[925]\ttraining's rmse: 0.0859701\tvalid_1's rmse: 0.0899928\n",
      "[950]\ttraining's rmse: 0.0859385\tvalid_1's rmse: 0.0899855\n",
      "[975]\ttraining's rmse: 0.0859099\tvalid_1's rmse: 0.0899801\n",
      "[1000]\ttraining's rmse: 0.0858829\tvalid_1's rmse: 0.0899745\n",
      "[1025]\ttraining's rmse: 0.0858552\tvalid_1's rmse: 0.0899693\n",
      "[1050]\ttraining's rmse: 0.0858283\tvalid_1's rmse: 0.0899634\n",
      "[1075]\ttraining's rmse: 0.085803\tvalid_1's rmse: 0.0899581\n",
      "[1100]\ttraining's rmse: 0.0857771\tvalid_1's rmse: 0.0899537\n",
      "[1125]\ttraining's rmse: 0.0857539\tvalid_1's rmse: 0.0899484\n",
      "[1150]\ttraining's rmse: 0.0857317\tvalid_1's rmse: 0.0899438\n",
      "[1175]\ttraining's rmse: 0.085709\tvalid_1's rmse: 0.0899402\n",
      "[1200]\ttraining's rmse: 0.0856905\tvalid_1's rmse: 0.0899343\n",
      "[1225]\ttraining's rmse: 0.0856722\tvalid_1's rmse: 0.0899313\n",
      "[1250]\ttraining's rmse: 0.0856517\tvalid_1's rmse: 0.0899267\n",
      "[1275]\ttraining's rmse: 0.0856301\tvalid_1's rmse: 0.089923\n",
      "[1300]\ttraining's rmse: 0.0856132\tvalid_1's rmse: 0.089918\n",
      "[1325]\ttraining's rmse: 0.0855983\tvalid_1's rmse: 0.0899131\n",
      "[1350]\ttraining's rmse: 0.0855835\tvalid_1's rmse: 0.0899089\n",
      "[1375]\ttraining's rmse: 0.0855679\tvalid_1's rmse: 0.0899056\n",
      "[1400]\ttraining's rmse: 0.0855549\tvalid_1's rmse: 0.0899034\n",
      "[1425]\ttraining's rmse: 0.0855394\tvalid_1's rmse: 0.0899009\n",
      "[1450]\ttraining's rmse: 0.0855268\tvalid_1's rmse: 0.0898982\n",
      "[1475]\ttraining's rmse: 0.0855132\tvalid_1's rmse: 0.0898955\n",
      "[1500]\ttraining's rmse: 0.0855007\tvalid_1's rmse: 0.0898913\n",
      "[1525]\ttraining's rmse: 0.0854883\tvalid_1's rmse: 0.0898892\n",
      "[1550]\ttraining's rmse: 0.0854743\tvalid_1's rmse: 0.0898873\n",
      "[1575]\ttraining's rmse: 0.0854636\tvalid_1's rmse: 0.0898848\n",
      "[1600]\ttraining's rmse: 0.085455\tvalid_1's rmse: 0.0898824\n",
      "[1625]\ttraining's rmse: 0.0854451\tvalid_1's rmse: 0.0898799\n",
      "[1650]\ttraining's rmse: 0.0854358\tvalid_1's rmse: 0.0898778\n",
      "[1675]\ttraining's rmse: 0.0854291\tvalid_1's rmse: 0.0898745\n",
      "[1700]\ttraining's rmse: 0.0854216\tvalid_1's rmse: 0.0898724\n",
      "[1725]\ttraining's rmse: 0.0854151\tvalid_1's rmse: 0.0898704\n",
      "[1750]\ttraining's rmse: 0.0854057\tvalid_1's rmse: 0.0898679\n",
      "[1775]\ttraining's rmse: 0.0853984\tvalid_1's rmse: 0.0898661\n",
      "[1800]\ttraining's rmse: 0.085391\tvalid_1's rmse: 0.0898643\n",
      "[1825]\ttraining's rmse: 0.0853833\tvalid_1's rmse: 0.0898627\n",
      "[1850]\ttraining's rmse: 0.0853763\tvalid_1's rmse: 0.089861\n",
      "[1875]\ttraining's rmse: 0.0853698\tvalid_1's rmse: 0.08986\n",
      "[1900]\ttraining's rmse: 0.0853641\tvalid_1's rmse: 0.0898589\n",
      "[1925]\ttraining's rmse: 0.0853565\tvalid_1's rmse: 0.0898578\n",
      "[1950]\ttraining's rmse: 0.0853522\tvalid_1's rmse: 0.0898561\n",
      "[1975]\ttraining's rmse: 0.0853487\tvalid_1's rmse: 0.0898543\n",
      "[2000]\ttraining's rmse: 0.0853417\tvalid_1's rmse: 0.0898526\n",
      "[2025]\ttraining's rmse: 0.0853374\tvalid_1's rmse: 0.0898515\n",
      "[2050]\ttraining's rmse: 0.0853334\tvalid_1's rmse: 0.08985\n",
      "[2075]\ttraining's rmse: 0.0853303\tvalid_1's rmse: 0.089849\n",
      "[2100]\ttraining's rmse: 0.0853258\tvalid_1's rmse: 0.0898484\n",
      "[2125]\ttraining's rmse: 0.0853221\tvalid_1's rmse: 0.0898476\n",
      "[2150]\ttraining's rmse: 0.0853179\tvalid_1's rmse: 0.0898468\n",
      "[2175]\ttraining's rmse: 0.085314\tvalid_1's rmse: 0.0898449\n",
      "[2200]\ttraining's rmse: 0.0853084\tvalid_1's rmse: 0.0898438\n",
      "[2225]\ttraining's rmse: 0.0853044\tvalid_1's rmse: 0.0898429\n",
      "[2250]\ttraining's rmse: 0.0852999\tvalid_1's rmse: 0.0898411\n",
      "[2275]\ttraining's rmse: 0.0852952\tvalid_1's rmse: 0.0898404\n",
      "[2300]\ttraining's rmse: 0.0852899\tvalid_1's rmse: 0.089839\n",
      "[2325]\ttraining's rmse: 0.0852869\tvalid_1's rmse: 0.0898376\n",
      "[2350]\ttraining's rmse: 0.0852846\tvalid_1's rmse: 0.0898366\n",
      "[2375]\ttraining's rmse: 0.0852813\tvalid_1's rmse: 0.0898356\n",
      "[2400]\ttraining's rmse: 0.0852776\tvalid_1's rmse: 0.0898353\n",
      "[2425]\ttraining's rmse: 0.0852747\tvalid_1's rmse: 0.0898346\n",
      "[2450]\ttraining's rmse: 0.0852735\tvalid_1's rmse: 0.0898336\n",
      "[2475]\ttraining's rmse: 0.0852694\tvalid_1's rmse: 0.0898332\n",
      "[2500]\ttraining's rmse: 0.0852669\tvalid_1's rmse: 0.0898327\n",
      "[2525]\ttraining's rmse: 0.0852648\tvalid_1's rmse: 0.089832\n",
      "[2550]\ttraining's rmse: 0.0852617\tvalid_1's rmse: 0.0898316\n",
      "[2575]\ttraining's rmse: 0.0852585\tvalid_1's rmse: 0.0898312\n",
      "[2600]\ttraining's rmse: 0.0852565\tvalid_1's rmse: 0.0898313\n",
      "[2625]\ttraining's rmse: 0.0852546\tvalid_1's rmse: 0.0898304\n",
      "[2650]\ttraining's rmse: 0.085252\tvalid_1's rmse: 0.0898296\n",
      "[2675]\ttraining's rmse: 0.085249\tvalid_1's rmse: 0.0898288\n",
      "[2700]\ttraining's rmse: 0.0852457\tvalid_1's rmse: 0.0898279\n",
      "[2725]\ttraining's rmse: 0.0852439\tvalid_1's rmse: 0.0898274\n",
      "[2750]\ttraining's rmse: 0.0852421\tvalid_1's rmse: 0.0898264\n",
      "[2775]\ttraining's rmse: 0.0852405\tvalid_1's rmse: 0.0898265\n",
      "[2800]\ttraining's rmse: 0.0852394\tvalid_1's rmse: 0.0898268\n",
      "Early stopping, best iteration is:\n",
      "[2768]\ttraining's rmse: 0.0852415\tvalid_1's rmse: 0.0898263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0892647\tvalid_1's rmse: 0.0904922\n",
      "[50]\ttraining's rmse: 0.0890908\tvalid_1's rmse: 0.0904351\n",
      "[75]\ttraining's rmse: 0.0889147\tvalid_1's rmse: 0.0903785\n",
      "[100]\ttraining's rmse: 0.088757\tvalid_1's rmse: 0.0903267\n",
      "[125]\ttraining's rmse: 0.0885984\tvalid_1's rmse: 0.0902742\n",
      "[150]\ttraining's rmse: 0.0884535\tvalid_1's rmse: 0.0902259\n",
      "[175]\ttraining's rmse: 0.0883304\tvalid_1's rmse: 0.090187\n",
      "[200]\ttraining's rmse: 0.0881983\tvalid_1's rmse: 0.0901464\n",
      "[225]\ttraining's rmse: 0.0880738\tvalid_1's rmse: 0.0901102\n",
      "[250]\ttraining's rmse: 0.0879671\tvalid_1's rmse: 0.0900749\n",
      "[275]\ttraining's rmse: 0.0878655\tvalid_1's rmse: 0.0900437\n",
      "[300]\ttraining's rmse: 0.0877689\tvalid_1's rmse: 0.0900158\n",
      "[325]\ttraining's rmse: 0.08767\tvalid_1's rmse: 0.0899872\n",
      "[350]\ttraining's rmse: 0.0875753\tvalid_1's rmse: 0.0899602\n",
      "[375]\ttraining's rmse: 0.0874993\tvalid_1's rmse: 0.0899373\n",
      "[400]\ttraining's rmse: 0.0874189\tvalid_1's rmse: 0.0899146\n",
      "[425]\ttraining's rmse: 0.0873457\tvalid_1's rmse: 0.0898939\n",
      "[450]\ttraining's rmse: 0.0872792\tvalid_1's rmse: 0.0898758\n",
      "[475]\ttraining's rmse: 0.0872179\tvalid_1's rmse: 0.0898578\n",
      "[500]\ttraining's rmse: 0.0871658\tvalid_1's rmse: 0.0898405\n",
      "[525]\ttraining's rmse: 0.0871008\tvalid_1's rmse: 0.0898222\n",
      "[550]\ttraining's rmse: 0.0870383\tvalid_1's rmse: 0.0898075\n",
      "[575]\ttraining's rmse: 0.0869822\tvalid_1's rmse: 0.0897929\n",
      "[600]\ttraining's rmse: 0.0869276\tvalid_1's rmse: 0.0897795\n",
      "[625]\ttraining's rmse: 0.0868819\tvalid_1's rmse: 0.0897659\n",
      "[650]\ttraining's rmse: 0.086831\tvalid_1's rmse: 0.089753\n",
      "[675]\ttraining's rmse: 0.0867841\tvalid_1's rmse: 0.0897414\n",
      "[700]\ttraining's rmse: 0.0867414\tvalid_1's rmse: 0.0897302\n",
      "[725]\ttraining's rmse: 0.0867012\tvalid_1's rmse: 0.0897203\n",
      "[750]\ttraining's rmse: 0.0866633\tvalid_1's rmse: 0.089711\n",
      "[775]\ttraining's rmse: 0.0866291\tvalid_1's rmse: 0.0897017\n",
      "[800]\ttraining's rmse: 0.0865879\tvalid_1's rmse: 0.0896921\n",
      "[825]\ttraining's rmse: 0.0865546\tvalid_1's rmse: 0.0896832\n",
      "[850]\ttraining's rmse: 0.0865191\tvalid_1's rmse: 0.0896758\n",
      "[875]\ttraining's rmse: 0.0864877\tvalid_1's rmse: 0.0896687\n",
      "[900]\ttraining's rmse: 0.0864537\tvalid_1's rmse: 0.0896608\n",
      "[925]\ttraining's rmse: 0.0864237\tvalid_1's rmse: 0.0896546\n",
      "[950]\ttraining's rmse: 0.0863938\tvalid_1's rmse: 0.0896478\n",
      "[975]\ttraining's rmse: 0.0863662\tvalid_1's rmse: 0.0896426\n",
      "[1000]\ttraining's rmse: 0.0863414\tvalid_1's rmse: 0.0896381\n",
      "[1025]\ttraining's rmse: 0.0863142\tvalid_1's rmse: 0.0896333\n",
      "[1050]\ttraining's rmse: 0.0862903\tvalid_1's rmse: 0.089628\n",
      "[1075]\ttraining's rmse: 0.0862648\tvalid_1's rmse: 0.0896233\n",
      "[1100]\ttraining's rmse: 0.0862422\tvalid_1's rmse: 0.0896188\n",
      "[1125]\ttraining's rmse: 0.0862216\tvalid_1's rmse: 0.0896145\n",
      "[1150]\ttraining's rmse: 0.0861992\tvalid_1's rmse: 0.089611\n",
      "[1175]\ttraining's rmse: 0.0861787\tvalid_1's rmse: 0.0896077\n",
      "[1200]\ttraining's rmse: 0.0861598\tvalid_1's rmse: 0.0896039\n",
      "[1225]\ttraining's rmse: 0.0861427\tvalid_1's rmse: 0.0896014\n",
      "[1250]\ttraining's rmse: 0.0861258\tvalid_1's rmse: 0.0895978\n",
      "[1275]\ttraining's rmse: 0.086105\tvalid_1's rmse: 0.0895952\n",
      "[1300]\ttraining's rmse: 0.0860894\tvalid_1's rmse: 0.0895919\n",
      "[1325]\ttraining's rmse: 0.086072\tvalid_1's rmse: 0.0895892\n",
      "[1350]\ttraining's rmse: 0.0860524\tvalid_1's rmse: 0.0895877\n",
      "[1375]\ttraining's rmse: 0.0860355\tvalid_1's rmse: 0.089586\n",
      "[1400]\ttraining's rmse: 0.086021\tvalid_1's rmse: 0.0895837\n",
      "[1425]\ttraining's rmse: 0.0860054\tvalid_1's rmse: 0.0895827\n",
      "[1450]\ttraining's rmse: 0.0859906\tvalid_1's rmse: 0.0895815\n",
      "[1475]\ttraining's rmse: 0.0859792\tvalid_1's rmse: 0.0895798\n",
      "[1500]\ttraining's rmse: 0.085968\tvalid_1's rmse: 0.0895784\n",
      "[1525]\ttraining's rmse: 0.0859546\tvalid_1's rmse: 0.0895765\n",
      "[1550]\ttraining's rmse: 0.0859434\tvalid_1's rmse: 0.0895761\n",
      "[1575]\ttraining's rmse: 0.0859328\tvalid_1's rmse: 0.0895746\n",
      "[1600]\ttraining's rmse: 0.0859225\tvalid_1's rmse: 0.0895733\n",
      "[1625]\ttraining's rmse: 0.085912\tvalid_1's rmse: 0.0895722\n",
      "[1650]\ttraining's rmse: 0.0859035\tvalid_1's rmse: 0.0895701\n",
      "[1675]\ttraining's rmse: 0.085896\tvalid_1's rmse: 0.0895691\n",
      "[1700]\ttraining's rmse: 0.0858872\tvalid_1's rmse: 0.0895677\n",
      "[1725]\ttraining's rmse: 0.0858769\tvalid_1's rmse: 0.089566\n",
      "[1750]\ttraining's rmse: 0.0858674\tvalid_1's rmse: 0.0895657\n",
      "[1775]\ttraining's rmse: 0.0858601\tvalid_1's rmse: 0.0895653\n",
      "[1800]\ttraining's rmse: 0.0858519\tvalid_1's rmse: 0.0895643\n",
      "[1825]\ttraining's rmse: 0.0858447\tvalid_1's rmse: 0.0895637\n",
      "[1850]\ttraining's rmse: 0.0858373\tvalid_1's rmse: 0.0895634\n",
      "[1875]\ttraining's rmse: 0.0858317\tvalid_1's rmse: 0.0895627\n",
      "[1900]\ttraining's rmse: 0.0858268\tvalid_1's rmse: 0.0895625\n",
      "[1925]\ttraining's rmse: 0.085823\tvalid_1's rmse: 0.0895625\n",
      "[1950]\ttraining's rmse: 0.0858191\tvalid_1's rmse: 0.0895617\n",
      "[1975]\ttraining's rmse: 0.085814\tvalid_1's rmse: 0.0895609\n",
      "[2000]\ttraining's rmse: 0.0858085\tvalid_1's rmse: 0.0895595\n",
      "[2025]\ttraining's rmse: 0.0858041\tvalid_1's rmse: 0.0895588\n",
      "[2050]\ttraining's rmse: 0.0857993\tvalid_1's rmse: 0.0895583\n",
      "[2075]\ttraining's rmse: 0.0857956\tvalid_1's rmse: 0.0895583\n",
      "[2100]\ttraining's rmse: 0.085791\tvalid_1's rmse: 0.0895582\n",
      "[2125]\ttraining's rmse: 0.0857878\tvalid_1's rmse: 0.0895577\n",
      "[2150]\ttraining's rmse: 0.0857831\tvalid_1's rmse: 0.0895577\n",
      "[2175]\ttraining's rmse: 0.0857795\tvalid_1's rmse: 0.0895575\n",
      "[2200]\ttraining's rmse: 0.0857768\tvalid_1's rmse: 0.0895568\n",
      "[2225]\ttraining's rmse: 0.0857741\tvalid_1's rmse: 0.0895567\n",
      "[2250]\ttraining's rmse: 0.0857707\tvalid_1's rmse: 0.0895565\n",
      "[2275]\ttraining's rmse: 0.0857665\tvalid_1's rmse: 0.0895558\n",
      "[2300]\ttraining's rmse: 0.0857644\tvalid_1's rmse: 0.0895556\n",
      "[2325]\ttraining's rmse: 0.0857604\tvalid_1's rmse: 0.0895553\n",
      "[2350]\ttraining's rmse: 0.0857581\tvalid_1's rmse: 0.0895555\n",
      "[2375]\ttraining's rmse: 0.0857546\tvalid_1's rmse: 0.0895547\n",
      "[2400]\ttraining's rmse: 0.0857516\tvalid_1's rmse: 0.0895544\n",
      "[2425]\ttraining's rmse: 0.0857489\tvalid_1's rmse: 0.0895544\n",
      "[2450]\ttraining's rmse: 0.0857471\tvalid_1's rmse: 0.0895546\n",
      "Early stopping, best iteration is:\n",
      "[2415]\ttraining's rmse: 0.0857501\tvalid_1's rmse: 0.0895542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.090486\tvalid_1's rmse: 0.0880756\n",
      "[50]\ttraining's rmse: 0.0903525\tvalid_1's rmse: 0.0880252\n",
      "[75]\ttraining's rmse: 0.0902087\tvalid_1's rmse: 0.0879745\n",
      "[100]\ttraining's rmse: 0.0900762\tvalid_1's rmse: 0.0879303\n",
      "[125]\ttraining's rmse: 0.0899421\tvalid_1's rmse: 0.0878854\n",
      "[150]\ttraining's rmse: 0.0898212\tvalid_1's rmse: 0.0878455\n",
      "[175]\ttraining's rmse: 0.0897187\tvalid_1's rmse: 0.0878136\n",
      "[200]\ttraining's rmse: 0.0896045\tvalid_1's rmse: 0.087781\n",
      "[225]\ttraining's rmse: 0.0894962\tvalid_1's rmse: 0.0877493\n",
      "[250]\ttraining's rmse: 0.0894014\tvalid_1's rmse: 0.0877215\n",
      "[275]\ttraining's rmse: 0.0893174\tvalid_1's rmse: 0.0876962\n",
      "[300]\ttraining's rmse: 0.0892318\tvalid_1's rmse: 0.0876734\n",
      "[325]\ttraining's rmse: 0.0891444\tvalid_1's rmse: 0.087652\n",
      "[350]\ttraining's rmse: 0.0890619\tvalid_1's rmse: 0.0876311\n",
      "[375]\ttraining's rmse: 0.0889948\tvalid_1's rmse: 0.0876143\n",
      "[400]\ttraining's rmse: 0.0889186\tvalid_1's rmse: 0.0875972\n",
      "[425]\ttraining's rmse: 0.088849\tvalid_1's rmse: 0.0875805\n",
      "[450]\ttraining's rmse: 0.0887863\tvalid_1's rmse: 0.0875654\n",
      "[475]\ttraining's rmse: 0.0887293\tvalid_1's rmse: 0.0875538\n",
      "[500]\ttraining's rmse: 0.0886793\tvalid_1's rmse: 0.0875411\n",
      "[525]\ttraining's rmse: 0.088614\tvalid_1's rmse: 0.0875273\n",
      "[550]\ttraining's rmse: 0.0885566\tvalid_1's rmse: 0.0875168\n",
      "[575]\ttraining's rmse: 0.0885023\tvalid_1's rmse: 0.0875138\n",
      "[600]\ttraining's rmse: 0.0884497\tvalid_1's rmse: 0.0875061\n",
      "[625]\ttraining's rmse: 0.0884079\tvalid_1's rmse: 0.0874969\n",
      "[650]\ttraining's rmse: 0.0883542\tvalid_1's rmse: 0.0874885\n",
      "[675]\ttraining's rmse: 0.0883013\tvalid_1's rmse: 0.0874895\n",
      "[700]\ttraining's rmse: 0.0882553\tvalid_1's rmse: 0.0874857\n",
      "[725]\ttraining's rmse: 0.088213\tvalid_1's rmse: 0.0874814\n",
      "[750]\ttraining's rmse: 0.0881731\tvalid_1's rmse: 0.0874807\n",
      "[775]\ttraining's rmse: 0.0881407\tvalid_1's rmse: 0.0874761\n",
      "[800]\ttraining's rmse: 0.0880979\tvalid_1's rmse: 0.0874763\n",
      "[825]\ttraining's rmse: 0.0880591\tvalid_1's rmse: 0.0874815\n",
      "Early stopping, best iteration is:\n",
      "[797]\ttraining's rmse: 0.0881028\tvalid_1's rmse: 0.0874723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0842897\tvalid_1's rmse: 0.086937\n",
      "[50]\ttraining's rmse: 0.0841563\tvalid_1's rmse: 0.0868785\n",
      "[75]\ttraining's rmse: 0.0840168\tvalid_1's rmse: 0.0868191\n",
      "[100]\ttraining's rmse: 0.0838958\tvalid_1's rmse: 0.0867713\n",
      "[125]\ttraining's rmse: 0.0837751\tvalid_1's rmse: 0.0867212\n",
      "[150]\ttraining's rmse: 0.0836616\tvalid_1's rmse: 0.0866737\n",
      "[175]\ttraining's rmse: 0.083568\tvalid_1's rmse: 0.0866343\n",
      "[200]\ttraining's rmse: 0.0834683\tvalid_1's rmse: 0.0865921\n",
      "[225]\ttraining's rmse: 0.0833675\tvalid_1's rmse: 0.0865537\n",
      "[250]\ttraining's rmse: 0.0832881\tvalid_1's rmse: 0.0865213\n",
      "[275]\ttraining's rmse: 0.0832089\tvalid_1's rmse: 0.0864887\n",
      "[300]\ttraining's rmse: 0.0831314\tvalid_1's rmse: 0.0864605\n",
      "[325]\ttraining's rmse: 0.0830546\tvalid_1's rmse: 0.0864316\n",
      "[350]\ttraining's rmse: 0.0829808\tvalid_1's rmse: 0.0864053\n",
      "[375]\ttraining's rmse: 0.0829193\tvalid_1's rmse: 0.0863819\n",
      "[400]\ttraining's rmse: 0.0828532\tvalid_1's rmse: 0.0863602\n",
      "[425]\ttraining's rmse: 0.0827964\tvalid_1's rmse: 0.0863376\n",
      "[450]\ttraining's rmse: 0.0827432\tvalid_1's rmse: 0.086317\n",
      "[475]\ttraining's rmse: 0.0826914\tvalid_1's rmse: 0.0862946\n",
      "[500]\ttraining's rmse: 0.0826461\tvalid_1's rmse: 0.0862755\n",
      "[525]\ttraining's rmse: 0.0825943\tvalid_1's rmse: 0.0862582\n",
      "[550]\ttraining's rmse: 0.0825441\tvalid_1's rmse: 0.0862428\n",
      "[575]\ttraining's rmse: 0.0824987\tvalid_1's rmse: 0.086227\n",
      "[600]\ttraining's rmse: 0.0824566\tvalid_1's rmse: 0.0862147\n",
      "[625]\ttraining's rmse: 0.0824198\tvalid_1's rmse: 0.0862026\n",
      "[650]\ttraining's rmse: 0.0823762\tvalid_1's rmse: 0.0861882\n",
      "[675]\ttraining's rmse: 0.0823334\tvalid_1's rmse: 0.0861744\n",
      "[700]\ttraining's rmse: 0.0822967\tvalid_1's rmse: 0.0861621\n",
      "[725]\ttraining's rmse: 0.0822581\tvalid_1's rmse: 0.0861506\n",
      "[750]\ttraining's rmse: 0.0822242\tvalid_1's rmse: 0.0861399\n",
      "[775]\ttraining's rmse: 0.0821971\tvalid_1's rmse: 0.0861273\n",
      "[800]\ttraining's rmse: 0.082163\tvalid_1's rmse: 0.0861195\n",
      "[825]\ttraining's rmse: 0.0821329\tvalid_1's rmse: 0.0861092\n",
      "[850]\ttraining's rmse: 0.0821015\tvalid_1's rmse: 0.0861008\n",
      "[875]\ttraining's rmse: 0.0820739\tvalid_1's rmse: 0.086092\n",
      "[900]\ttraining's rmse: 0.0820438\tvalid_1's rmse: 0.0860846\n",
      "[925]\ttraining's rmse: 0.0820187\tvalid_1's rmse: 0.0860778\n",
      "[950]\ttraining's rmse: 0.0819933\tvalid_1's rmse: 0.08607\n",
      "[975]\ttraining's rmse: 0.0819699\tvalid_1's rmse: 0.0860635\n",
      "[1000]\ttraining's rmse: 0.0819471\tvalid_1's rmse: 0.0860565\n",
      "[1025]\ttraining's rmse: 0.0819216\tvalid_1's rmse: 0.0860503\n",
      "[1050]\ttraining's rmse: 0.0819013\tvalid_1's rmse: 0.0860449\n",
      "[1075]\ttraining's rmse: 0.0818813\tvalid_1's rmse: 0.0860405\n",
      "[1100]\ttraining's rmse: 0.081864\tvalid_1's rmse: 0.0860351\n",
      "[1125]\ttraining's rmse: 0.0818486\tvalid_1's rmse: 0.0860291\n",
      "[1150]\ttraining's rmse: 0.0818279\tvalid_1's rmse: 0.0860232\n",
      "[1175]\ttraining's rmse: 0.0818109\tvalid_1's rmse: 0.0860192\n",
      "[1200]\ttraining's rmse: 0.0817936\tvalid_1's rmse: 0.0860145\n",
      "[1225]\ttraining's rmse: 0.0817756\tvalid_1's rmse: 0.0860108\n",
      "[1250]\ttraining's rmse: 0.08176\tvalid_1's rmse: 0.0860061\n",
      "[1275]\ttraining's rmse: 0.0817426\tvalid_1's rmse: 0.086003\n",
      "[1300]\ttraining's rmse: 0.08173\tvalid_1's rmse: 0.085998\n",
      "[1325]\ttraining's rmse: 0.0817161\tvalid_1's rmse: 0.0859953\n",
      "[1350]\ttraining's rmse: 0.0817033\tvalid_1's rmse: 0.0859914\n",
      "[1375]\ttraining's rmse: 0.0816901\tvalid_1's rmse: 0.0859884\n",
      "[1400]\ttraining's rmse: 0.0816788\tvalid_1's rmse: 0.0859846\n",
      "[1425]\ttraining's rmse: 0.0816664\tvalid_1's rmse: 0.0859828\n",
      "[1450]\ttraining's rmse: 0.0816523\tvalid_1's rmse: 0.0859802\n",
      "[1475]\ttraining's rmse: 0.081644\tvalid_1's rmse: 0.0859783\n",
      "[1500]\ttraining's rmse: 0.081637\tvalid_1's rmse: 0.0859753\n",
      "[1525]\ttraining's rmse: 0.0816277\tvalid_1's rmse: 0.0859722\n",
      "[1550]\ttraining's rmse: 0.0816182\tvalid_1's rmse: 0.0859705\n",
      "[1575]\ttraining's rmse: 0.081608\tvalid_1's rmse: 0.0859678\n",
      "[1600]\ttraining's rmse: 0.0816018\tvalid_1's rmse: 0.085966\n",
      "[1625]\ttraining's rmse: 0.081593\tvalid_1's rmse: 0.0859633\n",
      "[1650]\ttraining's rmse: 0.0815858\tvalid_1's rmse: 0.085961\n",
      "[1675]\ttraining's rmse: 0.0815798\tvalid_1's rmse: 0.0859589\n",
      "[1700]\ttraining's rmse: 0.0815737\tvalid_1's rmse: 0.0859572\n",
      "[1725]\ttraining's rmse: 0.0815667\tvalid_1's rmse: 0.0859559\n",
      "[1750]\ttraining's rmse: 0.0815591\tvalid_1's rmse: 0.0859532\n",
      "[1775]\ttraining's rmse: 0.0815517\tvalid_1's rmse: 0.0859521\n",
      "[1800]\ttraining's rmse: 0.0815462\tvalid_1's rmse: 0.0859512\n",
      "[1825]\ttraining's rmse: 0.08154\tvalid_1's rmse: 0.0859489\n",
      "[1850]\ttraining's rmse: 0.0815353\tvalid_1's rmse: 0.0859472\n",
      "[1875]\ttraining's rmse: 0.0815304\tvalid_1's rmse: 0.085946\n",
      "[1900]\ttraining's rmse: 0.0815259\tvalid_1's rmse: 0.0859446\n",
      "[1925]\ttraining's rmse: 0.0815225\tvalid_1's rmse: 0.0859432\n",
      "[1950]\ttraining's rmse: 0.08152\tvalid_1's rmse: 0.085941\n",
      "[1975]\ttraining's rmse: 0.0815144\tvalid_1's rmse: 0.0859394\n",
      "[2000]\ttraining's rmse: 0.0815096\tvalid_1's rmse: 0.0859383\n",
      "[2025]\ttraining's rmse: 0.0815055\tvalid_1's rmse: 0.0859366\n",
      "[2050]\ttraining's rmse: 0.0815018\tvalid_1's rmse: 0.0859357\n",
      "[2075]\ttraining's rmse: 0.0814988\tvalid_1's rmse: 0.0859347\n",
      "[2100]\ttraining's rmse: 0.0814942\tvalid_1's rmse: 0.0859341\n",
      "[2125]\ttraining's rmse: 0.081492\tvalid_1's rmse: 0.0859334\n",
      "[2150]\ttraining's rmse: 0.0814877\tvalid_1's rmse: 0.0859325\n",
      "[2175]\ttraining's rmse: 0.0814851\tvalid_1's rmse: 0.0859322\n",
      "[2200]\ttraining's rmse: 0.0814817\tvalid_1's rmse: 0.0859318\n",
      "[2225]\ttraining's rmse: 0.0814785\tvalid_1's rmse: 0.0859307\n",
      "[2250]\ttraining's rmse: 0.0814751\tvalid_1's rmse: 0.0859294\n",
      "[2275]\ttraining's rmse: 0.081472\tvalid_1's rmse: 0.0859279\n",
      "[2300]\ttraining's rmse: 0.0814696\tvalid_1's rmse: 0.0859275\n",
      "[2325]\ttraining's rmse: 0.0814662\tvalid_1's rmse: 0.0859265\n",
      "[2350]\ttraining's rmse: 0.0814632\tvalid_1's rmse: 0.085925\n",
      "[2375]\ttraining's rmse: 0.0814608\tvalid_1's rmse: 0.0859243\n",
      "[2400]\ttraining's rmse: 0.0814585\tvalid_1's rmse: 0.0859239\n",
      "[2425]\ttraining's rmse: 0.0814562\tvalid_1's rmse: 0.0859237\n",
      "[2450]\ttraining's rmse: 0.0814543\tvalid_1's rmse: 0.0859224\n",
      "[2475]\ttraining's rmse: 0.0814519\tvalid_1's rmse: 0.0859222\n",
      "[2500]\ttraining's rmse: 0.0814492\tvalid_1's rmse: 0.0859218\n",
      "[2525]\ttraining's rmse: 0.0814475\tvalid_1's rmse: 0.0859215\n",
      "[2550]\ttraining's rmse: 0.0814443\tvalid_1's rmse: 0.0859207\n",
      "[2575]\ttraining's rmse: 0.0814424\tvalid_1's rmse: 0.0859201\n",
      "[2600]\ttraining's rmse: 0.0814402\tvalid_1's rmse: 0.08592\n",
      "[2625]\ttraining's rmse: 0.0814388\tvalid_1's rmse: 0.0859194\n",
      "[2650]\ttraining's rmse: 0.0814377\tvalid_1's rmse: 0.0859196\n",
      "[2675]\ttraining's rmse: 0.0814361\tvalid_1's rmse: 0.0859191\n",
      "[2700]\ttraining's rmse: 0.0814335\tvalid_1's rmse: 0.0859187\n",
      "[2725]\ttraining's rmse: 0.0814311\tvalid_1's rmse: 0.085918\n",
      "[2750]\ttraining's rmse: 0.0814292\tvalid_1's rmse: 0.0859171\n",
      "[2775]\ttraining's rmse: 0.0814272\tvalid_1's rmse: 0.0859174\n",
      "Early stopping, best iteration is:\n",
      "[2748]\ttraining's rmse: 0.0814292\tvalid_1's rmse: 0.0859171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0845457\tvalid_1's rmse: 0.0864443\n",
      "[50]\ttraining's rmse: 0.0844184\tvalid_1's rmse: 0.0863845\n",
      "[75]\ttraining's rmse: 0.0842899\tvalid_1's rmse: 0.0863267\n",
      "[100]\ttraining's rmse: 0.084178\tvalid_1's rmse: 0.0862755\n",
      "[125]\ttraining's rmse: 0.0840593\tvalid_1's rmse: 0.0862252\n",
      "[150]\ttraining's rmse: 0.0839489\tvalid_1's rmse: 0.0861766\n",
      "[175]\ttraining's rmse: 0.083859\tvalid_1's rmse: 0.0861381\n",
      "[200]\ttraining's rmse: 0.0837621\tvalid_1's rmse: 0.0860988\n",
      "[225]\ttraining's rmse: 0.0836689\tvalid_1's rmse: 0.0860624\n",
      "[250]\ttraining's rmse: 0.0835897\tvalid_1's rmse: 0.0860293\n",
      "[275]\ttraining's rmse: 0.0835135\tvalid_1's rmse: 0.0859983\n",
      "[300]\ttraining's rmse: 0.0834364\tvalid_1's rmse: 0.0859692\n",
      "[325]\ttraining's rmse: 0.0833626\tvalid_1's rmse: 0.0859407\n",
      "[350]\ttraining's rmse: 0.0832868\tvalid_1's rmse: 0.085915\n",
      "[375]\ttraining's rmse: 0.0832262\tvalid_1's rmse: 0.085893\n",
      "[400]\ttraining's rmse: 0.0831616\tvalid_1's rmse: 0.0858715\n",
      "[425]\ttraining's rmse: 0.0831044\tvalid_1's rmse: 0.0858511\n",
      "[450]\ttraining's rmse: 0.0830474\tvalid_1's rmse: 0.08583\n",
      "[475]\ttraining's rmse: 0.0829962\tvalid_1's rmse: 0.0858117\n",
      "[500]\ttraining's rmse: 0.0829508\tvalid_1's rmse: 0.085795\n",
      "[525]\ttraining's rmse: 0.0828919\tvalid_1's rmse: 0.0857776\n",
      "[550]\ttraining's rmse: 0.0828386\tvalid_1's rmse: 0.0857619\n",
      "[575]\ttraining's rmse: 0.0827919\tvalid_1's rmse: 0.0857484\n",
      "[600]\ttraining's rmse: 0.0827456\tvalid_1's rmse: 0.0857349\n",
      "[625]\ttraining's rmse: 0.0827115\tvalid_1's rmse: 0.0857235\n",
      "[650]\ttraining's rmse: 0.0826675\tvalid_1's rmse: 0.0857106\n",
      "[675]\ttraining's rmse: 0.0826215\tvalid_1's rmse: 0.0856995\n",
      "[700]\ttraining's rmse: 0.0825827\tvalid_1's rmse: 0.0856887\n",
      "[725]\ttraining's rmse: 0.0825464\tvalid_1's rmse: 0.0856784\n",
      "[750]\ttraining's rmse: 0.0825113\tvalid_1's rmse: 0.0856691\n",
      "[775]\ttraining's rmse: 0.0824824\tvalid_1's rmse: 0.0856604\n",
      "[800]\ttraining's rmse: 0.0824427\tvalid_1's rmse: 0.0856516\n",
      "[825]\ttraining's rmse: 0.0824105\tvalid_1's rmse: 0.0856429\n",
      "[850]\ttraining's rmse: 0.08238\tvalid_1's rmse: 0.0856357\n",
      "[875]\ttraining's rmse: 0.0823524\tvalid_1's rmse: 0.0856292\n",
      "[900]\ttraining's rmse: 0.0823238\tvalid_1's rmse: 0.0856223\n",
      "[925]\ttraining's rmse: 0.0822974\tvalid_1's rmse: 0.0856164\n",
      "[950]\ttraining's rmse: 0.082272\tvalid_1's rmse: 0.0856106\n",
      "[975]\ttraining's rmse: 0.0822478\tvalid_1's rmse: 0.0856056\n",
      "[1000]\ttraining's rmse: 0.0822241\tvalid_1's rmse: 0.0855998\n",
      "[1025]\ttraining's rmse: 0.0821973\tvalid_1's rmse: 0.0855945\n",
      "[1050]\ttraining's rmse: 0.082177\tvalid_1's rmse: 0.0855891\n",
      "[1075]\ttraining's rmse: 0.082156\tvalid_1's rmse: 0.0855853\n",
      "[1100]\ttraining's rmse: 0.0821381\tvalid_1's rmse: 0.0855813\n",
      "[1125]\ttraining's rmse: 0.0821171\tvalid_1's rmse: 0.0855776\n",
      "[1150]\ttraining's rmse: 0.0820975\tvalid_1's rmse: 0.0855742\n",
      "[1175]\ttraining's rmse: 0.0820821\tvalid_1's rmse: 0.0855711\n",
      "[1200]\ttraining's rmse: 0.0820671\tvalid_1's rmse: 0.0855681\n",
      "[1225]\ttraining's rmse: 0.0820517\tvalid_1's rmse: 0.0855658\n",
      "[1250]\ttraining's rmse: 0.0820366\tvalid_1's rmse: 0.0855635\n",
      "[1275]\ttraining's rmse: 0.082018\tvalid_1's rmse: 0.0855613\n",
      "[1300]\ttraining's rmse: 0.0820052\tvalid_1's rmse: 0.0855591\n",
      "[1325]\ttraining's rmse: 0.0819911\tvalid_1's rmse: 0.0855566\n",
      "[1350]\ttraining's rmse: 0.0819775\tvalid_1's rmse: 0.0855547\n",
      "[1375]\ttraining's rmse: 0.0819635\tvalid_1's rmse: 0.0855535\n",
      "[1400]\ttraining's rmse: 0.0819535\tvalid_1's rmse: 0.0855509\n",
      "[1425]\ttraining's rmse: 0.0819405\tvalid_1's rmse: 0.0855497\n",
      "[1450]\ttraining's rmse: 0.0819299\tvalid_1's rmse: 0.0855484\n",
      "[1475]\ttraining's rmse: 0.0819188\tvalid_1's rmse: 0.0855467\n",
      "[1500]\ttraining's rmse: 0.0819088\tvalid_1's rmse: 0.0855448\n",
      "[1525]\ttraining's rmse: 0.0818969\tvalid_1's rmse: 0.0855432\n",
      "[1550]\ttraining's rmse: 0.0818859\tvalid_1's rmse: 0.0855416\n",
      "[1575]\ttraining's rmse: 0.0818773\tvalid_1's rmse: 0.0855401\n",
      "[1600]\ttraining's rmse: 0.0818689\tvalid_1's rmse: 0.0855396\n",
      "[1625]\ttraining's rmse: 0.081859\tvalid_1's rmse: 0.0855384\n",
      "[1650]\ttraining's rmse: 0.08185\tvalid_1's rmse: 0.0855373\n",
      "[1675]\ttraining's rmse: 0.081844\tvalid_1's rmse: 0.0855362\n",
      "[1700]\ttraining's rmse: 0.0818391\tvalid_1's rmse: 0.0855353\n",
      "[1725]\ttraining's rmse: 0.0818321\tvalid_1's rmse: 0.0855344\n",
      "[1750]\ttraining's rmse: 0.0818238\tvalid_1's rmse: 0.0855331\n",
      "[1775]\ttraining's rmse: 0.0818185\tvalid_1's rmse: 0.0855327\n",
      "[1800]\ttraining's rmse: 0.0818111\tvalid_1's rmse: 0.0855325\n",
      "[1825]\ttraining's rmse: 0.081804\tvalid_1's rmse: 0.0855316\n",
      "[1850]\ttraining's rmse: 0.0817995\tvalid_1's rmse: 0.0855311\n",
      "[1875]\ttraining's rmse: 0.081793\tvalid_1's rmse: 0.08553\n",
      "[1900]\ttraining's rmse: 0.0817887\tvalid_1's rmse: 0.0855297\n",
      "[1925]\ttraining's rmse: 0.0817836\tvalid_1's rmse: 0.0855291\n",
      "[1950]\ttraining's rmse: 0.0817796\tvalid_1's rmse: 0.0855281\n",
      "[1975]\ttraining's rmse: 0.0817745\tvalid_1's rmse: 0.0855273\n",
      "[2000]\ttraining's rmse: 0.0817701\tvalid_1's rmse: 0.0855266\n",
      "[2025]\ttraining's rmse: 0.0817668\tvalid_1's rmse: 0.0855264\n",
      "[2050]\ttraining's rmse: 0.0817622\tvalid_1's rmse: 0.0855257\n",
      "[2075]\ttraining's rmse: 0.0817588\tvalid_1's rmse: 0.0855253\n",
      "[2100]\ttraining's rmse: 0.0817546\tvalid_1's rmse: 0.085525\n",
      "[2125]\ttraining's rmse: 0.0817513\tvalid_1's rmse: 0.085525\n",
      "Early stopping, best iteration is:\n",
      "[2096]\ttraining's rmse: 0.0817552\tvalid_1's rmse: 0.0855249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.086563\tvalid_1's rmse: 0.0823398\n",
      "[50]\ttraining's rmse: 0.0864416\tvalid_1's rmse: 0.0822892\n",
      "[75]\ttraining's rmse: 0.0863188\tvalid_1's rmse: 0.0822401\n",
      "[100]\ttraining's rmse: 0.0862093\tvalid_1's rmse: 0.0821954\n",
      "[125]\ttraining's rmse: 0.0860936\tvalid_1's rmse: 0.0821534\n",
      "[150]\ttraining's rmse: 0.0859872\tvalid_1's rmse: 0.0821146\n",
      "[175]\ttraining's rmse: 0.0858996\tvalid_1's rmse: 0.0820829\n",
      "[200]\ttraining's rmse: 0.0858039\tvalid_1's rmse: 0.0820498\n",
      "[225]\ttraining's rmse: 0.0857141\tvalid_1's rmse: 0.082018\n",
      "[250]\ttraining's rmse: 0.0856369\tvalid_1's rmse: 0.0819907\n",
      "[275]\ttraining's rmse: 0.0855656\tvalid_1's rmse: 0.0819646\n",
      "[300]\ttraining's rmse: 0.0854944\tvalid_1's rmse: 0.0819397\n",
      "[325]\ttraining's rmse: 0.0854235\tvalid_1's rmse: 0.0819162\n",
      "[350]\ttraining's rmse: 0.085352\tvalid_1's rmse: 0.0818946\n",
      "[375]\ttraining's rmse: 0.0852952\tvalid_1's rmse: 0.0818746\n",
      "[400]\ttraining's rmse: 0.0852318\tvalid_1's rmse: 0.0818552\n",
      "[425]\ttraining's rmse: 0.0851763\tvalid_1's rmse: 0.0818384\n",
      "[450]\ttraining's rmse: 0.0851241\tvalid_1's rmse: 0.0818263\n",
      "[475]\ttraining's rmse: 0.0850757\tvalid_1's rmse: 0.0818105\n",
      "[500]\ttraining's rmse: 0.0850323\tvalid_1's rmse: 0.0817959\n",
      "[525]\ttraining's rmse: 0.0849771\tvalid_1's rmse: 0.0817805\n",
      "[550]\ttraining's rmse: 0.0849266\tvalid_1's rmse: 0.0817716\n",
      "[575]\ttraining's rmse: 0.0848827\tvalid_1's rmse: 0.0817647\n",
      "[600]\ttraining's rmse: 0.0848366\tvalid_1's rmse: 0.0817572\n",
      "[625]\ttraining's rmse: 0.0848006\tvalid_1's rmse: 0.0817622\n",
      "Early stopping, best iteration is:\n",
      "[595]\ttraining's rmse: 0.0848463\tvalid_1's rmse: 0.081756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0816398\tvalid_1's rmse: 0.0839973\n",
      "[50]\ttraining's rmse: 0.0815142\tvalid_1's rmse: 0.0839481\n",
      "[75]\ttraining's rmse: 0.0813904\tvalid_1's rmse: 0.0839003\n",
      "[100]\ttraining's rmse: 0.0812741\tvalid_1's rmse: 0.0838574\n",
      "[125]\ttraining's rmse: 0.081161\tvalid_1's rmse: 0.0838157\n",
      "[150]\ttraining's rmse: 0.0810558\tvalid_1's rmse: 0.0837751\n",
      "[175]\ttraining's rmse: 0.080968\tvalid_1's rmse: 0.0837409\n",
      "[200]\ttraining's rmse: 0.0808737\tvalid_1's rmse: 0.0837055\n",
      "[225]\ttraining's rmse: 0.0807799\tvalid_1's rmse: 0.0836726\n",
      "[250]\ttraining's rmse: 0.0807035\tvalid_1's rmse: 0.083643\n",
      "[275]\ttraining's rmse: 0.0806266\tvalid_1's rmse: 0.0836166\n",
      "[300]\ttraining's rmse: 0.0805562\tvalid_1's rmse: 0.0835911\n",
      "[325]\ttraining's rmse: 0.0804848\tvalid_1's rmse: 0.0835673\n",
      "[350]\ttraining's rmse: 0.0804153\tvalid_1's rmse: 0.0835434\n",
      "[375]\ttraining's rmse: 0.0803553\tvalid_1's rmse: 0.0835226\n",
      "[400]\ttraining's rmse: 0.0802927\tvalid_1's rmse: 0.083503\n",
      "[425]\ttraining's rmse: 0.0802367\tvalid_1's rmse: 0.0834844\n",
      "[450]\ttraining's rmse: 0.08019\tvalid_1's rmse: 0.0834661\n",
      "[475]\ttraining's rmse: 0.080143\tvalid_1's rmse: 0.0834494\n",
      "[500]\ttraining's rmse: 0.0801035\tvalid_1's rmse: 0.0834331\n",
      "[525]\ttraining's rmse: 0.0800524\tvalid_1's rmse: 0.0834163\n",
      "[550]\ttraining's rmse: 0.0800054\tvalid_1's rmse: 0.0834021\n",
      "[575]\ttraining's rmse: 0.0799614\tvalid_1's rmse: 0.0833891\n",
      "[600]\ttraining's rmse: 0.0799165\tvalid_1's rmse: 0.0833757\n",
      "[625]\ttraining's rmse: 0.0798822\tvalid_1's rmse: 0.0833641\n",
      "[650]\ttraining's rmse: 0.0798416\tvalid_1's rmse: 0.0833524\n",
      "[675]\ttraining's rmse: 0.0798014\tvalid_1's rmse: 0.0833405\n",
      "[700]\ttraining's rmse: 0.0797656\tvalid_1's rmse: 0.0833302\n",
      "[725]\ttraining's rmse: 0.079729\tvalid_1's rmse: 0.0833201\n",
      "[750]\ttraining's rmse: 0.0796974\tvalid_1's rmse: 0.0833115\n",
      "[775]\ttraining's rmse: 0.0796719\tvalid_1's rmse: 0.0833018\n",
      "[800]\ttraining's rmse: 0.0796405\tvalid_1's rmse: 0.0832939\n",
      "[825]\ttraining's rmse: 0.0796137\tvalid_1's rmse: 0.0832863\n",
      "[850]\ttraining's rmse: 0.0795823\tvalid_1's rmse: 0.083278\n",
      "[875]\ttraining's rmse: 0.0795552\tvalid_1's rmse: 0.0832715\n",
      "[900]\ttraining's rmse: 0.0795276\tvalid_1's rmse: 0.0832647\n",
      "[925]\ttraining's rmse: 0.079503\tvalid_1's rmse: 0.0832567\n",
      "[950]\ttraining's rmse: 0.0794817\tvalid_1's rmse: 0.0832507\n",
      "[975]\ttraining's rmse: 0.0794584\tvalid_1's rmse: 0.0832458\n",
      "[1000]\ttraining's rmse: 0.0794346\tvalid_1's rmse: 0.0832411\n",
      "[1025]\ttraining's rmse: 0.079412\tvalid_1's rmse: 0.0832347\n",
      "[1050]\ttraining's rmse: 0.0793914\tvalid_1's rmse: 0.083229\n",
      "[1075]\ttraining's rmse: 0.0793698\tvalid_1's rmse: 0.0832247\n",
      "[1100]\ttraining's rmse: 0.0793512\tvalid_1's rmse: 0.0832209\n",
      "[1125]\ttraining's rmse: 0.0793349\tvalid_1's rmse: 0.083216\n",
      "[1150]\ttraining's rmse: 0.0793175\tvalid_1's rmse: 0.0832124\n",
      "[1175]\ttraining's rmse: 0.0792995\tvalid_1's rmse: 0.0832095\n",
      "[1200]\ttraining's rmse: 0.0792858\tvalid_1's rmse: 0.0832051\n",
      "[1225]\ttraining's rmse: 0.0792708\tvalid_1's rmse: 0.0832005\n",
      "[1250]\ttraining's rmse: 0.079256\tvalid_1's rmse: 0.0831961\n",
      "[1275]\ttraining's rmse: 0.0792404\tvalid_1's rmse: 0.0831931\n",
      "[1300]\ttraining's rmse: 0.0792262\tvalid_1's rmse: 0.0831882\n",
      "[1325]\ttraining's rmse: 0.0792105\tvalid_1's rmse: 0.0831855\n",
      "[1350]\ttraining's rmse: 0.079196\tvalid_1's rmse: 0.0831839\n",
      "[1375]\ttraining's rmse: 0.0791842\tvalid_1's rmse: 0.0831814\n",
      "[1400]\ttraining's rmse: 0.0791731\tvalid_1's rmse: 0.0831792\n",
      "[1425]\ttraining's rmse: 0.0791605\tvalid_1's rmse: 0.0831761\n",
      "[1450]\ttraining's rmse: 0.0791502\tvalid_1's rmse: 0.0831742\n",
      "[1475]\ttraining's rmse: 0.0791416\tvalid_1's rmse: 0.083172\n",
      "[1500]\ttraining's rmse: 0.0791306\tvalid_1's rmse: 0.0831694\n",
      "[1525]\ttraining's rmse: 0.0791212\tvalid_1's rmse: 0.0831665\n",
      "[1550]\ttraining's rmse: 0.079111\tvalid_1's rmse: 0.0831649\n",
      "[1575]\ttraining's rmse: 0.0791041\tvalid_1's rmse: 0.0831613\n",
      "[1600]\ttraining's rmse: 0.0790959\tvalid_1's rmse: 0.0831569\n",
      "[1625]\ttraining's rmse: 0.07909\tvalid_1's rmse: 0.0831544\n",
      "[1650]\ttraining's rmse: 0.0790842\tvalid_1's rmse: 0.0831523\n",
      "[1675]\ttraining's rmse: 0.0790781\tvalid_1's rmse: 0.0831504\n",
      "[1700]\ttraining's rmse: 0.0790719\tvalid_1's rmse: 0.0831478\n",
      "[1725]\ttraining's rmse: 0.0790661\tvalid_1's rmse: 0.0831466\n",
      "[1750]\ttraining's rmse: 0.0790577\tvalid_1's rmse: 0.0831447\n",
      "[1775]\ttraining's rmse: 0.079053\tvalid_1's rmse: 0.0831438\n",
      "[1800]\ttraining's rmse: 0.0790476\tvalid_1's rmse: 0.083143\n",
      "[1825]\ttraining's rmse: 0.0790412\tvalid_1's rmse: 0.0831415\n",
      "[1850]\ttraining's rmse: 0.0790364\tvalid_1's rmse: 0.0831396\n",
      "[1875]\ttraining's rmse: 0.0790311\tvalid_1's rmse: 0.0831387\n",
      "[1900]\ttraining's rmse: 0.0790258\tvalid_1's rmse: 0.0831365\n",
      "[1925]\ttraining's rmse: 0.0790218\tvalid_1's rmse: 0.0831355\n",
      "[1950]\ttraining's rmse: 0.0790188\tvalid_1's rmse: 0.0831342\n",
      "[1975]\ttraining's rmse: 0.079014\tvalid_1's rmse: 0.0831333\n",
      "[2000]\ttraining's rmse: 0.0790112\tvalid_1's rmse: 0.0831324\n",
      "[2025]\ttraining's rmse: 0.0790071\tvalid_1's rmse: 0.0831309\n",
      "[2050]\ttraining's rmse: 0.0790035\tvalid_1's rmse: 0.0831303\n",
      "[2075]\ttraining's rmse: 0.0790002\tvalid_1's rmse: 0.0831292\n",
      "[2100]\ttraining's rmse: 0.0789973\tvalid_1's rmse: 0.0831284\n",
      "[2125]\ttraining's rmse: 0.078995\tvalid_1's rmse: 0.0831272\n",
      "[2150]\ttraining's rmse: 0.0789927\tvalid_1's rmse: 0.0831268\n",
      "[2175]\ttraining's rmse: 0.0789879\tvalid_1's rmse: 0.0831262\n",
      "[2200]\ttraining's rmse: 0.0789847\tvalid_1's rmse: 0.0831261\n",
      "[2225]\ttraining's rmse: 0.0789825\tvalid_1's rmse: 0.0831256\n",
      "[2250]\ttraining's rmse: 0.0789791\tvalid_1's rmse: 0.0831237\n",
      "[2275]\ttraining's rmse: 0.0789762\tvalid_1's rmse: 0.0831236\n",
      "[2300]\ttraining's rmse: 0.0789736\tvalid_1's rmse: 0.0831228\n",
      "[2325]\ttraining's rmse: 0.0789714\tvalid_1's rmse: 0.0831223\n",
      "[2350]\ttraining's rmse: 0.0789691\tvalid_1's rmse: 0.0831223\n",
      "[2375]\ttraining's rmse: 0.0789666\tvalid_1's rmse: 0.0831203\n",
      "[2400]\ttraining's rmse: 0.0789646\tvalid_1's rmse: 0.0831193\n",
      "[2425]\ttraining's rmse: 0.0789617\tvalid_1's rmse: 0.0831186\n",
      "[2450]\ttraining's rmse: 0.0789604\tvalid_1's rmse: 0.0831184\n",
      "[2475]\ttraining's rmse: 0.0789576\tvalid_1's rmse: 0.0831188\n",
      "[2500]\ttraining's rmse: 0.0789563\tvalid_1's rmse: 0.0831183\n",
      "[2525]\ttraining's rmse: 0.078953\tvalid_1's rmse: 0.0831178\n",
      "[2550]\ttraining's rmse: 0.0789516\tvalid_1's rmse: 0.0831176\n",
      "[2575]\ttraining's rmse: 0.0789498\tvalid_1's rmse: 0.0831174\n",
      "[2600]\ttraining's rmse: 0.0789479\tvalid_1's rmse: 0.0831172\n",
      "[2625]\ttraining's rmse: 0.0789463\tvalid_1's rmse: 0.0831157\n",
      "[2650]\ttraining's rmse: 0.0789445\tvalid_1's rmse: 0.0831147\n",
      "[2675]\ttraining's rmse: 0.078943\tvalid_1's rmse: 0.0831138\n",
      "[2700]\ttraining's rmse: 0.0789422\tvalid_1's rmse: 0.0831141\n",
      "[2725]\ttraining's rmse: 0.0789397\tvalid_1's rmse: 0.083114\n",
      "Early stopping, best iteration is:\n",
      "[2675]\ttraining's rmse: 0.078943\tvalid_1's rmse: 0.0831138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0818942\tvalid_1's rmse: 0.0835229\n",
      "[50]\ttraining's rmse: 0.0817817\tvalid_1's rmse: 0.0834708\n",
      "[75]\ttraining's rmse: 0.0816667\tvalid_1's rmse: 0.0834207\n",
      "[100]\ttraining's rmse: 0.0815619\tvalid_1's rmse: 0.0833739\n",
      "[125]\ttraining's rmse: 0.0814578\tvalid_1's rmse: 0.0833299\n",
      "[150]\ttraining's rmse: 0.0813615\tvalid_1's rmse: 0.0832883\n",
      "[175]\ttraining's rmse: 0.0812797\tvalid_1's rmse: 0.0832525\n",
      "[200]\ttraining's rmse: 0.0811888\tvalid_1's rmse: 0.0832162\n",
      "[225]\ttraining's rmse: 0.0811021\tvalid_1's rmse: 0.0831827\n",
      "[250]\ttraining's rmse: 0.0810281\tvalid_1's rmse: 0.0831528\n",
      "[275]\ttraining's rmse: 0.0809601\tvalid_1's rmse: 0.0831245\n",
      "[300]\ttraining's rmse: 0.080891\tvalid_1's rmse: 0.0830979\n",
      "[325]\ttraining's rmse: 0.0808235\tvalid_1's rmse: 0.0830727\n",
      "[350]\ttraining's rmse: 0.080758\tvalid_1's rmse: 0.0830482\n",
      "[375]\ttraining's rmse: 0.0807048\tvalid_1's rmse: 0.0830271\n",
      "[400]\ttraining's rmse: 0.0806478\tvalid_1's rmse: 0.083007\n",
      "[425]\ttraining's rmse: 0.0805942\tvalid_1's rmse: 0.0829876\n",
      "[450]\ttraining's rmse: 0.0805447\tvalid_1's rmse: 0.0829685\n",
      "[475]\ttraining's rmse: 0.0804997\tvalid_1's rmse: 0.0829527\n",
      "[500]\ttraining's rmse: 0.0804591\tvalid_1's rmse: 0.0829354\n",
      "[525]\ttraining's rmse: 0.0804087\tvalid_1's rmse: 0.08292\n",
      "[550]\ttraining's rmse: 0.0803624\tvalid_1's rmse: 0.0829064\n",
      "[575]\ttraining's rmse: 0.0803202\tvalid_1's rmse: 0.082893\n",
      "[600]\ttraining's rmse: 0.0802777\tvalid_1's rmse: 0.0828795\n",
      "[625]\ttraining's rmse: 0.0802432\tvalid_1's rmse: 0.0828674\n",
      "[650]\ttraining's rmse: 0.0802028\tvalid_1's rmse: 0.082854\n",
      "[675]\ttraining's rmse: 0.0801616\tvalid_1's rmse: 0.0828431\n",
      "[700]\ttraining's rmse: 0.0801274\tvalid_1's rmse: 0.082833\n",
      "[725]\ttraining's rmse: 0.0800951\tvalid_1's rmse: 0.0828234\n",
      "[750]\ttraining's rmse: 0.0800664\tvalid_1's rmse: 0.0828141\n",
      "[775]\ttraining's rmse: 0.0800389\tvalid_1's rmse: 0.0828051\n",
      "[800]\ttraining's rmse: 0.0800038\tvalid_1's rmse: 0.0827968\n",
      "[825]\ttraining's rmse: 0.0799756\tvalid_1's rmse: 0.0827898\n",
      "[850]\ttraining's rmse: 0.0799476\tvalid_1's rmse: 0.0827836\n",
      "[875]\ttraining's rmse: 0.0799245\tvalid_1's rmse: 0.0827774\n",
      "[900]\ttraining's rmse: 0.0798933\tvalid_1's rmse: 0.0827693\n",
      "[925]\ttraining's rmse: 0.0798702\tvalid_1's rmse: 0.0827637\n",
      "[950]\ttraining's rmse: 0.0798464\tvalid_1's rmse: 0.0827583\n",
      "[975]\ttraining's rmse: 0.0798231\tvalid_1's rmse: 0.0827528\n",
      "[1000]\ttraining's rmse: 0.0798014\tvalid_1's rmse: 0.0827478\n",
      "[1025]\ttraining's rmse: 0.0797754\tvalid_1's rmse: 0.0827428\n",
      "[1050]\ttraining's rmse: 0.0797552\tvalid_1's rmse: 0.0827378\n",
      "[1075]\ttraining's rmse: 0.0797352\tvalid_1's rmse: 0.0827345\n",
      "[1100]\ttraining's rmse: 0.0797186\tvalid_1's rmse: 0.0827299\n",
      "[1125]\ttraining's rmse: 0.0797009\tvalid_1's rmse: 0.0827261\n",
      "[1150]\ttraining's rmse: 0.0796835\tvalid_1's rmse: 0.0827228\n",
      "[1175]\ttraining's rmse: 0.0796684\tvalid_1's rmse: 0.0827196\n",
      "[1200]\ttraining's rmse: 0.0796537\tvalid_1's rmse: 0.0827157\n",
      "[1225]\ttraining's rmse: 0.079638\tvalid_1's rmse: 0.0827124\n",
      "[1250]\ttraining's rmse: 0.0796248\tvalid_1's rmse: 0.0827094\n",
      "[1275]\ttraining's rmse: 0.0796086\tvalid_1's rmse: 0.0827068\n",
      "[1300]\ttraining's rmse: 0.0795967\tvalid_1's rmse: 0.0827044\n",
      "[1325]\ttraining's rmse: 0.0795837\tvalid_1's rmse: 0.0827021\n",
      "[1350]\ttraining's rmse: 0.0795684\tvalid_1's rmse: 0.0826999\n",
      "[1375]\ttraining's rmse: 0.0795556\tvalid_1's rmse: 0.0826979\n",
      "[1400]\ttraining's rmse: 0.079546\tvalid_1's rmse: 0.0826957\n",
      "[1425]\ttraining's rmse: 0.0795349\tvalid_1's rmse: 0.0826943\n",
      "[1450]\ttraining's rmse: 0.0795241\tvalid_1's rmse: 0.0826926\n",
      "[1475]\ttraining's rmse: 0.0795159\tvalid_1's rmse: 0.082691\n",
      "[1500]\ttraining's rmse: 0.0795062\tvalid_1's rmse: 0.0826896\n",
      "[1525]\ttraining's rmse: 0.0794954\tvalid_1's rmse: 0.0826881\n",
      "[1550]\ttraining's rmse: 0.0794868\tvalid_1's rmse: 0.0826869\n",
      "[1575]\ttraining's rmse: 0.0794796\tvalid_1's rmse: 0.0826849\n",
      "[1600]\ttraining's rmse: 0.0794715\tvalid_1's rmse: 0.0826842\n",
      "[1625]\ttraining's rmse: 0.0794637\tvalid_1's rmse: 0.0826825\n",
      "[1650]\ttraining's rmse: 0.0794578\tvalid_1's rmse: 0.0826817\n",
      "[1675]\ttraining's rmse: 0.079453\tvalid_1's rmse: 0.0826809\n",
      "[1700]\ttraining's rmse: 0.0794468\tvalid_1's rmse: 0.0826793\n",
      "[1725]\ttraining's rmse: 0.0794402\tvalid_1's rmse: 0.0826782\n",
      "[1750]\ttraining's rmse: 0.0794329\tvalid_1's rmse: 0.0826773\n",
      "[1775]\ttraining's rmse: 0.0794267\tvalid_1's rmse: 0.0826768\n",
      "[1800]\ttraining's rmse: 0.0794197\tvalid_1's rmse: 0.0826759\n",
      "[1825]\ttraining's rmse: 0.0794126\tvalid_1's rmse: 0.0826746\n",
      "[1850]\ttraining's rmse: 0.0794083\tvalid_1's rmse: 0.0826738\n",
      "[1875]\ttraining's rmse: 0.0794043\tvalid_1's rmse: 0.0826732\n",
      "[1900]\ttraining's rmse: 0.0794001\tvalid_1's rmse: 0.0826729\n",
      "[1925]\ttraining's rmse: 0.0793951\tvalid_1's rmse: 0.082672\n",
      "[1950]\ttraining's rmse: 0.079392\tvalid_1's rmse: 0.0826712\n",
      "[1975]\ttraining's rmse: 0.079389\tvalid_1's rmse: 0.0826705\n",
      "[2000]\ttraining's rmse: 0.0793855\tvalid_1's rmse: 0.0826699\n",
      "[2025]\ttraining's rmse: 0.0793828\tvalid_1's rmse: 0.0826692\n",
      "[2050]\ttraining's rmse: 0.0793789\tvalid_1's rmse: 0.082669\n",
      "[2075]\ttraining's rmse: 0.0793753\tvalid_1's rmse: 0.0826688\n",
      "[2100]\ttraining's rmse: 0.0793718\tvalid_1's rmse: 0.0826685\n",
      "[2125]\ttraining's rmse: 0.0793688\tvalid_1's rmse: 0.0826686\n",
      "[2150]\ttraining's rmse: 0.0793661\tvalid_1's rmse: 0.0826685\n",
      "Early stopping, best iteration is:\n",
      "[2106]\ttraining's rmse: 0.0793707\tvalid_1's rmse: 0.0826684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.083647\tvalid_1's rmse: 0.0799605\n",
      "[50]\ttraining's rmse: 0.0835419\tvalid_1's rmse: 0.0799155\n",
      "[75]\ttraining's rmse: 0.0834327\tvalid_1's rmse: 0.0798697\n",
      "[100]\ttraining's rmse: 0.0833342\tvalid_1's rmse: 0.0798291\n",
      "[125]\ttraining's rmse: 0.0832324\tvalid_1's rmse: 0.0797879\n",
      "[150]\ttraining's rmse: 0.0831376\tvalid_1's rmse: 0.079751\n",
      "[175]\ttraining's rmse: 0.0830601\tvalid_1's rmse: 0.0797229\n",
      "[200]\ttraining's rmse: 0.0829748\tvalid_1's rmse: 0.0796957\n",
      "[225]\ttraining's rmse: 0.0828917\tvalid_1's rmse: 0.0796654\n",
      "[250]\ttraining's rmse: 0.0828212\tvalid_1's rmse: 0.0796376\n",
      "[275]\ttraining's rmse: 0.0827573\tvalid_1's rmse: 0.0796135\n",
      "[300]\ttraining's rmse: 0.0826932\tvalid_1's rmse: 0.0795961\n",
      "[325]\ttraining's rmse: 0.0826291\tvalid_1's rmse: 0.0795747\n",
      "[350]\ttraining's rmse: 0.0825655\tvalid_1's rmse: 0.0795544\n",
      "[375]\ttraining's rmse: 0.0825145\tvalid_1's rmse: 0.0795393\n",
      "[400]\ttraining's rmse: 0.0824595\tvalid_1's rmse: 0.0795277\n",
      "[425]\ttraining's rmse: 0.0824082\tvalid_1's rmse: 0.0795141\n",
      "[450]\ttraining's rmse: 0.082361\tvalid_1's rmse: 0.0795022\n",
      "[475]\ttraining's rmse: 0.082316\tvalid_1's rmse: 0.0794888\n",
      "[500]\ttraining's rmse: 0.082279\tvalid_1's rmse: 0.079477\n",
      "[525]\ttraining's rmse: 0.0822293\tvalid_1's rmse: 0.0794634\n",
      "[550]\ttraining's rmse: 0.0821823\tvalid_1's rmse: 0.0794612\n",
      "[575]\ttraining's rmse: 0.0821411\tvalid_1's rmse: 0.0794558\n",
      "[600]\ttraining's rmse: 0.0820991\tvalid_1's rmse: 0.07945\n",
      "[625]\ttraining's rmse: 0.0820683\tvalid_1's rmse: 0.0794409\n",
      "[650]\ttraining's rmse: 0.0820259\tvalid_1's rmse: 0.0794386\n",
      "[675]\ttraining's rmse: 0.0819835\tvalid_1's rmse: 0.0794438\n",
      "[700]\ttraining's rmse: 0.0819473\tvalid_1's rmse: 0.079442\n",
      "Early stopping, best iteration is:\n",
      "[657]\ttraining's rmse: 0.0820149\tvalid_1's rmse: 0.0794367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0811749\tvalid_1's rmse: 0.0835622\n",
      "[50]\ttraining's rmse: 0.081052\tvalid_1's rmse: 0.0835122\n",
      "[75]\ttraining's rmse: 0.0809323\tvalid_1's rmse: 0.0834631\n",
      "[100]\ttraining's rmse: 0.0808209\tvalid_1's rmse: 0.0834211\n",
      "[125]\ttraining's rmse: 0.0807064\tvalid_1's rmse: 0.083378\n",
      "[150]\ttraining's rmse: 0.0806021\tvalid_1's rmse: 0.0833379\n",
      "[175]\ttraining's rmse: 0.0805175\tvalid_1's rmse: 0.0833042\n",
      "[200]\ttraining's rmse: 0.0804283\tvalid_1's rmse: 0.0832704\n",
      "[225]\ttraining's rmse: 0.0803361\tvalid_1's rmse: 0.0832378\n",
      "[250]\ttraining's rmse: 0.0802581\tvalid_1's rmse: 0.0832078\n",
      "[275]\ttraining's rmse: 0.0801843\tvalid_1's rmse: 0.0831806\n",
      "[300]\ttraining's rmse: 0.080113\tvalid_1's rmse: 0.0831549\n",
      "[325]\ttraining's rmse: 0.0800429\tvalid_1's rmse: 0.083131\n",
      "[350]\ttraining's rmse: 0.0799778\tvalid_1's rmse: 0.0831079\n",
      "[375]\ttraining's rmse: 0.0799212\tvalid_1's rmse: 0.0830887\n",
      "[400]\ttraining's rmse: 0.079859\tvalid_1's rmse: 0.0830691\n",
      "[425]\ttraining's rmse: 0.0798033\tvalid_1's rmse: 0.0830505\n",
      "[450]\ttraining's rmse: 0.0797516\tvalid_1's rmse: 0.0830321\n",
      "[475]\ttraining's rmse: 0.0797073\tvalid_1's rmse: 0.0830155\n",
      "[500]\ttraining's rmse: 0.0796658\tvalid_1's rmse: 0.0830007\n",
      "[525]\ttraining's rmse: 0.0796149\tvalid_1's rmse: 0.0829859\n",
      "[550]\ttraining's rmse: 0.0795727\tvalid_1's rmse: 0.0829723\n",
      "[575]\ttraining's rmse: 0.0795292\tvalid_1's rmse: 0.0829598\n",
      "[600]\ttraining's rmse: 0.0794905\tvalid_1's rmse: 0.0829483\n",
      "[625]\ttraining's rmse: 0.0794559\tvalid_1's rmse: 0.0829375\n",
      "[650]\ttraining's rmse: 0.0794146\tvalid_1's rmse: 0.0829249\n",
      "[675]\ttraining's rmse: 0.0793761\tvalid_1's rmse: 0.0829133\n",
      "[700]\ttraining's rmse: 0.0793432\tvalid_1's rmse: 0.0829039\n",
      "[725]\ttraining's rmse: 0.0793099\tvalid_1's rmse: 0.0828955\n",
      "[750]\ttraining's rmse: 0.0792773\tvalid_1's rmse: 0.0828869\n",
      "[775]\ttraining's rmse: 0.0792526\tvalid_1's rmse: 0.0828777\n",
      "[800]\ttraining's rmse: 0.0792196\tvalid_1's rmse: 0.0828697\n",
      "[825]\ttraining's rmse: 0.0791917\tvalid_1's rmse: 0.0828621\n",
      "[850]\ttraining's rmse: 0.0791605\tvalid_1's rmse: 0.0828549\n",
      "[875]\ttraining's rmse: 0.0791363\tvalid_1's rmse: 0.0828477\n",
      "[900]\ttraining's rmse: 0.0791091\tvalid_1's rmse: 0.0828402\n",
      "[925]\ttraining's rmse: 0.0790853\tvalid_1's rmse: 0.082834\n",
      "[950]\ttraining's rmse: 0.0790615\tvalid_1's rmse: 0.0828292\n",
      "[975]\ttraining's rmse: 0.0790419\tvalid_1's rmse: 0.082825\n",
      "[1000]\ttraining's rmse: 0.0790213\tvalid_1's rmse: 0.0828194\n",
      "[1025]\ttraining's rmse: 0.0789985\tvalid_1's rmse: 0.0828137\n",
      "[1050]\ttraining's rmse: 0.0789786\tvalid_1's rmse: 0.0828083\n",
      "[1075]\ttraining's rmse: 0.0789578\tvalid_1's rmse: 0.0828057\n",
      "[1100]\ttraining's rmse: 0.0789407\tvalid_1's rmse: 0.0828015\n",
      "[1125]\ttraining's rmse: 0.0789258\tvalid_1's rmse: 0.0827953\n",
      "[1150]\ttraining's rmse: 0.0789078\tvalid_1's rmse: 0.082791\n",
      "[1175]\ttraining's rmse: 0.0788905\tvalid_1's rmse: 0.0827883\n",
      "[1200]\ttraining's rmse: 0.078876\tvalid_1's rmse: 0.0827838\n",
      "[1225]\ttraining's rmse: 0.0788606\tvalid_1's rmse: 0.0827791\n",
      "[1250]\ttraining's rmse: 0.0788478\tvalid_1's rmse: 0.0827746\n",
      "[1275]\ttraining's rmse: 0.0788315\tvalid_1's rmse: 0.0827727\n",
      "[1300]\ttraining's rmse: 0.0788177\tvalid_1's rmse: 0.0827688\n",
      "[1325]\ttraining's rmse: 0.0788058\tvalid_1's rmse: 0.082766\n",
      "[1350]\ttraining's rmse: 0.0787919\tvalid_1's rmse: 0.0827628\n",
      "[1375]\ttraining's rmse: 0.0787797\tvalid_1's rmse: 0.082759\n",
      "[1400]\ttraining's rmse: 0.0787686\tvalid_1's rmse: 0.0827558\n",
      "[1425]\ttraining's rmse: 0.0787565\tvalid_1's rmse: 0.0827538\n",
      "[1450]\ttraining's rmse: 0.0787454\tvalid_1's rmse: 0.0827518\n",
      "[1475]\ttraining's rmse: 0.0787372\tvalid_1's rmse: 0.0827497\n",
      "[1500]\ttraining's rmse: 0.0787304\tvalid_1's rmse: 0.0827474\n",
      "[1525]\ttraining's rmse: 0.0787238\tvalid_1's rmse: 0.0827447\n",
      "[1550]\ttraining's rmse: 0.078713\tvalid_1's rmse: 0.0827431\n",
      "[1575]\ttraining's rmse: 0.078704\tvalid_1's rmse: 0.0827407\n",
      "[1600]\ttraining's rmse: 0.0786969\tvalid_1's rmse: 0.0827384\n",
      "[1625]\ttraining's rmse: 0.0786898\tvalid_1's rmse: 0.0827359\n",
      "[1650]\ttraining's rmse: 0.0786835\tvalid_1's rmse: 0.0827342\n",
      "[1675]\ttraining's rmse: 0.0786786\tvalid_1's rmse: 0.0827329\n",
      "[1700]\ttraining's rmse: 0.0786743\tvalid_1's rmse: 0.0827309\n",
      "[1725]\ttraining's rmse: 0.0786659\tvalid_1's rmse: 0.0827299\n",
      "[1750]\ttraining's rmse: 0.0786595\tvalid_1's rmse: 0.0827282\n",
      "[1775]\ttraining's rmse: 0.0786535\tvalid_1's rmse: 0.0827274\n",
      "[1800]\ttraining's rmse: 0.0786488\tvalid_1's rmse: 0.0827258\n",
      "[1825]\ttraining's rmse: 0.0786426\tvalid_1's rmse: 0.0827248\n",
      "[1850]\ttraining's rmse: 0.0786377\tvalid_1's rmse: 0.0827232\n",
      "[1875]\ttraining's rmse: 0.0786338\tvalid_1's rmse: 0.0827227\n",
      "[1900]\ttraining's rmse: 0.0786293\tvalid_1's rmse: 0.0827211\n",
      "[1925]\ttraining's rmse: 0.0786259\tvalid_1's rmse: 0.0827204\n",
      "[1950]\ttraining's rmse: 0.0786209\tvalid_1's rmse: 0.0827181\n",
      "[1975]\ttraining's rmse: 0.0786175\tvalid_1's rmse: 0.082717\n",
      "[2000]\ttraining's rmse: 0.0786133\tvalid_1's rmse: 0.0827159\n",
      "[2025]\ttraining's rmse: 0.0786097\tvalid_1's rmse: 0.0827146\n",
      "[2050]\ttraining's rmse: 0.078606\tvalid_1's rmse: 0.0827134\n",
      "[2075]\ttraining's rmse: 0.0786031\tvalid_1's rmse: 0.0827123\n",
      "[2100]\ttraining's rmse: 0.0786006\tvalid_1's rmse: 0.0827124\n",
      "[2125]\ttraining's rmse: 0.0785975\tvalid_1's rmse: 0.0827117\n",
      "[2150]\ttraining's rmse: 0.0785937\tvalid_1's rmse: 0.0827114\n",
      "[2175]\ttraining's rmse: 0.0785905\tvalid_1's rmse: 0.0827117\n",
      "[2200]\ttraining's rmse: 0.0785876\tvalid_1's rmse: 0.0827115\n",
      "[2225]\ttraining's rmse: 0.078585\tvalid_1's rmse: 0.0827111\n",
      "[2250]\ttraining's rmse: 0.0785828\tvalid_1's rmse: 0.0827088\n",
      "[2275]\ttraining's rmse: 0.07858\tvalid_1's rmse: 0.0827086\n",
      "[2300]\ttraining's rmse: 0.0785775\tvalid_1's rmse: 0.0827079\n",
      "[2325]\ttraining's rmse: 0.0785745\tvalid_1's rmse: 0.0827068\n",
      "[2350]\ttraining's rmse: 0.0785723\tvalid_1's rmse: 0.082706\n",
      "[2375]\ttraining's rmse: 0.0785704\tvalid_1's rmse: 0.0827053\n",
      "[2400]\ttraining's rmse: 0.0785689\tvalid_1's rmse: 0.0827057\n",
      "[2425]\ttraining's rmse: 0.0785664\tvalid_1's rmse: 0.0827048\n",
      "[2450]\ttraining's rmse: 0.0785649\tvalid_1's rmse: 0.0827043\n",
      "[2475]\ttraining's rmse: 0.0785622\tvalid_1's rmse: 0.0827043\n",
      "[2500]\ttraining's rmse: 0.0785604\tvalid_1's rmse: 0.0827036\n",
      "[2525]\ttraining's rmse: 0.0785571\tvalid_1's rmse: 0.082703\n",
      "[2550]\ttraining's rmse: 0.0785536\tvalid_1's rmse: 0.0827021\n",
      "[2575]\ttraining's rmse: 0.0785512\tvalid_1's rmse: 0.0827021\n",
      "[2600]\ttraining's rmse: 0.0785489\tvalid_1's rmse: 0.0827022\n",
      "[2625]\ttraining's rmse: 0.078547\tvalid_1's rmse: 0.0827012\n",
      "[2650]\ttraining's rmse: 0.078545\tvalid_1's rmse: 0.082701\n",
      "[2675]\ttraining's rmse: 0.0785428\tvalid_1's rmse: 0.0827003\n",
      "[2700]\ttraining's rmse: 0.0785411\tvalid_1's rmse: 0.0826996\n",
      "[2725]\ttraining's rmse: 0.078538\tvalid_1's rmse: 0.0826992\n",
      "[2750]\ttraining's rmse: 0.0785357\tvalid_1's rmse: 0.0826983\n",
      "[2775]\ttraining's rmse: 0.0785335\tvalid_1's rmse: 0.0826972\n",
      "[2800]\ttraining's rmse: 0.0785312\tvalid_1's rmse: 0.0826976\n",
      "Early stopping, best iteration is:\n",
      "[2774]\ttraining's rmse: 0.0785335\tvalid_1's rmse: 0.0826971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0814686\tvalid_1's rmse: 0.0830061\n",
      "[50]\ttraining's rmse: 0.08136\tvalid_1's rmse: 0.0829533\n",
      "[75]\ttraining's rmse: 0.0812512\tvalid_1's rmse: 0.0829042\n",
      "[100]\ttraining's rmse: 0.0811497\tvalid_1's rmse: 0.0828594\n",
      "[125]\ttraining's rmse: 0.0810452\tvalid_1's rmse: 0.0828144\n",
      "[150]\ttraining's rmse: 0.080949\tvalid_1's rmse: 0.082772\n",
      "[175]\ttraining's rmse: 0.0808707\tvalid_1's rmse: 0.0827382\n",
      "[200]\ttraining's rmse: 0.080783\tvalid_1's rmse: 0.082703\n",
      "[225]\ttraining's rmse: 0.0806988\tvalid_1's rmse: 0.0826701\n",
      "[250]\ttraining's rmse: 0.0806262\tvalid_1's rmse: 0.082639\n",
      "[275]\ttraining's rmse: 0.0805583\tvalid_1's rmse: 0.0826121\n",
      "[300]\ttraining's rmse: 0.0804931\tvalid_1's rmse: 0.0825858\n",
      "[325]\ttraining's rmse: 0.0804266\tvalid_1's rmse: 0.0825597\n",
      "[350]\ttraining's rmse: 0.0803609\tvalid_1's rmse: 0.0825362\n",
      "[375]\ttraining's rmse: 0.0803083\tvalid_1's rmse: 0.0825154\n",
      "[400]\ttraining's rmse: 0.0802506\tvalid_1's rmse: 0.0824957\n",
      "[425]\ttraining's rmse: 0.0802006\tvalid_1's rmse: 0.0824776\n",
      "[450]\ttraining's rmse: 0.0801528\tvalid_1's rmse: 0.08246\n",
      "[475]\ttraining's rmse: 0.0801095\tvalid_1's rmse: 0.0824444\n",
      "[500]\ttraining's rmse: 0.0800715\tvalid_1's rmse: 0.0824288\n",
      "[525]\ttraining's rmse: 0.0800202\tvalid_1's rmse: 0.0824129\n",
      "[550]\ttraining's rmse: 0.0799748\tvalid_1's rmse: 0.0823979\n",
      "[575]\ttraining's rmse: 0.0799354\tvalid_1's rmse: 0.0823845\n",
      "[600]\ttraining's rmse: 0.079895\tvalid_1's rmse: 0.0823716\n",
      "[625]\ttraining's rmse: 0.0798621\tvalid_1's rmse: 0.08236\n",
      "[650]\ttraining's rmse: 0.0798212\tvalid_1's rmse: 0.0823481\n",
      "[675]\ttraining's rmse: 0.0797819\tvalid_1's rmse: 0.0823373\n",
      "[700]\ttraining's rmse: 0.0797475\tvalid_1's rmse: 0.0823274\n",
      "[725]\ttraining's rmse: 0.0797155\tvalid_1's rmse: 0.0823184\n",
      "[750]\ttraining's rmse: 0.0796838\tvalid_1's rmse: 0.0823095\n",
      "[775]\ttraining's rmse: 0.0796578\tvalid_1's rmse: 0.0823005\n",
      "[800]\ttraining's rmse: 0.0796231\tvalid_1's rmse: 0.0822925\n",
      "[825]\ttraining's rmse: 0.0795967\tvalid_1's rmse: 0.0822842\n",
      "[850]\ttraining's rmse: 0.0795685\tvalid_1's rmse: 0.0822773\n",
      "[875]\ttraining's rmse: 0.0795442\tvalid_1's rmse: 0.0822713\n",
      "[900]\ttraining's rmse: 0.0795176\tvalid_1's rmse: 0.0822648\n",
      "[925]\ttraining's rmse: 0.0794937\tvalid_1's rmse: 0.0822588\n",
      "[950]\ttraining's rmse: 0.0794702\tvalid_1's rmse: 0.0822529\n",
      "[975]\ttraining's rmse: 0.0794482\tvalid_1's rmse: 0.082248\n",
      "[1000]\ttraining's rmse: 0.0794266\tvalid_1's rmse: 0.0822425\n",
      "[1025]\ttraining's rmse: 0.0794032\tvalid_1's rmse: 0.0822385\n",
      "[1050]\ttraining's rmse: 0.0793842\tvalid_1's rmse: 0.0822328\n",
      "[1075]\ttraining's rmse: 0.0793645\tvalid_1's rmse: 0.0822292\n",
      "[1100]\ttraining's rmse: 0.0793499\tvalid_1's rmse: 0.0822252\n",
      "[1125]\ttraining's rmse: 0.0793312\tvalid_1's rmse: 0.0822205\n",
      "[1150]\ttraining's rmse: 0.0793136\tvalid_1's rmse: 0.0822169\n",
      "[1175]\ttraining's rmse: 0.0792981\tvalid_1's rmse: 0.0822136\n",
      "[1200]\ttraining's rmse: 0.079282\tvalid_1's rmse: 0.0822107\n",
      "[1225]\ttraining's rmse: 0.0792675\tvalid_1's rmse: 0.082208\n",
      "[1250]\ttraining's rmse: 0.0792541\tvalid_1's rmse: 0.0822051\n",
      "[1275]\ttraining's rmse: 0.0792376\tvalid_1's rmse: 0.0822023\n",
      "[1300]\ttraining's rmse: 0.0792253\tvalid_1's rmse: 0.0821992\n",
      "[1325]\ttraining's rmse: 0.0792145\tvalid_1's rmse: 0.0821975\n",
      "[1350]\ttraining's rmse: 0.0792015\tvalid_1's rmse: 0.0821961\n",
      "[1375]\ttraining's rmse: 0.079191\tvalid_1's rmse: 0.0821941\n",
      "[1400]\ttraining's rmse: 0.0791811\tvalid_1's rmse: 0.0821914\n",
      "[1425]\ttraining's rmse: 0.0791713\tvalid_1's rmse: 0.0821897\n",
      "[1450]\ttraining's rmse: 0.0791606\tvalid_1's rmse: 0.0821879\n",
      "[1475]\ttraining's rmse: 0.0791501\tvalid_1's rmse: 0.0821861\n",
      "[1500]\ttraining's rmse: 0.0791395\tvalid_1's rmse: 0.0821838\n",
      "[1525]\ttraining's rmse: 0.0791309\tvalid_1's rmse: 0.0821823\n",
      "[1550]\ttraining's rmse: 0.0791227\tvalid_1's rmse: 0.082181\n",
      "[1575]\ttraining's rmse: 0.0791142\tvalid_1's rmse: 0.0821795\n",
      "[1600]\ttraining's rmse: 0.0791071\tvalid_1's rmse: 0.0821789\n",
      "[1625]\ttraining's rmse: 0.0790994\tvalid_1's rmse: 0.0821777\n",
      "[1650]\ttraining's rmse: 0.0790908\tvalid_1's rmse: 0.0821765\n",
      "[1675]\ttraining's rmse: 0.0790856\tvalid_1's rmse: 0.0821758\n",
      "[1700]\ttraining's rmse: 0.0790805\tvalid_1's rmse: 0.0821744\n",
      "[1725]\ttraining's rmse: 0.0790741\tvalid_1's rmse: 0.082173\n",
      "[1750]\ttraining's rmse: 0.0790686\tvalid_1's rmse: 0.0821718\n",
      "[1775]\ttraining's rmse: 0.079062\tvalid_1's rmse: 0.0821715\n",
      "[1800]\ttraining's rmse: 0.0790562\tvalid_1's rmse: 0.0821702\n",
      "[1825]\ttraining's rmse: 0.0790488\tvalid_1's rmse: 0.0821695\n",
      "[1850]\ttraining's rmse: 0.0790442\tvalid_1's rmse: 0.082169\n",
      "[1875]\ttraining's rmse: 0.0790399\tvalid_1's rmse: 0.0821685\n",
      "[1900]\ttraining's rmse: 0.0790362\tvalid_1's rmse: 0.0821684\n",
      "[1925]\ttraining's rmse: 0.0790331\tvalid_1's rmse: 0.0821681\n",
      "[1950]\ttraining's rmse: 0.0790302\tvalid_1's rmse: 0.0821678\n",
      "[1975]\ttraining's rmse: 0.0790266\tvalid_1's rmse: 0.082167\n",
      "[2000]\ttraining's rmse: 0.0790214\tvalid_1's rmse: 0.0821657\n",
      "[2025]\ttraining's rmse: 0.0790175\tvalid_1's rmse: 0.0821653\n",
      "[2050]\ttraining's rmse: 0.0790143\tvalid_1's rmse: 0.0821652\n",
      "[2075]\ttraining's rmse: 0.0790116\tvalid_1's rmse: 0.0821644\n",
      "[2100]\ttraining's rmse: 0.0790096\tvalid_1's rmse: 0.0821641\n",
      "[2125]\ttraining's rmse: 0.0790056\tvalid_1's rmse: 0.0821636\n",
      "[2150]\ttraining's rmse: 0.0790016\tvalid_1's rmse: 0.0821631\n",
      "[2175]\ttraining's rmse: 0.0789987\tvalid_1's rmse: 0.0821632\n",
      "[2200]\ttraining's rmse: 0.0789957\tvalid_1's rmse: 0.0821629\n",
      "[2225]\ttraining's rmse: 0.0789936\tvalid_1's rmse: 0.0821629\n",
      "[2250]\ttraining's rmse: 0.0789909\tvalid_1's rmse: 0.0821628\n",
      "[2275]\ttraining's rmse: 0.0789881\tvalid_1's rmse: 0.0821625\n",
      "[2300]\ttraining's rmse: 0.0789854\tvalid_1's rmse: 0.082162\n",
      "[2325]\ttraining's rmse: 0.0789819\tvalid_1's rmse: 0.0821616\n",
      "[2350]\ttraining's rmse: 0.0789796\tvalid_1's rmse: 0.0821612\n",
      "[2375]\ttraining's rmse: 0.078977\tvalid_1's rmse: 0.0821609\n",
      "[2400]\ttraining's rmse: 0.0789742\tvalid_1's rmse: 0.0821608\n",
      "[2425]\ttraining's rmse: 0.0789726\tvalid_1's rmse: 0.0821607\n",
      "[2450]\ttraining's rmse: 0.0789703\tvalid_1's rmse: 0.0821604\n",
      "[2475]\ttraining's rmse: 0.0789671\tvalid_1's rmse: 0.0821611\n",
      "Early stopping, best iteration is:\n",
      "[2449]\ttraining's rmse: 0.0789703\tvalid_1's rmse: 0.0821604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0831713\tvalid_1's rmse: 0.0795473\n",
      "[50]\ttraining's rmse: 0.0830654\tvalid_1's rmse: 0.0795059\n",
      "[75]\ttraining's rmse: 0.0829559\tvalid_1's rmse: 0.07946\n",
      "[100]\ttraining's rmse: 0.0828587\tvalid_1's rmse: 0.0794204\n",
      "[125]\ttraining's rmse: 0.0827589\tvalid_1's rmse: 0.0793806\n",
      "[150]\ttraining's rmse: 0.082666\tvalid_1's rmse: 0.0793444\n",
      "[175]\ttraining's rmse: 0.0825886\tvalid_1's rmse: 0.079315\n",
      "[200]\ttraining's rmse: 0.0825041\tvalid_1's rmse: 0.0792835\n",
      "[225]\ttraining's rmse: 0.0824239\tvalid_1's rmse: 0.0792551\n",
      "[250]\ttraining's rmse: 0.0823568\tvalid_1's rmse: 0.07923\n",
      "[275]\ttraining's rmse: 0.0822943\tvalid_1's rmse: 0.0792049\n",
      "[300]\ttraining's rmse: 0.0822315\tvalid_1's rmse: 0.0791824\n",
      "[325]\ttraining's rmse: 0.082167\tvalid_1's rmse: 0.0791614\n",
      "[350]\ttraining's rmse: 0.0821036\tvalid_1's rmse: 0.0791406\n",
      "[375]\ttraining's rmse: 0.0820529\tvalid_1's rmse: 0.0791246\n",
      "[400]\ttraining's rmse: 0.0819984\tvalid_1's rmse: 0.0791131\n",
      "[425]\ttraining's rmse: 0.0819477\tvalid_1's rmse: 0.0790986\n",
      "[450]\ttraining's rmse: 0.0819015\tvalid_1's rmse: 0.0790834\n",
      "[475]\ttraining's rmse: 0.081858\tvalid_1's rmse: 0.0790751\n",
      "[500]\ttraining's rmse: 0.0818211\tvalid_1's rmse: 0.0790626\n",
      "[525]\ttraining's rmse: 0.0817707\tvalid_1's rmse: 0.0790486\n",
      "[550]\ttraining's rmse: 0.0817269\tvalid_1's rmse: 0.0790401\n",
      "[575]\ttraining's rmse: 0.0816871\tvalid_1's rmse: 0.0790306\n",
      "[600]\ttraining's rmse: 0.0816451\tvalid_1's rmse: 0.0790197\n",
      "[625]\ttraining's rmse: 0.0816141\tvalid_1's rmse: 0.0790157\n",
      "[650]\ttraining's rmse: 0.081575\tvalid_1's rmse: 0.0790171\n",
      "[675]\ttraining's rmse: 0.0815374\tvalid_1's rmse: 0.0790088\n",
      "[700]\ttraining's rmse: 0.0815026\tvalid_1's rmse: 0.079005\n",
      "[725]\ttraining's rmse: 0.0814692\tvalid_1's rmse: 0.0790147\n",
      "[750]\ttraining's rmse: 0.0814378\tvalid_1's rmse: 0.079027\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 0.0814897\tvalid_1's rmse: 0.0790022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0826366\tvalid_1's rmse: 0.0848193\n",
      "[50]\ttraining's rmse: 0.0825151\tvalid_1's rmse: 0.0847701\n",
      "[75]\ttraining's rmse: 0.0823923\tvalid_1's rmse: 0.0847232\n",
      "[100]\ttraining's rmse: 0.0822736\tvalid_1's rmse: 0.0846799\n",
      "[125]\ttraining's rmse: 0.0821559\tvalid_1's rmse: 0.0846369\n",
      "[150]\ttraining's rmse: 0.0820487\tvalid_1's rmse: 0.0845948\n",
      "[175]\ttraining's rmse: 0.081961\tvalid_1's rmse: 0.0845613\n",
      "[200]\ttraining's rmse: 0.0818676\tvalid_1's rmse: 0.0845274\n",
      "[225]\ttraining's rmse: 0.0817767\tvalid_1's rmse: 0.0844936\n",
      "[250]\ttraining's rmse: 0.0816992\tvalid_1's rmse: 0.0844637\n",
      "[275]\ttraining's rmse: 0.0816246\tvalid_1's rmse: 0.0844365\n",
      "[300]\ttraining's rmse: 0.0815524\tvalid_1's rmse: 0.0844111\n",
      "[325]\ttraining's rmse: 0.0814789\tvalid_1's rmse: 0.0843857\n",
      "[350]\ttraining's rmse: 0.0814092\tvalid_1's rmse: 0.0843618\n",
      "[375]\ttraining's rmse: 0.0813514\tvalid_1's rmse: 0.0843429\n",
      "[400]\ttraining's rmse: 0.0812875\tvalid_1's rmse: 0.0843235\n",
      "[425]\ttraining's rmse: 0.08123\tvalid_1's rmse: 0.0843058\n",
      "[450]\ttraining's rmse: 0.081175\tvalid_1's rmse: 0.0842872\n",
      "[475]\ttraining's rmse: 0.0811291\tvalid_1's rmse: 0.0842711\n",
      "[500]\ttraining's rmse: 0.0810865\tvalid_1's rmse: 0.0842559\n",
      "[525]\ttraining's rmse: 0.0810359\tvalid_1's rmse: 0.0842408\n",
      "[550]\ttraining's rmse: 0.0809904\tvalid_1's rmse: 0.0842259\n",
      "[575]\ttraining's rmse: 0.0809454\tvalid_1's rmse: 0.0842128\n",
      "[600]\ttraining's rmse: 0.0809029\tvalid_1's rmse: 0.0842003\n",
      "[625]\ttraining's rmse: 0.0808669\tvalid_1's rmse: 0.084189\n",
      "[650]\ttraining's rmse: 0.0808245\tvalid_1's rmse: 0.0841772\n",
      "[675]\ttraining's rmse: 0.0807802\tvalid_1's rmse: 0.0841652\n",
      "[700]\ttraining's rmse: 0.0807437\tvalid_1's rmse: 0.084154\n",
      "[725]\ttraining's rmse: 0.0807086\tvalid_1's rmse: 0.0841447\n",
      "[750]\ttraining's rmse: 0.0806754\tvalid_1's rmse: 0.0841362\n",
      "[775]\ttraining's rmse: 0.0806483\tvalid_1's rmse: 0.0841273\n",
      "[800]\ttraining's rmse: 0.0806149\tvalid_1's rmse: 0.0841197\n",
      "[825]\ttraining's rmse: 0.0805867\tvalid_1's rmse: 0.0841121\n",
      "[850]\ttraining's rmse: 0.0805548\tvalid_1's rmse: 0.0841057\n",
      "[875]\ttraining's rmse: 0.0805295\tvalid_1's rmse: 0.0840993\n",
      "[900]\ttraining's rmse: 0.0805002\tvalid_1's rmse: 0.0840929\n",
      "[925]\ttraining's rmse: 0.0804768\tvalid_1's rmse: 0.0840864\n",
      "[950]\ttraining's rmse: 0.0804522\tvalid_1's rmse: 0.0840808\n",
      "[975]\ttraining's rmse: 0.080429\tvalid_1's rmse: 0.0840761\n",
      "[1000]\ttraining's rmse: 0.0804056\tvalid_1's rmse: 0.0840711\n",
      "[1025]\ttraining's rmse: 0.0803847\tvalid_1's rmse: 0.0840648\n",
      "[1050]\ttraining's rmse: 0.0803631\tvalid_1's rmse: 0.0840595\n",
      "[1075]\ttraining's rmse: 0.0803408\tvalid_1's rmse: 0.0840549\n",
      "[1100]\ttraining's rmse: 0.0803212\tvalid_1's rmse: 0.0840499\n",
      "[1125]\ttraining's rmse: 0.0803039\tvalid_1's rmse: 0.0840455\n",
      "[1150]\ttraining's rmse: 0.080287\tvalid_1's rmse: 0.0840413\n",
      "[1175]\ttraining's rmse: 0.0802695\tvalid_1's rmse: 0.0840383\n",
      "[1200]\ttraining's rmse: 0.0802539\tvalid_1's rmse: 0.0840345\n",
      "[1225]\ttraining's rmse: 0.0802403\tvalid_1's rmse: 0.0840311\n",
      "[1250]\ttraining's rmse: 0.0802235\tvalid_1's rmse: 0.0840272\n",
      "[1275]\ttraining's rmse: 0.0802087\tvalid_1's rmse: 0.0840242\n",
      "[1300]\ttraining's rmse: 0.0801947\tvalid_1's rmse: 0.0840206\n",
      "[1325]\ttraining's rmse: 0.0801825\tvalid_1's rmse: 0.0840166\n",
      "[1350]\ttraining's rmse: 0.0801688\tvalid_1's rmse: 0.0840132\n",
      "[1375]\ttraining's rmse: 0.0801552\tvalid_1's rmse: 0.0840109\n",
      "[1400]\ttraining's rmse: 0.0801458\tvalid_1's rmse: 0.0840074\n",
      "[1425]\ttraining's rmse: 0.0801318\tvalid_1's rmse: 0.0840044\n",
      "[1450]\ttraining's rmse: 0.0801183\tvalid_1's rmse: 0.0840032\n",
      "[1475]\ttraining's rmse: 0.0801085\tvalid_1's rmse: 0.0839992\n",
      "[1500]\ttraining's rmse: 0.0800991\tvalid_1's rmse: 0.0839957\n",
      "[1525]\ttraining's rmse: 0.0800873\tvalid_1's rmse: 0.0839936\n",
      "[1550]\ttraining's rmse: 0.0800796\tvalid_1's rmse: 0.0839912\n",
      "[1575]\ttraining's rmse: 0.0800727\tvalid_1's rmse: 0.0839898\n",
      "[1600]\ttraining's rmse: 0.0800647\tvalid_1's rmse: 0.0839873\n",
      "[1625]\ttraining's rmse: 0.080059\tvalid_1's rmse: 0.0839841\n",
      "[1650]\ttraining's rmse: 0.0800498\tvalid_1's rmse: 0.0839818\n",
      "[1675]\ttraining's rmse: 0.0800451\tvalid_1's rmse: 0.0839807\n",
      "[1700]\ttraining's rmse: 0.0800398\tvalid_1's rmse: 0.0839782\n",
      "[1725]\ttraining's rmse: 0.0800349\tvalid_1's rmse: 0.0839767\n",
      "[1750]\ttraining's rmse: 0.0800291\tvalid_1's rmse: 0.0839747\n",
      "[1775]\ttraining's rmse: 0.0800234\tvalid_1's rmse: 0.0839724\n",
      "[1800]\ttraining's rmse: 0.0800178\tvalid_1's rmse: 0.0839707\n",
      "[1825]\ttraining's rmse: 0.0800132\tvalid_1's rmse: 0.0839698\n",
      "[1850]\ttraining's rmse: 0.080009\tvalid_1's rmse: 0.0839675\n",
      "[1875]\ttraining's rmse: 0.0800032\tvalid_1's rmse: 0.0839663\n",
      "[1900]\ttraining's rmse: 0.079998\tvalid_1's rmse: 0.0839661\n",
      "[1925]\ttraining's rmse: 0.079993\tvalid_1's rmse: 0.0839647\n",
      "[1950]\ttraining's rmse: 0.0799888\tvalid_1's rmse: 0.0839634\n",
      "[1975]\ttraining's rmse: 0.0799849\tvalid_1's rmse: 0.0839617\n",
      "[2000]\ttraining's rmse: 0.0799801\tvalid_1's rmse: 0.0839608\n",
      "[2025]\ttraining's rmse: 0.0799763\tvalid_1's rmse: 0.0839597\n",
      "[2050]\ttraining's rmse: 0.0799728\tvalid_1's rmse: 0.0839578\n",
      "[2075]\ttraining's rmse: 0.0799701\tvalid_1's rmse: 0.0839563\n",
      "[2100]\ttraining's rmse: 0.0799676\tvalid_1's rmse: 0.0839552\n",
      "[2125]\ttraining's rmse: 0.0799647\tvalid_1's rmse: 0.0839543\n",
      "[2150]\ttraining's rmse: 0.0799614\tvalid_1's rmse: 0.0839526\n",
      "[2175]\ttraining's rmse: 0.0799586\tvalid_1's rmse: 0.0839518\n",
      "[2200]\ttraining's rmse: 0.0799547\tvalid_1's rmse: 0.0839513\n",
      "[2225]\ttraining's rmse: 0.0799526\tvalid_1's rmse: 0.0839512\n",
      "[2250]\ttraining's rmse: 0.0799498\tvalid_1's rmse: 0.0839498\n",
      "[2275]\ttraining's rmse: 0.0799463\tvalid_1's rmse: 0.0839488\n",
      "[2300]\ttraining's rmse: 0.0799436\tvalid_1's rmse: 0.0839483\n",
      "[2325]\ttraining's rmse: 0.0799419\tvalid_1's rmse: 0.0839469\n",
      "[2350]\ttraining's rmse: 0.0799397\tvalid_1's rmse: 0.0839458\n",
      "[2375]\ttraining's rmse: 0.0799375\tvalid_1's rmse: 0.0839447\n",
      "[2400]\ttraining's rmse: 0.0799358\tvalid_1's rmse: 0.0839443\n",
      "[2425]\ttraining's rmse: 0.0799342\tvalid_1's rmse: 0.0839441\n",
      "[2450]\ttraining's rmse: 0.0799325\tvalid_1's rmse: 0.0839432\n",
      "[2475]\ttraining's rmse: 0.0799302\tvalid_1's rmse: 0.0839423\n",
      "[2500]\ttraining's rmse: 0.0799281\tvalid_1's rmse: 0.083942\n",
      "[2525]\ttraining's rmse: 0.0799266\tvalid_1's rmse: 0.0839417\n",
      "[2550]\ttraining's rmse: 0.079924\tvalid_1's rmse: 0.0839414\n",
      "[2575]\ttraining's rmse: 0.0799219\tvalid_1's rmse: 0.0839411\n",
      "[2600]\ttraining's rmse: 0.0799197\tvalid_1's rmse: 0.083941\n",
      "[2625]\ttraining's rmse: 0.0799192\tvalid_1's rmse: 0.0839403\n",
      "[2650]\ttraining's rmse: 0.0799177\tvalid_1's rmse: 0.0839386\n",
      "[2675]\ttraining's rmse: 0.0799164\tvalid_1's rmse: 0.083938\n",
      "[2700]\ttraining's rmse: 0.0799155\tvalid_1's rmse: 0.0839377\n",
      "[2725]\ttraining's rmse: 0.0799143\tvalid_1's rmse: 0.0839374\n",
      "[2750]\ttraining's rmse: 0.079913\tvalid_1's rmse: 0.0839371\n",
      "[2775]\ttraining's rmse: 0.0799113\tvalid_1's rmse: 0.0839368\n",
      "[2800]\ttraining's rmse: 0.0799103\tvalid_1's rmse: 0.0839372\n",
      "[2825]\ttraining's rmse: 0.0799082\tvalid_1's rmse: 0.0839368\n",
      "Early stopping, best iteration is:\n",
      "[2779]\ttraining's rmse: 0.0799108\tvalid_1's rmse: 0.0839368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0826886\tvalid_1's rmse: 0.0847308\n",
      "[50]\ttraining's rmse: 0.0825752\tvalid_1's rmse: 0.0846788\n",
      "[75]\ttraining's rmse: 0.0824594\tvalid_1's rmse: 0.0846285\n",
      "[100]\ttraining's rmse: 0.082355\tvalid_1's rmse: 0.0845836\n",
      "[125]\ttraining's rmse: 0.0822468\tvalid_1's rmse: 0.0845387\n",
      "[150]\ttraining's rmse: 0.0821501\tvalid_1's rmse: 0.0844968\n",
      "[175]\ttraining's rmse: 0.0820693\tvalid_1's rmse: 0.0844626\n",
      "[200]\ttraining's rmse: 0.0819791\tvalid_1's rmse: 0.0844275\n",
      "[225]\ttraining's rmse: 0.0818922\tvalid_1's rmse: 0.0843943\n",
      "[250]\ttraining's rmse: 0.0818192\tvalid_1's rmse: 0.0843644\n",
      "[275]\ttraining's rmse: 0.0817533\tvalid_1's rmse: 0.0843378\n",
      "[300]\ttraining's rmse: 0.0816841\tvalid_1's rmse: 0.0843096\n",
      "[325]\ttraining's rmse: 0.0816118\tvalid_1's rmse: 0.0842824\n",
      "[350]\ttraining's rmse: 0.0815465\tvalid_1's rmse: 0.0842606\n",
      "[375]\ttraining's rmse: 0.0814923\tvalid_1's rmse: 0.0842394\n",
      "[400]\ttraining's rmse: 0.0814343\tvalid_1's rmse: 0.0842194\n",
      "[425]\ttraining's rmse: 0.08138\tvalid_1's rmse: 0.0841989\n",
      "[450]\ttraining's rmse: 0.0813295\tvalid_1's rmse: 0.0841803\n",
      "[475]\ttraining's rmse: 0.0812829\tvalid_1's rmse: 0.0841639\n",
      "[500]\ttraining's rmse: 0.0812427\tvalid_1's rmse: 0.0841473\n",
      "[525]\ttraining's rmse: 0.0811932\tvalid_1's rmse: 0.0841317\n",
      "[550]\ttraining's rmse: 0.0811481\tvalid_1's rmse: 0.0841171\n",
      "[575]\ttraining's rmse: 0.0811047\tvalid_1's rmse: 0.084105\n",
      "[600]\ttraining's rmse: 0.0810639\tvalid_1's rmse: 0.0840923\n",
      "[625]\ttraining's rmse: 0.0810303\tvalid_1's rmse: 0.084081\n",
      "[650]\ttraining's rmse: 0.0809888\tvalid_1's rmse: 0.0840683\n",
      "[675]\ttraining's rmse: 0.0809472\tvalid_1's rmse: 0.0840564\n",
      "[700]\ttraining's rmse: 0.0809113\tvalid_1's rmse: 0.0840463\n",
      "[725]\ttraining's rmse: 0.0808775\tvalid_1's rmse: 0.0840368\n",
      "[750]\ttraining's rmse: 0.0808456\tvalid_1's rmse: 0.0840279\n",
      "[775]\ttraining's rmse: 0.0808187\tvalid_1's rmse: 0.0840188\n",
      "[800]\ttraining's rmse: 0.080786\tvalid_1's rmse: 0.0840119\n",
      "[825]\ttraining's rmse: 0.0807579\tvalid_1's rmse: 0.0840035\n",
      "[850]\ttraining's rmse: 0.0807303\tvalid_1's rmse: 0.0839971\n",
      "[875]\ttraining's rmse: 0.080704\tvalid_1's rmse: 0.0839899\n",
      "[900]\ttraining's rmse: 0.0806759\tvalid_1's rmse: 0.083982\n",
      "[925]\ttraining's rmse: 0.0806517\tvalid_1's rmse: 0.0839757\n",
      "[950]\ttraining's rmse: 0.0806283\tvalid_1's rmse: 0.0839705\n",
      "[975]\ttraining's rmse: 0.0806058\tvalid_1's rmse: 0.0839643\n",
      "[1000]\ttraining's rmse: 0.0805858\tvalid_1's rmse: 0.0839593\n",
      "[1025]\ttraining's rmse: 0.0805619\tvalid_1's rmse: 0.0839543\n",
      "[1050]\ttraining's rmse: 0.0805419\tvalid_1's rmse: 0.0839498\n",
      "[1075]\ttraining's rmse: 0.0805229\tvalid_1's rmse: 0.0839458\n",
      "[1100]\ttraining's rmse: 0.080506\tvalid_1's rmse: 0.0839414\n",
      "[1125]\ttraining's rmse: 0.0804868\tvalid_1's rmse: 0.0839371\n",
      "[1150]\ttraining's rmse: 0.0804667\tvalid_1's rmse: 0.083933\n",
      "[1175]\ttraining's rmse: 0.0804502\tvalid_1's rmse: 0.0839293\n",
      "[1200]\ttraining's rmse: 0.0804347\tvalid_1's rmse: 0.0839257\n",
      "[1225]\ttraining's rmse: 0.0804194\tvalid_1's rmse: 0.0839221\n",
      "[1250]\ttraining's rmse: 0.0804059\tvalid_1's rmse: 0.0839195\n",
      "[1275]\ttraining's rmse: 0.0803907\tvalid_1's rmse: 0.0839174\n",
      "[1300]\ttraining's rmse: 0.080378\tvalid_1's rmse: 0.0839143\n",
      "[1325]\ttraining's rmse: 0.0803636\tvalid_1's rmse: 0.0839118\n",
      "[1350]\ttraining's rmse: 0.0803503\tvalid_1's rmse: 0.0839094\n",
      "[1375]\ttraining's rmse: 0.0803377\tvalid_1's rmse: 0.0839073\n",
      "[1400]\ttraining's rmse: 0.0803289\tvalid_1's rmse: 0.0839049\n",
      "[1425]\ttraining's rmse: 0.0803187\tvalid_1's rmse: 0.0839032\n",
      "[1450]\ttraining's rmse: 0.0803066\tvalid_1's rmse: 0.0839019\n",
      "[1475]\ttraining's rmse: 0.0802922\tvalid_1's rmse: 0.0839004\n",
      "[1500]\ttraining's rmse: 0.0802829\tvalid_1's rmse: 0.083899\n",
      "[1525]\ttraining's rmse: 0.0802741\tvalid_1's rmse: 0.0838972\n",
      "[1550]\ttraining's rmse: 0.0802667\tvalid_1's rmse: 0.0838961\n",
      "[1575]\ttraining's rmse: 0.0802593\tvalid_1's rmse: 0.0838942\n",
      "[1600]\ttraining's rmse: 0.0802522\tvalid_1's rmse: 0.0838932\n",
      "[1625]\ttraining's rmse: 0.0802442\tvalid_1's rmse: 0.0838914\n",
      "[1650]\ttraining's rmse: 0.0802366\tvalid_1's rmse: 0.0838904\n",
      "[1675]\ttraining's rmse: 0.080232\tvalid_1's rmse: 0.0838892\n",
      "[1700]\ttraining's rmse: 0.0802263\tvalid_1's rmse: 0.0838877\n",
      "[1725]\ttraining's rmse: 0.0802204\tvalid_1's rmse: 0.0838862\n",
      "[1750]\ttraining's rmse: 0.0802139\tvalid_1's rmse: 0.0838859\n",
      "[1775]\ttraining's rmse: 0.080206\tvalid_1's rmse: 0.0838847\n",
      "[1800]\ttraining's rmse: 0.0802007\tvalid_1's rmse: 0.0838836\n",
      "[1825]\ttraining's rmse: 0.0801957\tvalid_1's rmse: 0.0838823\n",
      "[1850]\ttraining's rmse: 0.0801908\tvalid_1's rmse: 0.0838811\n",
      "[1875]\ttraining's rmse: 0.0801833\tvalid_1's rmse: 0.0838804\n",
      "[1900]\ttraining's rmse: 0.0801792\tvalid_1's rmse: 0.0838802\n",
      "[1925]\ttraining's rmse: 0.0801752\tvalid_1's rmse: 0.0838796\n",
      "[1950]\ttraining's rmse: 0.0801705\tvalid_1's rmse: 0.0838787\n",
      "[1975]\ttraining's rmse: 0.0801673\tvalid_1's rmse: 0.083878\n",
      "[2000]\ttraining's rmse: 0.0801636\tvalid_1's rmse: 0.0838775\n",
      "[2025]\ttraining's rmse: 0.0801595\tvalid_1's rmse: 0.0838767\n",
      "[2050]\ttraining's rmse: 0.0801565\tvalid_1's rmse: 0.0838762\n",
      "[2075]\ttraining's rmse: 0.080153\tvalid_1's rmse: 0.0838757\n",
      "[2100]\ttraining's rmse: 0.080149\tvalid_1's rmse: 0.083875\n",
      "[2125]\ttraining's rmse: 0.0801452\tvalid_1's rmse: 0.0838748\n",
      "[2150]\ttraining's rmse: 0.0801427\tvalid_1's rmse: 0.0838745\n",
      "[2175]\ttraining's rmse: 0.0801397\tvalid_1's rmse: 0.0838745\n",
      "[2200]\ttraining's rmse: 0.0801382\tvalid_1's rmse: 0.0838741\n",
      "[2225]\ttraining's rmse: 0.0801358\tvalid_1's rmse: 0.0838736\n",
      "[2250]\ttraining's rmse: 0.0801332\tvalid_1's rmse: 0.0838733\n",
      "[2275]\ttraining's rmse: 0.0801298\tvalid_1's rmse: 0.0838727\n",
      "[2300]\ttraining's rmse: 0.0801272\tvalid_1's rmse: 0.0838724\n",
      "[2325]\ttraining's rmse: 0.0801254\tvalid_1's rmse: 0.0838723\n",
      "[2350]\ttraining's rmse: 0.0801237\tvalid_1's rmse: 0.0838722\n",
      "[2375]\ttraining's rmse: 0.0801214\tvalid_1's rmse: 0.0838717\n",
      "[2400]\ttraining's rmse: 0.0801187\tvalid_1's rmse: 0.0838717\n",
      "[2425]\ttraining's rmse: 0.0801167\tvalid_1's rmse: 0.0838714\n",
      "[2450]\ttraining's rmse: 0.0801141\tvalid_1's rmse: 0.083871\n",
      "[2475]\ttraining's rmse: 0.0801113\tvalid_1's rmse: 0.0838712\n",
      "[2500]\ttraining's rmse: 0.0801091\tvalid_1's rmse: 0.0838712\n",
      "[2525]\ttraining's rmse: 0.0801068\tvalid_1's rmse: 0.083871\n",
      "Early stopping, best iteration is:\n",
      "[2485]\ttraining's rmse: 0.0801107\tvalid_1's rmse: 0.083871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0846614\tvalid_1's rmse: 0.0807306\n",
      "[50]\ttraining's rmse: 0.0845556\tvalid_1's rmse: 0.0806862\n",
      "[75]\ttraining's rmse: 0.0844439\tvalid_1's rmse: 0.0806402\n",
      "[100]\ttraining's rmse: 0.0843433\tvalid_1's rmse: 0.080601\n",
      "[125]\ttraining's rmse: 0.0842417\tvalid_1's rmse: 0.0805614\n",
      "[150]\ttraining's rmse: 0.084146\tvalid_1's rmse: 0.0805247\n",
      "[175]\ttraining's rmse: 0.0840672\tvalid_1's rmse: 0.0804933\n",
      "[200]\ttraining's rmse: 0.0839794\tvalid_1's rmse: 0.0804618\n",
      "[225]\ttraining's rmse: 0.0838964\tvalid_1's rmse: 0.0804327\n",
      "[250]\ttraining's rmse: 0.0838277\tvalid_1's rmse: 0.0804059\n",
      "[275]\ttraining's rmse: 0.0837657\tvalid_1's rmse: 0.0803828\n",
      "[300]\ttraining's rmse: 0.0837016\tvalid_1's rmse: 0.0803601\n",
      "[325]\ttraining's rmse: 0.0836363\tvalid_1's rmse: 0.0803384\n",
      "[350]\ttraining's rmse: 0.083572\tvalid_1's rmse: 0.0803173\n",
      "[375]\ttraining's rmse: 0.08352\tvalid_1's rmse: 0.0803066\n",
      "[400]\ttraining's rmse: 0.0834638\tvalid_1's rmse: 0.08029\n",
      "[425]\ttraining's rmse: 0.0834095\tvalid_1's rmse: 0.0802838\n",
      "[450]\ttraining's rmse: 0.0833617\tvalid_1's rmse: 0.0802723\n",
      "[475]\ttraining's rmse: 0.0833174\tvalid_1's rmse: 0.080259\n",
      "[500]\ttraining's rmse: 0.0832771\tvalid_1's rmse: 0.0802455\n",
      "[525]\ttraining's rmse: 0.0832259\tvalid_1's rmse: 0.0802313\n",
      "[550]\ttraining's rmse: 0.0831784\tvalid_1's rmse: 0.0802227\n",
      "[575]\ttraining's rmse: 0.0831359\tvalid_1's rmse: 0.0802146\n",
      "[600]\ttraining's rmse: 0.0830927\tvalid_1's rmse: 0.0802055\n",
      "[625]\ttraining's rmse: 0.0830597\tvalid_1's rmse: 0.0801976\n",
      "[650]\ttraining's rmse: 0.0830182\tvalid_1's rmse: 0.0801974\n",
      "[675]\ttraining's rmse: 0.0829758\tvalid_1's rmse: 0.080196\n",
      "[700]\ttraining's rmse: 0.0829391\tvalid_1's rmse: 0.0801882\n",
      "[725]\ttraining's rmse: 0.0829055\tvalid_1's rmse: 0.0801887\n",
      "[750]\ttraining's rmse: 0.0828725\tvalid_1's rmse: 0.080186\n",
      "[775]\ttraining's rmse: 0.0828449\tvalid_1's rmse: 0.0801802\n",
      "[800]\ttraining's rmse: 0.0828109\tvalid_1's rmse: 0.0801803\n",
      "[825]\ttraining's rmse: 0.0827817\tvalid_1's rmse: 0.0801777\n",
      "[850]\ttraining's rmse: 0.0827512\tvalid_1's rmse: 0.0801726\n",
      "[875]\ttraining's rmse: 0.0827239\tvalid_1's rmse: 0.0801676\n",
      "[900]\ttraining's rmse: 0.0826947\tvalid_1's rmse: 0.0801712\n",
      "[925]\ttraining's rmse: 0.082666\tvalid_1's rmse: 0.080171\n",
      "Early stopping, best iteration is:\n",
      "[889]\ttraining's rmse: 0.0827067\tvalid_1's rmse: 0.080165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0818236\tvalid_1's rmse: 0.0842714\n",
      "[50]\ttraining's rmse: 0.0816996\tvalid_1's rmse: 0.0842191\n",
      "[75]\ttraining's rmse: 0.0815769\tvalid_1's rmse: 0.0841687\n",
      "[100]\ttraining's rmse: 0.081463\tvalid_1's rmse: 0.0841254\n",
      "[125]\ttraining's rmse: 0.0813492\tvalid_1's rmse: 0.0840813\n",
      "[150]\ttraining's rmse: 0.0812472\tvalid_1's rmse: 0.084041\n",
      "[175]\ttraining's rmse: 0.0811616\tvalid_1's rmse: 0.084006\n",
      "[200]\ttraining's rmse: 0.0810702\tvalid_1's rmse: 0.0839711\n",
      "[225]\ttraining's rmse: 0.0809812\tvalid_1's rmse: 0.0839363\n",
      "[250]\ttraining's rmse: 0.0809032\tvalid_1's rmse: 0.0839075\n",
      "[275]\ttraining's rmse: 0.0808308\tvalid_1's rmse: 0.0838782\n",
      "[300]\ttraining's rmse: 0.0807594\tvalid_1's rmse: 0.0838507\n",
      "[325]\ttraining's rmse: 0.0806883\tvalid_1's rmse: 0.0838254\n",
      "[350]\ttraining's rmse: 0.0806211\tvalid_1's rmse: 0.0838\n",
      "[375]\ttraining's rmse: 0.0805676\tvalid_1's rmse: 0.0837796\n",
      "[400]\ttraining's rmse: 0.0805054\tvalid_1's rmse: 0.0837587\n",
      "[425]\ttraining's rmse: 0.0804515\tvalid_1's rmse: 0.0837395\n",
      "[450]\ttraining's rmse: 0.0803995\tvalid_1's rmse: 0.0837207\n",
      "[475]\ttraining's rmse: 0.0803529\tvalid_1's rmse: 0.0837035\n",
      "[500]\ttraining's rmse: 0.0803122\tvalid_1's rmse: 0.0836877\n",
      "[525]\ttraining's rmse: 0.0802594\tvalid_1's rmse: 0.0836726\n",
      "[550]\ttraining's rmse: 0.0802123\tvalid_1's rmse: 0.0836563\n",
      "[575]\ttraining's rmse: 0.0801696\tvalid_1's rmse: 0.0836435\n",
      "[600]\ttraining's rmse: 0.0801264\tvalid_1's rmse: 0.0836303\n",
      "[625]\ttraining's rmse: 0.0800946\tvalid_1's rmse: 0.0836193\n",
      "[650]\ttraining's rmse: 0.0800557\tvalid_1's rmse: 0.0836076\n",
      "[675]\ttraining's rmse: 0.0800182\tvalid_1's rmse: 0.0835961\n",
      "[700]\ttraining's rmse: 0.0799826\tvalid_1's rmse: 0.0835852\n",
      "[725]\ttraining's rmse: 0.0799497\tvalid_1's rmse: 0.0835765\n",
      "[750]\ttraining's rmse: 0.0799177\tvalid_1's rmse: 0.0835675\n",
      "[775]\ttraining's rmse: 0.0798924\tvalid_1's rmse: 0.0835569\n",
      "[800]\ttraining's rmse: 0.0798571\tvalid_1's rmse: 0.0835488\n",
      "[825]\ttraining's rmse: 0.0798297\tvalid_1's rmse: 0.0835392\n",
      "[850]\ttraining's rmse: 0.0797998\tvalid_1's rmse: 0.0835321\n",
      "[875]\ttraining's rmse: 0.0797751\tvalid_1's rmse: 0.0835247\n",
      "[900]\ttraining's rmse: 0.0797478\tvalid_1's rmse: 0.0835175\n",
      "[925]\ttraining's rmse: 0.079723\tvalid_1's rmse: 0.0835106\n",
      "[950]\ttraining's rmse: 0.0796997\tvalid_1's rmse: 0.0835032\n",
      "[975]\ttraining's rmse: 0.0796741\tvalid_1's rmse: 0.0834974\n",
      "[1000]\ttraining's rmse: 0.0796515\tvalid_1's rmse: 0.0834918\n",
      "[1025]\ttraining's rmse: 0.0796283\tvalid_1's rmse: 0.0834848\n",
      "[1050]\ttraining's rmse: 0.0796099\tvalid_1's rmse: 0.0834784\n",
      "[1075]\ttraining's rmse: 0.0795909\tvalid_1's rmse: 0.0834752\n",
      "[1100]\ttraining's rmse: 0.0795722\tvalid_1's rmse: 0.0834697\n",
      "[1125]\ttraining's rmse: 0.0795555\tvalid_1's rmse: 0.0834641\n",
      "[1150]\ttraining's rmse: 0.0795376\tvalid_1's rmse: 0.0834601\n",
      "[1175]\ttraining's rmse: 0.0795214\tvalid_1's rmse: 0.0834572\n",
      "[1200]\ttraining's rmse: 0.0795069\tvalid_1's rmse: 0.0834526\n",
      "[1225]\ttraining's rmse: 0.0794927\tvalid_1's rmse: 0.083449\n",
      "[1250]\ttraining's rmse: 0.0794785\tvalid_1's rmse: 0.0834443\n",
      "[1275]\ttraining's rmse: 0.0794627\tvalid_1's rmse: 0.0834399\n",
      "[1300]\ttraining's rmse: 0.0794525\tvalid_1's rmse: 0.0834362\n",
      "[1325]\ttraining's rmse: 0.0794381\tvalid_1's rmse: 0.083433\n",
      "[1350]\ttraining's rmse: 0.079424\tvalid_1's rmse: 0.0834307\n",
      "[1375]\ttraining's rmse: 0.0794113\tvalid_1's rmse: 0.0834281\n",
      "[1400]\ttraining's rmse: 0.079402\tvalid_1's rmse: 0.0834247\n",
      "[1425]\ttraining's rmse: 0.0793894\tvalid_1's rmse: 0.0834215\n",
      "[1450]\ttraining's rmse: 0.0793778\tvalid_1's rmse: 0.0834197\n",
      "[1475]\ttraining's rmse: 0.0793674\tvalid_1's rmse: 0.0834169\n",
      "[1500]\ttraining's rmse: 0.0793589\tvalid_1's rmse: 0.0834149\n",
      "[1525]\ttraining's rmse: 0.0793511\tvalid_1's rmse: 0.0834116\n",
      "[1550]\ttraining's rmse: 0.0793434\tvalid_1's rmse: 0.0834098\n",
      "[1575]\ttraining's rmse: 0.0793346\tvalid_1's rmse: 0.0834074\n",
      "[1600]\ttraining's rmse: 0.0793285\tvalid_1's rmse: 0.0834053\n",
      "[1625]\ttraining's rmse: 0.0793207\tvalid_1's rmse: 0.0834036\n",
      "[1650]\ttraining's rmse: 0.0793145\tvalid_1's rmse: 0.0834023\n",
      "[1675]\ttraining's rmse: 0.0793081\tvalid_1's rmse: 0.083401\n",
      "[1700]\ttraining's rmse: 0.0793031\tvalid_1's rmse: 0.083398\n",
      "[1725]\ttraining's rmse: 0.0792978\tvalid_1's rmse: 0.0833967\n",
      "[1750]\ttraining's rmse: 0.079291\tvalid_1's rmse: 0.0833954\n",
      "[1775]\ttraining's rmse: 0.0792846\tvalid_1's rmse: 0.0833938\n",
      "[1800]\ttraining's rmse: 0.079277\tvalid_1's rmse: 0.0833928\n",
      "[1825]\ttraining's rmse: 0.0792705\tvalid_1's rmse: 0.0833911\n",
      "[1850]\ttraining's rmse: 0.0792654\tvalid_1's rmse: 0.0833894\n",
      "[1875]\ttraining's rmse: 0.0792594\tvalid_1's rmse: 0.0833881\n",
      "[1900]\ttraining's rmse: 0.079255\tvalid_1's rmse: 0.0833866\n",
      "[1925]\ttraining's rmse: 0.0792507\tvalid_1's rmse: 0.0833848\n",
      "[1950]\ttraining's rmse: 0.0792468\tvalid_1's rmse: 0.0833824\n",
      "[1975]\ttraining's rmse: 0.0792429\tvalid_1's rmse: 0.0833811\n",
      "[2000]\ttraining's rmse: 0.0792387\tvalid_1's rmse: 0.0833794\n",
      "[2025]\ttraining's rmse: 0.0792356\tvalid_1's rmse: 0.083378\n",
      "[2050]\ttraining's rmse: 0.0792321\tvalid_1's rmse: 0.0833777\n",
      "[2075]\ttraining's rmse: 0.0792294\tvalid_1's rmse: 0.0833772\n",
      "[2100]\ttraining's rmse: 0.0792257\tvalid_1's rmse: 0.0833759\n",
      "[2125]\ttraining's rmse: 0.0792228\tvalid_1's rmse: 0.0833751\n",
      "[2150]\ttraining's rmse: 0.0792197\tvalid_1's rmse: 0.0833745\n",
      "[2175]\ttraining's rmse: 0.079217\tvalid_1's rmse: 0.083375\n",
      "[2200]\ttraining's rmse: 0.0792143\tvalid_1's rmse: 0.0833743\n",
      "[2225]\ttraining's rmse: 0.0792129\tvalid_1's rmse: 0.0833738\n",
      "[2250]\ttraining's rmse: 0.0792098\tvalid_1's rmse: 0.0833731\n",
      "[2275]\ttraining's rmse: 0.0792077\tvalid_1's rmse: 0.0833724\n",
      "[2300]\ttraining's rmse: 0.0792052\tvalid_1's rmse: 0.0833717\n",
      "[2325]\ttraining's rmse: 0.0792024\tvalid_1's rmse: 0.0833711\n",
      "[2350]\ttraining's rmse: 0.0792006\tvalid_1's rmse: 0.08337\n",
      "[2375]\ttraining's rmse: 0.0791982\tvalid_1's rmse: 0.0833695\n",
      "[2400]\ttraining's rmse: 0.0791957\tvalid_1's rmse: 0.0833693\n",
      "[2425]\ttraining's rmse: 0.0791935\tvalid_1's rmse: 0.0833689\n",
      "[2450]\ttraining's rmse: 0.0791917\tvalid_1's rmse: 0.0833691\n",
      "[2475]\ttraining's rmse: 0.0791869\tvalid_1's rmse: 0.0833681\n",
      "[2500]\ttraining's rmse: 0.0791844\tvalid_1's rmse: 0.0833671\n",
      "[2525]\ttraining's rmse: 0.0791827\tvalid_1's rmse: 0.0833664\n",
      "[2550]\ttraining's rmse: 0.0791801\tvalid_1's rmse: 0.0833658\n",
      "[2575]\ttraining's rmse: 0.0791784\tvalid_1's rmse: 0.0833659\n",
      "[2600]\ttraining's rmse: 0.0791771\tvalid_1's rmse: 0.0833656\n",
      "[2625]\ttraining's rmse: 0.0791762\tvalid_1's rmse: 0.0833652\n",
      "[2650]\ttraining's rmse: 0.0791746\tvalid_1's rmse: 0.0833649\n",
      "[2675]\ttraining's rmse: 0.079172\tvalid_1's rmse: 0.0833634\n",
      "[2700]\ttraining's rmse: 0.0791703\tvalid_1's rmse: 0.0833636\n",
      "[2725]\ttraining's rmse: 0.0791692\tvalid_1's rmse: 0.0833632\n",
      "[2750]\ttraining's rmse: 0.0791686\tvalid_1's rmse: 0.0833633\n",
      "[2775]\ttraining's rmse: 0.0791672\tvalid_1's rmse: 0.0833634\n",
      "Early stopping, best iteration is:\n",
      "[2725]\ttraining's rmse: 0.0791692\tvalid_1's rmse: 0.0833632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0820762\tvalid_1's rmse: 0.0837881\n",
      "[50]\ttraining's rmse: 0.0819656\tvalid_1's rmse: 0.0837357\n",
      "[75]\ttraining's rmse: 0.0818525\tvalid_1's rmse: 0.0836849\n",
      "[100]\ttraining's rmse: 0.0817511\tvalid_1's rmse: 0.0836385\n",
      "[125]\ttraining's rmse: 0.0816439\tvalid_1's rmse: 0.0835924\n",
      "[150]\ttraining's rmse: 0.0815506\tvalid_1's rmse: 0.083551\n",
      "[175]\ttraining's rmse: 0.0814712\tvalid_1's rmse: 0.0835159\n",
      "[200]\ttraining's rmse: 0.0813843\tvalid_1's rmse: 0.0834804\n",
      "[225]\ttraining's rmse: 0.0813011\tvalid_1's rmse: 0.083447\n",
      "[250]\ttraining's rmse: 0.0812284\tvalid_1's rmse: 0.083418\n",
      "[275]\ttraining's rmse: 0.0811634\tvalid_1's rmse: 0.0833913\n",
      "[300]\ttraining's rmse: 0.0810963\tvalid_1's rmse: 0.0833648\n",
      "[325]\ttraining's rmse: 0.0810295\tvalid_1's rmse: 0.0833384\n",
      "[350]\ttraining's rmse: 0.0809644\tvalid_1's rmse: 0.0833151\n",
      "[375]\ttraining's rmse: 0.0809107\tvalid_1's rmse: 0.0832937\n",
      "[400]\ttraining's rmse: 0.0808549\tvalid_1's rmse: 0.0832749\n",
      "[425]\ttraining's rmse: 0.0808038\tvalid_1's rmse: 0.083256\n",
      "[450]\ttraining's rmse: 0.0807557\tvalid_1's rmse: 0.0832368\n",
      "[475]\ttraining's rmse: 0.0807093\tvalid_1's rmse: 0.0832202\n",
      "[500]\ttraining's rmse: 0.0806717\tvalid_1's rmse: 0.0832042\n",
      "[525]\ttraining's rmse: 0.080622\tvalid_1's rmse: 0.0831886\n",
      "[550]\ttraining's rmse: 0.080575\tvalid_1's rmse: 0.0831733\n",
      "[575]\ttraining's rmse: 0.0805313\tvalid_1's rmse: 0.0831604\n",
      "[600]\ttraining's rmse: 0.0804903\tvalid_1's rmse: 0.0831483\n",
      "[625]\ttraining's rmse: 0.080458\tvalid_1's rmse: 0.0831368\n",
      "[650]\ttraining's rmse: 0.0804186\tvalid_1's rmse: 0.0831256\n",
      "[675]\ttraining's rmse: 0.0803792\tvalid_1's rmse: 0.0831137\n",
      "[700]\ttraining's rmse: 0.0803448\tvalid_1's rmse: 0.083104\n",
      "[725]\ttraining's rmse: 0.0803113\tvalid_1's rmse: 0.0830941\n",
      "[750]\ttraining's rmse: 0.0802813\tvalid_1's rmse: 0.0830856\n",
      "[775]\ttraining's rmse: 0.0802551\tvalid_1's rmse: 0.0830773\n",
      "[800]\ttraining's rmse: 0.0802214\tvalid_1's rmse: 0.0830693\n",
      "[825]\ttraining's rmse: 0.0801929\tvalid_1's rmse: 0.0830612\n",
      "[850]\ttraining's rmse: 0.080165\tvalid_1's rmse: 0.0830544\n",
      "[875]\ttraining's rmse: 0.0801388\tvalid_1's rmse: 0.0830474\n",
      "[900]\ttraining's rmse: 0.080113\tvalid_1's rmse: 0.0830408\n",
      "[925]\ttraining's rmse: 0.0800874\tvalid_1's rmse: 0.0830345\n",
      "[950]\ttraining's rmse: 0.0800641\tvalid_1's rmse: 0.0830296\n",
      "[975]\ttraining's rmse: 0.0800416\tvalid_1's rmse: 0.0830241\n",
      "[1000]\ttraining's rmse: 0.0800203\tvalid_1's rmse: 0.0830186\n",
      "[1025]\ttraining's rmse: 0.0799947\tvalid_1's rmse: 0.0830138\n",
      "[1050]\ttraining's rmse: 0.0799751\tvalid_1's rmse: 0.0830091\n",
      "[1075]\ttraining's rmse: 0.0799539\tvalid_1's rmse: 0.0830052\n",
      "[1100]\ttraining's rmse: 0.0799385\tvalid_1's rmse: 0.0830005\n",
      "[1125]\ttraining's rmse: 0.0799206\tvalid_1's rmse: 0.0829963\n",
      "[1150]\ttraining's rmse: 0.0799033\tvalid_1's rmse: 0.0829923\n",
      "[1175]\ttraining's rmse: 0.0798868\tvalid_1's rmse: 0.0829897\n",
      "[1200]\ttraining's rmse: 0.0798731\tvalid_1's rmse: 0.0829866\n",
      "[1225]\ttraining's rmse: 0.0798585\tvalid_1's rmse: 0.0829835\n",
      "[1250]\ttraining's rmse: 0.0798449\tvalid_1's rmse: 0.0829808\n",
      "[1275]\ttraining's rmse: 0.0798304\tvalid_1's rmse: 0.0829791\n",
      "[1300]\ttraining's rmse: 0.0798192\tvalid_1's rmse: 0.0829764\n",
      "[1325]\ttraining's rmse: 0.0798054\tvalid_1's rmse: 0.0829738\n",
      "[1350]\ttraining's rmse: 0.0797919\tvalid_1's rmse: 0.0829715\n",
      "[1375]\ttraining's rmse: 0.0797809\tvalid_1's rmse: 0.0829694\n",
      "[1400]\ttraining's rmse: 0.0797713\tvalid_1's rmse: 0.0829672\n",
      "[1425]\ttraining's rmse: 0.079761\tvalid_1's rmse: 0.0829658\n",
      "[1450]\ttraining's rmse: 0.07975\tvalid_1's rmse: 0.0829646\n",
      "[1475]\ttraining's rmse: 0.0797381\tvalid_1's rmse: 0.0829627\n",
      "[1500]\ttraining's rmse: 0.0797309\tvalid_1's rmse: 0.0829612\n",
      "[1525]\ttraining's rmse: 0.0797213\tvalid_1's rmse: 0.0829597\n",
      "[1550]\ttraining's rmse: 0.0797127\tvalid_1's rmse: 0.0829583\n",
      "[1575]\ttraining's rmse: 0.0797042\tvalid_1's rmse: 0.0829566\n",
      "[1600]\ttraining's rmse: 0.0796972\tvalid_1's rmse: 0.0829556\n",
      "[1625]\ttraining's rmse: 0.0796904\tvalid_1's rmse: 0.0829542\n",
      "[1650]\ttraining's rmse: 0.079682\tvalid_1's rmse: 0.0829531\n",
      "[1675]\ttraining's rmse: 0.0796763\tvalid_1's rmse: 0.0829521\n",
      "[1700]\ttraining's rmse: 0.0796708\tvalid_1's rmse: 0.0829509\n",
      "[1725]\ttraining's rmse: 0.0796644\tvalid_1's rmse: 0.0829499\n",
      "[1750]\ttraining's rmse: 0.0796573\tvalid_1's rmse: 0.0829491\n",
      "[1775]\ttraining's rmse: 0.0796519\tvalid_1's rmse: 0.0829482\n",
      "[1800]\ttraining's rmse: 0.0796456\tvalid_1's rmse: 0.0829476\n",
      "[1825]\ttraining's rmse: 0.0796394\tvalid_1's rmse: 0.0829463\n",
      "[1850]\ttraining's rmse: 0.0796336\tvalid_1's rmse: 0.082945\n",
      "[1875]\ttraining's rmse: 0.0796284\tvalid_1's rmse: 0.0829445\n",
      "[1900]\ttraining's rmse: 0.0796237\tvalid_1's rmse: 0.0829441\n",
      "[1925]\ttraining's rmse: 0.0796194\tvalid_1's rmse: 0.0829435\n",
      "[1950]\ttraining's rmse: 0.0796162\tvalid_1's rmse: 0.0829428\n",
      "[1975]\ttraining's rmse: 0.0796129\tvalid_1's rmse: 0.0829423\n",
      "[2000]\ttraining's rmse: 0.0796082\tvalid_1's rmse: 0.0829413\n",
      "[2025]\ttraining's rmse: 0.0796045\tvalid_1's rmse: 0.0829409\n",
      "[2050]\ttraining's rmse: 0.0796015\tvalid_1's rmse: 0.0829405\n",
      "[2075]\ttraining's rmse: 0.079599\tvalid_1's rmse: 0.0829404\n",
      "[2100]\ttraining's rmse: 0.0795947\tvalid_1's rmse: 0.0829395\n",
      "[2125]\ttraining's rmse: 0.0795922\tvalid_1's rmse: 0.0829391\n",
      "[2150]\ttraining's rmse: 0.0795893\tvalid_1's rmse: 0.0829392\n",
      "[2175]\ttraining's rmse: 0.079586\tvalid_1's rmse: 0.0829393\n",
      "[2200]\ttraining's rmse: 0.0795834\tvalid_1's rmse: 0.0829393\n",
      "Early stopping, best iteration is:\n",
      "[2155]\ttraining's rmse: 0.0795884\tvalid_1's rmse: 0.082939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0839182\tvalid_1's rmse: 0.0800451\n",
      "[50]\ttraining's rmse: 0.083812\tvalid_1's rmse: 0.0799985\n",
      "[75]\ttraining's rmse: 0.0837003\tvalid_1's rmse: 0.0799523\n",
      "[100]\ttraining's rmse: 0.0836011\tvalid_1's rmse: 0.0799118\n",
      "[125]\ttraining's rmse: 0.0834996\tvalid_1's rmse: 0.0798695\n",
      "[150]\ttraining's rmse: 0.0834074\tvalid_1's rmse: 0.0798336\n",
      "[175]\ttraining's rmse: 0.0833312\tvalid_1's rmse: 0.079804\n",
      "[200]\ttraining's rmse: 0.0832458\tvalid_1's rmse: 0.0797733\n",
      "[225]\ttraining's rmse: 0.0831635\tvalid_1's rmse: 0.0797442\n",
      "[250]\ttraining's rmse: 0.0830959\tvalid_1's rmse: 0.0797186\n",
      "[275]\ttraining's rmse: 0.0830348\tvalid_1's rmse: 0.0796952\n",
      "[300]\ttraining's rmse: 0.0829722\tvalid_1's rmse: 0.0796718\n",
      "[325]\ttraining's rmse: 0.0829083\tvalid_1's rmse: 0.0796546\n",
      "[350]\ttraining's rmse: 0.0828457\tvalid_1's rmse: 0.0796336\n",
      "[375]\ttraining's rmse: 0.0827949\tvalid_1's rmse: 0.0796178\n",
      "[400]\ttraining's rmse: 0.0827392\tvalid_1's rmse: 0.0796059\n",
      "[425]\ttraining's rmse: 0.0826884\tvalid_1's rmse: 0.0795922\n",
      "[450]\ttraining's rmse: 0.0826416\tvalid_1's rmse: 0.0795758\n",
      "[475]\ttraining's rmse: 0.082599\tvalid_1's rmse: 0.0795654\n",
      "[500]\ttraining's rmse: 0.082562\tvalid_1's rmse: 0.0795519\n",
      "[525]\ttraining's rmse: 0.08251\tvalid_1's rmse: 0.0795431\n",
      "[550]\ttraining's rmse: 0.0824654\tvalid_1's rmse: 0.0795314\n",
      "[575]\ttraining's rmse: 0.0824253\tvalid_1's rmse: 0.0795313\n",
      "[600]\ttraining's rmse: 0.0823806\tvalid_1's rmse: 0.079521\n",
      "[625]\ttraining's rmse: 0.08235\tvalid_1's rmse: 0.0795175\n",
      "[650]\ttraining's rmse: 0.0823102\tvalid_1's rmse: 0.0795223\n",
      "[675]\ttraining's rmse: 0.082271\tvalid_1's rmse: 0.0795186\n",
      "Early stopping, best iteration is:\n",
      "[629]\ttraining's rmse: 0.0823461\tvalid_1's rmse: 0.0795162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0834892\tvalid_1's rmse: 0.0857078\n",
      "[50]\ttraining's rmse: 0.0833642\tvalid_1's rmse: 0.0856573\n",
      "[75]\ttraining's rmse: 0.0832376\tvalid_1's rmse: 0.085608\n",
      "[100]\ttraining's rmse: 0.0831181\tvalid_1's rmse: 0.085565\n",
      "[125]\ttraining's rmse: 0.0830019\tvalid_1's rmse: 0.0855215\n",
      "[150]\ttraining's rmse: 0.082896\tvalid_1's rmse: 0.0854823\n",
      "[175]\ttraining's rmse: 0.0828083\tvalid_1's rmse: 0.0854489\n",
      "[200]\ttraining's rmse: 0.0827131\tvalid_1's rmse: 0.0854127\n",
      "[225]\ttraining's rmse: 0.0826188\tvalid_1's rmse: 0.0853796\n",
      "[250]\ttraining's rmse: 0.0825416\tvalid_1's rmse: 0.0853484\n",
      "[275]\ttraining's rmse: 0.0824681\tvalid_1's rmse: 0.0853216\n",
      "[300]\ttraining's rmse: 0.0823939\tvalid_1's rmse: 0.0852955\n",
      "[325]\ttraining's rmse: 0.08232\tvalid_1's rmse: 0.0852717\n",
      "[350]\ttraining's rmse: 0.0822493\tvalid_1's rmse: 0.0852478\n",
      "[375]\ttraining's rmse: 0.0821894\tvalid_1's rmse: 0.085228\n",
      "[400]\ttraining's rmse: 0.0821259\tvalid_1's rmse: 0.0852081\n",
      "[425]\ttraining's rmse: 0.0820664\tvalid_1's rmse: 0.0851892\n",
      "[450]\ttraining's rmse: 0.0820129\tvalid_1's rmse: 0.0851716\n",
      "[475]\ttraining's rmse: 0.0819643\tvalid_1's rmse: 0.0851541\n",
      "[500]\ttraining's rmse: 0.0819235\tvalid_1's rmse: 0.0851389\n",
      "[525]\ttraining's rmse: 0.0818719\tvalid_1's rmse: 0.0851227\n",
      "[550]\ttraining's rmse: 0.0818232\tvalid_1's rmse: 0.0851071\n",
      "[575]\ttraining's rmse: 0.0817788\tvalid_1's rmse: 0.0850938\n",
      "[600]\ttraining's rmse: 0.0817359\tvalid_1's rmse: 0.0850805\n",
      "[625]\ttraining's rmse: 0.0817031\tvalid_1's rmse: 0.0850699\n",
      "[650]\ttraining's rmse: 0.0816614\tvalid_1's rmse: 0.0850591\n",
      "[675]\ttraining's rmse: 0.0816185\tvalid_1's rmse: 0.0850487\n",
      "[700]\ttraining's rmse: 0.0815805\tvalid_1's rmse: 0.0850383\n",
      "[725]\ttraining's rmse: 0.0815463\tvalid_1's rmse: 0.0850296\n",
      "[750]\ttraining's rmse: 0.081511\tvalid_1's rmse: 0.085021\n",
      "[775]\ttraining's rmse: 0.0814838\tvalid_1's rmse: 0.0850124\n",
      "[800]\ttraining's rmse: 0.0814488\tvalid_1's rmse: 0.0850047\n",
      "[825]\ttraining's rmse: 0.0814202\tvalid_1's rmse: 0.0849975\n",
      "[850]\ttraining's rmse: 0.0813887\tvalid_1's rmse: 0.0849911\n",
      "[875]\ttraining's rmse: 0.0813622\tvalid_1's rmse: 0.0849832\n",
      "[900]\ttraining's rmse: 0.0813344\tvalid_1's rmse: 0.0849753\n",
      "[925]\ttraining's rmse: 0.0813077\tvalid_1's rmse: 0.0849681\n",
      "[950]\ttraining's rmse: 0.0812863\tvalid_1's rmse: 0.0849619\n",
      "[975]\ttraining's rmse: 0.0812647\tvalid_1's rmse: 0.0849572\n",
      "[1000]\ttraining's rmse: 0.0812423\tvalid_1's rmse: 0.0849531\n",
      "[1025]\ttraining's rmse: 0.0812164\tvalid_1's rmse: 0.084948\n",
      "[1050]\ttraining's rmse: 0.0811927\tvalid_1's rmse: 0.0849426\n",
      "[1075]\ttraining's rmse: 0.0811737\tvalid_1's rmse: 0.0849376\n",
      "[1100]\ttraining's rmse: 0.081157\tvalid_1's rmse: 0.0849333\n",
      "[1125]\ttraining's rmse: 0.0811381\tvalid_1's rmse: 0.0849288\n",
      "[1150]\ttraining's rmse: 0.0811191\tvalid_1's rmse: 0.0849257\n",
      "[1175]\ttraining's rmse: 0.0810978\tvalid_1's rmse: 0.0849226\n",
      "[1200]\ttraining's rmse: 0.0810815\tvalid_1's rmse: 0.0849182\n",
      "[1225]\ttraining's rmse: 0.0810668\tvalid_1's rmse: 0.0849133\n",
      "[1250]\ttraining's rmse: 0.0810541\tvalid_1's rmse: 0.08491\n",
      "[1275]\ttraining's rmse: 0.0810359\tvalid_1's rmse: 0.0849071\n",
      "[1300]\ttraining's rmse: 0.0810236\tvalid_1's rmse: 0.0849028\n",
      "[1325]\ttraining's rmse: 0.0810086\tvalid_1's rmse: 0.0848998\n",
      "[1350]\ttraining's rmse: 0.0809939\tvalid_1's rmse: 0.0848975\n",
      "[1375]\ttraining's rmse: 0.0809812\tvalid_1's rmse: 0.0848944\n",
      "[1400]\ttraining's rmse: 0.0809695\tvalid_1's rmse: 0.0848905\n",
      "[1425]\ttraining's rmse: 0.080957\tvalid_1's rmse: 0.0848889\n",
      "[1450]\ttraining's rmse: 0.0809457\tvalid_1's rmse: 0.0848861\n",
      "[1475]\ttraining's rmse: 0.0809383\tvalid_1's rmse: 0.084883\n",
      "[1500]\ttraining's rmse: 0.080927\tvalid_1's rmse: 0.0848809\n",
      "[1525]\ttraining's rmse: 0.0809168\tvalid_1's rmse: 0.0848787\n",
      "[1550]\ttraining's rmse: 0.0809053\tvalid_1's rmse: 0.0848745\n",
      "[1575]\ttraining's rmse: 0.0808968\tvalid_1's rmse: 0.084872\n",
      "[1600]\ttraining's rmse: 0.0808886\tvalid_1's rmse: 0.0848697\n",
      "[1625]\ttraining's rmse: 0.0808808\tvalid_1's rmse: 0.0848675\n",
      "[1650]\ttraining's rmse: 0.080872\tvalid_1's rmse: 0.0848647\n",
      "[1675]\ttraining's rmse: 0.0808679\tvalid_1's rmse: 0.084863\n",
      "[1700]\ttraining's rmse: 0.0808631\tvalid_1's rmse: 0.0848606\n",
      "[1725]\ttraining's rmse: 0.0808565\tvalid_1's rmse: 0.0848597\n",
      "[1750]\ttraining's rmse: 0.0808519\tvalid_1's rmse: 0.0848572\n",
      "[1775]\ttraining's rmse: 0.080846\tvalid_1's rmse: 0.0848563\n",
      "[1800]\ttraining's rmse: 0.0808404\tvalid_1's rmse: 0.0848544\n",
      "[1825]\ttraining's rmse: 0.0808362\tvalid_1's rmse: 0.084853\n",
      "[1850]\ttraining's rmse: 0.0808312\tvalid_1's rmse: 0.0848511\n",
      "[1875]\ttraining's rmse: 0.0808262\tvalid_1's rmse: 0.0848506\n",
      "[1900]\ttraining's rmse: 0.0808232\tvalid_1's rmse: 0.0848485\n",
      "[1925]\ttraining's rmse: 0.0808184\tvalid_1's rmse: 0.0848473\n",
      "[1950]\ttraining's rmse: 0.0808151\tvalid_1's rmse: 0.0848457\n",
      "[1975]\ttraining's rmse: 0.0808121\tvalid_1's rmse: 0.0848443\n",
      "[2000]\ttraining's rmse: 0.0808075\tvalid_1's rmse: 0.0848438\n",
      "[2025]\ttraining's rmse: 0.0808041\tvalid_1's rmse: 0.0848418\n",
      "[2050]\ttraining's rmse: 0.0808005\tvalid_1's rmse: 0.0848408\n",
      "[2075]\ttraining's rmse: 0.0807973\tvalid_1's rmse: 0.0848403\n",
      "[2100]\ttraining's rmse: 0.0807947\tvalid_1's rmse: 0.0848395\n",
      "[2125]\ttraining's rmse: 0.0807908\tvalid_1's rmse: 0.0848379\n",
      "[2150]\ttraining's rmse: 0.080788\tvalid_1's rmse: 0.0848371\n",
      "[2175]\ttraining's rmse: 0.080785\tvalid_1's rmse: 0.084837\n",
      "[2200]\ttraining's rmse: 0.0807808\tvalid_1's rmse: 0.0848358\n",
      "[2225]\ttraining's rmse: 0.0807786\tvalid_1's rmse: 0.0848354\n",
      "[2250]\ttraining's rmse: 0.0807765\tvalid_1's rmse: 0.0848349\n",
      "[2275]\ttraining's rmse: 0.0807736\tvalid_1's rmse: 0.0848344\n",
      "[2300]\ttraining's rmse: 0.080771\tvalid_1's rmse: 0.0848342\n",
      "[2325]\ttraining's rmse: 0.0807672\tvalid_1's rmse: 0.0848335\n",
      "[2350]\ttraining's rmse: 0.0807648\tvalid_1's rmse: 0.0848328\n",
      "[2375]\ttraining's rmse: 0.0807627\tvalid_1's rmse: 0.0848311\n",
      "[2400]\ttraining's rmse: 0.0807585\tvalid_1's rmse: 0.084831\n",
      "[2425]\ttraining's rmse: 0.0807568\tvalid_1's rmse: 0.084831\n",
      "Early stopping, best iteration is:\n",
      "[2383]\ttraining's rmse: 0.0807612\tvalid_1's rmse: 0.0848306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0834981\tvalid_1's rmse: 0.0857086\n",
      "[50]\ttraining's rmse: 0.0833823\tvalid_1's rmse: 0.0856567\n",
      "[75]\ttraining's rmse: 0.0832639\tvalid_1's rmse: 0.0856052\n",
      "[100]\ttraining's rmse: 0.0831617\tvalid_1's rmse: 0.0855606\n",
      "[125]\ttraining's rmse: 0.0830555\tvalid_1's rmse: 0.0855153\n",
      "[150]\ttraining's rmse: 0.0829581\tvalid_1's rmse: 0.0854728\n",
      "[175]\ttraining's rmse: 0.0828725\tvalid_1's rmse: 0.0854368\n",
      "[200]\ttraining's rmse: 0.0827818\tvalid_1's rmse: 0.0854012\n",
      "[225]\ttraining's rmse: 0.0826966\tvalid_1's rmse: 0.0853676\n",
      "[250]\ttraining's rmse: 0.0826236\tvalid_1's rmse: 0.0853387\n",
      "[275]\ttraining's rmse: 0.0825579\tvalid_1's rmse: 0.0853108\n",
      "[300]\ttraining's rmse: 0.0824899\tvalid_1's rmse: 0.0852865\n",
      "[325]\ttraining's rmse: 0.0824195\tvalid_1's rmse: 0.0852616\n",
      "[350]\ttraining's rmse: 0.0823521\tvalid_1's rmse: 0.0852369\n",
      "[375]\ttraining's rmse: 0.0822969\tvalid_1's rmse: 0.0852152\n",
      "[400]\ttraining's rmse: 0.0822379\tvalid_1's rmse: 0.0851948\n",
      "[425]\ttraining's rmse: 0.0821839\tvalid_1's rmse: 0.0851754\n",
      "[450]\ttraining's rmse: 0.082133\tvalid_1's rmse: 0.0851566\n",
      "[475]\ttraining's rmse: 0.0820866\tvalid_1's rmse: 0.0851405\n",
      "[500]\ttraining's rmse: 0.0820466\tvalid_1's rmse: 0.0851237\n",
      "[525]\ttraining's rmse: 0.0819934\tvalid_1's rmse: 0.0851071\n",
      "[550]\ttraining's rmse: 0.0819451\tvalid_1's rmse: 0.0850921\n",
      "[575]\ttraining's rmse: 0.0819014\tvalid_1's rmse: 0.0850783\n",
      "[600]\ttraining's rmse: 0.0818591\tvalid_1's rmse: 0.0850653\n",
      "[625]\ttraining's rmse: 0.081826\tvalid_1's rmse: 0.0850537\n",
      "[650]\ttraining's rmse: 0.0817849\tvalid_1's rmse: 0.085041\n",
      "[675]\ttraining's rmse: 0.0817453\tvalid_1's rmse: 0.0850303\n",
      "[700]\ttraining's rmse: 0.081709\tvalid_1's rmse: 0.0850191\n",
      "[725]\ttraining's rmse: 0.0816746\tvalid_1's rmse: 0.0850101\n",
      "[750]\ttraining's rmse: 0.0816441\tvalid_1's rmse: 0.0850012\n",
      "[775]\ttraining's rmse: 0.0816179\tvalid_1's rmse: 0.084993\n",
      "[800]\ttraining's rmse: 0.0815825\tvalid_1's rmse: 0.0849848\n",
      "[825]\ttraining's rmse: 0.0815567\tvalid_1's rmse: 0.0849775\n",
      "[850]\ttraining's rmse: 0.0815264\tvalid_1's rmse: 0.0849711\n",
      "[875]\ttraining's rmse: 0.0815017\tvalid_1's rmse: 0.0849647\n",
      "[900]\ttraining's rmse: 0.0814742\tvalid_1's rmse: 0.0849576\n",
      "[925]\ttraining's rmse: 0.0814484\tvalid_1's rmse: 0.0849515\n",
      "[950]\ttraining's rmse: 0.0814235\tvalid_1's rmse: 0.0849457\n",
      "[975]\ttraining's rmse: 0.0813991\tvalid_1's rmse: 0.0849401\n",
      "[1000]\ttraining's rmse: 0.0813786\tvalid_1's rmse: 0.0849347\n",
      "[1025]\ttraining's rmse: 0.0813559\tvalid_1's rmse: 0.0849302\n",
      "[1050]\ttraining's rmse: 0.0813364\tvalid_1's rmse: 0.0849254\n",
      "[1075]\ttraining's rmse: 0.0813173\tvalid_1's rmse: 0.0849217\n",
      "[1100]\ttraining's rmse: 0.0813001\tvalid_1's rmse: 0.0849171\n",
      "[1125]\ttraining's rmse: 0.0812821\tvalid_1's rmse: 0.084913\n",
      "[1150]\ttraining's rmse: 0.0812648\tvalid_1's rmse: 0.0849093\n",
      "[1175]\ttraining's rmse: 0.0812479\tvalid_1's rmse: 0.0849059\n",
      "[1200]\ttraining's rmse: 0.0812335\tvalid_1's rmse: 0.0849028\n",
      "[1225]\ttraining's rmse: 0.0812167\tvalid_1's rmse: 0.0848998\n",
      "[1250]\ttraining's rmse: 0.0812051\tvalid_1's rmse: 0.0848972\n",
      "[1275]\ttraining's rmse: 0.0811881\tvalid_1's rmse: 0.0848948\n",
      "[1300]\ttraining's rmse: 0.0811774\tvalid_1's rmse: 0.0848922\n",
      "[1325]\ttraining's rmse: 0.0811637\tvalid_1's rmse: 0.08489\n",
      "[1350]\ttraining's rmse: 0.0811511\tvalid_1's rmse: 0.0848879\n",
      "[1375]\ttraining's rmse: 0.0811384\tvalid_1's rmse: 0.0848861\n",
      "[1400]\ttraining's rmse: 0.0811295\tvalid_1's rmse: 0.0848833\n",
      "[1425]\ttraining's rmse: 0.0811172\tvalid_1's rmse: 0.0848816\n",
      "[1450]\ttraining's rmse: 0.0811043\tvalid_1's rmse: 0.0848799\n",
      "[1475]\ttraining's rmse: 0.0810939\tvalid_1's rmse: 0.0848782\n",
      "[1500]\ttraining's rmse: 0.0810857\tvalid_1's rmse: 0.0848765\n",
      "[1525]\ttraining's rmse: 0.0810763\tvalid_1's rmse: 0.0848751\n",
      "[1550]\ttraining's rmse: 0.0810651\tvalid_1's rmse: 0.084874\n",
      "[1575]\ttraining's rmse: 0.081058\tvalid_1's rmse: 0.0848727\n",
      "[1600]\ttraining's rmse: 0.0810508\tvalid_1's rmse: 0.0848719\n",
      "[1625]\ttraining's rmse: 0.0810434\tvalid_1's rmse: 0.0848708\n",
      "[1650]\ttraining's rmse: 0.0810357\tvalid_1's rmse: 0.0848703\n",
      "[1675]\ttraining's rmse: 0.0810298\tvalid_1's rmse: 0.0848698\n",
      "[1700]\ttraining's rmse: 0.0810243\tvalid_1's rmse: 0.0848684\n",
      "[1725]\ttraining's rmse: 0.0810177\tvalid_1's rmse: 0.0848671\n",
      "[1750]\ttraining's rmse: 0.0810102\tvalid_1's rmse: 0.0848663\n",
      "[1775]\ttraining's rmse: 0.0810057\tvalid_1's rmse: 0.0848658\n",
      "[1800]\ttraining's rmse: 0.0809974\tvalid_1's rmse: 0.0848644\n",
      "[1825]\ttraining's rmse: 0.0809928\tvalid_1's rmse: 0.084864\n",
      "[1850]\ttraining's rmse: 0.0809883\tvalid_1's rmse: 0.0848632\n",
      "[1875]\ttraining's rmse: 0.0809822\tvalid_1's rmse: 0.0848629\n",
      "[1900]\ttraining's rmse: 0.0809772\tvalid_1's rmse: 0.0848624\n",
      "[1925]\ttraining's rmse: 0.0809727\tvalid_1's rmse: 0.0848621\n",
      "[1950]\ttraining's rmse: 0.0809694\tvalid_1's rmse: 0.0848616\n",
      "[1975]\ttraining's rmse: 0.0809654\tvalid_1's rmse: 0.0848605\n",
      "[2000]\ttraining's rmse: 0.0809613\tvalid_1's rmse: 0.0848599\n",
      "[2025]\ttraining's rmse: 0.0809571\tvalid_1's rmse: 0.0848591\n",
      "[2050]\ttraining's rmse: 0.0809537\tvalid_1's rmse: 0.084859\n",
      "[2075]\ttraining's rmse: 0.0809506\tvalid_1's rmse: 0.0848584\n",
      "[2100]\ttraining's rmse: 0.0809482\tvalid_1's rmse: 0.0848581\n",
      "[2125]\ttraining's rmse: 0.0809457\tvalid_1's rmse: 0.0848576\n",
      "[2150]\ttraining's rmse: 0.0809433\tvalid_1's rmse: 0.0848571\n",
      "[2175]\ttraining's rmse: 0.0809398\tvalid_1's rmse: 0.0848568\n",
      "[2200]\ttraining's rmse: 0.0809364\tvalid_1's rmse: 0.0848565\n",
      "[2225]\ttraining's rmse: 0.0809337\tvalid_1's rmse: 0.0848561\n",
      "[2250]\ttraining's rmse: 0.0809306\tvalid_1's rmse: 0.084856\n",
      "[2275]\ttraining's rmse: 0.0809272\tvalid_1's rmse: 0.0848554\n",
      "[2300]\ttraining's rmse: 0.0809249\tvalid_1's rmse: 0.084855\n",
      "[2325]\ttraining's rmse: 0.0809209\tvalid_1's rmse: 0.084855\n",
      "[2350]\ttraining's rmse: 0.0809184\tvalid_1's rmse: 0.0848549\n",
      "[2375]\ttraining's rmse: 0.0809164\tvalid_1's rmse: 0.0848548\n",
      "Early stopping, best iteration is:\n",
      "[2335]\ttraining's rmse: 0.08092\tvalid_1's rmse: 0.0848547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0855911\tvalid_1's rmse: 0.0814614\n",
      "[50]\ttraining's rmse: 0.0854856\tvalid_1's rmse: 0.0814159\n",
      "[75]\ttraining's rmse: 0.0853735\tvalid_1's rmse: 0.0813695\n",
      "[100]\ttraining's rmse: 0.0852732\tvalid_1's rmse: 0.0813288\n",
      "[125]\ttraining's rmse: 0.0851673\tvalid_1's rmse: 0.0812876\n",
      "[150]\ttraining's rmse: 0.0850709\tvalid_1's rmse: 0.0812499\n",
      "[175]\ttraining's rmse: 0.0849898\tvalid_1's rmse: 0.0812204\n",
      "[200]\ttraining's rmse: 0.0848996\tvalid_1's rmse: 0.0811879\n",
      "[225]\ttraining's rmse: 0.0848155\tvalid_1's rmse: 0.0811569\n",
      "[250]\ttraining's rmse: 0.0847448\tvalid_1's rmse: 0.0811312\n",
      "[275]\ttraining's rmse: 0.0846803\tvalid_1's rmse: 0.0811066\n",
      "[300]\ttraining's rmse: 0.0846155\tvalid_1's rmse: 0.0810842\n",
      "[325]\ttraining's rmse: 0.0845491\tvalid_1's rmse: 0.0810637\n",
      "[350]\ttraining's rmse: 0.0844847\tvalid_1's rmse: 0.0810431\n",
      "[375]\ttraining's rmse: 0.0844321\tvalid_1's rmse: 0.0810271\n",
      "[400]\ttraining's rmse: 0.0843749\tvalid_1's rmse: 0.0810099\n",
      "[425]\ttraining's rmse: 0.0843214\tvalid_1's rmse: 0.0809965\n",
      "[450]\ttraining's rmse: 0.0842728\tvalid_1's rmse: 0.0809837\n",
      "[475]\ttraining's rmse: 0.0842277\tvalid_1's rmse: 0.0809708\n",
      "[500]\ttraining's rmse: 0.0841903\tvalid_1's rmse: 0.0809575\n",
      "[525]\ttraining's rmse: 0.0841403\tvalid_1's rmse: 0.0809444\n",
      "[550]\ttraining's rmse: 0.0840932\tvalid_1's rmse: 0.0809315\n",
      "[575]\ttraining's rmse: 0.084051\tvalid_1's rmse: 0.0809204\n",
      "[600]\ttraining's rmse: 0.0840086\tvalid_1's rmse: 0.0809151\n",
      "[625]\ttraining's rmse: 0.0839743\tvalid_1's rmse: 0.0809099\n",
      "[650]\ttraining's rmse: 0.0839324\tvalid_1's rmse: 0.080905\n",
      "[675]\ttraining's rmse: 0.083892\tvalid_1's rmse: 0.0808974\n",
      "[700]\ttraining's rmse: 0.0838545\tvalid_1's rmse: 0.0808944\n",
      "[725]\ttraining's rmse: 0.083821\tvalid_1's rmse: 0.0808984\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0838645\tvalid_1's rmse: 0.0808916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.082217\tvalid_1's rmse: 0.084668\n",
      "[50]\ttraining's rmse: 0.082096\tvalid_1's rmse: 0.084618\n",
      "[75]\ttraining's rmse: 0.0819704\tvalid_1's rmse: 0.0845665\n",
      "[100]\ttraining's rmse: 0.0818547\tvalid_1's rmse: 0.0845215\n",
      "[125]\ttraining's rmse: 0.0817402\tvalid_1's rmse: 0.0844776\n",
      "[150]\ttraining's rmse: 0.0816342\tvalid_1's rmse: 0.0844351\n",
      "[175]\ttraining's rmse: 0.0815473\tvalid_1's rmse: 0.0843988\n",
      "[200]\ttraining's rmse: 0.0814555\tvalid_1's rmse: 0.0843653\n",
      "[225]\ttraining's rmse: 0.081365\tvalid_1's rmse: 0.0843296\n",
      "[250]\ttraining's rmse: 0.0812887\tvalid_1's rmse: 0.0842977\n",
      "[275]\ttraining's rmse: 0.0812141\tvalid_1's rmse: 0.0842697\n",
      "[300]\ttraining's rmse: 0.0811424\tvalid_1's rmse: 0.0842434\n",
      "[325]\ttraining's rmse: 0.0810699\tvalid_1's rmse: 0.0842178\n",
      "[350]\ttraining's rmse: 0.0810033\tvalid_1's rmse: 0.084193\n",
      "[375]\ttraining's rmse: 0.0809436\tvalid_1's rmse: 0.0841738\n",
      "[400]\ttraining's rmse: 0.0808839\tvalid_1's rmse: 0.0841534\n",
      "[425]\ttraining's rmse: 0.0808296\tvalid_1's rmse: 0.0841337\n",
      "[450]\ttraining's rmse: 0.0807785\tvalid_1's rmse: 0.0841139\n",
      "[475]\ttraining's rmse: 0.0807315\tvalid_1's rmse: 0.0840981\n",
      "[500]\ttraining's rmse: 0.0806908\tvalid_1's rmse: 0.0840829\n",
      "[525]\ttraining's rmse: 0.0806391\tvalid_1's rmse: 0.0840665\n",
      "[550]\ttraining's rmse: 0.0805924\tvalid_1's rmse: 0.084052\n",
      "[575]\ttraining's rmse: 0.0805484\tvalid_1's rmse: 0.0840386\n",
      "[600]\ttraining's rmse: 0.0805058\tvalid_1's rmse: 0.0840263\n",
      "[625]\ttraining's rmse: 0.0804715\tvalid_1's rmse: 0.0840145\n",
      "[650]\ttraining's rmse: 0.0804343\tvalid_1's rmse: 0.0840018\n",
      "[675]\ttraining's rmse: 0.0803944\tvalid_1's rmse: 0.0839908\n",
      "[700]\ttraining's rmse: 0.0803577\tvalid_1's rmse: 0.0839798\n",
      "[725]\ttraining's rmse: 0.0803221\tvalid_1's rmse: 0.0839693\n",
      "[750]\ttraining's rmse: 0.0802879\tvalid_1's rmse: 0.08396\n",
      "[775]\ttraining's rmse: 0.0802631\tvalid_1's rmse: 0.0839497\n",
      "[800]\ttraining's rmse: 0.0802318\tvalid_1's rmse: 0.0839416\n",
      "[825]\ttraining's rmse: 0.0802046\tvalid_1's rmse: 0.0839327\n",
      "[850]\ttraining's rmse: 0.0801735\tvalid_1's rmse: 0.083925\n",
      "[875]\ttraining's rmse: 0.080148\tvalid_1's rmse: 0.0839165\n",
      "[900]\ttraining's rmse: 0.0801196\tvalid_1's rmse: 0.0839079\n",
      "[925]\ttraining's rmse: 0.0800961\tvalid_1's rmse: 0.0839015\n",
      "[950]\ttraining's rmse: 0.0800706\tvalid_1's rmse: 0.0838946\n",
      "[975]\ttraining's rmse: 0.0800493\tvalid_1's rmse: 0.083889\n",
      "[1000]\ttraining's rmse: 0.0800273\tvalid_1's rmse: 0.0838827\n",
      "[1025]\ttraining's rmse: 0.0800066\tvalid_1's rmse: 0.0838767\n",
      "[1050]\ttraining's rmse: 0.0799863\tvalid_1's rmse: 0.0838707\n",
      "[1075]\ttraining's rmse: 0.0799654\tvalid_1's rmse: 0.0838659\n",
      "[1100]\ttraining's rmse: 0.0799491\tvalid_1's rmse: 0.0838603\n",
      "[1125]\ttraining's rmse: 0.0799347\tvalid_1's rmse: 0.0838541\n",
      "[1150]\ttraining's rmse: 0.0799208\tvalid_1's rmse: 0.0838498\n",
      "[1175]\ttraining's rmse: 0.0799056\tvalid_1's rmse: 0.0838465\n",
      "[1200]\ttraining's rmse: 0.0798886\tvalid_1's rmse: 0.0838412\n",
      "[1225]\ttraining's rmse: 0.0798723\tvalid_1's rmse: 0.0838363\n",
      "[1250]\ttraining's rmse: 0.0798575\tvalid_1's rmse: 0.0838334\n",
      "[1275]\ttraining's rmse: 0.0798411\tvalid_1's rmse: 0.0838295\n",
      "[1300]\ttraining's rmse: 0.0798293\tvalid_1's rmse: 0.0838246\n",
      "[1325]\ttraining's rmse: 0.0798177\tvalid_1's rmse: 0.0838222\n",
      "[1350]\ttraining's rmse: 0.0798041\tvalid_1's rmse: 0.0838189\n",
      "[1375]\ttraining's rmse: 0.0797921\tvalid_1's rmse: 0.0838163\n",
      "[1400]\ttraining's rmse: 0.0797821\tvalid_1's rmse: 0.0838125\n",
      "[1425]\ttraining's rmse: 0.0797714\tvalid_1's rmse: 0.0838102\n",
      "[1450]\ttraining's rmse: 0.0797587\tvalid_1's rmse: 0.0838069\n",
      "[1475]\ttraining's rmse: 0.0797484\tvalid_1's rmse: 0.0838032\n",
      "[1500]\ttraining's rmse: 0.079739\tvalid_1's rmse: 0.0838006\n",
      "[1525]\ttraining's rmse: 0.0797312\tvalid_1's rmse: 0.0837981\n",
      "[1550]\ttraining's rmse: 0.0797211\tvalid_1's rmse: 0.0837965\n",
      "[1575]\ttraining's rmse: 0.0797139\tvalid_1's rmse: 0.0837936\n",
      "[1600]\ttraining's rmse: 0.0797078\tvalid_1's rmse: 0.0837916\n",
      "[1625]\ttraining's rmse: 0.0797004\tvalid_1's rmse: 0.0837877\n",
      "[1650]\ttraining's rmse: 0.0796945\tvalid_1's rmse: 0.0837843\n",
      "[1675]\ttraining's rmse: 0.0796904\tvalid_1's rmse: 0.0837838\n",
      "[1700]\ttraining's rmse: 0.0796835\tvalid_1's rmse: 0.0837824\n",
      "[1725]\ttraining's rmse: 0.0796751\tvalid_1's rmse: 0.0837809\n",
      "[1750]\ttraining's rmse: 0.0796698\tvalid_1's rmse: 0.0837792\n",
      "[1775]\ttraining's rmse: 0.0796647\tvalid_1's rmse: 0.0837778\n",
      "[1800]\ttraining's rmse: 0.0796583\tvalid_1's rmse: 0.0837753\n",
      "[1825]\ttraining's rmse: 0.0796532\tvalid_1's rmse: 0.0837734\n",
      "[1850]\ttraining's rmse: 0.0796481\tvalid_1's rmse: 0.083772\n",
      "[1875]\ttraining's rmse: 0.0796427\tvalid_1's rmse: 0.0837708\n",
      "[1900]\ttraining's rmse: 0.0796365\tvalid_1's rmse: 0.0837698\n",
      "[1925]\ttraining's rmse: 0.0796318\tvalid_1's rmse: 0.0837686\n",
      "[1950]\ttraining's rmse: 0.0796279\tvalid_1's rmse: 0.0837673\n",
      "[1975]\ttraining's rmse: 0.0796235\tvalid_1's rmse: 0.0837663\n",
      "[2000]\ttraining's rmse: 0.0796197\tvalid_1's rmse: 0.0837648\n",
      "[2025]\ttraining's rmse: 0.0796162\tvalid_1's rmse: 0.0837636\n",
      "[2050]\ttraining's rmse: 0.0796131\tvalid_1's rmse: 0.0837627\n",
      "[2075]\ttraining's rmse: 0.0796096\tvalid_1's rmse: 0.0837623\n",
      "[2100]\ttraining's rmse: 0.0796058\tvalid_1's rmse: 0.0837616\n",
      "[2125]\ttraining's rmse: 0.0796026\tvalid_1's rmse: 0.08376\n",
      "[2150]\ttraining's rmse: 0.0795994\tvalid_1's rmse: 0.0837587\n",
      "[2175]\ttraining's rmse: 0.0795969\tvalid_1's rmse: 0.0837581\n",
      "[2200]\ttraining's rmse: 0.079594\tvalid_1's rmse: 0.0837569\n",
      "[2225]\ttraining's rmse: 0.0795904\tvalid_1's rmse: 0.0837566\n",
      "[2250]\ttraining's rmse: 0.0795867\tvalid_1's rmse: 0.0837565\n",
      "[2275]\ttraining's rmse: 0.0795837\tvalid_1's rmse: 0.0837564\n",
      "[2300]\ttraining's rmse: 0.0795803\tvalid_1's rmse: 0.0837556\n",
      "[2325]\ttraining's rmse: 0.079577\tvalid_1's rmse: 0.0837547\n",
      "[2350]\ttraining's rmse: 0.0795745\tvalid_1's rmse: 0.0837543\n",
      "[2375]\ttraining's rmse: 0.0795722\tvalid_1's rmse: 0.0837532\n",
      "[2400]\ttraining's rmse: 0.0795705\tvalid_1's rmse: 0.0837527\n",
      "[2425]\ttraining's rmse: 0.0795682\tvalid_1's rmse: 0.0837519\n",
      "[2450]\ttraining's rmse: 0.0795669\tvalid_1's rmse: 0.0837518\n",
      "[2475]\ttraining's rmse: 0.0795645\tvalid_1's rmse: 0.0837508\n",
      "[2500]\ttraining's rmse: 0.0795629\tvalid_1's rmse: 0.0837508\n",
      "[2525]\ttraining's rmse: 0.0795597\tvalid_1's rmse: 0.0837503\n",
      "[2550]\ttraining's rmse: 0.0795575\tvalid_1's rmse: 0.0837501\n",
      "[2575]\ttraining's rmse: 0.0795563\tvalid_1's rmse: 0.0837502\n",
      "[2600]\ttraining's rmse: 0.0795554\tvalid_1's rmse: 0.0837498\n",
      "[2625]\ttraining's rmse: 0.0795542\tvalid_1's rmse: 0.0837484\n",
      "[2650]\ttraining's rmse: 0.0795523\tvalid_1's rmse: 0.083748\n",
      "[2675]\ttraining's rmse: 0.0795509\tvalid_1's rmse: 0.0837475\n",
      "[2700]\ttraining's rmse: 0.0795497\tvalid_1's rmse: 0.0837477\n",
      "[2725]\ttraining's rmse: 0.0795479\tvalid_1's rmse: 0.0837473\n",
      "[2750]\ttraining's rmse: 0.0795467\tvalid_1's rmse: 0.0837471\n",
      "[2775]\ttraining's rmse: 0.0795448\tvalid_1's rmse: 0.0837471\n",
      "Early stopping, best iteration is:\n",
      "[2742]\ttraining's rmse: 0.079547\tvalid_1's rmse: 0.0837469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0824314\tvalid_1's rmse: 0.0842595\n",
      "[50]\ttraining's rmse: 0.0823186\tvalid_1's rmse: 0.0842062\n",
      "[75]\ttraining's rmse: 0.0822041\tvalid_1's rmse: 0.0841545\n",
      "[100]\ttraining's rmse: 0.082102\tvalid_1's rmse: 0.0841072\n",
      "[125]\ttraining's rmse: 0.0819947\tvalid_1's rmse: 0.0840614\n",
      "[150]\ttraining's rmse: 0.0818974\tvalid_1's rmse: 0.0840197\n",
      "[175]\ttraining's rmse: 0.0818208\tvalid_1's rmse: 0.0839848\n",
      "[200]\ttraining's rmse: 0.0817316\tvalid_1's rmse: 0.0839491\n",
      "[225]\ttraining's rmse: 0.0816463\tvalid_1's rmse: 0.083916\n",
      "[250]\ttraining's rmse: 0.0815735\tvalid_1's rmse: 0.0838859\n",
      "[275]\ttraining's rmse: 0.0815051\tvalid_1's rmse: 0.0838593\n",
      "[300]\ttraining's rmse: 0.0814372\tvalid_1's rmse: 0.0838333\n",
      "[325]\ttraining's rmse: 0.0813688\tvalid_1's rmse: 0.0838065\n",
      "[350]\ttraining's rmse: 0.0813017\tvalid_1's rmse: 0.0837823\n",
      "[375]\ttraining's rmse: 0.0812477\tvalid_1's rmse: 0.083762\n",
      "[400]\ttraining's rmse: 0.0811913\tvalid_1's rmse: 0.0837431\n",
      "[425]\ttraining's rmse: 0.0811373\tvalid_1's rmse: 0.0837237\n",
      "[450]\ttraining's rmse: 0.0810869\tvalid_1's rmse: 0.0837065\n",
      "[475]\ttraining's rmse: 0.0810417\tvalid_1's rmse: 0.0836908\n",
      "[500]\ttraining's rmse: 0.0810003\tvalid_1's rmse: 0.0836736\n",
      "[525]\ttraining's rmse: 0.0809507\tvalid_1's rmse: 0.0836592\n",
      "[550]\ttraining's rmse: 0.0809026\tvalid_1's rmse: 0.0836445\n",
      "[575]\ttraining's rmse: 0.0808602\tvalid_1's rmse: 0.0836309\n",
      "[600]\ttraining's rmse: 0.0808201\tvalid_1's rmse: 0.0836185\n",
      "[625]\ttraining's rmse: 0.0807874\tvalid_1's rmse: 0.0836072\n",
      "[650]\ttraining's rmse: 0.080746\tvalid_1's rmse: 0.0835955\n",
      "[675]\ttraining's rmse: 0.0807046\tvalid_1's rmse: 0.0835842\n",
      "[700]\ttraining's rmse: 0.0806673\tvalid_1's rmse: 0.0835732\n",
      "[725]\ttraining's rmse: 0.0806339\tvalid_1's rmse: 0.0835637\n",
      "[750]\ttraining's rmse: 0.0806021\tvalid_1's rmse: 0.0835546\n",
      "[775]\ttraining's rmse: 0.080576\tvalid_1's rmse: 0.0835463\n",
      "[800]\ttraining's rmse: 0.0805427\tvalid_1's rmse: 0.0835391\n",
      "[825]\ttraining's rmse: 0.0805157\tvalid_1's rmse: 0.0835306\n",
      "[850]\ttraining's rmse: 0.0804861\tvalid_1's rmse: 0.0835238\n",
      "[875]\ttraining's rmse: 0.080461\tvalid_1's rmse: 0.0835169\n",
      "[900]\ttraining's rmse: 0.0804331\tvalid_1's rmse: 0.0835105\n",
      "[925]\ttraining's rmse: 0.0804061\tvalid_1's rmse: 0.083505\n",
      "[950]\ttraining's rmse: 0.0803842\tvalid_1's rmse: 0.0834994\n",
      "[975]\ttraining's rmse: 0.0803622\tvalid_1's rmse: 0.0834938\n",
      "[1000]\ttraining's rmse: 0.0803383\tvalid_1's rmse: 0.0834883\n",
      "[1025]\ttraining's rmse: 0.0803141\tvalid_1's rmse: 0.0834832\n",
      "[1050]\ttraining's rmse: 0.0802952\tvalid_1's rmse: 0.0834789\n",
      "[1075]\ttraining's rmse: 0.0802758\tvalid_1's rmse: 0.0834754\n",
      "[1100]\ttraining's rmse: 0.0802591\tvalid_1's rmse: 0.0834707\n",
      "[1125]\ttraining's rmse: 0.0802419\tvalid_1's rmse: 0.0834673\n",
      "[1150]\ttraining's rmse: 0.0802236\tvalid_1's rmse: 0.0834632\n",
      "[1175]\ttraining's rmse: 0.0802083\tvalid_1's rmse: 0.0834604\n",
      "[1200]\ttraining's rmse: 0.0801893\tvalid_1's rmse: 0.0834571\n",
      "[1225]\ttraining's rmse: 0.0801767\tvalid_1's rmse: 0.0834542\n",
      "[1250]\ttraining's rmse: 0.0801643\tvalid_1's rmse: 0.0834512\n",
      "[1275]\ttraining's rmse: 0.0801486\tvalid_1's rmse: 0.0834489\n",
      "[1300]\ttraining's rmse: 0.0801371\tvalid_1's rmse: 0.083446\n",
      "[1325]\ttraining's rmse: 0.0801238\tvalid_1's rmse: 0.0834432\n",
      "[1350]\ttraining's rmse: 0.0801097\tvalid_1's rmse: 0.0834408\n",
      "[1375]\ttraining's rmse: 0.0800971\tvalid_1's rmse: 0.0834388\n",
      "[1400]\ttraining's rmse: 0.0800863\tvalid_1's rmse: 0.0834364\n",
      "[1425]\ttraining's rmse: 0.0800735\tvalid_1's rmse: 0.083435\n",
      "[1450]\ttraining's rmse: 0.0800633\tvalid_1's rmse: 0.0834333\n",
      "[1475]\ttraining's rmse: 0.0800553\tvalid_1's rmse: 0.0834314\n",
      "[1500]\ttraining's rmse: 0.0800466\tvalid_1's rmse: 0.0834295\n",
      "[1525]\ttraining's rmse: 0.0800385\tvalid_1's rmse: 0.0834282\n",
      "[1550]\ttraining's rmse: 0.0800268\tvalid_1's rmse: 0.0834266\n",
      "[1575]\ttraining's rmse: 0.0800185\tvalid_1's rmse: 0.0834251\n",
      "[1600]\ttraining's rmse: 0.0800114\tvalid_1's rmse: 0.0834248\n",
      "[1625]\ttraining's rmse: 0.0800032\tvalid_1's rmse: 0.0834233\n",
      "[1650]\ttraining's rmse: 0.0799975\tvalid_1's rmse: 0.0834223\n",
      "[1675]\ttraining's rmse: 0.0799922\tvalid_1's rmse: 0.0834214\n",
      "[1700]\ttraining's rmse: 0.0799868\tvalid_1's rmse: 0.0834206\n",
      "[1725]\ttraining's rmse: 0.0799794\tvalid_1's rmse: 0.0834192\n",
      "[1750]\ttraining's rmse: 0.0799731\tvalid_1's rmse: 0.0834184\n",
      "[1775]\ttraining's rmse: 0.0799687\tvalid_1's rmse: 0.0834175\n",
      "[1800]\ttraining's rmse: 0.0799628\tvalid_1's rmse: 0.0834166\n",
      "[1825]\ttraining's rmse: 0.0799576\tvalid_1's rmse: 0.0834156\n",
      "[1850]\ttraining's rmse: 0.0799524\tvalid_1's rmse: 0.083415\n",
      "[1875]\ttraining's rmse: 0.0799467\tvalid_1's rmse: 0.0834139\n",
      "[1900]\ttraining's rmse: 0.0799414\tvalid_1's rmse: 0.0834141\n",
      "[1925]\ttraining's rmse: 0.0799355\tvalid_1's rmse: 0.0834132\n",
      "[1950]\ttraining's rmse: 0.0799322\tvalid_1's rmse: 0.0834125\n",
      "[1975]\ttraining's rmse: 0.0799281\tvalid_1's rmse: 0.083412\n",
      "[2000]\ttraining's rmse: 0.0799232\tvalid_1's rmse: 0.083411\n",
      "[2025]\ttraining's rmse: 0.07992\tvalid_1's rmse: 0.0834101\n",
      "[2050]\ttraining's rmse: 0.0799147\tvalid_1's rmse: 0.0834093\n",
      "[2075]\ttraining's rmse: 0.0799106\tvalid_1's rmse: 0.0834086\n",
      "[2100]\ttraining's rmse: 0.0799077\tvalid_1's rmse: 0.083408\n",
      "[2125]\ttraining's rmse: 0.079905\tvalid_1's rmse: 0.0834082\n",
      "[2150]\ttraining's rmse: 0.0799018\tvalid_1's rmse: 0.0834087\n",
      "Early stopping, best iteration is:\n",
      "[2101]\ttraining's rmse: 0.0799077\tvalid_1's rmse: 0.083408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0843487\tvalid_1's rmse: 0.0803607\n",
      "[50]\ttraining's rmse: 0.084238\tvalid_1's rmse: 0.0803113\n",
      "[75]\ttraining's rmse: 0.0841263\tvalid_1's rmse: 0.080264\n",
      "[100]\ttraining's rmse: 0.0840261\tvalid_1's rmse: 0.0802233\n",
      "[125]\ttraining's rmse: 0.0839215\tvalid_1's rmse: 0.0801828\n",
      "[150]\ttraining's rmse: 0.0838263\tvalid_1's rmse: 0.080146\n",
      "[175]\ttraining's rmse: 0.0837474\tvalid_1's rmse: 0.0801152\n",
      "[200]\ttraining's rmse: 0.0836609\tvalid_1's rmse: 0.0800842\n",
      "[225]\ttraining's rmse: 0.083579\tvalid_1's rmse: 0.0800541\n",
      "[250]\ttraining's rmse: 0.0835109\tvalid_1's rmse: 0.0800284\n",
      "[275]\ttraining's rmse: 0.0834473\tvalid_1's rmse: 0.0800029\n",
      "[300]\ttraining's rmse: 0.083384\tvalid_1's rmse: 0.0799794\n",
      "[325]\ttraining's rmse: 0.0833192\tvalid_1's rmse: 0.0799579\n",
      "[350]\ttraining's rmse: 0.083257\tvalid_1's rmse: 0.0799381\n",
      "[375]\ttraining's rmse: 0.0832068\tvalid_1's rmse: 0.0799217\n",
      "[400]\ttraining's rmse: 0.0831495\tvalid_1's rmse: 0.0799135\n",
      "[425]\ttraining's rmse: 0.0830989\tvalid_1's rmse: 0.079904\n",
      "[450]\ttraining's rmse: 0.0830513\tvalid_1's rmse: 0.0798888\n",
      "[475]\ttraining's rmse: 0.083006\tvalid_1's rmse: 0.0798793\n",
      "[500]\ttraining's rmse: 0.082968\tvalid_1's rmse: 0.0798662\n",
      "[525]\ttraining's rmse: 0.0829176\tvalid_1's rmse: 0.0798519\n",
      "[550]\ttraining's rmse: 0.0828749\tvalid_1's rmse: 0.0798404\n",
      "[575]\ttraining's rmse: 0.0828346\tvalid_1's rmse: 0.0798361\n",
      "[600]\ttraining's rmse: 0.0827916\tvalid_1's rmse: 0.0798321\n",
      "[625]\ttraining's rmse: 0.0827594\tvalid_1's rmse: 0.0798278\n",
      "[650]\ttraining's rmse: 0.0827164\tvalid_1's rmse: 0.07982\n",
      "[675]\ttraining's rmse: 0.0826743\tvalid_1's rmse: 0.0798122\n",
      "[700]\ttraining's rmse: 0.082639\tvalid_1's rmse: 0.0798081\n",
      "[725]\ttraining's rmse: 0.0826074\tvalid_1's rmse: 0.0798114\n",
      "[750]\ttraining's rmse: 0.0825752\tvalid_1's rmse: 0.0798115\n",
      "[775]\ttraining's rmse: 0.0825482\tvalid_1's rmse: 0.0798101\n",
      "Early stopping, best iteration is:\n",
      "[747]\ttraining's rmse: 0.0825799\tvalid_1's rmse: 0.0798052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0843747\tvalid_1's rmse: 0.0865659\n",
      "[50]\ttraining's rmse: 0.0842452\tvalid_1's rmse: 0.0865166\n",
      "[75]\ttraining's rmse: 0.0841134\tvalid_1's rmse: 0.0864679\n",
      "[100]\ttraining's rmse: 0.0839938\tvalid_1's rmse: 0.0864248\n",
      "[125]\ttraining's rmse: 0.0838732\tvalid_1's rmse: 0.0863805\n",
      "[150]\ttraining's rmse: 0.0837639\tvalid_1's rmse: 0.0863403\n",
      "[175]\ttraining's rmse: 0.0836747\tvalid_1's rmse: 0.0863072\n",
      "[200]\ttraining's rmse: 0.0835755\tvalid_1's rmse: 0.0862721\n",
      "[225]\ttraining's rmse: 0.0834787\tvalid_1's rmse: 0.0862391\n",
      "[250]\ttraining's rmse: 0.0833991\tvalid_1's rmse: 0.0862092\n",
      "[275]\ttraining's rmse: 0.0833222\tvalid_1's rmse: 0.086183\n",
      "[300]\ttraining's rmse: 0.0832417\tvalid_1's rmse: 0.0861559\n",
      "[325]\ttraining's rmse: 0.083167\tvalid_1's rmse: 0.086131\n",
      "[350]\ttraining's rmse: 0.083094\tvalid_1's rmse: 0.086108\n",
      "[375]\ttraining's rmse: 0.0830317\tvalid_1's rmse: 0.0860887\n",
      "[400]\ttraining's rmse: 0.0829632\tvalid_1's rmse: 0.0860689\n",
      "[425]\ttraining's rmse: 0.082905\tvalid_1's rmse: 0.0860506\n",
      "[450]\ttraining's rmse: 0.0828516\tvalid_1's rmse: 0.0860316\n",
      "[475]\ttraining's rmse: 0.0828008\tvalid_1's rmse: 0.0860149\n",
      "[500]\ttraining's rmse: 0.082757\tvalid_1's rmse: 0.0859986\n",
      "[525]\ttraining's rmse: 0.082701\tvalid_1's rmse: 0.0859819\n",
      "[550]\ttraining's rmse: 0.0826501\tvalid_1's rmse: 0.0859658\n",
      "[575]\ttraining's rmse: 0.0826031\tvalid_1's rmse: 0.0859529\n",
      "[600]\ttraining's rmse: 0.0825587\tvalid_1's rmse: 0.0859409\n",
      "[625]\ttraining's rmse: 0.082526\tvalid_1's rmse: 0.0859298\n",
      "[650]\ttraining's rmse: 0.082481\tvalid_1's rmse: 0.0859179\n",
      "[675]\ttraining's rmse: 0.0824344\tvalid_1's rmse: 0.085907\n",
      "[700]\ttraining's rmse: 0.0823956\tvalid_1's rmse: 0.0858961\n",
      "[725]\ttraining's rmse: 0.0823574\tvalid_1's rmse: 0.0858857\n",
      "[750]\ttraining's rmse: 0.0823215\tvalid_1's rmse: 0.0858764\n",
      "[775]\ttraining's rmse: 0.0822933\tvalid_1's rmse: 0.0858666\n",
      "[800]\ttraining's rmse: 0.0822588\tvalid_1's rmse: 0.0858591\n",
      "[825]\ttraining's rmse: 0.0822273\tvalid_1's rmse: 0.085851\n",
      "[850]\ttraining's rmse: 0.0821965\tvalid_1's rmse: 0.0858444\n",
      "[875]\ttraining's rmse: 0.0821706\tvalid_1's rmse: 0.0858372\n",
      "[900]\ttraining's rmse: 0.0821378\tvalid_1's rmse: 0.0858311\n",
      "[925]\ttraining's rmse: 0.0821115\tvalid_1's rmse: 0.0858246\n",
      "[950]\ttraining's rmse: 0.0820871\tvalid_1's rmse: 0.0858193\n",
      "[975]\ttraining's rmse: 0.0820629\tvalid_1's rmse: 0.0858148\n",
      "[1000]\ttraining's rmse: 0.0820385\tvalid_1's rmse: 0.0858096\n",
      "[1025]\ttraining's rmse: 0.0820138\tvalid_1's rmse: 0.0858037\n",
      "[1050]\ttraining's rmse: 0.0819933\tvalid_1's rmse: 0.0857975\n",
      "[1075]\ttraining's rmse: 0.0819742\tvalid_1's rmse: 0.0857919\n",
      "[1100]\ttraining's rmse: 0.0819558\tvalid_1's rmse: 0.0857868\n",
      "[1125]\ttraining's rmse: 0.0819387\tvalid_1's rmse: 0.085782\n",
      "[1150]\ttraining's rmse: 0.0819176\tvalid_1's rmse: 0.085778\n",
      "[1175]\ttraining's rmse: 0.0818977\tvalid_1's rmse: 0.0857744\n",
      "[1200]\ttraining's rmse: 0.081881\tvalid_1's rmse: 0.0857695\n",
      "[1225]\ttraining's rmse: 0.0818652\tvalid_1's rmse: 0.0857662\n",
      "[1250]\ttraining's rmse: 0.0818495\tvalid_1's rmse: 0.0857621\n",
      "[1275]\ttraining's rmse: 0.081832\tvalid_1's rmse: 0.0857587\n",
      "[1300]\ttraining's rmse: 0.0818209\tvalid_1's rmse: 0.085755\n",
      "[1325]\ttraining's rmse: 0.0818037\tvalid_1's rmse: 0.0857521\n",
      "[1350]\ttraining's rmse: 0.081787\tvalid_1's rmse: 0.0857486\n",
      "[1375]\ttraining's rmse: 0.081773\tvalid_1's rmse: 0.0857452\n",
      "[1400]\ttraining's rmse: 0.0817604\tvalid_1's rmse: 0.0857424\n",
      "[1425]\ttraining's rmse: 0.0817459\tvalid_1's rmse: 0.0857395\n",
      "[1450]\ttraining's rmse: 0.0817331\tvalid_1's rmse: 0.0857361\n",
      "[1475]\ttraining's rmse: 0.0817221\tvalid_1's rmse: 0.085734\n",
      "[1500]\ttraining's rmse: 0.0817141\tvalid_1's rmse: 0.0857314\n",
      "[1525]\ttraining's rmse: 0.0817032\tvalid_1's rmse: 0.0857284\n",
      "[1550]\ttraining's rmse: 0.0816944\tvalid_1's rmse: 0.0857268\n",
      "[1575]\ttraining's rmse: 0.0816852\tvalid_1's rmse: 0.0857241\n",
      "[1600]\ttraining's rmse: 0.0816774\tvalid_1's rmse: 0.0857218\n",
      "[1625]\ttraining's rmse: 0.0816711\tvalid_1's rmse: 0.0857188\n",
      "[1650]\ttraining's rmse: 0.0816625\tvalid_1's rmse: 0.0857164\n",
      "[1675]\ttraining's rmse: 0.0816577\tvalid_1's rmse: 0.0857148\n",
      "[1700]\ttraining's rmse: 0.0816523\tvalid_1's rmse: 0.0857118\n",
      "[1725]\ttraining's rmse: 0.0816455\tvalid_1's rmse: 0.0857092\n",
      "[1750]\ttraining's rmse: 0.0816399\tvalid_1's rmse: 0.0857075\n",
      "[1775]\ttraining's rmse: 0.0816351\tvalid_1's rmse: 0.0857064\n",
      "[1800]\ttraining's rmse: 0.0816281\tvalid_1's rmse: 0.0857038\n",
      "[1825]\ttraining's rmse: 0.0816215\tvalid_1's rmse: 0.0857029\n",
      "[1850]\ttraining's rmse: 0.0816165\tvalid_1's rmse: 0.0857007\n",
      "[1875]\ttraining's rmse: 0.0816116\tvalid_1's rmse: 0.0857\n",
      "[1900]\ttraining's rmse: 0.0816066\tvalid_1's rmse: 0.0856983\n",
      "[1925]\ttraining's rmse: 0.0816014\tvalid_1's rmse: 0.0856967\n",
      "[1950]\ttraining's rmse: 0.081597\tvalid_1's rmse: 0.0856947\n",
      "[1975]\ttraining's rmse: 0.0815935\tvalid_1's rmse: 0.0856938\n",
      "[2000]\ttraining's rmse: 0.0815906\tvalid_1's rmse: 0.0856931\n",
      "[2025]\ttraining's rmse: 0.0815864\tvalid_1's rmse: 0.085691\n",
      "[2050]\ttraining's rmse: 0.0815819\tvalid_1's rmse: 0.0856907\n",
      "[2075]\ttraining's rmse: 0.0815785\tvalid_1's rmse: 0.0856888\n",
      "[2100]\ttraining's rmse: 0.0815751\tvalid_1's rmse: 0.0856875\n",
      "[2125]\ttraining's rmse: 0.0815722\tvalid_1's rmse: 0.0856866\n",
      "[2150]\ttraining's rmse: 0.0815677\tvalid_1's rmse: 0.085686\n",
      "[2175]\ttraining's rmse: 0.0815641\tvalid_1's rmse: 0.0856855\n",
      "[2200]\ttraining's rmse: 0.0815614\tvalid_1's rmse: 0.085685\n",
      "[2225]\ttraining's rmse: 0.0815577\tvalid_1's rmse: 0.0856837\n",
      "[2250]\ttraining's rmse: 0.0815544\tvalid_1's rmse: 0.0856828\n",
      "[2275]\ttraining's rmse: 0.0815511\tvalid_1's rmse: 0.0856817\n",
      "[2300]\ttraining's rmse: 0.0815485\tvalid_1's rmse: 0.0856799\n",
      "[2325]\ttraining's rmse: 0.0815454\tvalid_1's rmse: 0.0856792\n",
      "[2350]\ttraining's rmse: 0.0815433\tvalid_1's rmse: 0.085679\n",
      "[2375]\ttraining's rmse: 0.0815403\tvalid_1's rmse: 0.0856782\n",
      "[2400]\ttraining's rmse: 0.0815371\tvalid_1's rmse: 0.0856781\n",
      "[2425]\ttraining's rmse: 0.0815343\tvalid_1's rmse: 0.0856769\n",
      "[2450]\ttraining's rmse: 0.0815322\tvalid_1's rmse: 0.0856765\n",
      "[2475]\ttraining's rmse: 0.0815295\tvalid_1's rmse: 0.0856764\n",
      "Early stopping, best iteration is:\n",
      "[2435]\ttraining's rmse: 0.0815334\tvalid_1's rmse: 0.0856762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0843437\tvalid_1's rmse: 0.0866486\n",
      "[50]\ttraining's rmse: 0.0842287\tvalid_1's rmse: 0.0865981\n",
      "[75]\ttraining's rmse: 0.0841049\tvalid_1's rmse: 0.0865459\n",
      "[100]\ttraining's rmse: 0.0839971\tvalid_1's rmse: 0.0865012\n",
      "[125]\ttraining's rmse: 0.0838832\tvalid_1's rmse: 0.0864572\n",
      "[150]\ttraining's rmse: 0.0837808\tvalid_1's rmse: 0.0864144\n",
      "[175]\ttraining's rmse: 0.0836972\tvalid_1's rmse: 0.0863798\n",
      "[200]\ttraining's rmse: 0.083601\tvalid_1's rmse: 0.0863436\n",
      "[225]\ttraining's rmse: 0.0835076\tvalid_1's rmse: 0.08631\n",
      "[250]\ttraining's rmse: 0.0834296\tvalid_1's rmse: 0.0862795\n",
      "[275]\ttraining's rmse: 0.0833573\tvalid_1's rmse: 0.086252\n",
      "[300]\ttraining's rmse: 0.0832851\tvalid_1's rmse: 0.0862267\n",
      "[325]\ttraining's rmse: 0.0832129\tvalid_1's rmse: 0.0862021\n",
      "[350]\ttraining's rmse: 0.0831428\tvalid_1's rmse: 0.0861788\n",
      "[375]\ttraining's rmse: 0.0830836\tvalid_1's rmse: 0.0861571\n",
      "[400]\ttraining's rmse: 0.0830215\tvalid_1's rmse: 0.0861372\n",
      "[425]\ttraining's rmse: 0.0829649\tvalid_1's rmse: 0.0861189\n",
      "[450]\ttraining's rmse: 0.0829115\tvalid_1's rmse: 0.0861001\n",
      "[475]\ttraining's rmse: 0.0828625\tvalid_1's rmse: 0.0860835\n",
      "[500]\ttraining's rmse: 0.0828202\tvalid_1's rmse: 0.0860674\n",
      "[525]\ttraining's rmse: 0.0827669\tvalid_1's rmse: 0.0860516\n",
      "[550]\ttraining's rmse: 0.0827181\tvalid_1's rmse: 0.0860373\n",
      "[575]\ttraining's rmse: 0.0826724\tvalid_1's rmse: 0.0860237\n",
      "[600]\ttraining's rmse: 0.0826284\tvalid_1's rmse: 0.0860118\n",
      "[625]\ttraining's rmse: 0.0825949\tvalid_1's rmse: 0.0860003\n",
      "[650]\ttraining's rmse: 0.0825508\tvalid_1's rmse: 0.0859882\n",
      "[675]\ttraining's rmse: 0.0825089\tvalid_1's rmse: 0.0859777\n",
      "[700]\ttraining's rmse: 0.0824702\tvalid_1's rmse: 0.0859672\n",
      "[725]\ttraining's rmse: 0.0824347\tvalid_1's rmse: 0.085958\n",
      "[750]\ttraining's rmse: 0.0824013\tvalid_1's rmse: 0.085949\n",
      "[775]\ttraining's rmse: 0.082373\tvalid_1's rmse: 0.0859405\n",
      "[800]\ttraining's rmse: 0.0823378\tvalid_1's rmse: 0.0859324\n",
      "[825]\ttraining's rmse: 0.0823087\tvalid_1's rmse: 0.0859241\n",
      "[850]\ttraining's rmse: 0.0822789\tvalid_1's rmse: 0.0859174\n",
      "[875]\ttraining's rmse: 0.082251\tvalid_1's rmse: 0.085911\n",
      "[900]\ttraining's rmse: 0.0822234\tvalid_1's rmse: 0.0859047\n",
      "[925]\ttraining's rmse: 0.0821965\tvalid_1's rmse: 0.085899\n",
      "[950]\ttraining's rmse: 0.082173\tvalid_1's rmse: 0.0858935\n",
      "[975]\ttraining's rmse: 0.0821502\tvalid_1's rmse: 0.0858886\n",
      "[1000]\ttraining's rmse: 0.0821298\tvalid_1's rmse: 0.0858834\n",
      "[1025]\ttraining's rmse: 0.0821041\tvalid_1's rmse: 0.0858786\n",
      "[1050]\ttraining's rmse: 0.0820861\tvalid_1's rmse: 0.0858736\n",
      "[1075]\ttraining's rmse: 0.0820664\tvalid_1's rmse: 0.0858699\n",
      "[1100]\ttraining's rmse: 0.0820484\tvalid_1's rmse: 0.0858655\n",
      "[1125]\ttraining's rmse: 0.0820302\tvalid_1's rmse: 0.0858621\n",
      "[1150]\ttraining's rmse: 0.0820087\tvalid_1's rmse: 0.085858\n",
      "[1175]\ttraining's rmse: 0.0819942\tvalid_1's rmse: 0.0858548\n",
      "[1200]\ttraining's rmse: 0.081978\tvalid_1's rmse: 0.0858516\n",
      "[1225]\ttraining's rmse: 0.0819612\tvalid_1's rmse: 0.0858486\n",
      "[1250]\ttraining's rmse: 0.0819473\tvalid_1's rmse: 0.0858453\n",
      "[1275]\ttraining's rmse: 0.0819315\tvalid_1's rmse: 0.0858437\n",
      "[1300]\ttraining's rmse: 0.0819188\tvalid_1's rmse: 0.0858412\n",
      "[1325]\ttraining's rmse: 0.0819026\tvalid_1's rmse: 0.085839\n",
      "[1350]\ttraining's rmse: 0.0818899\tvalid_1's rmse: 0.0858372\n",
      "[1375]\ttraining's rmse: 0.0818757\tvalid_1's rmse: 0.0858356\n",
      "[1400]\ttraining's rmse: 0.0818655\tvalid_1's rmse: 0.0858324\n",
      "[1425]\ttraining's rmse: 0.0818512\tvalid_1's rmse: 0.0858312\n",
      "[1450]\ttraining's rmse: 0.0818404\tvalid_1's rmse: 0.0858304\n",
      "[1475]\ttraining's rmse: 0.0818313\tvalid_1's rmse: 0.0858282\n",
      "[1500]\ttraining's rmse: 0.0818237\tvalid_1's rmse: 0.0858262\n",
      "[1525]\ttraining's rmse: 0.0818133\tvalid_1's rmse: 0.0858245\n",
      "[1550]\ttraining's rmse: 0.0818024\tvalid_1's rmse: 0.0858236\n",
      "[1575]\ttraining's rmse: 0.0817938\tvalid_1's rmse: 0.0858221\n",
      "[1600]\ttraining's rmse: 0.0817869\tvalid_1's rmse: 0.0858218\n",
      "[1625]\ttraining's rmse: 0.0817805\tvalid_1's rmse: 0.0858206\n",
      "[1650]\ttraining's rmse: 0.0817719\tvalid_1's rmse: 0.0858198\n",
      "[1675]\ttraining's rmse: 0.0817669\tvalid_1's rmse: 0.0858189\n",
      "[1700]\ttraining's rmse: 0.0817612\tvalid_1's rmse: 0.0858179\n",
      "[1725]\ttraining's rmse: 0.0817549\tvalid_1's rmse: 0.0858171\n",
      "[1750]\ttraining's rmse: 0.0817472\tvalid_1's rmse: 0.0858167\n",
      "[1775]\ttraining's rmse: 0.0817405\tvalid_1's rmse: 0.0858163\n",
      "[1800]\ttraining's rmse: 0.0817343\tvalid_1's rmse: 0.0858155\n",
      "[1825]\ttraining's rmse: 0.0817281\tvalid_1's rmse: 0.0858145\n",
      "[1850]\ttraining's rmse: 0.0817228\tvalid_1's rmse: 0.0858136\n",
      "[1875]\ttraining's rmse: 0.0817178\tvalid_1's rmse: 0.0858132\n",
      "[1900]\ttraining's rmse: 0.0817126\tvalid_1's rmse: 0.085813\n",
      "[1925]\ttraining's rmse: 0.0817069\tvalid_1's rmse: 0.0858125\n",
      "[1950]\ttraining's rmse: 0.0817024\tvalid_1's rmse: 0.0858112\n",
      "[1975]\ttraining's rmse: 0.0816989\tvalid_1's rmse: 0.0858111\n",
      "[2000]\ttraining's rmse: 0.0816953\tvalid_1's rmse: 0.0858106\n",
      "[2025]\ttraining's rmse: 0.0816912\tvalid_1's rmse: 0.0858099\n",
      "[2050]\ttraining's rmse: 0.0816863\tvalid_1's rmse: 0.0858096\n",
      "[2075]\ttraining's rmse: 0.0816844\tvalid_1's rmse: 0.0858092\n",
      "[2100]\ttraining's rmse: 0.0816807\tvalid_1's rmse: 0.0858086\n",
      "[2125]\ttraining's rmse: 0.0816772\tvalid_1's rmse: 0.0858086\n",
      "[2150]\ttraining's rmse: 0.0816727\tvalid_1's rmse: 0.0858085\n",
      "[2175]\ttraining's rmse: 0.0816697\tvalid_1's rmse: 0.0858083\n",
      "[2200]\ttraining's rmse: 0.0816659\tvalid_1's rmse: 0.0858076\n",
      "[2225]\ttraining's rmse: 0.0816626\tvalid_1's rmse: 0.0858074\n",
      "[2250]\ttraining's rmse: 0.0816605\tvalid_1's rmse: 0.0858072\n",
      "[2275]\ttraining's rmse: 0.0816566\tvalid_1's rmse: 0.0858068\n",
      "[2300]\ttraining's rmse: 0.0816526\tvalid_1's rmse: 0.0858064\n",
      "[2325]\ttraining's rmse: 0.0816493\tvalid_1's rmse: 0.0858064\n",
      "[2350]\ttraining's rmse: 0.0816466\tvalid_1's rmse: 0.0858063\n",
      "[2375]\ttraining's rmse: 0.0816431\tvalid_1's rmse: 0.0858063\n",
      "Early stopping, best iteration is:\n",
      "[2335]\ttraining's rmse: 0.0816484\tvalid_1's rmse: 0.0858059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0864902\tvalid_1's rmse: 0.0822994\n",
      "[50]\ttraining's rmse: 0.0863821\tvalid_1's rmse: 0.0822527\n",
      "[75]\ttraining's rmse: 0.0862672\tvalid_1's rmse: 0.0822051\n",
      "[100]\ttraining's rmse: 0.0861657\tvalid_1's rmse: 0.0821628\n",
      "[125]\ttraining's rmse: 0.0860599\tvalid_1's rmse: 0.0821207\n",
      "[150]\ttraining's rmse: 0.0859608\tvalid_1's rmse: 0.0820835\n",
      "[175]\ttraining's rmse: 0.0858786\tvalid_1's rmse: 0.0820563\n",
      "[200]\ttraining's rmse: 0.0857892\tvalid_1's rmse: 0.0820261\n",
      "[225]\ttraining's rmse: 0.0857036\tvalid_1's rmse: 0.0819938\n",
      "[250]\ttraining's rmse: 0.0856329\tvalid_1's rmse: 0.081968\n",
      "[275]\ttraining's rmse: 0.0855673\tvalid_1's rmse: 0.0819423\n",
      "[300]\ttraining's rmse: 0.0854993\tvalid_1's rmse: 0.0819178\n",
      "[325]\ttraining's rmse: 0.0854347\tvalid_1's rmse: 0.0818975\n",
      "[350]\ttraining's rmse: 0.0853685\tvalid_1's rmse: 0.0818767\n",
      "[375]\ttraining's rmse: 0.085313\tvalid_1's rmse: 0.0818641\n",
      "[400]\ttraining's rmse: 0.085254\tvalid_1's rmse: 0.081845\n",
      "[425]\ttraining's rmse: 0.0852003\tvalid_1's rmse: 0.0818338\n",
      "[450]\ttraining's rmse: 0.0851535\tvalid_1's rmse: 0.0818185\n",
      "[475]\ttraining's rmse: 0.0851063\tvalid_1's rmse: 0.0818047\n",
      "[500]\ttraining's rmse: 0.085068\tvalid_1's rmse: 0.0817913\n",
      "[525]\ttraining's rmse: 0.0850147\tvalid_1's rmse: 0.0817772\n",
      "[550]\ttraining's rmse: 0.0849686\tvalid_1's rmse: 0.0817642\n",
      "[575]\ttraining's rmse: 0.0849233\tvalid_1's rmse: 0.0817521\n",
      "[600]\ttraining's rmse: 0.0848808\tvalid_1's rmse: 0.0817437\n",
      "[625]\ttraining's rmse: 0.0848474\tvalid_1's rmse: 0.0817382\n",
      "[650]\ttraining's rmse: 0.0848049\tvalid_1's rmse: 0.0817277\n",
      "[675]\ttraining's rmse: 0.0847628\tvalid_1's rmse: 0.0817283\n",
      "[700]\ttraining's rmse: 0.0847259\tvalid_1's rmse: 0.0817197\n",
      "[725]\ttraining's rmse: 0.0846922\tvalid_1's rmse: 0.0817133\n",
      "[750]\ttraining's rmse: 0.0846596\tvalid_1's rmse: 0.0817101\n",
      "[775]\ttraining's rmse: 0.084633\tvalid_1's rmse: 0.0817092\n",
      "[800]\ttraining's rmse: 0.0845976\tvalid_1's rmse: 0.0817036\n",
      "[825]\ttraining's rmse: 0.0845686\tvalid_1's rmse: 0.0817048\n",
      "[850]\ttraining's rmse: 0.0845384\tvalid_1's rmse: 0.0816994\n",
      "[875]\ttraining's rmse: 0.0845107\tvalid_1's rmse: 0.0816982\n",
      "[900]\ttraining's rmse: 0.0844806\tvalid_1's rmse: 0.0816984\n",
      "Early stopping, best iteration is:\n",
      "[873]\ttraining's rmse: 0.0845119\tvalid_1's rmse: 0.0816944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0826853\tvalid_1's rmse: 0.0852744\n",
      "[50]\ttraining's rmse: 0.0825626\tvalid_1's rmse: 0.085221\n",
      "[75]\ttraining's rmse: 0.0824367\tvalid_1's rmse: 0.0851686\n",
      "[100]\ttraining's rmse: 0.0823198\tvalid_1's rmse: 0.0851242\n",
      "[125]\ttraining's rmse: 0.082204\tvalid_1's rmse: 0.0850797\n",
      "[150]\ttraining's rmse: 0.0820983\tvalid_1's rmse: 0.0850388\n",
      "[175]\ttraining's rmse: 0.0820112\tvalid_1's rmse: 0.085002\n",
      "[200]\ttraining's rmse: 0.0819191\tvalid_1's rmse: 0.0849679\n",
      "[225]\ttraining's rmse: 0.0818248\tvalid_1's rmse: 0.0849332\n",
      "[250]\ttraining's rmse: 0.08175\tvalid_1's rmse: 0.0849016\n",
      "[275]\ttraining's rmse: 0.0816762\tvalid_1's rmse: 0.0848738\n",
      "[300]\ttraining's rmse: 0.0816035\tvalid_1's rmse: 0.084846\n",
      "[325]\ttraining's rmse: 0.0815315\tvalid_1's rmse: 0.0848191\n",
      "[350]\ttraining's rmse: 0.0814647\tvalid_1's rmse: 0.0847961\n",
      "[375]\ttraining's rmse: 0.0814076\tvalid_1's rmse: 0.0847761\n",
      "[400]\ttraining's rmse: 0.0813455\tvalid_1's rmse: 0.0847545\n",
      "[425]\ttraining's rmse: 0.0812915\tvalid_1's rmse: 0.0847353\n",
      "[450]\ttraining's rmse: 0.0812405\tvalid_1's rmse: 0.0847161\n",
      "[475]\ttraining's rmse: 0.0811935\tvalid_1's rmse: 0.0846992\n",
      "[500]\ttraining's rmse: 0.0811528\tvalid_1's rmse: 0.0846824\n",
      "[525]\ttraining's rmse: 0.0811022\tvalid_1's rmse: 0.0846665\n",
      "[550]\ttraining's rmse: 0.0810567\tvalid_1's rmse: 0.0846517\n",
      "[575]\ttraining's rmse: 0.0810113\tvalid_1's rmse: 0.0846385\n",
      "[600]\ttraining's rmse: 0.0809684\tvalid_1's rmse: 0.0846244\n",
      "[625]\ttraining's rmse: 0.0809359\tvalid_1's rmse: 0.084613\n",
      "[650]\ttraining's rmse: 0.0808948\tvalid_1's rmse: 0.0846003\n",
      "[675]\ttraining's rmse: 0.0808536\tvalid_1's rmse: 0.0845883\n",
      "[700]\ttraining's rmse: 0.0808153\tvalid_1's rmse: 0.0845742\n",
      "[725]\ttraining's rmse: 0.0807792\tvalid_1's rmse: 0.0845642\n",
      "[750]\ttraining's rmse: 0.0807466\tvalid_1's rmse: 0.0845551\n",
      "[775]\ttraining's rmse: 0.0807225\tvalid_1's rmse: 0.0845468\n",
      "[800]\ttraining's rmse: 0.0806912\tvalid_1's rmse: 0.0845381\n",
      "[825]\ttraining's rmse: 0.0806636\tvalid_1's rmse: 0.0845298\n",
      "[850]\ttraining's rmse: 0.0806349\tvalid_1's rmse: 0.0845231\n",
      "[875]\ttraining's rmse: 0.0806096\tvalid_1's rmse: 0.0845155\n",
      "[900]\ttraining's rmse: 0.0805823\tvalid_1's rmse: 0.0845091\n",
      "[925]\ttraining's rmse: 0.0805577\tvalid_1's rmse: 0.084502\n",
      "[950]\ttraining's rmse: 0.0805334\tvalid_1's rmse: 0.0844961\n",
      "[975]\ttraining's rmse: 0.0805115\tvalid_1's rmse: 0.0844902\n",
      "[1000]\ttraining's rmse: 0.0804931\tvalid_1's rmse: 0.0844855\n",
      "[1025]\ttraining's rmse: 0.0804716\tvalid_1's rmse: 0.0844783\n",
      "[1050]\ttraining's rmse: 0.0804525\tvalid_1's rmse: 0.0844714\n",
      "[1075]\ttraining's rmse: 0.0804335\tvalid_1's rmse: 0.0844681\n",
      "[1100]\ttraining's rmse: 0.0804174\tvalid_1's rmse: 0.0844621\n",
      "[1125]\ttraining's rmse: 0.080401\tvalid_1's rmse: 0.0844566\n",
      "[1150]\ttraining's rmse: 0.0803844\tvalid_1's rmse: 0.0844517\n",
      "[1175]\ttraining's rmse: 0.080368\tvalid_1's rmse: 0.0844475\n",
      "[1200]\ttraining's rmse: 0.080354\tvalid_1's rmse: 0.0844427\n",
      "[1225]\ttraining's rmse: 0.0803389\tvalid_1's rmse: 0.0844397\n",
      "[1250]\ttraining's rmse: 0.0803243\tvalid_1's rmse: 0.0844357\n",
      "[1275]\ttraining's rmse: 0.080307\tvalid_1's rmse: 0.0844323\n",
      "[1300]\ttraining's rmse: 0.0802954\tvalid_1's rmse: 0.084428\n",
      "[1325]\ttraining's rmse: 0.0802837\tvalid_1's rmse: 0.084425\n",
      "[1350]\ttraining's rmse: 0.0802722\tvalid_1's rmse: 0.0844218\n",
      "[1375]\ttraining's rmse: 0.0802586\tvalid_1's rmse: 0.084419\n",
      "[1400]\ttraining's rmse: 0.0802475\tvalid_1's rmse: 0.0844151\n",
      "[1425]\ttraining's rmse: 0.0802362\tvalid_1's rmse: 0.0844123\n",
      "[1450]\ttraining's rmse: 0.0802248\tvalid_1's rmse: 0.0844096\n",
      "[1475]\ttraining's rmse: 0.0802159\tvalid_1's rmse: 0.0844062\n",
      "[1500]\ttraining's rmse: 0.080208\tvalid_1's rmse: 0.0844036\n",
      "[1525]\ttraining's rmse: 0.0802006\tvalid_1's rmse: 0.0844002\n",
      "[1550]\ttraining's rmse: 0.0801927\tvalid_1's rmse: 0.0843984\n",
      "[1575]\ttraining's rmse: 0.0801852\tvalid_1's rmse: 0.0843966\n",
      "[1600]\ttraining's rmse: 0.08018\tvalid_1's rmse: 0.0843943\n",
      "[1625]\ttraining's rmse: 0.0801731\tvalid_1's rmse: 0.0843909\n",
      "[1650]\ttraining's rmse: 0.0801655\tvalid_1's rmse: 0.0843893\n",
      "[1675]\ttraining's rmse: 0.0801584\tvalid_1's rmse: 0.0843874\n",
      "[1700]\ttraining's rmse: 0.0801532\tvalid_1's rmse: 0.0843859\n",
      "[1725]\ttraining's rmse: 0.0801479\tvalid_1's rmse: 0.084385\n",
      "[1750]\ttraining's rmse: 0.0801402\tvalid_1's rmse: 0.0843828\n",
      "[1775]\ttraining's rmse: 0.0801327\tvalid_1's rmse: 0.084381\n",
      "[1800]\ttraining's rmse: 0.0801242\tvalid_1's rmse: 0.0843786\n",
      "[1825]\ttraining's rmse: 0.0801195\tvalid_1's rmse: 0.0843768\n",
      "[1850]\ttraining's rmse: 0.0801158\tvalid_1's rmse: 0.0843749\n",
      "[1875]\ttraining's rmse: 0.0801114\tvalid_1's rmse: 0.0843738\n",
      "[1900]\ttraining's rmse: 0.0801071\tvalid_1's rmse: 0.0843712\n",
      "[1925]\ttraining's rmse: 0.0801025\tvalid_1's rmse: 0.0843697\n",
      "[1950]\ttraining's rmse: 0.0800974\tvalid_1's rmse: 0.0843682\n",
      "[1975]\ttraining's rmse: 0.0800922\tvalid_1's rmse: 0.0843667\n",
      "[2000]\ttraining's rmse: 0.0800891\tvalid_1's rmse: 0.0843652\n",
      "[2025]\ttraining's rmse: 0.0800863\tvalid_1's rmse: 0.0843648\n",
      "[2050]\ttraining's rmse: 0.0800827\tvalid_1's rmse: 0.084363\n",
      "[2075]\ttraining's rmse: 0.0800793\tvalid_1's rmse: 0.0843624\n",
      "[2100]\ttraining's rmse: 0.0800762\tvalid_1's rmse: 0.0843615\n",
      "[2125]\ttraining's rmse: 0.0800722\tvalid_1's rmse: 0.0843611\n",
      "[2150]\ttraining's rmse: 0.0800689\tvalid_1's rmse: 0.0843603\n",
      "[2175]\ttraining's rmse: 0.0800662\tvalid_1's rmse: 0.0843602\n",
      "[2200]\ttraining's rmse: 0.0800627\tvalid_1's rmse: 0.0843591\n",
      "[2225]\ttraining's rmse: 0.0800599\tvalid_1's rmse: 0.084357\n",
      "[2250]\ttraining's rmse: 0.0800557\tvalid_1's rmse: 0.0843565\n",
      "[2275]\ttraining's rmse: 0.0800524\tvalid_1's rmse: 0.0843556\n",
      "[2300]\ttraining's rmse: 0.080049\tvalid_1's rmse: 0.0843542\n",
      "[2325]\ttraining's rmse: 0.0800458\tvalid_1's rmse: 0.0843533\n",
      "[2350]\ttraining's rmse: 0.0800437\tvalid_1's rmse: 0.0843522\n",
      "[2375]\ttraining's rmse: 0.0800411\tvalid_1's rmse: 0.0843516\n",
      "[2400]\ttraining's rmse: 0.0800382\tvalid_1's rmse: 0.0843505\n",
      "[2425]\ttraining's rmse: 0.0800357\tvalid_1's rmse: 0.0843503\n",
      "[2450]\ttraining's rmse: 0.0800333\tvalid_1's rmse: 0.0843494\n",
      "[2475]\ttraining's rmse: 0.0800309\tvalid_1's rmse: 0.084349\n",
      "[2500]\ttraining's rmse: 0.0800285\tvalid_1's rmse: 0.0843489\n",
      "[2525]\ttraining's rmse: 0.080025\tvalid_1's rmse: 0.0843471\n",
      "[2550]\ttraining's rmse: 0.0800229\tvalid_1's rmse: 0.0843464\n",
      "[2575]\ttraining's rmse: 0.0800193\tvalid_1's rmse: 0.084346\n",
      "[2600]\ttraining's rmse: 0.080018\tvalid_1's rmse: 0.0843456\n",
      "[2625]\ttraining's rmse: 0.0800163\tvalid_1's rmse: 0.0843449\n",
      "[2650]\ttraining's rmse: 0.0800148\tvalid_1's rmse: 0.0843439\n",
      "[2675]\ttraining's rmse: 0.0800129\tvalid_1's rmse: 0.084344\n",
      "[2700]\ttraining's rmse: 0.0800118\tvalid_1's rmse: 0.0843431\n",
      "[2725]\ttraining's rmse: 0.0800102\tvalid_1's rmse: 0.0843427\n",
      "[2750]\ttraining's rmse: 0.0800084\tvalid_1's rmse: 0.0843427\n",
      "[2775]\ttraining's rmse: 0.0800065\tvalid_1's rmse: 0.0843421\n",
      "[2800]\ttraining's rmse: 0.0800051\tvalid_1's rmse: 0.0843421\n",
      "Early stopping, best iteration is:\n",
      "[2773]\ttraining's rmse: 0.0800065\tvalid_1's rmse: 0.084342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0829059\tvalid_1's rmse: 0.0848537\n",
      "[50]\ttraining's rmse: 0.0827933\tvalid_1's rmse: 0.0848007\n",
      "[75]\ttraining's rmse: 0.0826789\tvalid_1's rmse: 0.0847499\n",
      "[100]\ttraining's rmse: 0.0825761\tvalid_1's rmse: 0.0847045\n",
      "[125]\ttraining's rmse: 0.082468\tvalid_1's rmse: 0.0846577\n",
      "[150]\ttraining's rmse: 0.0823711\tvalid_1's rmse: 0.0846163\n",
      "[175]\ttraining's rmse: 0.0822905\tvalid_1's rmse: 0.0845826\n",
      "[200]\ttraining's rmse: 0.0822014\tvalid_1's rmse: 0.0845474\n",
      "[225]\ttraining's rmse: 0.082114\tvalid_1's rmse: 0.0845131\n",
      "[250]\ttraining's rmse: 0.0820405\tvalid_1's rmse: 0.0844833\n",
      "[275]\ttraining's rmse: 0.0819725\tvalid_1's rmse: 0.0844554\n",
      "[300]\ttraining's rmse: 0.0819037\tvalid_1's rmse: 0.0844292\n",
      "[325]\ttraining's rmse: 0.0818331\tvalid_1's rmse: 0.0844034\n",
      "[350]\ttraining's rmse: 0.0817681\tvalid_1's rmse: 0.0843795\n",
      "[375]\ttraining's rmse: 0.0817133\tvalid_1's rmse: 0.0843598\n",
      "[400]\ttraining's rmse: 0.0816522\tvalid_1's rmse: 0.0843389\n",
      "[425]\ttraining's rmse: 0.0815968\tvalid_1's rmse: 0.0843187\n",
      "[450]\ttraining's rmse: 0.0815471\tvalid_1's rmse: 0.0843009\n",
      "[475]\ttraining's rmse: 0.0815015\tvalid_1's rmse: 0.0842849\n",
      "[500]\ttraining's rmse: 0.0814608\tvalid_1's rmse: 0.084269\n",
      "[525]\ttraining's rmse: 0.0814079\tvalid_1's rmse: 0.084254\n",
      "[550]\ttraining's rmse: 0.0813575\tvalid_1's rmse: 0.084239\n",
      "[575]\ttraining's rmse: 0.0813144\tvalid_1's rmse: 0.0842252\n",
      "[600]\ttraining's rmse: 0.0812708\tvalid_1's rmse: 0.0842126\n",
      "[625]\ttraining's rmse: 0.0812371\tvalid_1's rmse: 0.0842001\n",
      "[650]\ttraining's rmse: 0.0811938\tvalid_1's rmse: 0.0841878\n",
      "[675]\ttraining's rmse: 0.0811513\tvalid_1's rmse: 0.0841766\n",
      "[700]\ttraining's rmse: 0.0811126\tvalid_1's rmse: 0.0841651\n",
      "[725]\ttraining's rmse: 0.0810776\tvalid_1's rmse: 0.0841549\n",
      "[750]\ttraining's rmse: 0.081046\tvalid_1's rmse: 0.0841459\n",
      "[775]\ttraining's rmse: 0.0810189\tvalid_1's rmse: 0.0841374\n",
      "[800]\ttraining's rmse: 0.0809851\tvalid_1's rmse: 0.0841299\n",
      "[825]\ttraining's rmse: 0.0809573\tvalid_1's rmse: 0.0841225\n",
      "[850]\ttraining's rmse: 0.0809302\tvalid_1's rmse: 0.084116\n",
      "[875]\ttraining's rmse: 0.0809045\tvalid_1's rmse: 0.0841097\n",
      "[900]\ttraining's rmse: 0.0808769\tvalid_1's rmse: 0.0841033\n",
      "[925]\ttraining's rmse: 0.0808517\tvalid_1's rmse: 0.0840978\n",
      "[950]\ttraining's rmse: 0.0808268\tvalid_1's rmse: 0.0840922\n",
      "[975]\ttraining's rmse: 0.0808038\tvalid_1's rmse: 0.0840873\n",
      "[1000]\ttraining's rmse: 0.0807811\tvalid_1's rmse: 0.0840829\n",
      "[1025]\ttraining's rmse: 0.0807553\tvalid_1's rmse: 0.0840786\n",
      "[1050]\ttraining's rmse: 0.0807362\tvalid_1's rmse: 0.0840748\n",
      "[1075]\ttraining's rmse: 0.0807162\tvalid_1's rmse: 0.0840716\n",
      "[1100]\ttraining's rmse: 0.0807006\tvalid_1's rmse: 0.0840684\n",
      "[1125]\ttraining's rmse: 0.0806839\tvalid_1's rmse: 0.0840647\n",
      "[1150]\ttraining's rmse: 0.080667\tvalid_1's rmse: 0.0840607\n",
      "[1175]\ttraining's rmse: 0.0806501\tvalid_1's rmse: 0.0840569\n",
      "[1200]\ttraining's rmse: 0.0806346\tvalid_1's rmse: 0.0840536\n",
      "[1225]\ttraining's rmse: 0.0806188\tvalid_1's rmse: 0.0840507\n",
      "[1250]\ttraining's rmse: 0.0806053\tvalid_1's rmse: 0.0840477\n",
      "[1275]\ttraining's rmse: 0.0805883\tvalid_1's rmse: 0.0840449\n",
      "[1300]\ttraining's rmse: 0.0805749\tvalid_1's rmse: 0.0840423\n",
      "[1325]\ttraining's rmse: 0.0805625\tvalid_1's rmse: 0.0840401\n",
      "[1350]\ttraining's rmse: 0.0805487\tvalid_1's rmse: 0.0840384\n",
      "[1375]\ttraining's rmse: 0.0805372\tvalid_1's rmse: 0.0840362\n",
      "[1400]\ttraining's rmse: 0.0805284\tvalid_1's rmse: 0.0840336\n",
      "[1425]\ttraining's rmse: 0.0805158\tvalid_1's rmse: 0.0840322\n",
      "[1450]\ttraining's rmse: 0.0805054\tvalid_1's rmse: 0.0840309\n",
      "[1475]\ttraining's rmse: 0.0804951\tvalid_1's rmse: 0.0840289\n",
      "[1500]\ttraining's rmse: 0.0804868\tvalid_1's rmse: 0.0840274\n",
      "[1525]\ttraining's rmse: 0.0804763\tvalid_1's rmse: 0.0840262\n",
      "[1550]\ttraining's rmse: 0.0804673\tvalid_1's rmse: 0.0840253\n",
      "[1575]\ttraining's rmse: 0.0804594\tvalid_1's rmse: 0.0840239\n",
      "[1600]\ttraining's rmse: 0.080451\tvalid_1's rmse: 0.0840228\n",
      "[1625]\ttraining's rmse: 0.0804425\tvalid_1's rmse: 0.0840218\n",
      "[1650]\ttraining's rmse: 0.0804348\tvalid_1's rmse: 0.0840206\n",
      "[1675]\ttraining's rmse: 0.0804291\tvalid_1's rmse: 0.0840198\n",
      "[1700]\ttraining's rmse: 0.0804241\tvalid_1's rmse: 0.084019\n",
      "[1725]\ttraining's rmse: 0.0804182\tvalid_1's rmse: 0.0840181\n",
      "[1750]\ttraining's rmse: 0.0804107\tvalid_1's rmse: 0.0840171\n",
      "[1775]\ttraining's rmse: 0.0804034\tvalid_1's rmse: 0.0840161\n",
      "[1800]\ttraining's rmse: 0.0803976\tvalid_1's rmse: 0.0840153\n",
      "[1825]\ttraining's rmse: 0.0803917\tvalid_1's rmse: 0.0840146\n",
      "[1850]\ttraining's rmse: 0.0803856\tvalid_1's rmse: 0.0840141\n",
      "[1875]\ttraining's rmse: 0.0803814\tvalid_1's rmse: 0.0840141\n",
      "[1900]\ttraining's rmse: 0.0803767\tvalid_1's rmse: 0.0840135\n",
      "[1925]\ttraining's rmse: 0.0803726\tvalid_1's rmse: 0.084013\n",
      "[1950]\ttraining's rmse: 0.0803686\tvalid_1's rmse: 0.0840124\n",
      "[1975]\ttraining's rmse: 0.0803648\tvalid_1's rmse: 0.0840117\n",
      "[2000]\ttraining's rmse: 0.0803609\tvalid_1's rmse: 0.0840112\n",
      "[2025]\ttraining's rmse: 0.0803565\tvalid_1's rmse: 0.0840107\n",
      "[2050]\ttraining's rmse: 0.0803522\tvalid_1's rmse: 0.0840106\n",
      "[2075]\ttraining's rmse: 0.0803489\tvalid_1's rmse: 0.08401\n",
      "[2100]\ttraining's rmse: 0.0803465\tvalid_1's rmse: 0.0840098\n",
      "[2125]\ttraining's rmse: 0.0803447\tvalid_1's rmse: 0.0840099\n",
      "[2150]\ttraining's rmse: 0.0803415\tvalid_1's rmse: 0.0840099\n",
      "Early stopping, best iteration is:\n",
      "[2101]\ttraining's rmse: 0.0803465\tvalid_1's rmse: 0.0840097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.084948\tvalid_1's rmse: 0.0806995\n",
      "[50]\ttraining's rmse: 0.0848403\tvalid_1's rmse: 0.0806514\n",
      "[75]\ttraining's rmse: 0.0847288\tvalid_1's rmse: 0.0806053\n",
      "[100]\ttraining's rmse: 0.0846283\tvalid_1's rmse: 0.0805651\n",
      "[125]\ttraining's rmse: 0.0845248\tvalid_1's rmse: 0.0805227\n",
      "[150]\ttraining's rmse: 0.08443\tvalid_1's rmse: 0.0804847\n",
      "[175]\ttraining's rmse: 0.0843504\tvalid_1's rmse: 0.0804537\n",
      "[200]\ttraining's rmse: 0.0842644\tvalid_1's rmse: 0.0804226\n",
      "[225]\ttraining's rmse: 0.0841794\tvalid_1's rmse: 0.0803915\n",
      "[250]\ttraining's rmse: 0.084109\tvalid_1's rmse: 0.0803662\n",
      "[275]\ttraining's rmse: 0.0840452\tvalid_1's rmse: 0.0803429\n",
      "[300]\ttraining's rmse: 0.0839819\tvalid_1's rmse: 0.0803206\n",
      "[325]\ttraining's rmse: 0.0839174\tvalid_1's rmse: 0.080298\n",
      "[350]\ttraining's rmse: 0.0838512\tvalid_1's rmse: 0.0802778\n",
      "[375]\ttraining's rmse: 0.0837977\tvalid_1's rmse: 0.0802598\n",
      "[400]\ttraining's rmse: 0.0837403\tvalid_1's rmse: 0.0802457\n",
      "[425]\ttraining's rmse: 0.0836891\tvalid_1's rmse: 0.0802303\n",
      "[450]\ttraining's rmse: 0.0836408\tvalid_1's rmse: 0.0802139\n",
      "[475]\ttraining's rmse: 0.0835958\tvalid_1's rmse: 0.0802043\n",
      "[500]\ttraining's rmse: 0.0835582\tvalid_1's rmse: 0.0801915\n",
      "[525]\ttraining's rmse: 0.0835073\tvalid_1's rmse: 0.0801786\n",
      "[550]\ttraining's rmse: 0.0834612\tvalid_1's rmse: 0.0801708\n",
      "[575]\ttraining's rmse: 0.0834194\tvalid_1's rmse: 0.0801683\n",
      "[600]\ttraining's rmse: 0.083377\tvalid_1's rmse: 0.0801575\n",
      "[625]\ttraining's rmse: 0.0833435\tvalid_1's rmse: 0.0801596\n",
      "[650]\ttraining's rmse: 0.083302\tvalid_1's rmse: 0.0801495\n",
      "[675]\ttraining's rmse: 0.0832593\tvalid_1's rmse: 0.0801515\n",
      "[700]\ttraining's rmse: 0.0832227\tvalid_1's rmse: 0.0801477\n",
      "Early stopping, best iteration is:\n",
      "[672]\ttraining's rmse: 0.0832656\tvalid_1's rmse: 0.0801457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0853033\tvalid_1's rmse: 0.0875971\n",
      "[50]\ttraining's rmse: 0.0851617\tvalid_1's rmse: 0.0875456\n",
      "[75]\ttraining's rmse: 0.0850255\tvalid_1's rmse: 0.0874957\n",
      "[100]\ttraining's rmse: 0.0848961\tvalid_1's rmse: 0.0874505\n",
      "[125]\ttraining's rmse: 0.0847678\tvalid_1's rmse: 0.0874067\n",
      "[150]\ttraining's rmse: 0.0846519\tvalid_1's rmse: 0.0873648\n",
      "[175]\ttraining's rmse: 0.084553\tvalid_1's rmse: 0.0873286\n",
      "[200]\ttraining's rmse: 0.0844484\tvalid_1's rmse: 0.0872934\n",
      "[225]\ttraining's rmse: 0.0843455\tvalid_1's rmse: 0.0872594\n",
      "[250]\ttraining's rmse: 0.0842591\tvalid_1's rmse: 0.0872292\n",
      "[275]\ttraining's rmse: 0.0841767\tvalid_1's rmse: 0.0872017\n",
      "[300]\ttraining's rmse: 0.0840997\tvalid_1's rmse: 0.0871756\n",
      "[325]\ttraining's rmse: 0.084018\tvalid_1's rmse: 0.0871502\n",
      "[350]\ttraining's rmse: 0.0839417\tvalid_1's rmse: 0.0871251\n",
      "[375]\ttraining's rmse: 0.0838725\tvalid_1's rmse: 0.0871049\n",
      "[400]\ttraining's rmse: 0.0838032\tvalid_1's rmse: 0.0870849\n",
      "[425]\ttraining's rmse: 0.08374\tvalid_1's rmse: 0.0870682\n",
      "[450]\ttraining's rmse: 0.083683\tvalid_1's rmse: 0.0870493\n",
      "[475]\ttraining's rmse: 0.0836287\tvalid_1's rmse: 0.0870305\n",
      "[500]\ttraining's rmse: 0.0835806\tvalid_1's rmse: 0.0870139\n",
      "[525]\ttraining's rmse: 0.0835223\tvalid_1's rmse: 0.086998\n",
      "[550]\ttraining's rmse: 0.0834693\tvalid_1's rmse: 0.0869816\n",
      "[575]\ttraining's rmse: 0.0834185\tvalid_1's rmse: 0.0869674\n",
      "[600]\ttraining's rmse: 0.0833734\tvalid_1's rmse: 0.086954\n",
      "[625]\ttraining's rmse: 0.0833345\tvalid_1's rmse: 0.0869419\n",
      "[650]\ttraining's rmse: 0.083291\tvalid_1's rmse: 0.0869297\n",
      "[675]\ttraining's rmse: 0.0832454\tvalid_1's rmse: 0.0869182\n",
      "[700]\ttraining's rmse: 0.0832058\tvalid_1's rmse: 0.0869076\n",
      "[725]\ttraining's rmse: 0.0831678\tvalid_1's rmse: 0.0868984\n",
      "[750]\ttraining's rmse: 0.083132\tvalid_1's rmse: 0.0868894\n",
      "[775]\ttraining's rmse: 0.0831047\tvalid_1's rmse: 0.0868808\n",
      "[800]\ttraining's rmse: 0.0830716\tvalid_1's rmse: 0.0868732\n",
      "[825]\ttraining's rmse: 0.0830409\tvalid_1's rmse: 0.0868632\n",
      "[850]\ttraining's rmse: 0.0830079\tvalid_1's rmse: 0.0868561\n",
      "[875]\ttraining's rmse: 0.0829784\tvalid_1's rmse: 0.0868487\n",
      "[900]\ttraining's rmse: 0.0829466\tvalid_1's rmse: 0.0868414\n",
      "[925]\ttraining's rmse: 0.0829184\tvalid_1's rmse: 0.0868343\n",
      "[950]\ttraining's rmse: 0.082893\tvalid_1's rmse: 0.0868275\n",
      "[975]\ttraining's rmse: 0.0828673\tvalid_1's rmse: 0.0868217\n",
      "[1000]\ttraining's rmse: 0.0828419\tvalid_1's rmse: 0.0868163\n",
      "[1025]\ttraining's rmse: 0.0828173\tvalid_1's rmse: 0.0868091\n",
      "[1050]\ttraining's rmse: 0.082796\tvalid_1's rmse: 0.0868042\n",
      "[1075]\ttraining's rmse: 0.0827743\tvalid_1's rmse: 0.0867992\n",
      "[1100]\ttraining's rmse: 0.0827545\tvalid_1's rmse: 0.0867948\n",
      "[1125]\ttraining's rmse: 0.0827348\tvalid_1's rmse: 0.086789\n",
      "[1150]\ttraining's rmse: 0.0827155\tvalid_1's rmse: 0.0867843\n",
      "[1175]\ttraining's rmse: 0.082698\tvalid_1's rmse: 0.0867812\n",
      "[1200]\ttraining's rmse: 0.082682\tvalid_1's rmse: 0.0867772\n",
      "[1225]\ttraining's rmse: 0.0826652\tvalid_1's rmse: 0.0867727\n",
      "[1250]\ttraining's rmse: 0.0826521\tvalid_1's rmse: 0.0867679\n",
      "[1275]\ttraining's rmse: 0.0826322\tvalid_1's rmse: 0.0867646\n",
      "[1300]\ttraining's rmse: 0.0826186\tvalid_1's rmse: 0.0867608\n",
      "[1325]\ttraining's rmse: 0.082606\tvalid_1's rmse: 0.0867572\n",
      "[1350]\ttraining's rmse: 0.0825907\tvalid_1's rmse: 0.0867547\n",
      "[1375]\ttraining's rmse: 0.0825764\tvalid_1's rmse: 0.0867519\n",
      "[1400]\ttraining's rmse: 0.0825642\tvalid_1's rmse: 0.0867493\n",
      "[1425]\ttraining's rmse: 0.0825478\tvalid_1's rmse: 0.0867473\n",
      "[1450]\ttraining's rmse: 0.0825341\tvalid_1's rmse: 0.0867453\n",
      "[1475]\ttraining's rmse: 0.0825243\tvalid_1's rmse: 0.0867425\n",
      "[1500]\ttraining's rmse: 0.0825137\tvalid_1's rmse: 0.0867395\n",
      "[1525]\ttraining's rmse: 0.0825042\tvalid_1's rmse: 0.0867369\n",
      "[1550]\ttraining's rmse: 0.0824932\tvalid_1's rmse: 0.086734\n",
      "[1575]\ttraining's rmse: 0.0824826\tvalid_1's rmse: 0.0867318\n",
      "[1600]\ttraining's rmse: 0.0824755\tvalid_1's rmse: 0.0867303\n",
      "[1625]\ttraining's rmse: 0.0824678\tvalid_1's rmse: 0.0867283\n",
      "[1650]\ttraining's rmse: 0.0824598\tvalid_1's rmse: 0.0867262\n",
      "[1675]\ttraining's rmse: 0.0824524\tvalid_1's rmse: 0.0867238\n",
      "[1700]\ttraining's rmse: 0.0824445\tvalid_1's rmse: 0.0867219\n",
      "[1725]\ttraining's rmse: 0.0824369\tvalid_1's rmse: 0.0867195\n",
      "[1750]\ttraining's rmse: 0.0824307\tvalid_1's rmse: 0.0867176\n",
      "[1775]\ttraining's rmse: 0.0824255\tvalid_1's rmse: 0.086716\n",
      "[1800]\ttraining's rmse: 0.0824188\tvalid_1's rmse: 0.0867147\n",
      "[1825]\ttraining's rmse: 0.0824133\tvalid_1's rmse: 0.0867136\n",
      "[1850]\ttraining's rmse: 0.0824076\tvalid_1's rmse: 0.0867119\n",
      "[1875]\ttraining's rmse: 0.0824013\tvalid_1's rmse: 0.0867099\n",
      "[1900]\ttraining's rmse: 0.0823963\tvalid_1's rmse: 0.0867091\n",
      "[1925]\ttraining's rmse: 0.082392\tvalid_1's rmse: 0.0867086\n",
      "[1950]\ttraining's rmse: 0.0823887\tvalid_1's rmse: 0.0867076\n",
      "[1975]\ttraining's rmse: 0.0823854\tvalid_1's rmse: 0.0867064\n",
      "[2000]\ttraining's rmse: 0.0823806\tvalid_1's rmse: 0.0867053\n",
      "[2025]\ttraining's rmse: 0.0823759\tvalid_1's rmse: 0.0867038\n",
      "[2050]\ttraining's rmse: 0.0823719\tvalid_1's rmse: 0.0867025\n",
      "[2075]\ttraining's rmse: 0.0823687\tvalid_1's rmse: 0.0867016\n",
      "[2100]\ttraining's rmse: 0.0823652\tvalid_1's rmse: 0.0867006\n",
      "[2125]\ttraining's rmse: 0.0823619\tvalid_1's rmse: 0.0867001\n",
      "[2150]\ttraining's rmse: 0.0823587\tvalid_1's rmse: 0.086699\n",
      "[2175]\ttraining's rmse: 0.0823555\tvalid_1's rmse: 0.0866987\n",
      "[2200]\ttraining's rmse: 0.0823516\tvalid_1's rmse: 0.086698\n",
      "[2225]\ttraining's rmse: 0.0823486\tvalid_1's rmse: 0.0866963\n",
      "[2250]\ttraining's rmse: 0.0823455\tvalid_1's rmse: 0.0866956\n",
      "[2275]\ttraining's rmse: 0.0823423\tvalid_1's rmse: 0.0866946\n",
      "[2300]\ttraining's rmse: 0.0823392\tvalid_1's rmse: 0.0866936\n",
      "[2325]\ttraining's rmse: 0.0823356\tvalid_1's rmse: 0.0866913\n",
      "[2350]\ttraining's rmse: 0.0823327\tvalid_1's rmse: 0.0866911\n",
      "[2375]\ttraining's rmse: 0.0823295\tvalid_1's rmse: 0.0866901\n",
      "[2400]\ttraining's rmse: 0.0823272\tvalid_1's rmse: 0.0866898\n",
      "[2425]\ttraining's rmse: 0.0823253\tvalid_1's rmse: 0.0866884\n",
      "[2450]\ttraining's rmse: 0.0823237\tvalid_1's rmse: 0.0866882\n",
      "[2475]\ttraining's rmse: 0.0823207\tvalid_1's rmse: 0.0866878\n",
      "[2500]\ttraining's rmse: 0.0823163\tvalid_1's rmse: 0.0866874\n",
      "[2525]\ttraining's rmse: 0.0823143\tvalid_1's rmse: 0.0866869\n",
      "[2550]\ttraining's rmse: 0.0823125\tvalid_1's rmse: 0.0866868\n",
      "[2575]\ttraining's rmse: 0.0823098\tvalid_1's rmse: 0.0866863\n",
      "[2600]\ttraining's rmse: 0.0823074\tvalid_1's rmse: 0.0866846\n",
      "[2625]\ttraining's rmse: 0.0823064\tvalid_1's rmse: 0.0866841\n",
      "[2650]\ttraining's rmse: 0.0823043\tvalid_1's rmse: 0.0866834\n",
      "[2675]\ttraining's rmse: 0.0823025\tvalid_1's rmse: 0.0866816\n",
      "[2700]\ttraining's rmse: 0.082301\tvalid_1's rmse: 0.0866812\n",
      "[2725]\ttraining's rmse: 0.0822991\tvalid_1's rmse: 0.0866805\n",
      "[2750]\ttraining's rmse: 0.082298\tvalid_1's rmse: 0.08668\n",
      "[2775]\ttraining's rmse: 0.0822962\tvalid_1's rmse: 0.0866796\n",
      "[2800]\ttraining's rmse: 0.0822942\tvalid_1's rmse: 0.086679\n",
      "[2825]\ttraining's rmse: 0.0822926\tvalid_1's rmse: 0.086679\n",
      "[2850]\ttraining's rmse: 0.0822895\tvalid_1's rmse: 0.0866788\n",
      "[2875]\ttraining's rmse: 0.0822879\tvalid_1's rmse: 0.0866784\n",
      "[2900]\ttraining's rmse: 0.082284\tvalid_1's rmse: 0.0866777\n",
      "[2925]\ttraining's rmse: 0.0822829\tvalid_1's rmse: 0.0866775\n",
      "[2950]\ttraining's rmse: 0.082282\tvalid_1's rmse: 0.0866772\n",
      "[2975]\ttraining's rmse: 0.0822808\tvalid_1's rmse: 0.0866773\n",
      "[3000]\ttraining's rmse: 0.0822793\tvalid_1's rmse: 0.086677\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0822793\tvalid_1's rmse: 0.086677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.085271\tvalid_1's rmse: 0.0876898\n",
      "[50]\ttraining's rmse: 0.085151\tvalid_1's rmse: 0.0876373\n",
      "[75]\ttraining's rmse: 0.0850255\tvalid_1's rmse: 0.0875846\n",
      "[100]\ttraining's rmse: 0.0849108\tvalid_1's rmse: 0.0875378\n",
      "[125]\ttraining's rmse: 0.0847948\tvalid_1's rmse: 0.0874921\n",
      "[150]\ttraining's rmse: 0.084687\tvalid_1's rmse: 0.0874491\n",
      "[175]\ttraining's rmse: 0.0845983\tvalid_1's rmse: 0.0874137\n",
      "[200]\ttraining's rmse: 0.0844993\tvalid_1's rmse: 0.0873763\n",
      "[225]\ttraining's rmse: 0.084408\tvalid_1's rmse: 0.0873429\n",
      "[250]\ttraining's rmse: 0.0843297\tvalid_1's rmse: 0.0873123\n",
      "[275]\ttraining's rmse: 0.0842575\tvalid_1's rmse: 0.087285\n",
      "[300]\ttraining's rmse: 0.0841836\tvalid_1's rmse: 0.087259\n",
      "[325]\ttraining's rmse: 0.0841096\tvalid_1's rmse: 0.087234\n",
      "[350]\ttraining's rmse: 0.0840371\tvalid_1's rmse: 0.0872107\n",
      "[375]\ttraining's rmse: 0.0839754\tvalid_1's rmse: 0.0871902\n",
      "[400]\ttraining's rmse: 0.08391\tvalid_1's rmse: 0.0871694\n",
      "[425]\ttraining's rmse: 0.0838515\tvalid_1's rmse: 0.0871492\n",
      "[450]\ttraining's rmse: 0.0837967\tvalid_1's rmse: 0.0871302\n",
      "[475]\ttraining's rmse: 0.0837466\tvalid_1's rmse: 0.0871141\n",
      "[500]\ttraining's rmse: 0.083704\tvalid_1's rmse: 0.0870985\n",
      "[525]\ttraining's rmse: 0.0836475\tvalid_1's rmse: 0.087083\n",
      "[550]\ttraining's rmse: 0.0835958\tvalid_1's rmse: 0.0870695\n",
      "[575]\ttraining's rmse: 0.0835509\tvalid_1's rmse: 0.0870554\n",
      "[600]\ttraining's rmse: 0.0835062\tvalid_1's rmse: 0.0870427\n",
      "[625]\ttraining's rmse: 0.083471\tvalid_1's rmse: 0.0870317\n",
      "[650]\ttraining's rmse: 0.0834254\tvalid_1's rmse: 0.0870186\n",
      "[675]\ttraining's rmse: 0.083381\tvalid_1's rmse: 0.087008\n",
      "[700]\ttraining's rmse: 0.0833416\tvalid_1's rmse: 0.0869969\n",
      "[725]\ttraining's rmse: 0.0833062\tvalid_1's rmse: 0.086988\n",
      "[750]\ttraining's rmse: 0.0832729\tvalid_1's rmse: 0.0869786\n",
      "[775]\ttraining's rmse: 0.0832444\tvalid_1's rmse: 0.08697\n",
      "[800]\ttraining's rmse: 0.0832097\tvalid_1's rmse: 0.0869614\n",
      "[825]\ttraining's rmse: 0.083179\tvalid_1's rmse: 0.0869524\n",
      "[850]\ttraining's rmse: 0.0831508\tvalid_1's rmse: 0.086946\n",
      "[875]\ttraining's rmse: 0.083123\tvalid_1's rmse: 0.0869393\n",
      "[900]\ttraining's rmse: 0.0830913\tvalid_1's rmse: 0.0869327\n",
      "[925]\ttraining's rmse: 0.0830652\tvalid_1's rmse: 0.0869271\n",
      "[950]\ttraining's rmse: 0.0830385\tvalid_1's rmse: 0.086922\n",
      "[975]\ttraining's rmse: 0.083013\tvalid_1's rmse: 0.0869166\n",
      "[1000]\ttraining's rmse: 0.0829918\tvalid_1's rmse: 0.0869122\n",
      "[1025]\ttraining's rmse: 0.0829653\tvalid_1's rmse: 0.0869074\n",
      "[1050]\ttraining's rmse: 0.0829445\tvalid_1's rmse: 0.0869028\n",
      "[1075]\ttraining's rmse: 0.0829211\tvalid_1's rmse: 0.0868987\n",
      "[1100]\ttraining's rmse: 0.0829022\tvalid_1's rmse: 0.0868943\n",
      "[1125]\ttraining's rmse: 0.0828819\tvalid_1's rmse: 0.0868902\n",
      "[1150]\ttraining's rmse: 0.0828621\tvalid_1's rmse: 0.0868866\n",
      "[1175]\ttraining's rmse: 0.0828456\tvalid_1's rmse: 0.0868839\n",
      "[1200]\ttraining's rmse: 0.0828282\tvalid_1's rmse: 0.0868799\n",
      "[1225]\ttraining's rmse: 0.0828125\tvalid_1's rmse: 0.0868772\n",
      "[1250]\ttraining's rmse: 0.0827966\tvalid_1's rmse: 0.0868748\n",
      "[1275]\ttraining's rmse: 0.0827787\tvalid_1's rmse: 0.0868721\n",
      "[1300]\ttraining's rmse: 0.0827653\tvalid_1's rmse: 0.086869\n",
      "[1325]\ttraining's rmse: 0.0827507\tvalid_1's rmse: 0.086868\n",
      "[1350]\ttraining's rmse: 0.0827369\tvalid_1's rmse: 0.0868665\n",
      "[1375]\ttraining's rmse: 0.0827251\tvalid_1's rmse: 0.0868645\n",
      "[1400]\ttraining's rmse: 0.0827143\tvalid_1's rmse: 0.0868617\n",
      "[1425]\ttraining's rmse: 0.0827006\tvalid_1's rmse: 0.0868605\n",
      "[1450]\ttraining's rmse: 0.0826867\tvalid_1's rmse: 0.0868592\n",
      "[1475]\ttraining's rmse: 0.0826764\tvalid_1's rmse: 0.086857\n",
      "[1500]\ttraining's rmse: 0.0826674\tvalid_1's rmse: 0.0868558\n",
      "[1525]\ttraining's rmse: 0.0826545\tvalid_1's rmse: 0.0868551\n",
      "[1550]\ttraining's rmse: 0.0826444\tvalid_1's rmse: 0.086854\n",
      "[1575]\ttraining's rmse: 0.0826362\tvalid_1's rmse: 0.0868524\n",
      "[1600]\ttraining's rmse: 0.0826279\tvalid_1's rmse: 0.0868513\n",
      "[1625]\ttraining's rmse: 0.0826194\tvalid_1's rmse: 0.0868501\n",
      "[1650]\ttraining's rmse: 0.0826107\tvalid_1's rmse: 0.0868493\n",
      "[1675]\ttraining's rmse: 0.0826047\tvalid_1's rmse: 0.0868481\n",
      "[1700]\ttraining's rmse: 0.0825973\tvalid_1's rmse: 0.0868472\n",
      "[1725]\ttraining's rmse: 0.0825895\tvalid_1's rmse: 0.0868463\n",
      "[1750]\ttraining's rmse: 0.0825824\tvalid_1's rmse: 0.0868461\n",
      "[1775]\ttraining's rmse: 0.0825753\tvalid_1's rmse: 0.0868454\n",
      "[1800]\ttraining's rmse: 0.0825686\tvalid_1's rmse: 0.0868449\n",
      "[1825]\ttraining's rmse: 0.0825624\tvalid_1's rmse: 0.0868444\n",
      "[1850]\ttraining's rmse: 0.0825546\tvalid_1's rmse: 0.0868438\n",
      "[1875]\ttraining's rmse: 0.0825506\tvalid_1's rmse: 0.0868436\n",
      "[1900]\ttraining's rmse: 0.082546\tvalid_1's rmse: 0.0868434\n",
      "[1925]\ttraining's rmse: 0.0825415\tvalid_1's rmse: 0.0868432\n",
      "[1950]\ttraining's rmse: 0.0825363\tvalid_1's rmse: 0.0868428\n",
      "[1975]\ttraining's rmse: 0.0825326\tvalid_1's rmse: 0.0868425\n",
      "[2000]\ttraining's rmse: 0.0825272\tvalid_1's rmse: 0.0868421\n",
      "[2025]\ttraining's rmse: 0.0825231\tvalid_1's rmse: 0.0868413\n",
      "[2050]\ttraining's rmse: 0.0825193\tvalid_1's rmse: 0.0868409\n",
      "[2075]\ttraining's rmse: 0.0825159\tvalid_1's rmse: 0.0868404\n",
      "[2100]\ttraining's rmse: 0.0825128\tvalid_1's rmse: 0.0868399\n",
      "[2125]\ttraining's rmse: 0.0825102\tvalid_1's rmse: 0.0868397\n",
      "[2150]\ttraining's rmse: 0.0825063\tvalid_1's rmse: 0.0868397\n",
      "[2175]\ttraining's rmse: 0.0825034\tvalid_1's rmse: 0.0868399\n",
      "Early stopping, best iteration is:\n",
      "[2136]\ttraining's rmse: 0.0825083\tvalid_1's rmse: 0.0868396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0875192\tvalid_1's rmse: 0.0831234\n",
      "[50]\ttraining's rmse: 0.0874059\tvalid_1's rmse: 0.0830747\n",
      "[75]\ttraining's rmse: 0.0872818\tvalid_1's rmse: 0.083026\n",
      "[100]\ttraining's rmse: 0.0871737\tvalid_1's rmse: 0.0829836\n",
      "[125]\ttraining's rmse: 0.0870603\tvalid_1's rmse: 0.0829417\n",
      "[150]\ttraining's rmse: 0.0869569\tvalid_1's rmse: 0.0829044\n",
      "[175]\ttraining's rmse: 0.0868692\tvalid_1's rmse: 0.0828734\n",
      "[200]\ttraining's rmse: 0.086775\tvalid_1's rmse: 0.0828416\n",
      "[225]\ttraining's rmse: 0.0866802\tvalid_1's rmse: 0.08281\n",
      "[250]\ttraining's rmse: 0.0866046\tvalid_1's rmse: 0.0827835\n",
      "[275]\ttraining's rmse: 0.0865339\tvalid_1's rmse: 0.0827577\n",
      "[300]\ttraining's rmse: 0.0864656\tvalid_1's rmse: 0.0827326\n",
      "[325]\ttraining's rmse: 0.0863936\tvalid_1's rmse: 0.0827116\n",
      "[350]\ttraining's rmse: 0.0863246\tvalid_1's rmse: 0.0826903\n",
      "[375]\ttraining's rmse: 0.0862676\tvalid_1's rmse: 0.0826786\n",
      "[400]\ttraining's rmse: 0.086205\tvalid_1's rmse: 0.0826683\n",
      "[425]\ttraining's rmse: 0.0861479\tvalid_1's rmse: 0.0826552\n",
      "[450]\ttraining's rmse: 0.0860963\tvalid_1's rmse: 0.0826425\n",
      "[475]\ttraining's rmse: 0.0860489\tvalid_1's rmse: 0.0826364\n",
      "[500]\ttraining's rmse: 0.0860086\tvalid_1's rmse: 0.0826227\n",
      "[525]\ttraining's rmse: 0.0859542\tvalid_1's rmse: 0.0826081\n",
      "[550]\ttraining's rmse: 0.0859043\tvalid_1's rmse: 0.0825945\n",
      "[575]\ttraining's rmse: 0.0858566\tvalid_1's rmse: 0.0825873\n",
      "[600]\ttraining's rmse: 0.0858106\tvalid_1's rmse: 0.0825816\n",
      "[625]\ttraining's rmse: 0.085775\tvalid_1's rmse: 0.0825723\n",
      "[650]\ttraining's rmse: 0.0857273\tvalid_1's rmse: 0.0825674\n",
      "[675]\ttraining's rmse: 0.0856833\tvalid_1's rmse: 0.0825655\n",
      "[700]\ttraining's rmse: 0.0856436\tvalid_1's rmse: 0.0825569\n",
      "[725]\ttraining's rmse: 0.0856065\tvalid_1's rmse: 0.0825609\n",
      "[750]\ttraining's rmse: 0.0855719\tvalid_1's rmse: 0.0825577\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0856356\tvalid_1's rmse: 0.0825558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0831665\tvalid_1's rmse: 0.0857579\n",
      "[50]\ttraining's rmse: 0.0830392\tvalid_1's rmse: 0.0857046\n",
      "[75]\ttraining's rmse: 0.0829136\tvalid_1's rmse: 0.0856515\n",
      "[100]\ttraining's rmse: 0.0827977\tvalid_1's rmse: 0.0856061\n",
      "[125]\ttraining's rmse: 0.0826807\tvalid_1's rmse: 0.0855593\n",
      "[150]\ttraining's rmse: 0.082574\tvalid_1's rmse: 0.0855162\n",
      "[175]\ttraining's rmse: 0.0824834\tvalid_1's rmse: 0.085479\n",
      "[200]\ttraining's rmse: 0.0823895\tvalid_1's rmse: 0.085443\n",
      "[225]\ttraining's rmse: 0.0822929\tvalid_1's rmse: 0.0854077\n",
      "[250]\ttraining's rmse: 0.082214\tvalid_1's rmse: 0.0853751\n",
      "[275]\ttraining's rmse: 0.082139\tvalid_1's rmse: 0.0853441\n",
      "[300]\ttraining's rmse: 0.0820665\tvalid_1's rmse: 0.0853154\n",
      "[325]\ttraining's rmse: 0.0819971\tvalid_1's rmse: 0.085289\n",
      "[350]\ttraining's rmse: 0.0819279\tvalid_1's rmse: 0.0852626\n",
      "[375]\ttraining's rmse: 0.0818667\tvalid_1's rmse: 0.0852419\n",
      "[400]\ttraining's rmse: 0.0818062\tvalid_1's rmse: 0.0852195\n",
      "[425]\ttraining's rmse: 0.0817502\tvalid_1's rmse: 0.0851986\n",
      "[450]\ttraining's rmse: 0.0816991\tvalid_1's rmse: 0.085178\n",
      "[475]\ttraining's rmse: 0.0816499\tvalid_1's rmse: 0.0851595\n",
      "[500]\ttraining's rmse: 0.0816092\tvalid_1's rmse: 0.0851433\n",
      "[525]\ttraining's rmse: 0.0815578\tvalid_1's rmse: 0.0851259\n",
      "[550]\ttraining's rmse: 0.0815121\tvalid_1's rmse: 0.0851107\n",
      "[575]\ttraining's rmse: 0.081466\tvalid_1's rmse: 0.0850965\n",
      "[600]\ttraining's rmse: 0.081425\tvalid_1's rmse: 0.085083\n",
      "[625]\ttraining's rmse: 0.0813914\tvalid_1's rmse: 0.0850699\n",
      "[650]\ttraining's rmse: 0.0813536\tvalid_1's rmse: 0.0850575\n",
      "[675]\ttraining's rmse: 0.0813158\tvalid_1's rmse: 0.0850457\n",
      "[700]\ttraining's rmse: 0.08128\tvalid_1's rmse: 0.0850333\n",
      "[725]\ttraining's rmse: 0.0812468\tvalid_1's rmse: 0.085024\n",
      "[750]\ttraining's rmse: 0.0812116\tvalid_1's rmse: 0.0850139\n",
      "[775]\ttraining's rmse: 0.0811861\tvalid_1's rmse: 0.0850043\n",
      "[800]\ttraining's rmse: 0.0811511\tvalid_1's rmse: 0.0849954\n",
      "[825]\ttraining's rmse: 0.0811234\tvalid_1's rmse: 0.0849871\n",
      "[850]\ttraining's rmse: 0.0810928\tvalid_1's rmse: 0.0849799\n",
      "[875]\ttraining's rmse: 0.0810655\tvalid_1's rmse: 0.0849718\n",
      "[900]\ttraining's rmse: 0.081037\tvalid_1's rmse: 0.0849654\n",
      "[925]\ttraining's rmse: 0.0810124\tvalid_1's rmse: 0.0849578\n",
      "[950]\ttraining's rmse: 0.0809857\tvalid_1's rmse: 0.0849497\n",
      "[975]\ttraining's rmse: 0.0809634\tvalid_1's rmse: 0.0849437\n",
      "[1000]\ttraining's rmse: 0.0809421\tvalid_1's rmse: 0.0849376\n",
      "[1025]\ttraining's rmse: 0.0809166\tvalid_1's rmse: 0.084931\n",
      "[1050]\ttraining's rmse: 0.0808971\tvalid_1's rmse: 0.0849254\n",
      "[1075]\ttraining's rmse: 0.0808767\tvalid_1's rmse: 0.0849203\n",
      "[1100]\ttraining's rmse: 0.0808575\tvalid_1's rmse: 0.0849151\n",
      "[1125]\ttraining's rmse: 0.0808415\tvalid_1's rmse: 0.0849081\n",
      "[1150]\ttraining's rmse: 0.0808227\tvalid_1's rmse: 0.0849035\n",
      "[1175]\ttraining's rmse: 0.0808068\tvalid_1's rmse: 0.084899\n",
      "[1200]\ttraining's rmse: 0.0807913\tvalid_1's rmse: 0.0848955\n",
      "[1225]\ttraining's rmse: 0.0807734\tvalid_1's rmse: 0.0848916\n",
      "[1250]\ttraining's rmse: 0.0807587\tvalid_1's rmse: 0.0848877\n",
      "[1275]\ttraining's rmse: 0.0807427\tvalid_1's rmse: 0.0848829\n",
      "[1300]\ttraining's rmse: 0.0807321\tvalid_1's rmse: 0.0848768\n",
      "[1325]\ttraining's rmse: 0.0807192\tvalid_1's rmse: 0.0848737\n",
      "[1350]\ttraining's rmse: 0.0807051\tvalid_1's rmse: 0.0848712\n",
      "[1375]\ttraining's rmse: 0.0806924\tvalid_1's rmse: 0.0848674\n",
      "[1400]\ttraining's rmse: 0.0806827\tvalid_1's rmse: 0.0848642\n",
      "[1425]\ttraining's rmse: 0.0806704\tvalid_1's rmse: 0.0848614\n",
      "[1450]\ttraining's rmse: 0.0806583\tvalid_1's rmse: 0.0848581\n",
      "[1475]\ttraining's rmse: 0.0806505\tvalid_1's rmse: 0.0848554\n",
      "[1500]\ttraining's rmse: 0.0806418\tvalid_1's rmse: 0.0848537\n",
      "[1525]\ttraining's rmse: 0.0806324\tvalid_1's rmse: 0.0848515\n",
      "[1550]\ttraining's rmse: 0.0806234\tvalid_1's rmse: 0.0848497\n",
      "[1575]\ttraining's rmse: 0.0806162\tvalid_1's rmse: 0.0848464\n",
      "[1600]\ttraining's rmse: 0.0806089\tvalid_1's rmse: 0.084844\n",
      "[1625]\ttraining's rmse: 0.0806012\tvalid_1's rmse: 0.0848415\n",
      "[1650]\ttraining's rmse: 0.080595\tvalid_1's rmse: 0.0848386\n",
      "[1675]\ttraining's rmse: 0.0805882\tvalid_1's rmse: 0.084836\n",
      "[1700]\ttraining's rmse: 0.0805835\tvalid_1's rmse: 0.0848341\n",
      "[1725]\ttraining's rmse: 0.0805776\tvalid_1's rmse: 0.0848325\n",
      "[1750]\ttraining's rmse: 0.0805704\tvalid_1's rmse: 0.0848313\n",
      "[1775]\ttraining's rmse: 0.0805645\tvalid_1's rmse: 0.0848299\n",
      "[1800]\ttraining's rmse: 0.0805608\tvalid_1's rmse: 0.0848289\n",
      "[1825]\ttraining's rmse: 0.0805553\tvalid_1's rmse: 0.0848278\n",
      "[1850]\ttraining's rmse: 0.080551\tvalid_1's rmse: 0.0848264\n",
      "[1875]\ttraining's rmse: 0.080547\tvalid_1's rmse: 0.084826\n",
      "[1900]\ttraining's rmse: 0.0805431\tvalid_1's rmse: 0.0848246\n",
      "[1925]\ttraining's rmse: 0.0805383\tvalid_1's rmse: 0.0848232\n",
      "[1950]\ttraining's rmse: 0.0805353\tvalid_1's rmse: 0.0848221\n",
      "[1975]\ttraining's rmse: 0.0805312\tvalid_1's rmse: 0.0848212\n",
      "[2000]\ttraining's rmse: 0.0805272\tvalid_1's rmse: 0.08482\n",
      "[2025]\ttraining's rmse: 0.0805239\tvalid_1's rmse: 0.0848182\n",
      "[2050]\ttraining's rmse: 0.0805193\tvalid_1's rmse: 0.0848176\n",
      "[2075]\ttraining's rmse: 0.0805169\tvalid_1's rmse: 0.0848163\n",
      "[2100]\ttraining's rmse: 0.0805142\tvalid_1's rmse: 0.0848149\n",
      "[2125]\ttraining's rmse: 0.0805111\tvalid_1's rmse: 0.0848141\n",
      "[2150]\ttraining's rmse: 0.0805064\tvalid_1's rmse: 0.0848126\n",
      "[2175]\ttraining's rmse: 0.080503\tvalid_1's rmse: 0.0848123\n",
      "[2200]\ttraining's rmse: 0.0804993\tvalid_1's rmse: 0.0848116\n",
      "[2225]\ttraining's rmse: 0.0804966\tvalid_1's rmse: 0.0848108\n",
      "[2250]\ttraining's rmse: 0.0804936\tvalid_1's rmse: 0.084809\n",
      "[2275]\ttraining's rmse: 0.0804894\tvalid_1's rmse: 0.0848079\n",
      "[2300]\ttraining's rmse: 0.080486\tvalid_1's rmse: 0.084807\n",
      "[2325]\ttraining's rmse: 0.0804839\tvalid_1's rmse: 0.0848068\n",
      "[2350]\ttraining's rmse: 0.0804809\tvalid_1's rmse: 0.084806\n",
      "[2375]\ttraining's rmse: 0.0804789\tvalid_1's rmse: 0.0848054\n",
      "[2400]\ttraining's rmse: 0.0804759\tvalid_1's rmse: 0.0848045\n",
      "[2425]\ttraining's rmse: 0.080473\tvalid_1's rmse: 0.084804\n",
      "[2450]\ttraining's rmse: 0.0804702\tvalid_1's rmse: 0.0848022\n",
      "[2475]\ttraining's rmse: 0.0804672\tvalid_1's rmse: 0.0848013\n",
      "[2500]\ttraining's rmse: 0.0804654\tvalid_1's rmse: 0.0848003\n",
      "[2525]\ttraining's rmse: 0.080463\tvalid_1's rmse: 0.0848\n",
      "[2550]\ttraining's rmse: 0.0804612\tvalid_1's rmse: 0.0847995\n",
      "[2575]\ttraining's rmse: 0.0804594\tvalid_1's rmse: 0.0847981\n",
      "[2600]\ttraining's rmse: 0.080458\tvalid_1's rmse: 0.0847981\n",
      "[2625]\ttraining's rmse: 0.0804568\tvalid_1's rmse: 0.0847977\n",
      "[2650]\ttraining's rmse: 0.0804548\tvalid_1's rmse: 0.0847971\n",
      "[2675]\ttraining's rmse: 0.0804533\tvalid_1's rmse: 0.0847965\n",
      "[2700]\ttraining's rmse: 0.080452\tvalid_1's rmse: 0.0847956\n",
      "[2725]\ttraining's rmse: 0.0804506\tvalid_1's rmse: 0.0847956\n",
      "[2750]\ttraining's rmse: 0.0804492\tvalid_1's rmse: 0.0847951\n",
      "[2775]\ttraining's rmse: 0.0804483\tvalid_1's rmse: 0.0847953\n",
      "Early stopping, best iteration is:\n",
      "[2737]\ttraining's rmse: 0.0804496\tvalid_1's rmse: 0.084795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0833423\tvalid_1's rmse: 0.0854123\n",
      "[50]\ttraining's rmse: 0.0832282\tvalid_1's rmse: 0.0853586\n",
      "[75]\ttraining's rmse: 0.0831106\tvalid_1's rmse: 0.0853061\n",
      "[100]\ttraining's rmse: 0.0830091\tvalid_1's rmse: 0.08526\n",
      "[125]\ttraining's rmse: 0.0828992\tvalid_1's rmse: 0.085211\n",
      "[150]\ttraining's rmse: 0.0828002\tvalid_1's rmse: 0.0851671\n",
      "[175]\ttraining's rmse: 0.0827162\tvalid_1's rmse: 0.0851315\n",
      "[200]\ttraining's rmse: 0.0826229\tvalid_1's rmse: 0.0850952\n",
      "[225]\ttraining's rmse: 0.0825332\tvalid_1's rmse: 0.0850606\n",
      "[250]\ttraining's rmse: 0.0824586\tvalid_1's rmse: 0.0850283\n",
      "[275]\ttraining's rmse: 0.0823898\tvalid_1's rmse: 0.0849997\n",
      "[300]\ttraining's rmse: 0.08232\tvalid_1's rmse: 0.0849722\n",
      "[325]\ttraining's rmse: 0.0822492\tvalid_1's rmse: 0.0849454\n",
      "[350]\ttraining's rmse: 0.0821794\tvalid_1's rmse: 0.0849203\n",
      "[375]\ttraining's rmse: 0.0821236\tvalid_1's rmse: 0.0848987\n",
      "[400]\ttraining's rmse: 0.0820648\tvalid_1's rmse: 0.0848782\n",
      "[425]\ttraining's rmse: 0.0820088\tvalid_1's rmse: 0.084859\n",
      "[450]\ttraining's rmse: 0.0819569\tvalid_1's rmse: 0.0848411\n",
      "[475]\ttraining's rmse: 0.0819066\tvalid_1's rmse: 0.0848242\n",
      "[500]\ttraining's rmse: 0.081866\tvalid_1's rmse: 0.0848084\n",
      "[525]\ttraining's rmse: 0.0818137\tvalid_1's rmse: 0.0847929\n",
      "[550]\ttraining's rmse: 0.0817646\tvalid_1's rmse: 0.0847779\n",
      "[575]\ttraining's rmse: 0.0817207\tvalid_1's rmse: 0.0847636\n",
      "[600]\ttraining's rmse: 0.0816768\tvalid_1's rmse: 0.0847508\n",
      "[625]\ttraining's rmse: 0.0816441\tvalid_1's rmse: 0.0847389\n",
      "[650]\ttraining's rmse: 0.0816022\tvalid_1's rmse: 0.0847276\n",
      "[675]\ttraining's rmse: 0.0815589\tvalid_1's rmse: 0.0847158\n",
      "[700]\ttraining's rmse: 0.0815195\tvalid_1's rmse: 0.0847045\n",
      "[725]\ttraining's rmse: 0.0814862\tvalid_1's rmse: 0.0846953\n",
      "[750]\ttraining's rmse: 0.0814522\tvalid_1's rmse: 0.0846861\n",
      "[775]\ttraining's rmse: 0.0814236\tvalid_1's rmse: 0.0846772\n",
      "[800]\ttraining's rmse: 0.0813881\tvalid_1's rmse: 0.0846696\n",
      "[825]\ttraining's rmse: 0.081359\tvalid_1's rmse: 0.084661\n",
      "[850]\ttraining's rmse: 0.0813327\tvalid_1's rmse: 0.0846548\n",
      "[875]\ttraining's rmse: 0.081307\tvalid_1's rmse: 0.0846487\n",
      "[900]\ttraining's rmse: 0.0812787\tvalid_1's rmse: 0.0846421\n",
      "[925]\ttraining's rmse: 0.0812536\tvalid_1's rmse: 0.0846364\n",
      "[950]\ttraining's rmse: 0.0812286\tvalid_1's rmse: 0.0846309\n",
      "[975]\ttraining's rmse: 0.0812059\tvalid_1's rmse: 0.084626\n",
      "[1000]\ttraining's rmse: 0.0811855\tvalid_1's rmse: 0.0846209\n",
      "[1025]\ttraining's rmse: 0.0811616\tvalid_1's rmse: 0.0846167\n",
      "[1050]\ttraining's rmse: 0.0811428\tvalid_1's rmse: 0.0846121\n",
      "[1075]\ttraining's rmse: 0.0811227\tvalid_1's rmse: 0.0846078\n",
      "[1100]\ttraining's rmse: 0.0811064\tvalid_1's rmse: 0.0846042\n",
      "[1125]\ttraining's rmse: 0.0810883\tvalid_1's rmse: 0.0846009\n",
      "[1150]\ttraining's rmse: 0.0810707\tvalid_1's rmse: 0.0845967\n",
      "[1175]\ttraining's rmse: 0.0810537\tvalid_1's rmse: 0.0845927\n",
      "[1200]\ttraining's rmse: 0.0810386\tvalid_1's rmse: 0.0845892\n",
      "[1225]\ttraining's rmse: 0.0810241\tvalid_1's rmse: 0.0845868\n",
      "[1250]\ttraining's rmse: 0.0810098\tvalid_1's rmse: 0.0845836\n",
      "[1275]\ttraining's rmse: 0.0809928\tvalid_1's rmse: 0.0845809\n",
      "[1300]\ttraining's rmse: 0.0809797\tvalid_1's rmse: 0.0845788\n",
      "[1325]\ttraining's rmse: 0.0809663\tvalid_1's rmse: 0.0845765\n",
      "[1350]\ttraining's rmse: 0.0809513\tvalid_1's rmse: 0.0845744\n",
      "[1375]\ttraining's rmse: 0.0809411\tvalid_1's rmse: 0.0845734\n",
      "[1400]\ttraining's rmse: 0.0809312\tvalid_1's rmse: 0.0845709\n",
      "[1425]\ttraining's rmse: 0.0809192\tvalid_1's rmse: 0.0845688\n",
      "[1450]\ttraining's rmse: 0.0809085\tvalid_1's rmse: 0.0845675\n",
      "[1475]\ttraining's rmse: 0.0808973\tvalid_1's rmse: 0.0845658\n",
      "[1500]\ttraining's rmse: 0.0808874\tvalid_1's rmse: 0.0845641\n",
      "[1525]\ttraining's rmse: 0.0808789\tvalid_1's rmse: 0.0845628\n",
      "[1550]\ttraining's rmse: 0.0808694\tvalid_1's rmse: 0.0845619\n",
      "[1575]\ttraining's rmse: 0.0808604\tvalid_1's rmse: 0.0845599\n",
      "[1600]\ttraining's rmse: 0.0808522\tvalid_1's rmse: 0.0845594\n",
      "[1625]\ttraining's rmse: 0.0808419\tvalid_1's rmse: 0.0845581\n",
      "[1650]\ttraining's rmse: 0.0808341\tvalid_1's rmse: 0.084557\n",
      "[1675]\ttraining's rmse: 0.0808277\tvalid_1's rmse: 0.0845556\n",
      "[1700]\ttraining's rmse: 0.0808219\tvalid_1's rmse: 0.0845547\n",
      "[1725]\ttraining's rmse: 0.0808156\tvalid_1's rmse: 0.0845537\n",
      "[1750]\ttraining's rmse: 0.0808088\tvalid_1's rmse: 0.0845525\n",
      "[1775]\ttraining's rmse: 0.0808031\tvalid_1's rmse: 0.0845514\n",
      "[1800]\ttraining's rmse: 0.0807974\tvalid_1's rmse: 0.0845506\n",
      "[1825]\ttraining's rmse: 0.0807918\tvalid_1's rmse: 0.0845495\n",
      "[1850]\ttraining's rmse: 0.0807876\tvalid_1's rmse: 0.0845488\n",
      "[1875]\ttraining's rmse: 0.0807813\tvalid_1's rmse: 0.0845481\n",
      "[1900]\ttraining's rmse: 0.080777\tvalid_1's rmse: 0.0845485\n",
      "[1925]\ttraining's rmse: 0.080773\tvalid_1's rmse: 0.0845478\n",
      "[1950]\ttraining's rmse: 0.0807693\tvalid_1's rmse: 0.0845469\n",
      "[1975]\ttraining's rmse: 0.0807652\tvalid_1's rmse: 0.0845461\n",
      "[2000]\ttraining's rmse: 0.0807609\tvalid_1's rmse: 0.0845454\n",
      "[2025]\ttraining's rmse: 0.0807564\tvalid_1's rmse: 0.0845448\n",
      "[2050]\ttraining's rmse: 0.0807527\tvalid_1's rmse: 0.0845448\n",
      "[2075]\ttraining's rmse: 0.0807488\tvalid_1's rmse: 0.0845445\n",
      "[2100]\ttraining's rmse: 0.0807462\tvalid_1's rmse: 0.0845444\n",
      "[2125]\ttraining's rmse: 0.0807432\tvalid_1's rmse: 0.0845446\n",
      "[2150]\ttraining's rmse: 0.0807402\tvalid_1's rmse: 0.0845446\n",
      "Early stopping, best iteration is:\n",
      "[2101]\ttraining's rmse: 0.0807461\tvalid_1's rmse: 0.0845444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0854667\tvalid_1's rmse: 0.0810985\n",
      "[50]\ttraining's rmse: 0.0853549\tvalid_1's rmse: 0.0810503\n",
      "[75]\ttraining's rmse: 0.0852388\tvalid_1's rmse: 0.0810011\n",
      "[100]\ttraining's rmse: 0.0851345\tvalid_1's rmse: 0.0809595\n",
      "[125]\ttraining's rmse: 0.085027\tvalid_1's rmse: 0.0809174\n",
      "[150]\ttraining's rmse: 0.0849271\tvalid_1's rmse: 0.0808825\n",
      "[175]\ttraining's rmse: 0.0848472\tvalid_1's rmse: 0.080852\n",
      "[200]\ttraining's rmse: 0.0847604\tvalid_1's rmse: 0.0808209\n",
      "[225]\ttraining's rmse: 0.084677\tvalid_1's rmse: 0.08079\n",
      "[250]\ttraining's rmse: 0.0846041\tvalid_1's rmse: 0.0807638\n",
      "[275]\ttraining's rmse: 0.0845391\tvalid_1's rmse: 0.0807391\n",
      "[300]\ttraining's rmse: 0.084473\tvalid_1's rmse: 0.0807154\n",
      "[325]\ttraining's rmse: 0.0844065\tvalid_1's rmse: 0.0806932\n",
      "[350]\ttraining's rmse: 0.084341\tvalid_1's rmse: 0.0806717\n",
      "[375]\ttraining's rmse: 0.0842884\tvalid_1's rmse: 0.0806535\n",
      "[400]\ttraining's rmse: 0.0842286\tvalid_1's rmse: 0.0806385\n",
      "[425]\ttraining's rmse: 0.0841772\tvalid_1's rmse: 0.0806228\n",
      "[450]\ttraining's rmse: 0.0841266\tvalid_1's rmse: 0.0806067\n",
      "[475]\ttraining's rmse: 0.0840819\tvalid_1's rmse: 0.0805986\n",
      "[500]\ttraining's rmse: 0.0840417\tvalid_1's rmse: 0.0805843\n",
      "[525]\ttraining's rmse: 0.0839905\tvalid_1's rmse: 0.0805714\n",
      "[550]\ttraining's rmse: 0.0839429\tvalid_1's rmse: 0.0805585\n",
      "[575]\ttraining's rmse: 0.0839006\tvalid_1's rmse: 0.0805527\n",
      "[600]\ttraining's rmse: 0.0838596\tvalid_1's rmse: 0.080543\n",
      "[625]\ttraining's rmse: 0.0838274\tvalid_1's rmse: 0.0805335\n",
      "[650]\ttraining's rmse: 0.0837859\tvalid_1's rmse: 0.0805266\n",
      "[675]\ttraining's rmse: 0.083741\tvalid_1's rmse: 0.0805259\n",
      "[700]\ttraining's rmse: 0.0837032\tvalid_1's rmse: 0.0805329\n",
      "[725]\ttraining's rmse: 0.0836692\tvalid_1's rmse: 0.0805296\n",
      "Early stopping, best iteration is:\n",
      "[684]\ttraining's rmse: 0.0837259\tvalid_1's rmse: 0.0805223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.086121\tvalid_1's rmse: 0.0882988\n",
      "[50]\ttraining's rmse: 0.0859807\tvalid_1's rmse: 0.0882464\n",
      "[75]\ttraining's rmse: 0.0858394\tvalid_1's rmse: 0.0881933\n",
      "[100]\ttraining's rmse: 0.0857046\tvalid_1's rmse: 0.088149\n",
      "[125]\ttraining's rmse: 0.085575\tvalid_1's rmse: 0.0881042\n",
      "[150]\ttraining's rmse: 0.0854534\tvalid_1's rmse: 0.088066\n",
      "[175]\ttraining's rmse: 0.0853515\tvalid_1's rmse: 0.08803\n",
      "[200]\ttraining's rmse: 0.0852428\tvalid_1's rmse: 0.0879946\n",
      "[225]\ttraining's rmse: 0.085136\tvalid_1's rmse: 0.0879593\n",
      "[250]\ttraining's rmse: 0.0850458\tvalid_1's rmse: 0.0879286\n",
      "[275]\ttraining's rmse: 0.0849617\tvalid_1's rmse: 0.0879016\n",
      "[300]\ttraining's rmse: 0.0848792\tvalid_1's rmse: 0.0878743\n",
      "[325]\ttraining's rmse: 0.0847941\tvalid_1's rmse: 0.0878491\n",
      "[350]\ttraining's rmse: 0.0847142\tvalid_1's rmse: 0.0878238\n",
      "[375]\ttraining's rmse: 0.0846477\tvalid_1's rmse: 0.0878034\n",
      "[400]\ttraining's rmse: 0.0845756\tvalid_1's rmse: 0.0877855\n",
      "[425]\ttraining's rmse: 0.0845101\tvalid_1's rmse: 0.0877651\n",
      "[450]\ttraining's rmse: 0.084452\tvalid_1's rmse: 0.0877459\n",
      "[475]\ttraining's rmse: 0.0843955\tvalid_1's rmse: 0.0877279\n",
      "[500]\ttraining's rmse: 0.0843468\tvalid_1's rmse: 0.087713\n",
      "[525]\ttraining's rmse: 0.0842868\tvalid_1's rmse: 0.0876971\n",
      "[550]\ttraining's rmse: 0.0842327\tvalid_1's rmse: 0.0876829\n",
      "[575]\ttraining's rmse: 0.0841796\tvalid_1's rmse: 0.0876676\n",
      "[600]\ttraining's rmse: 0.0841293\tvalid_1's rmse: 0.087655\n",
      "[625]\ttraining's rmse: 0.0840868\tvalid_1's rmse: 0.0876429\n",
      "[650]\ttraining's rmse: 0.0840406\tvalid_1's rmse: 0.0876312\n",
      "[675]\ttraining's rmse: 0.0839928\tvalid_1's rmse: 0.087621\n",
      "[700]\ttraining's rmse: 0.0839489\tvalid_1's rmse: 0.0876105\n",
      "[725]\ttraining's rmse: 0.0839091\tvalid_1's rmse: 0.087601\n",
      "[750]\ttraining's rmse: 0.083869\tvalid_1's rmse: 0.0875907\n",
      "[775]\ttraining's rmse: 0.0838382\tvalid_1's rmse: 0.0875821\n",
      "[800]\ttraining's rmse: 0.0838015\tvalid_1's rmse: 0.0875742\n",
      "[825]\ttraining's rmse: 0.0837693\tvalid_1's rmse: 0.0875665\n",
      "[850]\ttraining's rmse: 0.0837325\tvalid_1's rmse: 0.0875598\n",
      "[875]\ttraining's rmse: 0.0837042\tvalid_1's rmse: 0.0875537\n",
      "[900]\ttraining's rmse: 0.0836724\tvalid_1's rmse: 0.0875477\n",
      "[925]\ttraining's rmse: 0.0836435\tvalid_1's rmse: 0.0875411\n",
      "[950]\ttraining's rmse: 0.0836138\tvalid_1's rmse: 0.0875347\n",
      "[975]\ttraining's rmse: 0.0835869\tvalid_1's rmse: 0.0875295\n",
      "[1000]\ttraining's rmse: 0.0835599\tvalid_1's rmse: 0.0875251\n",
      "[1025]\ttraining's rmse: 0.083534\tvalid_1's rmse: 0.0875197\n",
      "[1050]\ttraining's rmse: 0.0835105\tvalid_1's rmse: 0.0875133\n",
      "[1075]\ttraining's rmse: 0.0834915\tvalid_1's rmse: 0.0875095\n",
      "[1100]\ttraining's rmse: 0.0834717\tvalid_1's rmse: 0.0875051\n",
      "[1125]\ttraining's rmse: 0.0834531\tvalid_1's rmse: 0.0874998\n",
      "[1150]\ttraining's rmse: 0.0834333\tvalid_1's rmse: 0.0874966\n",
      "[1175]\ttraining's rmse: 0.0834147\tvalid_1's rmse: 0.0874936\n",
      "[1200]\ttraining's rmse: 0.0833949\tvalid_1's rmse: 0.0874879\n",
      "[1225]\ttraining's rmse: 0.083378\tvalid_1's rmse: 0.0874835\n",
      "[1250]\ttraining's rmse: 0.0833593\tvalid_1's rmse: 0.0874795\n",
      "[1275]\ttraining's rmse: 0.08334\tvalid_1's rmse: 0.0874756\n",
      "[1300]\ttraining's rmse: 0.0833239\tvalid_1's rmse: 0.0874717\n",
      "[1325]\ttraining's rmse: 0.0833075\tvalid_1's rmse: 0.0874691\n",
      "[1350]\ttraining's rmse: 0.0832955\tvalid_1's rmse: 0.0874664\n",
      "[1375]\ttraining's rmse: 0.0832798\tvalid_1's rmse: 0.0874644\n",
      "[1400]\ttraining's rmse: 0.0832651\tvalid_1's rmse: 0.0874598\n",
      "[1425]\ttraining's rmse: 0.0832509\tvalid_1's rmse: 0.0874581\n",
      "[1450]\ttraining's rmse: 0.0832359\tvalid_1's rmse: 0.0874551\n",
      "[1475]\ttraining's rmse: 0.0832242\tvalid_1's rmse: 0.0874509\n",
      "[1500]\ttraining's rmse: 0.0832126\tvalid_1's rmse: 0.0874484\n",
      "[1525]\ttraining's rmse: 0.0832029\tvalid_1's rmse: 0.0874462\n",
      "[1550]\ttraining's rmse: 0.0831899\tvalid_1's rmse: 0.0874441\n",
      "[1575]\ttraining's rmse: 0.0831802\tvalid_1's rmse: 0.0874421\n",
      "[1600]\ttraining's rmse: 0.0831723\tvalid_1's rmse: 0.0874395\n",
      "[1625]\ttraining's rmse: 0.0831656\tvalid_1's rmse: 0.0874371\n",
      "[1650]\ttraining's rmse: 0.0831578\tvalid_1's rmse: 0.0874348\n",
      "[1675]\ttraining's rmse: 0.0831498\tvalid_1's rmse: 0.0874319\n",
      "[1700]\ttraining's rmse: 0.0831429\tvalid_1's rmse: 0.0874295\n",
      "[1725]\ttraining's rmse: 0.0831344\tvalid_1's rmse: 0.087428\n",
      "[1750]\ttraining's rmse: 0.0831274\tvalid_1's rmse: 0.0874267\n",
      "[1775]\ttraining's rmse: 0.0831207\tvalid_1's rmse: 0.0874247\n",
      "[1800]\ttraining's rmse: 0.0831136\tvalid_1's rmse: 0.0874229\n",
      "[1825]\ttraining's rmse: 0.0831072\tvalid_1's rmse: 0.0874206\n",
      "[1850]\ttraining's rmse: 0.0831013\tvalid_1's rmse: 0.0874182\n",
      "[1875]\ttraining's rmse: 0.0830961\tvalid_1's rmse: 0.0874168\n",
      "[1900]\ttraining's rmse: 0.0830902\tvalid_1's rmse: 0.0874156\n",
      "[1925]\ttraining's rmse: 0.0830848\tvalid_1's rmse: 0.087415\n",
      "[1950]\ttraining's rmse: 0.0830804\tvalid_1's rmse: 0.087414\n",
      "[1975]\ttraining's rmse: 0.0830757\tvalid_1's rmse: 0.0874127\n",
      "[2000]\ttraining's rmse: 0.0830697\tvalid_1's rmse: 0.0874119\n",
      "[2025]\ttraining's rmse: 0.0830656\tvalid_1's rmse: 0.0874101\n",
      "[2050]\ttraining's rmse: 0.0830614\tvalid_1's rmse: 0.0874085\n",
      "[2075]\ttraining's rmse: 0.083059\tvalid_1's rmse: 0.0874083\n",
      "[2100]\ttraining's rmse: 0.0830557\tvalid_1's rmse: 0.0874071\n",
      "[2125]\ttraining's rmse: 0.0830513\tvalid_1's rmse: 0.0874061\n",
      "[2150]\ttraining's rmse: 0.0830481\tvalid_1's rmse: 0.0874053\n",
      "[2175]\ttraining's rmse: 0.0830459\tvalid_1's rmse: 0.0874047\n",
      "[2200]\ttraining's rmse: 0.0830416\tvalid_1's rmse: 0.0874037\n",
      "[2225]\ttraining's rmse: 0.0830384\tvalid_1's rmse: 0.0874025\n",
      "[2250]\ttraining's rmse: 0.083033\tvalid_1's rmse: 0.087402\n",
      "[2275]\ttraining's rmse: 0.0830301\tvalid_1's rmse: 0.0874014\n",
      "[2300]\ttraining's rmse: 0.0830264\tvalid_1's rmse: 0.0874\n",
      "[2325]\ttraining's rmse: 0.0830225\tvalid_1's rmse: 0.0873995\n",
      "[2350]\ttraining's rmse: 0.083021\tvalid_1's rmse: 0.0873993\n",
      "[2375]\ttraining's rmse: 0.0830179\tvalid_1's rmse: 0.0873989\n",
      "[2400]\ttraining's rmse: 0.0830129\tvalid_1's rmse: 0.0873978\n",
      "[2425]\ttraining's rmse: 0.0830098\tvalid_1's rmse: 0.0873963\n",
      "[2450]\ttraining's rmse: 0.0830082\tvalid_1's rmse: 0.0873961\n",
      "[2475]\ttraining's rmse: 0.0830056\tvalid_1's rmse: 0.0873949\n",
      "[2500]\ttraining's rmse: 0.0830036\tvalid_1's rmse: 0.0873943\n",
      "[2525]\ttraining's rmse: 0.0830013\tvalid_1's rmse: 0.0873935\n",
      "[2550]\ttraining's rmse: 0.0829979\tvalid_1's rmse: 0.0873929\n",
      "[2575]\ttraining's rmse: 0.0829954\tvalid_1's rmse: 0.0873928\n",
      "[2600]\ttraining's rmse: 0.0829938\tvalid_1's rmse: 0.0873927\n",
      "[2625]\ttraining's rmse: 0.0829919\tvalid_1's rmse: 0.0873924\n",
      "[2650]\ttraining's rmse: 0.0829896\tvalid_1's rmse: 0.0873914\n",
      "[2675]\ttraining's rmse: 0.0829877\tvalid_1's rmse: 0.087391\n",
      "[2700]\ttraining's rmse: 0.0829853\tvalid_1's rmse: 0.0873904\n",
      "[2725]\ttraining's rmse: 0.0829821\tvalid_1's rmse: 0.0873899\n",
      "[2750]\ttraining's rmse: 0.0829799\tvalid_1's rmse: 0.0873897\n",
      "[2775]\ttraining's rmse: 0.0829779\tvalid_1's rmse: 0.0873892\n",
      "[2800]\ttraining's rmse: 0.0829756\tvalid_1's rmse: 0.0873892\n",
      "[2825]\ttraining's rmse: 0.0829738\tvalid_1's rmse: 0.0873881\n",
      "[2850]\ttraining's rmse: 0.0829716\tvalid_1's rmse: 0.0873878\n",
      "[2875]\ttraining's rmse: 0.0829699\tvalid_1's rmse: 0.0873874\n",
      "[2900]\ttraining's rmse: 0.0829677\tvalid_1's rmse: 0.0873867\n",
      "[2925]\ttraining's rmse: 0.0829667\tvalid_1's rmse: 0.0873861\n",
      "[2950]\ttraining's rmse: 0.0829659\tvalid_1's rmse: 0.0873859\n",
      "[2975]\ttraining's rmse: 0.0829647\tvalid_1's rmse: 0.0873856\n",
      "[3000]\ttraining's rmse: 0.0829629\tvalid_1's rmse: 0.0873846\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0829629\tvalid_1's rmse: 0.0873846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0860389\tvalid_1's rmse: 0.0884975\n",
      "[50]\ttraining's rmse: 0.0859161\tvalid_1's rmse: 0.0884439\n",
      "[75]\ttraining's rmse: 0.0857907\tvalid_1's rmse: 0.0883908\n",
      "[100]\ttraining's rmse: 0.0856764\tvalid_1's rmse: 0.0883432\n",
      "[125]\ttraining's rmse: 0.0855543\tvalid_1's rmse: 0.0882954\n",
      "[150]\ttraining's rmse: 0.0854458\tvalid_1's rmse: 0.0882521\n",
      "[175]\ttraining's rmse: 0.0853562\tvalid_1's rmse: 0.0882152\n",
      "[200]\ttraining's rmse: 0.0852596\tvalid_1's rmse: 0.0881771\n",
      "[225]\ttraining's rmse: 0.0851654\tvalid_1's rmse: 0.0881416\n",
      "[250]\ttraining's rmse: 0.0850827\tvalid_1's rmse: 0.0881093\n",
      "[275]\ttraining's rmse: 0.0850062\tvalid_1's rmse: 0.0880796\n",
      "[300]\ttraining's rmse: 0.0849296\tvalid_1's rmse: 0.0880522\n",
      "[325]\ttraining's rmse: 0.0848485\tvalid_1's rmse: 0.0880249\n",
      "[350]\ttraining's rmse: 0.0847757\tvalid_1's rmse: 0.0879991\n",
      "[375]\ttraining's rmse: 0.0847149\tvalid_1's rmse: 0.0879773\n",
      "[400]\ttraining's rmse: 0.0846474\tvalid_1's rmse: 0.0879565\n",
      "[425]\ttraining's rmse: 0.0845862\tvalid_1's rmse: 0.0879355\n",
      "[450]\ttraining's rmse: 0.0845296\tvalid_1's rmse: 0.0879165\n",
      "[475]\ttraining's rmse: 0.0844778\tvalid_1's rmse: 0.0878995\n",
      "[500]\ttraining's rmse: 0.0844338\tvalid_1's rmse: 0.0878846\n",
      "[525]\ttraining's rmse: 0.0843761\tvalid_1's rmse: 0.0878671\n",
      "[550]\ttraining's rmse: 0.0843223\tvalid_1's rmse: 0.0878516\n",
      "[575]\ttraining's rmse: 0.0842761\tvalid_1's rmse: 0.0878366\n",
      "[600]\ttraining's rmse: 0.0842292\tvalid_1's rmse: 0.087823\n",
      "[625]\ttraining's rmse: 0.0841924\tvalid_1's rmse: 0.0878108\n",
      "[650]\ttraining's rmse: 0.0841459\tvalid_1's rmse: 0.0877974\n",
      "[675]\ttraining's rmse: 0.0841027\tvalid_1's rmse: 0.087786\n",
      "[700]\ttraining's rmse: 0.0840629\tvalid_1's rmse: 0.087775\n",
      "[725]\ttraining's rmse: 0.0840267\tvalid_1's rmse: 0.0877658\n",
      "[750]\ttraining's rmse: 0.0839921\tvalid_1's rmse: 0.0877566\n",
      "[775]\ttraining's rmse: 0.0839636\tvalid_1's rmse: 0.0877476\n",
      "[800]\ttraining's rmse: 0.0839271\tvalid_1's rmse: 0.0877395\n",
      "[825]\ttraining's rmse: 0.0838972\tvalid_1's rmse: 0.0877318\n",
      "[850]\ttraining's rmse: 0.0838648\tvalid_1's rmse: 0.0877246\n",
      "[875]\ttraining's rmse: 0.0838365\tvalid_1's rmse: 0.087718\n",
      "[900]\ttraining's rmse: 0.0838078\tvalid_1's rmse: 0.0877105\n",
      "[925]\ttraining's rmse: 0.0837802\tvalid_1's rmse: 0.0877054\n",
      "[950]\ttraining's rmse: 0.0837539\tvalid_1's rmse: 0.0876994\n",
      "[975]\ttraining's rmse: 0.0837289\tvalid_1's rmse: 0.0876937\n",
      "[1000]\ttraining's rmse: 0.0837065\tvalid_1's rmse: 0.0876886\n",
      "[1025]\ttraining's rmse: 0.0836785\tvalid_1's rmse: 0.0876842\n",
      "[1050]\ttraining's rmse: 0.0836558\tvalid_1's rmse: 0.0876798\n",
      "[1075]\ttraining's rmse: 0.0836358\tvalid_1's rmse: 0.0876768\n",
      "[1100]\ttraining's rmse: 0.0836162\tvalid_1's rmse: 0.0876731\n",
      "[1125]\ttraining's rmse: 0.0835963\tvalid_1's rmse: 0.0876697\n",
      "[1150]\ttraining's rmse: 0.0835766\tvalid_1's rmse: 0.0876662\n",
      "[1175]\ttraining's rmse: 0.0835604\tvalid_1's rmse: 0.0876625\n",
      "[1200]\ttraining's rmse: 0.0835427\tvalid_1's rmse: 0.0876589\n",
      "[1225]\ttraining's rmse: 0.0835274\tvalid_1's rmse: 0.0876567\n",
      "[1250]\ttraining's rmse: 0.0835115\tvalid_1's rmse: 0.0876539\n",
      "[1275]\ttraining's rmse: 0.0834938\tvalid_1's rmse: 0.0876512\n",
      "[1300]\ttraining's rmse: 0.0834787\tvalid_1's rmse: 0.0876485\n",
      "[1325]\ttraining's rmse: 0.0834656\tvalid_1's rmse: 0.0876466\n",
      "[1350]\ttraining's rmse: 0.0834494\tvalid_1's rmse: 0.0876448\n",
      "[1375]\ttraining's rmse: 0.083435\tvalid_1's rmse: 0.0876426\n",
      "[1400]\ttraining's rmse: 0.0834225\tvalid_1's rmse: 0.0876402\n",
      "[1425]\ttraining's rmse: 0.0834068\tvalid_1's rmse: 0.0876386\n",
      "[1450]\ttraining's rmse: 0.0833952\tvalid_1's rmse: 0.0876377\n",
      "[1475]\ttraining's rmse: 0.0833837\tvalid_1's rmse: 0.0876361\n",
      "[1500]\ttraining's rmse: 0.0833736\tvalid_1's rmse: 0.0876348\n",
      "[1525]\ttraining's rmse: 0.0833633\tvalid_1's rmse: 0.0876332\n",
      "[1550]\ttraining's rmse: 0.083354\tvalid_1's rmse: 0.0876316\n",
      "[1575]\ttraining's rmse: 0.083343\tvalid_1's rmse: 0.0876301\n",
      "[1600]\ttraining's rmse: 0.0833362\tvalid_1's rmse: 0.0876298\n",
      "[1625]\ttraining's rmse: 0.0833263\tvalid_1's rmse: 0.0876273\n",
      "[1650]\ttraining's rmse: 0.0833165\tvalid_1's rmse: 0.0876265\n",
      "[1675]\ttraining's rmse: 0.0833103\tvalid_1's rmse: 0.0876255\n",
      "[1700]\ttraining's rmse: 0.0833031\tvalid_1's rmse: 0.0876239\n",
      "[1725]\ttraining's rmse: 0.0832969\tvalid_1's rmse: 0.0876228\n",
      "[1750]\ttraining's rmse: 0.0832907\tvalid_1's rmse: 0.0876221\n",
      "[1775]\ttraining's rmse: 0.0832835\tvalid_1's rmse: 0.0876217\n",
      "[1800]\ttraining's rmse: 0.083278\tvalid_1's rmse: 0.0876211\n",
      "[1825]\ttraining's rmse: 0.0832725\tvalid_1's rmse: 0.0876207\n",
      "[1850]\ttraining's rmse: 0.0832674\tvalid_1's rmse: 0.08762\n",
      "[1875]\ttraining's rmse: 0.0832617\tvalid_1's rmse: 0.0876196\n",
      "[1900]\ttraining's rmse: 0.0832574\tvalid_1's rmse: 0.0876194\n",
      "[1925]\ttraining's rmse: 0.0832515\tvalid_1's rmse: 0.0876191\n",
      "[1950]\ttraining's rmse: 0.0832473\tvalid_1's rmse: 0.087618\n",
      "[1975]\ttraining's rmse: 0.0832423\tvalid_1's rmse: 0.0876173\n",
      "[2000]\ttraining's rmse: 0.0832369\tvalid_1's rmse: 0.0876167\n",
      "[2025]\ttraining's rmse: 0.0832318\tvalid_1's rmse: 0.0876159\n",
      "[2050]\ttraining's rmse: 0.0832285\tvalid_1's rmse: 0.087616\n",
      "[2075]\ttraining's rmse: 0.0832257\tvalid_1's rmse: 0.0876155\n",
      "[2100]\ttraining's rmse: 0.0832228\tvalid_1's rmse: 0.0876153\n",
      "[2125]\ttraining's rmse: 0.0832193\tvalid_1's rmse: 0.0876153\n",
      "[2150]\ttraining's rmse: 0.0832158\tvalid_1's rmse: 0.0876149\n",
      "[2175]\ttraining's rmse: 0.0832129\tvalid_1's rmse: 0.0876146\n",
      "[2200]\ttraining's rmse: 0.0832096\tvalid_1's rmse: 0.0876141\n",
      "[2225]\ttraining's rmse: 0.0832065\tvalid_1's rmse: 0.0876139\n",
      "[2250]\ttraining's rmse: 0.0832028\tvalid_1's rmse: 0.0876139\n",
      "[2275]\ttraining's rmse: 0.0831987\tvalid_1's rmse: 0.0876137\n",
      "[2300]\ttraining's rmse: 0.0831958\tvalid_1's rmse: 0.0876134\n",
      "[2325]\ttraining's rmse: 0.0831924\tvalid_1's rmse: 0.0876133\n",
      "[2350]\ttraining's rmse: 0.0831902\tvalid_1's rmse: 0.0876131\n",
      "[2375]\ttraining's rmse: 0.0831867\tvalid_1's rmse: 0.0876125\n",
      "[2400]\ttraining's rmse: 0.0831835\tvalid_1's rmse: 0.0876127\n",
      "[2425]\ttraining's rmse: 0.0831803\tvalid_1's rmse: 0.0876123\n",
      "[2450]\ttraining's rmse: 0.0831774\tvalid_1's rmse: 0.087612\n",
      "[2475]\ttraining's rmse: 0.083175\tvalid_1's rmse: 0.0876123\n",
      "Early stopping, best iteration is:\n",
      "[2439]\ttraining's rmse: 0.0831785\tvalid_1's rmse: 0.0876119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0882666\tvalid_1's rmse: 0.0839703\n",
      "[50]\ttraining's rmse: 0.0881445\tvalid_1's rmse: 0.0839203\n",
      "[75]\ttraining's rmse: 0.0880168\tvalid_1's rmse: 0.0838711\n",
      "[100]\ttraining's rmse: 0.0879006\tvalid_1's rmse: 0.0838284\n",
      "[125]\ttraining's rmse: 0.087782\tvalid_1's rmse: 0.0837882\n",
      "[150]\ttraining's rmse: 0.0876719\tvalid_1's rmse: 0.0837484\n",
      "[175]\ttraining's rmse: 0.0875809\tvalid_1's rmse: 0.0837162\n",
      "[200]\ttraining's rmse: 0.0874802\tvalid_1's rmse: 0.0836845\n",
      "[225]\ttraining's rmse: 0.0873839\tvalid_1's rmse: 0.0836535\n",
      "[250]\ttraining's rmse: 0.0873019\tvalid_1's rmse: 0.0836263\n",
      "[275]\ttraining's rmse: 0.0872269\tvalid_1's rmse: 0.0836013\n",
      "[300]\ttraining's rmse: 0.0871544\tvalid_1's rmse: 0.0835777\n",
      "[325]\ttraining's rmse: 0.0870777\tvalid_1's rmse: 0.0835545\n",
      "[350]\ttraining's rmse: 0.0870041\tvalid_1's rmse: 0.0835321\n",
      "[375]\ttraining's rmse: 0.0869427\tvalid_1's rmse: 0.0835146\n",
      "[400]\ttraining's rmse: 0.0868758\tvalid_1's rmse: 0.0834966\n",
      "[425]\ttraining's rmse: 0.0868168\tvalid_1's rmse: 0.0834811\n",
      "[450]\ttraining's rmse: 0.0867613\tvalid_1's rmse: 0.083468\n",
      "[475]\ttraining's rmse: 0.0867117\tvalid_1's rmse: 0.0834553\n",
      "[500]\ttraining's rmse: 0.0866674\tvalid_1's rmse: 0.0834422\n",
      "[525]\ttraining's rmse: 0.0866088\tvalid_1's rmse: 0.0834287\n",
      "[550]\ttraining's rmse: 0.086558\tvalid_1's rmse: 0.0834168\n",
      "[575]\ttraining's rmse: 0.086509\tvalid_1's rmse: 0.0834141\n",
      "[600]\ttraining's rmse: 0.0864619\tvalid_1's rmse: 0.0834044\n",
      "[625]\ttraining's rmse: 0.0864252\tvalid_1's rmse: 0.0833947\n",
      "[650]\ttraining's rmse: 0.0863777\tvalid_1's rmse: 0.0833887\n",
      "[675]\ttraining's rmse: 0.0863303\tvalid_1's rmse: 0.0833822\n",
      "[700]\ttraining's rmse: 0.0862894\tvalid_1's rmse: 0.0833847\n",
      "[725]\ttraining's rmse: 0.0862505\tvalid_1's rmse: 0.0833934\n",
      "Early stopping, best iteration is:\n",
      "[677]\ttraining's rmse: 0.0863258\tvalid_1's rmse: 0.0833817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0835973\tvalid_1's rmse: 0.0863849\n",
      "[50]\ttraining's rmse: 0.0834702\tvalid_1's rmse: 0.086332\n",
      "[75]\ttraining's rmse: 0.0833439\tvalid_1's rmse: 0.0862773\n",
      "[100]\ttraining's rmse: 0.0832288\tvalid_1's rmse: 0.0862312\n",
      "[125]\ttraining's rmse: 0.0831111\tvalid_1's rmse: 0.0861855\n",
      "[150]\ttraining's rmse: 0.0830035\tvalid_1's rmse: 0.0861429\n",
      "[175]\ttraining's rmse: 0.0829141\tvalid_1's rmse: 0.0861065\n",
      "[200]\ttraining's rmse: 0.0828184\tvalid_1's rmse: 0.0860697\n",
      "[225]\ttraining's rmse: 0.0827263\tvalid_1's rmse: 0.0860331\n",
      "[250]\ttraining's rmse: 0.0826446\tvalid_1's rmse: 0.0859992\n",
      "[275]\ttraining's rmse: 0.0825682\tvalid_1's rmse: 0.0859704\n",
      "[300]\ttraining's rmse: 0.0824976\tvalid_1's rmse: 0.0859421\n",
      "[325]\ttraining's rmse: 0.082424\tvalid_1's rmse: 0.0859164\n",
      "[350]\ttraining's rmse: 0.0823568\tvalid_1's rmse: 0.0858906\n",
      "[375]\ttraining's rmse: 0.0822983\tvalid_1's rmse: 0.0858681\n",
      "[400]\ttraining's rmse: 0.0822376\tvalid_1's rmse: 0.0858467\n",
      "[425]\ttraining's rmse: 0.0821815\tvalid_1's rmse: 0.0858263\n",
      "[450]\ttraining's rmse: 0.08213\tvalid_1's rmse: 0.085806\n",
      "[475]\ttraining's rmse: 0.0820813\tvalid_1's rmse: 0.0857885\n",
      "[500]\ttraining's rmse: 0.0820399\tvalid_1's rmse: 0.0857721\n",
      "[525]\ttraining's rmse: 0.0819845\tvalid_1's rmse: 0.0857557\n",
      "[550]\ttraining's rmse: 0.0819362\tvalid_1's rmse: 0.0857398\n",
      "[575]\ttraining's rmse: 0.0818915\tvalid_1's rmse: 0.0857244\n",
      "[600]\ttraining's rmse: 0.0818503\tvalid_1's rmse: 0.0857111\n",
      "[625]\ttraining's rmse: 0.0818161\tvalid_1's rmse: 0.0856988\n",
      "[650]\ttraining's rmse: 0.0817756\tvalid_1's rmse: 0.0856857\n",
      "[675]\ttraining's rmse: 0.0817372\tvalid_1's rmse: 0.0856713\n",
      "[700]\ttraining's rmse: 0.0816996\tvalid_1's rmse: 0.0856606\n",
      "[725]\ttraining's rmse: 0.0816647\tvalid_1's rmse: 0.085651\n",
      "[750]\ttraining's rmse: 0.0816301\tvalid_1's rmse: 0.0856411\n",
      "[775]\ttraining's rmse: 0.0816037\tvalid_1's rmse: 0.0856311\n",
      "[800]\ttraining's rmse: 0.0815701\tvalid_1's rmse: 0.0856227\n",
      "[825]\ttraining's rmse: 0.0815416\tvalid_1's rmse: 0.0856143\n",
      "[850]\ttraining's rmse: 0.0815106\tvalid_1's rmse: 0.0856062\n",
      "[875]\ttraining's rmse: 0.0814846\tvalid_1's rmse: 0.0855972\n",
      "[900]\ttraining's rmse: 0.0814566\tvalid_1's rmse: 0.0855901\n",
      "[925]\ttraining's rmse: 0.0814323\tvalid_1's rmse: 0.0855824\n",
      "[950]\ttraining's rmse: 0.0814123\tvalid_1's rmse: 0.0855756\n",
      "[975]\ttraining's rmse: 0.0813896\tvalid_1's rmse: 0.0855691\n",
      "[1000]\ttraining's rmse: 0.0813668\tvalid_1's rmse: 0.0855641\n",
      "[1025]\ttraining's rmse: 0.0813452\tvalid_1's rmse: 0.0855568\n",
      "[1050]\ttraining's rmse: 0.0813241\tvalid_1's rmse: 0.085549\n",
      "[1075]\ttraining's rmse: 0.0813057\tvalid_1's rmse: 0.0855446\n",
      "[1100]\ttraining's rmse: 0.0812888\tvalid_1's rmse: 0.0855386\n",
      "[1125]\ttraining's rmse: 0.081271\tvalid_1's rmse: 0.0855329\n",
      "[1150]\ttraining's rmse: 0.0812523\tvalid_1's rmse: 0.0855274\n",
      "[1175]\ttraining's rmse: 0.0812382\tvalid_1's rmse: 0.0855238\n",
      "[1200]\ttraining's rmse: 0.0812229\tvalid_1's rmse: 0.085518\n",
      "[1225]\ttraining's rmse: 0.0812083\tvalid_1's rmse: 0.0855133\n",
      "[1250]\ttraining's rmse: 0.0811914\tvalid_1's rmse: 0.0855086\n",
      "[1275]\ttraining's rmse: 0.0811753\tvalid_1's rmse: 0.0855045\n",
      "[1300]\ttraining's rmse: 0.0811637\tvalid_1's rmse: 0.0855002\n",
      "[1325]\ttraining's rmse: 0.0811486\tvalid_1's rmse: 0.0854965\n",
      "[1350]\ttraining's rmse: 0.0811357\tvalid_1's rmse: 0.0854947\n",
      "[1375]\ttraining's rmse: 0.0811229\tvalid_1's rmse: 0.0854923\n",
      "[1400]\ttraining's rmse: 0.0811122\tvalid_1's rmse: 0.0854903\n",
      "[1425]\ttraining's rmse: 0.0811014\tvalid_1's rmse: 0.0854864\n",
      "[1450]\ttraining's rmse: 0.081087\tvalid_1's rmse: 0.0854833\n",
      "[1475]\ttraining's rmse: 0.0810751\tvalid_1's rmse: 0.0854798\n",
      "[1500]\ttraining's rmse: 0.081068\tvalid_1's rmse: 0.085478\n",
      "[1525]\ttraining's rmse: 0.0810563\tvalid_1's rmse: 0.0854761\n",
      "[1550]\ttraining's rmse: 0.0810484\tvalid_1's rmse: 0.0854744\n",
      "[1575]\ttraining's rmse: 0.0810394\tvalid_1's rmse: 0.0854714\n",
      "[1600]\ttraining's rmse: 0.0810337\tvalid_1's rmse: 0.0854698\n",
      "[1625]\ttraining's rmse: 0.0810272\tvalid_1's rmse: 0.0854676\n",
      "[1650]\ttraining's rmse: 0.0810208\tvalid_1's rmse: 0.0854655\n",
      "[1675]\ttraining's rmse: 0.0810152\tvalid_1's rmse: 0.0854635\n",
      "[1700]\ttraining's rmse: 0.0810086\tvalid_1's rmse: 0.0854602\n",
      "[1725]\ttraining's rmse: 0.081001\tvalid_1's rmse: 0.0854585\n",
      "[1750]\ttraining's rmse: 0.0809952\tvalid_1's rmse: 0.0854572\n",
      "[1775]\ttraining's rmse: 0.0809901\tvalid_1's rmse: 0.0854562\n",
      "[1800]\ttraining's rmse: 0.0809854\tvalid_1's rmse: 0.0854543\n",
      "[1825]\ttraining's rmse: 0.0809803\tvalid_1's rmse: 0.0854519\n",
      "[1850]\ttraining's rmse: 0.0809751\tvalid_1's rmse: 0.0854499\n",
      "[1875]\ttraining's rmse: 0.0809707\tvalid_1's rmse: 0.0854484\n",
      "[1900]\ttraining's rmse: 0.0809669\tvalid_1's rmse: 0.0854471\n",
      "[1925]\ttraining's rmse: 0.0809627\tvalid_1's rmse: 0.0854463\n",
      "[1950]\ttraining's rmse: 0.0809592\tvalid_1's rmse: 0.0854451\n",
      "[1975]\ttraining's rmse: 0.080954\tvalid_1's rmse: 0.085443\n",
      "[2000]\ttraining's rmse: 0.0809492\tvalid_1's rmse: 0.085442\n",
      "[2025]\ttraining's rmse: 0.0809453\tvalid_1's rmse: 0.0854405\n",
      "[2050]\ttraining's rmse: 0.080941\tvalid_1's rmse: 0.085439\n",
      "[2075]\ttraining's rmse: 0.080938\tvalid_1's rmse: 0.0854379\n",
      "[2100]\ttraining's rmse: 0.0809351\tvalid_1's rmse: 0.0854367\n",
      "[2125]\ttraining's rmse: 0.0809312\tvalid_1's rmse: 0.0854355\n",
      "[2150]\ttraining's rmse: 0.0809271\tvalid_1's rmse: 0.085434\n",
      "[2175]\ttraining's rmse: 0.0809246\tvalid_1's rmse: 0.0854333\n",
      "[2200]\ttraining's rmse: 0.0809222\tvalid_1's rmse: 0.0854331\n",
      "[2225]\ttraining's rmse: 0.0809195\tvalid_1's rmse: 0.0854321\n",
      "[2250]\ttraining's rmse: 0.0809171\tvalid_1's rmse: 0.0854319\n",
      "[2275]\ttraining's rmse: 0.080915\tvalid_1's rmse: 0.0854305\n",
      "[2300]\ttraining's rmse: 0.0809129\tvalid_1's rmse: 0.0854298\n",
      "[2325]\ttraining's rmse: 0.0809108\tvalid_1's rmse: 0.0854288\n",
      "[2350]\ttraining's rmse: 0.0809084\tvalid_1's rmse: 0.0854287\n",
      "[2375]\ttraining's rmse: 0.0809068\tvalid_1's rmse: 0.0854284\n",
      "[2400]\ttraining's rmse: 0.0809036\tvalid_1's rmse: 0.0854284\n",
      "[2425]\ttraining's rmse: 0.0809011\tvalid_1's rmse: 0.0854281\n",
      "[2450]\ttraining's rmse: 0.0808998\tvalid_1's rmse: 0.0854277\n",
      "[2475]\ttraining's rmse: 0.0808959\tvalid_1's rmse: 0.0854273\n",
      "[2500]\ttraining's rmse: 0.0808936\tvalid_1's rmse: 0.0854267\n",
      "[2525]\ttraining's rmse: 0.0808915\tvalid_1's rmse: 0.0854262\n",
      "[2550]\ttraining's rmse: 0.0808895\tvalid_1's rmse: 0.0854259\n",
      "[2575]\ttraining's rmse: 0.0808868\tvalid_1's rmse: 0.0854252\n",
      "[2600]\ttraining's rmse: 0.0808851\tvalid_1's rmse: 0.085425\n",
      "[2625]\ttraining's rmse: 0.0808834\tvalid_1's rmse: 0.0854249\n",
      "[2650]\ttraining's rmse: 0.0808828\tvalid_1's rmse: 0.0854251\n",
      "[2675]\ttraining's rmse: 0.0808809\tvalid_1's rmse: 0.0854237\n",
      "[2700]\ttraining's rmse: 0.0808786\tvalid_1's rmse: 0.0854236\n",
      "[2725]\ttraining's rmse: 0.0808771\tvalid_1's rmse: 0.0854236\n",
      "[2750]\ttraining's rmse: 0.0808749\tvalid_1's rmse: 0.0854237\n",
      "Early stopping, best iteration is:\n",
      "[2706]\ttraining's rmse: 0.0808779\tvalid_1's rmse: 0.0854235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.083872\tvalid_1's rmse: 0.0858514\n",
      "[50]\ttraining's rmse: 0.0837537\tvalid_1's rmse: 0.0857952\n",
      "[75]\ttraining's rmse: 0.083632\tvalid_1's rmse: 0.0857427\n",
      "[100]\ttraining's rmse: 0.0835251\tvalid_1's rmse: 0.0856943\n",
      "[125]\ttraining's rmse: 0.0834153\tvalid_1's rmse: 0.0856453\n",
      "[150]\ttraining's rmse: 0.0833128\tvalid_1's rmse: 0.0856016\n",
      "[175]\ttraining's rmse: 0.0832294\tvalid_1's rmse: 0.0855663\n",
      "[200]\ttraining's rmse: 0.0831352\tvalid_1's rmse: 0.0855294\n",
      "[225]\ttraining's rmse: 0.0830458\tvalid_1's rmse: 0.0854956\n",
      "[250]\ttraining's rmse: 0.0829722\tvalid_1's rmse: 0.0854646\n",
      "[275]\ttraining's rmse: 0.0829032\tvalid_1's rmse: 0.0854368\n",
      "[300]\ttraining's rmse: 0.0828328\tvalid_1's rmse: 0.0854101\n",
      "[325]\ttraining's rmse: 0.08276\tvalid_1's rmse: 0.0853838\n",
      "[350]\ttraining's rmse: 0.0826908\tvalid_1's rmse: 0.0853597\n",
      "[375]\ttraining's rmse: 0.0826344\tvalid_1's rmse: 0.0853379\n",
      "[400]\ttraining's rmse: 0.0825715\tvalid_1's rmse: 0.0853172\n",
      "[425]\ttraining's rmse: 0.082516\tvalid_1's rmse: 0.0852985\n",
      "[450]\ttraining's rmse: 0.0824627\tvalid_1's rmse: 0.0852806\n",
      "[475]\ttraining's rmse: 0.0824131\tvalid_1's rmse: 0.0852636\n",
      "[500]\ttraining's rmse: 0.0823734\tvalid_1's rmse: 0.0852482\n",
      "[525]\ttraining's rmse: 0.082318\tvalid_1's rmse: 0.0852318\n",
      "[550]\ttraining's rmse: 0.0822688\tvalid_1's rmse: 0.0852172\n",
      "[575]\ttraining's rmse: 0.0822247\tvalid_1's rmse: 0.0852038\n",
      "[600]\ttraining's rmse: 0.0821801\tvalid_1's rmse: 0.0851908\n",
      "[625]\ttraining's rmse: 0.0821452\tvalid_1's rmse: 0.085178\n",
      "[650]\ttraining's rmse: 0.0821009\tvalid_1's rmse: 0.0851652\n",
      "[675]\ttraining's rmse: 0.0820575\tvalid_1's rmse: 0.0851541\n",
      "[700]\ttraining's rmse: 0.0820224\tvalid_1's rmse: 0.0851437\n",
      "[725]\ttraining's rmse: 0.0819883\tvalid_1's rmse: 0.0851344\n",
      "[750]\ttraining's rmse: 0.0819548\tvalid_1's rmse: 0.0851255\n",
      "[775]\ttraining's rmse: 0.0819279\tvalid_1's rmse: 0.0851171\n",
      "[800]\ttraining's rmse: 0.0818908\tvalid_1's rmse: 0.0851093\n",
      "[825]\ttraining's rmse: 0.0818604\tvalid_1's rmse: 0.0851007\n",
      "[850]\ttraining's rmse: 0.0818333\tvalid_1's rmse: 0.0850954\n",
      "[875]\ttraining's rmse: 0.0818071\tvalid_1's rmse: 0.0850887\n",
      "[900]\ttraining's rmse: 0.0817787\tvalid_1's rmse: 0.0850826\n",
      "[925]\ttraining's rmse: 0.0817531\tvalid_1's rmse: 0.0850763\n",
      "[950]\ttraining's rmse: 0.081728\tvalid_1's rmse: 0.0850707\n",
      "[975]\ttraining's rmse: 0.0817064\tvalid_1's rmse: 0.0850654\n",
      "[1000]\ttraining's rmse: 0.0816844\tvalid_1's rmse: 0.0850597\n",
      "[1025]\ttraining's rmse: 0.0816609\tvalid_1's rmse: 0.0850562\n",
      "[1050]\ttraining's rmse: 0.0816415\tvalid_1's rmse: 0.0850515\n",
      "[1075]\ttraining's rmse: 0.0816228\tvalid_1's rmse: 0.0850485\n",
      "[1100]\ttraining's rmse: 0.0816068\tvalid_1's rmse: 0.0850443\n",
      "[1125]\ttraining's rmse: 0.0815885\tvalid_1's rmse: 0.0850407\n",
      "[1150]\ttraining's rmse: 0.0815699\tvalid_1's rmse: 0.0850366\n",
      "[1175]\ttraining's rmse: 0.0815543\tvalid_1's rmse: 0.0850341\n",
      "[1200]\ttraining's rmse: 0.0815389\tvalid_1's rmse: 0.0850306\n",
      "[1225]\ttraining's rmse: 0.0815239\tvalid_1's rmse: 0.0850273\n",
      "[1250]\ttraining's rmse: 0.0815099\tvalid_1's rmse: 0.0850245\n",
      "[1275]\ttraining's rmse: 0.0814929\tvalid_1's rmse: 0.0850224\n",
      "[1300]\ttraining's rmse: 0.0814798\tvalid_1's rmse: 0.0850195\n",
      "[1325]\ttraining's rmse: 0.0814682\tvalid_1's rmse: 0.0850174\n",
      "[1350]\ttraining's rmse: 0.0814521\tvalid_1's rmse: 0.0850154\n",
      "[1375]\ttraining's rmse: 0.0814394\tvalid_1's rmse: 0.0850138\n",
      "[1400]\ttraining's rmse: 0.0814287\tvalid_1's rmse: 0.0850114\n",
      "[1425]\ttraining's rmse: 0.0814159\tvalid_1's rmse: 0.0850095\n",
      "[1450]\ttraining's rmse: 0.0814045\tvalid_1's rmse: 0.0850083\n",
      "[1475]\ttraining's rmse: 0.0813934\tvalid_1's rmse: 0.0850062\n",
      "[1500]\ttraining's rmse: 0.0813837\tvalid_1's rmse: 0.0850049\n",
      "[1525]\ttraining's rmse: 0.0813729\tvalid_1's rmse: 0.0850035\n",
      "[1550]\ttraining's rmse: 0.0813625\tvalid_1's rmse: 0.0850021\n",
      "[1575]\ttraining's rmse: 0.0813545\tvalid_1's rmse: 0.0850012\n",
      "[1600]\ttraining's rmse: 0.0813472\tvalid_1's rmse: 0.0850006\n",
      "[1625]\ttraining's rmse: 0.0813377\tvalid_1's rmse: 0.0849997\n",
      "[1650]\ttraining's rmse: 0.0813294\tvalid_1's rmse: 0.0849988\n",
      "[1675]\ttraining's rmse: 0.0813237\tvalid_1's rmse: 0.0849978\n",
      "[1700]\ttraining's rmse: 0.0813164\tvalid_1's rmse: 0.0849964\n",
      "[1725]\ttraining's rmse: 0.081311\tvalid_1's rmse: 0.0849959\n",
      "[1750]\ttraining's rmse: 0.0813038\tvalid_1's rmse: 0.0849949\n",
      "[1775]\ttraining's rmse: 0.0812964\tvalid_1's rmse: 0.0849941\n",
      "[1800]\ttraining's rmse: 0.0812876\tvalid_1's rmse: 0.084994\n",
      "[1825]\ttraining's rmse: 0.0812818\tvalid_1's rmse: 0.084993\n",
      "[1850]\ttraining's rmse: 0.0812762\tvalid_1's rmse: 0.0849923\n",
      "[1875]\ttraining's rmse: 0.0812704\tvalid_1's rmse: 0.0849918\n",
      "[1900]\ttraining's rmse: 0.0812654\tvalid_1's rmse: 0.0849914\n",
      "[1925]\ttraining's rmse: 0.0812602\tvalid_1's rmse: 0.084991\n",
      "[1950]\ttraining's rmse: 0.0812557\tvalid_1's rmse: 0.08499\n",
      "[1975]\ttraining's rmse: 0.0812509\tvalid_1's rmse: 0.0849896\n",
      "[2000]\ttraining's rmse: 0.0812449\tvalid_1's rmse: 0.084989\n",
      "[2025]\ttraining's rmse: 0.0812386\tvalid_1's rmse: 0.0849883\n",
      "[2050]\ttraining's rmse: 0.0812345\tvalid_1's rmse: 0.0849876\n",
      "[2075]\ttraining's rmse: 0.0812319\tvalid_1's rmse: 0.0849873\n",
      "[2100]\ttraining's rmse: 0.0812297\tvalid_1's rmse: 0.0849871\n",
      "[2125]\ttraining's rmse: 0.0812263\tvalid_1's rmse: 0.0849868\n",
      "[2150]\ttraining's rmse: 0.0812232\tvalid_1's rmse: 0.0849869\n",
      "[2175]\ttraining's rmse: 0.0812193\tvalid_1's rmse: 0.0849864\n",
      "[2200]\ttraining's rmse: 0.0812163\tvalid_1's rmse: 0.0849862\n",
      "[2225]\ttraining's rmse: 0.0812138\tvalid_1's rmse: 0.0849859\n",
      "[2250]\ttraining's rmse: 0.0812105\tvalid_1's rmse: 0.0849858\n",
      "[2275]\ttraining's rmse: 0.0812078\tvalid_1's rmse: 0.0849855\n",
      "[2300]\ttraining's rmse: 0.0812048\tvalid_1's rmse: 0.0849857\n",
      "[2325]\ttraining's rmse: 0.0812013\tvalid_1's rmse: 0.0849855\n",
      "[2350]\ttraining's rmse: 0.0811991\tvalid_1's rmse: 0.0849854\n",
      "[2375]\ttraining's rmse: 0.0811961\tvalid_1's rmse: 0.0849854\n",
      "Early stopping, best iteration is:\n",
      "[2338]\ttraining's rmse: 0.0812002\tvalid_1's rmse: 0.0849851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.085997\tvalid_1's rmse: 0.0815236\n",
      "[50]\ttraining's rmse: 0.085882\tvalid_1's rmse: 0.0814749\n",
      "[75]\ttraining's rmse: 0.0857641\tvalid_1's rmse: 0.0814262\n",
      "[100]\ttraining's rmse: 0.0856592\tvalid_1's rmse: 0.0813839\n",
      "[125]\ttraining's rmse: 0.0855497\tvalid_1's rmse: 0.0813417\n",
      "[150]\ttraining's rmse: 0.0854477\tvalid_1's rmse: 0.0813046\n",
      "[175]\ttraining's rmse: 0.0853636\tvalid_1's rmse: 0.0812736\n",
      "[200]\ttraining's rmse: 0.0852738\tvalid_1's rmse: 0.0812414\n",
      "[225]\ttraining's rmse: 0.0851882\tvalid_1's rmse: 0.0812101\n",
      "[250]\ttraining's rmse: 0.0851165\tvalid_1's rmse: 0.0811848\n",
      "[275]\ttraining's rmse: 0.0850507\tvalid_1's rmse: 0.0811604\n",
      "[300]\ttraining's rmse: 0.0849833\tvalid_1's rmse: 0.081142\n",
      "[325]\ttraining's rmse: 0.084916\tvalid_1's rmse: 0.0811202\n",
      "[350]\ttraining's rmse: 0.0848511\tvalid_1's rmse: 0.0810985\n",
      "[375]\ttraining's rmse: 0.0847963\tvalid_1's rmse: 0.0810798\n",
      "[400]\ttraining's rmse: 0.0847369\tvalid_1's rmse: 0.0810648\n",
      "[425]\ttraining's rmse: 0.0846842\tvalid_1's rmse: 0.0810517\n",
      "[450]\ttraining's rmse: 0.0846326\tvalid_1's rmse: 0.0810358\n",
      "[475]\ttraining's rmse: 0.0845857\tvalid_1's rmse: 0.081022\n",
      "[500]\ttraining's rmse: 0.0845476\tvalid_1's rmse: 0.0810093\n",
      "[525]\ttraining's rmse: 0.0844971\tvalid_1's rmse: 0.0809995\n",
      "[550]\ttraining's rmse: 0.0844498\tvalid_1's rmse: 0.0809869\n",
      "[575]\ttraining's rmse: 0.0844052\tvalid_1's rmse: 0.0809807\n",
      "[600]\ttraining's rmse: 0.0843625\tvalid_1's rmse: 0.0809787\n",
      "[625]\ttraining's rmse: 0.084328\tvalid_1's rmse: 0.0809697\n",
      "[650]\ttraining's rmse: 0.0842858\tvalid_1's rmse: 0.0809646\n",
      "[675]\ttraining's rmse: 0.0842423\tvalid_1's rmse: 0.080963\n",
      "[700]\ttraining's rmse: 0.0842047\tvalid_1's rmse: 0.0809546\n",
      "[725]\ttraining's rmse: 0.0841683\tvalid_1's rmse: 0.0809481\n",
      "[750]\ttraining's rmse: 0.0841347\tvalid_1's rmse: 0.0809525\n",
      "[775]\ttraining's rmse: 0.0841068\tvalid_1's rmse: 0.0809463\n",
      "[800]\ttraining's rmse: 0.0840711\tvalid_1's rmse: 0.0809399\n",
      "[825]\ttraining's rmse: 0.0840411\tvalid_1's rmse: 0.0809332\n",
      "[850]\ttraining's rmse: 0.0840113\tvalid_1's rmse: 0.080932\n",
      "[875]\ttraining's rmse: 0.0839839\tvalid_1's rmse: 0.0809339\n",
      "[900]\ttraining's rmse: 0.0839554\tvalid_1's rmse: 0.080936\n",
      "Early stopping, best iteration is:\n",
      "[873]\ttraining's rmse: 0.0839852\tvalid_1's rmse: 0.0809271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0871845\tvalid_1's rmse: 0.0890942\n",
      "[50]\ttraining's rmse: 0.0870381\tvalid_1's rmse: 0.0890423\n",
      "[75]\ttraining's rmse: 0.0868901\tvalid_1's rmse: 0.0889909\n",
      "[100]\ttraining's rmse: 0.0867529\tvalid_1's rmse: 0.0889458\n",
      "[125]\ttraining's rmse: 0.0866209\tvalid_1's rmse: 0.0888998\n",
      "[150]\ttraining's rmse: 0.0865\tvalid_1's rmse: 0.088857\n",
      "[175]\ttraining's rmse: 0.0863971\tvalid_1's rmse: 0.0888237\n",
      "[200]\ttraining's rmse: 0.0862835\tvalid_1's rmse: 0.0887861\n",
      "[225]\ttraining's rmse: 0.0861804\tvalid_1's rmse: 0.0887526\n",
      "[250]\ttraining's rmse: 0.0860917\tvalid_1's rmse: 0.0887202\n",
      "[275]\ttraining's rmse: 0.0860066\tvalid_1's rmse: 0.088693\n",
      "[300]\ttraining's rmse: 0.0859208\tvalid_1's rmse: 0.0886661\n",
      "[325]\ttraining's rmse: 0.0858403\tvalid_1's rmse: 0.0886409\n",
      "[350]\ttraining's rmse: 0.0857572\tvalid_1's rmse: 0.0886161\n",
      "[375]\ttraining's rmse: 0.0856866\tvalid_1's rmse: 0.0885955\n",
      "[400]\ttraining's rmse: 0.0856108\tvalid_1's rmse: 0.0885741\n",
      "[425]\ttraining's rmse: 0.0855439\tvalid_1's rmse: 0.0885527\n",
      "[450]\ttraining's rmse: 0.085484\tvalid_1's rmse: 0.0885324\n",
      "[475]\ttraining's rmse: 0.0854291\tvalid_1's rmse: 0.088516\n",
      "[500]\ttraining's rmse: 0.0853799\tvalid_1's rmse: 0.0884999\n",
      "[525]\ttraining's rmse: 0.0853201\tvalid_1's rmse: 0.0884846\n",
      "[550]\ttraining's rmse: 0.0852657\tvalid_1's rmse: 0.0884697\n",
      "[575]\ttraining's rmse: 0.0852151\tvalid_1's rmse: 0.0884571\n",
      "[600]\ttraining's rmse: 0.0851663\tvalid_1's rmse: 0.0884439\n",
      "[625]\ttraining's rmse: 0.0851264\tvalid_1's rmse: 0.0884308\n",
      "[650]\ttraining's rmse: 0.0850781\tvalid_1's rmse: 0.0884188\n",
      "[675]\ttraining's rmse: 0.0850266\tvalid_1's rmse: 0.0884065\n",
      "[700]\ttraining's rmse: 0.0849847\tvalid_1's rmse: 0.088396\n",
      "[725]\ttraining's rmse: 0.0849454\tvalid_1's rmse: 0.0883857\n",
      "[750]\ttraining's rmse: 0.0849073\tvalid_1's rmse: 0.0883754\n",
      "[775]\ttraining's rmse: 0.0848768\tvalid_1's rmse: 0.0883648\n",
      "[800]\ttraining's rmse: 0.084836\tvalid_1's rmse: 0.0883548\n",
      "[825]\ttraining's rmse: 0.0848048\tvalid_1's rmse: 0.0883464\n",
      "[850]\ttraining's rmse: 0.0847681\tvalid_1's rmse: 0.08834\n",
      "[875]\ttraining's rmse: 0.0847387\tvalid_1's rmse: 0.0883316\n",
      "[900]\ttraining's rmse: 0.0847065\tvalid_1's rmse: 0.088324\n",
      "[925]\ttraining's rmse: 0.0846781\tvalid_1's rmse: 0.0883178\n",
      "[950]\ttraining's rmse: 0.0846491\tvalid_1's rmse: 0.088311\n",
      "[975]\ttraining's rmse: 0.0846213\tvalid_1's rmse: 0.088304\n",
      "[1000]\ttraining's rmse: 0.0845949\tvalid_1's rmse: 0.0882979\n",
      "[1025]\ttraining's rmse: 0.0845697\tvalid_1's rmse: 0.0882923\n",
      "[1050]\ttraining's rmse: 0.0845435\tvalid_1's rmse: 0.0882863\n",
      "[1075]\ttraining's rmse: 0.0845187\tvalid_1's rmse: 0.088281\n",
      "[1100]\ttraining's rmse: 0.0844973\tvalid_1's rmse: 0.0882752\n",
      "[1125]\ttraining's rmse: 0.0844758\tvalid_1's rmse: 0.0882702\n",
      "[1150]\ttraining's rmse: 0.0844554\tvalid_1's rmse: 0.0882661\n",
      "[1175]\ttraining's rmse: 0.0844367\tvalid_1's rmse: 0.0882628\n",
      "[1200]\ttraining's rmse: 0.084421\tvalid_1's rmse: 0.0882583\n",
      "[1225]\ttraining's rmse: 0.0844017\tvalid_1's rmse: 0.0882536\n",
      "[1250]\ttraining's rmse: 0.0843844\tvalid_1's rmse: 0.0882504\n",
      "[1275]\ttraining's rmse: 0.0843658\tvalid_1's rmse: 0.0882464\n",
      "[1300]\ttraining's rmse: 0.0843536\tvalid_1's rmse: 0.0882425\n",
      "[1325]\ttraining's rmse: 0.0843368\tvalid_1's rmse: 0.088238\n",
      "[1350]\ttraining's rmse: 0.0843218\tvalid_1's rmse: 0.0882343\n",
      "[1375]\ttraining's rmse: 0.0843062\tvalid_1's rmse: 0.0882306\n",
      "[1400]\ttraining's rmse: 0.0842935\tvalid_1's rmse: 0.0882251\n",
      "[1425]\ttraining's rmse: 0.0842793\tvalid_1's rmse: 0.0882224\n",
      "[1450]\ttraining's rmse: 0.0842664\tvalid_1's rmse: 0.0882189\n",
      "[1475]\ttraining's rmse: 0.0842552\tvalid_1's rmse: 0.0882163\n",
      "[1500]\ttraining's rmse: 0.0842456\tvalid_1's rmse: 0.0882141\n",
      "[1525]\ttraining's rmse: 0.0842351\tvalid_1's rmse: 0.0882119\n",
      "[1550]\ttraining's rmse: 0.0842248\tvalid_1's rmse: 0.0882092\n",
      "[1575]\ttraining's rmse: 0.0842148\tvalid_1's rmse: 0.0882068\n",
      "[1600]\ttraining's rmse: 0.0842048\tvalid_1's rmse: 0.0882039\n",
      "[1625]\ttraining's rmse: 0.0841962\tvalid_1's rmse: 0.0882018\n",
      "[1650]\ttraining's rmse: 0.0841879\tvalid_1's rmse: 0.0881991\n",
      "[1675]\ttraining's rmse: 0.0841826\tvalid_1's rmse: 0.088196\n",
      "[1700]\ttraining's rmse: 0.0841759\tvalid_1's rmse: 0.0881935\n",
      "[1725]\ttraining's rmse: 0.084169\tvalid_1's rmse: 0.0881919\n",
      "[1750]\ttraining's rmse: 0.0841627\tvalid_1's rmse: 0.0881908\n",
      "[1775]\ttraining's rmse: 0.0841552\tvalid_1's rmse: 0.088189\n",
      "[1800]\ttraining's rmse: 0.0841484\tvalid_1's rmse: 0.0881881\n",
      "[1825]\ttraining's rmse: 0.0841418\tvalid_1's rmse: 0.088186\n",
      "[1850]\ttraining's rmse: 0.0841358\tvalid_1's rmse: 0.088184\n",
      "[1875]\ttraining's rmse: 0.0841297\tvalid_1's rmse: 0.0881818\n",
      "[1900]\ttraining's rmse: 0.0841247\tvalid_1's rmse: 0.0881803\n",
      "[1925]\ttraining's rmse: 0.0841173\tvalid_1's rmse: 0.0881783\n",
      "[1950]\ttraining's rmse: 0.0841136\tvalid_1's rmse: 0.0881768\n",
      "[1975]\ttraining's rmse: 0.0841094\tvalid_1's rmse: 0.0881756\n",
      "[2000]\ttraining's rmse: 0.0841034\tvalid_1's rmse: 0.0881743\n",
      "[2025]\ttraining's rmse: 0.0840996\tvalid_1's rmse: 0.0881722\n",
      "[2050]\ttraining's rmse: 0.0840959\tvalid_1's rmse: 0.0881714\n",
      "[2075]\ttraining's rmse: 0.0840935\tvalid_1's rmse: 0.0881701\n",
      "[2100]\ttraining's rmse: 0.08409\tvalid_1's rmse: 0.088169\n",
      "[2125]\ttraining's rmse: 0.0840869\tvalid_1's rmse: 0.0881678\n",
      "[2150]\ttraining's rmse: 0.0840815\tvalid_1's rmse: 0.0881673\n",
      "[2175]\ttraining's rmse: 0.0840768\tvalid_1's rmse: 0.088167\n",
      "[2200]\ttraining's rmse: 0.0840731\tvalid_1's rmse: 0.0881656\n",
      "[2225]\ttraining's rmse: 0.0840702\tvalid_1's rmse: 0.088164\n",
      "[2250]\ttraining's rmse: 0.084067\tvalid_1's rmse: 0.0881628\n",
      "[2275]\ttraining's rmse: 0.0840618\tvalid_1's rmse: 0.088162\n",
      "[2300]\ttraining's rmse: 0.0840593\tvalid_1's rmse: 0.0881604\n",
      "[2325]\ttraining's rmse: 0.0840556\tvalid_1's rmse: 0.0881589\n",
      "[2350]\ttraining's rmse: 0.084054\tvalid_1's rmse: 0.0881583\n",
      "[2375]\ttraining's rmse: 0.0840514\tvalid_1's rmse: 0.088158\n",
      "[2400]\ttraining's rmse: 0.0840485\tvalid_1's rmse: 0.088157\n",
      "[2425]\ttraining's rmse: 0.0840452\tvalid_1's rmse: 0.0881562\n",
      "[2450]\ttraining's rmse: 0.084043\tvalid_1's rmse: 0.0881553\n",
      "[2475]\ttraining's rmse: 0.0840393\tvalid_1's rmse: 0.0881548\n",
      "[2500]\ttraining's rmse: 0.0840362\tvalid_1's rmse: 0.0881539\n",
      "[2525]\ttraining's rmse: 0.0840334\tvalid_1's rmse: 0.0881526\n",
      "[2550]\ttraining's rmse: 0.0840306\tvalid_1's rmse: 0.0881524\n",
      "[2575]\ttraining's rmse: 0.0840281\tvalid_1's rmse: 0.0881521\n",
      "[2600]\ttraining's rmse: 0.0840258\tvalid_1's rmse: 0.0881516\n",
      "[2625]\ttraining's rmse: 0.0840233\tvalid_1's rmse: 0.0881502\n",
      "[2650]\ttraining's rmse: 0.0840213\tvalid_1's rmse: 0.0881495\n",
      "[2675]\ttraining's rmse: 0.0840193\tvalid_1's rmse: 0.0881489\n",
      "[2700]\ttraining's rmse: 0.0840173\tvalid_1's rmse: 0.0881487\n",
      "[2725]\ttraining's rmse: 0.0840147\tvalid_1's rmse: 0.0881483\n",
      "[2750]\ttraining's rmse: 0.0840132\tvalid_1's rmse: 0.0881481\n",
      "[2775]\ttraining's rmse: 0.0840109\tvalid_1's rmse: 0.0881484\n",
      "Early stopping, best iteration is:\n",
      "[2742]\ttraining's rmse: 0.0840134\tvalid_1's rmse: 0.088148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0870507\tvalid_1's rmse: 0.089397\n",
      "[50]\ttraining's rmse: 0.0869239\tvalid_1's rmse: 0.0893432\n",
      "[75]\ttraining's rmse: 0.086791\tvalid_1's rmse: 0.0892897\n",
      "[100]\ttraining's rmse: 0.0866713\tvalid_1's rmse: 0.0892407\n",
      "[125]\ttraining's rmse: 0.0865488\tvalid_1's rmse: 0.0891929\n",
      "[150]\ttraining's rmse: 0.0864365\tvalid_1's rmse: 0.0891474\n",
      "[175]\ttraining's rmse: 0.0863442\tvalid_1's rmse: 0.0891116\n",
      "[200]\ttraining's rmse: 0.0862409\tvalid_1's rmse: 0.0890728\n",
      "[225]\ttraining's rmse: 0.0861427\tvalid_1's rmse: 0.0890377\n",
      "[250]\ttraining's rmse: 0.0860586\tvalid_1's rmse: 0.0890063\n",
      "[275]\ttraining's rmse: 0.0859829\tvalid_1's rmse: 0.0889781\n",
      "[300]\ttraining's rmse: 0.0859085\tvalid_1's rmse: 0.0889516\n",
      "[325]\ttraining's rmse: 0.0858325\tvalid_1's rmse: 0.0889251\n",
      "[350]\ttraining's rmse: 0.08576\tvalid_1's rmse: 0.0889004\n",
      "[375]\ttraining's rmse: 0.0856986\tvalid_1's rmse: 0.088879\n",
      "[400]\ttraining's rmse: 0.0856328\tvalid_1's rmse: 0.0888577\n",
      "[425]\ttraining's rmse: 0.08557\tvalid_1's rmse: 0.0888365\n",
      "[450]\ttraining's rmse: 0.0855134\tvalid_1's rmse: 0.0888174\n",
      "[475]\ttraining's rmse: 0.0854625\tvalid_1's rmse: 0.0888002\n",
      "[500]\ttraining's rmse: 0.085416\tvalid_1's rmse: 0.0887832\n",
      "[525]\ttraining's rmse: 0.0853594\tvalid_1's rmse: 0.0887667\n",
      "[550]\ttraining's rmse: 0.085307\tvalid_1's rmse: 0.088752\n",
      "[575]\ttraining's rmse: 0.0852567\tvalid_1's rmse: 0.0887387\n",
      "[600]\ttraining's rmse: 0.085209\tvalid_1's rmse: 0.0887257\n",
      "[625]\ttraining's rmse: 0.0851711\tvalid_1's rmse: 0.0887131\n",
      "[650]\ttraining's rmse: 0.0851247\tvalid_1's rmse: 0.0887012\n",
      "[675]\ttraining's rmse: 0.0850797\tvalid_1's rmse: 0.0886903\n",
      "[700]\ttraining's rmse: 0.0850393\tvalid_1's rmse: 0.0886793\n",
      "[725]\ttraining's rmse: 0.085002\tvalid_1's rmse: 0.0886695\n",
      "[750]\ttraining's rmse: 0.084966\tvalid_1's rmse: 0.0886611\n",
      "[775]\ttraining's rmse: 0.0849358\tvalid_1's rmse: 0.0886522\n",
      "[800]\ttraining's rmse: 0.0848977\tvalid_1's rmse: 0.0886437\n",
      "[825]\ttraining's rmse: 0.0848671\tvalid_1's rmse: 0.0886354\n",
      "[850]\ttraining's rmse: 0.0848347\tvalid_1's rmse: 0.0886287\n",
      "[875]\ttraining's rmse: 0.0848059\tvalid_1's rmse: 0.0886225\n",
      "[900]\ttraining's rmse: 0.0847761\tvalid_1's rmse: 0.0886151\n",
      "[925]\ttraining's rmse: 0.0847451\tvalid_1's rmse: 0.0886084\n",
      "[950]\ttraining's rmse: 0.0847183\tvalid_1's rmse: 0.0886025\n",
      "[975]\ttraining's rmse: 0.0846917\tvalid_1's rmse: 0.0885969\n",
      "[1000]\ttraining's rmse: 0.0846671\tvalid_1's rmse: 0.0885918\n",
      "[1025]\ttraining's rmse: 0.0846399\tvalid_1's rmse: 0.0885882\n",
      "[1050]\ttraining's rmse: 0.0846166\tvalid_1's rmse: 0.0885832\n",
      "[1075]\ttraining's rmse: 0.084592\tvalid_1's rmse: 0.0885794\n",
      "[1100]\ttraining's rmse: 0.0845736\tvalid_1's rmse: 0.088575\n",
      "[1125]\ttraining's rmse: 0.0845521\tvalid_1's rmse: 0.0885711\n",
      "[1150]\ttraining's rmse: 0.0845298\tvalid_1's rmse: 0.0885666\n",
      "[1175]\ttraining's rmse: 0.0845128\tvalid_1's rmse: 0.088564\n",
      "[1200]\ttraining's rmse: 0.0844919\tvalid_1's rmse: 0.0885609\n",
      "[1225]\ttraining's rmse: 0.084473\tvalid_1's rmse: 0.0885578\n",
      "[1250]\ttraining's rmse: 0.0844575\tvalid_1's rmse: 0.0885543\n",
      "[1275]\ttraining's rmse: 0.0844412\tvalid_1's rmse: 0.0885524\n",
      "[1300]\ttraining's rmse: 0.0844275\tvalid_1's rmse: 0.0885498\n",
      "[1325]\ttraining's rmse: 0.0844098\tvalid_1's rmse: 0.088548\n",
      "[1350]\ttraining's rmse: 0.0843954\tvalid_1's rmse: 0.0885468\n",
      "[1375]\ttraining's rmse: 0.0843825\tvalid_1's rmse: 0.0885447\n",
      "[1400]\ttraining's rmse: 0.0843713\tvalid_1's rmse: 0.0885418\n",
      "[1425]\ttraining's rmse: 0.0843559\tvalid_1's rmse: 0.0885395\n",
      "[1450]\ttraining's rmse: 0.0843428\tvalid_1's rmse: 0.088538\n",
      "[1475]\ttraining's rmse: 0.0843287\tvalid_1's rmse: 0.0885368\n",
      "[1500]\ttraining's rmse: 0.0843183\tvalid_1's rmse: 0.0885349\n",
      "[1525]\ttraining's rmse: 0.0843068\tvalid_1's rmse: 0.0885337\n",
      "[1550]\ttraining's rmse: 0.0842934\tvalid_1's rmse: 0.0885332\n",
      "[1575]\ttraining's rmse: 0.0842834\tvalid_1's rmse: 0.0885323\n",
      "[1600]\ttraining's rmse: 0.0842759\tvalid_1's rmse: 0.088532\n",
      "[1625]\ttraining's rmse: 0.0842685\tvalid_1's rmse: 0.0885307\n",
      "[1650]\ttraining's rmse: 0.084259\tvalid_1's rmse: 0.08853\n",
      "[1675]\ttraining's rmse: 0.0842539\tvalid_1's rmse: 0.0885291\n",
      "[1700]\ttraining's rmse: 0.0842457\tvalid_1's rmse: 0.0885278\n",
      "[1725]\ttraining's rmse: 0.0842373\tvalid_1's rmse: 0.0885264\n",
      "[1750]\ttraining's rmse: 0.084227\tvalid_1's rmse: 0.0885258\n",
      "[1775]\ttraining's rmse: 0.08422\tvalid_1's rmse: 0.0885253\n",
      "[1800]\ttraining's rmse: 0.0842142\tvalid_1's rmse: 0.0885246\n",
      "[1825]\ttraining's rmse: 0.0842062\tvalid_1's rmse: 0.0885236\n",
      "[1850]\ttraining's rmse: 0.0842012\tvalid_1's rmse: 0.0885227\n",
      "[1875]\ttraining's rmse: 0.0841965\tvalid_1's rmse: 0.0885217\n",
      "[1900]\ttraining's rmse: 0.0841915\tvalid_1's rmse: 0.0885217\n",
      "[1925]\ttraining's rmse: 0.084186\tvalid_1's rmse: 0.0885212\n",
      "[1950]\ttraining's rmse: 0.084182\tvalid_1's rmse: 0.0885203\n",
      "[1975]\ttraining's rmse: 0.0841769\tvalid_1's rmse: 0.08852\n",
      "[2000]\ttraining's rmse: 0.0841723\tvalid_1's rmse: 0.0885196\n",
      "[2025]\ttraining's rmse: 0.0841686\tvalid_1's rmse: 0.0885191\n",
      "[2050]\ttraining's rmse: 0.0841629\tvalid_1's rmse: 0.0885184\n",
      "[2075]\ttraining's rmse: 0.0841589\tvalid_1's rmse: 0.0885178\n",
      "[2100]\ttraining's rmse: 0.0841559\tvalid_1's rmse: 0.0885179\n",
      "[2125]\ttraining's rmse: 0.0841525\tvalid_1's rmse: 0.0885177\n",
      "[2150]\ttraining's rmse: 0.0841485\tvalid_1's rmse: 0.0885173\n",
      "[2175]\ttraining's rmse: 0.0841453\tvalid_1's rmse: 0.088517\n",
      "[2200]\ttraining's rmse: 0.0841424\tvalid_1's rmse: 0.0885167\n",
      "[2225]\ttraining's rmse: 0.0841403\tvalid_1's rmse: 0.0885166\n",
      "[2250]\ttraining's rmse: 0.084137\tvalid_1's rmse: 0.0885162\n",
      "[2275]\ttraining's rmse: 0.084133\tvalid_1's rmse: 0.0885159\n",
      "[2300]\ttraining's rmse: 0.0841286\tvalid_1's rmse: 0.0885156\n",
      "[2325]\ttraining's rmse: 0.0841263\tvalid_1's rmse: 0.0885156\n",
      "[2350]\ttraining's rmse: 0.0841225\tvalid_1's rmse: 0.0885153\n",
      "[2375]\ttraining's rmse: 0.0841193\tvalid_1's rmse: 0.0885147\n",
      "[2400]\ttraining's rmse: 0.0841152\tvalid_1's rmse: 0.0885147\n",
      "[2425]\ttraining's rmse: 0.0841122\tvalid_1's rmse: 0.0885146\n",
      "[2450]\ttraining's rmse: 0.0841094\tvalid_1's rmse: 0.0885145\n",
      "[2475]\ttraining's rmse: 0.0841067\tvalid_1's rmse: 0.0885143\n",
      "[2500]\ttraining's rmse: 0.0841049\tvalid_1's rmse: 0.0885139\n",
      "[2525]\ttraining's rmse: 0.0841015\tvalid_1's rmse: 0.0885137\n",
      "[2550]\ttraining's rmse: 0.0840993\tvalid_1's rmse: 0.088514\n",
      "Early stopping, best iteration is:\n",
      "[2512]\ttraining's rmse: 0.0841037\tvalid_1's rmse: 0.0885136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0891058\tvalid_1's rmse: 0.0852111\n",
      "[50]\ttraining's rmse: 0.0889843\tvalid_1's rmse: 0.0851642\n",
      "[75]\ttraining's rmse: 0.0888515\tvalid_1's rmse: 0.0851142\n",
      "[100]\ttraining's rmse: 0.0887345\tvalid_1's rmse: 0.085072\n",
      "[125]\ttraining's rmse: 0.0886132\tvalid_1's rmse: 0.0850298\n",
      "[150]\ttraining's rmse: 0.0885008\tvalid_1's rmse: 0.0849924\n",
      "[175]\ttraining's rmse: 0.0884096\tvalid_1's rmse: 0.0849601\n",
      "[200]\ttraining's rmse: 0.0883059\tvalid_1's rmse: 0.084927\n",
      "[225]\ttraining's rmse: 0.0882072\tvalid_1's rmse: 0.0848954\n",
      "[250]\ttraining's rmse: 0.088124\tvalid_1's rmse: 0.0848673\n",
      "[275]\ttraining's rmse: 0.0880468\tvalid_1's rmse: 0.0848438\n",
      "[300]\ttraining's rmse: 0.0879698\tvalid_1's rmse: 0.0848208\n",
      "[325]\ttraining's rmse: 0.0878923\tvalid_1's rmse: 0.0847995\n",
      "[350]\ttraining's rmse: 0.0878184\tvalid_1's rmse: 0.0847787\n",
      "[375]\ttraining's rmse: 0.0877572\tvalid_1's rmse: 0.0847613\n",
      "[400]\ttraining's rmse: 0.0876906\tvalid_1's rmse: 0.0847471\n",
      "[425]\ttraining's rmse: 0.0876308\tvalid_1's rmse: 0.0847344\n",
      "[450]\ttraining's rmse: 0.0875743\tvalid_1's rmse: 0.0847186\n",
      "[475]\ttraining's rmse: 0.0875215\tvalid_1's rmse: 0.0847091\n",
      "[500]\ttraining's rmse: 0.0874758\tvalid_1's rmse: 0.0846959\n",
      "[525]\ttraining's rmse: 0.0874181\tvalid_1's rmse: 0.0846831\n",
      "[550]\ttraining's rmse: 0.087364\tvalid_1's rmse: 0.0846718\n",
      "[575]\ttraining's rmse: 0.0873136\tvalid_1's rmse: 0.0846614\n",
      "[600]\ttraining's rmse: 0.087265\tvalid_1's rmse: 0.0846521\n",
      "[625]\ttraining's rmse: 0.0872258\tvalid_1's rmse: 0.0846474\n",
      "[650]\ttraining's rmse: 0.087178\tvalid_1's rmse: 0.0846397\n",
      "[675]\ttraining's rmse: 0.0871297\tvalid_1's rmse: 0.0846314\n",
      "[700]\ttraining's rmse: 0.0870892\tvalid_1's rmse: 0.0846231\n",
      "[725]\ttraining's rmse: 0.0870495\tvalid_1's rmse: 0.0846265\n",
      "[750]\ttraining's rmse: 0.0870118\tvalid_1's rmse: 0.0846243\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 0.0870736\tvalid_1's rmse: 0.0846203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0841253\tvalid_1's rmse: 0.0868056\n",
      "[50]\ttraining's rmse: 0.083996\tvalid_1's rmse: 0.0867536\n",
      "[75]\ttraining's rmse: 0.0838633\tvalid_1's rmse: 0.0867005\n",
      "[100]\ttraining's rmse: 0.0837417\tvalid_1's rmse: 0.086655\n",
      "[125]\ttraining's rmse: 0.0836209\tvalid_1's rmse: 0.0866062\n",
      "[150]\ttraining's rmse: 0.0835116\tvalid_1's rmse: 0.0865631\n",
      "[175]\ttraining's rmse: 0.0834203\tvalid_1's rmse: 0.0865266\n",
      "[200]\ttraining's rmse: 0.0833234\tvalid_1's rmse: 0.0864893\n",
      "[225]\ttraining's rmse: 0.0832266\tvalid_1's rmse: 0.0864527\n",
      "[250]\ttraining's rmse: 0.0831458\tvalid_1's rmse: 0.0864213\n",
      "[275]\ttraining's rmse: 0.0830676\tvalid_1's rmse: 0.0863926\n",
      "[300]\ttraining's rmse: 0.0829942\tvalid_1's rmse: 0.0863649\n",
      "[325]\ttraining's rmse: 0.0829169\tvalid_1's rmse: 0.0863389\n",
      "[350]\ttraining's rmse: 0.0828475\tvalid_1's rmse: 0.0863136\n",
      "[375]\ttraining's rmse: 0.0827857\tvalid_1's rmse: 0.086293\n",
      "[400]\ttraining's rmse: 0.0827208\tvalid_1's rmse: 0.0862721\n",
      "[425]\ttraining's rmse: 0.0826647\tvalid_1's rmse: 0.0862521\n",
      "[450]\ttraining's rmse: 0.0826105\tvalid_1's rmse: 0.0862322\n",
      "[475]\ttraining's rmse: 0.0825617\tvalid_1's rmse: 0.0862132\n",
      "[500]\ttraining's rmse: 0.0825178\tvalid_1's rmse: 0.0861969\n",
      "[525]\ttraining's rmse: 0.0824676\tvalid_1's rmse: 0.0861806\n",
      "[550]\ttraining's rmse: 0.0824201\tvalid_1's rmse: 0.0861653\n",
      "[575]\ttraining's rmse: 0.0823726\tvalid_1's rmse: 0.0861512\n",
      "[600]\ttraining's rmse: 0.0823324\tvalid_1's rmse: 0.0861383\n",
      "[625]\ttraining's rmse: 0.0822968\tvalid_1's rmse: 0.0861248\n",
      "[650]\ttraining's rmse: 0.0822571\tvalid_1's rmse: 0.0861122\n",
      "[675]\ttraining's rmse: 0.0822145\tvalid_1's rmse: 0.0861003\n",
      "[700]\ttraining's rmse: 0.0821763\tvalid_1's rmse: 0.0860887\n",
      "[725]\ttraining's rmse: 0.0821405\tvalid_1's rmse: 0.0860787\n",
      "[750]\ttraining's rmse: 0.0821074\tvalid_1's rmse: 0.0860696\n",
      "[775]\ttraining's rmse: 0.0820817\tvalid_1's rmse: 0.0860591\n",
      "[800]\ttraining's rmse: 0.0820462\tvalid_1's rmse: 0.0860505\n",
      "[825]\ttraining's rmse: 0.0820166\tvalid_1's rmse: 0.0860412\n",
      "[850]\ttraining's rmse: 0.0819823\tvalid_1's rmse: 0.0860336\n",
      "[875]\ttraining's rmse: 0.0819555\tvalid_1's rmse: 0.0860255\n",
      "[900]\ttraining's rmse: 0.0819246\tvalid_1's rmse: 0.0860177\n",
      "[925]\ttraining's rmse: 0.0818979\tvalid_1's rmse: 0.0860096\n",
      "[950]\ttraining's rmse: 0.0818718\tvalid_1's rmse: 0.0860009\n",
      "[975]\ttraining's rmse: 0.0818488\tvalid_1's rmse: 0.0859962\n",
      "[1000]\ttraining's rmse: 0.0818281\tvalid_1's rmse: 0.0859906\n",
      "[1025]\ttraining's rmse: 0.0818038\tvalid_1's rmse: 0.0859848\n",
      "[1050]\ttraining's rmse: 0.0817821\tvalid_1's rmse: 0.0859784\n",
      "[1075]\ttraining's rmse: 0.0817623\tvalid_1's rmse: 0.0859736\n",
      "[1100]\ttraining's rmse: 0.0817456\tvalid_1's rmse: 0.0859664\n",
      "[1125]\ttraining's rmse: 0.0817295\tvalid_1's rmse: 0.0859603\n",
      "[1150]\ttraining's rmse: 0.0817082\tvalid_1's rmse: 0.0859558\n",
      "[1175]\ttraining's rmse: 0.0816936\tvalid_1's rmse: 0.0859517\n",
      "[1200]\ttraining's rmse: 0.0816773\tvalid_1's rmse: 0.0859468\n",
      "[1225]\ttraining's rmse: 0.0816645\tvalid_1's rmse: 0.0859432\n",
      "[1250]\ttraining's rmse: 0.0816521\tvalid_1's rmse: 0.0859396\n",
      "[1275]\ttraining's rmse: 0.0816345\tvalid_1's rmse: 0.0859355\n",
      "[1300]\ttraining's rmse: 0.0816225\tvalid_1's rmse: 0.0859326\n",
      "[1325]\ttraining's rmse: 0.0816082\tvalid_1's rmse: 0.08593\n",
      "[1350]\ttraining's rmse: 0.0815947\tvalid_1's rmse: 0.0859276\n",
      "[1375]\ttraining's rmse: 0.0815847\tvalid_1's rmse: 0.0859242\n",
      "[1400]\ttraining's rmse: 0.0815724\tvalid_1's rmse: 0.0859217\n",
      "[1425]\ttraining's rmse: 0.0815593\tvalid_1's rmse: 0.0859186\n",
      "[1450]\ttraining's rmse: 0.0815462\tvalid_1's rmse: 0.0859153\n",
      "[1475]\ttraining's rmse: 0.0815367\tvalid_1's rmse: 0.0859122\n",
      "[1500]\ttraining's rmse: 0.0815279\tvalid_1's rmse: 0.085909\n",
      "[1525]\ttraining's rmse: 0.0815193\tvalid_1's rmse: 0.0859058\n",
      "[1550]\ttraining's rmse: 0.0815077\tvalid_1's rmse: 0.0859031\n",
      "[1575]\ttraining's rmse: 0.0815006\tvalid_1's rmse: 0.085901\n",
      "[1600]\ttraining's rmse: 0.0814925\tvalid_1's rmse: 0.0858998\n",
      "[1625]\ttraining's rmse: 0.0814869\tvalid_1's rmse: 0.0858974\n",
      "[1650]\ttraining's rmse: 0.0814794\tvalid_1's rmse: 0.0858932\n",
      "[1675]\ttraining's rmse: 0.0814728\tvalid_1's rmse: 0.0858905\n",
      "[1700]\ttraining's rmse: 0.0814672\tvalid_1's rmse: 0.0858879\n",
      "[1725]\ttraining's rmse: 0.0814593\tvalid_1's rmse: 0.085887\n",
      "[1750]\ttraining's rmse: 0.0814506\tvalid_1's rmse: 0.0858857\n",
      "[1775]\ttraining's rmse: 0.0814429\tvalid_1's rmse: 0.0858848\n",
      "[1800]\ttraining's rmse: 0.0814365\tvalid_1's rmse: 0.0858832\n",
      "[1825]\ttraining's rmse: 0.0814304\tvalid_1's rmse: 0.0858819\n",
      "[1850]\ttraining's rmse: 0.0814249\tvalid_1's rmse: 0.0858804\n",
      "[1875]\ttraining's rmse: 0.0814184\tvalid_1's rmse: 0.0858797\n",
      "[1900]\ttraining's rmse: 0.0814143\tvalid_1's rmse: 0.0858784\n",
      "[1925]\ttraining's rmse: 0.0814096\tvalid_1's rmse: 0.0858778\n",
      "[1950]\ttraining's rmse: 0.0814061\tvalid_1's rmse: 0.0858753\n",
      "[1975]\ttraining's rmse: 0.0814032\tvalid_1's rmse: 0.0858737\n",
      "[2000]\ttraining's rmse: 0.0813992\tvalid_1's rmse: 0.0858726\n",
      "[2025]\ttraining's rmse: 0.0813945\tvalid_1's rmse: 0.0858699\n",
      "[2050]\ttraining's rmse: 0.0813897\tvalid_1's rmse: 0.0858679\n",
      "[2075]\ttraining's rmse: 0.0813859\tvalid_1's rmse: 0.0858673\n",
      "[2100]\ttraining's rmse: 0.0813828\tvalid_1's rmse: 0.0858665\n",
      "[2125]\ttraining's rmse: 0.0813801\tvalid_1's rmse: 0.0858661\n",
      "[2150]\ttraining's rmse: 0.0813758\tvalid_1's rmse: 0.0858656\n",
      "[2175]\ttraining's rmse: 0.0813737\tvalid_1's rmse: 0.0858652\n",
      "[2200]\ttraining's rmse: 0.0813707\tvalid_1's rmse: 0.0858642\n",
      "[2225]\ttraining's rmse: 0.0813683\tvalid_1's rmse: 0.0858629\n",
      "[2250]\ttraining's rmse: 0.0813654\tvalid_1's rmse: 0.0858623\n",
      "[2275]\ttraining's rmse: 0.081363\tvalid_1's rmse: 0.0858615\n",
      "[2300]\ttraining's rmse: 0.08136\tvalid_1's rmse: 0.0858601\n",
      "[2325]\ttraining's rmse: 0.0813561\tvalid_1's rmse: 0.0858591\n",
      "[2350]\ttraining's rmse: 0.0813538\tvalid_1's rmse: 0.0858587\n",
      "[2375]\ttraining's rmse: 0.0813517\tvalid_1's rmse: 0.085858\n",
      "[2400]\ttraining's rmse: 0.0813493\tvalid_1's rmse: 0.0858577\n",
      "[2425]\ttraining's rmse: 0.0813465\tvalid_1's rmse: 0.0858573\n",
      "[2450]\ttraining's rmse: 0.0813449\tvalid_1's rmse: 0.0858572\n",
      "[2475]\ttraining's rmse: 0.0813417\tvalid_1's rmse: 0.0858567\n",
      "[2500]\ttraining's rmse: 0.0813398\tvalid_1's rmse: 0.0858564\n",
      "[2525]\ttraining's rmse: 0.0813359\tvalid_1's rmse: 0.0858556\n",
      "[2550]\ttraining's rmse: 0.0813338\tvalid_1's rmse: 0.085855\n",
      "[2575]\ttraining's rmse: 0.0813314\tvalid_1's rmse: 0.0858535\n",
      "[2600]\ttraining's rmse: 0.0813288\tvalid_1's rmse: 0.085853\n",
      "[2625]\ttraining's rmse: 0.0813263\tvalid_1's rmse: 0.0858524\n",
      "[2650]\ttraining's rmse: 0.0813231\tvalid_1's rmse: 0.0858521\n",
      "[2675]\ttraining's rmse: 0.0813215\tvalid_1's rmse: 0.0858517\n",
      "[2700]\ttraining's rmse: 0.0813187\tvalid_1's rmse: 0.0858503\n",
      "[2725]\ttraining's rmse: 0.081317\tvalid_1's rmse: 0.0858501\n",
      "[2750]\ttraining's rmse: 0.0813148\tvalid_1's rmse: 0.0858495\n",
      "[2775]\ttraining's rmse: 0.0813127\tvalid_1's rmse: 0.0858493\n",
      "[2800]\ttraining's rmse: 0.0813113\tvalid_1's rmse: 0.0858491\n",
      "[2825]\ttraining's rmse: 0.08131\tvalid_1's rmse: 0.0858489\n",
      "[2850]\ttraining's rmse: 0.0813075\tvalid_1's rmse: 0.0858487\n",
      "[2875]\ttraining's rmse: 0.0813045\tvalid_1's rmse: 0.0858477\n",
      "[2900]\ttraining's rmse: 0.0813025\tvalid_1's rmse: 0.085847\n",
      "[2925]\ttraining's rmse: 0.0813019\tvalid_1's rmse: 0.085847\n",
      "[2950]\ttraining's rmse: 0.0812998\tvalid_1's rmse: 0.0858467\n",
      "[2975]\ttraining's rmse: 0.0812989\tvalid_1's rmse: 0.0858464\n",
      "[3000]\ttraining's rmse: 0.0812969\tvalid_1's rmse: 0.0858468\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0812969\tvalid_1's rmse: 0.0858468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0844247\tvalid_1's rmse: 0.0862279\n",
      "[50]\ttraining's rmse: 0.0843032\tvalid_1's rmse: 0.0861713\n",
      "[75]\ttraining's rmse: 0.084182\tvalid_1's rmse: 0.0861175\n",
      "[100]\ttraining's rmse: 0.0840726\tvalid_1's rmse: 0.0860701\n",
      "[125]\ttraining's rmse: 0.0839576\tvalid_1's rmse: 0.0860226\n",
      "[150]\ttraining's rmse: 0.083854\tvalid_1's rmse: 0.0859781\n",
      "[175]\ttraining's rmse: 0.0837656\tvalid_1's rmse: 0.0859419\n",
      "[200]\ttraining's rmse: 0.0836684\tvalid_1's rmse: 0.0859049\n",
      "[225]\ttraining's rmse: 0.0835792\tvalid_1's rmse: 0.0858694\n",
      "[250]\ttraining's rmse: 0.0835045\tvalid_1's rmse: 0.0858396\n",
      "[275]\ttraining's rmse: 0.0834322\tvalid_1's rmse: 0.0858104\n",
      "[300]\ttraining's rmse: 0.0833605\tvalid_1's rmse: 0.085783\n",
      "[325]\ttraining's rmse: 0.083285\tvalid_1's rmse: 0.0857557\n",
      "[350]\ttraining's rmse: 0.0832136\tvalid_1's rmse: 0.0857314\n",
      "[375]\ttraining's rmse: 0.083157\tvalid_1's rmse: 0.0857105\n",
      "[400]\ttraining's rmse: 0.0830972\tvalid_1's rmse: 0.0856906\n",
      "[425]\ttraining's rmse: 0.0830405\tvalid_1's rmse: 0.0856709\n",
      "[450]\ttraining's rmse: 0.0829875\tvalid_1's rmse: 0.0856533\n",
      "[475]\ttraining's rmse: 0.0829386\tvalid_1's rmse: 0.0856373\n",
      "[500]\ttraining's rmse: 0.0828949\tvalid_1's rmse: 0.0856217\n",
      "[525]\ttraining's rmse: 0.0828427\tvalid_1's rmse: 0.0856054\n",
      "[550]\ttraining's rmse: 0.0827913\tvalid_1's rmse: 0.0855905\n",
      "[575]\ttraining's rmse: 0.0827455\tvalid_1's rmse: 0.085577\n",
      "[600]\ttraining's rmse: 0.0826997\tvalid_1's rmse: 0.0855639\n",
      "[625]\ttraining's rmse: 0.0826642\tvalid_1's rmse: 0.0855518\n",
      "[650]\ttraining's rmse: 0.0826187\tvalid_1's rmse: 0.0855391\n",
      "[675]\ttraining's rmse: 0.0825749\tvalid_1's rmse: 0.0855271\n",
      "[700]\ttraining's rmse: 0.0825366\tvalid_1's rmse: 0.0855166\n",
      "[725]\ttraining's rmse: 0.0825008\tvalid_1's rmse: 0.0855066\n",
      "[750]\ttraining's rmse: 0.0824684\tvalid_1's rmse: 0.0854987\n",
      "[775]\ttraining's rmse: 0.0824403\tvalid_1's rmse: 0.0854906\n",
      "[800]\ttraining's rmse: 0.0824047\tvalid_1's rmse: 0.0854822\n",
      "[825]\ttraining's rmse: 0.0823739\tvalid_1's rmse: 0.0854733\n",
      "[850]\ttraining's rmse: 0.0823424\tvalid_1's rmse: 0.0854657\n",
      "[875]\ttraining's rmse: 0.0823164\tvalid_1's rmse: 0.0854585\n",
      "[900]\ttraining's rmse: 0.0822888\tvalid_1's rmse: 0.0854527\n",
      "[925]\ttraining's rmse: 0.0822613\tvalid_1's rmse: 0.0854462\n",
      "[950]\ttraining's rmse: 0.0822349\tvalid_1's rmse: 0.0854405\n",
      "[975]\ttraining's rmse: 0.0822131\tvalid_1's rmse: 0.0854352\n",
      "[1000]\ttraining's rmse: 0.0821909\tvalid_1's rmse: 0.08543\n",
      "[1025]\ttraining's rmse: 0.0821664\tvalid_1's rmse: 0.0854256\n",
      "[1050]\ttraining's rmse: 0.0821442\tvalid_1's rmse: 0.0854217\n",
      "[1075]\ttraining's rmse: 0.0821232\tvalid_1's rmse: 0.0854175\n",
      "[1100]\ttraining's rmse: 0.0821093\tvalid_1's rmse: 0.0854134\n",
      "[1125]\ttraining's rmse: 0.0820896\tvalid_1's rmse: 0.0854098\n",
      "[1150]\ttraining's rmse: 0.0820684\tvalid_1's rmse: 0.0854051\n",
      "[1175]\ttraining's rmse: 0.0820531\tvalid_1's rmse: 0.0854016\n",
      "[1200]\ttraining's rmse: 0.0820368\tvalid_1's rmse: 0.0853988\n",
      "[1225]\ttraining's rmse: 0.08202\tvalid_1's rmse: 0.0853963\n",
      "[1250]\ttraining's rmse: 0.0820057\tvalid_1's rmse: 0.085393\n",
      "[1275]\ttraining's rmse: 0.0819883\tvalid_1's rmse: 0.0853906\n",
      "[1300]\ttraining's rmse: 0.0819754\tvalid_1's rmse: 0.0853875\n",
      "[1325]\ttraining's rmse: 0.0819624\tvalid_1's rmse: 0.085385\n",
      "[1350]\ttraining's rmse: 0.0819483\tvalid_1's rmse: 0.085383\n",
      "[1375]\ttraining's rmse: 0.0819331\tvalid_1's rmse: 0.0853811\n",
      "[1400]\ttraining's rmse: 0.0819234\tvalid_1's rmse: 0.0853789\n",
      "[1425]\ttraining's rmse: 0.0819113\tvalid_1's rmse: 0.0853776\n",
      "[1450]\ttraining's rmse: 0.0818988\tvalid_1's rmse: 0.0853762\n",
      "[1475]\ttraining's rmse: 0.0818887\tvalid_1's rmse: 0.0853747\n",
      "[1500]\ttraining's rmse: 0.0818792\tvalid_1's rmse: 0.0853736\n",
      "[1525]\ttraining's rmse: 0.081869\tvalid_1's rmse: 0.0853725\n",
      "[1550]\ttraining's rmse: 0.0818596\tvalid_1's rmse: 0.0853721\n",
      "[1575]\ttraining's rmse: 0.0818513\tvalid_1's rmse: 0.0853708\n",
      "[1600]\ttraining's rmse: 0.081842\tvalid_1's rmse: 0.0853699\n",
      "[1625]\ttraining's rmse: 0.0818332\tvalid_1's rmse: 0.0853681\n",
      "[1650]\ttraining's rmse: 0.0818251\tvalid_1's rmse: 0.0853672\n",
      "[1675]\ttraining's rmse: 0.0818181\tvalid_1's rmse: 0.085366\n",
      "[1700]\ttraining's rmse: 0.0818123\tvalid_1's rmse: 0.0853654\n",
      "[1725]\ttraining's rmse: 0.0818031\tvalid_1's rmse: 0.085364\n",
      "[1750]\ttraining's rmse: 0.081795\tvalid_1's rmse: 0.0853631\n",
      "[1775]\ttraining's rmse: 0.0817878\tvalid_1's rmse: 0.0853628\n",
      "[1800]\ttraining's rmse: 0.0817816\tvalid_1's rmse: 0.0853621\n",
      "[1825]\ttraining's rmse: 0.0817732\tvalid_1's rmse: 0.085361\n",
      "[1850]\ttraining's rmse: 0.0817676\tvalid_1's rmse: 0.0853601\n",
      "[1875]\ttraining's rmse: 0.0817608\tvalid_1's rmse: 0.0853592\n",
      "[1900]\ttraining's rmse: 0.0817552\tvalid_1's rmse: 0.0853593\n",
      "[1925]\ttraining's rmse: 0.0817503\tvalid_1's rmse: 0.0853583\n",
      "[1950]\ttraining's rmse: 0.0817471\tvalid_1's rmse: 0.0853576\n",
      "[1975]\ttraining's rmse: 0.0817435\tvalid_1's rmse: 0.0853572\n",
      "[2000]\ttraining's rmse: 0.0817394\tvalid_1's rmse: 0.0853565\n",
      "[2025]\ttraining's rmse: 0.0817349\tvalid_1's rmse: 0.0853558\n",
      "[2050]\ttraining's rmse: 0.0817294\tvalid_1's rmse: 0.0853558\n",
      "[2075]\ttraining's rmse: 0.0817266\tvalid_1's rmse: 0.0853556\n",
      "[2100]\ttraining's rmse: 0.0817234\tvalid_1's rmse: 0.0853548\n",
      "[2125]\ttraining's rmse: 0.0817201\tvalid_1's rmse: 0.0853542\n",
      "[2150]\ttraining's rmse: 0.0817152\tvalid_1's rmse: 0.0853543\n",
      "[2175]\ttraining's rmse: 0.0817131\tvalid_1's rmse: 0.0853539\n",
      "[2200]\ttraining's rmse: 0.08171\tvalid_1's rmse: 0.0853537\n",
      "[2225]\ttraining's rmse: 0.0817067\tvalid_1's rmse: 0.0853535\n",
      "[2250]\ttraining's rmse: 0.0817042\tvalid_1's rmse: 0.0853531\n",
      "[2275]\ttraining's rmse: 0.0817006\tvalid_1's rmse: 0.085353\n",
      "[2300]\ttraining's rmse: 0.0816979\tvalid_1's rmse: 0.0853528\n",
      "[2325]\ttraining's rmse: 0.0816959\tvalid_1's rmse: 0.0853526\n",
      "[2350]\ttraining's rmse: 0.081693\tvalid_1's rmse: 0.0853526\n",
      "[2375]\ttraining's rmse: 0.0816895\tvalid_1's rmse: 0.0853523\n",
      "[2400]\ttraining's rmse: 0.0816864\tvalid_1's rmse: 0.0853521\n",
      "[2425]\ttraining's rmse: 0.0816835\tvalid_1's rmse: 0.0853523\n",
      "[2450]\ttraining's rmse: 0.0816809\tvalid_1's rmse: 0.0853519\n",
      "[2475]\ttraining's rmse: 0.0816786\tvalid_1's rmse: 0.0853521\n",
      "[2500]\ttraining's rmse: 0.0816764\tvalid_1's rmse: 0.0853519\n",
      "[2525]\ttraining's rmse: 0.0816739\tvalid_1's rmse: 0.0853516\n",
      "[2550]\ttraining's rmse: 0.0816717\tvalid_1's rmse: 0.0853516\n",
      "[2575]\ttraining's rmse: 0.081669\tvalid_1's rmse: 0.0853515\n",
      "[2600]\ttraining's rmse: 0.081667\tvalid_1's rmse: 0.0853511\n",
      "[2625]\ttraining's rmse: 0.081664\tvalid_1's rmse: 0.0853509\n",
      "[2650]\ttraining's rmse: 0.0816613\tvalid_1's rmse: 0.085351\n",
      "Early stopping, best iteration is:\n",
      "[2620]\ttraining's rmse: 0.081666\tvalid_1's rmse: 0.0853508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0863978\tvalid_1's rmse: 0.0822238\n",
      "[50]\ttraining's rmse: 0.0862828\tvalid_1's rmse: 0.0821752\n",
      "[75]\ttraining's rmse: 0.0861626\tvalid_1's rmse: 0.0821263\n",
      "[100]\ttraining's rmse: 0.0860545\tvalid_1's rmse: 0.0820826\n",
      "[125]\ttraining's rmse: 0.0859462\tvalid_1's rmse: 0.0820421\n",
      "[150]\ttraining's rmse: 0.0858453\tvalid_1's rmse: 0.0820036\n",
      "[175]\ttraining's rmse: 0.0857616\tvalid_1's rmse: 0.0819747\n",
      "[200]\ttraining's rmse: 0.0856734\tvalid_1's rmse: 0.081943\n",
      "[225]\ttraining's rmse: 0.0855847\tvalid_1's rmse: 0.081913\n",
      "[250]\ttraining's rmse: 0.0855108\tvalid_1's rmse: 0.0818861\n",
      "[275]\ttraining's rmse: 0.0854429\tvalid_1's rmse: 0.0818617\n",
      "[300]\ttraining's rmse: 0.085376\tvalid_1's rmse: 0.0818381\n",
      "[325]\ttraining's rmse: 0.0853075\tvalid_1's rmse: 0.0818154\n",
      "[350]\ttraining's rmse: 0.0852404\tvalid_1's rmse: 0.0817935\n",
      "[375]\ttraining's rmse: 0.0851858\tvalid_1's rmse: 0.0817742\n",
      "[400]\ttraining's rmse: 0.0851251\tvalid_1's rmse: 0.0817616\n",
      "[425]\ttraining's rmse: 0.0850683\tvalid_1's rmse: 0.0817482\n",
      "[450]\ttraining's rmse: 0.0850159\tvalid_1's rmse: 0.0817321\n",
      "[475]\ttraining's rmse: 0.0849684\tvalid_1's rmse: 0.0817181\n",
      "[500]\ttraining's rmse: 0.0849279\tvalid_1's rmse: 0.0817058\n",
      "[525]\ttraining's rmse: 0.0848779\tvalid_1's rmse: 0.0816976\n",
      "[550]\ttraining's rmse: 0.0848294\tvalid_1's rmse: 0.0816928\n",
      "[575]\ttraining's rmse: 0.0847871\tvalid_1's rmse: 0.0816821\n",
      "[600]\ttraining's rmse: 0.084742\tvalid_1's rmse: 0.0816721\n",
      "[625]\ttraining's rmse: 0.0847077\tvalid_1's rmse: 0.0816631\n",
      "[650]\ttraining's rmse: 0.0846662\tvalid_1's rmse: 0.0816561\n",
      "[675]\ttraining's rmse: 0.0846235\tvalid_1's rmse: 0.0816514\n",
      "[700]\ttraining's rmse: 0.0845871\tvalid_1's rmse: 0.0816435\n",
      "[725]\ttraining's rmse: 0.0845514\tvalid_1's rmse: 0.0816452\n",
      "[750]\ttraining's rmse: 0.0845183\tvalid_1's rmse: 0.0816542\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 0.0845727\tvalid_1's rmse: 0.0816409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0883078\tvalid_1's rmse: 0.0897885\n",
      "[50]\ttraining's rmse: 0.0881228\tvalid_1's rmse: 0.089738\n",
      "[75]\ttraining's rmse: 0.0879385\tvalid_1's rmse: 0.0896852\n",
      "[100]\ttraining's rmse: 0.0877716\tvalid_1's rmse: 0.0896382\n",
      "[125]\ttraining's rmse: 0.0876047\tvalid_1's rmse: 0.0895918\n",
      "[150]\ttraining's rmse: 0.0874527\tvalid_1's rmse: 0.0895508\n",
      "[175]\ttraining's rmse: 0.0873234\tvalid_1's rmse: 0.089513\n",
      "[200]\ttraining's rmse: 0.0871899\tvalid_1's rmse: 0.0894773\n",
      "[225]\ttraining's rmse: 0.0870617\tvalid_1's rmse: 0.0894428\n",
      "[250]\ttraining's rmse: 0.0869518\tvalid_1's rmse: 0.0894107\n",
      "[275]\ttraining's rmse: 0.0868469\tvalid_1's rmse: 0.0893818\n",
      "[300]\ttraining's rmse: 0.0867486\tvalid_1's rmse: 0.0893517\n",
      "[325]\ttraining's rmse: 0.0866487\tvalid_1's rmse: 0.0893274\n",
      "[350]\ttraining's rmse: 0.0865557\tvalid_1's rmse: 0.0893029\n",
      "[375]\ttraining's rmse: 0.0864741\tvalid_1's rmse: 0.0892828\n",
      "[400]\ttraining's rmse: 0.0863895\tvalid_1's rmse: 0.0892623\n",
      "[425]\ttraining's rmse: 0.0863112\tvalid_1's rmse: 0.0892425\n",
      "[450]\ttraining's rmse: 0.0862399\tvalid_1's rmse: 0.0892212\n",
      "[475]\ttraining's rmse: 0.0861738\tvalid_1's rmse: 0.0892026\n",
      "[500]\ttraining's rmse: 0.0861149\tvalid_1's rmse: 0.0891842\n",
      "[525]\ttraining's rmse: 0.0860451\tvalid_1's rmse: 0.0891673\n",
      "[550]\ttraining's rmse: 0.0859851\tvalid_1's rmse: 0.089152\n",
      "[575]\ttraining's rmse: 0.0859264\tvalid_1's rmse: 0.0891372\n",
      "[600]\ttraining's rmse: 0.0858695\tvalid_1's rmse: 0.0891239\n",
      "[625]\ttraining's rmse: 0.0858222\tvalid_1's rmse: 0.0891104\n",
      "[650]\ttraining's rmse: 0.0857687\tvalid_1's rmse: 0.0890973\n",
      "[675]\ttraining's rmse: 0.0857163\tvalid_1's rmse: 0.0890858\n",
      "[700]\ttraining's rmse: 0.0856727\tvalid_1's rmse: 0.0890752\n",
      "[725]\ttraining's rmse: 0.0856278\tvalid_1's rmse: 0.0890636\n",
      "[750]\ttraining's rmse: 0.0855852\tvalid_1's rmse: 0.0890543\n",
      "[775]\ttraining's rmse: 0.0855493\tvalid_1's rmse: 0.0890436\n",
      "[800]\ttraining's rmse: 0.0855098\tvalid_1's rmse: 0.0890344\n",
      "[825]\ttraining's rmse: 0.0854765\tvalid_1's rmse: 0.089025\n",
      "[850]\ttraining's rmse: 0.0854405\tvalid_1's rmse: 0.089016\n",
      "[875]\ttraining's rmse: 0.0854083\tvalid_1's rmse: 0.0890081\n",
      "[900]\ttraining's rmse: 0.0853687\tvalid_1's rmse: 0.0889999\n",
      "[925]\ttraining's rmse: 0.0853378\tvalid_1's rmse: 0.0889915\n",
      "[950]\ttraining's rmse: 0.0853089\tvalid_1's rmse: 0.0889855\n",
      "[975]\ttraining's rmse: 0.0852809\tvalid_1's rmse: 0.0889803\n",
      "[1000]\ttraining's rmse: 0.0852533\tvalid_1's rmse: 0.0889748\n",
      "[1025]\ttraining's rmse: 0.085226\tvalid_1's rmse: 0.0889678\n",
      "[1050]\ttraining's rmse: 0.0851996\tvalid_1's rmse: 0.0889606\n",
      "[1075]\ttraining's rmse: 0.0851714\tvalid_1's rmse: 0.0889562\n",
      "[1100]\ttraining's rmse: 0.085151\tvalid_1's rmse: 0.0889509\n",
      "[1125]\ttraining's rmse: 0.0851269\tvalid_1's rmse: 0.088945\n",
      "[1150]\ttraining's rmse: 0.0851041\tvalid_1's rmse: 0.0889392\n",
      "[1175]\ttraining's rmse: 0.0850833\tvalid_1's rmse: 0.0889345\n",
      "[1200]\ttraining's rmse: 0.0850648\tvalid_1's rmse: 0.0889294\n",
      "[1225]\ttraining's rmse: 0.0850478\tvalid_1's rmse: 0.0889262\n",
      "[1250]\ttraining's rmse: 0.0850285\tvalid_1's rmse: 0.0889216\n",
      "[1275]\ttraining's rmse: 0.0850053\tvalid_1's rmse: 0.088918\n",
      "[1300]\ttraining's rmse: 0.0849936\tvalid_1's rmse: 0.088913\n",
      "[1325]\ttraining's rmse: 0.0849757\tvalid_1's rmse: 0.088909\n",
      "[1350]\ttraining's rmse: 0.0849597\tvalid_1's rmse: 0.0889059\n",
      "[1375]\ttraining's rmse: 0.0849432\tvalid_1's rmse: 0.088902\n",
      "[1400]\ttraining's rmse: 0.0849295\tvalid_1's rmse: 0.0888993\n",
      "[1425]\ttraining's rmse: 0.0849145\tvalid_1's rmse: 0.0888958\n",
      "[1450]\ttraining's rmse: 0.0849009\tvalid_1's rmse: 0.0888937\n",
      "[1475]\ttraining's rmse: 0.084887\tvalid_1's rmse: 0.0888897\n",
      "[1500]\ttraining's rmse: 0.0848752\tvalid_1's rmse: 0.0888879\n",
      "[1525]\ttraining's rmse: 0.084863\tvalid_1's rmse: 0.0888847\n",
      "[1550]\ttraining's rmse: 0.0848519\tvalid_1's rmse: 0.0888829\n",
      "[1575]\ttraining's rmse: 0.0848421\tvalid_1's rmse: 0.088881\n",
      "[1600]\ttraining's rmse: 0.0848336\tvalid_1's rmse: 0.0888788\n",
      "[1625]\ttraining's rmse: 0.0848246\tvalid_1's rmse: 0.0888762\n",
      "[1650]\ttraining's rmse: 0.0848161\tvalid_1's rmse: 0.0888737\n",
      "[1675]\ttraining's rmse: 0.0848085\tvalid_1's rmse: 0.0888703\n",
      "[1700]\ttraining's rmse: 0.0848023\tvalid_1's rmse: 0.0888673\n",
      "[1725]\ttraining's rmse: 0.0847943\tvalid_1's rmse: 0.0888658\n",
      "[1750]\ttraining's rmse: 0.0847884\tvalid_1's rmse: 0.0888639\n",
      "[1775]\ttraining's rmse: 0.0847811\tvalid_1's rmse: 0.088862\n",
      "[1800]\ttraining's rmse: 0.0847727\tvalid_1's rmse: 0.0888598\n",
      "[1825]\ttraining's rmse: 0.0847682\tvalid_1's rmse: 0.0888586\n",
      "[1850]\ttraining's rmse: 0.0847622\tvalid_1's rmse: 0.0888558\n",
      "[1875]\ttraining's rmse: 0.0847554\tvalid_1's rmse: 0.0888527\n",
      "[1900]\ttraining's rmse: 0.0847503\tvalid_1's rmse: 0.0888519\n",
      "[1925]\ttraining's rmse: 0.0847449\tvalid_1's rmse: 0.0888513\n",
      "[1950]\ttraining's rmse: 0.0847414\tvalid_1's rmse: 0.0888495\n",
      "[1975]\ttraining's rmse: 0.0847351\tvalid_1's rmse: 0.0888484\n",
      "[2000]\ttraining's rmse: 0.0847296\tvalid_1's rmse: 0.088847\n",
      "[2025]\ttraining's rmse: 0.084724\tvalid_1's rmse: 0.0888448\n",
      "[2050]\ttraining's rmse: 0.0847188\tvalid_1's rmse: 0.0888433\n",
      "[2075]\ttraining's rmse: 0.0847155\tvalid_1's rmse: 0.088843\n",
      "[2100]\ttraining's rmse: 0.0847119\tvalid_1's rmse: 0.0888413\n",
      "[2125]\ttraining's rmse: 0.0847089\tvalid_1's rmse: 0.0888402\n",
      "[2150]\ttraining's rmse: 0.0847038\tvalid_1's rmse: 0.0888391\n",
      "[2175]\ttraining's rmse: 0.0847001\tvalid_1's rmse: 0.088838\n",
      "[2200]\ttraining's rmse: 0.0846974\tvalid_1's rmse: 0.0888367\n",
      "[2225]\ttraining's rmse: 0.0846935\tvalid_1's rmse: 0.0888357\n",
      "[2250]\ttraining's rmse: 0.0846898\tvalid_1's rmse: 0.0888347\n",
      "[2275]\ttraining's rmse: 0.0846855\tvalid_1's rmse: 0.0888333\n",
      "[2300]\ttraining's rmse: 0.0846815\tvalid_1's rmse: 0.0888322\n",
      "[2325]\ttraining's rmse: 0.0846772\tvalid_1's rmse: 0.0888312\n",
      "[2350]\ttraining's rmse: 0.0846745\tvalid_1's rmse: 0.0888298\n",
      "[2375]\ttraining's rmse: 0.0846722\tvalid_1's rmse: 0.0888291\n",
      "[2400]\ttraining's rmse: 0.0846697\tvalid_1's rmse: 0.0888288\n",
      "[2425]\ttraining's rmse: 0.0846669\tvalid_1's rmse: 0.088828\n",
      "[2450]\ttraining's rmse: 0.0846639\tvalid_1's rmse: 0.0888266\n",
      "[2475]\ttraining's rmse: 0.0846609\tvalid_1's rmse: 0.0888257\n",
      "[2500]\ttraining's rmse: 0.0846579\tvalid_1's rmse: 0.0888248\n",
      "[2525]\ttraining's rmse: 0.0846552\tvalid_1's rmse: 0.0888244\n",
      "[2550]\ttraining's rmse: 0.0846526\tvalid_1's rmse: 0.0888233\n",
      "[2575]\ttraining's rmse: 0.0846499\tvalid_1's rmse: 0.0888222\n",
      "[2600]\ttraining's rmse: 0.084647\tvalid_1's rmse: 0.0888214\n",
      "[2625]\ttraining's rmse: 0.0846446\tvalid_1's rmse: 0.0888193\n",
      "[2650]\ttraining's rmse: 0.0846429\tvalid_1's rmse: 0.0888184\n",
      "[2675]\ttraining's rmse: 0.08464\tvalid_1's rmse: 0.0888174\n",
      "[2700]\ttraining's rmse: 0.0846386\tvalid_1's rmse: 0.0888171\n",
      "[2725]\ttraining's rmse: 0.0846374\tvalid_1's rmse: 0.0888174\n",
      "[2750]\ttraining's rmse: 0.0846352\tvalid_1's rmse: 0.0888172\n",
      "Early stopping, best iteration is:\n",
      "[2701]\ttraining's rmse: 0.0846385\tvalid_1's rmse: 0.0888171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0881759\tvalid_1's rmse: 0.0900513\n",
      "[50]\ttraining's rmse: 0.0880073\tvalid_1's rmse: 0.0899958\n",
      "[75]\ttraining's rmse: 0.0878388\tvalid_1's rmse: 0.0899424\n",
      "[100]\ttraining's rmse: 0.0876874\tvalid_1's rmse: 0.0898951\n",
      "[125]\ttraining's rmse: 0.087536\tvalid_1's rmse: 0.0898469\n",
      "[150]\ttraining's rmse: 0.0873973\tvalid_1's rmse: 0.0898021\n",
      "[175]\ttraining's rmse: 0.0872802\tvalid_1's rmse: 0.089765\n",
      "[200]\ttraining's rmse: 0.0871559\tvalid_1's rmse: 0.0897264\n",
      "[225]\ttraining's rmse: 0.0870341\tvalid_1's rmse: 0.08969\n",
      "[250]\ttraining's rmse: 0.0869313\tvalid_1's rmse: 0.0896573\n",
      "[275]\ttraining's rmse: 0.086833\tvalid_1's rmse: 0.0896279\n",
      "[300]\ttraining's rmse: 0.0867372\tvalid_1's rmse: 0.0895993\n",
      "[325]\ttraining's rmse: 0.0866433\tvalid_1's rmse: 0.0895722\n",
      "[350]\ttraining's rmse: 0.0865515\tvalid_1's rmse: 0.0895468\n",
      "[375]\ttraining's rmse: 0.0864749\tvalid_1's rmse: 0.0895237\n",
      "[400]\ttraining's rmse: 0.0863961\tvalid_1's rmse: 0.089503\n",
      "[425]\ttraining's rmse: 0.0863255\tvalid_1's rmse: 0.0894808\n",
      "[450]\ttraining's rmse: 0.0862618\tvalid_1's rmse: 0.0894615\n",
      "[475]\ttraining's rmse: 0.0862029\tvalid_1's rmse: 0.0894442\n",
      "[500]\ttraining's rmse: 0.0861487\tvalid_1's rmse: 0.0894266\n",
      "[525]\ttraining's rmse: 0.0860852\tvalid_1's rmse: 0.0894092\n",
      "[550]\ttraining's rmse: 0.0860259\tvalid_1's rmse: 0.0893936\n",
      "[575]\ttraining's rmse: 0.0859707\tvalid_1's rmse: 0.0893798\n",
      "[600]\ttraining's rmse: 0.0859193\tvalid_1's rmse: 0.0893659\n",
      "[625]\ttraining's rmse: 0.0858752\tvalid_1's rmse: 0.0893521\n",
      "[650]\ttraining's rmse: 0.0858238\tvalid_1's rmse: 0.0893384\n",
      "[675]\ttraining's rmse: 0.0857747\tvalid_1's rmse: 0.0893262\n",
      "[700]\ttraining's rmse: 0.0857317\tvalid_1's rmse: 0.0893149\n",
      "[725]\ttraining's rmse: 0.0856894\tvalid_1's rmse: 0.0893052\n",
      "[750]\ttraining's rmse: 0.0856521\tvalid_1's rmse: 0.0892954\n",
      "[775]\ttraining's rmse: 0.0856189\tvalid_1's rmse: 0.0892854\n",
      "[800]\ttraining's rmse: 0.0855794\tvalid_1's rmse: 0.0892766\n",
      "[825]\ttraining's rmse: 0.0855445\tvalid_1's rmse: 0.0892684\n",
      "[850]\ttraining's rmse: 0.085508\tvalid_1's rmse: 0.089261\n",
      "[875]\ttraining's rmse: 0.0854769\tvalid_1's rmse: 0.0892543\n",
      "[900]\ttraining's rmse: 0.0854427\tvalid_1's rmse: 0.089246\n",
      "[925]\ttraining's rmse: 0.0854128\tvalid_1's rmse: 0.0892397\n",
      "[950]\ttraining's rmse: 0.0853843\tvalid_1's rmse: 0.089234\n",
      "[975]\ttraining's rmse: 0.0853578\tvalid_1's rmse: 0.0892276\n",
      "[1000]\ttraining's rmse: 0.0853328\tvalid_1's rmse: 0.0892236\n",
      "[1025]\ttraining's rmse: 0.0853054\tvalid_1's rmse: 0.0892194\n",
      "[1050]\ttraining's rmse: 0.0852807\tvalid_1's rmse: 0.0892142\n",
      "[1075]\ttraining's rmse: 0.0852572\tvalid_1's rmse: 0.0892104\n",
      "[1100]\ttraining's rmse: 0.085237\tvalid_1's rmse: 0.0892051\n",
      "[1125]\ttraining's rmse: 0.0852151\tvalid_1's rmse: 0.089201\n",
      "[1150]\ttraining's rmse: 0.0851934\tvalid_1's rmse: 0.0891963\n",
      "[1175]\ttraining's rmse: 0.0851721\tvalid_1's rmse: 0.0891942\n",
      "[1200]\ttraining's rmse: 0.0851511\tvalid_1's rmse: 0.0891899\n",
      "[1225]\ttraining's rmse: 0.0851338\tvalid_1's rmse: 0.089187\n",
      "[1250]\ttraining's rmse: 0.0851177\tvalid_1's rmse: 0.0891837\n",
      "[1275]\ttraining's rmse: 0.0850982\tvalid_1's rmse: 0.089181\n",
      "[1300]\ttraining's rmse: 0.0850817\tvalid_1's rmse: 0.0891785\n",
      "[1325]\ttraining's rmse: 0.0850658\tvalid_1's rmse: 0.0891769\n",
      "[1350]\ttraining's rmse: 0.0850493\tvalid_1's rmse: 0.0891745\n",
      "[1375]\ttraining's rmse: 0.085035\tvalid_1's rmse: 0.0891723\n",
      "[1400]\ttraining's rmse: 0.0850229\tvalid_1's rmse: 0.0891703\n",
      "[1425]\ttraining's rmse: 0.0850083\tvalid_1's rmse: 0.0891684\n",
      "[1450]\ttraining's rmse: 0.0849952\tvalid_1's rmse: 0.0891671\n",
      "[1475]\ttraining's rmse: 0.0849813\tvalid_1's rmse: 0.089165\n",
      "[1500]\ttraining's rmse: 0.0849686\tvalid_1's rmse: 0.0891633\n",
      "[1525]\ttraining's rmse: 0.0849575\tvalid_1's rmse: 0.0891624\n",
      "[1550]\ttraining's rmse: 0.084945\tvalid_1's rmse: 0.0891612\n",
      "[1575]\ttraining's rmse: 0.0849353\tvalid_1's rmse: 0.0891592\n",
      "[1600]\ttraining's rmse: 0.0849264\tvalid_1's rmse: 0.0891585\n",
      "[1625]\ttraining's rmse: 0.0849174\tvalid_1's rmse: 0.0891572\n",
      "[1650]\ttraining's rmse: 0.0849092\tvalid_1's rmse: 0.0891565\n",
      "[1675]\ttraining's rmse: 0.0849025\tvalid_1's rmse: 0.0891554\n",
      "[1700]\ttraining's rmse: 0.0848956\tvalid_1's rmse: 0.089154\n",
      "[1725]\ttraining's rmse: 0.0848873\tvalid_1's rmse: 0.089153\n",
      "[1750]\ttraining's rmse: 0.0848789\tvalid_1's rmse: 0.0891523\n",
      "[1775]\ttraining's rmse: 0.0848718\tvalid_1's rmse: 0.0891522\n",
      "[1800]\ttraining's rmse: 0.0848651\tvalid_1's rmse: 0.0891514\n",
      "[1825]\ttraining's rmse: 0.0848568\tvalid_1's rmse: 0.0891501\n",
      "[1850]\ttraining's rmse: 0.0848499\tvalid_1's rmse: 0.089149\n",
      "[1875]\ttraining's rmse: 0.0848436\tvalid_1's rmse: 0.0891485\n",
      "[1900]\ttraining's rmse: 0.0848363\tvalid_1's rmse: 0.0891482\n",
      "[1925]\ttraining's rmse: 0.08483\tvalid_1's rmse: 0.0891481\n",
      "[1950]\ttraining's rmse: 0.0848252\tvalid_1's rmse: 0.0891473\n",
      "[1975]\ttraining's rmse: 0.0848205\tvalid_1's rmse: 0.0891467\n",
      "[2000]\ttraining's rmse: 0.0848151\tvalid_1's rmse: 0.0891463\n",
      "[2025]\ttraining's rmse: 0.0848105\tvalid_1's rmse: 0.0891458\n",
      "[2050]\ttraining's rmse: 0.0848063\tvalid_1's rmse: 0.0891456\n",
      "[2075]\ttraining's rmse: 0.0848013\tvalid_1's rmse: 0.0891445\n",
      "[2100]\ttraining's rmse: 0.0847986\tvalid_1's rmse: 0.0891439\n",
      "[2125]\ttraining's rmse: 0.0847939\tvalid_1's rmse: 0.0891437\n",
      "[2150]\ttraining's rmse: 0.0847885\tvalid_1's rmse: 0.0891439\n",
      "[2175]\ttraining's rmse: 0.0847837\tvalid_1's rmse: 0.0891437\n",
      "[2200]\ttraining's rmse: 0.0847781\tvalid_1's rmse: 0.0891437\n",
      "[2225]\ttraining's rmse: 0.0847754\tvalid_1's rmse: 0.0891435\n",
      "[2250]\ttraining's rmse: 0.0847716\tvalid_1's rmse: 0.0891432\n",
      "[2275]\ttraining's rmse: 0.0847673\tvalid_1's rmse: 0.0891429\n",
      "[2300]\ttraining's rmse: 0.0847638\tvalid_1's rmse: 0.0891424\n",
      "[2325]\ttraining's rmse: 0.0847592\tvalid_1's rmse: 0.0891421\n",
      "[2350]\ttraining's rmse: 0.0847567\tvalid_1's rmse: 0.0891416\n",
      "[2375]\ttraining's rmse: 0.0847533\tvalid_1's rmse: 0.0891415\n",
      "[2400]\ttraining's rmse: 0.0847499\tvalid_1's rmse: 0.0891412\n",
      "[2425]\ttraining's rmse: 0.0847482\tvalid_1's rmse: 0.0891412\n",
      "[2450]\ttraining's rmse: 0.0847444\tvalid_1's rmse: 0.089141\n",
      "[2475]\ttraining's rmse: 0.0847405\tvalid_1's rmse: 0.0891407\n",
      "[2500]\ttraining's rmse: 0.0847385\tvalid_1's rmse: 0.0891403\n",
      "[2525]\ttraining's rmse: 0.0847361\tvalid_1's rmse: 0.0891403\n",
      "[2550]\ttraining's rmse: 0.084734\tvalid_1's rmse: 0.0891405\n",
      "Early stopping, best iteration is:\n",
      "[2509]\ttraining's rmse: 0.0847373\tvalid_1's rmse: 0.0891402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0897799\tvalid_1's rmse: 0.0868928\n",
      "[50]\ttraining's rmse: 0.089652\tvalid_1's rmse: 0.0868451\n",
      "[75]\ttraining's rmse: 0.0895193\tvalid_1's rmse: 0.0867971\n",
      "[100]\ttraining's rmse: 0.0893979\tvalid_1's rmse: 0.0867546\n",
      "[125]\ttraining's rmse: 0.0892735\tvalid_1's rmse: 0.0867125\n",
      "[150]\ttraining's rmse: 0.0891598\tvalid_1's rmse: 0.0866733\n",
      "[175]\ttraining's rmse: 0.0890625\tvalid_1's rmse: 0.0866403\n",
      "[200]\ttraining's rmse: 0.0889573\tvalid_1's rmse: 0.0866086\n",
      "[225]\ttraining's rmse: 0.0888581\tvalid_1's rmse: 0.0865778\n",
      "[250]\ttraining's rmse: 0.0887723\tvalid_1's rmse: 0.086552\n",
      "[275]\ttraining's rmse: 0.0886939\tvalid_1's rmse: 0.0865264\n",
      "[300]\ttraining's rmse: 0.0886147\tvalid_1's rmse: 0.0865041\n",
      "[325]\ttraining's rmse: 0.0885353\tvalid_1's rmse: 0.0864824\n",
      "[350]\ttraining's rmse: 0.0884571\tvalid_1's rmse: 0.0864614\n",
      "[375]\ttraining's rmse: 0.0883933\tvalid_1's rmse: 0.0864459\n",
      "[400]\ttraining's rmse: 0.0883241\tvalid_1's rmse: 0.0864291\n",
      "[425]\ttraining's rmse: 0.0882608\tvalid_1's rmse: 0.0864182\n",
      "[450]\ttraining's rmse: 0.088201\tvalid_1's rmse: 0.0864038\n",
      "[475]\ttraining's rmse: 0.0881445\tvalid_1's rmse: 0.0863966\n",
      "[500]\ttraining's rmse: 0.088101\tvalid_1's rmse: 0.0863832\n",
      "[525]\ttraining's rmse: 0.0880383\tvalid_1's rmse: 0.0863691\n",
      "[550]\ttraining's rmse: 0.087984\tvalid_1's rmse: 0.086357\n",
      "[575]\ttraining's rmse: 0.0879333\tvalid_1's rmse: 0.0863476\n",
      "[600]\ttraining's rmse: 0.0878837\tvalid_1's rmse: 0.0863436\n",
      "[625]\ttraining's rmse: 0.0878446\tvalid_1's rmse: 0.0863357\n",
      "[650]\ttraining's rmse: 0.0877952\tvalid_1's rmse: 0.0863294\n",
      "[675]\ttraining's rmse: 0.0877467\tvalid_1's rmse: 0.0863254\n",
      "[700]\ttraining's rmse: 0.0877036\tvalid_1's rmse: 0.0863172\n",
      "[725]\ttraining's rmse: 0.0876617\tvalid_1's rmse: 0.0863296\n",
      "[750]\ttraining's rmse: 0.0876237\tvalid_1's rmse: 0.086342\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0876945\tvalid_1's rmse: 0.0863164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0846194\tvalid_1's rmse: 0.0872298\n",
      "[50]\ttraining's rmse: 0.0844852\tvalid_1's rmse: 0.0871731\n",
      "[75]\ttraining's rmse: 0.0843503\tvalid_1's rmse: 0.0871184\n",
      "[100]\ttraining's rmse: 0.0842279\tvalid_1's rmse: 0.0870678\n",
      "[125]\ttraining's rmse: 0.0841048\tvalid_1's rmse: 0.0870219\n",
      "[150]\ttraining's rmse: 0.0839931\tvalid_1's rmse: 0.0869774\n",
      "[175]\ttraining's rmse: 0.0838949\tvalid_1's rmse: 0.0869399\n",
      "[200]\ttraining's rmse: 0.0837978\tvalid_1's rmse: 0.0869007\n",
      "[225]\ttraining's rmse: 0.0837033\tvalid_1's rmse: 0.086864\n",
      "[250]\ttraining's rmse: 0.0836195\tvalid_1's rmse: 0.0868301\n",
      "[275]\ttraining's rmse: 0.0835433\tvalid_1's rmse: 0.0867991\n",
      "[300]\ttraining's rmse: 0.0834667\tvalid_1's rmse: 0.0867713\n",
      "[325]\ttraining's rmse: 0.0833893\tvalid_1's rmse: 0.0867441\n",
      "[350]\ttraining's rmse: 0.083315\tvalid_1's rmse: 0.086718\n",
      "[375]\ttraining's rmse: 0.0832547\tvalid_1's rmse: 0.0866963\n",
      "[400]\ttraining's rmse: 0.0831872\tvalid_1's rmse: 0.0866741\n",
      "[425]\ttraining's rmse: 0.0831302\tvalid_1's rmse: 0.0866532\n",
      "[450]\ttraining's rmse: 0.0830776\tvalid_1's rmse: 0.0866328\n",
      "[475]\ttraining's rmse: 0.0830246\tvalid_1's rmse: 0.0866129\n",
      "[500]\ttraining's rmse: 0.0829794\tvalid_1's rmse: 0.0865956\n",
      "[525]\ttraining's rmse: 0.0829273\tvalid_1's rmse: 0.0865782\n",
      "[550]\ttraining's rmse: 0.0828783\tvalid_1's rmse: 0.0865628\n",
      "[575]\ttraining's rmse: 0.0828307\tvalid_1's rmse: 0.0865488\n",
      "[600]\ttraining's rmse: 0.0827881\tvalid_1's rmse: 0.0865334\n",
      "[625]\ttraining's rmse: 0.0827506\tvalid_1's rmse: 0.0865205\n",
      "[650]\ttraining's rmse: 0.0827102\tvalid_1's rmse: 0.0865058\n",
      "[675]\ttraining's rmse: 0.0826678\tvalid_1's rmse: 0.0864937\n",
      "[700]\ttraining's rmse: 0.0826314\tvalid_1's rmse: 0.086482\n",
      "[725]\ttraining's rmse: 0.0825952\tvalid_1's rmse: 0.0864725\n",
      "[750]\ttraining's rmse: 0.0825587\tvalid_1's rmse: 0.0864619\n",
      "[775]\ttraining's rmse: 0.0825321\tvalid_1's rmse: 0.0864505\n",
      "[800]\ttraining's rmse: 0.0824969\tvalid_1's rmse: 0.0864433\n",
      "[825]\ttraining's rmse: 0.0824654\tvalid_1's rmse: 0.0864328\n",
      "[850]\ttraining's rmse: 0.0824349\tvalid_1's rmse: 0.0864259\n",
      "[875]\ttraining's rmse: 0.0824085\tvalid_1's rmse: 0.0864174\n",
      "[900]\ttraining's rmse: 0.0823801\tvalid_1's rmse: 0.086411\n",
      "[925]\ttraining's rmse: 0.0823522\tvalid_1's rmse: 0.0864033\n",
      "[950]\ttraining's rmse: 0.0823287\tvalid_1's rmse: 0.0863981\n",
      "[975]\ttraining's rmse: 0.0823062\tvalid_1's rmse: 0.0863902\n",
      "[1000]\ttraining's rmse: 0.082282\tvalid_1's rmse: 0.0863835\n",
      "[1025]\ttraining's rmse: 0.0822582\tvalid_1's rmse: 0.0863748\n",
      "[1050]\ttraining's rmse: 0.0822382\tvalid_1's rmse: 0.086368\n",
      "[1075]\ttraining's rmse: 0.0822169\tvalid_1's rmse: 0.0863631\n",
      "[1100]\ttraining's rmse: 0.0821986\tvalid_1's rmse: 0.0863581\n",
      "[1125]\ttraining's rmse: 0.0821821\tvalid_1's rmse: 0.0863527\n",
      "[1150]\ttraining's rmse: 0.082162\tvalid_1's rmse: 0.0863481\n",
      "[1175]\ttraining's rmse: 0.0821441\tvalid_1's rmse: 0.0863443\n",
      "[1200]\ttraining's rmse: 0.082129\tvalid_1's rmse: 0.08634\n",
      "[1225]\ttraining's rmse: 0.0821146\tvalid_1's rmse: 0.086336\n",
      "[1250]\ttraining's rmse: 0.082098\tvalid_1's rmse: 0.0863323\n",
      "[1275]\ttraining's rmse: 0.0820807\tvalid_1's rmse: 0.0863284\n",
      "[1300]\ttraining's rmse: 0.0820675\tvalid_1's rmse: 0.0863237\n",
      "[1325]\ttraining's rmse: 0.0820574\tvalid_1's rmse: 0.0863197\n",
      "[1350]\ttraining's rmse: 0.0820428\tvalid_1's rmse: 0.0863153\n",
      "[1375]\ttraining's rmse: 0.082029\tvalid_1's rmse: 0.0863111\n",
      "[1400]\ttraining's rmse: 0.0820172\tvalid_1's rmse: 0.0863082\n",
      "[1425]\ttraining's rmse: 0.0820052\tvalid_1's rmse: 0.0863055\n",
      "[1450]\ttraining's rmse: 0.0819943\tvalid_1's rmse: 0.0863037\n",
      "[1475]\ttraining's rmse: 0.081983\tvalid_1's rmse: 0.0863012\n",
      "[1500]\ttraining's rmse: 0.0819721\tvalid_1's rmse: 0.0862985\n",
      "[1525]\ttraining's rmse: 0.081961\tvalid_1's rmse: 0.0862959\n",
      "[1550]\ttraining's rmse: 0.0819513\tvalid_1's rmse: 0.0862948\n",
      "[1575]\ttraining's rmse: 0.0819436\tvalid_1's rmse: 0.0862928\n",
      "[1600]\ttraining's rmse: 0.0819365\tvalid_1's rmse: 0.0862919\n",
      "[1625]\ttraining's rmse: 0.0819293\tvalid_1's rmse: 0.0862885\n",
      "[1650]\ttraining's rmse: 0.0819223\tvalid_1's rmse: 0.0862857\n",
      "[1675]\ttraining's rmse: 0.0819154\tvalid_1's rmse: 0.0862839\n",
      "[1700]\ttraining's rmse: 0.08191\tvalid_1's rmse: 0.0862817\n",
      "[1725]\ttraining's rmse: 0.0819043\tvalid_1's rmse: 0.0862802\n",
      "[1750]\ttraining's rmse: 0.0818955\tvalid_1's rmse: 0.0862777\n",
      "[1775]\ttraining's rmse: 0.0818891\tvalid_1's rmse: 0.0862762\n",
      "[1800]\ttraining's rmse: 0.0818834\tvalid_1's rmse: 0.0862741\n",
      "[1825]\ttraining's rmse: 0.0818764\tvalid_1's rmse: 0.0862719\n",
      "[1850]\ttraining's rmse: 0.0818707\tvalid_1's rmse: 0.0862699\n",
      "[1875]\ttraining's rmse: 0.0818659\tvalid_1's rmse: 0.086269\n",
      "[1900]\ttraining's rmse: 0.0818624\tvalid_1's rmse: 0.0862677\n",
      "[1925]\ttraining's rmse: 0.0818577\tvalid_1's rmse: 0.0862667\n",
      "[1950]\ttraining's rmse: 0.0818538\tvalid_1's rmse: 0.0862654\n",
      "[1975]\ttraining's rmse: 0.0818492\tvalid_1's rmse: 0.0862638\n",
      "[2000]\ttraining's rmse: 0.0818434\tvalid_1's rmse: 0.0862616\n",
      "[2025]\ttraining's rmse: 0.0818387\tvalid_1's rmse: 0.0862601\n",
      "[2050]\ttraining's rmse: 0.0818346\tvalid_1's rmse: 0.0862589\n",
      "[2075]\ttraining's rmse: 0.0818305\tvalid_1's rmse: 0.0862582\n",
      "[2100]\ttraining's rmse: 0.0818276\tvalid_1's rmse: 0.0862574\n",
      "[2125]\ttraining's rmse: 0.0818246\tvalid_1's rmse: 0.0862567\n",
      "[2150]\ttraining's rmse: 0.0818218\tvalid_1's rmse: 0.086255\n",
      "[2175]\ttraining's rmse: 0.081819\tvalid_1's rmse: 0.086254\n",
      "[2200]\ttraining's rmse: 0.0818154\tvalid_1's rmse: 0.0862524\n",
      "[2225]\ttraining's rmse: 0.0818125\tvalid_1's rmse: 0.0862517\n",
      "[2250]\ttraining's rmse: 0.0818099\tvalid_1's rmse: 0.0862511\n",
      "[2275]\ttraining's rmse: 0.0818069\tvalid_1's rmse: 0.0862505\n",
      "[2300]\ttraining's rmse: 0.0818038\tvalid_1's rmse: 0.0862498\n",
      "[2325]\ttraining's rmse: 0.0818006\tvalid_1's rmse: 0.0862488\n",
      "[2350]\ttraining's rmse: 0.081798\tvalid_1's rmse: 0.086248\n",
      "[2375]\ttraining's rmse: 0.0817947\tvalid_1's rmse: 0.0862473\n",
      "[2400]\ttraining's rmse: 0.0817925\tvalid_1's rmse: 0.0862474\n",
      "[2425]\ttraining's rmse: 0.0817895\tvalid_1's rmse: 0.0862466\n",
      "[2450]\ttraining's rmse: 0.0817881\tvalid_1's rmse: 0.0862465\n",
      "[2475]\ttraining's rmse: 0.0817853\tvalid_1's rmse: 0.0862467\n",
      "[2500]\ttraining's rmse: 0.0817824\tvalid_1's rmse: 0.0862459\n",
      "[2525]\ttraining's rmse: 0.0817802\tvalid_1's rmse: 0.0862456\n",
      "[2550]\ttraining's rmse: 0.081778\tvalid_1's rmse: 0.0862452\n",
      "[2575]\ttraining's rmse: 0.0817749\tvalid_1's rmse: 0.086245\n",
      "[2600]\ttraining's rmse: 0.081772\tvalid_1's rmse: 0.0862443\n",
      "[2625]\ttraining's rmse: 0.0817703\tvalid_1's rmse: 0.0862443\n",
      "[2650]\ttraining's rmse: 0.0817673\tvalid_1's rmse: 0.0862436\n",
      "[2675]\ttraining's rmse: 0.0817645\tvalid_1's rmse: 0.086243\n",
      "[2700]\ttraining's rmse: 0.0817622\tvalid_1's rmse: 0.0862427\n",
      "[2725]\ttraining's rmse: 0.081759\tvalid_1's rmse: 0.086243\n",
      "[2750]\ttraining's rmse: 0.0817571\tvalid_1's rmse: 0.0862424\n",
      "[2775]\ttraining's rmse: 0.0817546\tvalid_1's rmse: 0.0862424\n",
      "[2800]\ttraining's rmse: 0.0817528\tvalid_1's rmse: 0.0862421\n",
      "[2825]\ttraining's rmse: 0.0817518\tvalid_1's rmse: 0.0862417\n",
      "[2850]\ttraining's rmse: 0.0817501\tvalid_1's rmse: 0.0862412\n",
      "[2875]\ttraining's rmse: 0.0817483\tvalid_1's rmse: 0.0862412\n",
      "[2900]\ttraining's rmse: 0.081747\tvalid_1's rmse: 0.0862409\n",
      "[2925]\ttraining's rmse: 0.0817458\tvalid_1's rmse: 0.0862408\n",
      "[2950]\ttraining's rmse: 0.0817446\tvalid_1's rmse: 0.0862405\n",
      "[2975]\ttraining's rmse: 0.0817424\tvalid_1's rmse: 0.0862405\n",
      "[3000]\ttraining's rmse: 0.0817408\tvalid_1's rmse: 0.0862405\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\ttraining's rmse: 0.0817408\tvalid_1's rmse: 0.0862405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0848509\tvalid_1's rmse: 0.0867839\n",
      "[50]\ttraining's rmse: 0.0847286\tvalid_1's rmse: 0.0867276\n",
      "[75]\ttraining's rmse: 0.0846024\tvalid_1's rmse: 0.0866703\n",
      "[100]\ttraining's rmse: 0.0844905\tvalid_1's rmse: 0.0866205\n",
      "[125]\ttraining's rmse: 0.0843747\tvalid_1's rmse: 0.0865721\n",
      "[150]\ttraining's rmse: 0.0842663\tvalid_1's rmse: 0.086526\n",
      "[175]\ttraining's rmse: 0.0841779\tvalid_1's rmse: 0.0864893\n",
      "[200]\ttraining's rmse: 0.0840794\tvalid_1's rmse: 0.0864509\n",
      "[225]\ttraining's rmse: 0.0839868\tvalid_1's rmse: 0.0864155\n",
      "[250]\ttraining's rmse: 0.0839084\tvalid_1's rmse: 0.0863848\n",
      "[275]\ttraining's rmse: 0.0838354\tvalid_1's rmse: 0.0863552\n",
      "[300]\ttraining's rmse: 0.0837611\tvalid_1's rmse: 0.0863268\n",
      "[325]\ttraining's rmse: 0.0836876\tvalid_1's rmse: 0.0862989\n",
      "[350]\ttraining's rmse: 0.0836148\tvalid_1's rmse: 0.0862738\n",
      "[375]\ttraining's rmse: 0.0835557\tvalid_1's rmse: 0.0862527\n",
      "[400]\ttraining's rmse: 0.0834922\tvalid_1's rmse: 0.086231\n",
      "[425]\ttraining's rmse: 0.0834341\tvalid_1's rmse: 0.086211\n",
      "[450]\ttraining's rmse: 0.0833812\tvalid_1's rmse: 0.0861928\n",
      "[475]\ttraining's rmse: 0.083329\tvalid_1's rmse: 0.0861765\n",
      "[500]\ttraining's rmse: 0.0832827\tvalid_1's rmse: 0.0861589\n",
      "[525]\ttraining's rmse: 0.0832277\tvalid_1's rmse: 0.0861424\n",
      "[550]\ttraining's rmse: 0.0831756\tvalid_1's rmse: 0.0861266\n",
      "[575]\ttraining's rmse: 0.0831264\tvalid_1's rmse: 0.086111\n",
      "[600]\ttraining's rmse: 0.0830808\tvalid_1's rmse: 0.0860976\n",
      "[625]\ttraining's rmse: 0.0830457\tvalid_1's rmse: 0.0860858\n",
      "[650]\ttraining's rmse: 0.0830005\tvalid_1's rmse: 0.0860739\n",
      "[675]\ttraining's rmse: 0.0829569\tvalid_1's rmse: 0.0860622\n",
      "[700]\ttraining's rmse: 0.0829182\tvalid_1's rmse: 0.0860519\n",
      "[725]\ttraining's rmse: 0.0828831\tvalid_1's rmse: 0.0860416\n",
      "[750]\ttraining's rmse: 0.0828483\tvalid_1's rmse: 0.0860332\n",
      "[775]\ttraining's rmse: 0.0828202\tvalid_1's rmse: 0.0860244\n",
      "[800]\ttraining's rmse: 0.0827842\tvalid_1's rmse: 0.0860162\n",
      "[825]\ttraining's rmse: 0.0827522\tvalid_1's rmse: 0.0860073\n",
      "[850]\ttraining's rmse: 0.0827192\tvalid_1's rmse: 0.0860005\n",
      "[875]\ttraining's rmse: 0.0826908\tvalid_1's rmse: 0.0859939\n",
      "[900]\ttraining's rmse: 0.0826636\tvalid_1's rmse: 0.0859871\n",
      "[925]\ttraining's rmse: 0.0826335\tvalid_1's rmse: 0.0859809\n",
      "[950]\ttraining's rmse: 0.0826081\tvalid_1's rmse: 0.0859751\n",
      "[975]\ttraining's rmse: 0.0825874\tvalid_1's rmse: 0.0859698\n",
      "[1000]\ttraining's rmse: 0.0825653\tvalid_1's rmse: 0.085965\n",
      "[1025]\ttraining's rmse: 0.0825393\tvalid_1's rmse: 0.0859596\n",
      "[1050]\ttraining's rmse: 0.0825177\tvalid_1's rmse: 0.0859547\n",
      "[1075]\ttraining's rmse: 0.0824968\tvalid_1's rmse: 0.0859513\n",
      "[1100]\ttraining's rmse: 0.082482\tvalid_1's rmse: 0.0859471\n",
      "[1125]\ttraining's rmse: 0.0824626\tvalid_1's rmse: 0.0859435\n",
      "[1150]\ttraining's rmse: 0.0824427\tvalid_1's rmse: 0.0859398\n",
      "[1175]\ttraining's rmse: 0.0824261\tvalid_1's rmse: 0.0859367\n",
      "[1200]\ttraining's rmse: 0.0824103\tvalid_1's rmse: 0.0859336\n",
      "[1225]\ttraining's rmse: 0.082394\tvalid_1's rmse: 0.0859311\n",
      "[1250]\ttraining's rmse: 0.0823787\tvalid_1's rmse: 0.0859283\n",
      "[1275]\ttraining's rmse: 0.0823615\tvalid_1's rmse: 0.0859261\n",
      "[1300]\ttraining's rmse: 0.0823498\tvalid_1's rmse: 0.0859239\n",
      "[1325]\ttraining's rmse: 0.082336\tvalid_1's rmse: 0.0859229\n",
      "[1350]\ttraining's rmse: 0.0823221\tvalid_1's rmse: 0.0859215\n",
      "[1375]\ttraining's rmse: 0.0823104\tvalid_1's rmse: 0.0859196\n",
      "[1400]\ttraining's rmse: 0.0823\tvalid_1's rmse: 0.0859172\n",
      "[1425]\ttraining's rmse: 0.0822869\tvalid_1's rmse: 0.0859159\n",
      "[1450]\ttraining's rmse: 0.0822764\tvalid_1's rmse: 0.0859145\n",
      "[1475]\ttraining's rmse: 0.0822666\tvalid_1's rmse: 0.0859132\n",
      "[1500]\ttraining's rmse: 0.0822556\tvalid_1's rmse: 0.0859116\n",
      "[1525]\ttraining's rmse: 0.0822458\tvalid_1's rmse: 0.0859098\n",
      "[1550]\ttraining's rmse: 0.0822368\tvalid_1's rmse: 0.085909\n",
      "[1575]\ttraining's rmse: 0.0822269\tvalid_1's rmse: 0.0859075\n",
      "[1600]\ttraining's rmse: 0.0822199\tvalid_1's rmse: 0.0859066\n",
      "[1625]\ttraining's rmse: 0.0822115\tvalid_1's rmse: 0.0859054\n",
      "[1650]\ttraining's rmse: 0.0822034\tvalid_1's rmse: 0.0859047\n",
      "[1675]\ttraining's rmse: 0.0821972\tvalid_1's rmse: 0.0859035\n",
      "[1700]\ttraining's rmse: 0.0821903\tvalid_1's rmse: 0.0859028\n",
      "[1725]\ttraining's rmse: 0.0821833\tvalid_1's rmse: 0.0859021\n",
      "[1750]\ttraining's rmse: 0.0821762\tvalid_1's rmse: 0.0859013\n",
      "[1775]\ttraining's rmse: 0.0821688\tvalid_1's rmse: 0.0859006\n",
      "[1800]\ttraining's rmse: 0.0821618\tvalid_1's rmse: 0.0858998\n",
      "[1825]\ttraining's rmse: 0.082156\tvalid_1's rmse: 0.0858991\n",
      "[1850]\ttraining's rmse: 0.0821497\tvalid_1's rmse: 0.0858981\n",
      "[1875]\ttraining's rmse: 0.0821427\tvalid_1's rmse: 0.0858976\n",
      "[1900]\ttraining's rmse: 0.0821379\tvalid_1's rmse: 0.0858977\n",
      "[1925]\ttraining's rmse: 0.0821321\tvalid_1's rmse: 0.085897\n",
      "[1950]\ttraining's rmse: 0.0821276\tvalid_1's rmse: 0.0858958\n",
      "[1975]\ttraining's rmse: 0.0821223\tvalid_1's rmse: 0.085895\n",
      "[2000]\ttraining's rmse: 0.0821175\tvalid_1's rmse: 0.0858944\n",
      "[2025]\ttraining's rmse: 0.0821141\tvalid_1's rmse: 0.0858942\n",
      "[2050]\ttraining's rmse: 0.0821091\tvalid_1's rmse: 0.0858939\n",
      "[2075]\ttraining's rmse: 0.082106\tvalid_1's rmse: 0.0858937\n",
      "[2100]\ttraining's rmse: 0.0821013\tvalid_1's rmse: 0.0858932\n",
      "[2125]\ttraining's rmse: 0.0820984\tvalid_1's rmse: 0.0858932\n",
      "[2150]\ttraining's rmse: 0.0820945\tvalid_1's rmse: 0.0858933\n",
      "[2175]\ttraining's rmse: 0.0820912\tvalid_1's rmse: 0.0858931\n",
      "[2200]\ttraining's rmse: 0.0820863\tvalid_1's rmse: 0.0858928\n",
      "[2225]\ttraining's rmse: 0.0820838\tvalid_1's rmse: 0.0858922\n",
      "[2250]\ttraining's rmse: 0.0820813\tvalid_1's rmse: 0.0858921\n",
      "[2275]\ttraining's rmse: 0.082078\tvalid_1's rmse: 0.0858918\n",
      "[2300]\ttraining's rmse: 0.0820738\tvalid_1's rmse: 0.0858917\n",
      "[2325]\ttraining's rmse: 0.0820718\tvalid_1's rmse: 0.085892\n",
      "Early stopping, best iteration is:\n",
      "[2291]\ttraining's rmse: 0.0820755\tvalid_1's rmse: 0.0858916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0868864\tvalid_1's rmse: 0.0826539\n",
      "[50]\ttraining's rmse: 0.0867688\tvalid_1's rmse: 0.0826051\n",
      "[75]\ttraining's rmse: 0.0866456\tvalid_1's rmse: 0.0825559\n",
      "[100]\ttraining's rmse: 0.0865369\tvalid_1's rmse: 0.0825122\n",
      "[125]\ttraining's rmse: 0.0864266\tvalid_1's rmse: 0.0824731\n",
      "[150]\ttraining's rmse: 0.0863228\tvalid_1's rmse: 0.0824346\n",
      "[175]\ttraining's rmse: 0.0862353\tvalid_1's rmse: 0.082402\n",
      "[200]\ttraining's rmse: 0.0861432\tvalid_1's rmse: 0.0823738\n",
      "[225]\ttraining's rmse: 0.0860552\tvalid_1's rmse: 0.0823435\n",
      "[250]\ttraining's rmse: 0.085981\tvalid_1's rmse: 0.0823172\n",
      "[275]\ttraining's rmse: 0.0859118\tvalid_1's rmse: 0.0822917\n",
      "[300]\ttraining's rmse: 0.0858439\tvalid_1's rmse: 0.0822748\n",
      "[325]\ttraining's rmse: 0.0857743\tvalid_1's rmse: 0.0822519\n",
      "[350]\ttraining's rmse: 0.0857043\tvalid_1's rmse: 0.08223\n",
      "[375]\ttraining's rmse: 0.0856477\tvalid_1's rmse: 0.0822105\n",
      "[400]\ttraining's rmse: 0.0855856\tvalid_1's rmse: 0.0822045\n",
      "[425]\ttraining's rmse: 0.0855305\tvalid_1's rmse: 0.082189\n",
      "[450]\ttraining's rmse: 0.0854782\tvalid_1's rmse: 0.0821723\n",
      "[475]\ttraining's rmse: 0.0854292\tvalid_1's rmse: 0.082164\n",
      "[500]\ttraining's rmse: 0.0853882\tvalid_1's rmse: 0.0821534\n",
      "[525]\ttraining's rmse: 0.0853341\tvalid_1's rmse: 0.0821392\n",
      "[550]\ttraining's rmse: 0.0852876\tvalid_1's rmse: 0.0821262\n",
      "[575]\ttraining's rmse: 0.0852441\tvalid_1's rmse: 0.0821144\n",
      "[600]\ttraining's rmse: 0.0851987\tvalid_1's rmse: 0.0821043\n",
      "[625]\ttraining's rmse: 0.085164\tvalid_1's rmse: 0.0821009\n",
      "[650]\ttraining's rmse: 0.0851203\tvalid_1's rmse: 0.0820974\n",
      "[675]\ttraining's rmse: 0.085074\tvalid_1's rmse: 0.082094\n",
      "[700]\ttraining's rmse: 0.0850362\tvalid_1's rmse: 0.0820918\n",
      "[725]\ttraining's rmse: 0.0850013\tvalid_1's rmse: 0.0820905\n",
      "[750]\ttraining's rmse: 0.0849683\tvalid_1's rmse: 0.0821134\n",
      "[775]\ttraining's rmse: 0.0849386\tvalid_1's rmse: 0.0821189\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0849862\tvalid_1's rmse: 0.0820871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0889634\tvalid_1's rmse: 0.0903502\n",
      "[50]\ttraining's rmse: 0.0887698\tvalid_1's rmse: 0.0902993\n",
      "[75]\ttraining's rmse: 0.088587\tvalid_1's rmse: 0.0902472\n",
      "[100]\ttraining's rmse: 0.0884149\tvalid_1's rmse: 0.0902039\n",
      "[125]\ttraining's rmse: 0.0882476\tvalid_1's rmse: 0.0901564\n",
      "[150]\ttraining's rmse: 0.0880915\tvalid_1's rmse: 0.0901143\n",
      "[175]\ttraining's rmse: 0.0879561\tvalid_1's rmse: 0.0900777\n",
      "[200]\ttraining's rmse: 0.0878148\tvalid_1's rmse: 0.0900416\n",
      "[225]\ttraining's rmse: 0.0876756\tvalid_1's rmse: 0.0900059\n",
      "[250]\ttraining's rmse: 0.0875629\tvalid_1's rmse: 0.0899728\n",
      "[275]\ttraining's rmse: 0.0874556\tvalid_1's rmse: 0.0899441\n",
      "[300]\ttraining's rmse: 0.0873511\tvalid_1's rmse: 0.0899158\n",
      "[325]\ttraining's rmse: 0.0872504\tvalid_1's rmse: 0.0898908\n",
      "[350]\ttraining's rmse: 0.0871539\tvalid_1's rmse: 0.0898649\n",
      "[375]\ttraining's rmse: 0.0870702\tvalid_1's rmse: 0.0898433\n",
      "[400]\ttraining's rmse: 0.086979\tvalid_1's rmse: 0.0898215\n",
      "[425]\ttraining's rmse: 0.0868983\tvalid_1's rmse: 0.0898015\n",
      "[450]\ttraining's rmse: 0.0868246\tvalid_1's rmse: 0.0897812\n",
      "[475]\ttraining's rmse: 0.0867535\tvalid_1's rmse: 0.089762\n",
      "[500]\ttraining's rmse: 0.0866942\tvalid_1's rmse: 0.089746\n",
      "[525]\ttraining's rmse: 0.0866208\tvalid_1's rmse: 0.0897293\n",
      "[550]\ttraining's rmse: 0.0865562\tvalid_1's rmse: 0.0897129\n",
      "[575]\ttraining's rmse: 0.086497\tvalid_1's rmse: 0.0896991\n",
      "[600]\ttraining's rmse: 0.086441\tvalid_1's rmse: 0.0896865\n",
      "[625]\ttraining's rmse: 0.086393\tvalid_1's rmse: 0.0896735\n",
      "[650]\ttraining's rmse: 0.0863364\tvalid_1's rmse: 0.0896613\n",
      "[675]\ttraining's rmse: 0.0862849\tvalid_1's rmse: 0.0896481\n",
      "[700]\ttraining's rmse: 0.0862371\tvalid_1's rmse: 0.0896373\n",
      "[725]\ttraining's rmse: 0.0861931\tvalid_1's rmse: 0.0896259\n",
      "[750]\ttraining's rmse: 0.0861473\tvalid_1's rmse: 0.0896147\n",
      "[775]\ttraining's rmse: 0.0861118\tvalid_1's rmse: 0.0896041\n",
      "[800]\ttraining's rmse: 0.0860701\tvalid_1's rmse: 0.0895944\n",
      "[825]\ttraining's rmse: 0.0860331\tvalid_1's rmse: 0.0895843\n",
      "[850]\ttraining's rmse: 0.0859953\tvalid_1's rmse: 0.0895772\n",
      "[875]\ttraining's rmse: 0.0859605\tvalid_1's rmse: 0.0895698\n",
      "[900]\ttraining's rmse: 0.0859226\tvalid_1's rmse: 0.0895626\n",
      "[925]\ttraining's rmse: 0.0858897\tvalid_1's rmse: 0.089554\n",
      "[950]\ttraining's rmse: 0.0858589\tvalid_1's rmse: 0.089547\n",
      "[975]\ttraining's rmse: 0.0858299\tvalid_1's rmse: 0.0895391\n",
      "[1000]\ttraining's rmse: 0.0857988\tvalid_1's rmse: 0.0895328\n",
      "[1025]\ttraining's rmse: 0.0857702\tvalid_1's rmse: 0.089527\n",
      "[1050]\ttraining's rmse: 0.085743\tvalid_1's rmse: 0.0895206\n",
      "[1075]\ttraining's rmse: 0.0857176\tvalid_1's rmse: 0.0895153\n",
      "[1100]\ttraining's rmse: 0.085696\tvalid_1's rmse: 0.0895104\n",
      "[1125]\ttraining's rmse: 0.0856745\tvalid_1's rmse: 0.0895055\n",
      "[1150]\ttraining's rmse: 0.0856521\tvalid_1's rmse: 0.0895003\n",
      "[1175]\ttraining's rmse: 0.0856316\tvalid_1's rmse: 0.0894979\n",
      "[1200]\ttraining's rmse: 0.085609\tvalid_1's rmse: 0.0894931\n",
      "[1225]\ttraining's rmse: 0.0855905\tvalid_1's rmse: 0.089489\n",
      "[1250]\ttraining's rmse: 0.0855732\tvalid_1's rmse: 0.0894845\n",
      "[1275]\ttraining's rmse: 0.0855529\tvalid_1's rmse: 0.0894805\n",
      "[1300]\ttraining's rmse: 0.0855375\tvalid_1's rmse: 0.089477\n",
      "[1325]\ttraining's rmse: 0.0855206\tvalid_1's rmse: 0.0894734\n",
      "[1350]\ttraining's rmse: 0.0855039\tvalid_1's rmse: 0.0894691\n",
      "[1375]\ttraining's rmse: 0.0854872\tvalid_1's rmse: 0.0894658\n",
      "[1400]\ttraining's rmse: 0.085474\tvalid_1's rmse: 0.0894605\n",
      "[1425]\ttraining's rmse: 0.0854574\tvalid_1's rmse: 0.0894579\n",
      "[1450]\ttraining's rmse: 0.0854434\tvalid_1's rmse: 0.089455\n",
      "[1475]\ttraining's rmse: 0.0854307\tvalid_1's rmse: 0.0894509\n",
      "[1500]\ttraining's rmse: 0.0854194\tvalid_1's rmse: 0.0894478\n",
      "[1525]\ttraining's rmse: 0.0854053\tvalid_1's rmse: 0.0894455\n",
      "[1550]\ttraining's rmse: 0.0853943\tvalid_1's rmse: 0.0894437\n",
      "[1575]\ttraining's rmse: 0.0853816\tvalid_1's rmse: 0.0894418\n",
      "[1600]\ttraining's rmse: 0.0853727\tvalid_1's rmse: 0.089439\n",
      "[1625]\ttraining's rmse: 0.0853643\tvalid_1's rmse: 0.0894367\n",
      "[1650]\ttraining's rmse: 0.0853536\tvalid_1's rmse: 0.0894346\n",
      "[1675]\ttraining's rmse: 0.0853453\tvalid_1's rmse: 0.0894319\n",
      "[1700]\ttraining's rmse: 0.0853372\tvalid_1's rmse: 0.0894297\n",
      "[1725]\ttraining's rmse: 0.0853301\tvalid_1's rmse: 0.0894274\n",
      "[1750]\ttraining's rmse: 0.0853216\tvalid_1's rmse: 0.089425\n",
      "[1775]\ttraining's rmse: 0.0853158\tvalid_1's rmse: 0.0894239\n",
      "[1800]\ttraining's rmse: 0.0853074\tvalid_1's rmse: 0.0894217\n",
      "[1825]\ttraining's rmse: 0.0853008\tvalid_1's rmse: 0.0894194\n",
      "[1850]\ttraining's rmse: 0.0852951\tvalid_1's rmse: 0.0894173\n",
      "[1875]\ttraining's rmse: 0.08529\tvalid_1's rmse: 0.0894156\n",
      "[1900]\ttraining's rmse: 0.0852837\tvalid_1's rmse: 0.0894146\n",
      "[1925]\ttraining's rmse: 0.0852784\tvalid_1's rmse: 0.0894126\n",
      "[1950]\ttraining's rmse: 0.085274\tvalid_1's rmse: 0.0894114\n",
      "[1975]\ttraining's rmse: 0.0852678\tvalid_1's rmse: 0.0894096\n",
      "[2000]\ttraining's rmse: 0.0852637\tvalid_1's rmse: 0.0894093\n",
      "[2025]\ttraining's rmse: 0.0852594\tvalid_1's rmse: 0.0894076\n",
      "[2050]\ttraining's rmse: 0.0852544\tvalid_1's rmse: 0.0894056\n",
      "[2075]\ttraining's rmse: 0.0852512\tvalid_1's rmse: 0.0894046\n",
      "[2100]\ttraining's rmse: 0.0852467\tvalid_1's rmse: 0.0894036\n",
      "[2125]\ttraining's rmse: 0.0852442\tvalid_1's rmse: 0.0894037\n",
      "[2150]\ttraining's rmse: 0.0852413\tvalid_1's rmse: 0.0894026\n",
      "[2175]\ttraining's rmse: 0.0852378\tvalid_1's rmse: 0.089402\n",
      "[2200]\ttraining's rmse: 0.0852348\tvalid_1's rmse: 0.0894012\n",
      "[2225]\ttraining's rmse: 0.0852316\tvalid_1's rmse: 0.0894005\n",
      "[2250]\ttraining's rmse: 0.0852269\tvalid_1's rmse: 0.0893996\n",
      "[2275]\ttraining's rmse: 0.0852213\tvalid_1's rmse: 0.0893985\n",
      "[2300]\ttraining's rmse: 0.0852179\tvalid_1's rmse: 0.0893977\n",
      "[2325]\ttraining's rmse: 0.0852144\tvalid_1's rmse: 0.0893972\n",
      "[2350]\ttraining's rmse: 0.0852103\tvalid_1's rmse: 0.089395\n",
      "[2375]\ttraining's rmse: 0.0852078\tvalid_1's rmse: 0.0893939\n",
      "[2400]\ttraining's rmse: 0.0852043\tvalid_1's rmse: 0.0893936\n",
      "[2425]\ttraining's rmse: 0.085201\tvalid_1's rmse: 0.089393\n",
      "[2450]\ttraining's rmse: 0.0851987\tvalid_1's rmse: 0.089392\n",
      "[2475]\ttraining's rmse: 0.0851955\tvalid_1's rmse: 0.0893915\n",
      "[2500]\ttraining's rmse: 0.0851926\tvalid_1's rmse: 0.0893913\n",
      "[2525]\ttraining's rmse: 0.0851896\tvalid_1's rmse: 0.0893908\n",
      "[2550]\ttraining's rmse: 0.0851872\tvalid_1's rmse: 0.0893902\n",
      "[2575]\ttraining's rmse: 0.0851856\tvalid_1's rmse: 0.0893893\n",
      "[2600]\ttraining's rmse: 0.0851823\tvalid_1's rmse: 0.089389\n",
      "[2625]\ttraining's rmse: 0.0851804\tvalid_1's rmse: 0.0893887\n",
      "[2650]\ttraining's rmse: 0.0851791\tvalid_1's rmse: 0.0893878\n",
      "[2675]\ttraining's rmse: 0.0851772\tvalid_1's rmse: 0.089387\n",
      "[2700]\ttraining's rmse: 0.085174\tvalid_1's rmse: 0.0893864\n",
      "[2725]\ttraining's rmse: 0.0851722\tvalid_1's rmse: 0.089386\n",
      "[2750]\ttraining's rmse: 0.08517\tvalid_1's rmse: 0.0893857\n",
      "[2775]\ttraining's rmse: 0.0851682\tvalid_1's rmse: 0.089385\n",
      "[2800]\ttraining's rmse: 0.0851662\tvalid_1's rmse: 0.0893842\n",
      "[2825]\ttraining's rmse: 0.0851645\tvalid_1's rmse: 0.0893837\n",
      "[2850]\ttraining's rmse: 0.0851614\tvalid_1's rmse: 0.0893836\n",
      "[2875]\ttraining's rmse: 0.0851596\tvalid_1's rmse: 0.0893831\n",
      "[2900]\ttraining's rmse: 0.0851586\tvalid_1's rmse: 0.0893832\n",
      "[2925]\ttraining's rmse: 0.0851574\tvalid_1's rmse: 0.0893827\n",
      "[2950]\ttraining's rmse: 0.0851559\tvalid_1's rmse: 0.0893824\n",
      "[2975]\ttraining's rmse: 0.0851532\tvalid_1's rmse: 0.0893815\n",
      "[3000]\ttraining's rmse: 0.0851515\tvalid_1's rmse: 0.0893814\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0851515\tvalid_1's rmse: 0.0893814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0887392\tvalid_1's rmse: 0.0908354\n",
      "[50]\ttraining's rmse: 0.0885724\tvalid_1's rmse: 0.0907817\n",
      "[75]\ttraining's rmse: 0.0884046\tvalid_1's rmse: 0.0907271\n",
      "[100]\ttraining's rmse: 0.0882531\tvalid_1's rmse: 0.0906781\n",
      "[125]\ttraining's rmse: 0.0880987\tvalid_1's rmse: 0.0906291\n",
      "[150]\ttraining's rmse: 0.0879577\tvalid_1's rmse: 0.0905844\n",
      "[175]\ttraining's rmse: 0.0878374\tvalid_1's rmse: 0.0905471\n",
      "[200]\ttraining's rmse: 0.0877087\tvalid_1's rmse: 0.0905075\n",
      "[225]\ttraining's rmse: 0.0875883\tvalid_1's rmse: 0.0904701\n",
      "[250]\ttraining's rmse: 0.0874836\tvalid_1's rmse: 0.0904378\n",
      "[275]\ttraining's rmse: 0.0873858\tvalid_1's rmse: 0.0904069\n",
      "[300]\ttraining's rmse: 0.0872941\tvalid_1's rmse: 0.0903789\n",
      "[325]\ttraining's rmse: 0.0872007\tvalid_1's rmse: 0.0903515\n",
      "[350]\ttraining's rmse: 0.0871114\tvalid_1's rmse: 0.0903259\n",
      "[375]\ttraining's rmse: 0.0870385\tvalid_1's rmse: 0.0903035\n",
      "[400]\ttraining's rmse: 0.0869589\tvalid_1's rmse: 0.0902817\n",
      "[425]\ttraining's rmse: 0.0868889\tvalid_1's rmse: 0.0902617\n",
      "[450]\ttraining's rmse: 0.0868237\tvalid_1's rmse: 0.0902425\n",
      "[475]\ttraining's rmse: 0.0867621\tvalid_1's rmse: 0.0902246\n",
      "[500]\ttraining's rmse: 0.0867082\tvalid_1's rmse: 0.0902069\n",
      "[525]\ttraining's rmse: 0.0866436\tvalid_1's rmse: 0.0901898\n",
      "[550]\ttraining's rmse: 0.0865858\tvalid_1's rmse: 0.0901745\n",
      "[575]\ttraining's rmse: 0.0865321\tvalid_1's rmse: 0.0901605\n",
      "[600]\ttraining's rmse: 0.08648\tvalid_1's rmse: 0.0901462\n",
      "[625]\ttraining's rmse: 0.0864353\tvalid_1's rmse: 0.0901326\n",
      "[650]\ttraining's rmse: 0.086383\tvalid_1's rmse: 0.0901196\n",
      "[675]\ttraining's rmse: 0.0863365\tvalid_1's rmse: 0.0901071\n",
      "[700]\ttraining's rmse: 0.0862932\tvalid_1's rmse: 0.0900946\n",
      "[725]\ttraining's rmse: 0.0862522\tvalid_1's rmse: 0.0900848\n",
      "[750]\ttraining's rmse: 0.0862139\tvalid_1's rmse: 0.0900748\n",
      "[775]\ttraining's rmse: 0.0861815\tvalid_1's rmse: 0.0900654\n",
      "[800]\ttraining's rmse: 0.0861391\tvalid_1's rmse: 0.0900577\n",
      "[825]\ttraining's rmse: 0.0861065\tvalid_1's rmse: 0.0900486\n",
      "[850]\ttraining's rmse: 0.0860729\tvalid_1's rmse: 0.0900415\n",
      "[875]\ttraining's rmse: 0.0860422\tvalid_1's rmse: 0.090034\n",
      "[900]\ttraining's rmse: 0.0860089\tvalid_1's rmse: 0.0900259\n",
      "[925]\ttraining's rmse: 0.08598\tvalid_1's rmse: 0.0900191\n",
      "[950]\ttraining's rmse: 0.0859515\tvalid_1's rmse: 0.0900133\n",
      "[975]\ttraining's rmse: 0.0859252\tvalid_1's rmse: 0.0900075\n",
      "[1000]\ttraining's rmse: 0.0859001\tvalid_1's rmse: 0.0900026\n",
      "[1025]\ttraining's rmse: 0.0858701\tvalid_1's rmse: 0.0899979\n",
      "[1050]\ttraining's rmse: 0.0858471\tvalid_1's rmse: 0.089994\n",
      "[1075]\ttraining's rmse: 0.0858229\tvalid_1's rmse: 0.0899905\n",
      "[1100]\ttraining's rmse: 0.0858041\tvalid_1's rmse: 0.0899861\n",
      "[1125]\ttraining's rmse: 0.0857811\tvalid_1's rmse: 0.0899815\n",
      "[1150]\ttraining's rmse: 0.0857578\tvalid_1's rmse: 0.0899776\n",
      "[1175]\ttraining's rmse: 0.0857405\tvalid_1's rmse: 0.0899746\n",
      "[1200]\ttraining's rmse: 0.0857197\tvalid_1's rmse: 0.0899707\n",
      "[1225]\ttraining's rmse: 0.0857013\tvalid_1's rmse: 0.0899677\n",
      "[1250]\ttraining's rmse: 0.0856858\tvalid_1's rmse: 0.0899651\n",
      "[1275]\ttraining's rmse: 0.085663\tvalid_1's rmse: 0.0899629\n",
      "[1300]\ttraining's rmse: 0.0856486\tvalid_1's rmse: 0.0899606\n",
      "[1325]\ttraining's rmse: 0.085633\tvalid_1's rmse: 0.0899586\n",
      "[1350]\ttraining's rmse: 0.0856133\tvalid_1's rmse: 0.0899569\n",
      "[1375]\ttraining's rmse: 0.0855976\tvalid_1's rmse: 0.0899545\n",
      "[1400]\ttraining's rmse: 0.0855848\tvalid_1's rmse: 0.0899521\n",
      "[1425]\ttraining's rmse: 0.0855702\tvalid_1's rmse: 0.0899509\n",
      "[1450]\ttraining's rmse: 0.0855532\tvalid_1's rmse: 0.0899494\n",
      "[1475]\ttraining's rmse: 0.0855428\tvalid_1's rmse: 0.0899476\n",
      "[1500]\ttraining's rmse: 0.0855297\tvalid_1's rmse: 0.0899456\n",
      "[1525]\ttraining's rmse: 0.0855169\tvalid_1's rmse: 0.0899444\n",
      "[1550]\ttraining's rmse: 0.0855061\tvalid_1's rmse: 0.0899443\n",
      "[1575]\ttraining's rmse: 0.0854963\tvalid_1's rmse: 0.089943\n",
      "[1600]\ttraining's rmse: 0.085487\tvalid_1's rmse: 0.0899414\n",
      "[1625]\ttraining's rmse: 0.0854773\tvalid_1's rmse: 0.08994\n",
      "[1650]\ttraining's rmse: 0.0854691\tvalid_1's rmse: 0.0899397\n",
      "[1675]\ttraining's rmse: 0.0854611\tvalid_1's rmse: 0.0899383\n",
      "[1700]\ttraining's rmse: 0.0854544\tvalid_1's rmse: 0.0899368\n",
      "[1725]\ttraining's rmse: 0.0854443\tvalid_1's rmse: 0.0899355\n",
      "[1750]\ttraining's rmse: 0.0854355\tvalid_1's rmse: 0.0899346\n",
      "[1775]\ttraining's rmse: 0.0854285\tvalid_1's rmse: 0.0899339\n",
      "[1800]\ttraining's rmse: 0.0854212\tvalid_1's rmse: 0.0899338\n",
      "[1825]\ttraining's rmse: 0.085413\tvalid_1's rmse: 0.0899328\n",
      "[1850]\ttraining's rmse: 0.0854069\tvalid_1's rmse: 0.0899318\n",
      "[1875]\ttraining's rmse: 0.0853997\tvalid_1's rmse: 0.0899311\n",
      "[1900]\ttraining's rmse: 0.0853945\tvalid_1's rmse: 0.0899303\n",
      "[1925]\ttraining's rmse: 0.0853896\tvalid_1's rmse: 0.0899294\n",
      "[1950]\ttraining's rmse: 0.0853853\tvalid_1's rmse: 0.0899287\n",
      "[1975]\ttraining's rmse: 0.0853804\tvalid_1's rmse: 0.0899285\n",
      "[2000]\ttraining's rmse: 0.0853741\tvalid_1's rmse: 0.0899276\n",
      "[2025]\ttraining's rmse: 0.0853694\tvalid_1's rmse: 0.0899269\n",
      "[2050]\ttraining's rmse: 0.0853631\tvalid_1's rmse: 0.0899267\n",
      "[2075]\ttraining's rmse: 0.0853596\tvalid_1's rmse: 0.0899257\n",
      "[2100]\ttraining's rmse: 0.0853562\tvalid_1's rmse: 0.0899255\n",
      "[2125]\ttraining's rmse: 0.0853514\tvalid_1's rmse: 0.0899255\n",
      "[2150]\ttraining's rmse: 0.0853477\tvalid_1's rmse: 0.0899254\n",
      "[2175]\ttraining's rmse: 0.085345\tvalid_1's rmse: 0.0899249\n",
      "[2200]\ttraining's rmse: 0.0853401\tvalid_1's rmse: 0.089924\n",
      "[2225]\ttraining's rmse: 0.0853363\tvalid_1's rmse: 0.0899237\n",
      "[2250]\ttraining's rmse: 0.0853335\tvalid_1's rmse: 0.0899234\n",
      "[2275]\ttraining's rmse: 0.0853302\tvalid_1's rmse: 0.0899232\n",
      "[2300]\ttraining's rmse: 0.0853272\tvalid_1's rmse: 0.0899229\n",
      "[2325]\ttraining's rmse: 0.0853237\tvalid_1's rmse: 0.0899226\n",
      "[2350]\ttraining's rmse: 0.08532\tvalid_1's rmse: 0.0899226\n",
      "[2375]\ttraining's rmse: 0.0853177\tvalid_1's rmse: 0.0899227\n",
      "Early stopping, best iteration is:\n",
      "[2327]\ttraining's rmse: 0.0853236\tvalid_1's rmse: 0.0899225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0904447\tvalid_1's rmse: 0.0874394\n",
      "[50]\ttraining's rmse: 0.0903151\tvalid_1's rmse: 0.0873907\n",
      "[75]\ttraining's rmse: 0.0901744\tvalid_1's rmse: 0.0873396\n",
      "[100]\ttraining's rmse: 0.0900455\tvalid_1's rmse: 0.0872969\n",
      "[125]\ttraining's rmse: 0.0899164\tvalid_1's rmse: 0.0872543\n",
      "[150]\ttraining's rmse: 0.0897971\tvalid_1's rmse: 0.0872151\n",
      "[175]\ttraining's rmse: 0.0896944\tvalid_1's rmse: 0.0871839\n",
      "[200]\ttraining's rmse: 0.0895835\tvalid_1's rmse: 0.0871508\n",
      "[225]\ttraining's rmse: 0.089477\tvalid_1's rmse: 0.0871189\n",
      "[250]\ttraining's rmse: 0.0893872\tvalid_1's rmse: 0.0870922\n",
      "[275]\ttraining's rmse: 0.0893042\tvalid_1's rmse: 0.0870677\n",
      "[300]\ttraining's rmse: 0.0892212\tvalid_1's rmse: 0.0870448\n",
      "[325]\ttraining's rmse: 0.0891359\tvalid_1's rmse: 0.0870237\n",
      "[350]\ttraining's rmse: 0.0890552\tvalid_1's rmse: 0.0870022\n",
      "[375]\ttraining's rmse: 0.0889885\tvalid_1's rmse: 0.0869849\n",
      "[400]\ttraining's rmse: 0.0889158\tvalid_1's rmse: 0.0869672\n",
      "[425]\ttraining's rmse: 0.0888501\tvalid_1's rmse: 0.0869559\n",
      "[450]\ttraining's rmse: 0.0887881\tvalid_1's rmse: 0.08694\n",
      "[475]\ttraining's rmse: 0.0887284\tvalid_1's rmse: 0.0869303\n",
      "[500]\ttraining's rmse: 0.0886809\tvalid_1's rmse: 0.0869183\n",
      "[525]\ttraining's rmse: 0.0886176\tvalid_1's rmse: 0.086905\n",
      "[550]\ttraining's rmse: 0.088562\tvalid_1's rmse: 0.0868939\n",
      "[575]\ttraining's rmse: 0.088506\tvalid_1's rmse: 0.0868839\n",
      "[600]\ttraining's rmse: 0.0884542\tvalid_1's rmse: 0.0868806\n",
      "[625]\ttraining's rmse: 0.0884126\tvalid_1's rmse: 0.0868812\n",
      "[650]\ttraining's rmse: 0.0883617\tvalid_1's rmse: 0.0868776\n",
      "[675]\ttraining's rmse: 0.08831\tvalid_1's rmse: 0.0868798\n",
      "[700]\ttraining's rmse: 0.0882628\tvalid_1's rmse: 0.0868802\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's rmse: 0.0883533\tvalid_1's rmse: 0.0868765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0849055\tvalid_1's rmse: 0.0875387\n",
      "[50]\ttraining's rmse: 0.0847721\tvalid_1's rmse: 0.0874821\n",
      "[75]\ttraining's rmse: 0.0846374\tvalid_1's rmse: 0.0874259\n",
      "[100]\ttraining's rmse: 0.0845169\tvalid_1's rmse: 0.0873766\n",
      "[125]\ttraining's rmse: 0.084392\tvalid_1's rmse: 0.0873286\n",
      "[150]\ttraining's rmse: 0.0842803\tvalid_1's rmse: 0.0872827\n",
      "[175]\ttraining's rmse: 0.0841839\tvalid_1's rmse: 0.0872431\n",
      "[200]\ttraining's rmse: 0.0840819\tvalid_1's rmse: 0.0872024\n",
      "[225]\ttraining's rmse: 0.0839829\tvalid_1's rmse: 0.0871653\n",
      "[250]\ttraining's rmse: 0.083899\tvalid_1's rmse: 0.0871303\n",
      "[275]\ttraining's rmse: 0.0838184\tvalid_1's rmse: 0.0870991\n",
      "[300]\ttraining's rmse: 0.0837396\tvalid_1's rmse: 0.0870696\n",
      "[325]\ttraining's rmse: 0.0836618\tvalid_1's rmse: 0.0870415\n",
      "[350]\ttraining's rmse: 0.0835899\tvalid_1's rmse: 0.0870162\n",
      "[375]\ttraining's rmse: 0.0835266\tvalid_1's rmse: 0.0869929\n",
      "[400]\ttraining's rmse: 0.0834576\tvalid_1's rmse: 0.0869689\n",
      "[425]\ttraining's rmse: 0.0833979\tvalid_1's rmse: 0.086947\n",
      "[450]\ttraining's rmse: 0.0833403\tvalid_1's rmse: 0.0869261\n",
      "[475]\ttraining's rmse: 0.0832887\tvalid_1's rmse: 0.0869083\n",
      "[500]\ttraining's rmse: 0.0832444\tvalid_1's rmse: 0.0868916\n",
      "[525]\ttraining's rmse: 0.0831919\tvalid_1's rmse: 0.0868753\n",
      "[550]\ttraining's rmse: 0.0831426\tvalid_1's rmse: 0.0868608\n",
      "[575]\ttraining's rmse: 0.0830969\tvalid_1's rmse: 0.0868448\n",
      "[600]\ttraining's rmse: 0.0830535\tvalid_1's rmse: 0.0868296\n",
      "[625]\ttraining's rmse: 0.083019\tvalid_1's rmse: 0.0868182\n",
      "[650]\ttraining's rmse: 0.0829764\tvalid_1's rmse: 0.0868058\n",
      "[675]\ttraining's rmse: 0.0829312\tvalid_1's rmse: 0.0867905\n",
      "[700]\ttraining's rmse: 0.0828944\tvalid_1's rmse: 0.08678\n",
      "[725]\ttraining's rmse: 0.0828571\tvalid_1's rmse: 0.0867696\n",
      "[750]\ttraining's rmse: 0.0828225\tvalid_1's rmse: 0.0867608\n",
      "[775]\ttraining's rmse: 0.0827955\tvalid_1's rmse: 0.086751\n",
      "[800]\ttraining's rmse: 0.0827613\tvalid_1's rmse: 0.086743\n",
      "[825]\ttraining's rmse: 0.0827292\tvalid_1's rmse: 0.0867322\n",
      "[850]\ttraining's rmse: 0.0826981\tvalid_1's rmse: 0.0867252\n",
      "[875]\ttraining's rmse: 0.0826708\tvalid_1's rmse: 0.0867162\n",
      "[900]\ttraining's rmse: 0.0826405\tvalid_1's rmse: 0.0867075\n",
      "[925]\ttraining's rmse: 0.0826138\tvalid_1's rmse: 0.086699\n",
      "[950]\ttraining's rmse: 0.0825898\tvalid_1's rmse: 0.0866914\n",
      "[975]\ttraining's rmse: 0.0825653\tvalid_1's rmse: 0.0866845\n",
      "[1000]\ttraining's rmse: 0.0825404\tvalid_1's rmse: 0.0866785\n",
      "[1025]\ttraining's rmse: 0.0825178\tvalid_1's rmse: 0.0866701\n",
      "[1050]\ttraining's rmse: 0.0824974\tvalid_1's rmse: 0.086663\n",
      "[1075]\ttraining's rmse: 0.0824775\tvalid_1's rmse: 0.0866581\n",
      "[1100]\ttraining's rmse: 0.0824604\tvalid_1's rmse: 0.0866526\n",
      "[1125]\ttraining's rmse: 0.0824425\tvalid_1's rmse: 0.0866466\n",
      "[1150]\ttraining's rmse: 0.0824215\tvalid_1's rmse: 0.086641\n",
      "[1175]\ttraining's rmse: 0.0824033\tvalid_1's rmse: 0.0866375\n",
      "[1200]\ttraining's rmse: 0.0823875\tvalid_1's rmse: 0.0866332\n",
      "[1225]\ttraining's rmse: 0.0823718\tvalid_1's rmse: 0.0866265\n",
      "[1250]\ttraining's rmse: 0.0823563\tvalid_1's rmse: 0.0866225\n",
      "[1275]\ttraining's rmse: 0.0823393\tvalid_1's rmse: 0.0866193\n",
      "[1300]\ttraining's rmse: 0.0823259\tvalid_1's rmse: 0.086615\n",
      "[1325]\ttraining's rmse: 0.0823142\tvalid_1's rmse: 0.0866119\n",
      "[1350]\ttraining's rmse: 0.0823004\tvalid_1's rmse: 0.0866085\n",
      "[1375]\ttraining's rmse: 0.0822877\tvalid_1's rmse: 0.086605\n",
      "[1400]\ttraining's rmse: 0.0822754\tvalid_1's rmse: 0.0866014\n",
      "[1425]\ttraining's rmse: 0.0822628\tvalid_1's rmse: 0.0865994\n",
      "[1450]\ttraining's rmse: 0.0822515\tvalid_1's rmse: 0.0865967\n",
      "[1475]\ttraining's rmse: 0.0822405\tvalid_1's rmse: 0.0865931\n",
      "[1500]\ttraining's rmse: 0.0822311\tvalid_1's rmse: 0.0865908\n",
      "[1525]\ttraining's rmse: 0.0822225\tvalid_1's rmse: 0.0865887\n",
      "[1550]\ttraining's rmse: 0.0822123\tvalid_1's rmse: 0.086586\n",
      "[1575]\ttraining's rmse: 0.0822047\tvalid_1's rmse: 0.0865839\n",
      "[1600]\ttraining's rmse: 0.0821961\tvalid_1's rmse: 0.0865813\n",
      "[1625]\ttraining's rmse: 0.0821863\tvalid_1's rmse: 0.0865776\n",
      "[1650]\ttraining's rmse: 0.0821767\tvalid_1's rmse: 0.0865742\n",
      "[1675]\ttraining's rmse: 0.0821696\tvalid_1's rmse: 0.0865717\n",
      "[1700]\ttraining's rmse: 0.0821627\tvalid_1's rmse: 0.0865684\n",
      "[1725]\ttraining's rmse: 0.082157\tvalid_1's rmse: 0.0865667\n",
      "[1750]\ttraining's rmse: 0.0821516\tvalid_1's rmse: 0.086565\n",
      "[1775]\ttraining's rmse: 0.0821447\tvalid_1's rmse: 0.0865628\n",
      "[1800]\ttraining's rmse: 0.0821383\tvalid_1's rmse: 0.0865611\n",
      "[1825]\ttraining's rmse: 0.0821319\tvalid_1's rmse: 0.0865587\n",
      "[1850]\ttraining's rmse: 0.0821248\tvalid_1's rmse: 0.0865555\n",
      "[1875]\ttraining's rmse: 0.0821198\tvalid_1's rmse: 0.0865539\n",
      "[1900]\ttraining's rmse: 0.0821156\tvalid_1's rmse: 0.086554\n",
      "[1925]\ttraining's rmse: 0.0821121\tvalid_1's rmse: 0.0865533\n",
      "[1950]\ttraining's rmse: 0.0821065\tvalid_1's rmse: 0.0865524\n",
      "[1975]\ttraining's rmse: 0.0821021\tvalid_1's rmse: 0.0865508\n",
      "[2000]\ttraining's rmse: 0.0820976\tvalid_1's rmse: 0.0865499\n",
      "[2025]\ttraining's rmse: 0.0820934\tvalid_1's rmse: 0.0865481\n",
      "[2050]\ttraining's rmse: 0.08209\tvalid_1's rmse: 0.0865473\n",
      "[2075]\ttraining's rmse: 0.0820858\tvalid_1's rmse: 0.0865456\n",
      "[2100]\ttraining's rmse: 0.0820817\tvalid_1's rmse: 0.0865445\n",
      "[2125]\ttraining's rmse: 0.0820788\tvalid_1's rmse: 0.0865442\n",
      "[2150]\ttraining's rmse: 0.0820751\tvalid_1's rmse: 0.0865425\n",
      "[2175]\ttraining's rmse: 0.0820724\tvalid_1's rmse: 0.0865409\n",
      "[2200]\ttraining's rmse: 0.0820702\tvalid_1's rmse: 0.0865403\n",
      "[2225]\ttraining's rmse: 0.082067\tvalid_1's rmse: 0.0865392\n",
      "[2250]\ttraining's rmse: 0.082064\tvalid_1's rmse: 0.0865382\n",
      "[2275]\ttraining's rmse: 0.0820607\tvalid_1's rmse: 0.0865379\n",
      "[2300]\ttraining's rmse: 0.082058\tvalid_1's rmse: 0.0865374\n",
      "[2325]\ttraining's rmse: 0.0820549\tvalid_1's rmse: 0.0865362\n",
      "[2350]\ttraining's rmse: 0.0820531\tvalid_1's rmse: 0.086536\n",
      "[2375]\ttraining's rmse: 0.0820502\tvalid_1's rmse: 0.0865354\n",
      "[2400]\ttraining's rmse: 0.0820474\tvalid_1's rmse: 0.0865354\n",
      "[2425]\ttraining's rmse: 0.0820458\tvalid_1's rmse: 0.0865348\n",
      "[2450]\ttraining's rmse: 0.0820429\tvalid_1's rmse: 0.0865341\n",
      "[2475]\ttraining's rmse: 0.0820391\tvalid_1's rmse: 0.0865331\n",
      "[2500]\ttraining's rmse: 0.0820361\tvalid_1's rmse: 0.086532\n",
      "[2525]\ttraining's rmse: 0.0820342\tvalid_1's rmse: 0.0865322\n",
      "Early stopping, best iteration is:\n",
      "[2497]\ttraining's rmse: 0.0820362\tvalid_1's rmse: 0.0865318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0851507\tvalid_1's rmse: 0.087063\n",
      "[50]\ttraining's rmse: 0.0850277\tvalid_1's rmse: 0.0870063\n",
      "[75]\ttraining's rmse: 0.0849017\tvalid_1's rmse: 0.0869505\n",
      "[100]\ttraining's rmse: 0.084789\tvalid_1's rmse: 0.0869001\n",
      "[125]\ttraining's rmse: 0.0846698\tvalid_1's rmse: 0.0868476\n",
      "[150]\ttraining's rmse: 0.0845634\tvalid_1's rmse: 0.0868026\n",
      "[175]\ttraining's rmse: 0.0844753\tvalid_1's rmse: 0.0867656\n",
      "[200]\ttraining's rmse: 0.0843787\tvalid_1's rmse: 0.0867277\n",
      "[225]\ttraining's rmse: 0.084288\tvalid_1's rmse: 0.0866936\n",
      "[250]\ttraining's rmse: 0.0842095\tvalid_1's rmse: 0.0866606\n",
      "[275]\ttraining's rmse: 0.0841327\tvalid_1's rmse: 0.0866301\n",
      "[300]\ttraining's rmse: 0.0840562\tvalid_1's rmse: 0.0866006\n",
      "[325]\ttraining's rmse: 0.0839829\tvalid_1's rmse: 0.0865732\n",
      "[350]\ttraining's rmse: 0.0839083\tvalid_1's rmse: 0.0865473\n",
      "[375]\ttraining's rmse: 0.0838503\tvalid_1's rmse: 0.0865244\n",
      "[400]\ttraining's rmse: 0.0837849\tvalid_1's rmse: 0.0865009\n",
      "[425]\ttraining's rmse: 0.0837241\tvalid_1's rmse: 0.08648\n",
      "[450]\ttraining's rmse: 0.0836689\tvalid_1's rmse: 0.0864605\n",
      "[475]\ttraining's rmse: 0.0836168\tvalid_1's rmse: 0.0864427\n",
      "[500]\ttraining's rmse: 0.0835715\tvalid_1's rmse: 0.0864265\n",
      "[525]\ttraining's rmse: 0.0835164\tvalid_1's rmse: 0.0864102\n",
      "[550]\ttraining's rmse: 0.0834624\tvalid_1's rmse: 0.0863947\n",
      "[575]\ttraining's rmse: 0.0834137\tvalid_1's rmse: 0.0863814\n",
      "[600]\ttraining's rmse: 0.0833697\tvalid_1's rmse: 0.0863674\n",
      "[625]\ttraining's rmse: 0.0833342\tvalid_1's rmse: 0.0863561\n",
      "[650]\ttraining's rmse: 0.0832906\tvalid_1's rmse: 0.0863433\n",
      "[675]\ttraining's rmse: 0.0832438\tvalid_1's rmse: 0.0863314\n",
      "[700]\ttraining's rmse: 0.0832057\tvalid_1's rmse: 0.0863213\n",
      "[725]\ttraining's rmse: 0.0831705\tvalid_1's rmse: 0.086311\n",
      "[750]\ttraining's rmse: 0.0831364\tvalid_1's rmse: 0.0863017\n",
      "[775]\ttraining's rmse: 0.0831061\tvalid_1's rmse: 0.0862926\n",
      "[800]\ttraining's rmse: 0.0830709\tvalid_1's rmse: 0.0862843\n",
      "[825]\ttraining's rmse: 0.083039\tvalid_1's rmse: 0.0862751\n",
      "[850]\ttraining's rmse: 0.0830092\tvalid_1's rmse: 0.0862691\n",
      "[875]\ttraining's rmse: 0.0829795\tvalid_1's rmse: 0.0862622\n",
      "[900]\ttraining's rmse: 0.0829492\tvalid_1's rmse: 0.0862553\n",
      "[925]\ttraining's rmse: 0.0829199\tvalid_1's rmse: 0.0862492\n",
      "[950]\ttraining's rmse: 0.0828939\tvalid_1's rmse: 0.0862435\n",
      "[975]\ttraining's rmse: 0.0828698\tvalid_1's rmse: 0.0862385\n",
      "[1000]\ttraining's rmse: 0.0828472\tvalid_1's rmse: 0.086233\n",
      "[1025]\ttraining's rmse: 0.0828205\tvalid_1's rmse: 0.0862288\n",
      "[1050]\ttraining's rmse: 0.0827994\tvalid_1's rmse: 0.0862242\n",
      "[1075]\ttraining's rmse: 0.0827782\tvalid_1's rmse: 0.0862215\n",
      "[1100]\ttraining's rmse: 0.0827614\tvalid_1's rmse: 0.0862176\n",
      "[1125]\ttraining's rmse: 0.0827405\tvalid_1's rmse: 0.0862137\n",
      "[1150]\ttraining's rmse: 0.0827215\tvalid_1's rmse: 0.0862099\n",
      "[1175]\ttraining's rmse: 0.0827037\tvalid_1's rmse: 0.0862074\n",
      "[1200]\ttraining's rmse: 0.0826856\tvalid_1's rmse: 0.0862037\n",
      "[1225]\ttraining's rmse: 0.0826687\tvalid_1's rmse: 0.0862006\n",
      "[1250]\ttraining's rmse: 0.0826546\tvalid_1's rmse: 0.0861979\n",
      "[1275]\ttraining's rmse: 0.0826367\tvalid_1's rmse: 0.0861955\n",
      "[1300]\ttraining's rmse: 0.0826221\tvalid_1's rmse: 0.0861932\n",
      "[1325]\ttraining's rmse: 0.0826087\tvalid_1's rmse: 0.0861907\n",
      "[1350]\ttraining's rmse: 0.0825963\tvalid_1's rmse: 0.0861894\n",
      "[1375]\ttraining's rmse: 0.0825836\tvalid_1's rmse: 0.0861883\n",
      "[1400]\ttraining's rmse: 0.0825733\tvalid_1's rmse: 0.086186\n",
      "[1425]\ttraining's rmse: 0.0825591\tvalid_1's rmse: 0.0861843\n",
      "[1450]\ttraining's rmse: 0.082548\tvalid_1's rmse: 0.0861826\n",
      "[1475]\ttraining's rmse: 0.0825356\tvalid_1's rmse: 0.0861811\n",
      "[1500]\ttraining's rmse: 0.0825249\tvalid_1's rmse: 0.08618\n",
      "[1525]\ttraining's rmse: 0.082515\tvalid_1's rmse: 0.0861788\n",
      "[1550]\ttraining's rmse: 0.0825059\tvalid_1's rmse: 0.0861779\n",
      "[1575]\ttraining's rmse: 0.0824963\tvalid_1's rmse: 0.0861765\n",
      "[1600]\ttraining's rmse: 0.0824876\tvalid_1's rmse: 0.0861757\n",
      "[1625]\ttraining's rmse: 0.0824785\tvalid_1's rmse: 0.0861743\n",
      "[1650]\ttraining's rmse: 0.0824689\tvalid_1's rmse: 0.0861733\n",
      "[1675]\ttraining's rmse: 0.082462\tvalid_1's rmse: 0.0861725\n",
      "[1700]\ttraining's rmse: 0.082455\tvalid_1's rmse: 0.0861721\n",
      "[1725]\ttraining's rmse: 0.0824482\tvalid_1's rmse: 0.0861709\n",
      "[1750]\ttraining's rmse: 0.0824408\tvalid_1's rmse: 0.0861698\n",
      "[1775]\ttraining's rmse: 0.0824352\tvalid_1's rmse: 0.0861693\n",
      "[1800]\ttraining's rmse: 0.08243\tvalid_1's rmse: 0.086169\n",
      "[1825]\ttraining's rmse: 0.0824229\tvalid_1's rmse: 0.0861682\n",
      "[1850]\ttraining's rmse: 0.082417\tvalid_1's rmse: 0.0861674\n",
      "[1875]\ttraining's rmse: 0.0824111\tvalid_1's rmse: 0.0861666\n",
      "[1900]\ttraining's rmse: 0.0824069\tvalid_1's rmse: 0.0861664\n",
      "[1925]\ttraining's rmse: 0.0824004\tvalid_1's rmse: 0.0861657\n",
      "[1950]\ttraining's rmse: 0.0823965\tvalid_1's rmse: 0.0861651\n",
      "[1975]\ttraining's rmse: 0.0823927\tvalid_1's rmse: 0.0861644\n",
      "[2000]\ttraining's rmse: 0.0823884\tvalid_1's rmse: 0.0861638\n",
      "[2025]\ttraining's rmse: 0.0823839\tvalid_1's rmse: 0.086163\n",
      "[2050]\ttraining's rmse: 0.0823803\tvalid_1's rmse: 0.0861632\n",
      "[2075]\ttraining's rmse: 0.0823771\tvalid_1's rmse: 0.086163\n",
      "[2100]\ttraining's rmse: 0.0823727\tvalid_1's rmse: 0.0861626\n",
      "[2125]\ttraining's rmse: 0.0823704\tvalid_1's rmse: 0.0861626\n",
      "[2150]\ttraining's rmse: 0.0823662\tvalid_1's rmse: 0.0861629\n",
      "Early stopping, best iteration is:\n",
      "[2102]\ttraining's rmse: 0.0823726\tvalid_1's rmse: 0.0861625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0871811\tvalid_1's rmse: 0.0829479\n",
      "[50]\ttraining's rmse: 0.0870585\tvalid_1's rmse: 0.082896\n",
      "[75]\ttraining's rmse: 0.0869338\tvalid_1's rmse: 0.0828463\n",
      "[100]\ttraining's rmse: 0.0868245\tvalid_1's rmse: 0.082804\n",
      "[125]\ttraining's rmse: 0.0867122\tvalid_1's rmse: 0.0827612\n",
      "[150]\ttraining's rmse: 0.086608\tvalid_1's rmse: 0.0827228\n",
      "[175]\ttraining's rmse: 0.0865224\tvalid_1's rmse: 0.0826913\n",
      "[200]\ttraining's rmse: 0.0864309\tvalid_1's rmse: 0.0826588\n",
      "[225]\ttraining's rmse: 0.0863411\tvalid_1's rmse: 0.082629\n",
      "[250]\ttraining's rmse: 0.0862656\tvalid_1's rmse: 0.0826027\n",
      "[275]\ttraining's rmse: 0.0861954\tvalid_1's rmse: 0.0825772\n",
      "[300]\ttraining's rmse: 0.0861251\tvalid_1's rmse: 0.0825526\n",
      "[325]\ttraining's rmse: 0.0860542\tvalid_1's rmse: 0.0825289\n",
      "[350]\ttraining's rmse: 0.0859821\tvalid_1's rmse: 0.0825073\n",
      "[375]\ttraining's rmse: 0.0859249\tvalid_1's rmse: 0.0824879\n",
      "[400]\ttraining's rmse: 0.0858644\tvalid_1's rmse: 0.0824748\n",
      "[425]\ttraining's rmse: 0.0858071\tvalid_1's rmse: 0.0824591\n",
      "[450]\ttraining's rmse: 0.0857538\tvalid_1's rmse: 0.0824439\n",
      "[475]\ttraining's rmse: 0.0857017\tvalid_1's rmse: 0.0824302\n",
      "[500]\ttraining's rmse: 0.0856594\tvalid_1's rmse: 0.0824165\n",
      "[525]\ttraining's rmse: 0.0856063\tvalid_1's rmse: 0.0824036\n",
      "[550]\ttraining's rmse: 0.0855582\tvalid_1's rmse: 0.0823928\n",
      "[575]\ttraining's rmse: 0.085513\tvalid_1's rmse: 0.082382\n",
      "[600]\ttraining's rmse: 0.0854665\tvalid_1's rmse: 0.0823723\n",
      "[625]\ttraining's rmse: 0.0854327\tvalid_1's rmse: 0.0823678\n",
      "[650]\ttraining's rmse: 0.0853893\tvalid_1's rmse: 0.0823591\n",
      "[675]\ttraining's rmse: 0.085344\tvalid_1's rmse: 0.0823498\n",
      "[700]\ttraining's rmse: 0.085307\tvalid_1's rmse: 0.082341\n",
      "[725]\ttraining's rmse: 0.0852712\tvalid_1's rmse: 0.0823466\n",
      "[750]\ttraining's rmse: 0.0852375\tvalid_1's rmse: 0.0823431\n",
      "[775]\ttraining's rmse: 0.0852079\tvalid_1's rmse: 0.0823423\n",
      "[800]\ttraining's rmse: 0.0851713\tvalid_1's rmse: 0.0823362\n",
      "[825]\ttraining's rmse: 0.0851381\tvalid_1's rmse: 0.0823405\n",
      "[850]\ttraining's rmse: 0.0851066\tvalid_1's rmse: 0.0823387\n",
      "[875]\ttraining's rmse: 0.0850792\tvalid_1's rmse: 0.0823393\n",
      "Early stopping, best iteration is:\n",
      "[849]\ttraining's rmse: 0.0851082\tvalid_1's rmse: 0.0823352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0897026\tvalid_1's rmse: 0.0912601\n",
      "[50]\ttraining's rmse: 0.0895118\tvalid_1's rmse: 0.091209\n",
      "[75]\ttraining's rmse: 0.0893191\tvalid_1's rmse: 0.0911554\n",
      "[100]\ttraining's rmse: 0.0891449\tvalid_1's rmse: 0.0911096\n",
      "[125]\ttraining's rmse: 0.0889727\tvalid_1's rmse: 0.0910612\n",
      "[150]\ttraining's rmse: 0.0888123\tvalid_1's rmse: 0.0910181\n",
      "[175]\ttraining's rmse: 0.0886759\tvalid_1's rmse: 0.0909818\n",
      "[200]\ttraining's rmse: 0.0885311\tvalid_1's rmse: 0.0909456\n",
      "[225]\ttraining's rmse: 0.0883957\tvalid_1's rmse: 0.0909112\n",
      "[250]\ttraining's rmse: 0.0882827\tvalid_1's rmse: 0.0908789\n",
      "[275]\ttraining's rmse: 0.0881765\tvalid_1's rmse: 0.0908485\n",
      "[300]\ttraining's rmse: 0.0880715\tvalid_1's rmse: 0.0908197\n",
      "[325]\ttraining's rmse: 0.0879662\tvalid_1's rmse: 0.0907951\n",
      "[350]\ttraining's rmse: 0.0878669\tvalid_1's rmse: 0.090769\n",
      "[375]\ttraining's rmse: 0.087779\tvalid_1's rmse: 0.0907494\n",
      "[400]\ttraining's rmse: 0.0876857\tvalid_1's rmse: 0.0907269\n",
      "[425]\ttraining's rmse: 0.0876056\tvalid_1's rmse: 0.090707\n",
      "[450]\ttraining's rmse: 0.0875327\tvalid_1's rmse: 0.0906884\n",
      "[475]\ttraining's rmse: 0.0874638\tvalid_1's rmse: 0.0906696\n",
      "[500]\ttraining's rmse: 0.0874022\tvalid_1's rmse: 0.0906517\n",
      "[525]\ttraining's rmse: 0.0873306\tvalid_1's rmse: 0.0906346\n",
      "[550]\ttraining's rmse: 0.0872656\tvalid_1's rmse: 0.0906196\n",
      "[575]\ttraining's rmse: 0.087205\tvalid_1's rmse: 0.0906046\n",
      "[600]\ttraining's rmse: 0.0871463\tvalid_1's rmse: 0.0905895\n",
      "[625]\ttraining's rmse: 0.0870975\tvalid_1's rmse: 0.0905755\n",
      "[650]\ttraining's rmse: 0.0870441\tvalid_1's rmse: 0.0905637\n",
      "[675]\ttraining's rmse: 0.0869923\tvalid_1's rmse: 0.0905521\n",
      "[700]\ttraining's rmse: 0.0869441\tvalid_1's rmse: 0.0905403\n",
      "[725]\ttraining's rmse: 0.0868987\tvalid_1's rmse: 0.0905302\n",
      "[750]\ttraining's rmse: 0.0868535\tvalid_1's rmse: 0.0905201\n",
      "[775]\ttraining's rmse: 0.086818\tvalid_1's rmse: 0.0905098\n",
      "[800]\ttraining's rmse: 0.0867716\tvalid_1's rmse: 0.0904996\n",
      "[825]\ttraining's rmse: 0.0867365\tvalid_1's rmse: 0.0904893\n",
      "[850]\ttraining's rmse: 0.0866959\tvalid_1's rmse: 0.090482\n",
      "[875]\ttraining's rmse: 0.0866648\tvalid_1's rmse: 0.0904751\n",
      "[900]\ttraining's rmse: 0.0866262\tvalid_1's rmse: 0.0904674\n",
      "[925]\ttraining's rmse: 0.0865935\tvalid_1's rmse: 0.0904608\n",
      "[950]\ttraining's rmse: 0.0865633\tvalid_1's rmse: 0.0904534\n",
      "[975]\ttraining's rmse: 0.0865355\tvalid_1's rmse: 0.090446\n",
      "[1000]\ttraining's rmse: 0.0865034\tvalid_1's rmse: 0.0904391\n",
      "[1025]\ttraining's rmse: 0.0864725\tvalid_1's rmse: 0.0904327\n",
      "[1050]\ttraining's rmse: 0.0864445\tvalid_1's rmse: 0.0904273\n",
      "[1075]\ttraining's rmse: 0.0864184\tvalid_1's rmse: 0.0904211\n",
      "[1100]\ttraining's rmse: 0.0863961\tvalid_1's rmse: 0.0904151\n",
      "[1125]\ttraining's rmse: 0.0863737\tvalid_1's rmse: 0.0904077\n",
      "[1150]\ttraining's rmse: 0.0863533\tvalid_1's rmse: 0.0904027\n",
      "[1175]\ttraining's rmse: 0.0863311\tvalid_1's rmse: 0.0903996\n",
      "[1200]\ttraining's rmse: 0.086308\tvalid_1's rmse: 0.0903934\n",
      "[1225]\ttraining's rmse: 0.0862875\tvalid_1's rmse: 0.0903894\n",
      "[1250]\ttraining's rmse: 0.0862691\tvalid_1's rmse: 0.090385\n",
      "[1275]\ttraining's rmse: 0.086247\tvalid_1's rmse: 0.0903802\n",
      "[1300]\ttraining's rmse: 0.0862319\tvalid_1's rmse: 0.0903757\n",
      "[1325]\ttraining's rmse: 0.0862145\tvalid_1's rmse: 0.0903729\n",
      "[1350]\ttraining's rmse: 0.0861967\tvalid_1's rmse: 0.0903693\n",
      "[1375]\ttraining's rmse: 0.0861802\tvalid_1's rmse: 0.0903659\n",
      "[1400]\ttraining's rmse: 0.0861643\tvalid_1's rmse: 0.0903623\n",
      "[1425]\ttraining's rmse: 0.0861492\tvalid_1's rmse: 0.0903593\n",
      "[1450]\ttraining's rmse: 0.0861361\tvalid_1's rmse: 0.0903562\n",
      "[1475]\ttraining's rmse: 0.086127\tvalid_1's rmse: 0.0903539\n",
      "[1500]\ttraining's rmse: 0.0861153\tvalid_1's rmse: 0.0903514\n",
      "[1525]\ttraining's rmse: 0.0861048\tvalid_1's rmse: 0.0903498\n",
      "[1550]\ttraining's rmse: 0.0860922\tvalid_1's rmse: 0.090347\n",
      "[1575]\ttraining's rmse: 0.0860822\tvalid_1's rmse: 0.0903438\n",
      "[1600]\ttraining's rmse: 0.0860739\tvalid_1's rmse: 0.0903421\n",
      "[1625]\ttraining's rmse: 0.0860637\tvalid_1's rmse: 0.0903397\n",
      "[1650]\ttraining's rmse: 0.0860536\tvalid_1's rmse: 0.0903368\n",
      "[1675]\ttraining's rmse: 0.0860456\tvalid_1's rmse: 0.0903338\n",
      "[1700]\ttraining's rmse: 0.0860368\tvalid_1's rmse: 0.0903312\n",
      "[1725]\ttraining's rmse: 0.0860287\tvalid_1's rmse: 0.0903299\n",
      "[1750]\ttraining's rmse: 0.0860203\tvalid_1's rmse: 0.0903274\n",
      "[1775]\ttraining's rmse: 0.0860139\tvalid_1's rmse: 0.0903263\n",
      "[1800]\ttraining's rmse: 0.0860063\tvalid_1's rmse: 0.0903236\n",
      "[1825]\ttraining's rmse: 0.0860008\tvalid_1's rmse: 0.0903226\n",
      "[1850]\ttraining's rmse: 0.0859949\tvalid_1's rmse: 0.0903213\n",
      "[1875]\ttraining's rmse: 0.0859881\tvalid_1's rmse: 0.09032\n",
      "[1900]\ttraining's rmse: 0.0859823\tvalid_1's rmse: 0.0903184\n",
      "[1925]\ttraining's rmse: 0.0859765\tvalid_1's rmse: 0.0903176\n",
      "[1950]\ttraining's rmse: 0.0859718\tvalid_1's rmse: 0.0903161\n",
      "[1975]\ttraining's rmse: 0.085967\tvalid_1's rmse: 0.0903156\n",
      "[2000]\ttraining's rmse: 0.0859623\tvalid_1's rmse: 0.0903148\n",
      "[2025]\ttraining's rmse: 0.0859584\tvalid_1's rmse: 0.0903122\n",
      "[2050]\ttraining's rmse: 0.0859528\tvalid_1's rmse: 0.0903109\n",
      "[2075]\ttraining's rmse: 0.0859502\tvalid_1's rmse: 0.0903101\n",
      "[2100]\ttraining's rmse: 0.0859449\tvalid_1's rmse: 0.0903095\n",
      "[2125]\ttraining's rmse: 0.0859405\tvalid_1's rmse: 0.0903077\n",
      "[2150]\ttraining's rmse: 0.0859347\tvalid_1's rmse: 0.0903055\n",
      "[2175]\ttraining's rmse: 0.0859313\tvalid_1's rmse: 0.0903051\n",
      "[2200]\ttraining's rmse: 0.0859259\tvalid_1's rmse: 0.0903041\n",
      "[2225]\ttraining's rmse: 0.0859228\tvalid_1's rmse: 0.0903026\n",
      "[2250]\ttraining's rmse: 0.0859198\tvalid_1's rmse: 0.090302\n",
      "[2275]\ttraining's rmse: 0.0859152\tvalid_1's rmse: 0.0903012\n",
      "[2300]\ttraining's rmse: 0.0859114\tvalid_1's rmse: 0.0902998\n",
      "[2325]\ttraining's rmse: 0.0859071\tvalid_1's rmse: 0.0902987\n",
      "[2350]\ttraining's rmse: 0.0859044\tvalid_1's rmse: 0.090298\n",
      "[2375]\ttraining's rmse: 0.0859009\tvalid_1's rmse: 0.0902973\n",
      "[2400]\ttraining's rmse: 0.0858968\tvalid_1's rmse: 0.0902963\n",
      "[2425]\ttraining's rmse: 0.0858934\tvalid_1's rmse: 0.0902956\n",
      "[2450]\ttraining's rmse: 0.0858907\tvalid_1's rmse: 0.0902949\n",
      "[2475]\ttraining's rmse: 0.0858863\tvalid_1's rmse: 0.0902948\n",
      "[2500]\ttraining's rmse: 0.0858833\tvalid_1's rmse: 0.0902945\n",
      "[2525]\ttraining's rmse: 0.0858801\tvalid_1's rmse: 0.0902939\n",
      "[2550]\ttraining's rmse: 0.085877\tvalid_1's rmse: 0.0902927\n",
      "[2575]\ttraining's rmse: 0.0858753\tvalid_1's rmse: 0.0902927\n",
      "[2600]\ttraining's rmse: 0.0858735\tvalid_1's rmse: 0.0902925\n",
      "[2625]\ttraining's rmse: 0.0858722\tvalid_1's rmse: 0.0902924\n",
      "[2650]\ttraining's rmse: 0.0858694\tvalid_1's rmse: 0.0902923\n",
      "[2675]\ttraining's rmse: 0.0858673\tvalid_1's rmse: 0.0902922\n",
      "[2700]\ttraining's rmse: 0.085866\tvalid_1's rmse: 0.0902913\n",
      "[2725]\ttraining's rmse: 0.0858633\tvalid_1's rmse: 0.0902915\n",
      "[2750]\ttraining's rmse: 0.0858613\tvalid_1's rmse: 0.0902905\n",
      "[2775]\ttraining's rmse: 0.0858587\tvalid_1's rmse: 0.0902903\n",
      "[2800]\ttraining's rmse: 0.0858569\tvalid_1's rmse: 0.0902899\n",
      "[2825]\ttraining's rmse: 0.0858554\tvalid_1's rmse: 0.0902901\n",
      "[2850]\ttraining's rmse: 0.0858525\tvalid_1's rmse: 0.09029\n",
      "Early stopping, best iteration is:\n",
      "[2801]\ttraining's rmse: 0.0858569\tvalid_1's rmse: 0.0902899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0896933\tvalid_1's rmse: 0.0912957\n",
      "[50]\ttraining's rmse: 0.0895223\tvalid_1's rmse: 0.0912398\n",
      "[75]\ttraining's rmse: 0.0893482\tvalid_1's rmse: 0.0911846\n",
      "[100]\ttraining's rmse: 0.0891893\tvalid_1's rmse: 0.0911368\n",
      "[125]\ttraining's rmse: 0.0890298\tvalid_1's rmse: 0.0910876\n",
      "[150]\ttraining's rmse: 0.0888849\tvalid_1's rmse: 0.0910414\n",
      "[175]\ttraining's rmse: 0.0887621\tvalid_1's rmse: 0.091003\n",
      "[200]\ttraining's rmse: 0.0886314\tvalid_1's rmse: 0.0909645\n",
      "[225]\ttraining's rmse: 0.0885113\tvalid_1's rmse: 0.0909274\n",
      "[250]\ttraining's rmse: 0.0884049\tvalid_1's rmse: 0.0908949\n",
      "[275]\ttraining's rmse: 0.0883039\tvalid_1's rmse: 0.090865\n",
      "[300]\ttraining's rmse: 0.0882067\tvalid_1's rmse: 0.0908385\n",
      "[325]\ttraining's rmse: 0.0881084\tvalid_1's rmse: 0.0908109\n",
      "[350]\ttraining's rmse: 0.0880143\tvalid_1's rmse: 0.0907854\n",
      "[375]\ttraining's rmse: 0.0879398\tvalid_1's rmse: 0.0907631\n",
      "[400]\ttraining's rmse: 0.0878583\tvalid_1's rmse: 0.0907422\n",
      "[425]\ttraining's rmse: 0.0877832\tvalid_1's rmse: 0.0907215\n",
      "[450]\ttraining's rmse: 0.0877157\tvalid_1's rmse: 0.0907033\n",
      "[475]\ttraining's rmse: 0.0876537\tvalid_1's rmse: 0.0906855\n",
      "[500]\ttraining's rmse: 0.0875993\tvalid_1's rmse: 0.0906697\n",
      "[525]\ttraining's rmse: 0.087534\tvalid_1's rmse: 0.0906531\n",
      "[550]\ttraining's rmse: 0.0874737\tvalid_1's rmse: 0.0906383\n",
      "[575]\ttraining's rmse: 0.0874175\tvalid_1's rmse: 0.0906244\n",
      "[600]\ttraining's rmse: 0.0873646\tvalid_1's rmse: 0.0906104\n",
      "[625]\ttraining's rmse: 0.0873206\tvalid_1's rmse: 0.0905982\n",
      "[650]\ttraining's rmse: 0.0872681\tvalid_1's rmse: 0.0905861\n",
      "[675]\ttraining's rmse: 0.0872192\tvalid_1's rmse: 0.0905742\n",
      "[700]\ttraining's rmse: 0.0871726\tvalid_1's rmse: 0.0905618\n",
      "[725]\ttraining's rmse: 0.0871299\tvalid_1's rmse: 0.0905517\n",
      "[750]\ttraining's rmse: 0.0870899\tvalid_1's rmse: 0.0905424\n",
      "[775]\ttraining's rmse: 0.0870548\tvalid_1's rmse: 0.0905328\n",
      "[800]\ttraining's rmse: 0.0870121\tvalid_1's rmse: 0.0905245\n",
      "[825]\ttraining's rmse: 0.0869762\tvalid_1's rmse: 0.0905167\n",
      "[850]\ttraining's rmse: 0.0869412\tvalid_1's rmse: 0.0905102\n",
      "[875]\ttraining's rmse: 0.0869104\tvalid_1's rmse: 0.0905051\n",
      "[900]\ttraining's rmse: 0.0868743\tvalid_1's rmse: 0.0904982\n",
      "[925]\ttraining's rmse: 0.0868443\tvalid_1's rmse: 0.0904921\n",
      "[950]\ttraining's rmse: 0.0868144\tvalid_1's rmse: 0.0904856\n",
      "[975]\ttraining's rmse: 0.0867882\tvalid_1's rmse: 0.090481\n",
      "[1000]\ttraining's rmse: 0.0867623\tvalid_1's rmse: 0.0904765\n",
      "[1025]\ttraining's rmse: 0.0867336\tvalid_1's rmse: 0.0904721\n",
      "[1050]\ttraining's rmse: 0.0867066\tvalid_1's rmse: 0.0904676\n",
      "[1075]\ttraining's rmse: 0.086681\tvalid_1's rmse: 0.0904642\n",
      "[1100]\ttraining's rmse: 0.0866599\tvalid_1's rmse: 0.0904599\n",
      "[1125]\ttraining's rmse: 0.0866359\tvalid_1's rmse: 0.0904554\n",
      "[1150]\ttraining's rmse: 0.0866139\tvalid_1's rmse: 0.0904523\n",
      "[1175]\ttraining's rmse: 0.0865951\tvalid_1's rmse: 0.0904498\n",
      "[1200]\ttraining's rmse: 0.0865744\tvalid_1's rmse: 0.0904468\n",
      "[1225]\ttraining's rmse: 0.0865551\tvalid_1's rmse: 0.0904446\n",
      "[1250]\ttraining's rmse: 0.0865389\tvalid_1's rmse: 0.0904418\n",
      "[1275]\ttraining's rmse: 0.0865185\tvalid_1's rmse: 0.0904396\n",
      "[1300]\ttraining's rmse: 0.0865038\tvalid_1's rmse: 0.0904368\n",
      "[1325]\ttraining's rmse: 0.086486\tvalid_1's rmse: 0.0904347\n",
      "[1350]\ttraining's rmse: 0.08647\tvalid_1's rmse: 0.0904337\n",
      "[1375]\ttraining's rmse: 0.0864532\tvalid_1's rmse: 0.0904322\n",
      "[1400]\ttraining's rmse: 0.086439\tvalid_1's rmse: 0.0904302\n",
      "[1425]\ttraining's rmse: 0.086422\tvalid_1's rmse: 0.0904292\n",
      "[1450]\ttraining's rmse: 0.0864077\tvalid_1's rmse: 0.0904284\n",
      "[1475]\ttraining's rmse: 0.0863972\tvalid_1's rmse: 0.0904272\n",
      "[1500]\ttraining's rmse: 0.0863867\tvalid_1's rmse: 0.0904264\n",
      "[1525]\ttraining's rmse: 0.0863737\tvalid_1's rmse: 0.0904252\n",
      "[1550]\ttraining's rmse: 0.086362\tvalid_1's rmse: 0.0904241\n",
      "[1575]\ttraining's rmse: 0.0863508\tvalid_1's rmse: 0.0904229\n",
      "[1600]\ttraining's rmse: 0.086342\tvalid_1's rmse: 0.0904223\n",
      "[1625]\ttraining's rmse: 0.0863319\tvalid_1's rmse: 0.0904207\n",
      "[1650]\ttraining's rmse: 0.0863236\tvalid_1's rmse: 0.0904198\n",
      "[1675]\ttraining's rmse: 0.0863161\tvalid_1's rmse: 0.0904182\n",
      "[1700]\ttraining's rmse: 0.086306\tvalid_1's rmse: 0.0904171\n",
      "[1725]\ttraining's rmse: 0.086299\tvalid_1's rmse: 0.0904164\n",
      "[1750]\ttraining's rmse: 0.0862895\tvalid_1's rmse: 0.0904154\n",
      "[1775]\ttraining's rmse: 0.0862818\tvalid_1's rmse: 0.0904148\n",
      "[1800]\ttraining's rmse: 0.0862737\tvalid_1's rmse: 0.090414\n",
      "[1825]\ttraining's rmse: 0.0862665\tvalid_1's rmse: 0.0904137\n",
      "[1850]\ttraining's rmse: 0.08626\tvalid_1's rmse: 0.0904128\n",
      "[1875]\ttraining's rmse: 0.0862544\tvalid_1's rmse: 0.0904126\n",
      "[1900]\ttraining's rmse: 0.0862493\tvalid_1's rmse: 0.0904121\n",
      "[1925]\ttraining's rmse: 0.0862436\tvalid_1's rmse: 0.090412\n",
      "[1950]\ttraining's rmse: 0.0862385\tvalid_1's rmse: 0.090411\n",
      "[1975]\ttraining's rmse: 0.0862336\tvalid_1's rmse: 0.0904106\n",
      "[2000]\ttraining's rmse: 0.0862286\tvalid_1's rmse: 0.0904099\n",
      "[2025]\ttraining's rmse: 0.0862247\tvalid_1's rmse: 0.0904095\n",
      "[2050]\ttraining's rmse: 0.08622\tvalid_1's rmse: 0.0904092\n",
      "[2075]\ttraining's rmse: 0.0862145\tvalid_1's rmse: 0.0904088\n",
      "[2100]\ttraining's rmse: 0.0862103\tvalid_1's rmse: 0.0904083\n",
      "[2125]\ttraining's rmse: 0.0862056\tvalid_1's rmse: 0.0904081\n",
      "[2150]\ttraining's rmse: 0.0862008\tvalid_1's rmse: 0.0904078\n",
      "[2175]\ttraining's rmse: 0.0861953\tvalid_1's rmse: 0.0904078\n",
      "[2200]\ttraining's rmse: 0.0861907\tvalid_1's rmse: 0.0904074\n",
      "[2225]\ttraining's rmse: 0.0861881\tvalid_1's rmse: 0.0904074\n",
      "[2250]\ttraining's rmse: 0.086185\tvalid_1's rmse: 0.0904075\n",
      "[2275]\ttraining's rmse: 0.0861814\tvalid_1's rmse: 0.0904071\n",
      "[2300]\ttraining's rmse: 0.0861782\tvalid_1's rmse: 0.0904067\n",
      "[2325]\ttraining's rmse: 0.0861743\tvalid_1's rmse: 0.0904065\n",
      "[2350]\ttraining's rmse: 0.0861716\tvalid_1's rmse: 0.0904058\n",
      "[2375]\ttraining's rmse: 0.0861682\tvalid_1's rmse: 0.0904055\n",
      "[2400]\ttraining's rmse: 0.0861657\tvalid_1's rmse: 0.0904061\n",
      "Early stopping, best iteration is:\n",
      "[2368]\ttraining's rmse: 0.0861694\tvalid_1's rmse: 0.0904054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0911283\tvalid_1's rmse: 0.0884607\n",
      "[50]\ttraining's rmse: 0.0909949\tvalid_1's rmse: 0.0884102\n",
      "[75]\ttraining's rmse: 0.0908499\tvalid_1's rmse: 0.0883587\n",
      "[100]\ttraining's rmse: 0.0907196\tvalid_1's rmse: 0.0883163\n",
      "[125]\ttraining's rmse: 0.0905836\tvalid_1's rmse: 0.0882725\n",
      "[150]\ttraining's rmse: 0.0904636\tvalid_1's rmse: 0.0882324\n",
      "[175]\ttraining's rmse: 0.0903621\tvalid_1's rmse: 0.0881999\n",
      "[200]\ttraining's rmse: 0.0902482\tvalid_1's rmse: 0.0881677\n",
      "[225]\ttraining's rmse: 0.0901395\tvalid_1's rmse: 0.0881363\n",
      "[250]\ttraining's rmse: 0.0900489\tvalid_1's rmse: 0.0881091\n",
      "[275]\ttraining's rmse: 0.0899635\tvalid_1's rmse: 0.088084\n",
      "[300]\ttraining's rmse: 0.0898809\tvalid_1's rmse: 0.0880605\n",
      "[325]\ttraining's rmse: 0.0897947\tvalid_1's rmse: 0.0880399\n",
      "[350]\ttraining's rmse: 0.0897113\tvalid_1's rmse: 0.0880178\n",
      "[375]\ttraining's rmse: 0.0896452\tvalid_1's rmse: 0.0880036\n",
      "[400]\ttraining's rmse: 0.0895706\tvalid_1's rmse: 0.0879851\n",
      "[425]\ttraining's rmse: 0.0895023\tvalid_1's rmse: 0.0879691\n",
      "[450]\ttraining's rmse: 0.0894413\tvalid_1's rmse: 0.0879536\n",
      "[475]\ttraining's rmse: 0.0893835\tvalid_1's rmse: 0.0879392\n",
      "[500]\ttraining's rmse: 0.0893349\tvalid_1's rmse: 0.0879275\n",
      "[525]\ttraining's rmse: 0.0892704\tvalid_1's rmse: 0.0879149\n",
      "[550]\ttraining's rmse: 0.0892118\tvalid_1's rmse: 0.0879033\n",
      "[575]\ttraining's rmse: 0.0891577\tvalid_1's rmse: 0.0878935\n",
      "[600]\ttraining's rmse: 0.0891042\tvalid_1's rmse: 0.0878845\n",
      "[625]\ttraining's rmse: 0.0890626\tvalid_1's rmse: 0.0878819\n",
      "[650]\ttraining's rmse: 0.0890092\tvalid_1's rmse: 0.087883\n",
      "[675]\ttraining's rmse: 0.0889578\tvalid_1's rmse: 0.0878798\n",
      "[700]\ttraining's rmse: 0.0889118\tvalid_1's rmse: 0.0878774\n",
      "[725]\ttraining's rmse: 0.0888711\tvalid_1's rmse: 0.0878727\n",
      "[750]\ttraining's rmse: 0.0888308\tvalid_1's rmse: 0.0878724\n",
      "[775]\ttraining's rmse: 0.0887979\tvalid_1's rmse: 0.0878684\n",
      "[800]\ttraining's rmse: 0.0887548\tvalid_1's rmse: 0.0878648\n",
      "[825]\ttraining's rmse: 0.0887194\tvalid_1's rmse: 0.0878637\n",
      "[850]\ttraining's rmse: 0.0886817\tvalid_1's rmse: 0.087866\n",
      "Early stopping, best iteration is:\n",
      "[823]\ttraining's rmse: 0.0887224\tvalid_1's rmse: 0.0878604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0852557\tvalid_1's rmse: 0.0880369\n",
      "[50]\ttraining's rmse: 0.0851211\tvalid_1's rmse: 0.0879802\n",
      "[75]\ttraining's rmse: 0.0849892\tvalid_1's rmse: 0.0879248\n",
      "[100]\ttraining's rmse: 0.0848652\tvalid_1's rmse: 0.0878764\n",
      "[125]\ttraining's rmse: 0.0847436\tvalid_1's rmse: 0.0878264\n",
      "[150]\ttraining's rmse: 0.0846321\tvalid_1's rmse: 0.0877809\n",
      "[175]\ttraining's rmse: 0.0845372\tvalid_1's rmse: 0.0877403\n",
      "[200]\ttraining's rmse: 0.0844348\tvalid_1's rmse: 0.0877015\n",
      "[225]\ttraining's rmse: 0.0843346\tvalid_1's rmse: 0.0876641\n",
      "[250]\ttraining's rmse: 0.0842514\tvalid_1's rmse: 0.0876298\n",
      "[275]\ttraining's rmse: 0.0841742\tvalid_1's rmse: 0.0875984\n",
      "[300]\ttraining's rmse: 0.0840956\tvalid_1's rmse: 0.0875668\n",
      "[325]\ttraining's rmse: 0.0840163\tvalid_1's rmse: 0.0875402\n",
      "[350]\ttraining's rmse: 0.0839424\tvalid_1's rmse: 0.0875147\n",
      "[375]\ttraining's rmse: 0.0838784\tvalid_1's rmse: 0.0874922\n",
      "[400]\ttraining's rmse: 0.0838114\tvalid_1's rmse: 0.0874705\n",
      "[425]\ttraining's rmse: 0.0837523\tvalid_1's rmse: 0.0874495\n",
      "[450]\ttraining's rmse: 0.0836938\tvalid_1's rmse: 0.0874292\n",
      "[475]\ttraining's rmse: 0.0836444\tvalid_1's rmse: 0.0874094\n",
      "[500]\ttraining's rmse: 0.083598\tvalid_1's rmse: 0.0873911\n",
      "[525]\ttraining's rmse: 0.0835435\tvalid_1's rmse: 0.0873742\n",
      "[550]\ttraining's rmse: 0.0834939\tvalid_1's rmse: 0.0873583\n",
      "[575]\ttraining's rmse: 0.0834461\tvalid_1's rmse: 0.0873448\n",
      "[600]\ttraining's rmse: 0.0834022\tvalid_1's rmse: 0.0873312\n",
      "[625]\ttraining's rmse: 0.0833661\tvalid_1's rmse: 0.087318\n",
      "[650]\ttraining's rmse: 0.0833223\tvalid_1's rmse: 0.0873047\n",
      "[675]\ttraining's rmse: 0.0832808\tvalid_1's rmse: 0.0872905\n",
      "[700]\ttraining's rmse: 0.0832413\tvalid_1's rmse: 0.087278\n",
      "[725]\ttraining's rmse: 0.0832027\tvalid_1's rmse: 0.0872654\n",
      "[750]\ttraining's rmse: 0.0831689\tvalid_1's rmse: 0.0872545\n",
      "[775]\ttraining's rmse: 0.0831387\tvalid_1's rmse: 0.0872431\n",
      "[800]\ttraining's rmse: 0.0831021\tvalid_1's rmse: 0.0872334\n",
      "[825]\ttraining's rmse: 0.0830718\tvalid_1's rmse: 0.0872241\n",
      "[850]\ttraining's rmse: 0.0830413\tvalid_1's rmse: 0.0872162\n",
      "[875]\ttraining's rmse: 0.0830115\tvalid_1's rmse: 0.0872074\n",
      "[900]\ttraining's rmse: 0.0829824\tvalid_1's rmse: 0.0871997\n",
      "[925]\ttraining's rmse: 0.0829547\tvalid_1's rmse: 0.0871922\n",
      "[950]\ttraining's rmse: 0.0829297\tvalid_1's rmse: 0.0871837\n",
      "[975]\ttraining's rmse: 0.0829066\tvalid_1's rmse: 0.087177\n",
      "[1000]\ttraining's rmse: 0.0828828\tvalid_1's rmse: 0.0871708\n",
      "[1025]\ttraining's rmse: 0.0828555\tvalid_1's rmse: 0.0871641\n",
      "[1050]\ttraining's rmse: 0.0828356\tvalid_1's rmse: 0.0871569\n",
      "[1075]\ttraining's rmse: 0.0828142\tvalid_1's rmse: 0.0871528\n",
      "[1100]\ttraining's rmse: 0.0827961\tvalid_1's rmse: 0.0871467\n",
      "[1125]\ttraining's rmse: 0.0827771\tvalid_1's rmse: 0.0871401\n",
      "[1150]\ttraining's rmse: 0.082759\tvalid_1's rmse: 0.0871353\n",
      "[1175]\ttraining's rmse: 0.0827414\tvalid_1's rmse: 0.0871305\n",
      "[1200]\ttraining's rmse: 0.0827245\tvalid_1's rmse: 0.0871248\n",
      "[1225]\ttraining's rmse: 0.0827069\tvalid_1's rmse: 0.0871199\n",
      "[1250]\ttraining's rmse: 0.0826926\tvalid_1's rmse: 0.0871154\n",
      "[1275]\ttraining's rmse: 0.082675\tvalid_1's rmse: 0.0871112\n",
      "[1300]\ttraining's rmse: 0.0826619\tvalid_1's rmse: 0.0871069\n",
      "[1325]\ttraining's rmse: 0.0826488\tvalid_1's rmse: 0.0871037\n",
      "[1350]\ttraining's rmse: 0.0826335\tvalid_1's rmse: 0.0871007\n",
      "[1375]\ttraining's rmse: 0.0826214\tvalid_1's rmse: 0.0870982\n",
      "[1400]\ttraining's rmse: 0.0826107\tvalid_1's rmse: 0.087095\n",
      "[1425]\ttraining's rmse: 0.0826012\tvalid_1's rmse: 0.087092\n",
      "[1450]\ttraining's rmse: 0.0825897\tvalid_1's rmse: 0.0870891\n",
      "[1475]\ttraining's rmse: 0.0825787\tvalid_1's rmse: 0.0870869\n",
      "[1500]\ttraining's rmse: 0.0825671\tvalid_1's rmse: 0.0870844\n",
      "[1525]\ttraining's rmse: 0.082558\tvalid_1's rmse: 0.0870816\n",
      "[1550]\ttraining's rmse: 0.082547\tvalid_1's rmse: 0.0870793\n",
      "[1575]\ttraining's rmse: 0.0825386\tvalid_1's rmse: 0.0870776\n",
      "[1600]\ttraining's rmse: 0.0825305\tvalid_1's rmse: 0.0870742\n",
      "[1625]\ttraining's rmse: 0.0825225\tvalid_1's rmse: 0.0870719\n",
      "[1650]\ttraining's rmse: 0.0825143\tvalid_1's rmse: 0.0870699\n",
      "[1675]\ttraining's rmse: 0.0825082\tvalid_1's rmse: 0.0870674\n",
      "[1700]\ttraining's rmse: 0.0825021\tvalid_1's rmse: 0.0870649\n",
      "[1725]\ttraining's rmse: 0.0824939\tvalid_1's rmse: 0.0870636\n",
      "[1750]\ttraining's rmse: 0.0824875\tvalid_1's rmse: 0.0870617\n",
      "[1775]\ttraining's rmse: 0.0824807\tvalid_1's rmse: 0.0870595\n",
      "[1800]\ttraining's rmse: 0.0824743\tvalid_1's rmse: 0.0870578\n",
      "[1825]\ttraining's rmse: 0.0824684\tvalid_1's rmse: 0.0870569\n",
      "[1850]\ttraining's rmse: 0.0824635\tvalid_1's rmse: 0.0870547\n",
      "[1875]\ttraining's rmse: 0.0824583\tvalid_1's rmse: 0.0870541\n",
      "[1900]\ttraining's rmse: 0.0824528\tvalid_1's rmse: 0.0870531\n",
      "[1925]\ttraining's rmse: 0.0824487\tvalid_1's rmse: 0.0870513\n",
      "[1950]\ttraining's rmse: 0.0824444\tvalid_1's rmse: 0.0870492\n",
      "[1975]\ttraining's rmse: 0.0824404\tvalid_1's rmse: 0.0870485\n",
      "[2000]\ttraining's rmse: 0.0824352\tvalid_1's rmse: 0.0870474\n",
      "[2025]\ttraining's rmse: 0.082432\tvalid_1's rmse: 0.0870471\n",
      "[2050]\ttraining's rmse: 0.0824275\tvalid_1's rmse: 0.087046\n",
      "[2075]\ttraining's rmse: 0.0824244\tvalid_1's rmse: 0.0870456\n",
      "[2100]\ttraining's rmse: 0.0824206\tvalid_1's rmse: 0.0870449\n",
      "[2125]\ttraining's rmse: 0.0824176\tvalid_1's rmse: 0.0870442\n",
      "[2150]\ttraining's rmse: 0.0824135\tvalid_1's rmse: 0.0870441\n",
      "[2175]\ttraining's rmse: 0.0824107\tvalid_1's rmse: 0.0870441\n",
      "[2200]\ttraining's rmse: 0.0824078\tvalid_1's rmse: 0.0870435\n",
      "[2225]\ttraining's rmse: 0.0824052\tvalid_1's rmse: 0.0870435\n",
      "[2250]\ttraining's rmse: 0.0824022\tvalid_1's rmse: 0.0870425\n",
      "[2275]\ttraining's rmse: 0.0823989\tvalid_1's rmse: 0.0870423\n",
      "[2300]\ttraining's rmse: 0.082396\tvalid_1's rmse: 0.0870414\n",
      "[2325]\ttraining's rmse: 0.0823934\tvalid_1's rmse: 0.0870397\n",
      "[2350]\ttraining's rmse: 0.082391\tvalid_1's rmse: 0.087039\n",
      "[2375]\ttraining's rmse: 0.082389\tvalid_1's rmse: 0.0870378\n",
      "[2400]\ttraining's rmse: 0.0823859\tvalid_1's rmse: 0.0870371\n",
      "[2425]\ttraining's rmse: 0.0823835\tvalid_1's rmse: 0.0870355\n",
      "[2450]\ttraining's rmse: 0.0823809\tvalid_1's rmse: 0.0870338\n",
      "[2475]\ttraining's rmse: 0.0823776\tvalid_1's rmse: 0.0870337\n",
      "[2500]\ttraining's rmse: 0.0823754\tvalid_1's rmse: 0.0870337\n",
      "[2525]\ttraining's rmse: 0.0823731\tvalid_1's rmse: 0.0870335\n",
      "[2550]\ttraining's rmse: 0.0823706\tvalid_1's rmse: 0.0870329\n",
      "[2575]\ttraining's rmse: 0.0823686\tvalid_1's rmse: 0.0870326\n",
      "[2600]\ttraining's rmse: 0.0823656\tvalid_1's rmse: 0.0870324\n",
      "[2625]\ttraining's rmse: 0.0823636\tvalid_1's rmse: 0.0870318\n",
      "[2650]\ttraining's rmse: 0.0823618\tvalid_1's rmse: 0.0870304\n",
      "[2675]\ttraining's rmse: 0.0823593\tvalid_1's rmse: 0.0870291\n",
      "[2700]\ttraining's rmse: 0.0823555\tvalid_1's rmse: 0.0870286\n",
      "[2725]\ttraining's rmse: 0.0823528\tvalid_1's rmse: 0.0870289\n",
      "[2750]\ttraining's rmse: 0.0823504\tvalid_1's rmse: 0.0870291\n",
      "Early stopping, best iteration is:\n",
      "[2709]\ttraining's rmse: 0.0823542\tvalid_1's rmse: 0.0870284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0856201\tvalid_1's rmse: 0.0873212\n",
      "[50]\ttraining's rmse: 0.0854915\tvalid_1's rmse: 0.087263\n",
      "[75]\ttraining's rmse: 0.0853614\tvalid_1's rmse: 0.0872065\n",
      "[100]\ttraining's rmse: 0.0852464\tvalid_1's rmse: 0.0871558\n",
      "[125]\ttraining's rmse: 0.0851284\tvalid_1's rmse: 0.0871052\n",
      "[150]\ttraining's rmse: 0.0850222\tvalid_1's rmse: 0.0870588\n",
      "[175]\ttraining's rmse: 0.0849318\tvalid_1's rmse: 0.0870189\n",
      "[200]\ttraining's rmse: 0.0848304\tvalid_1's rmse: 0.086979\n",
      "[225]\ttraining's rmse: 0.0847367\tvalid_1's rmse: 0.0869436\n",
      "[250]\ttraining's rmse: 0.084654\tvalid_1's rmse: 0.0869123\n",
      "[275]\ttraining's rmse: 0.0845773\tvalid_1's rmse: 0.0868813\n",
      "[300]\ttraining's rmse: 0.0845018\tvalid_1's rmse: 0.086852\n",
      "[325]\ttraining's rmse: 0.0844253\tvalid_1's rmse: 0.086824\n",
      "[350]\ttraining's rmse: 0.0843519\tvalid_1's rmse: 0.0867992\n",
      "[375]\ttraining's rmse: 0.0842911\tvalid_1's rmse: 0.0867767\n",
      "[400]\ttraining's rmse: 0.0842238\tvalid_1's rmse: 0.0867555\n",
      "[425]\ttraining's rmse: 0.0841642\tvalid_1's rmse: 0.0867354\n",
      "[450]\ttraining's rmse: 0.0841069\tvalid_1's rmse: 0.0867167\n",
      "[475]\ttraining's rmse: 0.0840548\tvalid_1's rmse: 0.0866989\n",
      "[500]\ttraining's rmse: 0.0840104\tvalid_1's rmse: 0.0866815\n",
      "[525]\ttraining's rmse: 0.0839524\tvalid_1's rmse: 0.0866642\n",
      "[550]\ttraining's rmse: 0.0839002\tvalid_1's rmse: 0.0866483\n",
      "[575]\ttraining's rmse: 0.0838528\tvalid_1's rmse: 0.0866344\n",
      "[600]\ttraining's rmse: 0.0838089\tvalid_1's rmse: 0.086621\n",
      "[625]\ttraining's rmse: 0.0837719\tvalid_1's rmse: 0.0866081\n",
      "[650]\ttraining's rmse: 0.0837264\tvalid_1's rmse: 0.0865956\n",
      "[675]\ttraining's rmse: 0.0836805\tvalid_1's rmse: 0.086584\n",
      "[700]\ttraining's rmse: 0.0836404\tvalid_1's rmse: 0.0865735\n",
      "[725]\ttraining's rmse: 0.0836026\tvalid_1's rmse: 0.0865626\n",
      "[750]\ttraining's rmse: 0.0835681\tvalid_1's rmse: 0.086553\n",
      "[775]\ttraining's rmse: 0.0835378\tvalid_1's rmse: 0.0865443\n",
      "[800]\ttraining's rmse: 0.0834983\tvalid_1's rmse: 0.0865361\n",
      "[825]\ttraining's rmse: 0.0834689\tvalid_1's rmse: 0.086527\n",
      "[850]\ttraining's rmse: 0.0834385\tvalid_1's rmse: 0.0865203\n",
      "[875]\ttraining's rmse: 0.0834107\tvalid_1's rmse: 0.0865126\n",
      "[900]\ttraining's rmse: 0.0833816\tvalid_1's rmse: 0.0865048\n",
      "[925]\ttraining's rmse: 0.0833523\tvalid_1's rmse: 0.0864988\n",
      "[950]\ttraining's rmse: 0.083328\tvalid_1's rmse: 0.0864945\n",
      "[975]\ttraining's rmse: 0.083303\tvalid_1's rmse: 0.0864894\n",
      "[1000]\ttraining's rmse: 0.0832787\tvalid_1's rmse: 0.0864847\n",
      "[1025]\ttraining's rmse: 0.0832531\tvalid_1's rmse: 0.0864803\n",
      "[1050]\ttraining's rmse: 0.0832341\tvalid_1's rmse: 0.0864757\n",
      "[1075]\ttraining's rmse: 0.0832125\tvalid_1's rmse: 0.0864722\n",
      "[1100]\ttraining's rmse: 0.0831957\tvalid_1's rmse: 0.086468\n",
      "[1125]\ttraining's rmse: 0.0831749\tvalid_1's rmse: 0.0864639\n",
      "[1150]\ttraining's rmse: 0.0831553\tvalid_1's rmse: 0.0864599\n",
      "[1175]\ttraining's rmse: 0.0831401\tvalid_1's rmse: 0.0864569\n",
      "[1200]\ttraining's rmse: 0.083124\tvalid_1's rmse: 0.0864542\n",
      "[1225]\ttraining's rmse: 0.0831085\tvalid_1's rmse: 0.0864511\n",
      "[1250]\ttraining's rmse: 0.0830935\tvalid_1's rmse: 0.0864486\n",
      "[1275]\ttraining's rmse: 0.0830754\tvalid_1's rmse: 0.086446\n",
      "[1300]\ttraining's rmse: 0.0830624\tvalid_1's rmse: 0.0864437\n",
      "[1325]\ttraining's rmse: 0.0830475\tvalid_1's rmse: 0.0864417\n",
      "[1350]\ttraining's rmse: 0.0830343\tvalid_1's rmse: 0.0864397\n",
      "[1375]\ttraining's rmse: 0.0830212\tvalid_1's rmse: 0.0864384\n",
      "[1400]\ttraining's rmse: 0.0830101\tvalid_1's rmse: 0.0864357\n",
      "[1425]\ttraining's rmse: 0.0829976\tvalid_1's rmse: 0.086434\n",
      "[1450]\ttraining's rmse: 0.082984\tvalid_1's rmse: 0.0864332\n",
      "[1475]\ttraining's rmse: 0.0829722\tvalid_1's rmse: 0.0864314\n",
      "[1500]\ttraining's rmse: 0.0829634\tvalid_1's rmse: 0.0864291\n",
      "[1525]\ttraining's rmse: 0.0829532\tvalid_1's rmse: 0.0864279\n",
      "[1550]\ttraining's rmse: 0.0829433\tvalid_1's rmse: 0.086427\n",
      "[1575]\ttraining's rmse: 0.0829341\tvalid_1's rmse: 0.0864255\n",
      "[1600]\ttraining's rmse: 0.0829258\tvalid_1's rmse: 0.0864247\n",
      "[1625]\ttraining's rmse: 0.0829173\tvalid_1's rmse: 0.0864237\n",
      "[1650]\ttraining's rmse: 0.0829106\tvalid_1's rmse: 0.0864232\n",
      "[1675]\ttraining's rmse: 0.0829029\tvalid_1's rmse: 0.0864224\n",
      "[1700]\ttraining's rmse: 0.0828964\tvalid_1's rmse: 0.0864212\n",
      "[1725]\ttraining's rmse: 0.0828886\tvalid_1's rmse: 0.0864204\n",
      "[1750]\ttraining's rmse: 0.0828799\tvalid_1's rmse: 0.0864194\n",
      "[1775]\ttraining's rmse: 0.082872\tvalid_1's rmse: 0.0864184\n",
      "[1800]\ttraining's rmse: 0.0828661\tvalid_1's rmse: 0.0864178\n",
      "[1825]\ttraining's rmse: 0.0828584\tvalid_1's rmse: 0.0864174\n",
      "[1850]\ttraining's rmse: 0.0828529\tvalid_1's rmse: 0.0864168\n",
      "[1875]\ttraining's rmse: 0.0828477\tvalid_1's rmse: 0.0864165\n",
      "[1900]\ttraining's rmse: 0.0828424\tvalid_1's rmse: 0.0864163\n",
      "[1925]\ttraining's rmse: 0.0828365\tvalid_1's rmse: 0.0864156\n",
      "[1950]\ttraining's rmse: 0.0828322\tvalid_1's rmse: 0.0864147\n",
      "[1975]\ttraining's rmse: 0.0828284\tvalid_1's rmse: 0.0864142\n",
      "[2000]\ttraining's rmse: 0.0828233\tvalid_1's rmse: 0.0864137\n",
      "[2025]\ttraining's rmse: 0.0828175\tvalid_1's rmse: 0.0864128\n",
      "[2050]\ttraining's rmse: 0.0828128\tvalid_1's rmse: 0.0864127\n",
      "[2075]\ttraining's rmse: 0.0828096\tvalid_1's rmse: 0.0864127\n",
      "[2100]\ttraining's rmse: 0.0828054\tvalid_1's rmse: 0.0864123\n",
      "[2125]\ttraining's rmse: 0.0828023\tvalid_1's rmse: 0.0864122\n",
      "[2150]\ttraining's rmse: 0.0827982\tvalid_1's rmse: 0.0864122\n",
      "[2175]\ttraining's rmse: 0.0827949\tvalid_1's rmse: 0.0864119\n",
      "[2200]\ttraining's rmse: 0.082792\tvalid_1's rmse: 0.0864119\n",
      "[2225]\ttraining's rmse: 0.0827886\tvalid_1's rmse: 0.0864118\n",
      "[2250]\ttraining's rmse: 0.0827838\tvalid_1's rmse: 0.0864109\n",
      "[2275]\ttraining's rmse: 0.0827793\tvalid_1's rmse: 0.0864106\n",
      "[2300]\ttraining's rmse: 0.0827758\tvalid_1's rmse: 0.0864102\n",
      "[2325]\ttraining's rmse: 0.0827726\tvalid_1's rmse: 0.0864102\n",
      "Early stopping, best iteration is:\n",
      "[2290]\ttraining's rmse: 0.0827768\tvalid_1's rmse: 0.08641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0875569\tvalid_1's rmse: 0.0834002\n",
      "[50]\ttraining's rmse: 0.0874363\tvalid_1's rmse: 0.083349\n",
      "[75]\ttraining's rmse: 0.087312\tvalid_1's rmse: 0.0832987\n",
      "[100]\ttraining's rmse: 0.0872012\tvalid_1's rmse: 0.0832547\n",
      "[125]\ttraining's rmse: 0.0870877\tvalid_1's rmse: 0.0832117\n",
      "[150]\ttraining's rmse: 0.0869808\tvalid_1's rmse: 0.0831727\n",
      "[175]\ttraining's rmse: 0.0868927\tvalid_1's rmse: 0.0831429\n",
      "[200]\ttraining's rmse: 0.0867979\tvalid_1's rmse: 0.08311\n",
      "[225]\ttraining's rmse: 0.0867093\tvalid_1's rmse: 0.0830788\n",
      "[250]\ttraining's rmse: 0.0866341\tvalid_1's rmse: 0.0830527\n",
      "[275]\ttraining's rmse: 0.0865643\tvalid_1's rmse: 0.0830263\n",
      "[300]\ttraining's rmse: 0.0864945\tvalid_1's rmse: 0.0830024\n",
      "[325]\ttraining's rmse: 0.0864209\tvalid_1's rmse: 0.0829797\n",
      "[350]\ttraining's rmse: 0.0863485\tvalid_1's rmse: 0.0829583\n",
      "[375]\ttraining's rmse: 0.0862919\tvalid_1's rmse: 0.0829409\n",
      "[400]\ttraining's rmse: 0.0862287\tvalid_1's rmse: 0.0829312\n",
      "[425]\ttraining's rmse: 0.0861726\tvalid_1's rmse: 0.0829148\n",
      "[450]\ttraining's rmse: 0.0861171\tvalid_1's rmse: 0.082897\n",
      "[475]\ttraining's rmse: 0.0860672\tvalid_1's rmse: 0.0828821\n",
      "[500]\ttraining's rmse: 0.0860248\tvalid_1's rmse: 0.0828687\n",
      "[525]\ttraining's rmse: 0.0859697\tvalid_1's rmse: 0.0828545\n",
      "[550]\ttraining's rmse: 0.085921\tvalid_1's rmse: 0.0828474\n",
      "[575]\ttraining's rmse: 0.0858756\tvalid_1's rmse: 0.0828363\n",
      "[600]\ttraining's rmse: 0.08583\tvalid_1's rmse: 0.0828255\n",
      "[625]\ttraining's rmse: 0.0857944\tvalid_1's rmse: 0.0828204\n",
      "[650]\ttraining's rmse: 0.085749\tvalid_1's rmse: 0.0828098\n",
      "[675]\ttraining's rmse: 0.0857044\tvalid_1's rmse: 0.0828123\n",
      "[700]\ttraining's rmse: 0.0856636\tvalid_1's rmse: 0.0828032\n",
      "[725]\ttraining's rmse: 0.0856266\tvalid_1's rmse: 0.082806\n",
      "[750]\ttraining's rmse: 0.085593\tvalid_1's rmse: 0.0828107\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 0.0856497\tvalid_1's rmse: 0.0828001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.083159\tvalid_1's rmse: 0.0855302\n",
      "[50]\ttraining's rmse: 0.0830349\tvalid_1's rmse: 0.0854786\n",
      "[75]\ttraining's rmse: 0.0829097\tvalid_1's rmse: 0.0854289\n",
      "[100]\ttraining's rmse: 0.0827926\tvalid_1's rmse: 0.0853844\n",
      "[125]\ttraining's rmse: 0.0826771\tvalid_1's rmse: 0.0853403\n",
      "[150]\ttraining's rmse: 0.0825699\tvalid_1's rmse: 0.0852999\n",
      "[175]\ttraining's rmse: 0.0824818\tvalid_1's rmse: 0.0852661\n",
      "[200]\ttraining's rmse: 0.082389\tvalid_1's rmse: 0.0852321\n",
      "[225]\ttraining's rmse: 0.0822944\tvalid_1's rmse: 0.085199\n",
      "[250]\ttraining's rmse: 0.0822183\tvalid_1's rmse: 0.0851693\n",
      "[275]\ttraining's rmse: 0.0821458\tvalid_1's rmse: 0.0851419\n",
      "[300]\ttraining's rmse: 0.0820731\tvalid_1's rmse: 0.0851164\n",
      "[325]\ttraining's rmse: 0.0820015\tvalid_1's rmse: 0.085092\n",
      "[350]\ttraining's rmse: 0.0819352\tvalid_1's rmse: 0.0850689\n",
      "[375]\ttraining's rmse: 0.0818778\tvalid_1's rmse: 0.0850483\n",
      "[400]\ttraining's rmse: 0.0818115\tvalid_1's rmse: 0.0850284\n",
      "[425]\ttraining's rmse: 0.0817535\tvalid_1's rmse: 0.0850102\n",
      "[450]\ttraining's rmse: 0.0817011\tvalid_1's rmse: 0.0849908\n",
      "[475]\ttraining's rmse: 0.0816539\tvalid_1's rmse: 0.0849731\n",
      "[500]\ttraining's rmse: 0.0816097\tvalid_1's rmse: 0.0849558\n",
      "[525]\ttraining's rmse: 0.0815559\tvalid_1's rmse: 0.0849402\n",
      "[550]\ttraining's rmse: 0.0815091\tvalid_1's rmse: 0.0849269\n",
      "[575]\ttraining's rmse: 0.0814632\tvalid_1's rmse: 0.0849143\n",
      "[600]\ttraining's rmse: 0.0814195\tvalid_1's rmse: 0.0849014\n",
      "[625]\ttraining's rmse: 0.0813858\tvalid_1's rmse: 0.0848896\n",
      "[650]\ttraining's rmse: 0.0813442\tvalid_1's rmse: 0.0848772\n",
      "[675]\ttraining's rmse: 0.0813037\tvalid_1's rmse: 0.0848658\n",
      "[700]\ttraining's rmse: 0.0812678\tvalid_1's rmse: 0.0848557\n",
      "[725]\ttraining's rmse: 0.0812322\tvalid_1's rmse: 0.0848462\n",
      "[750]\ttraining's rmse: 0.0812011\tvalid_1's rmse: 0.0848383\n",
      "[775]\ttraining's rmse: 0.0811721\tvalid_1's rmse: 0.0848299\n",
      "[800]\ttraining's rmse: 0.0811373\tvalid_1's rmse: 0.0848227\n",
      "[825]\ttraining's rmse: 0.0811086\tvalid_1's rmse: 0.084814\n",
      "[850]\ttraining's rmse: 0.0810762\tvalid_1's rmse: 0.0848071\n",
      "[875]\ttraining's rmse: 0.0810509\tvalid_1's rmse: 0.0848001\n",
      "[900]\ttraining's rmse: 0.0810219\tvalid_1's rmse: 0.0847934\n",
      "[925]\ttraining's rmse: 0.0809989\tvalid_1's rmse: 0.0847868\n",
      "[950]\ttraining's rmse: 0.0809742\tvalid_1's rmse: 0.0847796\n",
      "[975]\ttraining's rmse: 0.0809499\tvalid_1's rmse: 0.0847736\n",
      "[1000]\ttraining's rmse: 0.0809268\tvalid_1's rmse: 0.084769\n",
      "[1025]\ttraining's rmse: 0.0809039\tvalid_1's rmse: 0.0847625\n",
      "[1050]\ttraining's rmse: 0.0808834\tvalid_1's rmse: 0.084757\n",
      "[1075]\ttraining's rmse: 0.080862\tvalid_1's rmse: 0.0847538\n",
      "[1100]\ttraining's rmse: 0.0808445\tvalid_1's rmse: 0.0847498\n",
      "[1125]\ttraining's rmse: 0.0808276\tvalid_1's rmse: 0.0847448\n",
      "[1150]\ttraining's rmse: 0.0808099\tvalid_1's rmse: 0.0847401\n",
      "[1175]\ttraining's rmse: 0.0807917\tvalid_1's rmse: 0.0847364\n",
      "[1200]\ttraining's rmse: 0.0807749\tvalid_1's rmse: 0.0847309\n",
      "[1225]\ttraining's rmse: 0.0807587\tvalid_1's rmse: 0.0847267\n",
      "[1250]\ttraining's rmse: 0.0807433\tvalid_1's rmse: 0.0847216\n",
      "[1275]\ttraining's rmse: 0.0807247\tvalid_1's rmse: 0.0847178\n",
      "[1300]\ttraining's rmse: 0.0807126\tvalid_1's rmse: 0.0847121\n",
      "[1325]\ttraining's rmse: 0.080697\tvalid_1's rmse: 0.084708\n",
      "[1350]\ttraining's rmse: 0.0806846\tvalid_1's rmse: 0.084704\n",
      "[1375]\ttraining's rmse: 0.0806726\tvalid_1's rmse: 0.0847009\n",
      "[1400]\ttraining's rmse: 0.0806619\tvalid_1's rmse: 0.0846987\n",
      "[1425]\ttraining's rmse: 0.0806491\tvalid_1's rmse: 0.084696\n",
      "[1450]\ttraining's rmse: 0.080638\tvalid_1's rmse: 0.0846943\n",
      "[1475]\ttraining's rmse: 0.0806268\tvalid_1's rmse: 0.08469\n",
      "[1500]\ttraining's rmse: 0.0806172\tvalid_1's rmse: 0.0846874\n",
      "[1525]\ttraining's rmse: 0.0806076\tvalid_1's rmse: 0.0846843\n",
      "[1550]\ttraining's rmse: 0.0805986\tvalid_1's rmse: 0.084682\n",
      "[1575]\ttraining's rmse: 0.0805902\tvalid_1's rmse: 0.0846795\n",
      "[1600]\ttraining's rmse: 0.0805821\tvalid_1's rmse: 0.0846782\n",
      "[1625]\ttraining's rmse: 0.0805756\tvalid_1's rmse: 0.0846753\n",
      "[1650]\ttraining's rmse: 0.0805686\tvalid_1's rmse: 0.0846729\n",
      "[1675]\ttraining's rmse: 0.0805639\tvalid_1's rmse: 0.0846707\n",
      "[1700]\ttraining's rmse: 0.080559\tvalid_1's rmse: 0.0846679\n",
      "[1725]\ttraining's rmse: 0.0805527\tvalid_1's rmse: 0.0846668\n",
      "[1750]\ttraining's rmse: 0.080547\tvalid_1's rmse: 0.0846647\n",
      "[1775]\ttraining's rmse: 0.0805417\tvalid_1's rmse: 0.0846619\n",
      "[1800]\ttraining's rmse: 0.0805352\tvalid_1's rmse: 0.0846601\n",
      "[1825]\ttraining's rmse: 0.0805279\tvalid_1's rmse: 0.0846587\n",
      "[1850]\ttraining's rmse: 0.0805232\tvalid_1's rmse: 0.0846574\n",
      "[1875]\ttraining's rmse: 0.0805178\tvalid_1's rmse: 0.084656\n",
      "[1900]\ttraining's rmse: 0.0805146\tvalid_1's rmse: 0.0846554\n",
      "[1925]\ttraining's rmse: 0.0805113\tvalid_1's rmse: 0.0846542\n",
      "[1950]\ttraining's rmse: 0.0805074\tvalid_1's rmse: 0.084654\n",
      "[1975]\ttraining's rmse: 0.0805033\tvalid_1's rmse: 0.084652\n",
      "[2000]\ttraining's rmse: 0.0804984\tvalid_1's rmse: 0.0846512\n",
      "[2025]\ttraining's rmse: 0.0804952\tvalid_1's rmse: 0.0846506\n",
      "[2050]\ttraining's rmse: 0.0804912\tvalid_1's rmse: 0.0846489\n",
      "[2075]\ttraining's rmse: 0.0804878\tvalid_1's rmse: 0.0846479\n",
      "[2100]\ttraining's rmse: 0.080484\tvalid_1's rmse: 0.0846468\n",
      "[2125]\ttraining's rmse: 0.0804813\tvalid_1's rmse: 0.0846454\n",
      "[2150]\ttraining's rmse: 0.0804784\tvalid_1's rmse: 0.0846443\n",
      "[2175]\ttraining's rmse: 0.0804756\tvalid_1's rmse: 0.0846442\n",
      "[2200]\ttraining's rmse: 0.0804729\tvalid_1's rmse: 0.0846435\n",
      "[2225]\ttraining's rmse: 0.080471\tvalid_1's rmse: 0.0846424\n",
      "[2250]\ttraining's rmse: 0.0804675\tvalid_1's rmse: 0.084642\n",
      "[2275]\ttraining's rmse: 0.0804641\tvalid_1's rmse: 0.0846416\n",
      "[2300]\ttraining's rmse: 0.0804609\tvalid_1's rmse: 0.0846409\n",
      "[2325]\ttraining's rmse: 0.0804576\tvalid_1's rmse: 0.0846403\n",
      "[2350]\ttraining's rmse: 0.0804542\tvalid_1's rmse: 0.0846405\n",
      "[2375]\ttraining's rmse: 0.0804513\tvalid_1's rmse: 0.0846393\n",
      "[2400]\ttraining's rmse: 0.0804495\tvalid_1's rmse: 0.0846391\n",
      "[2425]\ttraining's rmse: 0.0804479\tvalid_1's rmse: 0.0846391\n",
      "[2450]\ttraining's rmse: 0.0804455\tvalid_1's rmse: 0.0846382\n",
      "[2475]\ttraining's rmse: 0.0804424\tvalid_1's rmse: 0.0846381\n",
      "[2500]\ttraining's rmse: 0.0804408\tvalid_1's rmse: 0.0846376\n",
      "[2525]\ttraining's rmse: 0.080439\tvalid_1's rmse: 0.0846378\n",
      "[2550]\ttraining's rmse: 0.0804374\tvalid_1's rmse: 0.0846375\n",
      "[2575]\ttraining's rmse: 0.0804356\tvalid_1's rmse: 0.0846371\n",
      "[2600]\ttraining's rmse: 0.0804336\tvalid_1's rmse: 0.084637\n",
      "[2625]\ttraining's rmse: 0.0804322\tvalid_1's rmse: 0.0846371\n",
      "[2650]\ttraining's rmse: 0.0804303\tvalid_1's rmse: 0.084636\n",
      "[2675]\ttraining's rmse: 0.0804284\tvalid_1's rmse: 0.0846347\n",
      "[2700]\ttraining's rmse: 0.0804258\tvalid_1's rmse: 0.0846338\n",
      "[2725]\ttraining's rmse: 0.0804224\tvalid_1's rmse: 0.084633\n",
      "[2750]\ttraining's rmse: 0.0804213\tvalid_1's rmse: 0.0846329\n",
      "[2775]\ttraining's rmse: 0.0804203\tvalid_1's rmse: 0.0846321\n",
      "[2800]\ttraining's rmse: 0.0804179\tvalid_1's rmse: 0.084632\n",
      "[2825]\ttraining's rmse: 0.0804165\tvalid_1's rmse: 0.0846312\n",
      "[2850]\ttraining's rmse: 0.0804146\tvalid_1's rmse: 0.084631\n",
      "[2875]\ttraining's rmse: 0.0804136\tvalid_1's rmse: 0.084631\n",
      "[2900]\ttraining's rmse: 0.0804117\tvalid_1's rmse: 0.0846302\n",
      "[2925]\ttraining's rmse: 0.0804103\tvalid_1's rmse: 0.0846301\n",
      "[2950]\ttraining's rmse: 0.0804094\tvalid_1's rmse: 0.0846294\n",
      "[2975]\ttraining's rmse: 0.0804083\tvalid_1's rmse: 0.0846292\n",
      "[3000]\ttraining's rmse: 0.0804065\tvalid_1's rmse: 0.0846291\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0804065\tvalid_1's rmse: 0.0846291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.083299\tvalid_1's rmse: 0.0852739\n",
      "[50]\ttraining's rmse: 0.0831821\tvalid_1's rmse: 0.0852206\n",
      "[75]\ttraining's rmse: 0.0830643\tvalid_1's rmse: 0.0851697\n",
      "[100]\ttraining's rmse: 0.0829602\tvalid_1's rmse: 0.0851246\n",
      "[125]\ttraining's rmse: 0.0828514\tvalid_1's rmse: 0.0850797\n",
      "[150]\ttraining's rmse: 0.0827511\tvalid_1's rmse: 0.0850374\n",
      "[175]\ttraining's rmse: 0.0826682\tvalid_1's rmse: 0.0850026\n",
      "[200]\ttraining's rmse: 0.0825804\tvalid_1's rmse: 0.0849673\n",
      "[225]\ttraining's rmse: 0.0824922\tvalid_1's rmse: 0.0849341\n",
      "[250]\ttraining's rmse: 0.0824186\tvalid_1's rmse: 0.0849042\n",
      "[275]\ttraining's rmse: 0.0823512\tvalid_1's rmse: 0.0848765\n",
      "[300]\ttraining's rmse: 0.0822824\tvalid_1's rmse: 0.0848506\n",
      "[325]\ttraining's rmse: 0.0822115\tvalid_1's rmse: 0.0848252\n",
      "[350]\ttraining's rmse: 0.0821436\tvalid_1's rmse: 0.0848022\n",
      "[375]\ttraining's rmse: 0.0820917\tvalid_1's rmse: 0.0847821\n",
      "[400]\ttraining's rmse: 0.0820322\tvalid_1's rmse: 0.0847617\n",
      "[425]\ttraining's rmse: 0.0819789\tvalid_1's rmse: 0.0847421\n",
      "[450]\ttraining's rmse: 0.0819298\tvalid_1's rmse: 0.0847245\n",
      "[475]\ttraining's rmse: 0.0818826\tvalid_1's rmse: 0.0847078\n",
      "[500]\ttraining's rmse: 0.0818422\tvalid_1's rmse: 0.0846915\n",
      "[525]\ttraining's rmse: 0.0817895\tvalid_1's rmse: 0.084676\n",
      "[550]\ttraining's rmse: 0.0817433\tvalid_1's rmse: 0.0846613\n",
      "[575]\ttraining's rmse: 0.0816998\tvalid_1's rmse: 0.0846474\n",
      "[600]\ttraining's rmse: 0.0816566\tvalid_1's rmse: 0.0846337\n",
      "[625]\ttraining's rmse: 0.0816231\tvalid_1's rmse: 0.0846214\n",
      "[650]\ttraining's rmse: 0.0815814\tvalid_1's rmse: 0.0846095\n",
      "[675]\ttraining's rmse: 0.0815417\tvalid_1's rmse: 0.0845984\n",
      "[700]\ttraining's rmse: 0.0815051\tvalid_1's rmse: 0.0845883\n",
      "[725]\ttraining's rmse: 0.0814693\tvalid_1's rmse: 0.0845782\n",
      "[750]\ttraining's rmse: 0.0814374\tvalid_1's rmse: 0.0845693\n",
      "[775]\ttraining's rmse: 0.0814096\tvalid_1's rmse: 0.0845609\n",
      "[800]\ttraining's rmse: 0.0813756\tvalid_1's rmse: 0.0845528\n",
      "[825]\ttraining's rmse: 0.0813483\tvalid_1's rmse: 0.0845448\n",
      "[850]\ttraining's rmse: 0.0813195\tvalid_1's rmse: 0.084537\n",
      "[875]\ttraining's rmse: 0.0812963\tvalid_1's rmse: 0.08453\n",
      "[900]\ttraining's rmse: 0.0812686\tvalid_1's rmse: 0.0845222\n",
      "[925]\ttraining's rmse: 0.0812401\tvalid_1's rmse: 0.0845161\n",
      "[950]\ttraining's rmse: 0.0812155\tvalid_1's rmse: 0.0845105\n",
      "[975]\ttraining's rmse: 0.0811909\tvalid_1's rmse: 0.0845048\n",
      "[1000]\ttraining's rmse: 0.0811698\tvalid_1's rmse: 0.0845004\n",
      "[1025]\ttraining's rmse: 0.0811464\tvalid_1's rmse: 0.0844955\n",
      "[1050]\ttraining's rmse: 0.0811268\tvalid_1's rmse: 0.0844905\n",
      "[1075]\ttraining's rmse: 0.0811073\tvalid_1's rmse: 0.0844869\n",
      "[1100]\ttraining's rmse: 0.0810925\tvalid_1's rmse: 0.0844828\n",
      "[1125]\ttraining's rmse: 0.0810746\tvalid_1's rmse: 0.0844782\n",
      "[1150]\ttraining's rmse: 0.0810566\tvalid_1's rmse: 0.0844739\n",
      "[1175]\ttraining's rmse: 0.0810409\tvalid_1's rmse: 0.084471\n",
      "[1200]\ttraining's rmse: 0.0810248\tvalid_1's rmse: 0.0844674\n",
      "[1225]\ttraining's rmse: 0.0810092\tvalid_1's rmse: 0.0844643\n",
      "[1250]\ttraining's rmse: 0.0809983\tvalid_1's rmse: 0.0844612\n",
      "[1275]\ttraining's rmse: 0.0809817\tvalid_1's rmse: 0.0844591\n",
      "[1300]\ttraining's rmse: 0.0809691\tvalid_1's rmse: 0.0844567\n",
      "[1325]\ttraining's rmse: 0.0809566\tvalid_1's rmse: 0.0844546\n",
      "[1350]\ttraining's rmse: 0.0809425\tvalid_1's rmse: 0.0844529\n",
      "[1375]\ttraining's rmse: 0.0809302\tvalid_1's rmse: 0.0844509\n",
      "[1400]\ttraining's rmse: 0.0809195\tvalid_1's rmse: 0.0844485\n",
      "[1425]\ttraining's rmse: 0.0809106\tvalid_1's rmse: 0.0844472\n",
      "[1450]\ttraining's rmse: 0.0809003\tvalid_1's rmse: 0.0844453\n",
      "[1475]\ttraining's rmse: 0.0808892\tvalid_1's rmse: 0.0844433\n",
      "[1500]\ttraining's rmse: 0.0808803\tvalid_1's rmse: 0.0844419\n",
      "[1525]\ttraining's rmse: 0.0808696\tvalid_1's rmse: 0.0844401\n",
      "[1550]\ttraining's rmse: 0.0808593\tvalid_1's rmse: 0.0844387\n",
      "[1575]\ttraining's rmse: 0.0808504\tvalid_1's rmse: 0.0844368\n",
      "[1600]\ttraining's rmse: 0.0808431\tvalid_1's rmse: 0.0844353\n",
      "[1625]\ttraining's rmse: 0.0808342\tvalid_1's rmse: 0.0844338\n",
      "[1650]\ttraining's rmse: 0.0808284\tvalid_1's rmse: 0.084433\n",
      "[1675]\ttraining's rmse: 0.0808224\tvalid_1's rmse: 0.0844312\n",
      "[1700]\ttraining's rmse: 0.0808173\tvalid_1's rmse: 0.0844307\n",
      "[1725]\ttraining's rmse: 0.0808112\tvalid_1's rmse: 0.0844294\n",
      "[1750]\ttraining's rmse: 0.0808035\tvalid_1's rmse: 0.0844283\n",
      "[1775]\ttraining's rmse: 0.0807968\tvalid_1's rmse: 0.0844275\n",
      "[1800]\ttraining's rmse: 0.0807902\tvalid_1's rmse: 0.084427\n",
      "[1825]\ttraining's rmse: 0.0807827\tvalid_1's rmse: 0.0844257\n",
      "[1850]\ttraining's rmse: 0.0807765\tvalid_1's rmse: 0.0844245\n",
      "[1875]\ttraining's rmse: 0.0807726\tvalid_1's rmse: 0.0844238\n",
      "[1900]\ttraining's rmse: 0.0807683\tvalid_1's rmse: 0.0844239\n",
      "[1925]\ttraining's rmse: 0.0807636\tvalid_1's rmse: 0.0844234\n",
      "[1950]\ttraining's rmse: 0.0807596\tvalid_1's rmse: 0.0844222\n",
      "[1975]\ttraining's rmse: 0.0807569\tvalid_1's rmse: 0.0844219\n",
      "[2000]\ttraining's rmse: 0.0807523\tvalid_1's rmse: 0.0844211\n",
      "[2025]\ttraining's rmse: 0.0807481\tvalid_1's rmse: 0.0844205\n",
      "[2050]\ttraining's rmse: 0.0807437\tvalid_1's rmse: 0.08442\n",
      "[2075]\ttraining's rmse: 0.0807407\tvalid_1's rmse: 0.0844191\n",
      "[2100]\ttraining's rmse: 0.0807377\tvalid_1's rmse: 0.0844189\n",
      "[2125]\ttraining's rmse: 0.0807356\tvalid_1's rmse: 0.0844189\n",
      "[2150]\ttraining's rmse: 0.0807316\tvalid_1's rmse: 0.0844186\n",
      "[2175]\ttraining's rmse: 0.0807287\tvalid_1's rmse: 0.0844184\n",
      "[2200]\ttraining's rmse: 0.0807266\tvalid_1's rmse: 0.0844179\n",
      "[2225]\ttraining's rmse: 0.0807238\tvalid_1's rmse: 0.0844178\n",
      "[2250]\ttraining's rmse: 0.0807208\tvalid_1's rmse: 0.0844173\n",
      "[2275]\ttraining's rmse: 0.0807178\tvalid_1's rmse: 0.0844167\n",
      "[2300]\ttraining's rmse: 0.0807131\tvalid_1's rmse: 0.0844165\n",
      "[2325]\ttraining's rmse: 0.0807099\tvalid_1's rmse: 0.0844165\n",
      "[2350]\ttraining's rmse: 0.0807079\tvalid_1's rmse: 0.0844161\n",
      "[2375]\ttraining's rmse: 0.080705\tvalid_1's rmse: 0.0844161\n",
      "[2400]\ttraining's rmse: 0.080701\tvalid_1's rmse: 0.0844162\n",
      "[2425]\ttraining's rmse: 0.0806978\tvalid_1's rmse: 0.0844164\n",
      "Early stopping, best iteration is:\n",
      "[2386]\ttraining's rmse: 0.0807037\tvalid_1's rmse: 0.0844158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0852831\tvalid_1's rmse: 0.0812413\n",
      "[50]\ttraining's rmse: 0.0851741\tvalid_1's rmse: 0.0811942\n",
      "[75]\ttraining's rmse: 0.0850607\tvalid_1's rmse: 0.0811493\n",
      "[100]\ttraining's rmse: 0.0849597\tvalid_1's rmse: 0.0811091\n",
      "[125]\ttraining's rmse: 0.0848562\tvalid_1's rmse: 0.0810681\n",
      "[150]\ttraining's rmse: 0.0847605\tvalid_1's rmse: 0.0810322\n",
      "[175]\ttraining's rmse: 0.0846819\tvalid_1's rmse: 0.0810033\n",
      "[200]\ttraining's rmse: 0.0845963\tvalid_1's rmse: 0.0809737\n",
      "[225]\ttraining's rmse: 0.0845087\tvalid_1's rmse: 0.080943\n",
      "[250]\ttraining's rmse: 0.0844385\tvalid_1's rmse: 0.0809179\n",
      "[275]\ttraining's rmse: 0.0843748\tvalid_1's rmse: 0.0808938\n",
      "[300]\ttraining's rmse: 0.0843091\tvalid_1's rmse: 0.0808719\n",
      "[325]\ttraining's rmse: 0.0842436\tvalid_1's rmse: 0.0808518\n",
      "[350]\ttraining's rmse: 0.0841806\tvalid_1's rmse: 0.0808315\n",
      "[375]\ttraining's rmse: 0.0841262\tvalid_1's rmse: 0.0808142\n",
      "[400]\ttraining's rmse: 0.0840691\tvalid_1's rmse: 0.080801\n",
      "[425]\ttraining's rmse: 0.0840177\tvalid_1's rmse: 0.0807911\n",
      "[450]\ttraining's rmse: 0.0839679\tvalid_1's rmse: 0.0807747\n",
      "[475]\ttraining's rmse: 0.0839243\tvalid_1's rmse: 0.0807661\n",
      "[500]\ttraining's rmse: 0.0838838\tvalid_1's rmse: 0.080753\n",
      "[525]\ttraining's rmse: 0.0838318\tvalid_1's rmse: 0.080739\n",
      "[550]\ttraining's rmse: 0.0837851\tvalid_1's rmse: 0.0807361\n",
      "[575]\ttraining's rmse: 0.0837424\tvalid_1's rmse: 0.0807308\n",
      "[600]\ttraining's rmse: 0.0837002\tvalid_1's rmse: 0.0807236\n",
      "[625]\ttraining's rmse: 0.0836671\tvalid_1's rmse: 0.0807152\n",
      "[650]\ttraining's rmse: 0.0836241\tvalid_1's rmse: 0.0807159\n",
      "[675]\ttraining's rmse: 0.083582\tvalid_1's rmse: 0.080717\n",
      "[700]\ttraining's rmse: 0.0835444\tvalid_1's rmse: 0.080709\n",
      "[725]\ttraining's rmse: 0.0835113\tvalid_1's rmse: 0.0807214\n",
      "[750]\ttraining's rmse: 0.0834796\tvalid_1's rmse: 0.0807193\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0835372\tvalid_1's rmse: 0.0807078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0828071\tvalid_1's rmse: 0.0854182\n",
      "[50]\ttraining's rmse: 0.0826799\tvalid_1's rmse: 0.0853662\n",
      "[75]\ttraining's rmse: 0.0825536\tvalid_1's rmse: 0.0853145\n",
      "[100]\ttraining's rmse: 0.0824386\tvalid_1's rmse: 0.0852716\n",
      "[125]\ttraining's rmse: 0.0823221\tvalid_1's rmse: 0.0852265\n",
      "[150]\ttraining's rmse: 0.0822131\tvalid_1's rmse: 0.0851844\n",
      "[175]\ttraining's rmse: 0.0821239\tvalid_1's rmse: 0.0851502\n",
      "[200]\ttraining's rmse: 0.0820277\tvalid_1's rmse: 0.0851133\n",
      "[225]\ttraining's rmse: 0.0819348\tvalid_1's rmse: 0.0850786\n",
      "[250]\ttraining's rmse: 0.0818558\tvalid_1's rmse: 0.0850475\n",
      "[275]\ttraining's rmse: 0.0817803\tvalid_1's rmse: 0.0850201\n",
      "[300]\ttraining's rmse: 0.0817081\tvalid_1's rmse: 0.0849929\n",
      "[325]\ttraining's rmse: 0.0816348\tvalid_1's rmse: 0.0849659\n",
      "[350]\ttraining's rmse: 0.0815653\tvalid_1's rmse: 0.0849418\n",
      "[375]\ttraining's rmse: 0.0815039\tvalid_1's rmse: 0.0849199\n",
      "[400]\ttraining's rmse: 0.0814426\tvalid_1's rmse: 0.0848993\n",
      "[425]\ttraining's rmse: 0.0813844\tvalid_1's rmse: 0.0848801\n",
      "[450]\ttraining's rmse: 0.0813347\tvalid_1's rmse: 0.0848617\n",
      "[475]\ttraining's rmse: 0.0812905\tvalid_1's rmse: 0.0848451\n",
      "[500]\ttraining's rmse: 0.0812466\tvalid_1's rmse: 0.0848288\n",
      "[525]\ttraining's rmse: 0.0811958\tvalid_1's rmse: 0.0848131\n",
      "[550]\ttraining's rmse: 0.0811489\tvalid_1's rmse: 0.084798\n",
      "[575]\ttraining's rmse: 0.0811038\tvalid_1's rmse: 0.0847845\n",
      "[600]\ttraining's rmse: 0.0810618\tvalid_1's rmse: 0.0847698\n",
      "[625]\ttraining's rmse: 0.0810288\tvalid_1's rmse: 0.0847592\n",
      "[650]\ttraining's rmse: 0.0809879\tvalid_1's rmse: 0.0847467\n",
      "[675]\ttraining's rmse: 0.0809472\tvalid_1's rmse: 0.0847338\n",
      "[700]\ttraining's rmse: 0.0809105\tvalid_1's rmse: 0.0847215\n",
      "[725]\ttraining's rmse: 0.080877\tvalid_1's rmse: 0.084712\n",
      "[750]\ttraining's rmse: 0.0808454\tvalid_1's rmse: 0.084701\n",
      "[775]\ttraining's rmse: 0.0808187\tvalid_1's rmse: 0.0846919\n",
      "[800]\ttraining's rmse: 0.0807867\tvalid_1's rmse: 0.0846828\n",
      "[825]\ttraining's rmse: 0.0807609\tvalid_1's rmse: 0.0846747\n",
      "[850]\ttraining's rmse: 0.0807292\tvalid_1's rmse: 0.0846672\n",
      "[875]\ttraining's rmse: 0.0807039\tvalid_1's rmse: 0.0846601\n",
      "[900]\ttraining's rmse: 0.0806754\tvalid_1's rmse: 0.0846523\n",
      "[925]\ttraining's rmse: 0.0806503\tvalid_1's rmse: 0.0846458\n",
      "[950]\ttraining's rmse: 0.0806279\tvalid_1's rmse: 0.084639\n",
      "[975]\ttraining's rmse: 0.0806051\tvalid_1's rmse: 0.0846331\n",
      "[1000]\ttraining's rmse: 0.0805834\tvalid_1's rmse: 0.0846264\n",
      "[1025]\ttraining's rmse: 0.0805599\tvalid_1's rmse: 0.0846202\n",
      "[1050]\ttraining's rmse: 0.0805383\tvalid_1's rmse: 0.0846144\n",
      "[1075]\ttraining's rmse: 0.080517\tvalid_1's rmse: 0.0846091\n",
      "[1100]\ttraining's rmse: 0.0804997\tvalid_1's rmse: 0.0846038\n",
      "[1125]\ttraining's rmse: 0.0804849\tvalid_1's rmse: 0.084599\n",
      "[1150]\ttraining's rmse: 0.080468\tvalid_1's rmse: 0.0845943\n",
      "[1175]\ttraining's rmse: 0.0804502\tvalid_1's rmse: 0.08459\n",
      "[1200]\ttraining's rmse: 0.0804353\tvalid_1's rmse: 0.0845848\n",
      "[1225]\ttraining's rmse: 0.080422\tvalid_1's rmse: 0.0845809\n",
      "[1250]\ttraining's rmse: 0.0804083\tvalid_1's rmse: 0.0845766\n",
      "[1275]\ttraining's rmse: 0.080393\tvalid_1's rmse: 0.0845729\n",
      "[1300]\ttraining's rmse: 0.0803794\tvalid_1's rmse: 0.0845664\n",
      "[1325]\ttraining's rmse: 0.080367\tvalid_1's rmse: 0.0845639\n",
      "[1350]\ttraining's rmse: 0.0803547\tvalid_1's rmse: 0.0845611\n",
      "[1375]\ttraining's rmse: 0.0803411\tvalid_1's rmse: 0.0845578\n",
      "[1400]\ttraining's rmse: 0.08033\tvalid_1's rmse: 0.0845542\n",
      "[1425]\ttraining's rmse: 0.0803178\tvalid_1's rmse: 0.0845509\n",
      "[1450]\ttraining's rmse: 0.0803078\tvalid_1's rmse: 0.0845477\n",
      "[1475]\ttraining's rmse: 0.0802973\tvalid_1's rmse: 0.0845443\n",
      "[1500]\ttraining's rmse: 0.0802894\tvalid_1's rmse: 0.084541\n",
      "[1525]\ttraining's rmse: 0.0802811\tvalid_1's rmse: 0.0845379\n",
      "[1550]\ttraining's rmse: 0.0802707\tvalid_1's rmse: 0.084535\n",
      "[1575]\ttraining's rmse: 0.0802637\tvalid_1's rmse: 0.0845324\n",
      "[1600]\ttraining's rmse: 0.0802566\tvalid_1's rmse: 0.0845303\n",
      "[1625]\ttraining's rmse: 0.0802486\tvalid_1's rmse: 0.0845283\n",
      "[1650]\ttraining's rmse: 0.0802421\tvalid_1's rmse: 0.0845264\n",
      "[1675]\ttraining's rmse: 0.0802361\tvalid_1's rmse: 0.0845234\n",
      "[1700]\ttraining's rmse: 0.0802292\tvalid_1's rmse: 0.0845215\n",
      "[1725]\ttraining's rmse: 0.0802228\tvalid_1's rmse: 0.0845188\n",
      "[1750]\ttraining's rmse: 0.0802146\tvalid_1's rmse: 0.0845176\n",
      "[1775]\ttraining's rmse: 0.0802088\tvalid_1's rmse: 0.0845154\n",
      "[1800]\ttraining's rmse: 0.0802044\tvalid_1's rmse: 0.0845141\n",
      "[1825]\ttraining's rmse: 0.0801991\tvalid_1's rmse: 0.0845128\n",
      "[1850]\ttraining's rmse: 0.0801952\tvalid_1's rmse: 0.0845112\n",
      "[1875]\ttraining's rmse: 0.0801897\tvalid_1's rmse: 0.0845096\n",
      "[1900]\ttraining's rmse: 0.0801861\tvalid_1's rmse: 0.0845092\n",
      "[1925]\ttraining's rmse: 0.0801817\tvalid_1's rmse: 0.0845084\n",
      "[1950]\ttraining's rmse: 0.0801784\tvalid_1's rmse: 0.0845073\n",
      "[1975]\ttraining's rmse: 0.0801748\tvalid_1's rmse: 0.0845063\n",
      "[2000]\ttraining's rmse: 0.0801713\tvalid_1's rmse: 0.0845051\n",
      "[2025]\ttraining's rmse: 0.0801678\tvalid_1's rmse: 0.0845042\n",
      "[2050]\ttraining's rmse: 0.0801634\tvalid_1's rmse: 0.0845015\n",
      "[2075]\ttraining's rmse: 0.0801605\tvalid_1's rmse: 0.0845008\n",
      "[2100]\ttraining's rmse: 0.0801569\tvalid_1's rmse: 0.0844999\n",
      "[2125]\ttraining's rmse: 0.0801534\tvalid_1's rmse: 0.0844985\n",
      "[2150]\ttraining's rmse: 0.0801507\tvalid_1's rmse: 0.0844981\n",
      "[2175]\ttraining's rmse: 0.0801482\tvalid_1's rmse: 0.0844977\n",
      "[2200]\ttraining's rmse: 0.0801455\tvalid_1's rmse: 0.084497\n",
      "[2225]\ttraining's rmse: 0.0801418\tvalid_1's rmse: 0.0844957\n",
      "[2250]\ttraining's rmse: 0.0801388\tvalid_1's rmse: 0.0844953\n",
      "[2275]\ttraining's rmse: 0.0801359\tvalid_1's rmse: 0.0844938\n",
      "[2300]\ttraining's rmse: 0.0801325\tvalid_1's rmse: 0.0844923\n",
      "[2325]\ttraining's rmse: 0.080129\tvalid_1's rmse: 0.0844915\n",
      "[2350]\ttraining's rmse: 0.0801268\tvalid_1's rmse: 0.0844912\n",
      "[2375]\ttraining's rmse: 0.0801244\tvalid_1's rmse: 0.0844906\n",
      "[2400]\ttraining's rmse: 0.080122\tvalid_1's rmse: 0.0844898\n",
      "[2425]\ttraining's rmse: 0.0801197\tvalid_1's rmse: 0.084489\n",
      "[2450]\ttraining's rmse: 0.0801166\tvalid_1's rmse: 0.0844886\n",
      "[2475]\ttraining's rmse: 0.0801141\tvalid_1's rmse: 0.0844883\n",
      "[2500]\ttraining's rmse: 0.0801114\tvalid_1's rmse: 0.0844872\n",
      "[2525]\ttraining's rmse: 0.0801091\tvalid_1's rmse: 0.084487\n",
      "[2550]\ttraining's rmse: 0.0801067\tvalid_1's rmse: 0.0844862\n",
      "[2575]\ttraining's rmse: 0.0801054\tvalid_1's rmse: 0.0844859\n",
      "[2600]\ttraining's rmse: 0.0801038\tvalid_1's rmse: 0.0844855\n",
      "[2625]\ttraining's rmse: 0.0801022\tvalid_1's rmse: 0.0844845\n",
      "[2650]\ttraining's rmse: 0.0801013\tvalid_1's rmse: 0.0844842\n",
      "[2675]\ttraining's rmse: 0.0801003\tvalid_1's rmse: 0.0844838\n",
      "[2700]\ttraining's rmse: 0.0800984\tvalid_1's rmse: 0.0844833\n",
      "[2725]\ttraining's rmse: 0.0800971\tvalid_1's rmse: 0.0844826\n",
      "[2750]\ttraining's rmse: 0.0800955\tvalid_1's rmse: 0.0844818\n",
      "[2775]\ttraining's rmse: 0.0800931\tvalid_1's rmse: 0.0844819\n",
      "[2800]\ttraining's rmse: 0.0800911\tvalid_1's rmse: 0.0844818\n",
      "Early stopping, best iteration is:\n",
      "[2758]\ttraining's rmse: 0.0800943\tvalid_1's rmse: 0.0844815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.083107\tvalid_1's rmse: 0.0848409\n",
      "[50]\ttraining's rmse: 0.0829903\tvalid_1's rmse: 0.084786\n",
      "[75]\ttraining's rmse: 0.0828696\tvalid_1's rmse: 0.084733\n",
      "[100]\ttraining's rmse: 0.0827624\tvalid_1's rmse: 0.0846861\n",
      "[125]\ttraining's rmse: 0.0826568\tvalid_1's rmse: 0.08464\n",
      "[150]\ttraining's rmse: 0.0825553\tvalid_1's rmse: 0.0845957\n",
      "[175]\ttraining's rmse: 0.0824724\tvalid_1's rmse: 0.0845597\n",
      "[200]\ttraining's rmse: 0.0823811\tvalid_1's rmse: 0.0845234\n",
      "[225]\ttraining's rmse: 0.0822942\tvalid_1's rmse: 0.0844895\n",
      "[250]\ttraining's rmse: 0.0822209\tvalid_1's rmse: 0.0844588\n",
      "[275]\ttraining's rmse: 0.0821524\tvalid_1's rmse: 0.0844318\n",
      "[300]\ttraining's rmse: 0.0820821\tvalid_1's rmse: 0.0844062\n",
      "[325]\ttraining's rmse: 0.0820106\tvalid_1's rmse: 0.0843806\n",
      "[350]\ttraining's rmse: 0.0819436\tvalid_1's rmse: 0.0843579\n",
      "[375]\ttraining's rmse: 0.0818881\tvalid_1's rmse: 0.0843369\n",
      "[400]\ttraining's rmse: 0.0818263\tvalid_1's rmse: 0.084316\n",
      "[425]\ttraining's rmse: 0.0817698\tvalid_1's rmse: 0.0842959\n",
      "[450]\ttraining's rmse: 0.08172\tvalid_1's rmse: 0.0842771\n",
      "[475]\ttraining's rmse: 0.0816749\tvalid_1's rmse: 0.0842607\n",
      "[500]\ttraining's rmse: 0.0816333\tvalid_1's rmse: 0.0842447\n",
      "[525]\ttraining's rmse: 0.0815788\tvalid_1's rmse: 0.084227\n",
      "[550]\ttraining's rmse: 0.0815297\tvalid_1's rmse: 0.0842115\n",
      "[575]\ttraining's rmse: 0.0814869\tvalid_1's rmse: 0.0841976\n",
      "[600]\ttraining's rmse: 0.0814437\tvalid_1's rmse: 0.0841845\n",
      "[625]\ttraining's rmse: 0.0814098\tvalid_1's rmse: 0.0841728\n",
      "[650]\ttraining's rmse: 0.0813673\tvalid_1's rmse: 0.0841608\n",
      "[675]\ttraining's rmse: 0.0813257\tvalid_1's rmse: 0.0841495\n",
      "[700]\ttraining's rmse: 0.0812895\tvalid_1's rmse: 0.0841402\n",
      "[725]\ttraining's rmse: 0.0812556\tvalid_1's rmse: 0.0841301\n",
      "[750]\ttraining's rmse: 0.081223\tvalid_1's rmse: 0.0841206\n",
      "[775]\ttraining's rmse: 0.0811953\tvalid_1's rmse: 0.0841115\n",
      "[800]\ttraining's rmse: 0.0811592\tvalid_1's rmse: 0.0841036\n",
      "[825]\ttraining's rmse: 0.0811314\tvalid_1's rmse: 0.0840952\n",
      "[850]\ttraining's rmse: 0.0811006\tvalid_1's rmse: 0.0840874\n",
      "[875]\ttraining's rmse: 0.0810749\tvalid_1's rmse: 0.0840803\n",
      "[900]\ttraining's rmse: 0.0810471\tvalid_1's rmse: 0.0840729\n",
      "[925]\ttraining's rmse: 0.0810204\tvalid_1's rmse: 0.0840672\n",
      "[950]\ttraining's rmse: 0.0809956\tvalid_1's rmse: 0.084062\n",
      "[975]\ttraining's rmse: 0.0809728\tvalid_1's rmse: 0.0840566\n",
      "[1000]\ttraining's rmse: 0.0809516\tvalid_1's rmse: 0.0840521\n",
      "[1025]\ttraining's rmse: 0.0809269\tvalid_1's rmse: 0.0840473\n",
      "[1050]\ttraining's rmse: 0.0809057\tvalid_1's rmse: 0.0840421\n",
      "[1075]\ttraining's rmse: 0.0808839\tvalid_1's rmse: 0.0840383\n",
      "[1100]\ttraining's rmse: 0.0808676\tvalid_1's rmse: 0.0840341\n",
      "[1125]\ttraining's rmse: 0.0808513\tvalid_1's rmse: 0.0840307\n",
      "[1150]\ttraining's rmse: 0.0808323\tvalid_1's rmse: 0.0840269\n",
      "[1175]\ttraining's rmse: 0.0808182\tvalid_1's rmse: 0.0840241\n",
      "[1200]\ttraining's rmse: 0.0808014\tvalid_1's rmse: 0.0840202\n",
      "[1225]\ttraining's rmse: 0.080786\tvalid_1's rmse: 0.0840171\n",
      "[1250]\ttraining's rmse: 0.0807743\tvalid_1's rmse: 0.0840144\n",
      "[1275]\ttraining's rmse: 0.0807573\tvalid_1's rmse: 0.0840121\n",
      "[1300]\ttraining's rmse: 0.0807449\tvalid_1's rmse: 0.0840098\n",
      "[1325]\ttraining's rmse: 0.0807305\tvalid_1's rmse: 0.0840078\n",
      "[1350]\ttraining's rmse: 0.080718\tvalid_1's rmse: 0.084006\n",
      "[1375]\ttraining's rmse: 0.0807049\tvalid_1's rmse: 0.0840039\n",
      "[1400]\ttraining's rmse: 0.0806939\tvalid_1's rmse: 0.0840016\n",
      "[1425]\ttraining's rmse: 0.0806821\tvalid_1's rmse: 0.0840001\n",
      "[1450]\ttraining's rmse: 0.080674\tvalid_1's rmse: 0.0839987\n",
      "[1475]\ttraining's rmse: 0.0806632\tvalid_1's rmse: 0.0839965\n",
      "[1500]\ttraining's rmse: 0.0806543\tvalid_1's rmse: 0.0839956\n",
      "[1525]\ttraining's rmse: 0.0806446\tvalid_1's rmse: 0.0839945\n",
      "[1550]\ttraining's rmse: 0.0806348\tvalid_1's rmse: 0.0839934\n",
      "[1575]\ttraining's rmse: 0.0806258\tvalid_1's rmse: 0.0839913\n",
      "[1600]\ttraining's rmse: 0.0806195\tvalid_1's rmse: 0.0839907\n",
      "[1625]\ttraining's rmse: 0.0806129\tvalid_1's rmse: 0.0839896\n",
      "[1650]\ttraining's rmse: 0.0806051\tvalid_1's rmse: 0.083988\n",
      "[1675]\ttraining's rmse: 0.080598\tvalid_1's rmse: 0.0839865\n",
      "[1700]\ttraining's rmse: 0.0805925\tvalid_1's rmse: 0.0839857\n",
      "[1725]\ttraining's rmse: 0.0805875\tvalid_1's rmse: 0.0839849\n",
      "[1750]\ttraining's rmse: 0.0805802\tvalid_1's rmse: 0.083984\n",
      "[1775]\ttraining's rmse: 0.0805747\tvalid_1's rmse: 0.0839835\n",
      "[1800]\ttraining's rmse: 0.0805683\tvalid_1's rmse: 0.0839828\n",
      "[1825]\ttraining's rmse: 0.0805614\tvalid_1's rmse: 0.0839815\n",
      "[1850]\ttraining's rmse: 0.0805556\tvalid_1's rmse: 0.0839804\n",
      "[1875]\ttraining's rmse: 0.0805501\tvalid_1's rmse: 0.0839799\n",
      "[1900]\ttraining's rmse: 0.080545\tvalid_1's rmse: 0.0839797\n",
      "[1925]\ttraining's rmse: 0.0805414\tvalid_1's rmse: 0.0839791\n",
      "[1950]\ttraining's rmse: 0.0805383\tvalid_1's rmse: 0.0839783\n",
      "[1975]\ttraining's rmse: 0.0805338\tvalid_1's rmse: 0.0839776\n",
      "[2000]\ttraining's rmse: 0.0805293\tvalid_1's rmse: 0.0839771\n",
      "[2025]\ttraining's rmse: 0.0805267\tvalid_1's rmse: 0.0839765\n",
      "[2050]\ttraining's rmse: 0.0805216\tvalid_1's rmse: 0.0839763\n",
      "[2075]\ttraining's rmse: 0.0805191\tvalid_1's rmse: 0.0839761\n",
      "[2100]\ttraining's rmse: 0.0805161\tvalid_1's rmse: 0.0839756\n",
      "[2125]\ttraining's rmse: 0.0805125\tvalid_1's rmse: 0.0839755\n",
      "[2150]\ttraining's rmse: 0.0805095\tvalid_1's rmse: 0.0839757\n",
      "[2175]\ttraining's rmse: 0.0805068\tvalid_1's rmse: 0.0839759\n",
      "Early stopping, best iteration is:\n",
      "[2134]\ttraining's rmse: 0.080511\tvalid_1's rmse: 0.0839754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0850143\tvalid_1's rmse: 0.0809694\n",
      "[50]\ttraining's rmse: 0.0849062\tvalid_1's rmse: 0.0809224\n",
      "[75]\ttraining's rmse: 0.0847927\tvalid_1's rmse: 0.0808753\n",
      "[100]\ttraining's rmse: 0.0846916\tvalid_1's rmse: 0.080834\n",
      "[125]\ttraining's rmse: 0.0845882\tvalid_1's rmse: 0.0807931\n",
      "[150]\ttraining's rmse: 0.0844932\tvalid_1's rmse: 0.0807568\n",
      "[175]\ttraining's rmse: 0.0844143\tvalid_1's rmse: 0.0807268\n",
      "[200]\ttraining's rmse: 0.0843324\tvalid_1's rmse: 0.0806956\n",
      "[225]\ttraining's rmse: 0.0842502\tvalid_1's rmse: 0.0806652\n",
      "[250]\ttraining's rmse: 0.0841809\tvalid_1's rmse: 0.0806399\n",
      "[275]\ttraining's rmse: 0.0841171\tvalid_1's rmse: 0.0806163\n",
      "[300]\ttraining's rmse: 0.0840534\tvalid_1's rmse: 0.0805934\n",
      "[325]\ttraining's rmse: 0.0839871\tvalid_1's rmse: 0.0805719\n",
      "[350]\ttraining's rmse: 0.0839226\tvalid_1's rmse: 0.0805507\n",
      "[375]\ttraining's rmse: 0.0838723\tvalid_1's rmse: 0.0805335\n",
      "[400]\ttraining's rmse: 0.0838167\tvalid_1's rmse: 0.0805216\n",
      "[425]\ttraining's rmse: 0.0837638\tvalid_1's rmse: 0.0805064\n",
      "[450]\ttraining's rmse: 0.0837146\tvalid_1's rmse: 0.0804935\n",
      "[475]\ttraining's rmse: 0.083668\tvalid_1's rmse: 0.080482\n",
      "[500]\ttraining's rmse: 0.0836296\tvalid_1's rmse: 0.0804681\n",
      "[525]\ttraining's rmse: 0.0835787\tvalid_1's rmse: 0.0804599\n",
      "[550]\ttraining's rmse: 0.0835343\tvalid_1's rmse: 0.0804573\n",
      "[575]\ttraining's rmse: 0.0834922\tvalid_1's rmse: 0.0804458\n",
      "[600]\ttraining's rmse: 0.0834507\tvalid_1's rmse: 0.0804374\n",
      "[625]\ttraining's rmse: 0.0834193\tvalid_1's rmse: 0.0804346\n",
      "[650]\ttraining's rmse: 0.0833784\tvalid_1's rmse: 0.0804276\n",
      "[675]\ttraining's rmse: 0.083335\tvalid_1's rmse: 0.080419\n",
      "[700]\ttraining's rmse: 0.0832972\tvalid_1's rmse: 0.0804122\n",
      "[725]\ttraining's rmse: 0.0832629\tvalid_1's rmse: 0.0804139\n",
      "[750]\ttraining's rmse: 0.0832305\tvalid_1's rmse: 0.0804069\n",
      "[775]\ttraining's rmse: 0.0832037\tvalid_1's rmse: 0.0804044\n",
      "[800]\ttraining's rmse: 0.0831694\tvalid_1's rmse: 0.080407\n",
      "[825]\ttraining's rmse: 0.0831403\tvalid_1's rmse: 0.0804072\n",
      "[850]\ttraining's rmse: 0.083111\tvalid_1's rmse: 0.0804067\n",
      "[875]\ttraining's rmse: 0.0830836\tvalid_1's rmse: 0.0804018\n",
      "[900]\ttraining's rmse: 0.0830536\tvalid_1's rmse: 0.080411\n",
      "[925]\ttraining's rmse: 0.0830286\tvalid_1's rmse: 0.0804198\n",
      "Early stopping, best iteration is:\n",
      "[879]\ttraining's rmse: 0.0830783\tvalid_1's rmse: 0.0804008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0840082\tvalid_1's rmse: 0.0864139\n",
      "[50]\ttraining's rmse: 0.0838801\tvalid_1's rmse: 0.0863639\n",
      "[75]\ttraining's rmse: 0.083755\tvalid_1's rmse: 0.0863134\n",
      "[100]\ttraining's rmse: 0.0836378\tvalid_1's rmse: 0.086269\n",
      "[125]\ttraining's rmse: 0.0835188\tvalid_1's rmse: 0.0862256\n",
      "[150]\ttraining's rmse: 0.0834109\tvalid_1's rmse: 0.0861852\n",
      "[175]\ttraining's rmse: 0.0833223\tvalid_1's rmse: 0.0861511\n",
      "[200]\ttraining's rmse: 0.0832282\tvalid_1's rmse: 0.0861167\n",
      "[225]\ttraining's rmse: 0.0831359\tvalid_1's rmse: 0.0860831\n",
      "[250]\ttraining's rmse: 0.0830548\tvalid_1's rmse: 0.0860532\n",
      "[275]\ttraining's rmse: 0.0829809\tvalid_1's rmse: 0.0860267\n",
      "[300]\ttraining's rmse: 0.0829099\tvalid_1's rmse: 0.0860008\n",
      "[325]\ttraining's rmse: 0.0828368\tvalid_1's rmse: 0.0859766\n",
      "[350]\ttraining's rmse: 0.0827658\tvalid_1's rmse: 0.0859534\n",
      "[375]\ttraining's rmse: 0.0827062\tvalid_1's rmse: 0.085933\n",
      "[400]\ttraining's rmse: 0.0826441\tvalid_1's rmse: 0.0859134\n",
      "[425]\ttraining's rmse: 0.0825859\tvalid_1's rmse: 0.085894\n",
      "[450]\ttraining's rmse: 0.0825349\tvalid_1's rmse: 0.0858761\n",
      "[475]\ttraining's rmse: 0.0824853\tvalid_1's rmse: 0.0858595\n",
      "[500]\ttraining's rmse: 0.0824413\tvalid_1's rmse: 0.0858427\n",
      "[525]\ttraining's rmse: 0.0823864\tvalid_1's rmse: 0.0858266\n",
      "[550]\ttraining's rmse: 0.0823392\tvalid_1's rmse: 0.0858125\n",
      "[575]\ttraining's rmse: 0.0822931\tvalid_1's rmse: 0.085798\n",
      "[600]\ttraining's rmse: 0.0822503\tvalid_1's rmse: 0.0857851\n",
      "[625]\ttraining's rmse: 0.0822146\tvalid_1's rmse: 0.0857735\n",
      "[650]\ttraining's rmse: 0.0821724\tvalid_1's rmse: 0.0857617\n",
      "[675]\ttraining's rmse: 0.0821304\tvalid_1's rmse: 0.0857501\n",
      "[700]\ttraining's rmse: 0.0820914\tvalid_1's rmse: 0.0857403\n",
      "[725]\ttraining's rmse: 0.0820585\tvalid_1's rmse: 0.0857306\n",
      "[750]\ttraining's rmse: 0.0820242\tvalid_1's rmse: 0.0857218\n",
      "[775]\ttraining's rmse: 0.0819978\tvalid_1's rmse: 0.0857145\n",
      "[800]\ttraining's rmse: 0.0819622\tvalid_1's rmse: 0.0857057\n",
      "[825]\ttraining's rmse: 0.0819314\tvalid_1's rmse: 0.0856981\n",
      "[850]\ttraining's rmse: 0.0818996\tvalid_1's rmse: 0.0856915\n",
      "[875]\ttraining's rmse: 0.0818737\tvalid_1's rmse: 0.0856849\n",
      "[900]\ttraining's rmse: 0.0818412\tvalid_1's rmse: 0.0856783\n",
      "[925]\ttraining's rmse: 0.0818159\tvalid_1's rmse: 0.0856735\n",
      "[950]\ttraining's rmse: 0.0817914\tvalid_1's rmse: 0.0856684\n",
      "[975]\ttraining's rmse: 0.08177\tvalid_1's rmse: 0.0856622\n",
      "[1000]\ttraining's rmse: 0.0817482\tvalid_1's rmse: 0.0856566\n",
      "[1025]\ttraining's rmse: 0.0817255\tvalid_1's rmse: 0.0856519\n",
      "[1050]\ttraining's rmse: 0.0817062\tvalid_1's rmse: 0.0856466\n",
      "[1075]\ttraining's rmse: 0.0816854\tvalid_1's rmse: 0.0856429\n",
      "[1100]\ttraining's rmse: 0.0816681\tvalid_1's rmse: 0.0856381\n",
      "[1125]\ttraining's rmse: 0.0816497\tvalid_1's rmse: 0.0856337\n",
      "[1150]\ttraining's rmse: 0.0816324\tvalid_1's rmse: 0.0856287\n",
      "[1175]\ttraining's rmse: 0.0816166\tvalid_1's rmse: 0.0856247\n",
      "[1200]\ttraining's rmse: 0.0816018\tvalid_1's rmse: 0.0856205\n",
      "[1225]\ttraining's rmse: 0.0815867\tvalid_1's rmse: 0.0856156\n",
      "[1250]\ttraining's rmse: 0.0815724\tvalid_1's rmse: 0.0856116\n",
      "[1275]\ttraining's rmse: 0.0815551\tvalid_1's rmse: 0.0856091\n",
      "[1300]\ttraining's rmse: 0.0815418\tvalid_1's rmse: 0.0856049\n",
      "[1325]\ttraining's rmse: 0.0815253\tvalid_1's rmse: 0.0856011\n",
      "[1350]\ttraining's rmse: 0.0815113\tvalid_1's rmse: 0.0855985\n",
      "[1375]\ttraining's rmse: 0.0815\tvalid_1's rmse: 0.0855958\n",
      "[1400]\ttraining's rmse: 0.0814896\tvalid_1's rmse: 0.0855923\n",
      "[1425]\ttraining's rmse: 0.0814748\tvalid_1's rmse: 0.085591\n",
      "[1450]\ttraining's rmse: 0.0814631\tvalid_1's rmse: 0.0855891\n",
      "[1475]\ttraining's rmse: 0.0814517\tvalid_1's rmse: 0.0855866\n",
      "[1500]\ttraining's rmse: 0.081441\tvalid_1's rmse: 0.0855834\n",
      "[1525]\ttraining's rmse: 0.0814326\tvalid_1's rmse: 0.0855804\n",
      "[1550]\ttraining's rmse: 0.0814233\tvalid_1's rmse: 0.0855785\n",
      "[1575]\ttraining's rmse: 0.0814154\tvalid_1's rmse: 0.085576\n",
      "[1600]\ttraining's rmse: 0.0814094\tvalid_1's rmse: 0.0855734\n",
      "[1625]\ttraining's rmse: 0.0814027\tvalid_1's rmse: 0.0855716\n",
      "[1650]\ttraining's rmse: 0.0813964\tvalid_1's rmse: 0.0855695\n",
      "[1675]\ttraining's rmse: 0.0813908\tvalid_1's rmse: 0.0855672\n",
      "[1700]\ttraining's rmse: 0.0813854\tvalid_1's rmse: 0.0855656\n",
      "[1725]\ttraining's rmse: 0.0813788\tvalid_1's rmse: 0.085564\n",
      "[1750]\ttraining's rmse: 0.0813716\tvalid_1's rmse: 0.0855626\n",
      "[1775]\ttraining's rmse: 0.0813657\tvalid_1's rmse: 0.0855613\n",
      "[1800]\ttraining's rmse: 0.08136\tvalid_1's rmse: 0.0855604\n",
      "[1825]\ttraining's rmse: 0.0813547\tvalid_1's rmse: 0.0855585\n",
      "[1850]\ttraining's rmse: 0.0813484\tvalid_1's rmse: 0.0855553\n",
      "[1875]\ttraining's rmse: 0.0813424\tvalid_1's rmse: 0.0855549\n",
      "[1900]\ttraining's rmse: 0.0813378\tvalid_1's rmse: 0.0855529\n",
      "[1925]\ttraining's rmse: 0.0813336\tvalid_1's rmse: 0.0855523\n",
      "[1950]\ttraining's rmse: 0.0813293\tvalid_1's rmse: 0.085551\n",
      "[1975]\ttraining's rmse: 0.0813252\tvalid_1's rmse: 0.0855501\n",
      "[2000]\ttraining's rmse: 0.0813216\tvalid_1's rmse: 0.0855486\n",
      "[2025]\ttraining's rmse: 0.0813175\tvalid_1's rmse: 0.0855464\n",
      "[2050]\ttraining's rmse: 0.0813133\tvalid_1's rmse: 0.0855449\n",
      "[2075]\ttraining's rmse: 0.0813106\tvalid_1's rmse: 0.085544\n",
      "[2100]\ttraining's rmse: 0.0813079\tvalid_1's rmse: 0.0855427\n",
      "[2125]\ttraining's rmse: 0.0813055\tvalid_1's rmse: 0.0855414\n",
      "[2150]\ttraining's rmse: 0.0813028\tvalid_1's rmse: 0.0855417\n",
      "Early stopping, best iteration is:\n",
      "[2118]\ttraining's rmse: 0.0813061\tvalid_1's rmse: 0.0855413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.084105\tvalid_1's rmse: 0.0862388\n",
      "[50]\ttraining's rmse: 0.0839895\tvalid_1's rmse: 0.0861867\n",
      "[75]\ttraining's rmse: 0.0838717\tvalid_1's rmse: 0.0861367\n",
      "[100]\ttraining's rmse: 0.0837666\tvalid_1's rmse: 0.0860908\n",
      "[125]\ttraining's rmse: 0.0836569\tvalid_1's rmse: 0.0860458\n",
      "[150]\ttraining's rmse: 0.0835563\tvalid_1's rmse: 0.0860027\n",
      "[175]\ttraining's rmse: 0.0834704\tvalid_1's rmse: 0.085968\n",
      "[200]\ttraining's rmse: 0.0833785\tvalid_1's rmse: 0.0859321\n",
      "[225]\ttraining's rmse: 0.0832932\tvalid_1's rmse: 0.0858992\n",
      "[250]\ttraining's rmse: 0.0832196\tvalid_1's rmse: 0.085868\n",
      "[275]\ttraining's rmse: 0.08315\tvalid_1's rmse: 0.0858398\n",
      "[300]\ttraining's rmse: 0.0830797\tvalid_1's rmse: 0.085814\n",
      "[325]\ttraining's rmse: 0.0830084\tvalid_1's rmse: 0.0857885\n",
      "[350]\ttraining's rmse: 0.0829414\tvalid_1's rmse: 0.0857647\n",
      "[375]\ttraining's rmse: 0.0828864\tvalid_1's rmse: 0.0857435\n",
      "[400]\ttraining's rmse: 0.0828257\tvalid_1's rmse: 0.0857238\n",
      "[425]\ttraining's rmse: 0.0827703\tvalid_1's rmse: 0.0857039\n",
      "[450]\ttraining's rmse: 0.0827196\tvalid_1's rmse: 0.0856861\n",
      "[475]\ttraining's rmse: 0.0826713\tvalid_1's rmse: 0.0856696\n",
      "[500]\ttraining's rmse: 0.082631\tvalid_1's rmse: 0.0856541\n",
      "[525]\ttraining's rmse: 0.0825785\tvalid_1's rmse: 0.0856378\n",
      "[550]\ttraining's rmse: 0.082532\tvalid_1's rmse: 0.0856243\n",
      "[575]\ttraining's rmse: 0.082488\tvalid_1's rmse: 0.0856102\n",
      "[600]\ttraining's rmse: 0.0824464\tvalid_1's rmse: 0.0855984\n",
      "[625]\ttraining's rmse: 0.0824132\tvalid_1's rmse: 0.0855867\n",
      "[650]\ttraining's rmse: 0.0823705\tvalid_1's rmse: 0.0855751\n",
      "[675]\ttraining's rmse: 0.0823305\tvalid_1's rmse: 0.0855634\n",
      "[700]\ttraining's rmse: 0.0822947\tvalid_1's rmse: 0.0855523\n",
      "[725]\ttraining's rmse: 0.0822603\tvalid_1's rmse: 0.0855425\n",
      "[750]\ttraining's rmse: 0.0822277\tvalid_1's rmse: 0.0855329\n",
      "[775]\ttraining's rmse: 0.0822018\tvalid_1's rmse: 0.0855241\n",
      "[800]\ttraining's rmse: 0.0821644\tvalid_1's rmse: 0.0855158\n",
      "[825]\ttraining's rmse: 0.0821379\tvalid_1's rmse: 0.085507\n",
      "[850]\ttraining's rmse: 0.0821085\tvalid_1's rmse: 0.0855002\n",
      "[875]\ttraining's rmse: 0.0820838\tvalid_1's rmse: 0.0854933\n",
      "[900]\ttraining's rmse: 0.0820569\tvalid_1's rmse: 0.0854869\n",
      "[925]\ttraining's rmse: 0.0820323\tvalid_1's rmse: 0.0854811\n",
      "[950]\ttraining's rmse: 0.0820084\tvalid_1's rmse: 0.0854755\n",
      "[975]\ttraining's rmse: 0.0819837\tvalid_1's rmse: 0.0854687\n",
      "[1000]\ttraining's rmse: 0.0819627\tvalid_1's rmse: 0.0854643\n",
      "[1025]\ttraining's rmse: 0.0819379\tvalid_1's rmse: 0.0854593\n",
      "[1050]\ttraining's rmse: 0.0819164\tvalid_1's rmse: 0.0854546\n",
      "[1075]\ttraining's rmse: 0.0818963\tvalid_1's rmse: 0.0854502\n",
      "[1100]\ttraining's rmse: 0.0818803\tvalid_1's rmse: 0.0854453\n",
      "[1125]\ttraining's rmse: 0.0818629\tvalid_1's rmse: 0.0854415\n",
      "[1150]\ttraining's rmse: 0.0818442\tvalid_1's rmse: 0.0854378\n",
      "[1175]\ttraining's rmse: 0.081829\tvalid_1's rmse: 0.085435\n",
      "[1200]\ttraining's rmse: 0.0818135\tvalid_1's rmse: 0.085432\n",
      "[1225]\ttraining's rmse: 0.0817992\tvalid_1's rmse: 0.0854294\n",
      "[1250]\ttraining's rmse: 0.0817841\tvalid_1's rmse: 0.0854267\n",
      "[1275]\ttraining's rmse: 0.0817676\tvalid_1's rmse: 0.0854241\n",
      "[1300]\ttraining's rmse: 0.0817549\tvalid_1's rmse: 0.0854217\n",
      "[1325]\ttraining's rmse: 0.0817426\tvalid_1's rmse: 0.0854199\n",
      "[1350]\ttraining's rmse: 0.0817283\tvalid_1's rmse: 0.0854172\n",
      "[1375]\ttraining's rmse: 0.0817166\tvalid_1's rmse: 0.085415\n",
      "[1400]\ttraining's rmse: 0.0817068\tvalid_1's rmse: 0.0854123\n",
      "[1425]\ttraining's rmse: 0.0816937\tvalid_1's rmse: 0.0854111\n",
      "[1450]\ttraining's rmse: 0.0816816\tvalid_1's rmse: 0.0854088\n",
      "[1475]\ttraining's rmse: 0.0816708\tvalid_1's rmse: 0.0854069\n",
      "[1500]\ttraining's rmse: 0.0816611\tvalid_1's rmse: 0.0854052\n",
      "[1525]\ttraining's rmse: 0.0816499\tvalid_1's rmse: 0.0854034\n",
      "[1550]\ttraining's rmse: 0.0816421\tvalid_1's rmse: 0.085403\n",
      "[1575]\ttraining's rmse: 0.081635\tvalid_1's rmse: 0.0854016\n",
      "[1600]\ttraining's rmse: 0.081628\tvalid_1's rmse: 0.0854007\n",
      "[1625]\ttraining's rmse: 0.0816212\tvalid_1's rmse: 0.0853997\n",
      "[1650]\ttraining's rmse: 0.0816148\tvalid_1's rmse: 0.0853982\n",
      "[1675]\ttraining's rmse: 0.0816096\tvalid_1's rmse: 0.0853971\n",
      "[1700]\ttraining's rmse: 0.0816025\tvalid_1's rmse: 0.0853958\n",
      "[1725]\ttraining's rmse: 0.0815942\tvalid_1's rmse: 0.0853946\n",
      "[1750]\ttraining's rmse: 0.0815873\tvalid_1's rmse: 0.0853926\n",
      "[1775]\ttraining's rmse: 0.0815816\tvalid_1's rmse: 0.0853921\n",
      "[1800]\ttraining's rmse: 0.0815732\tvalid_1's rmse: 0.0853906\n",
      "[1825]\ttraining's rmse: 0.0815681\tvalid_1's rmse: 0.0853894\n",
      "[1850]\ttraining's rmse: 0.0815627\tvalid_1's rmse: 0.0853886\n",
      "[1875]\ttraining's rmse: 0.0815587\tvalid_1's rmse: 0.085388\n",
      "[1900]\ttraining's rmse: 0.0815543\tvalid_1's rmse: 0.0853876\n",
      "[1925]\ttraining's rmse: 0.0815501\tvalid_1's rmse: 0.0853872\n",
      "[1950]\ttraining's rmse: 0.0815472\tvalid_1's rmse: 0.0853866\n",
      "[1975]\ttraining's rmse: 0.0815438\tvalid_1's rmse: 0.085386\n",
      "[2000]\ttraining's rmse: 0.0815393\tvalid_1's rmse: 0.0853852\n",
      "[2025]\ttraining's rmse: 0.0815351\tvalid_1's rmse: 0.0853847\n",
      "[2050]\ttraining's rmse: 0.0815322\tvalid_1's rmse: 0.0853843\n",
      "[2075]\ttraining's rmse: 0.0815292\tvalid_1's rmse: 0.0853842\n",
      "[2100]\ttraining's rmse: 0.0815271\tvalid_1's rmse: 0.085384\n",
      "[2125]\ttraining's rmse: 0.0815242\tvalid_1's rmse: 0.0853836\n",
      "[2150]\ttraining's rmse: 0.08152\tvalid_1's rmse: 0.0853838\n",
      "[2175]\ttraining's rmse: 0.0815171\tvalid_1's rmse: 0.0853837\n",
      "[2200]\ttraining's rmse: 0.0815135\tvalid_1's rmse: 0.0853832\n",
      "[2225]\ttraining's rmse: 0.0815106\tvalid_1's rmse: 0.0853828\n",
      "[2250]\ttraining's rmse: 0.0815081\tvalid_1's rmse: 0.0853829\n",
      "[2275]\ttraining's rmse: 0.0815047\tvalid_1's rmse: 0.0853828\n",
      "[2300]\ttraining's rmse: 0.081501\tvalid_1's rmse: 0.0853822\n",
      "[2325]\ttraining's rmse: 0.0814968\tvalid_1's rmse: 0.0853818\n",
      "[2350]\ttraining's rmse: 0.0814943\tvalid_1's rmse: 0.0853816\n",
      "[2375]\ttraining's rmse: 0.0814914\tvalid_1's rmse: 0.0853808\n",
      "[2400]\ttraining's rmse: 0.0814894\tvalid_1's rmse: 0.0853807\n",
      "[2425]\ttraining's rmse: 0.0814874\tvalid_1's rmse: 0.0853807\n",
      "[2450]\ttraining's rmse: 0.0814844\tvalid_1's rmse: 0.0853802\n",
      "[2475]\ttraining's rmse: 0.0814819\tvalid_1's rmse: 0.0853805\n",
      "[2500]\ttraining's rmse: 0.0814793\tvalid_1's rmse: 0.0853801\n",
      "[2525]\ttraining's rmse: 0.0814776\tvalid_1's rmse: 0.0853801\n",
      "[2550]\ttraining's rmse: 0.0814756\tvalid_1's rmse: 0.0853799\n",
      "[2575]\ttraining's rmse: 0.0814737\tvalid_1's rmse: 0.08538\n",
      "[2600]\ttraining's rmse: 0.0814721\tvalid_1's rmse: 0.0853801\n",
      "[2625]\ttraining's rmse: 0.0814705\tvalid_1's rmse: 0.0853797\n",
      "[2650]\ttraining's rmse: 0.0814693\tvalid_1's rmse: 0.0853799\n",
      "[2675]\ttraining's rmse: 0.0814667\tvalid_1's rmse: 0.08538\n",
      "Early stopping, best iteration is:\n",
      "[2625]\ttraining's rmse: 0.0814705\tvalid_1's rmse: 0.0853797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0862072\tvalid_1's rmse: 0.0819693\n",
      "[50]\ttraining's rmse: 0.0860993\tvalid_1's rmse: 0.0819243\n",
      "[75]\ttraining's rmse: 0.0859842\tvalid_1's rmse: 0.0818782\n",
      "[100]\ttraining's rmse: 0.0858845\tvalid_1's rmse: 0.0818372\n",
      "[125]\ttraining's rmse: 0.0857768\tvalid_1's rmse: 0.0817955\n",
      "[150]\ttraining's rmse: 0.0856787\tvalid_1's rmse: 0.0817587\n",
      "[175]\ttraining's rmse: 0.0855991\tvalid_1's rmse: 0.0817293\n",
      "[200]\ttraining's rmse: 0.0855106\tvalid_1's rmse: 0.0816989\n",
      "[225]\ttraining's rmse: 0.0854257\tvalid_1's rmse: 0.0816677\n",
      "[250]\ttraining's rmse: 0.0853544\tvalid_1's rmse: 0.0816423\n",
      "[275]\ttraining's rmse: 0.0852884\tvalid_1's rmse: 0.0816181\n",
      "[300]\ttraining's rmse: 0.0852235\tvalid_1's rmse: 0.0815977\n",
      "[325]\ttraining's rmse: 0.0851588\tvalid_1's rmse: 0.081578\n",
      "[350]\ttraining's rmse: 0.0850923\tvalid_1's rmse: 0.0815566\n",
      "[375]\ttraining's rmse: 0.0850396\tvalid_1's rmse: 0.0815421\n",
      "[400]\ttraining's rmse: 0.0849819\tvalid_1's rmse: 0.0815384\n",
      "[425]\ttraining's rmse: 0.0849296\tvalid_1's rmse: 0.0815272\n",
      "[450]\ttraining's rmse: 0.0848794\tvalid_1's rmse: 0.0815153\n",
      "[475]\ttraining's rmse: 0.084834\tvalid_1's rmse: 0.0815029\n",
      "[500]\ttraining's rmse: 0.0847968\tvalid_1's rmse: 0.081491\n",
      "[525]\ttraining's rmse: 0.084743\tvalid_1's rmse: 0.0814818\n",
      "[550]\ttraining's rmse: 0.0846975\tvalid_1's rmse: 0.08147\n",
      "[575]\ttraining's rmse: 0.084652\tvalid_1's rmse: 0.0814589\n",
      "[600]\ttraining's rmse: 0.0846081\tvalid_1's rmse: 0.0814484\n",
      "[625]\ttraining's rmse: 0.0845738\tvalid_1's rmse: 0.0814404\n",
      "[650]\ttraining's rmse: 0.0845301\tvalid_1's rmse: 0.081443\n",
      "[675]\ttraining's rmse: 0.0844881\tvalid_1's rmse: 0.0814353\n",
      "[700]\ttraining's rmse: 0.0844534\tvalid_1's rmse: 0.0814278\n",
      "[725]\ttraining's rmse: 0.0844192\tvalid_1's rmse: 0.0814275\n",
      "[750]\ttraining's rmse: 0.0843871\tvalid_1's rmse: 0.0814273\n",
      "[775]\ttraining's rmse: 0.0843579\tvalid_1's rmse: 0.0814349\n",
      "Early stopping, best iteration is:\n",
      "[747]\ttraining's rmse: 0.0843924\tvalid_1's rmse: 0.0814224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0832005\tvalid_1's rmse: 0.0858093\n",
      "[50]\ttraining's rmse: 0.0830735\tvalid_1's rmse: 0.0857567\n",
      "[75]\ttraining's rmse: 0.082946\tvalid_1's rmse: 0.0857038\n",
      "[100]\ttraining's rmse: 0.0828304\tvalid_1's rmse: 0.0856585\n",
      "[125]\ttraining's rmse: 0.0827143\tvalid_1's rmse: 0.0856128\n",
      "[150]\ttraining's rmse: 0.0826049\tvalid_1's rmse: 0.0855714\n",
      "[175]\ttraining's rmse: 0.0825162\tvalid_1's rmse: 0.0855354\n",
      "[200]\ttraining's rmse: 0.0824205\tvalid_1's rmse: 0.0854981\n",
      "[225]\ttraining's rmse: 0.0823244\tvalid_1's rmse: 0.0854611\n",
      "[250]\ttraining's rmse: 0.0822476\tvalid_1's rmse: 0.0854282\n",
      "[275]\ttraining's rmse: 0.0821756\tvalid_1's rmse: 0.0853995\n",
      "[300]\ttraining's rmse: 0.0821042\tvalid_1's rmse: 0.0853717\n",
      "[325]\ttraining's rmse: 0.0820297\tvalid_1's rmse: 0.0853462\n",
      "[350]\ttraining's rmse: 0.0819602\tvalid_1's rmse: 0.0853213\n",
      "[375]\ttraining's rmse: 0.0819004\tvalid_1's rmse: 0.0853003\n",
      "[400]\ttraining's rmse: 0.081836\tvalid_1's rmse: 0.0852781\n",
      "[425]\ttraining's rmse: 0.0817793\tvalid_1's rmse: 0.0852581\n",
      "[450]\ttraining's rmse: 0.0817298\tvalid_1's rmse: 0.0852389\n",
      "[475]\ttraining's rmse: 0.0816791\tvalid_1's rmse: 0.0852209\n",
      "[500]\ttraining's rmse: 0.0816385\tvalid_1's rmse: 0.0852046\n",
      "[525]\ttraining's rmse: 0.0815864\tvalid_1's rmse: 0.0851875\n",
      "[550]\ttraining's rmse: 0.0815402\tvalid_1's rmse: 0.0851714\n",
      "[575]\ttraining's rmse: 0.0814934\tvalid_1's rmse: 0.085157\n",
      "[600]\ttraining's rmse: 0.0814527\tvalid_1's rmse: 0.0851432\n",
      "[625]\ttraining's rmse: 0.0814186\tvalid_1's rmse: 0.0851316\n",
      "[650]\ttraining's rmse: 0.0813752\tvalid_1's rmse: 0.0851179\n",
      "[675]\ttraining's rmse: 0.0813337\tvalid_1's rmse: 0.0851057\n",
      "[700]\ttraining's rmse: 0.0812988\tvalid_1's rmse: 0.0850945\n",
      "[725]\ttraining's rmse: 0.0812647\tvalid_1's rmse: 0.085084\n",
      "[750]\ttraining's rmse: 0.0812322\tvalid_1's rmse: 0.0850745\n",
      "[775]\ttraining's rmse: 0.0812071\tvalid_1's rmse: 0.0850649\n",
      "[800]\ttraining's rmse: 0.0811749\tvalid_1's rmse: 0.0850571\n",
      "[825]\ttraining's rmse: 0.0811449\tvalid_1's rmse: 0.0850473\n",
      "[850]\ttraining's rmse: 0.0811148\tvalid_1's rmse: 0.0850401\n",
      "[875]\ttraining's rmse: 0.0810882\tvalid_1's rmse: 0.0850315\n",
      "[900]\ttraining's rmse: 0.0810599\tvalid_1's rmse: 0.0850245\n",
      "[925]\ttraining's rmse: 0.0810351\tvalid_1's rmse: 0.0850178\n",
      "[950]\ttraining's rmse: 0.081012\tvalid_1's rmse: 0.0850119\n",
      "[975]\ttraining's rmse: 0.08099\tvalid_1's rmse: 0.0850047\n",
      "[1000]\ttraining's rmse: 0.0809669\tvalid_1's rmse: 0.0849985\n",
      "[1025]\ttraining's rmse: 0.080946\tvalid_1's rmse: 0.0849907\n",
      "[1050]\ttraining's rmse: 0.0809248\tvalid_1's rmse: 0.0849837\n",
      "[1075]\ttraining's rmse: 0.080905\tvalid_1's rmse: 0.08498\n",
      "[1100]\ttraining's rmse: 0.0808863\tvalid_1's rmse: 0.0849758\n",
      "[1125]\ttraining's rmse: 0.0808694\tvalid_1's rmse: 0.0849689\n",
      "[1150]\ttraining's rmse: 0.0808517\tvalid_1's rmse: 0.0849646\n",
      "[1175]\ttraining's rmse: 0.0808362\tvalid_1's rmse: 0.0849606\n",
      "[1200]\ttraining's rmse: 0.0808205\tvalid_1's rmse: 0.084956\n",
      "[1225]\ttraining's rmse: 0.0808046\tvalid_1's rmse: 0.0849507\n",
      "[1250]\ttraining's rmse: 0.0807911\tvalid_1's rmse: 0.0849463\n",
      "[1275]\ttraining's rmse: 0.0807761\tvalid_1's rmse: 0.0849428\n",
      "[1300]\ttraining's rmse: 0.0807632\tvalid_1's rmse: 0.0849385\n",
      "[1325]\ttraining's rmse: 0.0807515\tvalid_1's rmse: 0.0849344\n",
      "[1350]\ttraining's rmse: 0.0807381\tvalid_1's rmse: 0.084932\n",
      "[1375]\ttraining's rmse: 0.0807265\tvalid_1's rmse: 0.0849295\n",
      "[1400]\ttraining's rmse: 0.0807169\tvalid_1's rmse: 0.084925\n",
      "[1425]\ttraining's rmse: 0.0807037\tvalid_1's rmse: 0.0849222\n",
      "[1450]\ttraining's rmse: 0.0806909\tvalid_1's rmse: 0.0849193\n",
      "[1475]\ttraining's rmse: 0.0806804\tvalid_1's rmse: 0.0849157\n",
      "[1500]\ttraining's rmse: 0.0806727\tvalid_1's rmse: 0.0849125\n",
      "[1525]\ttraining's rmse: 0.0806637\tvalid_1's rmse: 0.0849092\n",
      "[1550]\ttraining's rmse: 0.0806523\tvalid_1's rmse: 0.0849068\n",
      "[1575]\ttraining's rmse: 0.080644\tvalid_1's rmse: 0.0849046\n",
      "[1600]\ttraining's rmse: 0.0806377\tvalid_1's rmse: 0.0849018\n",
      "[1625]\ttraining's rmse: 0.0806307\tvalid_1's rmse: 0.0848989\n",
      "[1650]\ttraining's rmse: 0.0806229\tvalid_1's rmse: 0.0848964\n",
      "[1675]\ttraining's rmse: 0.0806169\tvalid_1's rmse: 0.0848939\n",
      "[1700]\ttraining's rmse: 0.0806113\tvalid_1's rmse: 0.0848907\n",
      "[1725]\ttraining's rmse: 0.080604\tvalid_1's rmse: 0.0848886\n",
      "[1750]\ttraining's rmse: 0.0805964\tvalid_1's rmse: 0.0848865\n",
      "[1775]\ttraining's rmse: 0.0805903\tvalid_1's rmse: 0.0848847\n",
      "[1800]\ttraining's rmse: 0.0805839\tvalid_1's rmse: 0.0848821\n",
      "[1825]\ttraining's rmse: 0.0805792\tvalid_1's rmse: 0.0848805\n",
      "[1850]\ttraining's rmse: 0.0805759\tvalid_1's rmse: 0.0848787\n",
      "[1875]\ttraining's rmse: 0.080571\tvalid_1's rmse: 0.0848774\n",
      "[1900]\ttraining's rmse: 0.0805664\tvalid_1's rmse: 0.0848758\n",
      "[1925]\ttraining's rmse: 0.0805597\tvalid_1's rmse: 0.0848743\n",
      "[1950]\ttraining's rmse: 0.0805553\tvalid_1's rmse: 0.0848719\n",
      "[1975]\ttraining's rmse: 0.080552\tvalid_1's rmse: 0.084871\n",
      "[2000]\ttraining's rmse: 0.0805488\tvalid_1's rmse: 0.0848706\n",
      "[2025]\ttraining's rmse: 0.0805451\tvalid_1's rmse: 0.0848693\n",
      "[2050]\ttraining's rmse: 0.0805407\tvalid_1's rmse: 0.0848689\n",
      "[2075]\ttraining's rmse: 0.0805382\tvalid_1's rmse: 0.0848676\n",
      "[2100]\ttraining's rmse: 0.0805336\tvalid_1's rmse: 0.0848665\n",
      "[2125]\ttraining's rmse: 0.0805307\tvalid_1's rmse: 0.0848652\n",
      "[2150]\ttraining's rmse: 0.0805259\tvalid_1's rmse: 0.0848642\n",
      "[2175]\ttraining's rmse: 0.080523\tvalid_1's rmse: 0.0848637\n",
      "[2200]\ttraining's rmse: 0.0805199\tvalid_1's rmse: 0.0848615\n",
      "[2225]\ttraining's rmse: 0.0805173\tvalid_1's rmse: 0.0848608\n",
      "[2250]\ttraining's rmse: 0.0805155\tvalid_1's rmse: 0.0848597\n",
      "[2275]\ttraining's rmse: 0.0805112\tvalid_1's rmse: 0.084859\n",
      "[2300]\ttraining's rmse: 0.0805079\tvalid_1's rmse: 0.0848579\n",
      "[2325]\ttraining's rmse: 0.0805042\tvalid_1's rmse: 0.0848577\n",
      "[2350]\ttraining's rmse: 0.0805013\tvalid_1's rmse: 0.0848577\n",
      "[2375]\ttraining's rmse: 0.0804999\tvalid_1's rmse: 0.084857\n",
      "[2400]\ttraining's rmse: 0.0804975\tvalid_1's rmse: 0.0848563\n",
      "[2425]\ttraining's rmse: 0.0804959\tvalid_1's rmse: 0.0848561\n",
      "[2450]\ttraining's rmse: 0.0804944\tvalid_1's rmse: 0.0848554\n",
      "[2475]\ttraining's rmse: 0.080493\tvalid_1's rmse: 0.0848557\n",
      "[2500]\ttraining's rmse: 0.0804896\tvalid_1's rmse: 0.0848553\n",
      "[2525]\ttraining's rmse: 0.0804877\tvalid_1's rmse: 0.0848533\n",
      "[2550]\ttraining's rmse: 0.0804859\tvalid_1's rmse: 0.0848527\n",
      "[2575]\ttraining's rmse: 0.0804836\tvalid_1's rmse: 0.0848523\n",
      "[2600]\ttraining's rmse: 0.080481\tvalid_1's rmse: 0.084852\n",
      "[2625]\ttraining's rmse: 0.0804793\tvalid_1's rmse: 0.0848509\n",
      "[2650]\ttraining's rmse: 0.0804768\tvalid_1's rmse: 0.0848509\n",
      "[2675]\ttraining's rmse: 0.0804755\tvalid_1's rmse: 0.0848506\n",
      "[2700]\ttraining's rmse: 0.0804745\tvalid_1's rmse: 0.0848504\n",
      "[2725]\ttraining's rmse: 0.0804724\tvalid_1's rmse: 0.0848501\n",
      "[2750]\ttraining's rmse: 0.0804706\tvalid_1's rmse: 0.0848498\n",
      "[2775]\ttraining's rmse: 0.0804684\tvalid_1's rmse: 0.0848493\n",
      "[2800]\ttraining's rmse: 0.0804669\tvalid_1's rmse: 0.0848487\n",
      "[2825]\ttraining's rmse: 0.0804658\tvalid_1's rmse: 0.0848489\n",
      "Early stopping, best iteration is:\n",
      "[2787]\ttraining's rmse: 0.0804675\tvalid_1's rmse: 0.0848485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0834656\tvalid_1's rmse: 0.0852995\n",
      "[50]\ttraining's rmse: 0.0833518\tvalid_1's rmse: 0.0852456\n",
      "[75]\ttraining's rmse: 0.0832303\tvalid_1's rmse: 0.0851929\n",
      "[100]\ttraining's rmse: 0.0831226\tvalid_1's rmse: 0.0851463\n",
      "[125]\ttraining's rmse: 0.0830113\tvalid_1's rmse: 0.0850998\n",
      "[150]\ttraining's rmse: 0.0829067\tvalid_1's rmse: 0.0850559\n",
      "[175]\ttraining's rmse: 0.0828244\tvalid_1's rmse: 0.0850211\n",
      "[200]\ttraining's rmse: 0.0827326\tvalid_1's rmse: 0.0849855\n",
      "[225]\ttraining's rmse: 0.0826423\tvalid_1's rmse: 0.0849511\n",
      "[250]\ttraining's rmse: 0.0825642\tvalid_1's rmse: 0.0849219\n",
      "[275]\ttraining's rmse: 0.0824941\tvalid_1's rmse: 0.0848941\n",
      "[300]\ttraining's rmse: 0.082421\tvalid_1's rmse: 0.0848668\n",
      "[325]\ttraining's rmse: 0.0823486\tvalid_1's rmse: 0.0848411\n",
      "[350]\ttraining's rmse: 0.0822788\tvalid_1's rmse: 0.0848178\n",
      "[375]\ttraining's rmse: 0.0822248\tvalid_1's rmse: 0.0847973\n",
      "[400]\ttraining's rmse: 0.0821636\tvalid_1's rmse: 0.084778\n",
      "[425]\ttraining's rmse: 0.0821069\tvalid_1's rmse: 0.0847581\n",
      "[450]\ttraining's rmse: 0.0820548\tvalid_1's rmse: 0.08474\n",
      "[475]\ttraining's rmse: 0.0820051\tvalid_1's rmse: 0.0847225\n",
      "[500]\ttraining's rmse: 0.0819645\tvalid_1's rmse: 0.0847055\n",
      "[525]\ttraining's rmse: 0.0819116\tvalid_1's rmse: 0.0846899\n",
      "[550]\ttraining's rmse: 0.081862\tvalid_1's rmse: 0.0846751\n",
      "[575]\ttraining's rmse: 0.081817\tvalid_1's rmse: 0.0846621\n",
      "[600]\ttraining's rmse: 0.0817731\tvalid_1's rmse: 0.0846489\n",
      "[625]\ttraining's rmse: 0.0817391\tvalid_1's rmse: 0.0846369\n",
      "[650]\ttraining's rmse: 0.0816976\tvalid_1's rmse: 0.0846254\n",
      "[675]\ttraining's rmse: 0.0816525\tvalid_1's rmse: 0.0846133\n",
      "[700]\ttraining's rmse: 0.0816145\tvalid_1's rmse: 0.0846023\n",
      "[725]\ttraining's rmse: 0.0815804\tvalid_1's rmse: 0.084593\n",
      "[750]\ttraining's rmse: 0.0815462\tvalid_1's rmse: 0.0845835\n",
      "[775]\ttraining's rmse: 0.0815188\tvalid_1's rmse: 0.0845746\n",
      "[800]\ttraining's rmse: 0.0814833\tvalid_1's rmse: 0.0845667\n",
      "[825]\ttraining's rmse: 0.0814532\tvalid_1's rmse: 0.0845578\n",
      "[850]\ttraining's rmse: 0.0814228\tvalid_1's rmse: 0.0845503\n",
      "[875]\ttraining's rmse: 0.0813965\tvalid_1's rmse: 0.0845436\n",
      "[900]\ttraining's rmse: 0.0813685\tvalid_1's rmse: 0.0845372\n",
      "[925]\ttraining's rmse: 0.0813403\tvalid_1's rmse: 0.0845321\n",
      "[950]\ttraining's rmse: 0.081317\tvalid_1's rmse: 0.0845269\n",
      "[975]\ttraining's rmse: 0.081294\tvalid_1's rmse: 0.0845216\n",
      "[1000]\ttraining's rmse: 0.0812729\tvalid_1's rmse: 0.0845168\n",
      "[1025]\ttraining's rmse: 0.0812486\tvalid_1's rmse: 0.0845117\n",
      "[1050]\ttraining's rmse: 0.0812285\tvalid_1's rmse: 0.0845065\n",
      "[1075]\ttraining's rmse: 0.0812077\tvalid_1's rmse: 0.084503\n",
      "[1100]\ttraining's rmse: 0.0811917\tvalid_1's rmse: 0.0844988\n",
      "[1125]\ttraining's rmse: 0.0811734\tvalid_1's rmse: 0.0844955\n",
      "[1150]\ttraining's rmse: 0.0811564\tvalid_1's rmse: 0.084492\n",
      "[1175]\ttraining's rmse: 0.08114\tvalid_1's rmse: 0.0844887\n",
      "[1200]\ttraining's rmse: 0.0811238\tvalid_1's rmse: 0.0844856\n",
      "[1225]\ttraining's rmse: 0.0811103\tvalid_1's rmse: 0.0844826\n",
      "[1250]\ttraining's rmse: 0.081096\tvalid_1's rmse: 0.0844794\n",
      "[1275]\ttraining's rmse: 0.08108\tvalid_1's rmse: 0.0844769\n",
      "[1300]\ttraining's rmse: 0.0810672\tvalid_1's rmse: 0.0844741\n",
      "[1325]\ttraining's rmse: 0.0810528\tvalid_1's rmse: 0.0844713\n",
      "[1350]\ttraining's rmse: 0.081039\tvalid_1's rmse: 0.0844698\n",
      "[1375]\ttraining's rmse: 0.0810267\tvalid_1's rmse: 0.0844679\n",
      "[1400]\ttraining's rmse: 0.0810165\tvalid_1's rmse: 0.0844657\n",
      "[1425]\ttraining's rmse: 0.0810055\tvalid_1's rmse: 0.0844638\n",
      "[1450]\ttraining's rmse: 0.0809936\tvalid_1's rmse: 0.0844625\n",
      "[1475]\ttraining's rmse: 0.0809824\tvalid_1's rmse: 0.0844606\n",
      "[1500]\ttraining's rmse: 0.0809743\tvalid_1's rmse: 0.0844589\n",
      "[1525]\ttraining's rmse: 0.0809656\tvalid_1's rmse: 0.0844575\n",
      "[1550]\ttraining's rmse: 0.0809585\tvalid_1's rmse: 0.0844567\n",
      "[1575]\ttraining's rmse: 0.0809497\tvalid_1's rmse: 0.084455\n",
      "[1600]\ttraining's rmse: 0.0809415\tvalid_1's rmse: 0.0844544\n",
      "[1625]\ttraining's rmse: 0.0809337\tvalid_1's rmse: 0.0844531\n",
      "[1650]\ttraining's rmse: 0.0809266\tvalid_1's rmse: 0.0844525\n",
      "[1675]\ttraining's rmse: 0.0809193\tvalid_1's rmse: 0.0844511\n",
      "[1700]\ttraining's rmse: 0.0809131\tvalid_1's rmse: 0.0844496\n",
      "[1725]\ttraining's rmse: 0.0809068\tvalid_1's rmse: 0.0844486\n",
      "[1750]\ttraining's rmse: 0.080897\tvalid_1's rmse: 0.0844475\n",
      "[1775]\ttraining's rmse: 0.08089\tvalid_1's rmse: 0.0844469\n",
      "[1800]\ttraining's rmse: 0.080885\tvalid_1's rmse: 0.0844459\n",
      "[1825]\ttraining's rmse: 0.0808788\tvalid_1's rmse: 0.0844452\n",
      "[1850]\ttraining's rmse: 0.0808744\tvalid_1's rmse: 0.0844443\n",
      "[1875]\ttraining's rmse: 0.0808691\tvalid_1's rmse: 0.0844437\n",
      "[1900]\ttraining's rmse: 0.0808656\tvalid_1's rmse: 0.0844433\n",
      "[1925]\ttraining's rmse: 0.0808603\tvalid_1's rmse: 0.0844428\n",
      "[1950]\ttraining's rmse: 0.0808565\tvalid_1's rmse: 0.0844422\n",
      "[1975]\ttraining's rmse: 0.0808519\tvalid_1's rmse: 0.0844412\n",
      "[2000]\ttraining's rmse: 0.0808474\tvalid_1's rmse: 0.0844402\n",
      "[2025]\ttraining's rmse: 0.0808429\tvalid_1's rmse: 0.0844392\n",
      "[2050]\ttraining's rmse: 0.0808396\tvalid_1's rmse: 0.0844393\n",
      "[2075]\ttraining's rmse: 0.0808361\tvalid_1's rmse: 0.0844386\n",
      "[2100]\ttraining's rmse: 0.0808338\tvalid_1's rmse: 0.0844387\n",
      "[2125]\ttraining's rmse: 0.0808292\tvalid_1's rmse: 0.0844384\n",
      "[2150]\ttraining's rmse: 0.080826\tvalid_1's rmse: 0.0844386\n",
      "Early stopping, best iteration is:\n",
      "[2123]\ttraining's rmse: 0.0808299\tvalid_1's rmse: 0.0844382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.085442\tvalid_1's rmse: 0.0812877\n",
      "[50]\ttraining's rmse: 0.0853345\tvalid_1's rmse: 0.0812415\n",
      "[75]\ttraining's rmse: 0.085219\tvalid_1's rmse: 0.0811935\n",
      "[100]\ttraining's rmse: 0.0851155\tvalid_1's rmse: 0.0811512\n",
      "[125]\ttraining's rmse: 0.0850089\tvalid_1's rmse: 0.0811092\n",
      "[150]\ttraining's rmse: 0.0849149\tvalid_1's rmse: 0.0810737\n",
      "[175]\ttraining's rmse: 0.0848346\tvalid_1's rmse: 0.0810434\n",
      "[200]\ttraining's rmse: 0.0847463\tvalid_1's rmse: 0.081012\n",
      "[225]\ttraining's rmse: 0.0846613\tvalid_1's rmse: 0.0809821\n",
      "[250]\ttraining's rmse: 0.0845906\tvalid_1's rmse: 0.0809579\n",
      "[275]\ttraining's rmse: 0.0845256\tvalid_1's rmse: 0.0809334\n",
      "[300]\ttraining's rmse: 0.084461\tvalid_1's rmse: 0.0809112\n",
      "[325]\ttraining's rmse: 0.084395\tvalid_1's rmse: 0.0808897\n",
      "[350]\ttraining's rmse: 0.0843294\tvalid_1's rmse: 0.080868\n",
      "[375]\ttraining's rmse: 0.0842785\tvalid_1's rmse: 0.0808527\n",
      "[400]\ttraining's rmse: 0.0842213\tvalid_1's rmse: 0.0808443\n",
      "[425]\ttraining's rmse: 0.0841686\tvalid_1's rmse: 0.0808297\n",
      "[450]\ttraining's rmse: 0.0841198\tvalid_1's rmse: 0.0808133\n",
      "[475]\ttraining's rmse: 0.084074\tvalid_1's rmse: 0.0808006\n",
      "[500]\ttraining's rmse: 0.0840345\tvalid_1's rmse: 0.0807875\n",
      "[525]\ttraining's rmse: 0.083984\tvalid_1's rmse: 0.0807791\n",
      "[550]\ttraining's rmse: 0.0839368\tvalid_1's rmse: 0.0807725\n",
      "[575]\ttraining's rmse: 0.0838944\tvalid_1's rmse: 0.0807722\n",
      "[600]\ttraining's rmse: 0.0838513\tvalid_1's rmse: 0.0807622\n",
      "[625]\ttraining's rmse: 0.0838165\tvalid_1's rmse: 0.0807576\n",
      "[650]\ttraining's rmse: 0.0837749\tvalid_1's rmse: 0.0807576\n",
      "[675]\ttraining's rmse: 0.0837313\tvalid_1's rmse: 0.0807488\n",
      "[700]\ttraining's rmse: 0.0836944\tvalid_1's rmse: 0.0807404\n",
      "[725]\ttraining's rmse: 0.0836596\tvalid_1's rmse: 0.0807494\n",
      "[750]\ttraining's rmse: 0.0836277\tvalid_1's rmse: 0.080746\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's rmse: 0.0836944\tvalid_1's rmse: 0.0807404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0848868\tvalid_1's rmse: 0.0872673\n",
      "[50]\ttraining's rmse: 0.0847592\tvalid_1's rmse: 0.0872187\n",
      "[75]\ttraining's rmse: 0.0846302\tvalid_1's rmse: 0.087168\n",
      "[100]\ttraining's rmse: 0.0845102\tvalid_1's rmse: 0.087124\n",
      "[125]\ttraining's rmse: 0.0843886\tvalid_1's rmse: 0.0870793\n",
      "[150]\ttraining's rmse: 0.0842768\tvalid_1's rmse: 0.0870373\n",
      "[175]\ttraining's rmse: 0.0841858\tvalid_1's rmse: 0.0870037\n",
      "[200]\ttraining's rmse: 0.0840903\tvalid_1's rmse: 0.0869688\n",
      "[225]\ttraining's rmse: 0.0839924\tvalid_1's rmse: 0.0869362\n",
      "[250]\ttraining's rmse: 0.0839126\tvalid_1's rmse: 0.0869064\n",
      "[275]\ttraining's rmse: 0.0838346\tvalid_1's rmse: 0.0868775\n",
      "[300]\ttraining's rmse: 0.0837588\tvalid_1's rmse: 0.0868515\n",
      "[325]\ttraining's rmse: 0.0836801\tvalid_1's rmse: 0.0868267\n",
      "[350]\ttraining's rmse: 0.0836075\tvalid_1's rmse: 0.0868018\n",
      "[375]\ttraining's rmse: 0.0835499\tvalid_1's rmse: 0.0867824\n",
      "[400]\ttraining's rmse: 0.0834832\tvalid_1's rmse: 0.0867621\n",
      "[425]\ttraining's rmse: 0.0834236\tvalid_1's rmse: 0.0867423\n",
      "[450]\ttraining's rmse: 0.0833708\tvalid_1's rmse: 0.0867236\n",
      "[475]\ttraining's rmse: 0.0833193\tvalid_1's rmse: 0.0867068\n",
      "[500]\ttraining's rmse: 0.0832749\tvalid_1's rmse: 0.0866917\n",
      "[525]\ttraining's rmse: 0.0832189\tvalid_1's rmse: 0.0866747\n",
      "[550]\ttraining's rmse: 0.0831681\tvalid_1's rmse: 0.0866585\n",
      "[575]\ttraining's rmse: 0.0831205\tvalid_1's rmse: 0.0866466\n",
      "[600]\ttraining's rmse: 0.0830755\tvalid_1's rmse: 0.0866338\n",
      "[625]\ttraining's rmse: 0.0830407\tvalid_1's rmse: 0.0866226\n",
      "[650]\ttraining's rmse: 0.0829998\tvalid_1's rmse: 0.08661\n",
      "[675]\ttraining's rmse: 0.0829547\tvalid_1's rmse: 0.0865988\n",
      "[700]\ttraining's rmse: 0.0829173\tvalid_1's rmse: 0.0865869\n",
      "[725]\ttraining's rmse: 0.0828832\tvalid_1's rmse: 0.0865767\n",
      "[750]\ttraining's rmse: 0.0828484\tvalid_1's rmse: 0.0865672\n",
      "[775]\ttraining's rmse: 0.0828214\tvalid_1's rmse: 0.086559\n",
      "[800]\ttraining's rmse: 0.0827876\tvalid_1's rmse: 0.0865523\n",
      "[825]\ttraining's rmse: 0.0827583\tvalid_1's rmse: 0.0865439\n",
      "[850]\ttraining's rmse: 0.0827269\tvalid_1's rmse: 0.0865372\n",
      "[875]\ttraining's rmse: 0.082701\tvalid_1's rmse: 0.0865305\n",
      "[900]\ttraining's rmse: 0.0826695\tvalid_1's rmse: 0.0865236\n",
      "[925]\ttraining's rmse: 0.0826441\tvalid_1's rmse: 0.0865165\n",
      "[950]\ttraining's rmse: 0.0826187\tvalid_1's rmse: 0.0865113\n",
      "[975]\ttraining's rmse: 0.0825937\tvalid_1's rmse: 0.0865054\n",
      "[1000]\ttraining's rmse: 0.0825694\tvalid_1's rmse: 0.0865008\n",
      "[1025]\ttraining's rmse: 0.082543\tvalid_1's rmse: 0.0864945\n",
      "[1050]\ttraining's rmse: 0.0825213\tvalid_1's rmse: 0.0864891\n",
      "[1075]\ttraining's rmse: 0.0825004\tvalid_1's rmse: 0.0864839\n",
      "[1100]\ttraining's rmse: 0.0824813\tvalid_1's rmse: 0.0864797\n",
      "[1125]\ttraining's rmse: 0.0824619\tvalid_1's rmse: 0.0864745\n",
      "[1150]\ttraining's rmse: 0.0824428\tvalid_1's rmse: 0.086471\n",
      "[1175]\ttraining's rmse: 0.0824265\tvalid_1's rmse: 0.0864687\n",
      "[1200]\ttraining's rmse: 0.0824092\tvalid_1's rmse: 0.0864635\n",
      "[1225]\ttraining's rmse: 0.082393\tvalid_1's rmse: 0.0864587\n",
      "[1250]\ttraining's rmse: 0.0823792\tvalid_1's rmse: 0.086454\n",
      "[1275]\ttraining's rmse: 0.0823632\tvalid_1's rmse: 0.0864516\n",
      "[1300]\ttraining's rmse: 0.0823518\tvalid_1's rmse: 0.086448\n",
      "[1325]\ttraining's rmse: 0.0823399\tvalid_1's rmse: 0.0864451\n",
      "[1350]\ttraining's rmse: 0.0823255\tvalid_1's rmse: 0.0864413\n",
      "[1375]\ttraining's rmse: 0.0823133\tvalid_1's rmse: 0.086439\n",
      "[1400]\ttraining's rmse: 0.0823018\tvalid_1's rmse: 0.0864345\n",
      "[1425]\ttraining's rmse: 0.0822875\tvalid_1's rmse: 0.0864325\n",
      "[1450]\ttraining's rmse: 0.0822742\tvalid_1's rmse: 0.0864302\n",
      "[1475]\ttraining's rmse: 0.0822635\tvalid_1's rmse: 0.0864273\n",
      "[1500]\ttraining's rmse: 0.0822512\tvalid_1's rmse: 0.0864249\n",
      "[1525]\ttraining's rmse: 0.0822419\tvalid_1's rmse: 0.0864224\n",
      "[1550]\ttraining's rmse: 0.0822322\tvalid_1's rmse: 0.0864205\n",
      "[1575]\ttraining's rmse: 0.0822251\tvalid_1's rmse: 0.0864177\n",
      "[1600]\ttraining's rmse: 0.0822167\tvalid_1's rmse: 0.0864138\n",
      "[1625]\ttraining's rmse: 0.0822088\tvalid_1's rmse: 0.0864109\n",
      "[1650]\ttraining's rmse: 0.0822003\tvalid_1's rmse: 0.086408\n",
      "[1675]\ttraining's rmse: 0.0821953\tvalid_1's rmse: 0.0864067\n",
      "[1700]\ttraining's rmse: 0.0821901\tvalid_1's rmse: 0.0864045\n",
      "[1725]\ttraining's rmse: 0.0821834\tvalid_1's rmse: 0.0864016\n",
      "[1750]\ttraining's rmse: 0.0821749\tvalid_1's rmse: 0.0863998\n",
      "[1775]\ttraining's rmse: 0.0821689\tvalid_1's rmse: 0.0863985\n",
      "[1800]\ttraining's rmse: 0.0821627\tvalid_1's rmse: 0.086397\n",
      "[1825]\ttraining's rmse: 0.0821587\tvalid_1's rmse: 0.0863954\n",
      "[1850]\ttraining's rmse: 0.0821531\tvalid_1's rmse: 0.0863936\n",
      "[1875]\ttraining's rmse: 0.0821478\tvalid_1's rmse: 0.0863923\n",
      "[1900]\ttraining's rmse: 0.0821443\tvalid_1's rmse: 0.0863916\n",
      "[1925]\ttraining's rmse: 0.0821394\tvalid_1's rmse: 0.0863891\n",
      "[1950]\ttraining's rmse: 0.0821355\tvalid_1's rmse: 0.0863871\n",
      "[1975]\ttraining's rmse: 0.0821321\tvalid_1's rmse: 0.0863861\n",
      "[2000]\ttraining's rmse: 0.0821265\tvalid_1's rmse: 0.0863849\n",
      "[2025]\ttraining's rmse: 0.0821219\tvalid_1's rmse: 0.0863833\n",
      "[2050]\ttraining's rmse: 0.0821183\tvalid_1's rmse: 0.0863823\n",
      "[2075]\ttraining's rmse: 0.0821137\tvalid_1's rmse: 0.0863807\n",
      "[2100]\ttraining's rmse: 0.08211\tvalid_1's rmse: 0.086379\n",
      "[2125]\ttraining's rmse: 0.0821058\tvalid_1's rmse: 0.0863779\n",
      "[2150]\ttraining's rmse: 0.0821013\tvalid_1's rmse: 0.0863778\n",
      "[2175]\ttraining's rmse: 0.0820976\tvalid_1's rmse: 0.0863772\n",
      "[2200]\ttraining's rmse: 0.0820952\tvalid_1's rmse: 0.0863769\n",
      "[2225]\ttraining's rmse: 0.0820923\tvalid_1's rmse: 0.0863758\n",
      "[2250]\ttraining's rmse: 0.0820896\tvalid_1's rmse: 0.086375\n",
      "[2275]\ttraining's rmse: 0.0820856\tvalid_1's rmse: 0.0863738\n",
      "[2300]\ttraining's rmse: 0.0820822\tvalid_1's rmse: 0.0863722\n",
      "[2325]\ttraining's rmse: 0.08208\tvalid_1's rmse: 0.0863715\n",
      "[2350]\ttraining's rmse: 0.0820762\tvalid_1's rmse: 0.0863709\n",
      "[2375]\ttraining's rmse: 0.082073\tvalid_1's rmse: 0.0863701\n",
      "[2400]\ttraining's rmse: 0.0820696\tvalid_1's rmse: 0.0863689\n",
      "[2425]\ttraining's rmse: 0.0820675\tvalid_1's rmse: 0.0863681\n",
      "[2450]\ttraining's rmse: 0.082066\tvalid_1's rmse: 0.0863678\n",
      "[2475]\ttraining's rmse: 0.0820638\tvalid_1's rmse: 0.0863677\n",
      "[2500]\ttraining's rmse: 0.0820623\tvalid_1's rmse: 0.0863662\n",
      "[2525]\ttraining's rmse: 0.0820594\tvalid_1's rmse: 0.0863654\n",
      "[2550]\ttraining's rmse: 0.0820566\tvalid_1's rmse: 0.0863653\n",
      "[2575]\ttraining's rmse: 0.0820542\tvalid_1's rmse: 0.0863656\n",
      "Early stopping, best iteration is:\n",
      "[2539]\ttraining's rmse: 0.0820582\tvalid_1's rmse: 0.0863652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0849475\tvalid_1's rmse: 0.0871746\n",
      "[50]\ttraining's rmse: 0.0848281\tvalid_1's rmse: 0.0871223\n",
      "[75]\ttraining's rmse: 0.0847025\tvalid_1's rmse: 0.0870719\n",
      "[100]\ttraining's rmse: 0.0845937\tvalid_1's rmse: 0.0870273\n",
      "[125]\ttraining's rmse: 0.0844788\tvalid_1's rmse: 0.0869817\n",
      "[150]\ttraining's rmse: 0.0843756\tvalid_1's rmse: 0.0869407\n",
      "[175]\ttraining's rmse: 0.0842897\tvalid_1's rmse: 0.0869064\n",
      "[200]\ttraining's rmse: 0.0841938\tvalid_1's rmse: 0.0868705\n",
      "[225]\ttraining's rmse: 0.0841014\tvalid_1's rmse: 0.0868379\n",
      "[250]\ttraining's rmse: 0.0840224\tvalid_1's rmse: 0.0868082\n",
      "[275]\ttraining's rmse: 0.0839508\tvalid_1's rmse: 0.08678\n",
      "[300]\ttraining's rmse: 0.0838786\tvalid_1's rmse: 0.0867562\n",
      "[325]\ttraining's rmse: 0.083804\tvalid_1's rmse: 0.0867315\n",
      "[350]\ttraining's rmse: 0.0837329\tvalid_1's rmse: 0.0867074\n",
      "[375]\ttraining's rmse: 0.0836739\tvalid_1's rmse: 0.0866875\n",
      "[400]\ttraining's rmse: 0.0836115\tvalid_1's rmse: 0.0866684\n",
      "[425]\ttraining's rmse: 0.0835528\tvalid_1's rmse: 0.0866488\n",
      "[450]\ttraining's rmse: 0.0834994\tvalid_1's rmse: 0.0866315\n",
      "[475]\ttraining's rmse: 0.0834516\tvalid_1's rmse: 0.0866144\n",
      "[500]\ttraining's rmse: 0.0834089\tvalid_1's rmse: 0.0865978\n",
      "[525]\ttraining's rmse: 0.0833549\tvalid_1's rmse: 0.0865823\n",
      "[550]\ttraining's rmse: 0.0833044\tvalid_1's rmse: 0.0865677\n",
      "[575]\ttraining's rmse: 0.0832593\tvalid_1's rmse: 0.0865528\n",
      "[600]\ttraining's rmse: 0.0832151\tvalid_1's rmse: 0.0865398\n",
      "[625]\ttraining's rmse: 0.0831787\tvalid_1's rmse: 0.0865284\n",
      "[650]\ttraining's rmse: 0.0831344\tvalid_1's rmse: 0.0865166\n",
      "[675]\ttraining's rmse: 0.0830927\tvalid_1's rmse: 0.0865061\n",
      "[700]\ttraining's rmse: 0.0830535\tvalid_1's rmse: 0.0864947\n",
      "[725]\ttraining's rmse: 0.0830191\tvalid_1's rmse: 0.0864853\n",
      "[750]\ttraining's rmse: 0.0829858\tvalid_1's rmse: 0.0864762\n",
      "[775]\ttraining's rmse: 0.082957\tvalid_1's rmse: 0.0864671\n",
      "[800]\ttraining's rmse: 0.0829205\tvalid_1's rmse: 0.0864588\n",
      "[825]\ttraining's rmse: 0.0828921\tvalid_1's rmse: 0.08645\n",
      "[850]\ttraining's rmse: 0.0828614\tvalid_1's rmse: 0.0864427\n",
      "[875]\ttraining's rmse: 0.0828346\tvalid_1's rmse: 0.0864358\n",
      "[900]\ttraining's rmse: 0.0828054\tvalid_1's rmse: 0.086429\n",
      "[925]\ttraining's rmse: 0.0827783\tvalid_1's rmse: 0.0864234\n",
      "[950]\ttraining's rmse: 0.0827555\tvalid_1's rmse: 0.0864177\n",
      "[975]\ttraining's rmse: 0.0827316\tvalid_1's rmse: 0.0864118\n",
      "[1000]\ttraining's rmse: 0.0827111\tvalid_1's rmse: 0.0864079\n",
      "[1025]\ttraining's rmse: 0.0826877\tvalid_1's rmse: 0.0864032\n",
      "[1050]\ttraining's rmse: 0.082666\tvalid_1's rmse: 0.0863981\n",
      "[1075]\ttraining's rmse: 0.082647\tvalid_1's rmse: 0.0863941\n",
      "[1100]\ttraining's rmse: 0.0826287\tvalid_1's rmse: 0.0863895\n",
      "[1125]\ttraining's rmse: 0.0826075\tvalid_1's rmse: 0.0863857\n",
      "[1150]\ttraining's rmse: 0.082589\tvalid_1's rmse: 0.0863824\n",
      "[1175]\ttraining's rmse: 0.0825726\tvalid_1's rmse: 0.0863802\n",
      "[1200]\ttraining's rmse: 0.0825554\tvalid_1's rmse: 0.0863769\n",
      "[1225]\ttraining's rmse: 0.0825413\tvalid_1's rmse: 0.0863747\n",
      "[1250]\ttraining's rmse: 0.0825277\tvalid_1's rmse: 0.0863725\n",
      "[1275]\ttraining's rmse: 0.0825104\tvalid_1's rmse: 0.0863697\n",
      "[1300]\ttraining's rmse: 0.0824966\tvalid_1's rmse: 0.0863667\n",
      "[1325]\ttraining's rmse: 0.0824836\tvalid_1's rmse: 0.0863645\n",
      "[1350]\ttraining's rmse: 0.0824682\tvalid_1's rmse: 0.0863629\n",
      "[1375]\ttraining's rmse: 0.0824563\tvalid_1's rmse: 0.0863616\n",
      "[1400]\ttraining's rmse: 0.0824468\tvalid_1's rmse: 0.0863592\n",
      "[1425]\ttraining's rmse: 0.0824332\tvalid_1's rmse: 0.0863575\n",
      "[1450]\ttraining's rmse: 0.082421\tvalid_1's rmse: 0.0863563\n",
      "[1475]\ttraining's rmse: 0.0824099\tvalid_1's rmse: 0.0863546\n",
      "[1500]\ttraining's rmse: 0.082401\tvalid_1's rmse: 0.0863528\n",
      "[1525]\ttraining's rmse: 0.0823903\tvalid_1's rmse: 0.0863517\n",
      "[1550]\ttraining's rmse: 0.0823792\tvalid_1's rmse: 0.0863509\n",
      "[1575]\ttraining's rmse: 0.0823718\tvalid_1's rmse: 0.0863495\n",
      "[1600]\ttraining's rmse: 0.0823648\tvalid_1's rmse: 0.0863489\n",
      "[1625]\ttraining's rmse: 0.0823563\tvalid_1's rmse: 0.0863476\n",
      "[1650]\ttraining's rmse: 0.0823501\tvalid_1's rmse: 0.0863472\n",
      "[1675]\ttraining's rmse: 0.082344\tvalid_1's rmse: 0.0863456\n",
      "[1700]\ttraining's rmse: 0.0823371\tvalid_1's rmse: 0.0863445\n",
      "[1725]\ttraining's rmse: 0.0823303\tvalid_1's rmse: 0.0863437\n",
      "[1750]\ttraining's rmse: 0.0823239\tvalid_1's rmse: 0.0863431\n",
      "[1775]\ttraining's rmse: 0.0823186\tvalid_1's rmse: 0.0863423\n",
      "[1800]\ttraining's rmse: 0.0823129\tvalid_1's rmse: 0.0863418\n",
      "[1825]\ttraining's rmse: 0.0823069\tvalid_1's rmse: 0.0863409\n",
      "[1850]\ttraining's rmse: 0.0823019\tvalid_1's rmse: 0.08634\n",
      "[1875]\ttraining's rmse: 0.0822968\tvalid_1's rmse: 0.0863396\n",
      "[1900]\ttraining's rmse: 0.0822919\tvalid_1's rmse: 0.0863395\n",
      "[1925]\ttraining's rmse: 0.0822877\tvalid_1's rmse: 0.0863391\n",
      "[1950]\ttraining's rmse: 0.082284\tvalid_1's rmse: 0.0863385\n",
      "[1975]\ttraining's rmse: 0.08228\tvalid_1's rmse: 0.0863383\n",
      "[2000]\ttraining's rmse: 0.0822752\tvalid_1's rmse: 0.0863376\n",
      "[2025]\ttraining's rmse: 0.0822709\tvalid_1's rmse: 0.086337\n",
      "[2050]\ttraining's rmse: 0.0822642\tvalid_1's rmse: 0.0863365\n",
      "[2075]\ttraining's rmse: 0.0822616\tvalid_1's rmse: 0.0863362\n",
      "[2100]\ttraining's rmse: 0.0822575\tvalid_1's rmse: 0.0863358\n",
      "[2125]\ttraining's rmse: 0.0822543\tvalid_1's rmse: 0.0863358\n",
      "[2150]\ttraining's rmse: 0.0822504\tvalid_1's rmse: 0.0863356\n",
      "[2175]\ttraining's rmse: 0.082248\tvalid_1's rmse: 0.0863355\n",
      "[2200]\ttraining's rmse: 0.082244\tvalid_1's rmse: 0.0863349\n",
      "[2225]\ttraining's rmse: 0.0822411\tvalid_1's rmse: 0.0863342\n",
      "[2250]\ttraining's rmse: 0.0822381\tvalid_1's rmse: 0.0863341\n",
      "[2275]\ttraining's rmse: 0.0822339\tvalid_1's rmse: 0.086334\n",
      "[2300]\ttraining's rmse: 0.0822316\tvalid_1's rmse: 0.0863336\n",
      "[2325]\ttraining's rmse: 0.0822293\tvalid_1's rmse: 0.0863333\n",
      "[2350]\ttraining's rmse: 0.0822266\tvalid_1's rmse: 0.0863333\n",
      "[2375]\ttraining's rmse: 0.082224\tvalid_1's rmse: 0.0863331\n",
      "Early stopping, best iteration is:\n",
      "[2334]\ttraining's rmse: 0.082228\tvalid_1's rmse: 0.0863329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0870994\tvalid_1's rmse: 0.0828036\n",
      "[50]\ttraining's rmse: 0.0869916\tvalid_1's rmse: 0.0827568\n",
      "[75]\ttraining's rmse: 0.0868767\tvalid_1's rmse: 0.0827094\n",
      "[100]\ttraining's rmse: 0.0867729\tvalid_1's rmse: 0.0826667\n",
      "[125]\ttraining's rmse: 0.0866664\tvalid_1's rmse: 0.0826241\n",
      "[150]\ttraining's rmse: 0.086568\tvalid_1's rmse: 0.0825867\n",
      "[175]\ttraining's rmse: 0.0864877\tvalid_1's rmse: 0.0825553\n",
      "[200]\ttraining's rmse: 0.0863995\tvalid_1's rmse: 0.082526\n",
      "[225]\ttraining's rmse: 0.0863133\tvalid_1's rmse: 0.0824939\n",
      "[250]\ttraining's rmse: 0.0862414\tvalid_1's rmse: 0.0824675\n",
      "[275]\ttraining's rmse: 0.0861766\tvalid_1's rmse: 0.0824426\n",
      "[300]\ttraining's rmse: 0.0861112\tvalid_1's rmse: 0.0824189\n",
      "[325]\ttraining's rmse: 0.0860427\tvalid_1's rmse: 0.0823968\n",
      "[350]\ttraining's rmse: 0.085977\tvalid_1's rmse: 0.0823757\n",
      "[375]\ttraining's rmse: 0.0859236\tvalid_1's rmse: 0.0823591\n",
      "[400]\ttraining's rmse: 0.0858635\tvalid_1's rmse: 0.0823405\n",
      "[425]\ttraining's rmse: 0.0858088\tvalid_1's rmse: 0.0823266\n",
      "[450]\ttraining's rmse: 0.0857587\tvalid_1's rmse: 0.0823122\n",
      "[475]\ttraining's rmse: 0.0857118\tvalid_1's rmse: 0.0822991\n",
      "[500]\ttraining's rmse: 0.0856744\tvalid_1's rmse: 0.0822853\n",
      "[525]\ttraining's rmse: 0.0856229\tvalid_1's rmse: 0.0822749\n",
      "[550]\ttraining's rmse: 0.0855757\tvalid_1's rmse: 0.082262\n",
      "[575]\ttraining's rmse: 0.0855319\tvalid_1's rmse: 0.0822601\n",
      "[600]\ttraining's rmse: 0.0854883\tvalid_1's rmse: 0.0822497\n",
      "[625]\ttraining's rmse: 0.0854535\tvalid_1's rmse: 0.0822505\n",
      "[650]\ttraining's rmse: 0.0854128\tvalid_1's rmse: 0.082249\n",
      "[675]\ttraining's rmse: 0.0853687\tvalid_1's rmse: 0.0822443\n",
      "[700]\ttraining's rmse: 0.085331\tvalid_1's rmse: 0.0822424\n",
      "[725]\ttraining's rmse: 0.0852949\tvalid_1's rmse: 0.0822399\n",
      "[750]\ttraining's rmse: 0.0852629\tvalid_1's rmse: 0.0822364\n",
      "[775]\ttraining's rmse: 0.0852339\tvalid_1's rmse: 0.0822358\n",
      "[800]\ttraining's rmse: 0.0851998\tvalid_1's rmse: 0.0822367\n",
      "[825]\ttraining's rmse: 0.0851712\tvalid_1's rmse: 0.0822357\n",
      "Early stopping, best iteration is:\n",
      "[797]\ttraining's rmse: 0.0852039\tvalid_1's rmse: 0.0822312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0836608\tvalid_1's rmse: 0.0864055\n",
      "[50]\ttraining's rmse: 0.0835318\tvalid_1's rmse: 0.0863516\n",
      "[75]\ttraining's rmse: 0.0834061\tvalid_1's rmse: 0.0862979\n",
      "[100]\ttraining's rmse: 0.0832856\tvalid_1's rmse: 0.0862519\n",
      "[125]\ttraining's rmse: 0.0831642\tvalid_1's rmse: 0.0862056\n",
      "[150]\ttraining's rmse: 0.0830561\tvalid_1's rmse: 0.0861636\n",
      "[175]\ttraining's rmse: 0.0829669\tvalid_1's rmse: 0.0861274\n",
      "[200]\ttraining's rmse: 0.0828731\tvalid_1's rmse: 0.0860916\n",
      "[225]\ttraining's rmse: 0.0827813\tvalid_1's rmse: 0.0860562\n",
      "[250]\ttraining's rmse: 0.0827024\tvalid_1's rmse: 0.086025\n",
      "[275]\ttraining's rmse: 0.0826305\tvalid_1's rmse: 0.0859971\n",
      "[300]\ttraining's rmse: 0.0825581\tvalid_1's rmse: 0.0859702\n",
      "[325]\ttraining's rmse: 0.0824868\tvalid_1's rmse: 0.0859455\n",
      "[350]\ttraining's rmse: 0.0824162\tvalid_1's rmse: 0.0859209\n",
      "[375]\ttraining's rmse: 0.0823546\tvalid_1's rmse: 0.085899\n",
      "[400]\ttraining's rmse: 0.0822916\tvalid_1's rmse: 0.0858771\n",
      "[425]\ttraining's rmse: 0.0822351\tvalid_1's rmse: 0.0858563\n",
      "[450]\ttraining's rmse: 0.0821816\tvalid_1's rmse: 0.085837\n",
      "[475]\ttraining's rmse: 0.0821329\tvalid_1's rmse: 0.0858203\n",
      "[500]\ttraining's rmse: 0.0820894\tvalid_1's rmse: 0.085803\n",
      "[525]\ttraining's rmse: 0.0820353\tvalid_1's rmse: 0.0857862\n",
      "[550]\ttraining's rmse: 0.0819884\tvalid_1's rmse: 0.0857714\n",
      "[575]\ttraining's rmse: 0.0819429\tvalid_1's rmse: 0.0857564\n",
      "[600]\ttraining's rmse: 0.0818989\tvalid_1's rmse: 0.0857421\n",
      "[625]\ttraining's rmse: 0.0818628\tvalid_1's rmse: 0.0857297\n",
      "[650]\ttraining's rmse: 0.0818212\tvalid_1's rmse: 0.085717\n",
      "[675]\ttraining's rmse: 0.0817792\tvalid_1's rmse: 0.085705\n",
      "[700]\ttraining's rmse: 0.0817451\tvalid_1's rmse: 0.0856944\n",
      "[725]\ttraining's rmse: 0.081708\tvalid_1's rmse: 0.0856839\n",
      "[750]\ttraining's rmse: 0.0816756\tvalid_1's rmse: 0.0856739\n",
      "[775]\ttraining's rmse: 0.0816501\tvalid_1's rmse: 0.0856647\n",
      "[800]\ttraining's rmse: 0.0816164\tvalid_1's rmse: 0.085655\n",
      "[825]\ttraining's rmse: 0.0815864\tvalid_1's rmse: 0.085646\n",
      "[850]\ttraining's rmse: 0.0815577\tvalid_1's rmse: 0.085638\n",
      "[875]\ttraining's rmse: 0.0815319\tvalid_1's rmse: 0.0856296\n",
      "[900]\ttraining's rmse: 0.0815033\tvalid_1's rmse: 0.0856224\n",
      "[925]\ttraining's rmse: 0.0814792\tvalid_1's rmse: 0.0856144\n",
      "[950]\ttraining's rmse: 0.0814565\tvalid_1's rmse: 0.0856075\n",
      "[975]\ttraining's rmse: 0.0814346\tvalid_1's rmse: 0.0856008\n",
      "[1000]\ttraining's rmse: 0.0814117\tvalid_1's rmse: 0.0855957\n",
      "[1025]\ttraining's rmse: 0.0813853\tvalid_1's rmse: 0.0855897\n",
      "[1050]\ttraining's rmse: 0.0813634\tvalid_1's rmse: 0.0855841\n",
      "[1075]\ttraining's rmse: 0.0813435\tvalid_1's rmse: 0.0855791\n",
      "[1100]\ttraining's rmse: 0.0813285\tvalid_1's rmse: 0.0855756\n",
      "[1125]\ttraining's rmse: 0.0813118\tvalid_1's rmse: 0.0855703\n",
      "[1150]\ttraining's rmse: 0.0812951\tvalid_1's rmse: 0.0855659\n",
      "[1175]\ttraining's rmse: 0.0812769\tvalid_1's rmse: 0.0855613\n",
      "[1200]\ttraining's rmse: 0.0812599\tvalid_1's rmse: 0.0855552\n",
      "[1225]\ttraining's rmse: 0.0812422\tvalid_1's rmse: 0.0855506\n",
      "[1250]\ttraining's rmse: 0.0812274\tvalid_1's rmse: 0.0855455\n",
      "[1275]\ttraining's rmse: 0.081209\tvalid_1's rmse: 0.0855419\n",
      "[1300]\ttraining's rmse: 0.0811949\tvalid_1's rmse: 0.0855377\n",
      "[1325]\ttraining's rmse: 0.0811838\tvalid_1's rmse: 0.0855335\n",
      "[1350]\ttraining's rmse: 0.0811709\tvalid_1's rmse: 0.0855301\n",
      "[1375]\ttraining's rmse: 0.0811576\tvalid_1's rmse: 0.0855278\n",
      "[1400]\ttraining's rmse: 0.0811481\tvalid_1's rmse: 0.085524\n",
      "[1425]\ttraining's rmse: 0.0811333\tvalid_1's rmse: 0.0855218\n",
      "[1450]\ttraining's rmse: 0.0811223\tvalid_1's rmse: 0.0855188\n",
      "[1475]\ttraining's rmse: 0.081113\tvalid_1's rmse: 0.085515\n",
      "[1500]\ttraining's rmse: 0.081103\tvalid_1's rmse: 0.0855128\n",
      "[1525]\ttraining's rmse: 0.0810934\tvalid_1's rmse: 0.0855095\n",
      "[1550]\ttraining's rmse: 0.0810838\tvalid_1's rmse: 0.0855061\n",
      "[1575]\ttraining's rmse: 0.081076\tvalid_1's rmse: 0.0855036\n",
      "[1600]\ttraining's rmse: 0.0810692\tvalid_1's rmse: 0.085502\n",
      "[1625]\ttraining's rmse: 0.0810622\tvalid_1's rmse: 0.0854985\n",
      "[1650]\ttraining's rmse: 0.0810535\tvalid_1's rmse: 0.0854964\n",
      "[1675]\ttraining's rmse: 0.0810481\tvalid_1's rmse: 0.0854945\n",
      "[1700]\ttraining's rmse: 0.0810422\tvalid_1's rmse: 0.0854925\n",
      "[1725]\ttraining's rmse: 0.081035\tvalid_1's rmse: 0.0854912\n",
      "[1750]\ttraining's rmse: 0.0810302\tvalid_1's rmse: 0.0854893\n",
      "[1775]\ttraining's rmse: 0.0810253\tvalid_1's rmse: 0.0854873\n",
      "[1800]\ttraining's rmse: 0.0810198\tvalid_1's rmse: 0.085485\n",
      "[1825]\ttraining's rmse: 0.0810135\tvalid_1's rmse: 0.0854827\n",
      "[1850]\ttraining's rmse: 0.0810093\tvalid_1's rmse: 0.0854805\n",
      "[1875]\ttraining's rmse: 0.0810063\tvalid_1's rmse: 0.0854798\n",
      "[1900]\ttraining's rmse: 0.0810017\tvalid_1's rmse: 0.0854781\n",
      "[1925]\ttraining's rmse: 0.0809969\tvalid_1's rmse: 0.0854771\n",
      "[1950]\ttraining's rmse: 0.080993\tvalid_1's rmse: 0.0854755\n",
      "[1975]\ttraining's rmse: 0.080989\tvalid_1's rmse: 0.0854739\n",
      "[2000]\ttraining's rmse: 0.0809849\tvalid_1's rmse: 0.0854729\n",
      "[2025]\ttraining's rmse: 0.0809816\tvalid_1's rmse: 0.0854713\n",
      "[2050]\ttraining's rmse: 0.0809771\tvalid_1's rmse: 0.0854701\n",
      "[2075]\ttraining's rmse: 0.0809725\tvalid_1's rmse: 0.0854685\n",
      "[2100]\ttraining's rmse: 0.0809697\tvalid_1's rmse: 0.0854682\n",
      "[2125]\ttraining's rmse: 0.0809666\tvalid_1's rmse: 0.0854681\n",
      "[2150]\ttraining's rmse: 0.0809621\tvalid_1's rmse: 0.0854672\n",
      "[2175]\ttraining's rmse: 0.0809591\tvalid_1's rmse: 0.0854666\n",
      "[2200]\ttraining's rmse: 0.080956\tvalid_1's rmse: 0.0854653\n",
      "[2225]\ttraining's rmse: 0.0809519\tvalid_1's rmse: 0.0854643\n",
      "[2250]\ttraining's rmse: 0.0809497\tvalid_1's rmse: 0.085464\n",
      "[2275]\ttraining's rmse: 0.0809459\tvalid_1's rmse: 0.0854638\n",
      "Early stopping, best iteration is:\n",
      "[2233]\ttraining's rmse: 0.0809507\tvalid_1's rmse: 0.0854638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0839315\tvalid_1's rmse: 0.0858863\n",
      "[50]\ttraining's rmse: 0.0838137\tvalid_1's rmse: 0.0858324\n",
      "[75]\ttraining's rmse: 0.0836946\tvalid_1's rmse: 0.0857802\n",
      "[100]\ttraining's rmse: 0.083586\tvalid_1's rmse: 0.0857329\n",
      "[125]\ttraining's rmse: 0.0834741\tvalid_1's rmse: 0.0856854\n",
      "[150]\ttraining's rmse: 0.0833721\tvalid_1's rmse: 0.0856424\n",
      "[175]\ttraining's rmse: 0.0832858\tvalid_1's rmse: 0.0856079\n",
      "[200]\ttraining's rmse: 0.0831947\tvalid_1's rmse: 0.0855724\n",
      "[225]\ttraining's rmse: 0.0831057\tvalid_1's rmse: 0.0855387\n",
      "[250]\ttraining's rmse: 0.0830275\tvalid_1's rmse: 0.085507\n",
      "[275]\ttraining's rmse: 0.0829555\tvalid_1's rmse: 0.0854781\n",
      "[300]\ttraining's rmse: 0.0828836\tvalid_1's rmse: 0.0854518\n",
      "[325]\ttraining's rmse: 0.0828102\tvalid_1's rmse: 0.0854247\n",
      "[350]\ttraining's rmse: 0.0827394\tvalid_1's rmse: 0.0854008\n",
      "[375]\ttraining's rmse: 0.0826837\tvalid_1's rmse: 0.0853799\n",
      "[400]\ttraining's rmse: 0.0826229\tvalid_1's rmse: 0.0853605\n",
      "[425]\ttraining's rmse: 0.0825659\tvalid_1's rmse: 0.0853418\n",
      "[450]\ttraining's rmse: 0.0825122\tvalid_1's rmse: 0.0853236\n",
      "[475]\ttraining's rmse: 0.0824625\tvalid_1's rmse: 0.0853059\n",
      "[500]\ttraining's rmse: 0.0824203\tvalid_1's rmse: 0.0852894\n",
      "[525]\ttraining's rmse: 0.0823657\tvalid_1's rmse: 0.0852727\n",
      "[550]\ttraining's rmse: 0.0823148\tvalid_1's rmse: 0.0852572\n",
      "[575]\ttraining's rmse: 0.0822693\tvalid_1's rmse: 0.0852437\n",
      "[600]\ttraining's rmse: 0.0822249\tvalid_1's rmse: 0.0852318\n",
      "[625]\ttraining's rmse: 0.0821899\tvalid_1's rmse: 0.0852201\n",
      "[650]\ttraining's rmse: 0.0821462\tvalid_1's rmse: 0.0852067\n",
      "[675]\ttraining's rmse: 0.082104\tvalid_1's rmse: 0.0851958\n",
      "[700]\ttraining's rmse: 0.0820675\tvalid_1's rmse: 0.0851862\n",
      "[725]\ttraining's rmse: 0.0820332\tvalid_1's rmse: 0.0851767\n",
      "[750]\ttraining's rmse: 0.0820021\tvalid_1's rmse: 0.085169\n",
      "[775]\ttraining's rmse: 0.0819741\tvalid_1's rmse: 0.08516\n",
      "[800]\ttraining's rmse: 0.0819378\tvalid_1's rmse: 0.0851516\n",
      "[825]\ttraining's rmse: 0.0819068\tvalid_1's rmse: 0.0851438\n",
      "[850]\ttraining's rmse: 0.0818776\tvalid_1's rmse: 0.085137\n",
      "[875]\ttraining's rmse: 0.0818499\tvalid_1's rmse: 0.0851299\n",
      "[900]\ttraining's rmse: 0.0818213\tvalid_1's rmse: 0.0851235\n",
      "[925]\ttraining's rmse: 0.0817945\tvalid_1's rmse: 0.0851175\n",
      "[950]\ttraining's rmse: 0.0817712\tvalid_1's rmse: 0.0851133\n",
      "[975]\ttraining's rmse: 0.0817474\tvalid_1's rmse: 0.0851081\n",
      "[1000]\ttraining's rmse: 0.0817261\tvalid_1's rmse: 0.0851031\n",
      "[1025]\ttraining's rmse: 0.0817005\tvalid_1's rmse: 0.0850986\n",
      "[1050]\ttraining's rmse: 0.0816803\tvalid_1's rmse: 0.0850939\n",
      "[1075]\ttraining's rmse: 0.0816613\tvalid_1's rmse: 0.0850899\n",
      "[1100]\ttraining's rmse: 0.0816446\tvalid_1's rmse: 0.0850851\n",
      "[1125]\ttraining's rmse: 0.0816253\tvalid_1's rmse: 0.0850812\n",
      "[1150]\ttraining's rmse: 0.0816066\tvalid_1's rmse: 0.0850777\n",
      "[1175]\ttraining's rmse: 0.0815911\tvalid_1's rmse: 0.0850747\n",
      "[1200]\ttraining's rmse: 0.0815726\tvalid_1's rmse: 0.0850711\n",
      "[1225]\ttraining's rmse: 0.0815561\tvalid_1's rmse: 0.085069\n",
      "[1250]\ttraining's rmse: 0.0815421\tvalid_1's rmse: 0.0850661\n",
      "[1275]\ttraining's rmse: 0.0815244\tvalid_1's rmse: 0.0850638\n",
      "[1300]\ttraining's rmse: 0.0815129\tvalid_1's rmse: 0.0850615\n",
      "[1325]\ttraining's rmse: 0.0814994\tvalid_1's rmse: 0.0850591\n",
      "[1350]\ttraining's rmse: 0.0814867\tvalid_1's rmse: 0.0850571\n",
      "[1375]\ttraining's rmse: 0.0814753\tvalid_1's rmse: 0.0850558\n",
      "[1400]\ttraining's rmse: 0.0814633\tvalid_1's rmse: 0.0850534\n",
      "[1425]\ttraining's rmse: 0.0814517\tvalid_1's rmse: 0.0850519\n",
      "[1450]\ttraining's rmse: 0.0814402\tvalid_1's rmse: 0.0850505\n",
      "[1475]\ttraining's rmse: 0.0814289\tvalid_1's rmse: 0.0850485\n",
      "[1500]\ttraining's rmse: 0.0814197\tvalid_1's rmse: 0.085047\n",
      "[1525]\ttraining's rmse: 0.0814116\tvalid_1's rmse: 0.0850462\n",
      "[1550]\ttraining's rmse: 0.081401\tvalid_1's rmse: 0.0850454\n",
      "[1575]\ttraining's rmse: 0.0813933\tvalid_1's rmse: 0.0850439\n",
      "[1600]\ttraining's rmse: 0.081386\tvalid_1's rmse: 0.0850435\n",
      "[1625]\ttraining's rmse: 0.0813776\tvalid_1's rmse: 0.0850426\n",
      "[1650]\ttraining's rmse: 0.0813694\tvalid_1's rmse: 0.0850419\n",
      "[1675]\ttraining's rmse: 0.0813635\tvalid_1's rmse: 0.0850404\n",
      "[1700]\ttraining's rmse: 0.0813572\tvalid_1's rmse: 0.0850399\n",
      "[1725]\ttraining's rmse: 0.0813489\tvalid_1's rmse: 0.0850394\n",
      "[1750]\ttraining's rmse: 0.0813409\tvalid_1's rmse: 0.0850388\n",
      "[1775]\ttraining's rmse: 0.0813339\tvalid_1's rmse: 0.0850385\n",
      "[1800]\ttraining's rmse: 0.0813287\tvalid_1's rmse: 0.0850374\n",
      "[1825]\ttraining's rmse: 0.0813216\tvalid_1's rmse: 0.0850364\n",
      "[1850]\ttraining's rmse: 0.081316\tvalid_1's rmse: 0.0850354\n",
      "[1875]\ttraining's rmse: 0.0813109\tvalid_1's rmse: 0.0850352\n",
      "[1900]\ttraining's rmse: 0.0813072\tvalid_1's rmse: 0.085035\n",
      "[1925]\ttraining's rmse: 0.0813017\tvalid_1's rmse: 0.0850345\n",
      "[1950]\ttraining's rmse: 0.0812978\tvalid_1's rmse: 0.0850337\n",
      "[1975]\ttraining's rmse: 0.0812944\tvalid_1's rmse: 0.0850334\n",
      "[2000]\ttraining's rmse: 0.0812875\tvalid_1's rmse: 0.0850329\n",
      "[2025]\ttraining's rmse: 0.0812841\tvalid_1's rmse: 0.0850324\n",
      "[2050]\ttraining's rmse: 0.0812799\tvalid_1's rmse: 0.0850319\n",
      "[2075]\ttraining's rmse: 0.0812776\tvalid_1's rmse: 0.0850316\n",
      "[2100]\ttraining's rmse: 0.0812746\tvalid_1's rmse: 0.0850314\n",
      "[2125]\ttraining's rmse: 0.0812721\tvalid_1's rmse: 0.0850316\n",
      "Early stopping, best iteration is:\n",
      "[2096]\ttraining's rmse: 0.081275\tvalid_1's rmse: 0.0850313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.086029\tvalid_1's rmse: 0.0816227\n",
      "[50]\ttraining's rmse: 0.0859188\tvalid_1's rmse: 0.0815748\n",
      "[75]\ttraining's rmse: 0.0858023\tvalid_1's rmse: 0.0815285\n",
      "[100]\ttraining's rmse: 0.0856988\tvalid_1's rmse: 0.0814864\n",
      "[125]\ttraining's rmse: 0.0855913\tvalid_1's rmse: 0.0814449\n",
      "[150]\ttraining's rmse: 0.0854951\tvalid_1's rmse: 0.0814082\n",
      "[175]\ttraining's rmse: 0.0854162\tvalid_1's rmse: 0.0813763\n",
      "[200]\ttraining's rmse: 0.0853246\tvalid_1's rmse: 0.0813443\n",
      "[225]\ttraining's rmse: 0.085241\tvalid_1's rmse: 0.0813136\n",
      "[250]\ttraining's rmse: 0.0851696\tvalid_1's rmse: 0.0812887\n",
      "[275]\ttraining's rmse: 0.0851027\tvalid_1's rmse: 0.0812646\n",
      "[300]\ttraining's rmse: 0.0850352\tvalid_1's rmse: 0.0812422\n",
      "[325]\ttraining's rmse: 0.084969\tvalid_1's rmse: 0.0812208\n",
      "[350]\ttraining's rmse: 0.0849029\tvalid_1's rmse: 0.0811991\n",
      "[375]\ttraining's rmse: 0.0848511\tvalid_1's rmse: 0.0811826\n",
      "[400]\ttraining's rmse: 0.084793\tvalid_1's rmse: 0.0811693\n",
      "[425]\ttraining's rmse: 0.0847413\tvalid_1's rmse: 0.0811555\n",
      "[450]\ttraining's rmse: 0.0846902\tvalid_1's rmse: 0.0811401\n",
      "[475]\ttraining's rmse: 0.0846424\tvalid_1's rmse: 0.0811299\n",
      "[500]\ttraining's rmse: 0.0846054\tvalid_1's rmse: 0.0811168\n",
      "[525]\ttraining's rmse: 0.0845524\tvalid_1's rmse: 0.0811096\n",
      "[550]\ttraining's rmse: 0.0845077\tvalid_1's rmse: 0.0811018\n",
      "[575]\ttraining's rmse: 0.0844626\tvalid_1's rmse: 0.0810899\n",
      "[600]\ttraining's rmse: 0.0844193\tvalid_1's rmse: 0.0810847\n",
      "[625]\ttraining's rmse: 0.0843831\tvalid_1's rmse: 0.0810802\n",
      "[650]\ttraining's rmse: 0.0843404\tvalid_1's rmse: 0.0810752\n",
      "[675]\ttraining's rmse: 0.0842965\tvalid_1's rmse: 0.0810702\n",
      "[700]\ttraining's rmse: 0.0842585\tvalid_1's rmse: 0.0810684\n",
      "[725]\ttraining's rmse: 0.0842246\tvalid_1's rmse: 0.0810734\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.084269\tvalid_1's rmse: 0.0810642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0858094\tvalid_1's rmse: 0.0882928\n",
      "[50]\ttraining's rmse: 0.085672\tvalid_1's rmse: 0.0882399\n",
      "[75]\ttraining's rmse: 0.0855319\tvalid_1's rmse: 0.0881893\n",
      "[100]\ttraining's rmse: 0.0853991\tvalid_1's rmse: 0.0881455\n",
      "[125]\ttraining's rmse: 0.0852719\tvalid_1's rmse: 0.0881013\n",
      "[150]\ttraining's rmse: 0.0851516\tvalid_1's rmse: 0.0880594\n",
      "[175]\ttraining's rmse: 0.0850574\tvalid_1's rmse: 0.0880237\n",
      "[200]\ttraining's rmse: 0.0849524\tvalid_1's rmse: 0.087987\n",
      "[225]\ttraining's rmse: 0.0848498\tvalid_1's rmse: 0.0879519\n",
      "[250]\ttraining's rmse: 0.08476\tvalid_1's rmse: 0.0879226\n",
      "[275]\ttraining's rmse: 0.0846789\tvalid_1's rmse: 0.0878944\n",
      "[300]\ttraining's rmse: 0.0845994\tvalid_1's rmse: 0.0878681\n",
      "[325]\ttraining's rmse: 0.0845181\tvalid_1's rmse: 0.0878408\n",
      "[350]\ttraining's rmse: 0.0844427\tvalid_1's rmse: 0.0878174\n",
      "[375]\ttraining's rmse: 0.084382\tvalid_1's rmse: 0.0877975\n",
      "[400]\ttraining's rmse: 0.0843102\tvalid_1's rmse: 0.0877772\n",
      "[425]\ttraining's rmse: 0.0842505\tvalid_1's rmse: 0.0877583\n",
      "[450]\ttraining's rmse: 0.0841903\tvalid_1's rmse: 0.0877388\n",
      "[475]\ttraining's rmse: 0.084137\tvalid_1's rmse: 0.0877221\n",
      "[500]\ttraining's rmse: 0.0840888\tvalid_1's rmse: 0.0877073\n",
      "[525]\ttraining's rmse: 0.0840312\tvalid_1's rmse: 0.0876911\n",
      "[550]\ttraining's rmse: 0.0839783\tvalid_1's rmse: 0.0876756\n",
      "[575]\ttraining's rmse: 0.0839293\tvalid_1's rmse: 0.0876618\n",
      "[600]\ttraining's rmse: 0.083881\tvalid_1's rmse: 0.0876486\n",
      "[625]\ttraining's rmse: 0.0838433\tvalid_1's rmse: 0.0876363\n",
      "[650]\ttraining's rmse: 0.0837984\tvalid_1's rmse: 0.0876238\n",
      "[675]\ttraining's rmse: 0.0837531\tvalid_1's rmse: 0.0876106\n",
      "[700]\ttraining's rmse: 0.0837109\tvalid_1's rmse: 0.0875991\n",
      "[725]\ttraining's rmse: 0.0836726\tvalid_1's rmse: 0.0875897\n",
      "[750]\ttraining's rmse: 0.083637\tvalid_1's rmse: 0.0875794\n",
      "[775]\ttraining's rmse: 0.0836094\tvalid_1's rmse: 0.0875699\n",
      "[800]\ttraining's rmse: 0.0835746\tvalid_1's rmse: 0.0875623\n",
      "[825]\ttraining's rmse: 0.0835423\tvalid_1's rmse: 0.0875555\n",
      "[850]\ttraining's rmse: 0.0835094\tvalid_1's rmse: 0.0875483\n",
      "[875]\ttraining's rmse: 0.0834813\tvalid_1's rmse: 0.0875405\n",
      "[900]\ttraining's rmse: 0.0834463\tvalid_1's rmse: 0.0875327\n",
      "[925]\ttraining's rmse: 0.0834184\tvalid_1's rmse: 0.0875247\n",
      "[950]\ttraining's rmse: 0.0833942\tvalid_1's rmse: 0.0875179\n",
      "[975]\ttraining's rmse: 0.0833671\tvalid_1's rmse: 0.0875111\n",
      "[1000]\ttraining's rmse: 0.0833451\tvalid_1's rmse: 0.0875056\n",
      "[1025]\ttraining's rmse: 0.0833189\tvalid_1's rmse: 0.0874986\n",
      "[1050]\ttraining's rmse: 0.0832966\tvalid_1's rmse: 0.0874922\n",
      "[1075]\ttraining's rmse: 0.083276\tvalid_1's rmse: 0.087488\n",
      "[1100]\ttraining's rmse: 0.0832567\tvalid_1's rmse: 0.0874837\n",
      "[1125]\ttraining's rmse: 0.083237\tvalid_1's rmse: 0.0874788\n",
      "[1150]\ttraining's rmse: 0.0832185\tvalid_1's rmse: 0.0874741\n",
      "[1175]\ttraining's rmse: 0.0832011\tvalid_1's rmse: 0.0874714\n",
      "[1200]\ttraining's rmse: 0.0831845\tvalid_1's rmse: 0.0874673\n",
      "[1225]\ttraining's rmse: 0.0831667\tvalid_1's rmse: 0.0874638\n",
      "[1250]\ttraining's rmse: 0.0831533\tvalid_1's rmse: 0.0874606\n",
      "[1275]\ttraining's rmse: 0.0831349\tvalid_1's rmse: 0.0874562\n",
      "[1300]\ttraining's rmse: 0.0831213\tvalid_1's rmse: 0.0874525\n",
      "[1325]\ttraining's rmse: 0.0831042\tvalid_1's rmse: 0.087449\n",
      "[1350]\ttraining's rmse: 0.083089\tvalid_1's rmse: 0.0874453\n",
      "[1375]\ttraining's rmse: 0.0830747\tvalid_1's rmse: 0.0874423\n",
      "[1400]\ttraining's rmse: 0.0830624\tvalid_1's rmse: 0.087439\n",
      "[1425]\ttraining's rmse: 0.0830439\tvalid_1's rmse: 0.0874347\n",
      "[1450]\ttraining's rmse: 0.0830321\tvalid_1's rmse: 0.0874325\n",
      "[1475]\ttraining's rmse: 0.0830201\tvalid_1's rmse: 0.0874292\n",
      "[1500]\ttraining's rmse: 0.0830102\tvalid_1's rmse: 0.0874265\n",
      "[1525]\ttraining's rmse: 0.0830013\tvalid_1's rmse: 0.0874249\n",
      "[1550]\ttraining's rmse: 0.0829912\tvalid_1's rmse: 0.0874235\n",
      "[1575]\ttraining's rmse: 0.0829813\tvalid_1's rmse: 0.0874218\n",
      "[1600]\ttraining's rmse: 0.0829752\tvalid_1's rmse: 0.0874198\n",
      "[1625]\ttraining's rmse: 0.0829666\tvalid_1's rmse: 0.0874174\n",
      "[1650]\ttraining's rmse: 0.0829571\tvalid_1's rmse: 0.0874146\n",
      "[1675]\ttraining's rmse: 0.0829508\tvalid_1's rmse: 0.0874113\n",
      "[1700]\ttraining's rmse: 0.0829421\tvalid_1's rmse: 0.0874082\n",
      "[1725]\ttraining's rmse: 0.0829349\tvalid_1's rmse: 0.0874062\n",
      "[1750]\ttraining's rmse: 0.082927\tvalid_1's rmse: 0.087404\n",
      "[1775]\ttraining's rmse: 0.0829191\tvalid_1's rmse: 0.0874022\n",
      "[1800]\ttraining's rmse: 0.0829135\tvalid_1's rmse: 0.0874009\n",
      "[1825]\ttraining's rmse: 0.0829078\tvalid_1's rmse: 0.0873986\n",
      "[1850]\ttraining's rmse: 0.0829027\tvalid_1's rmse: 0.0873974\n",
      "[1875]\ttraining's rmse: 0.0828966\tvalid_1's rmse: 0.0873952\n",
      "[1900]\ttraining's rmse: 0.0828904\tvalid_1's rmse: 0.0873942\n",
      "[1925]\ttraining's rmse: 0.0828864\tvalid_1's rmse: 0.087393\n",
      "[1950]\ttraining's rmse: 0.0828823\tvalid_1's rmse: 0.0873904\n",
      "[1975]\ttraining's rmse: 0.082877\tvalid_1's rmse: 0.0873894\n",
      "[2000]\ttraining's rmse: 0.0828732\tvalid_1's rmse: 0.0873881\n",
      "[2025]\ttraining's rmse: 0.0828702\tvalid_1's rmse: 0.0873865\n",
      "[2050]\ttraining's rmse: 0.0828665\tvalid_1's rmse: 0.0873851\n",
      "[2075]\ttraining's rmse: 0.0828628\tvalid_1's rmse: 0.0873834\n",
      "[2100]\ttraining's rmse: 0.0828601\tvalid_1's rmse: 0.0873828\n",
      "[2125]\ttraining's rmse: 0.0828562\tvalid_1's rmse: 0.0873815\n",
      "[2150]\ttraining's rmse: 0.0828523\tvalid_1's rmse: 0.0873807\n",
      "[2175]\ttraining's rmse: 0.0828488\tvalid_1's rmse: 0.0873795\n",
      "[2200]\ttraining's rmse: 0.0828451\tvalid_1's rmse: 0.0873791\n",
      "[2225]\ttraining's rmse: 0.0828416\tvalid_1's rmse: 0.0873783\n",
      "[2250]\ttraining's rmse: 0.0828386\tvalid_1's rmse: 0.0873777\n",
      "[2275]\ttraining's rmse: 0.0828363\tvalid_1's rmse: 0.0873771\n",
      "[2300]\ttraining's rmse: 0.0828342\tvalid_1's rmse: 0.0873758\n",
      "[2325]\ttraining's rmse: 0.082832\tvalid_1's rmse: 0.0873751\n",
      "[2350]\ttraining's rmse: 0.082829\tvalid_1's rmse: 0.0873745\n",
      "[2375]\ttraining's rmse: 0.0828264\tvalid_1's rmse: 0.0873735\n",
      "[2400]\ttraining's rmse: 0.0828242\tvalid_1's rmse: 0.0873731\n",
      "[2425]\ttraining's rmse: 0.0828209\tvalid_1's rmse: 0.0873721\n",
      "[2450]\ttraining's rmse: 0.0828173\tvalid_1's rmse: 0.0873722\n",
      "[2475]\ttraining's rmse: 0.082815\tvalid_1's rmse: 0.0873716\n",
      "[2500]\ttraining's rmse: 0.0828133\tvalid_1's rmse: 0.0873716\n",
      "[2525]\ttraining's rmse: 0.0828091\tvalid_1's rmse: 0.0873716\n",
      "[2550]\ttraining's rmse: 0.0828054\tvalid_1's rmse: 0.0873711\n",
      "[2575]\ttraining's rmse: 0.0828029\tvalid_1's rmse: 0.0873711\n",
      "[2600]\ttraining's rmse: 0.0828005\tvalid_1's rmse: 0.0873707\n",
      "[2625]\ttraining's rmse: 0.0827978\tvalid_1's rmse: 0.0873697\n",
      "[2650]\ttraining's rmse: 0.082796\tvalid_1's rmse: 0.0873693\n",
      "[2675]\ttraining's rmse: 0.0827943\tvalid_1's rmse: 0.0873687\n",
      "[2700]\ttraining's rmse: 0.0827929\tvalid_1's rmse: 0.0873677\n",
      "[2725]\ttraining's rmse: 0.0827892\tvalid_1's rmse: 0.0873674\n",
      "[2750]\ttraining's rmse: 0.0827876\tvalid_1's rmse: 0.0873668\n",
      "[2775]\ttraining's rmse: 0.0827852\tvalid_1's rmse: 0.0873665\n",
      "[2800]\ttraining's rmse: 0.0827845\tvalid_1's rmse: 0.0873658\n",
      "[2825]\ttraining's rmse: 0.0827821\tvalid_1's rmse: 0.0873659\n",
      "[2850]\ttraining's rmse: 0.0827802\tvalid_1's rmse: 0.0873659\n",
      "Early stopping, best iteration is:\n",
      "[2814]\ttraining's rmse: 0.0827834\tvalid_1's rmse: 0.0873657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0858683\tvalid_1's rmse: 0.0882092\n",
      "[50]\ttraining's rmse: 0.0857468\tvalid_1's rmse: 0.0881575\n",
      "[75]\ttraining's rmse: 0.0856206\tvalid_1's rmse: 0.0881057\n",
      "[100]\ttraining's rmse: 0.085506\tvalid_1's rmse: 0.0880605\n",
      "[125]\ttraining's rmse: 0.0853887\tvalid_1's rmse: 0.0880166\n",
      "[150]\ttraining's rmse: 0.085281\tvalid_1's rmse: 0.0879744\n",
      "[175]\ttraining's rmse: 0.0851907\tvalid_1's rmse: 0.087938\n",
      "[200]\ttraining's rmse: 0.0850945\tvalid_1's rmse: 0.0879011\n",
      "[225]\ttraining's rmse: 0.0850001\tvalid_1's rmse: 0.0878672\n",
      "[250]\ttraining's rmse: 0.0849185\tvalid_1's rmse: 0.0878367\n",
      "[275]\ttraining's rmse: 0.0848446\tvalid_1's rmse: 0.0878101\n",
      "[300]\ttraining's rmse: 0.0847688\tvalid_1's rmse: 0.0877836\n",
      "[325]\ttraining's rmse: 0.0846944\tvalid_1's rmse: 0.0877579\n",
      "[350]\ttraining's rmse: 0.0846233\tvalid_1's rmse: 0.0877349\n",
      "[375]\ttraining's rmse: 0.0845636\tvalid_1's rmse: 0.0877135\n",
      "[400]\ttraining's rmse: 0.0845001\tvalid_1's rmse: 0.0876934\n",
      "[425]\ttraining's rmse: 0.0844413\tvalid_1's rmse: 0.0876744\n",
      "[450]\ttraining's rmse: 0.0843855\tvalid_1's rmse: 0.0876556\n",
      "[475]\ttraining's rmse: 0.0843354\tvalid_1's rmse: 0.0876387\n",
      "[500]\ttraining's rmse: 0.0842923\tvalid_1's rmse: 0.0876224\n",
      "[525]\ttraining's rmse: 0.0842371\tvalid_1's rmse: 0.0876065\n",
      "[550]\ttraining's rmse: 0.0841863\tvalid_1's rmse: 0.0875924\n",
      "[575]\ttraining's rmse: 0.0841407\tvalid_1's rmse: 0.0875787\n",
      "[600]\ttraining's rmse: 0.0840972\tvalid_1's rmse: 0.0875659\n",
      "[625]\ttraining's rmse: 0.0840618\tvalid_1's rmse: 0.0875538\n",
      "[650]\ttraining's rmse: 0.0840168\tvalid_1's rmse: 0.0875415\n",
      "[675]\ttraining's rmse: 0.0839744\tvalid_1's rmse: 0.0875305\n",
      "[700]\ttraining's rmse: 0.0839355\tvalid_1's rmse: 0.0875191\n",
      "[725]\ttraining's rmse: 0.0838997\tvalid_1's rmse: 0.0875102\n",
      "[750]\ttraining's rmse: 0.0838669\tvalid_1's rmse: 0.0875012\n",
      "[775]\ttraining's rmse: 0.0838382\tvalid_1's rmse: 0.0874918\n",
      "[800]\ttraining's rmse: 0.0838014\tvalid_1's rmse: 0.0874837\n",
      "[825]\ttraining's rmse: 0.0837693\tvalid_1's rmse: 0.0874758\n",
      "[850]\ttraining's rmse: 0.0837379\tvalid_1's rmse: 0.0874696\n",
      "[875]\ttraining's rmse: 0.0837122\tvalid_1's rmse: 0.0874631\n",
      "[900]\ttraining's rmse: 0.0836811\tvalid_1's rmse: 0.0874562\n",
      "[925]\ttraining's rmse: 0.083655\tvalid_1's rmse: 0.0874498\n",
      "[950]\ttraining's rmse: 0.083629\tvalid_1's rmse: 0.0874443\n",
      "[975]\ttraining's rmse: 0.0836032\tvalid_1's rmse: 0.0874392\n",
      "[1000]\ttraining's rmse: 0.0835814\tvalid_1's rmse: 0.0874341\n",
      "[1025]\ttraining's rmse: 0.0835543\tvalid_1's rmse: 0.0874298\n",
      "[1050]\ttraining's rmse: 0.0835332\tvalid_1's rmse: 0.0874244\n",
      "[1075]\ttraining's rmse: 0.0835105\tvalid_1's rmse: 0.0874202\n",
      "[1100]\ttraining's rmse: 0.0834923\tvalid_1's rmse: 0.0874166\n",
      "[1125]\ttraining's rmse: 0.0834733\tvalid_1's rmse: 0.0874128\n",
      "[1150]\ttraining's rmse: 0.0834545\tvalid_1's rmse: 0.0874096\n",
      "[1175]\ttraining's rmse: 0.0834381\tvalid_1's rmse: 0.0874066\n",
      "[1200]\ttraining's rmse: 0.0834212\tvalid_1's rmse: 0.0874039\n",
      "[1225]\ttraining's rmse: 0.0834042\tvalid_1's rmse: 0.0874005\n",
      "[1250]\ttraining's rmse: 0.0833889\tvalid_1's rmse: 0.087398\n",
      "[1275]\ttraining's rmse: 0.0833698\tvalid_1's rmse: 0.0873955\n",
      "[1300]\ttraining's rmse: 0.0833566\tvalid_1's rmse: 0.0873931\n",
      "[1325]\ttraining's rmse: 0.083343\tvalid_1's rmse: 0.0873913\n",
      "[1350]\ttraining's rmse: 0.0833273\tvalid_1's rmse: 0.0873896\n",
      "[1375]\ttraining's rmse: 0.083314\tvalid_1's rmse: 0.0873879\n",
      "[1400]\ttraining's rmse: 0.0833021\tvalid_1's rmse: 0.0873861\n",
      "[1425]\ttraining's rmse: 0.0832892\tvalid_1's rmse: 0.0873848\n",
      "[1450]\ttraining's rmse: 0.083277\tvalid_1's rmse: 0.0873837\n",
      "[1475]\ttraining's rmse: 0.0832662\tvalid_1's rmse: 0.0873815\n",
      "[1500]\ttraining's rmse: 0.0832567\tvalid_1's rmse: 0.0873804\n",
      "[1525]\ttraining's rmse: 0.0832457\tvalid_1's rmse: 0.0873797\n",
      "[1550]\ttraining's rmse: 0.0832341\tvalid_1's rmse: 0.0873789\n",
      "[1575]\ttraining's rmse: 0.0832229\tvalid_1's rmse: 0.0873775\n",
      "[1600]\ttraining's rmse: 0.083215\tvalid_1's rmse: 0.0873768\n",
      "[1625]\ttraining's rmse: 0.0832076\tvalid_1's rmse: 0.0873755\n",
      "[1650]\ttraining's rmse: 0.0831982\tvalid_1's rmse: 0.0873745\n",
      "[1675]\ttraining's rmse: 0.0831921\tvalid_1's rmse: 0.0873738\n",
      "[1700]\ttraining's rmse: 0.0831852\tvalid_1's rmse: 0.0873723\n",
      "[1725]\ttraining's rmse: 0.0831778\tvalid_1's rmse: 0.0873711\n",
      "[1750]\ttraining's rmse: 0.0831686\tvalid_1's rmse: 0.0873699\n",
      "[1775]\ttraining's rmse: 0.0831618\tvalid_1's rmse: 0.0873693\n",
      "[1800]\ttraining's rmse: 0.0831538\tvalid_1's rmse: 0.0873688\n",
      "[1825]\ttraining's rmse: 0.0831479\tvalid_1's rmse: 0.0873684\n",
      "[1850]\ttraining's rmse: 0.0831406\tvalid_1's rmse: 0.0873672\n",
      "[1875]\ttraining's rmse: 0.0831352\tvalid_1's rmse: 0.0873664\n",
      "[1900]\ttraining's rmse: 0.0831308\tvalid_1's rmse: 0.087366\n",
      "[1925]\ttraining's rmse: 0.0831267\tvalid_1's rmse: 0.0873655\n",
      "[1950]\ttraining's rmse: 0.0831233\tvalid_1's rmse: 0.0873652\n",
      "[1975]\ttraining's rmse: 0.0831183\tvalid_1's rmse: 0.0873649\n",
      "[2000]\ttraining's rmse: 0.0831135\tvalid_1's rmse: 0.0873646\n",
      "[2025]\ttraining's rmse: 0.0831091\tvalid_1's rmse: 0.087364\n",
      "[2050]\ttraining's rmse: 0.0831038\tvalid_1's rmse: 0.0873633\n",
      "[2075]\ttraining's rmse: 0.0831012\tvalid_1's rmse: 0.0873628\n",
      "[2100]\ttraining's rmse: 0.0830975\tvalid_1's rmse: 0.0873625\n",
      "[2125]\ttraining's rmse: 0.0830942\tvalid_1's rmse: 0.087362\n",
      "[2150]\ttraining's rmse: 0.08309\tvalid_1's rmse: 0.0873619\n",
      "[2175]\ttraining's rmse: 0.083087\tvalid_1's rmse: 0.0873619\n",
      "[2200]\ttraining's rmse: 0.0830837\tvalid_1's rmse: 0.0873619\n",
      "Early stopping, best iteration is:\n",
      "[2163]\ttraining's rmse: 0.0830878\tvalid_1's rmse: 0.0873617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0881218\tvalid_1's rmse: 0.0836202\n",
      "[50]\ttraining's rmse: 0.0880049\tvalid_1's rmse: 0.083573\n",
      "[75]\ttraining's rmse: 0.0878826\tvalid_1's rmse: 0.0835264\n",
      "[100]\ttraining's rmse: 0.0877724\tvalid_1's rmse: 0.0834858\n",
      "[125]\ttraining's rmse: 0.0876581\tvalid_1's rmse: 0.0834436\n",
      "[150]\ttraining's rmse: 0.0875526\tvalid_1's rmse: 0.0834051\n",
      "[175]\ttraining's rmse: 0.0874637\tvalid_1's rmse: 0.0833743\n",
      "[200]\ttraining's rmse: 0.0873667\tvalid_1's rmse: 0.0833421\n",
      "[225]\ttraining's rmse: 0.0872756\tvalid_1's rmse: 0.0833109\n",
      "[250]\ttraining's rmse: 0.0871978\tvalid_1's rmse: 0.0832846\n",
      "[275]\ttraining's rmse: 0.0871272\tvalid_1's rmse: 0.0832579\n",
      "[300]\ttraining's rmse: 0.0870544\tvalid_1's rmse: 0.083234\n",
      "[325]\ttraining's rmse: 0.0869822\tvalid_1's rmse: 0.0832123\n",
      "[350]\ttraining's rmse: 0.0869141\tvalid_1's rmse: 0.0831909\n",
      "[375]\ttraining's rmse: 0.0868585\tvalid_1's rmse: 0.0831763\n",
      "[400]\ttraining's rmse: 0.0867966\tvalid_1's rmse: 0.0831627\n",
      "[425]\ttraining's rmse: 0.0867383\tvalid_1's rmse: 0.0831489\n",
      "[450]\ttraining's rmse: 0.0866868\tvalid_1's rmse: 0.0831357\n",
      "[475]\ttraining's rmse: 0.0866376\tvalid_1's rmse: 0.0831218\n",
      "[500]\ttraining's rmse: 0.0865977\tvalid_1's rmse: 0.0831088\n",
      "[525]\ttraining's rmse: 0.0865416\tvalid_1's rmse: 0.0831051\n",
      "[550]\ttraining's rmse: 0.0864907\tvalid_1's rmse: 0.083091\n",
      "[575]\ttraining's rmse: 0.0864449\tvalid_1's rmse: 0.0830798\n",
      "[600]\ttraining's rmse: 0.0863994\tvalid_1's rmse: 0.0830692\n",
      "[625]\ttraining's rmse: 0.0863633\tvalid_1's rmse: 0.0830632\n",
      "[650]\ttraining's rmse: 0.0863201\tvalid_1's rmse: 0.0830532\n",
      "[675]\ttraining's rmse: 0.0862742\tvalid_1's rmse: 0.0830446\n",
      "[700]\ttraining's rmse: 0.0862349\tvalid_1's rmse: 0.0830404\n",
      "[725]\ttraining's rmse: 0.0861974\tvalid_1's rmse: 0.0830437\n",
      "Early stopping, best iteration is:\n",
      "[692]\ttraining's rmse: 0.0862477\tvalid_1's rmse: 0.0830381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0841366\tvalid_1's rmse: 0.086881\n",
      "[50]\ttraining's rmse: 0.0840049\tvalid_1's rmse: 0.0868246\n",
      "[75]\ttraining's rmse: 0.0838776\tvalid_1's rmse: 0.0867714\n",
      "[100]\ttraining's rmse: 0.08376\tvalid_1's rmse: 0.0867266\n",
      "[125]\ttraining's rmse: 0.083642\tvalid_1's rmse: 0.0866792\n",
      "[150]\ttraining's rmse: 0.0835314\tvalid_1's rmse: 0.0866364\n",
      "[175]\ttraining's rmse: 0.0834357\tvalid_1's rmse: 0.0865963\n",
      "[200]\ttraining's rmse: 0.0833381\tvalid_1's rmse: 0.0865597\n",
      "[225]\ttraining's rmse: 0.0832429\tvalid_1's rmse: 0.0865227\n",
      "[250]\ttraining's rmse: 0.0831604\tvalid_1's rmse: 0.0864906\n",
      "[275]\ttraining's rmse: 0.0830851\tvalid_1's rmse: 0.0864595\n",
      "[300]\ttraining's rmse: 0.0830116\tvalid_1's rmse: 0.0864303\n",
      "[325]\ttraining's rmse: 0.0829372\tvalid_1's rmse: 0.0864027\n",
      "[350]\ttraining's rmse: 0.0828661\tvalid_1's rmse: 0.0863757\n",
      "[375]\ttraining's rmse: 0.082805\tvalid_1's rmse: 0.0863535\n",
      "[400]\ttraining's rmse: 0.0827425\tvalid_1's rmse: 0.0863309\n",
      "[425]\ttraining's rmse: 0.082684\tvalid_1's rmse: 0.0863099\n",
      "[450]\ttraining's rmse: 0.0826299\tvalid_1's rmse: 0.0862902\n",
      "[475]\ttraining's rmse: 0.0825815\tvalid_1's rmse: 0.0862708\n",
      "[500]\ttraining's rmse: 0.0825397\tvalid_1's rmse: 0.0862538\n",
      "[525]\ttraining's rmse: 0.082486\tvalid_1's rmse: 0.0862353\n",
      "[550]\ttraining's rmse: 0.0824378\tvalid_1's rmse: 0.0862192\n",
      "[575]\ttraining's rmse: 0.0823919\tvalid_1's rmse: 0.0862046\n",
      "[600]\ttraining's rmse: 0.0823501\tvalid_1's rmse: 0.0861918\n",
      "[625]\ttraining's rmse: 0.0823167\tvalid_1's rmse: 0.0861784\n",
      "[650]\ttraining's rmse: 0.0822735\tvalid_1's rmse: 0.0861658\n",
      "[675]\ttraining's rmse: 0.0822333\tvalid_1's rmse: 0.0861532\n",
      "[700]\ttraining's rmse: 0.0821957\tvalid_1's rmse: 0.0861419\n",
      "[725]\ttraining's rmse: 0.0821563\tvalid_1's rmse: 0.0861321\n",
      "[750]\ttraining's rmse: 0.0821227\tvalid_1's rmse: 0.0861219\n",
      "[775]\ttraining's rmse: 0.0820966\tvalid_1's rmse: 0.086111\n",
      "[800]\ttraining's rmse: 0.0820625\tvalid_1's rmse: 0.0861025\n",
      "[825]\ttraining's rmse: 0.0820362\tvalid_1's rmse: 0.0860942\n",
      "[850]\ttraining's rmse: 0.0820074\tvalid_1's rmse: 0.0860866\n",
      "[875]\ttraining's rmse: 0.0819812\tvalid_1's rmse: 0.0860791\n",
      "[900]\ttraining's rmse: 0.0819512\tvalid_1's rmse: 0.0860706\n",
      "[925]\ttraining's rmse: 0.0819272\tvalid_1's rmse: 0.0860632\n",
      "[950]\ttraining's rmse: 0.0819043\tvalid_1's rmse: 0.0860546\n",
      "[975]\ttraining's rmse: 0.081881\tvalid_1's rmse: 0.0860474\n",
      "[1000]\ttraining's rmse: 0.0818589\tvalid_1's rmse: 0.0860408\n",
      "[1025]\ttraining's rmse: 0.0818351\tvalid_1's rmse: 0.0860347\n",
      "[1050]\ttraining's rmse: 0.0818119\tvalid_1's rmse: 0.0860271\n",
      "[1075]\ttraining's rmse: 0.0817907\tvalid_1's rmse: 0.0860225\n",
      "[1100]\ttraining's rmse: 0.0817743\tvalid_1's rmse: 0.0860176\n",
      "[1125]\ttraining's rmse: 0.081758\tvalid_1's rmse: 0.0860114\n",
      "[1150]\ttraining's rmse: 0.0817384\tvalid_1's rmse: 0.0860059\n",
      "[1175]\ttraining's rmse: 0.0817223\tvalid_1's rmse: 0.0860023\n",
      "[1200]\ttraining's rmse: 0.0817087\tvalid_1's rmse: 0.0859975\n",
      "[1225]\ttraining's rmse: 0.0816947\tvalid_1's rmse: 0.0859935\n",
      "[1250]\ttraining's rmse: 0.0816778\tvalid_1's rmse: 0.0859894\n",
      "[1275]\ttraining's rmse: 0.0816588\tvalid_1's rmse: 0.0859857\n",
      "[1300]\ttraining's rmse: 0.0816455\tvalid_1's rmse: 0.0859811\n",
      "[1325]\ttraining's rmse: 0.0816313\tvalid_1's rmse: 0.0859769\n",
      "[1350]\ttraining's rmse: 0.081618\tvalid_1's rmse: 0.0859727\n",
      "[1375]\ttraining's rmse: 0.0816033\tvalid_1's rmse: 0.085969\n",
      "[1400]\ttraining's rmse: 0.0815922\tvalid_1's rmse: 0.0859654\n",
      "[1425]\ttraining's rmse: 0.0815781\tvalid_1's rmse: 0.0859626\n",
      "[1450]\ttraining's rmse: 0.0815648\tvalid_1's rmse: 0.0859586\n",
      "[1475]\ttraining's rmse: 0.0815532\tvalid_1's rmse: 0.0859544\n",
      "[1500]\ttraining's rmse: 0.0815419\tvalid_1's rmse: 0.085952\n",
      "[1525]\ttraining's rmse: 0.0815304\tvalid_1's rmse: 0.0859505\n",
      "[1550]\ttraining's rmse: 0.0815188\tvalid_1's rmse: 0.0859476\n",
      "[1575]\ttraining's rmse: 0.0815109\tvalid_1's rmse: 0.0859465\n",
      "[1600]\ttraining's rmse: 0.0815045\tvalid_1's rmse: 0.085945\n",
      "[1625]\ttraining's rmse: 0.0814968\tvalid_1's rmse: 0.0859434\n",
      "[1650]\ttraining's rmse: 0.0814896\tvalid_1's rmse: 0.085941\n",
      "[1675]\ttraining's rmse: 0.0814829\tvalid_1's rmse: 0.0859389\n",
      "[1700]\ttraining's rmse: 0.0814765\tvalid_1's rmse: 0.0859369\n",
      "[1725]\ttraining's rmse: 0.0814702\tvalid_1's rmse: 0.0859357\n",
      "[1750]\ttraining's rmse: 0.0814637\tvalid_1's rmse: 0.0859347\n",
      "[1775]\ttraining's rmse: 0.0814578\tvalid_1's rmse: 0.0859328\n",
      "[1800]\ttraining's rmse: 0.0814524\tvalid_1's rmse: 0.0859314\n",
      "[1825]\ttraining's rmse: 0.0814469\tvalid_1's rmse: 0.0859304\n",
      "[1850]\ttraining's rmse: 0.0814422\tvalid_1's rmse: 0.0859288\n",
      "[1875]\ttraining's rmse: 0.0814364\tvalid_1's rmse: 0.085927\n",
      "[1900]\ttraining's rmse: 0.0814323\tvalid_1's rmse: 0.085925\n",
      "[1925]\ttraining's rmse: 0.0814276\tvalid_1's rmse: 0.0859243\n",
      "[1950]\ttraining's rmse: 0.081424\tvalid_1's rmse: 0.0859217\n",
      "[1975]\ttraining's rmse: 0.0814211\tvalid_1's rmse: 0.0859204\n",
      "[2000]\ttraining's rmse: 0.0814175\tvalid_1's rmse: 0.0859192\n",
      "[2025]\ttraining's rmse: 0.0814144\tvalid_1's rmse: 0.0859169\n",
      "[2050]\ttraining's rmse: 0.0814105\tvalid_1's rmse: 0.0859157\n",
      "[2075]\ttraining's rmse: 0.0814059\tvalid_1's rmse: 0.0859142\n",
      "[2100]\ttraining's rmse: 0.0814027\tvalid_1's rmse: 0.0859138\n",
      "[2125]\ttraining's rmse: 0.0813998\tvalid_1's rmse: 0.0859128\n",
      "[2150]\ttraining's rmse: 0.0813971\tvalid_1's rmse: 0.0859117\n",
      "[2175]\ttraining's rmse: 0.0813936\tvalid_1's rmse: 0.085911\n",
      "[2200]\ttraining's rmse: 0.0813907\tvalid_1's rmse: 0.0859098\n",
      "[2225]\ttraining's rmse: 0.0813879\tvalid_1's rmse: 0.0859091\n",
      "[2250]\ttraining's rmse: 0.0813851\tvalid_1's rmse: 0.0859082\n",
      "[2275]\ttraining's rmse: 0.0813819\tvalid_1's rmse: 0.0859075\n",
      "[2300]\ttraining's rmse: 0.0813801\tvalid_1's rmse: 0.0859061\n",
      "[2325]\ttraining's rmse: 0.0813774\tvalid_1's rmse: 0.0859051\n",
      "[2350]\ttraining's rmse: 0.0813751\tvalid_1's rmse: 0.0859049\n",
      "[2375]\ttraining's rmse: 0.0813721\tvalid_1's rmse: 0.0859028\n",
      "[2400]\ttraining's rmse: 0.0813695\tvalid_1's rmse: 0.085902\n",
      "[2425]\ttraining's rmse: 0.0813661\tvalid_1's rmse: 0.0859016\n",
      "[2450]\ttraining's rmse: 0.0813636\tvalid_1's rmse: 0.085901\n",
      "[2475]\ttraining's rmse: 0.0813616\tvalid_1's rmse: 0.0859007\n",
      "[2500]\ttraining's rmse: 0.0813599\tvalid_1's rmse: 0.0859\n",
      "[2525]\ttraining's rmse: 0.0813583\tvalid_1's rmse: 0.0859\n",
      "[2550]\ttraining's rmse: 0.0813561\tvalid_1's rmse: 0.0858992\n",
      "[2575]\ttraining's rmse: 0.0813547\tvalid_1's rmse: 0.0858983\n",
      "[2600]\ttraining's rmse: 0.0813528\tvalid_1's rmse: 0.085898\n",
      "[2625]\ttraining's rmse: 0.0813502\tvalid_1's rmse: 0.085897\n",
      "[2650]\ttraining's rmse: 0.0813478\tvalid_1's rmse: 0.0858971\n",
      "Early stopping, best iteration is:\n",
      "[2620]\ttraining's rmse: 0.0813512\tvalid_1's rmse: 0.0858966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0843676\tvalid_1's rmse: 0.0864414\n",
      "[50]\ttraining's rmse: 0.0842473\tvalid_1's rmse: 0.0863875\n",
      "[75]\ttraining's rmse: 0.0841279\tvalid_1's rmse: 0.0863346\n",
      "[100]\ttraining's rmse: 0.0840155\tvalid_1's rmse: 0.0862874\n",
      "[125]\ttraining's rmse: 0.083902\tvalid_1's rmse: 0.0862408\n",
      "[150]\ttraining's rmse: 0.0838012\tvalid_1's rmse: 0.0861967\n",
      "[175]\ttraining's rmse: 0.0837167\tvalid_1's rmse: 0.0861611\n",
      "[200]\ttraining's rmse: 0.0836212\tvalid_1's rmse: 0.0861249\n",
      "[225]\ttraining's rmse: 0.0835295\tvalid_1's rmse: 0.0860898\n",
      "[250]\ttraining's rmse: 0.08345\tvalid_1's rmse: 0.0860578\n",
      "[275]\ttraining's rmse: 0.0833782\tvalid_1's rmse: 0.0860291\n",
      "[300]\ttraining's rmse: 0.0833064\tvalid_1's rmse: 0.086001\n",
      "[325]\ttraining's rmse: 0.0832316\tvalid_1's rmse: 0.085975\n",
      "[350]\ttraining's rmse: 0.0831593\tvalid_1's rmse: 0.0859506\n",
      "[375]\ttraining's rmse: 0.0831006\tvalid_1's rmse: 0.0859295\n",
      "[400]\ttraining's rmse: 0.0830369\tvalid_1's rmse: 0.0859091\n",
      "[425]\ttraining's rmse: 0.0829771\tvalid_1's rmse: 0.0858886\n",
      "[450]\ttraining's rmse: 0.0829237\tvalid_1's rmse: 0.0858698\n",
      "[475]\ttraining's rmse: 0.0828745\tvalid_1's rmse: 0.0858519\n",
      "[500]\ttraining's rmse: 0.0828321\tvalid_1's rmse: 0.0858352\n",
      "[525]\ttraining's rmse: 0.0827763\tvalid_1's rmse: 0.0858188\n",
      "[550]\ttraining's rmse: 0.0827275\tvalid_1's rmse: 0.0858035\n",
      "[575]\ttraining's rmse: 0.0826817\tvalid_1's rmse: 0.0857892\n",
      "[600]\ttraining's rmse: 0.0826355\tvalid_1's rmse: 0.0857757\n",
      "[625]\ttraining's rmse: 0.0826001\tvalid_1's rmse: 0.0857634\n",
      "[650]\ttraining's rmse: 0.0825551\tvalid_1's rmse: 0.0857506\n",
      "[675]\ttraining's rmse: 0.0825131\tvalid_1's rmse: 0.0857396\n",
      "[700]\ttraining's rmse: 0.0824748\tvalid_1's rmse: 0.0857294\n",
      "[725]\ttraining's rmse: 0.0824386\tvalid_1's rmse: 0.0857202\n",
      "[750]\ttraining's rmse: 0.0824065\tvalid_1's rmse: 0.0857111\n",
      "[775]\ttraining's rmse: 0.0823794\tvalid_1's rmse: 0.0857018\n",
      "[800]\ttraining's rmse: 0.0823422\tvalid_1's rmse: 0.0856932\n",
      "[825]\ttraining's rmse: 0.0823082\tvalid_1's rmse: 0.0856841\n",
      "[850]\ttraining's rmse: 0.0822786\tvalid_1's rmse: 0.0856771\n",
      "[875]\ttraining's rmse: 0.0822511\tvalid_1's rmse: 0.0856699\n",
      "[900]\ttraining's rmse: 0.0822236\tvalid_1's rmse: 0.0856637\n",
      "[925]\ttraining's rmse: 0.0821962\tvalid_1's rmse: 0.085658\n",
      "[950]\ttraining's rmse: 0.0821709\tvalid_1's rmse: 0.0856525\n",
      "[975]\ttraining's rmse: 0.0821473\tvalid_1's rmse: 0.0856467\n",
      "[1000]\ttraining's rmse: 0.0821236\tvalid_1's rmse: 0.0856414\n",
      "[1025]\ttraining's rmse: 0.0820973\tvalid_1's rmse: 0.0856361\n",
      "[1050]\ttraining's rmse: 0.0820758\tvalid_1's rmse: 0.0856313\n",
      "[1075]\ttraining's rmse: 0.0820517\tvalid_1's rmse: 0.0856272\n",
      "[1100]\ttraining's rmse: 0.0820356\tvalid_1's rmse: 0.0856234\n",
      "[1125]\ttraining's rmse: 0.0820165\tvalid_1's rmse: 0.0856196\n",
      "[1150]\ttraining's rmse: 0.0819976\tvalid_1's rmse: 0.0856163\n",
      "[1175]\ttraining's rmse: 0.0819826\tvalid_1's rmse: 0.085613\n",
      "[1200]\ttraining's rmse: 0.0819658\tvalid_1's rmse: 0.0856099\n",
      "[1225]\ttraining's rmse: 0.0819515\tvalid_1's rmse: 0.0856069\n",
      "[1250]\ttraining's rmse: 0.0819374\tvalid_1's rmse: 0.0856036\n",
      "[1275]\ttraining's rmse: 0.081921\tvalid_1's rmse: 0.0856013\n",
      "[1300]\ttraining's rmse: 0.0819073\tvalid_1's rmse: 0.085599\n",
      "[1325]\ttraining's rmse: 0.0818946\tvalid_1's rmse: 0.0855971\n",
      "[1350]\ttraining's rmse: 0.081881\tvalid_1's rmse: 0.0855954\n",
      "[1375]\ttraining's rmse: 0.0818686\tvalid_1's rmse: 0.0855938\n",
      "[1400]\ttraining's rmse: 0.0818589\tvalid_1's rmse: 0.085592\n",
      "[1425]\ttraining's rmse: 0.0818472\tvalid_1's rmse: 0.0855907\n",
      "[1450]\ttraining's rmse: 0.0818338\tvalid_1's rmse: 0.0855894\n",
      "[1475]\ttraining's rmse: 0.0818234\tvalid_1's rmse: 0.0855876\n",
      "[1500]\ttraining's rmse: 0.0818157\tvalid_1's rmse: 0.085586\n",
      "[1525]\ttraining's rmse: 0.0818055\tvalid_1's rmse: 0.0855851\n",
      "[1550]\ttraining's rmse: 0.0817973\tvalid_1's rmse: 0.085585\n",
      "[1575]\ttraining's rmse: 0.0817884\tvalid_1's rmse: 0.0855839\n",
      "[1600]\ttraining's rmse: 0.08178\tvalid_1's rmse: 0.0855829\n",
      "[1625]\ttraining's rmse: 0.0817709\tvalid_1's rmse: 0.0855814\n",
      "[1650]\ttraining's rmse: 0.0817632\tvalid_1's rmse: 0.0855812\n",
      "[1675]\ttraining's rmse: 0.0817578\tvalid_1's rmse: 0.0855801\n",
      "[1700]\ttraining's rmse: 0.0817515\tvalid_1's rmse: 0.0855792\n",
      "[1725]\ttraining's rmse: 0.0817448\tvalid_1's rmse: 0.0855782\n",
      "[1750]\ttraining's rmse: 0.0817372\tvalid_1's rmse: 0.0855779\n",
      "[1775]\ttraining's rmse: 0.0817309\tvalid_1's rmse: 0.0855772\n",
      "[1800]\ttraining's rmse: 0.0817238\tvalid_1's rmse: 0.0855765\n",
      "[1825]\ttraining's rmse: 0.0817161\tvalid_1's rmse: 0.0855753\n",
      "[1850]\ttraining's rmse: 0.0817104\tvalid_1's rmse: 0.085574\n",
      "[1875]\ttraining's rmse: 0.0817047\tvalid_1's rmse: 0.0855733\n",
      "[1900]\ttraining's rmse: 0.0816999\tvalid_1's rmse: 0.0855736\n",
      "[1925]\ttraining's rmse: 0.0816935\tvalid_1's rmse: 0.085573\n",
      "[1950]\ttraining's rmse: 0.0816903\tvalid_1's rmse: 0.0855721\n",
      "[1975]\ttraining's rmse: 0.0816871\tvalid_1's rmse: 0.085572\n",
      "[2000]\ttraining's rmse: 0.0816823\tvalid_1's rmse: 0.0855715\n",
      "[2025]\ttraining's rmse: 0.081679\tvalid_1's rmse: 0.085571\n",
      "[2050]\ttraining's rmse: 0.0816756\tvalid_1's rmse: 0.0855705\n",
      "[2075]\ttraining's rmse: 0.0816725\tvalid_1's rmse: 0.08557\n",
      "[2100]\ttraining's rmse: 0.0816676\tvalid_1's rmse: 0.0855695\n",
      "[2125]\ttraining's rmse: 0.0816648\tvalid_1's rmse: 0.0855695\n",
      "[2150]\ttraining's rmse: 0.0816614\tvalid_1's rmse: 0.0855694\n",
      "[2175]\ttraining's rmse: 0.0816585\tvalid_1's rmse: 0.0855688\n",
      "[2200]\ttraining's rmse: 0.0816552\tvalid_1's rmse: 0.0855683\n",
      "[2225]\ttraining's rmse: 0.0816531\tvalid_1's rmse: 0.085568\n",
      "[2250]\ttraining's rmse: 0.0816499\tvalid_1's rmse: 0.0855683\n",
      "Early stopping, best iteration is:\n",
      "[2205]\ttraining's rmse: 0.0816545\tvalid_1's rmse: 0.085568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0865442\tvalid_1's rmse: 0.0820144\n",
      "[50]\ttraining's rmse: 0.0864299\tvalid_1's rmse: 0.0819655\n",
      "[75]\ttraining's rmse: 0.0863116\tvalid_1's rmse: 0.0819164\n",
      "[100]\ttraining's rmse: 0.0862052\tvalid_1's rmse: 0.0818735\n",
      "[125]\ttraining's rmse: 0.0860971\tvalid_1's rmse: 0.0818316\n",
      "[150]\ttraining's rmse: 0.085997\tvalid_1's rmse: 0.0817941\n",
      "[175]\ttraining's rmse: 0.0859156\tvalid_1's rmse: 0.0817637\n",
      "[200]\ttraining's rmse: 0.0858255\tvalid_1's rmse: 0.0817327\n",
      "[225]\ttraining's rmse: 0.0857398\tvalid_1's rmse: 0.0817015\n",
      "[250]\ttraining's rmse: 0.0856676\tvalid_1's rmse: 0.0816762\n",
      "[275]\ttraining's rmse: 0.0855999\tvalid_1's rmse: 0.0816508\n",
      "[300]\ttraining's rmse: 0.0855316\tvalid_1's rmse: 0.0816287\n",
      "[325]\ttraining's rmse: 0.0854636\tvalid_1's rmse: 0.0816063\n",
      "[350]\ttraining's rmse: 0.085396\tvalid_1's rmse: 0.0815858\n",
      "[375]\ttraining's rmse: 0.0853423\tvalid_1's rmse: 0.0815666\n",
      "[400]\ttraining's rmse: 0.0852837\tvalid_1's rmse: 0.0815522\n",
      "[425]\ttraining's rmse: 0.0852284\tvalid_1's rmse: 0.0815387\n",
      "[450]\ttraining's rmse: 0.0851757\tvalid_1's rmse: 0.0815244\n",
      "[475]\ttraining's rmse: 0.0851265\tvalid_1's rmse: 0.0815103\n",
      "[500]\ttraining's rmse: 0.0850855\tvalid_1's rmse: 0.0814999\n",
      "[525]\ttraining's rmse: 0.0850308\tvalid_1's rmse: 0.0814979\n",
      "[550]\ttraining's rmse: 0.0849824\tvalid_1's rmse: 0.0814848\n",
      "[575]\ttraining's rmse: 0.0849373\tvalid_1's rmse: 0.0814726\n",
      "[600]\ttraining's rmse: 0.0848924\tvalid_1's rmse: 0.0814618\n",
      "[625]\ttraining's rmse: 0.0848577\tvalid_1's rmse: 0.0814526\n",
      "[650]\ttraining's rmse: 0.0848157\tvalid_1's rmse: 0.081443\n",
      "[675]\ttraining's rmse: 0.0847717\tvalid_1's rmse: 0.0814412\n",
      "[700]\ttraining's rmse: 0.0847333\tvalid_1's rmse: 0.081433\n",
      "[725]\ttraining's rmse: 0.0846969\tvalid_1's rmse: 0.0814526\n",
      "[750]\ttraining's rmse: 0.0846641\tvalid_1's rmse: 0.081457\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's rmse: 0.0847333\tvalid_1's rmse: 0.081433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0866275\tvalid_1's rmse: 0.088983\n",
      "[50]\ttraining's rmse: 0.0864853\tvalid_1's rmse: 0.088933\n",
      "[75]\ttraining's rmse: 0.0863423\tvalid_1's rmse: 0.0888821\n",
      "[100]\ttraining's rmse: 0.0862047\tvalid_1's rmse: 0.0888377\n",
      "[125]\ttraining's rmse: 0.0860713\tvalid_1's rmse: 0.0887933\n",
      "[150]\ttraining's rmse: 0.085947\tvalid_1's rmse: 0.0887527\n",
      "[175]\ttraining's rmse: 0.0858444\tvalid_1's rmse: 0.088719\n",
      "[200]\ttraining's rmse: 0.0857356\tvalid_1's rmse: 0.0886819\n",
      "[225]\ttraining's rmse: 0.0856299\tvalid_1's rmse: 0.0886501\n",
      "[250]\ttraining's rmse: 0.085541\tvalid_1's rmse: 0.088619\n",
      "[275]\ttraining's rmse: 0.0854591\tvalid_1's rmse: 0.0885916\n",
      "[300]\ttraining's rmse: 0.0853725\tvalid_1's rmse: 0.0885623\n",
      "[325]\ttraining's rmse: 0.0852924\tvalid_1's rmse: 0.0885373\n",
      "[350]\ttraining's rmse: 0.0852098\tvalid_1's rmse: 0.088512\n",
      "[375]\ttraining's rmse: 0.0851407\tvalid_1's rmse: 0.0884932\n",
      "[400]\ttraining's rmse: 0.0850678\tvalid_1's rmse: 0.0884724\n",
      "[425]\ttraining's rmse: 0.0850031\tvalid_1's rmse: 0.0884532\n",
      "[450]\ttraining's rmse: 0.0849448\tvalid_1's rmse: 0.0884353\n",
      "[475]\ttraining's rmse: 0.0848874\tvalid_1's rmse: 0.088418\n",
      "[500]\ttraining's rmse: 0.0848378\tvalid_1's rmse: 0.0884015\n",
      "[525]\ttraining's rmse: 0.0847779\tvalid_1's rmse: 0.0883855\n",
      "[550]\ttraining's rmse: 0.0847213\tvalid_1's rmse: 0.0883693\n",
      "[575]\ttraining's rmse: 0.0846698\tvalid_1's rmse: 0.0883557\n",
      "[600]\ttraining's rmse: 0.0846206\tvalid_1's rmse: 0.0883423\n",
      "[625]\ttraining's rmse: 0.0845817\tvalid_1's rmse: 0.0883289\n",
      "[650]\ttraining's rmse: 0.0845357\tvalid_1's rmse: 0.0883174\n",
      "[675]\ttraining's rmse: 0.0844898\tvalid_1's rmse: 0.088306\n",
      "[700]\ttraining's rmse: 0.0844478\tvalid_1's rmse: 0.0882953\n",
      "[725]\ttraining's rmse: 0.0844103\tvalid_1's rmse: 0.0882852\n",
      "[750]\ttraining's rmse: 0.0843732\tvalid_1's rmse: 0.0882772\n",
      "[775]\ttraining's rmse: 0.0843435\tvalid_1's rmse: 0.0882681\n",
      "[800]\ttraining's rmse: 0.0843062\tvalid_1's rmse: 0.0882592\n",
      "[825]\ttraining's rmse: 0.0842739\tvalid_1's rmse: 0.0882505\n",
      "[850]\ttraining's rmse: 0.0842409\tvalid_1's rmse: 0.088244\n",
      "[875]\ttraining's rmse: 0.0842124\tvalid_1's rmse: 0.0882372\n",
      "[900]\ttraining's rmse: 0.0841787\tvalid_1's rmse: 0.0882295\n",
      "[925]\ttraining's rmse: 0.0841511\tvalid_1's rmse: 0.088223\n",
      "[950]\ttraining's rmse: 0.0841241\tvalid_1's rmse: 0.0882161\n",
      "[975]\ttraining's rmse: 0.0840986\tvalid_1's rmse: 0.0882104\n",
      "[1000]\ttraining's rmse: 0.0840729\tvalid_1's rmse: 0.0882049\n",
      "[1025]\ttraining's rmse: 0.0840469\tvalid_1's rmse: 0.0881985\n",
      "[1050]\ttraining's rmse: 0.0840255\tvalid_1's rmse: 0.0881931\n",
      "[1075]\ttraining's rmse: 0.0840018\tvalid_1's rmse: 0.0881883\n",
      "[1100]\ttraining's rmse: 0.0839841\tvalid_1's rmse: 0.0881827\n",
      "[1125]\ttraining's rmse: 0.0839633\tvalid_1's rmse: 0.0881774\n",
      "[1150]\ttraining's rmse: 0.0839428\tvalid_1's rmse: 0.0881725\n",
      "[1175]\ttraining's rmse: 0.0839248\tvalid_1's rmse: 0.0881683\n",
      "[1200]\ttraining's rmse: 0.0839044\tvalid_1's rmse: 0.0881632\n",
      "[1225]\ttraining's rmse: 0.0838877\tvalid_1's rmse: 0.0881597\n",
      "[1250]\ttraining's rmse: 0.0838729\tvalid_1's rmse: 0.0881569\n",
      "[1275]\ttraining's rmse: 0.0838546\tvalid_1's rmse: 0.0881535\n",
      "[1300]\ttraining's rmse: 0.0838405\tvalid_1's rmse: 0.0881493\n",
      "[1325]\ttraining's rmse: 0.0838254\tvalid_1's rmse: 0.0881456\n",
      "[1350]\ttraining's rmse: 0.0838142\tvalid_1's rmse: 0.0881424\n",
      "[1375]\ttraining's rmse: 0.0837987\tvalid_1's rmse: 0.088139\n",
      "[1400]\ttraining's rmse: 0.0837866\tvalid_1's rmse: 0.0881342\n",
      "[1425]\ttraining's rmse: 0.0837716\tvalid_1's rmse: 0.0881317\n",
      "[1450]\ttraining's rmse: 0.083757\tvalid_1's rmse: 0.0881282\n",
      "[1475]\ttraining's rmse: 0.0837475\tvalid_1's rmse: 0.0881256\n",
      "[1500]\ttraining's rmse: 0.0837382\tvalid_1's rmse: 0.0881239\n",
      "[1525]\ttraining's rmse: 0.0837257\tvalid_1's rmse: 0.0881215\n",
      "[1550]\ttraining's rmse: 0.0837144\tvalid_1's rmse: 0.0881194\n",
      "[1575]\ttraining's rmse: 0.0837065\tvalid_1's rmse: 0.0881173\n",
      "[1600]\ttraining's rmse: 0.0837004\tvalid_1's rmse: 0.0881153\n",
      "[1625]\ttraining's rmse: 0.0836911\tvalid_1's rmse: 0.0881123\n",
      "[1650]\ttraining's rmse: 0.0836829\tvalid_1's rmse: 0.0881099\n",
      "[1675]\ttraining's rmse: 0.0836762\tvalid_1's rmse: 0.0881083\n",
      "[1700]\ttraining's rmse: 0.0836696\tvalid_1's rmse: 0.0881047\n",
      "[1725]\ttraining's rmse: 0.0836633\tvalid_1's rmse: 0.0881028\n",
      "[1750]\ttraining's rmse: 0.0836554\tvalid_1's rmse: 0.0881012\n",
      "[1775]\ttraining's rmse: 0.0836489\tvalid_1's rmse: 0.0881\n",
      "[1800]\ttraining's rmse: 0.0836419\tvalid_1's rmse: 0.0880985\n",
      "[1825]\ttraining's rmse: 0.0836344\tvalid_1's rmse: 0.0880967\n",
      "[1850]\ttraining's rmse: 0.0836284\tvalid_1's rmse: 0.0880951\n",
      "[1875]\ttraining's rmse: 0.0836219\tvalid_1's rmse: 0.0880934\n",
      "[1900]\ttraining's rmse: 0.0836172\tvalid_1's rmse: 0.0880925\n",
      "[1925]\ttraining's rmse: 0.0836124\tvalid_1's rmse: 0.0880905\n",
      "[1950]\ttraining's rmse: 0.0836083\tvalid_1's rmse: 0.0880891\n",
      "[1975]\ttraining's rmse: 0.0836035\tvalid_1's rmse: 0.0880879\n",
      "[2000]\ttraining's rmse: 0.083599\tvalid_1's rmse: 0.088086\n",
      "[2025]\ttraining's rmse: 0.083595\tvalid_1's rmse: 0.088085\n",
      "[2050]\ttraining's rmse: 0.0835914\tvalid_1's rmse: 0.088084\n",
      "[2075]\ttraining's rmse: 0.0835883\tvalid_1's rmse: 0.0880823\n",
      "[2100]\ttraining's rmse: 0.083584\tvalid_1's rmse: 0.0880806\n",
      "[2125]\ttraining's rmse: 0.0835814\tvalid_1's rmse: 0.0880798\n",
      "[2150]\ttraining's rmse: 0.0835774\tvalid_1's rmse: 0.0880792\n",
      "[2175]\ttraining's rmse: 0.0835742\tvalid_1's rmse: 0.0880779\n",
      "[2200]\ttraining's rmse: 0.0835717\tvalid_1's rmse: 0.0880777\n",
      "[2225]\ttraining's rmse: 0.0835657\tvalid_1's rmse: 0.0880766\n",
      "[2250]\ttraining's rmse: 0.0835626\tvalid_1's rmse: 0.0880758\n",
      "[2275]\ttraining's rmse: 0.083559\tvalid_1's rmse: 0.088075\n",
      "[2300]\ttraining's rmse: 0.0835553\tvalid_1's rmse: 0.0880737\n",
      "[2325]\ttraining's rmse: 0.0835529\tvalid_1's rmse: 0.0880729\n",
      "[2350]\ttraining's rmse: 0.0835499\tvalid_1's rmse: 0.0880725\n",
      "[2375]\ttraining's rmse: 0.0835465\tvalid_1's rmse: 0.088071\n",
      "[2400]\ttraining's rmse: 0.083544\tvalid_1's rmse: 0.0880708\n",
      "[2425]\ttraining's rmse: 0.0835414\tvalid_1's rmse: 0.0880693\n",
      "[2450]\ttraining's rmse: 0.0835396\tvalid_1's rmse: 0.0880684\n",
      "[2475]\ttraining's rmse: 0.0835364\tvalid_1's rmse: 0.0880679\n",
      "[2500]\ttraining's rmse: 0.0835328\tvalid_1's rmse: 0.0880672\n",
      "[2525]\ttraining's rmse: 0.0835288\tvalid_1's rmse: 0.0880662\n",
      "[2550]\ttraining's rmse: 0.0835268\tvalid_1's rmse: 0.088066\n",
      "[2575]\ttraining's rmse: 0.0835248\tvalid_1's rmse: 0.0880652\n",
      "[2600]\ttraining's rmse: 0.0835218\tvalid_1's rmse: 0.0880642\n",
      "[2625]\ttraining's rmse: 0.0835202\tvalid_1's rmse: 0.0880635\n",
      "[2650]\ttraining's rmse: 0.083518\tvalid_1's rmse: 0.0880632\n",
      "[2675]\ttraining's rmse: 0.0835165\tvalid_1's rmse: 0.0880626\n",
      "[2700]\ttraining's rmse: 0.0835149\tvalid_1's rmse: 0.0880615\n",
      "[2725]\ttraining's rmse: 0.0835117\tvalid_1's rmse: 0.088061\n",
      "[2750]\ttraining's rmse: 0.0835102\tvalid_1's rmse: 0.0880603\n",
      "[2775]\ttraining's rmse: 0.0835079\tvalid_1's rmse: 0.0880599\n",
      "[2800]\ttraining's rmse: 0.0835047\tvalid_1's rmse: 0.08806\n",
      "[2825]\ttraining's rmse: 0.0835037\tvalid_1's rmse: 0.0880595\n",
      "[2850]\ttraining's rmse: 0.083502\tvalid_1's rmse: 0.0880594\n",
      "[2875]\ttraining's rmse: 0.0834998\tvalid_1's rmse: 0.0880596\n",
      "[2900]\ttraining's rmse: 0.0834975\tvalid_1's rmse: 0.088059\n",
      "[2925]\ttraining's rmse: 0.0834966\tvalid_1's rmse: 0.0880587\n",
      "[2950]\ttraining's rmse: 0.0834952\tvalid_1's rmse: 0.0880578\n",
      "[2975]\ttraining's rmse: 0.0834931\tvalid_1's rmse: 0.0880574\n",
      "[3000]\ttraining's rmse: 0.0834885\tvalid_1's rmse: 0.0880572\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\ttraining's rmse: 0.0834885\tvalid_1's rmse: 0.0880572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0866279\tvalid_1's rmse: 0.0890171\n",
      "[50]\ttraining's rmse: 0.0865044\tvalid_1's rmse: 0.0889642\n",
      "[75]\ttraining's rmse: 0.0863757\tvalid_1's rmse: 0.0889118\n",
      "[100]\ttraining's rmse: 0.0862592\tvalid_1's rmse: 0.0888668\n",
      "[125]\ttraining's rmse: 0.0861388\tvalid_1's rmse: 0.088819\n",
      "[150]\ttraining's rmse: 0.0860239\tvalid_1's rmse: 0.0887743\n",
      "[175]\ttraining's rmse: 0.0859328\tvalid_1's rmse: 0.0887382\n",
      "[200]\ttraining's rmse: 0.0858339\tvalid_1's rmse: 0.0887019\n",
      "[225]\ttraining's rmse: 0.085735\tvalid_1's rmse: 0.0886673\n",
      "[250]\ttraining's rmse: 0.0856525\tvalid_1's rmse: 0.0886352\n",
      "[275]\ttraining's rmse: 0.0855747\tvalid_1's rmse: 0.088606\n",
      "[300]\ttraining's rmse: 0.085496\tvalid_1's rmse: 0.0885778\n",
      "[325]\ttraining's rmse: 0.0854173\tvalid_1's rmse: 0.0885512\n",
      "[350]\ttraining's rmse: 0.0853414\tvalid_1's rmse: 0.0885263\n",
      "[375]\ttraining's rmse: 0.08528\tvalid_1's rmse: 0.088505\n",
      "[400]\ttraining's rmse: 0.0852141\tvalid_1's rmse: 0.0884845\n",
      "[425]\ttraining's rmse: 0.0851532\tvalid_1's rmse: 0.0884644\n",
      "[450]\ttraining's rmse: 0.0850962\tvalid_1's rmse: 0.0884448\n",
      "[475]\ttraining's rmse: 0.0850437\tvalid_1's rmse: 0.088428\n",
      "[500]\ttraining's rmse: 0.0849995\tvalid_1's rmse: 0.0884127\n",
      "[525]\ttraining's rmse: 0.0849411\tvalid_1's rmse: 0.0883948\n",
      "[550]\ttraining's rmse: 0.0848884\tvalid_1's rmse: 0.0883798\n",
      "[575]\ttraining's rmse: 0.0848379\tvalid_1's rmse: 0.088366\n",
      "[600]\ttraining's rmse: 0.0847891\tvalid_1's rmse: 0.0883518\n",
      "[625]\ttraining's rmse: 0.0847528\tvalid_1's rmse: 0.0883397\n",
      "[650]\ttraining's rmse: 0.0847053\tvalid_1's rmse: 0.0883262\n",
      "[675]\ttraining's rmse: 0.0846609\tvalid_1's rmse: 0.0883155\n",
      "[700]\ttraining's rmse: 0.08462\tvalid_1's rmse: 0.0883046\n",
      "[725]\ttraining's rmse: 0.0845832\tvalid_1's rmse: 0.0882955\n",
      "[750]\ttraining's rmse: 0.0845485\tvalid_1's rmse: 0.0882868\n",
      "[775]\ttraining's rmse: 0.0845195\tvalid_1's rmse: 0.0882777\n",
      "[800]\ttraining's rmse: 0.0844838\tvalid_1's rmse: 0.0882695\n",
      "[825]\ttraining's rmse: 0.0844527\tvalid_1's rmse: 0.0882614\n",
      "[850]\ttraining's rmse: 0.0844184\tvalid_1's rmse: 0.0882551\n",
      "[875]\ttraining's rmse: 0.0843901\tvalid_1's rmse: 0.0882484\n",
      "[900]\ttraining's rmse: 0.0843579\tvalid_1's rmse: 0.0882409\n",
      "[925]\ttraining's rmse: 0.0843296\tvalid_1's rmse: 0.0882344\n",
      "[950]\ttraining's rmse: 0.0843032\tvalid_1's rmse: 0.0882285\n",
      "[975]\ttraining's rmse: 0.0842795\tvalid_1's rmse: 0.088223\n",
      "[1000]\ttraining's rmse: 0.084256\tvalid_1's rmse: 0.088219\n",
      "[1025]\ttraining's rmse: 0.0842317\tvalid_1's rmse: 0.0882144\n",
      "[1050]\ttraining's rmse: 0.0842098\tvalid_1's rmse: 0.088209\n",
      "[1075]\ttraining's rmse: 0.0841888\tvalid_1's rmse: 0.0882059\n",
      "[1100]\ttraining's rmse: 0.0841697\tvalid_1's rmse: 0.0882021\n",
      "[1125]\ttraining's rmse: 0.0841485\tvalid_1's rmse: 0.0881978\n",
      "[1150]\ttraining's rmse: 0.0841284\tvalid_1's rmse: 0.0881949\n",
      "[1175]\ttraining's rmse: 0.0841123\tvalid_1's rmse: 0.0881925\n",
      "[1200]\ttraining's rmse: 0.0840954\tvalid_1's rmse: 0.0881889\n",
      "[1225]\ttraining's rmse: 0.0840806\tvalid_1's rmse: 0.0881858\n",
      "[1250]\ttraining's rmse: 0.0840649\tvalid_1's rmse: 0.0881828\n",
      "[1275]\ttraining's rmse: 0.0840455\tvalid_1's rmse: 0.0881801\n",
      "[1300]\ttraining's rmse: 0.0840341\tvalid_1's rmse: 0.0881784\n",
      "[1325]\ttraining's rmse: 0.084019\tvalid_1's rmse: 0.0881764\n",
      "[1350]\ttraining's rmse: 0.0840031\tvalid_1's rmse: 0.0881745\n",
      "[1375]\ttraining's rmse: 0.0839881\tvalid_1's rmse: 0.0881735\n",
      "[1400]\ttraining's rmse: 0.0839752\tvalid_1's rmse: 0.0881707\n",
      "[1425]\ttraining's rmse: 0.0839621\tvalid_1's rmse: 0.08817\n",
      "[1450]\ttraining's rmse: 0.0839491\tvalid_1's rmse: 0.0881696\n",
      "[1475]\ttraining's rmse: 0.0839383\tvalid_1's rmse: 0.088168\n",
      "[1500]\ttraining's rmse: 0.0839305\tvalid_1's rmse: 0.0881671\n",
      "[1525]\ttraining's rmse: 0.0839185\tvalid_1's rmse: 0.0881656\n",
      "[1550]\ttraining's rmse: 0.0839076\tvalid_1's rmse: 0.0881655\n",
      "[1575]\ttraining's rmse: 0.0838985\tvalid_1's rmse: 0.0881641\n",
      "[1600]\ttraining's rmse: 0.0838911\tvalid_1's rmse: 0.0881634\n",
      "[1625]\ttraining's rmse: 0.0838813\tvalid_1's rmse: 0.0881622\n",
      "[1650]\ttraining's rmse: 0.0838731\tvalid_1's rmse: 0.0881612\n",
      "[1675]\ttraining's rmse: 0.0838671\tvalid_1's rmse: 0.0881598\n",
      "[1700]\ttraining's rmse: 0.0838604\tvalid_1's rmse: 0.0881589\n",
      "[1725]\ttraining's rmse: 0.083852\tvalid_1's rmse: 0.0881575\n",
      "[1750]\ttraining's rmse: 0.0838441\tvalid_1's rmse: 0.0881569\n",
      "[1775]\ttraining's rmse: 0.0838382\tvalid_1's rmse: 0.0881568\n",
      "[1800]\ttraining's rmse: 0.0838321\tvalid_1's rmse: 0.0881558\n",
      "[1825]\ttraining's rmse: 0.0838249\tvalid_1's rmse: 0.0881553\n",
      "[1850]\ttraining's rmse: 0.0838195\tvalid_1's rmse: 0.088154\n",
      "[1875]\ttraining's rmse: 0.0838136\tvalid_1's rmse: 0.0881533\n",
      "[1900]\ttraining's rmse: 0.0838088\tvalid_1's rmse: 0.0881533\n",
      "[1925]\ttraining's rmse: 0.0838043\tvalid_1's rmse: 0.0881528\n",
      "[1950]\ttraining's rmse: 0.0838006\tvalid_1's rmse: 0.0881521\n",
      "[1975]\ttraining's rmse: 0.0837955\tvalid_1's rmse: 0.0881515\n",
      "[2000]\ttraining's rmse: 0.0837892\tvalid_1's rmse: 0.0881505\n",
      "[2025]\ttraining's rmse: 0.0837854\tvalid_1's rmse: 0.0881499\n",
      "[2050]\ttraining's rmse: 0.0837822\tvalid_1's rmse: 0.0881497\n",
      "[2075]\ttraining's rmse: 0.0837793\tvalid_1's rmse: 0.0881493\n",
      "[2100]\ttraining's rmse: 0.0837756\tvalid_1's rmse: 0.0881486\n",
      "[2125]\ttraining's rmse: 0.08377\tvalid_1's rmse: 0.0881487\n",
      "[2150]\ttraining's rmse: 0.0837646\tvalid_1's rmse: 0.0881483\n",
      "[2175]\ttraining's rmse: 0.0837608\tvalid_1's rmse: 0.0881483\n",
      "[2200]\ttraining's rmse: 0.0837581\tvalid_1's rmse: 0.088148\n",
      "[2225]\ttraining's rmse: 0.0837557\tvalid_1's rmse: 0.0881476\n",
      "[2250]\ttraining's rmse: 0.083753\tvalid_1's rmse: 0.0881478\n",
      "[2275]\ttraining's rmse: 0.0837502\tvalid_1's rmse: 0.0881479\n",
      "Early stopping, best iteration is:\n",
      "[2236]\ttraining's rmse: 0.0837545\tvalid_1's rmse: 0.0881475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0888646\tvalid_1's rmse: 0.084464\n",
      "[50]\ttraining's rmse: 0.0887453\tvalid_1's rmse: 0.084416\n",
      "[75]\ttraining's rmse: 0.0886184\tvalid_1's rmse: 0.0843678\n",
      "[100]\ttraining's rmse: 0.0885046\tvalid_1's rmse: 0.0843257\n",
      "[125]\ttraining's rmse: 0.0883853\tvalid_1's rmse: 0.0842829\n",
      "[150]\ttraining's rmse: 0.0882786\tvalid_1's rmse: 0.0842454\n",
      "[175]\ttraining's rmse: 0.0881873\tvalid_1's rmse: 0.0842134\n",
      "[200]\ttraining's rmse: 0.0880873\tvalid_1's rmse: 0.0841836\n",
      "[225]\ttraining's rmse: 0.0879893\tvalid_1's rmse: 0.0841527\n",
      "[250]\ttraining's rmse: 0.0879073\tvalid_1's rmse: 0.0841247\n",
      "[275]\ttraining's rmse: 0.0878308\tvalid_1's rmse: 0.0840993\n",
      "[300]\ttraining's rmse: 0.0877553\tvalid_1's rmse: 0.0840752\n",
      "[325]\ttraining's rmse: 0.0876779\tvalid_1's rmse: 0.084052\n",
      "[350]\ttraining's rmse: 0.0876047\tvalid_1's rmse: 0.0840305\n",
      "[375]\ttraining's rmse: 0.0875424\tvalid_1's rmse: 0.0840207\n",
      "[400]\ttraining's rmse: 0.0874767\tvalid_1's rmse: 0.0840103\n",
      "[425]\ttraining's rmse: 0.0874149\tvalid_1's rmse: 0.0839957\n",
      "[450]\ttraining's rmse: 0.0873597\tvalid_1's rmse: 0.0839815\n",
      "[475]\ttraining's rmse: 0.0873081\tvalid_1's rmse: 0.0839675\n",
      "[500]\ttraining's rmse: 0.0872645\tvalid_1's rmse: 0.0839597\n",
      "[525]\ttraining's rmse: 0.0872043\tvalid_1's rmse: 0.0839464\n",
      "[550]\ttraining's rmse: 0.087152\tvalid_1's rmse: 0.0839442\n",
      "[575]\ttraining's rmse: 0.0871035\tvalid_1's rmse: 0.0839336\n",
      "[600]\ttraining's rmse: 0.0870562\tvalid_1's rmse: 0.0839262\n",
      "[625]\ttraining's rmse: 0.0870183\tvalid_1's rmse: 0.0839228\n",
      "[650]\ttraining's rmse: 0.0869694\tvalid_1's rmse: 0.0839258\n",
      "[675]\ttraining's rmse: 0.0869217\tvalid_1's rmse: 0.0839274\n",
      "Early stopping, best iteration is:\n",
      "[632]\ttraining's rmse: 0.0870069\tvalid_1's rmse: 0.0839204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0845617\tvalid_1's rmse: 0.0875052\n",
      "[50]\ttraining's rmse: 0.0844332\tvalid_1's rmse: 0.0874505\n",
      "[75]\ttraining's rmse: 0.0843061\tvalid_1's rmse: 0.0873965\n",
      "[100]\ttraining's rmse: 0.0841865\tvalid_1's rmse: 0.0873509\n",
      "[125]\ttraining's rmse: 0.0840649\tvalid_1's rmse: 0.0873029\n",
      "[150]\ttraining's rmse: 0.0839571\tvalid_1's rmse: 0.0872609\n",
      "[175]\ttraining's rmse: 0.0838663\tvalid_1's rmse: 0.087223\n",
      "[200]\ttraining's rmse: 0.0837704\tvalid_1's rmse: 0.0871857\n",
      "[225]\ttraining's rmse: 0.0836728\tvalid_1's rmse: 0.0871504\n",
      "[250]\ttraining's rmse: 0.0835897\tvalid_1's rmse: 0.0871183\n",
      "[275]\ttraining's rmse: 0.0835117\tvalid_1's rmse: 0.0870877\n",
      "[300]\ttraining's rmse: 0.0834364\tvalid_1's rmse: 0.0870575\n",
      "[325]\ttraining's rmse: 0.0833628\tvalid_1's rmse: 0.0870318\n",
      "[350]\ttraining's rmse: 0.0832928\tvalid_1's rmse: 0.0870077\n",
      "[375]\ttraining's rmse: 0.0832317\tvalid_1's rmse: 0.0869864\n",
      "[400]\ttraining's rmse: 0.0831672\tvalid_1's rmse: 0.0869646\n",
      "[425]\ttraining's rmse: 0.0831087\tvalid_1's rmse: 0.0869438\n",
      "[450]\ttraining's rmse: 0.0830558\tvalid_1's rmse: 0.0869243\n",
      "[475]\ttraining's rmse: 0.083007\tvalid_1's rmse: 0.0869033\n",
      "[500]\ttraining's rmse: 0.0829629\tvalid_1's rmse: 0.0868848\n",
      "[525]\ttraining's rmse: 0.0829116\tvalid_1's rmse: 0.0868681\n",
      "[550]\ttraining's rmse: 0.0828642\tvalid_1's rmse: 0.0868533\n",
      "[575]\ttraining's rmse: 0.0828185\tvalid_1's rmse: 0.0868392\n",
      "[600]\ttraining's rmse: 0.0827746\tvalid_1's rmse: 0.086823\n",
      "[625]\ttraining's rmse: 0.0827392\tvalid_1's rmse: 0.0868102\n",
      "[650]\ttraining's rmse: 0.082697\tvalid_1's rmse: 0.0867978\n",
      "[675]\ttraining's rmse: 0.0826562\tvalid_1's rmse: 0.0867845\n",
      "[700]\ttraining's rmse: 0.0826188\tvalid_1's rmse: 0.0867721\n",
      "[725]\ttraining's rmse: 0.082586\tvalid_1's rmse: 0.0867618\n",
      "[750]\ttraining's rmse: 0.0825559\tvalid_1's rmse: 0.0867519\n",
      "[775]\ttraining's rmse: 0.0825288\tvalid_1's rmse: 0.0867417\n",
      "[800]\ttraining's rmse: 0.0824946\tvalid_1's rmse: 0.0867329\n",
      "[825]\ttraining's rmse: 0.0824657\tvalid_1's rmse: 0.086723\n",
      "[850]\ttraining's rmse: 0.0824343\tvalid_1's rmse: 0.0867147\n",
      "[875]\ttraining's rmse: 0.082409\tvalid_1's rmse: 0.086706\n",
      "[900]\ttraining's rmse: 0.0823796\tvalid_1's rmse: 0.0866983\n",
      "[925]\ttraining's rmse: 0.0823523\tvalid_1's rmse: 0.08669\n",
      "[950]\ttraining's rmse: 0.0823294\tvalid_1's rmse: 0.0866841\n",
      "[975]\ttraining's rmse: 0.0823072\tvalid_1's rmse: 0.0866772\n",
      "[1000]\ttraining's rmse: 0.0822821\tvalid_1's rmse: 0.0866696\n",
      "[1025]\ttraining's rmse: 0.0822586\tvalid_1's rmse: 0.0866636\n",
      "[1050]\ttraining's rmse: 0.0822379\tvalid_1's rmse: 0.0866568\n",
      "[1075]\ttraining's rmse: 0.0822186\tvalid_1's rmse: 0.0866532\n",
      "[1100]\ttraining's rmse: 0.082202\tvalid_1's rmse: 0.0866491\n",
      "[1125]\ttraining's rmse: 0.0821857\tvalid_1's rmse: 0.0866428\n",
      "[1150]\ttraining's rmse: 0.08217\tvalid_1's rmse: 0.0866385\n",
      "[1175]\ttraining's rmse: 0.0821518\tvalid_1's rmse: 0.0866345\n",
      "[1200]\ttraining's rmse: 0.0821353\tvalid_1's rmse: 0.0866304\n",
      "[1225]\ttraining's rmse: 0.0821195\tvalid_1's rmse: 0.0866261\n",
      "[1250]\ttraining's rmse: 0.082104\tvalid_1's rmse: 0.0866213\n",
      "[1275]\ttraining's rmse: 0.082084\tvalid_1's rmse: 0.0866168\n",
      "[1300]\ttraining's rmse: 0.0820732\tvalid_1's rmse: 0.086612\n",
      "[1325]\ttraining's rmse: 0.0820573\tvalid_1's rmse: 0.0866086\n",
      "[1350]\ttraining's rmse: 0.0820445\tvalid_1's rmse: 0.0866049\n",
      "[1375]\ttraining's rmse: 0.0820297\tvalid_1's rmse: 0.0866006\n",
      "[1400]\ttraining's rmse: 0.0820215\tvalid_1's rmse: 0.0865971\n",
      "[1425]\ttraining's rmse: 0.0820086\tvalid_1's rmse: 0.086593\n",
      "[1450]\ttraining's rmse: 0.0819957\tvalid_1's rmse: 0.0865902\n",
      "[1475]\ttraining's rmse: 0.0819846\tvalid_1's rmse: 0.0865876\n",
      "[1500]\ttraining's rmse: 0.0819757\tvalid_1's rmse: 0.0865843\n",
      "[1525]\ttraining's rmse: 0.0819644\tvalid_1's rmse: 0.0865817\n",
      "[1550]\ttraining's rmse: 0.0819548\tvalid_1's rmse: 0.0865792\n",
      "[1575]\ttraining's rmse: 0.0819473\tvalid_1's rmse: 0.0865756\n",
      "[1600]\ttraining's rmse: 0.0819403\tvalid_1's rmse: 0.0865734\n",
      "[1625]\ttraining's rmse: 0.0819331\tvalid_1's rmse: 0.0865714\n",
      "[1650]\ttraining's rmse: 0.0819262\tvalid_1's rmse: 0.0865683\n",
      "[1675]\ttraining's rmse: 0.0819203\tvalid_1's rmse: 0.0865668\n",
      "[1700]\ttraining's rmse: 0.0819147\tvalid_1's rmse: 0.0865644\n",
      "[1725]\ttraining's rmse: 0.0819071\tvalid_1's rmse: 0.0865634\n",
      "[1750]\ttraining's rmse: 0.0818981\tvalid_1's rmse: 0.0865609\n",
      "[1775]\ttraining's rmse: 0.0818913\tvalid_1's rmse: 0.0865597\n",
      "[1800]\ttraining's rmse: 0.0818848\tvalid_1's rmse: 0.0865577\n",
      "[1825]\ttraining's rmse: 0.0818802\tvalid_1's rmse: 0.0865561\n",
      "[1850]\ttraining's rmse: 0.0818755\tvalid_1's rmse: 0.086554\n",
      "[1875]\ttraining's rmse: 0.0818711\tvalid_1's rmse: 0.0865526\n",
      "[1900]\ttraining's rmse: 0.0818663\tvalid_1's rmse: 0.0865515\n",
      "[1925]\ttraining's rmse: 0.0818613\tvalid_1's rmse: 0.0865503\n",
      "[1950]\ttraining's rmse: 0.0818581\tvalid_1's rmse: 0.0865493\n",
      "[1975]\ttraining's rmse: 0.0818543\tvalid_1's rmse: 0.0865481\n",
      "[2000]\ttraining's rmse: 0.081851\tvalid_1's rmse: 0.0865472\n",
      "[2025]\ttraining's rmse: 0.081848\tvalid_1's rmse: 0.086546\n",
      "[2050]\ttraining's rmse: 0.0818439\tvalid_1's rmse: 0.0865444\n",
      "[2075]\ttraining's rmse: 0.0818407\tvalid_1's rmse: 0.0865438\n",
      "[2100]\ttraining's rmse: 0.0818363\tvalid_1's rmse: 0.0865426\n",
      "[2125]\ttraining's rmse: 0.0818328\tvalid_1's rmse: 0.0865414\n",
      "[2150]\ttraining's rmse: 0.08183\tvalid_1's rmse: 0.0865402\n",
      "[2175]\ttraining's rmse: 0.0818258\tvalid_1's rmse: 0.0865394\n",
      "[2200]\ttraining's rmse: 0.0818222\tvalid_1's rmse: 0.0865374\n",
      "[2225]\ttraining's rmse: 0.0818198\tvalid_1's rmse: 0.086536\n",
      "[2250]\ttraining's rmse: 0.0818169\tvalid_1's rmse: 0.0865346\n",
      "[2275]\ttraining's rmse: 0.0818142\tvalid_1's rmse: 0.086534\n",
      "[2300]\ttraining's rmse: 0.0818124\tvalid_1's rmse: 0.086533\n",
      "[2325]\ttraining's rmse: 0.0818074\tvalid_1's rmse: 0.0865315\n",
      "[2350]\ttraining's rmse: 0.0818048\tvalid_1's rmse: 0.0865313\n",
      "[2375]\ttraining's rmse: 0.0818018\tvalid_1's rmse: 0.0865306\n",
      "[2400]\ttraining's rmse: 0.0817976\tvalid_1's rmse: 0.0865297\n",
      "[2425]\ttraining's rmse: 0.0817955\tvalid_1's rmse: 0.0865282\n",
      "[2450]\ttraining's rmse: 0.0817939\tvalid_1's rmse: 0.086528\n",
      "[2475]\ttraining's rmse: 0.081791\tvalid_1's rmse: 0.0865282\n",
      "[2500]\ttraining's rmse: 0.0817894\tvalid_1's rmse: 0.0865273\n",
      "[2525]\ttraining's rmse: 0.0817875\tvalid_1's rmse: 0.0865265\n",
      "[2550]\ttraining's rmse: 0.0817857\tvalid_1's rmse: 0.0865264\n",
      "[2575]\ttraining's rmse: 0.081784\tvalid_1's rmse: 0.0865259\n",
      "[2600]\ttraining's rmse: 0.0817822\tvalid_1's rmse: 0.086526\n",
      "[2625]\ttraining's rmse: 0.0817798\tvalid_1's rmse: 0.0865243\n",
      "[2650]\ttraining's rmse: 0.0817784\tvalid_1's rmse: 0.0865238\n",
      "[2675]\ttraining's rmse: 0.0817771\tvalid_1's rmse: 0.0865231\n",
      "[2700]\ttraining's rmse: 0.0817754\tvalid_1's rmse: 0.0865225\n",
      "[2725]\ttraining's rmse: 0.0817736\tvalid_1's rmse: 0.0865227\n",
      "[2750]\ttraining's rmse: 0.0817714\tvalid_1's rmse: 0.0865228\n",
      "Early stopping, best iteration is:\n",
      "[2700]\ttraining's rmse: 0.0817754\tvalid_1's rmse: 0.0865225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0848854\tvalid_1's rmse: 0.0868737\n",
      "[50]\ttraining's rmse: 0.0847612\tvalid_1's rmse: 0.0868171\n",
      "[75]\ttraining's rmse: 0.0846385\tvalid_1's rmse: 0.086761\n",
      "[100]\ttraining's rmse: 0.0845256\tvalid_1's rmse: 0.0867131\n",
      "[125]\ttraining's rmse: 0.0844101\tvalid_1's rmse: 0.0866653\n",
      "[150]\ttraining's rmse: 0.0843025\tvalid_1's rmse: 0.0866213\n",
      "[175]\ttraining's rmse: 0.0842158\tvalid_1's rmse: 0.086585\n",
      "[200]\ttraining's rmse: 0.084118\tvalid_1's rmse: 0.0865478\n",
      "[225]\ttraining's rmse: 0.0840284\tvalid_1's rmse: 0.0865134\n",
      "[250]\ttraining's rmse: 0.0839499\tvalid_1's rmse: 0.0864827\n",
      "[275]\ttraining's rmse: 0.0838783\tvalid_1's rmse: 0.086454\n",
      "[300]\ttraining's rmse: 0.0838067\tvalid_1's rmse: 0.0864259\n",
      "[325]\ttraining's rmse: 0.0837331\tvalid_1's rmse: 0.086399\n",
      "[350]\ttraining's rmse: 0.0836602\tvalid_1's rmse: 0.0863752\n",
      "[375]\ttraining's rmse: 0.0836027\tvalid_1's rmse: 0.0863543\n",
      "[400]\ttraining's rmse: 0.0835415\tvalid_1's rmse: 0.0863338\n",
      "[425]\ttraining's rmse: 0.083484\tvalid_1's rmse: 0.086315\n",
      "[450]\ttraining's rmse: 0.0834299\tvalid_1's rmse: 0.0862962\n",
      "[475]\ttraining's rmse: 0.0833817\tvalid_1's rmse: 0.08628\n",
      "[500]\ttraining's rmse: 0.0833385\tvalid_1's rmse: 0.0862638\n",
      "[525]\ttraining's rmse: 0.0832835\tvalid_1's rmse: 0.0862473\n",
      "[550]\ttraining's rmse: 0.0832294\tvalid_1's rmse: 0.0862308\n",
      "[575]\ttraining's rmse: 0.083183\tvalid_1's rmse: 0.0862178\n",
      "[600]\ttraining's rmse: 0.0831392\tvalid_1's rmse: 0.0862054\n",
      "[625]\ttraining's rmse: 0.0831035\tvalid_1's rmse: 0.0861933\n",
      "[650]\ttraining's rmse: 0.0830569\tvalid_1's rmse: 0.0861805\n",
      "[675]\ttraining's rmse: 0.0830128\tvalid_1's rmse: 0.0861698\n",
      "[700]\ttraining's rmse: 0.0829738\tvalid_1's rmse: 0.0861592\n",
      "[725]\ttraining's rmse: 0.0829383\tvalid_1's rmse: 0.0861496\n",
      "[750]\ttraining's rmse: 0.0829039\tvalid_1's rmse: 0.0861406\n",
      "[775]\ttraining's rmse: 0.0828748\tvalid_1's rmse: 0.0861309\n",
      "[800]\ttraining's rmse: 0.0828388\tvalid_1's rmse: 0.086124\n",
      "[825]\ttraining's rmse: 0.0828081\tvalid_1's rmse: 0.0861164\n",
      "[850]\ttraining's rmse: 0.0827778\tvalid_1's rmse: 0.0861095\n",
      "[875]\ttraining's rmse: 0.0827503\tvalid_1's rmse: 0.0861025\n",
      "[900]\ttraining's rmse: 0.0827207\tvalid_1's rmse: 0.0860949\n",
      "[925]\ttraining's rmse: 0.0826939\tvalid_1's rmse: 0.0860891\n",
      "[950]\ttraining's rmse: 0.0826671\tvalid_1's rmse: 0.0860836\n",
      "[975]\ttraining's rmse: 0.082643\tvalid_1's rmse: 0.0860778\n",
      "[1000]\ttraining's rmse: 0.0826201\tvalid_1's rmse: 0.0860738\n",
      "[1025]\ttraining's rmse: 0.0825942\tvalid_1's rmse: 0.0860692\n",
      "[1050]\ttraining's rmse: 0.0825744\tvalid_1's rmse: 0.086064\n",
      "[1075]\ttraining's rmse: 0.0825519\tvalid_1's rmse: 0.0860604\n",
      "[1100]\ttraining's rmse: 0.0825342\tvalid_1's rmse: 0.0860562\n",
      "[1125]\ttraining's rmse: 0.0825152\tvalid_1's rmse: 0.0860522\n",
      "[1150]\ttraining's rmse: 0.0824973\tvalid_1's rmse: 0.0860493\n",
      "[1175]\ttraining's rmse: 0.0824794\tvalid_1's rmse: 0.0860465\n",
      "[1200]\ttraining's rmse: 0.082463\tvalid_1's rmse: 0.0860431\n",
      "[1225]\ttraining's rmse: 0.0824466\tvalid_1's rmse: 0.0860402\n",
      "[1250]\ttraining's rmse: 0.0824328\tvalid_1's rmse: 0.0860375\n",
      "[1275]\ttraining's rmse: 0.0824151\tvalid_1's rmse: 0.0860355\n",
      "[1300]\ttraining's rmse: 0.0824012\tvalid_1's rmse: 0.0860332\n",
      "[1325]\ttraining's rmse: 0.0823888\tvalid_1's rmse: 0.0860314\n",
      "[1350]\ttraining's rmse: 0.0823749\tvalid_1's rmse: 0.0860291\n",
      "[1375]\ttraining's rmse: 0.0823637\tvalid_1's rmse: 0.0860275\n",
      "[1400]\ttraining's rmse: 0.0823539\tvalid_1's rmse: 0.0860256\n",
      "[1425]\ttraining's rmse: 0.0823404\tvalid_1's rmse: 0.086024\n",
      "[1450]\ttraining's rmse: 0.0823267\tvalid_1's rmse: 0.0860228\n",
      "[1475]\ttraining's rmse: 0.082316\tvalid_1's rmse: 0.0860211\n",
      "[1500]\ttraining's rmse: 0.0823071\tvalid_1's rmse: 0.0860203\n",
      "[1525]\ttraining's rmse: 0.0822976\tvalid_1's rmse: 0.0860195\n",
      "[1550]\ttraining's rmse: 0.0822894\tvalid_1's rmse: 0.0860185\n",
      "[1575]\ttraining's rmse: 0.0822803\tvalid_1's rmse: 0.0860173\n",
      "[1600]\ttraining's rmse: 0.0822724\tvalid_1's rmse: 0.0860163\n",
      "[1625]\ttraining's rmse: 0.0822647\tvalid_1's rmse: 0.0860154\n",
      "[1650]\ttraining's rmse: 0.0822565\tvalid_1's rmse: 0.0860143\n",
      "[1675]\ttraining's rmse: 0.0822501\tvalid_1's rmse: 0.086013\n",
      "[1700]\ttraining's rmse: 0.0822436\tvalid_1's rmse: 0.0860121\n",
      "[1725]\ttraining's rmse: 0.0822372\tvalid_1's rmse: 0.0860107\n",
      "[1750]\ttraining's rmse: 0.0822293\tvalid_1's rmse: 0.0860096\n",
      "[1775]\ttraining's rmse: 0.0822223\tvalid_1's rmse: 0.0860084\n",
      "[1800]\ttraining's rmse: 0.0822163\tvalid_1's rmse: 0.0860081\n",
      "[1825]\ttraining's rmse: 0.0822091\tvalid_1's rmse: 0.0860073\n",
      "[1850]\ttraining's rmse: 0.0822042\tvalid_1's rmse: 0.0860068\n",
      "[1875]\ttraining's rmse: 0.0821991\tvalid_1's rmse: 0.0860064\n",
      "[1900]\ttraining's rmse: 0.0821925\tvalid_1's rmse: 0.0860061\n",
      "[1925]\ttraining's rmse: 0.0821877\tvalid_1's rmse: 0.0860055\n",
      "[1950]\ttraining's rmse: 0.0821846\tvalid_1's rmse: 0.0860048\n",
      "[1975]\ttraining's rmse: 0.0821791\tvalid_1's rmse: 0.0860036\n",
      "[2000]\ttraining's rmse: 0.0821745\tvalid_1's rmse: 0.0860026\n",
      "[2025]\ttraining's rmse: 0.0821717\tvalid_1's rmse: 0.0860022\n",
      "[2050]\ttraining's rmse: 0.0821674\tvalid_1's rmse: 0.0860021\n",
      "[2075]\ttraining's rmse: 0.0821645\tvalid_1's rmse: 0.086002\n",
      "[2100]\ttraining's rmse: 0.0821612\tvalid_1's rmse: 0.0860014\n",
      "[2125]\ttraining's rmse: 0.0821585\tvalid_1's rmse: 0.0860014\n",
      "[2150]\ttraining's rmse: 0.0821554\tvalid_1's rmse: 0.0860012\n",
      "[2175]\ttraining's rmse: 0.0821531\tvalid_1's rmse: 0.0860014\n",
      "[2200]\ttraining's rmse: 0.0821498\tvalid_1's rmse: 0.0860012\n",
      "[2225]\ttraining's rmse: 0.0821468\tvalid_1's rmse: 0.0860011\n",
      "[2250]\ttraining's rmse: 0.0821423\tvalid_1's rmse: 0.086001\n",
      "[2275]\ttraining's rmse: 0.082137\tvalid_1's rmse: 0.0860008\n",
      "[2300]\ttraining's rmse: 0.0821342\tvalid_1's rmse: 0.0860005\n",
      "[2325]\ttraining's rmse: 0.0821305\tvalid_1's rmse: 0.0860003\n",
      "[2350]\ttraining's rmse: 0.082128\tvalid_1's rmse: 0.086\n",
      "[2375]\ttraining's rmse: 0.0821242\tvalid_1's rmse: 0.0859996\n",
      "[2400]\ttraining's rmse: 0.082121\tvalid_1's rmse: 0.0860001\n",
      "Early stopping, best iteration is:\n",
      "[2363]\ttraining's rmse: 0.0821259\tvalid_1's rmse: 0.0859995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0870695\tvalid_1's rmse: 0.0824349\n",
      "[50]\ttraining's rmse: 0.0869535\tvalid_1's rmse: 0.0823853\n",
      "[75]\ttraining's rmse: 0.0868327\tvalid_1's rmse: 0.0823371\n",
      "[100]\ttraining's rmse: 0.0867242\tvalid_1's rmse: 0.0822938\n",
      "[125]\ttraining's rmse: 0.0866139\tvalid_1's rmse: 0.0822517\n",
      "[150]\ttraining's rmse: 0.0865102\tvalid_1's rmse: 0.0822125\n",
      "[175]\ttraining's rmse: 0.0864278\tvalid_1's rmse: 0.0821824\n",
      "[200]\ttraining's rmse: 0.0863354\tvalid_1's rmse: 0.0821499\n",
      "[225]\ttraining's rmse: 0.0862484\tvalid_1's rmse: 0.0821182\n",
      "[250]\ttraining's rmse: 0.0861729\tvalid_1's rmse: 0.0820918\n",
      "[275]\ttraining's rmse: 0.0861067\tvalid_1's rmse: 0.0820672\n",
      "[300]\ttraining's rmse: 0.0860378\tvalid_1's rmse: 0.0820428\n",
      "[325]\ttraining's rmse: 0.0859712\tvalid_1's rmse: 0.0820211\n",
      "[350]\ttraining's rmse: 0.0859038\tvalid_1's rmse: 0.082\n",
      "[375]\ttraining's rmse: 0.0858494\tvalid_1's rmse: 0.0819814\n",
      "[400]\ttraining's rmse: 0.0857898\tvalid_1's rmse: 0.0819714\n",
      "[425]\ttraining's rmse: 0.0857349\tvalid_1's rmse: 0.0819576\n",
      "[450]\ttraining's rmse: 0.0856823\tvalid_1's rmse: 0.0819407\n",
      "[475]\ttraining's rmse: 0.0856354\tvalid_1's rmse: 0.0819313\n",
      "[500]\ttraining's rmse: 0.0855949\tvalid_1's rmse: 0.0819179\n",
      "[525]\ttraining's rmse: 0.0855412\tvalid_1's rmse: 0.0819042\n",
      "[550]\ttraining's rmse: 0.0854932\tvalid_1's rmse: 0.0818907\n",
      "[575]\ttraining's rmse: 0.0854476\tvalid_1's rmse: 0.0818788\n",
      "[600]\ttraining's rmse: 0.0854049\tvalid_1's rmse: 0.0818706\n",
      "[625]\ttraining's rmse: 0.085371\tvalid_1's rmse: 0.0818622\n",
      "[650]\ttraining's rmse: 0.0853278\tvalid_1's rmse: 0.0818573\n",
      "[675]\ttraining's rmse: 0.0852837\tvalid_1's rmse: 0.0818485\n",
      "[700]\ttraining's rmse: 0.0852462\tvalid_1's rmse: 0.0818442\n",
      "[725]\ttraining's rmse: 0.0852105\tvalid_1's rmse: 0.0818418\n",
      "[750]\ttraining's rmse: 0.0851751\tvalid_1's rmse: 0.0818473\n",
      "[775]\ttraining's rmse: 0.0851451\tvalid_1's rmse: 0.0818501\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0851951\tvalid_1's rmse: 0.0818379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876844\tvalid_1's rmse: 0.0897727\n",
      "[50]\ttraining's rmse: 0.0875371\tvalid_1's rmse: 0.0897197\n",
      "[75]\ttraining's rmse: 0.087389\tvalid_1's rmse: 0.0896697\n",
      "[100]\ttraining's rmse: 0.0872505\tvalid_1's rmse: 0.0896234\n",
      "[125]\ttraining's rmse: 0.0871177\tvalid_1's rmse: 0.0895784\n",
      "[150]\ttraining's rmse: 0.0869925\tvalid_1's rmse: 0.0895379\n",
      "[175]\ttraining's rmse: 0.0868896\tvalid_1's rmse: 0.0895027\n",
      "[200]\ttraining's rmse: 0.0867813\tvalid_1's rmse: 0.0894662\n",
      "[225]\ttraining's rmse: 0.0866724\tvalid_1's rmse: 0.0894321\n",
      "[250]\ttraining's rmse: 0.0865817\tvalid_1's rmse: 0.0894005\n",
      "[275]\ttraining's rmse: 0.0864996\tvalid_1's rmse: 0.0893753\n",
      "[300]\ttraining's rmse: 0.0864178\tvalid_1's rmse: 0.0893497\n",
      "[325]\ttraining's rmse: 0.0863351\tvalid_1's rmse: 0.0893253\n",
      "[350]\ttraining's rmse: 0.0862546\tvalid_1's rmse: 0.0893028\n",
      "[375]\ttraining's rmse: 0.0861886\tvalid_1's rmse: 0.0892831\n",
      "[400]\ttraining's rmse: 0.0861137\tvalid_1's rmse: 0.0892616\n",
      "[425]\ttraining's rmse: 0.0860497\tvalid_1's rmse: 0.0892423\n",
      "[450]\ttraining's rmse: 0.0859875\tvalid_1's rmse: 0.0892227\n",
      "[475]\ttraining's rmse: 0.0859317\tvalid_1's rmse: 0.0892038\n",
      "[500]\ttraining's rmse: 0.0858827\tvalid_1's rmse: 0.0891865\n",
      "[525]\ttraining's rmse: 0.0858203\tvalid_1's rmse: 0.0891708\n",
      "[550]\ttraining's rmse: 0.0857659\tvalid_1's rmse: 0.0891556\n",
      "[575]\ttraining's rmse: 0.0857149\tvalid_1's rmse: 0.0891421\n",
      "[600]\ttraining's rmse: 0.0856661\tvalid_1's rmse: 0.0891289\n",
      "[625]\ttraining's rmse: 0.085624\tvalid_1's rmse: 0.0891164\n",
      "[650]\ttraining's rmse: 0.0855744\tvalid_1's rmse: 0.0891023\n",
      "[675]\ttraining's rmse: 0.0855254\tvalid_1's rmse: 0.0890898\n",
      "[700]\ttraining's rmse: 0.0854843\tvalid_1's rmse: 0.0890773\n",
      "[725]\ttraining's rmse: 0.0854456\tvalid_1's rmse: 0.089067\n",
      "[750]\ttraining's rmse: 0.0854061\tvalid_1's rmse: 0.0890558\n",
      "[775]\ttraining's rmse: 0.0853733\tvalid_1's rmse: 0.0890451\n",
      "[800]\ttraining's rmse: 0.0853351\tvalid_1's rmse: 0.0890351\n",
      "[825]\ttraining's rmse: 0.0853005\tvalid_1's rmse: 0.0890261\n",
      "[850]\ttraining's rmse: 0.0852669\tvalid_1's rmse: 0.0890186\n",
      "[875]\ttraining's rmse: 0.0852351\tvalid_1's rmse: 0.0890087\n",
      "[900]\ttraining's rmse: 0.0852028\tvalid_1's rmse: 0.089001\n",
      "[925]\ttraining's rmse: 0.0851744\tvalid_1's rmse: 0.0889936\n",
      "[950]\ttraining's rmse: 0.0851461\tvalid_1's rmse: 0.0889862\n",
      "[975]\ttraining's rmse: 0.0851204\tvalid_1's rmse: 0.0889793\n",
      "[1000]\ttraining's rmse: 0.0850931\tvalid_1's rmse: 0.0889738\n",
      "[1025]\ttraining's rmse: 0.0850634\tvalid_1's rmse: 0.0889671\n",
      "[1050]\ttraining's rmse: 0.0850429\tvalid_1's rmse: 0.0889608\n",
      "[1075]\ttraining's rmse: 0.0850218\tvalid_1's rmse: 0.0889571\n",
      "[1100]\ttraining's rmse: 0.085\tvalid_1's rmse: 0.0889521\n",
      "[1125]\ttraining's rmse: 0.0849774\tvalid_1's rmse: 0.0889457\n",
      "[1150]\ttraining's rmse: 0.0849557\tvalid_1's rmse: 0.0889404\n",
      "[1175]\ttraining's rmse: 0.084939\tvalid_1's rmse: 0.0889367\n",
      "[1200]\ttraining's rmse: 0.0849186\tvalid_1's rmse: 0.0889315\n",
      "[1225]\ttraining's rmse: 0.0849003\tvalid_1's rmse: 0.0889279\n",
      "[1250]\ttraining's rmse: 0.0848816\tvalid_1's rmse: 0.0889235\n",
      "[1275]\ttraining's rmse: 0.0848638\tvalid_1's rmse: 0.0889203\n",
      "[1300]\ttraining's rmse: 0.0848473\tvalid_1's rmse: 0.0889149\n",
      "[1325]\ttraining's rmse: 0.0848326\tvalid_1's rmse: 0.088911\n",
      "[1350]\ttraining's rmse: 0.0848162\tvalid_1's rmse: 0.0889069\n",
      "[1375]\ttraining's rmse: 0.0848021\tvalid_1's rmse: 0.0889038\n",
      "[1400]\ttraining's rmse: 0.08479\tvalid_1's rmse: 0.0888996\n",
      "[1425]\ttraining's rmse: 0.084776\tvalid_1's rmse: 0.0888984\n",
      "[1450]\ttraining's rmse: 0.0847628\tvalid_1's rmse: 0.0888962\n",
      "[1475]\ttraining's rmse: 0.0847511\tvalid_1's rmse: 0.0888928\n",
      "[1500]\ttraining's rmse: 0.0847383\tvalid_1's rmse: 0.0888898\n",
      "[1525]\ttraining's rmse: 0.0847274\tvalid_1's rmse: 0.0888867\n",
      "[1550]\ttraining's rmse: 0.0847163\tvalid_1's rmse: 0.0888839\n",
      "[1575]\ttraining's rmse: 0.0847076\tvalid_1's rmse: 0.0888805\n",
      "[1600]\ttraining's rmse: 0.0847016\tvalid_1's rmse: 0.0888793\n",
      "[1625]\ttraining's rmse: 0.0846914\tvalid_1's rmse: 0.0888744\n",
      "[1650]\ttraining's rmse: 0.0846824\tvalid_1's rmse: 0.0888712\n",
      "[1675]\ttraining's rmse: 0.0846748\tvalid_1's rmse: 0.0888687\n",
      "[1700]\ttraining's rmse: 0.0846671\tvalid_1's rmse: 0.0888659\n",
      "[1725]\ttraining's rmse: 0.0846595\tvalid_1's rmse: 0.0888636\n",
      "[1750]\ttraining's rmse: 0.0846523\tvalid_1's rmse: 0.0888617\n",
      "[1775]\ttraining's rmse: 0.0846454\tvalid_1's rmse: 0.0888594\n",
      "[1800]\ttraining's rmse: 0.0846402\tvalid_1's rmse: 0.0888564\n",
      "[1825]\ttraining's rmse: 0.0846333\tvalid_1's rmse: 0.0888552\n",
      "[1850]\ttraining's rmse: 0.0846257\tvalid_1's rmse: 0.0888533\n",
      "[1875]\ttraining's rmse: 0.0846203\tvalid_1's rmse: 0.0888532\n",
      "[1900]\ttraining's rmse: 0.0846151\tvalid_1's rmse: 0.0888517\n",
      "[1925]\ttraining's rmse: 0.0846088\tvalid_1's rmse: 0.0888496\n",
      "[1950]\ttraining's rmse: 0.0846053\tvalid_1's rmse: 0.0888484\n",
      "[1975]\ttraining's rmse: 0.0845998\tvalid_1's rmse: 0.0888474\n",
      "[2000]\ttraining's rmse: 0.0845953\tvalid_1's rmse: 0.0888465\n",
      "[2025]\ttraining's rmse: 0.0845913\tvalid_1's rmse: 0.0888455\n",
      "[2050]\ttraining's rmse: 0.0845872\tvalid_1's rmse: 0.0888449\n",
      "[2075]\ttraining's rmse: 0.0845837\tvalid_1's rmse: 0.0888436\n",
      "[2100]\ttraining's rmse: 0.0845804\tvalid_1's rmse: 0.0888429\n",
      "[2125]\ttraining's rmse: 0.084577\tvalid_1's rmse: 0.0888424\n",
      "[2150]\ttraining's rmse: 0.084573\tvalid_1's rmse: 0.0888412\n",
      "[2175]\ttraining's rmse: 0.0845699\tvalid_1's rmse: 0.0888392\n",
      "[2200]\ttraining's rmse: 0.0845668\tvalid_1's rmse: 0.0888381\n",
      "[2225]\ttraining's rmse: 0.0845636\tvalid_1's rmse: 0.088837\n",
      "[2250]\ttraining's rmse: 0.0845586\tvalid_1's rmse: 0.0888356\n",
      "[2275]\ttraining's rmse: 0.0845551\tvalid_1's rmse: 0.0888354\n",
      "[2300]\ttraining's rmse: 0.084553\tvalid_1's rmse: 0.088834\n",
      "[2325]\ttraining's rmse: 0.0845491\tvalid_1's rmse: 0.0888338\n",
      "[2350]\ttraining's rmse: 0.0845468\tvalid_1's rmse: 0.0888325\n",
      "[2375]\ttraining's rmse: 0.0845446\tvalid_1's rmse: 0.0888316\n",
      "[2400]\ttraining's rmse: 0.0845426\tvalid_1's rmse: 0.0888305\n",
      "[2425]\ttraining's rmse: 0.08454\tvalid_1's rmse: 0.0888295\n",
      "[2450]\ttraining's rmse: 0.0845374\tvalid_1's rmse: 0.0888286\n",
      "[2475]\ttraining's rmse: 0.0845347\tvalid_1's rmse: 0.0888286\n",
      "[2500]\ttraining's rmse: 0.0845331\tvalid_1's rmse: 0.0888284\n",
      "[2525]\ttraining's rmse: 0.0845295\tvalid_1's rmse: 0.0888283\n",
      "Early stopping, best iteration is:\n",
      "[2494]\ttraining's rmse: 0.0845334\tvalid_1's rmse: 0.0888282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876299\tvalid_1's rmse: 0.0899116\n",
      "[50]\ttraining's rmse: 0.0875031\tvalid_1's rmse: 0.0898574\n",
      "[75]\ttraining's rmse: 0.0873729\tvalid_1's rmse: 0.0898034\n",
      "[100]\ttraining's rmse: 0.0872577\tvalid_1's rmse: 0.0897578\n",
      "[125]\ttraining's rmse: 0.0871343\tvalid_1's rmse: 0.0897099\n",
      "[150]\ttraining's rmse: 0.0870212\tvalid_1's rmse: 0.0896668\n",
      "[175]\ttraining's rmse: 0.086928\tvalid_1's rmse: 0.089631\n",
      "[200]\ttraining's rmse: 0.0868265\tvalid_1's rmse: 0.0895927\n",
      "[225]\ttraining's rmse: 0.0867278\tvalid_1's rmse: 0.0895582\n",
      "[250]\ttraining's rmse: 0.0866433\tvalid_1's rmse: 0.0895269\n",
      "[275]\ttraining's rmse: 0.0865657\tvalid_1's rmse: 0.0894984\n",
      "[300]\ttraining's rmse: 0.0864865\tvalid_1's rmse: 0.0894706\n",
      "[325]\ttraining's rmse: 0.086407\tvalid_1's rmse: 0.0894427\n",
      "[350]\ttraining's rmse: 0.0863313\tvalid_1's rmse: 0.0894178\n",
      "[375]\ttraining's rmse: 0.0862683\tvalid_1's rmse: 0.0893955\n",
      "[400]\ttraining's rmse: 0.0862027\tvalid_1's rmse: 0.0893754\n",
      "[425]\ttraining's rmse: 0.0861404\tvalid_1's rmse: 0.0893546\n",
      "[450]\ttraining's rmse: 0.0860834\tvalid_1's rmse: 0.0893356\n",
      "[475]\ttraining's rmse: 0.0860299\tvalid_1's rmse: 0.0893177\n",
      "[500]\ttraining's rmse: 0.0859836\tvalid_1's rmse: 0.0893021\n",
      "[525]\ttraining's rmse: 0.0859256\tvalid_1's rmse: 0.0892867\n",
      "[550]\ttraining's rmse: 0.085874\tvalid_1's rmse: 0.0892726\n",
      "[575]\ttraining's rmse: 0.0858267\tvalid_1's rmse: 0.089259\n",
      "[600]\ttraining's rmse: 0.0857821\tvalid_1's rmse: 0.0892467\n",
      "[625]\ttraining's rmse: 0.0857451\tvalid_1's rmse: 0.0892343\n",
      "[650]\ttraining's rmse: 0.0856974\tvalid_1's rmse: 0.0892214\n",
      "[675]\ttraining's rmse: 0.0856527\tvalid_1's rmse: 0.0892103\n",
      "[700]\ttraining's rmse: 0.0856123\tvalid_1's rmse: 0.0892\n",
      "[725]\ttraining's rmse: 0.0855738\tvalid_1's rmse: 0.0891906\n",
      "[750]\ttraining's rmse: 0.085539\tvalid_1's rmse: 0.089181\n",
      "[775]\ttraining's rmse: 0.0855085\tvalid_1's rmse: 0.089172\n",
      "[800]\ttraining's rmse: 0.085468\tvalid_1's rmse: 0.0891645\n",
      "[825]\ttraining's rmse: 0.0854339\tvalid_1's rmse: 0.0891552\n",
      "[850]\ttraining's rmse: 0.0854019\tvalid_1's rmse: 0.0891489\n",
      "[875]\ttraining's rmse: 0.0853718\tvalid_1's rmse: 0.0891423\n",
      "[900]\ttraining's rmse: 0.0853397\tvalid_1's rmse: 0.0891349\n",
      "[925]\ttraining's rmse: 0.0853083\tvalid_1's rmse: 0.0891291\n",
      "[950]\ttraining's rmse: 0.0852805\tvalid_1's rmse: 0.0891229\n",
      "[975]\ttraining's rmse: 0.0852549\tvalid_1's rmse: 0.0891177\n",
      "[1000]\ttraining's rmse: 0.0852325\tvalid_1's rmse: 0.0891131\n",
      "[1025]\ttraining's rmse: 0.0852049\tvalid_1's rmse: 0.0891095\n",
      "[1050]\ttraining's rmse: 0.0851813\tvalid_1's rmse: 0.0891036\n",
      "[1075]\ttraining's rmse: 0.0851572\tvalid_1's rmse: 0.0891003\n",
      "[1100]\ttraining's rmse: 0.0851377\tvalid_1's rmse: 0.0890955\n",
      "[1125]\ttraining's rmse: 0.0851166\tvalid_1's rmse: 0.0890923\n",
      "[1150]\ttraining's rmse: 0.0850965\tvalid_1's rmse: 0.0890885\n",
      "[1175]\ttraining's rmse: 0.0850783\tvalid_1's rmse: 0.0890861\n",
      "[1200]\ttraining's rmse: 0.0850586\tvalid_1's rmse: 0.0890825\n",
      "[1225]\ttraining's rmse: 0.0850418\tvalid_1's rmse: 0.0890798\n",
      "[1250]\ttraining's rmse: 0.0850276\tvalid_1's rmse: 0.0890777\n",
      "[1275]\ttraining's rmse: 0.085008\tvalid_1's rmse: 0.0890755\n",
      "[1300]\ttraining's rmse: 0.0849929\tvalid_1's rmse: 0.0890723\n",
      "[1325]\ttraining's rmse: 0.0849787\tvalid_1's rmse: 0.0890707\n",
      "[1350]\ttraining's rmse: 0.0849644\tvalid_1's rmse: 0.0890691\n",
      "[1375]\ttraining's rmse: 0.0849485\tvalid_1's rmse: 0.0890681\n",
      "[1400]\ttraining's rmse: 0.0849374\tvalid_1's rmse: 0.0890665\n",
      "[1425]\ttraining's rmse: 0.0849228\tvalid_1's rmse: 0.0890654\n",
      "[1450]\ttraining's rmse: 0.0849107\tvalid_1's rmse: 0.0890638\n",
      "[1475]\ttraining's rmse: 0.0848973\tvalid_1's rmse: 0.089062\n",
      "[1500]\ttraining's rmse: 0.0848863\tvalid_1's rmse: 0.0890604\n",
      "[1525]\ttraining's rmse: 0.0848759\tvalid_1's rmse: 0.0890593\n",
      "[1550]\ttraining's rmse: 0.084867\tvalid_1's rmse: 0.0890588\n",
      "[1575]\ttraining's rmse: 0.0848568\tvalid_1's rmse: 0.0890575\n",
      "[1600]\ttraining's rmse: 0.0848491\tvalid_1's rmse: 0.0890569\n",
      "[1625]\ttraining's rmse: 0.0848371\tvalid_1's rmse: 0.0890551\n",
      "[1650]\ttraining's rmse: 0.0848297\tvalid_1's rmse: 0.0890544\n",
      "[1675]\ttraining's rmse: 0.0848217\tvalid_1's rmse: 0.0890537\n",
      "[1700]\ttraining's rmse: 0.0848166\tvalid_1's rmse: 0.0890529\n",
      "[1725]\ttraining's rmse: 0.0848092\tvalid_1's rmse: 0.0890521\n",
      "[1750]\ttraining's rmse: 0.0848003\tvalid_1's rmse: 0.0890512\n",
      "[1775]\ttraining's rmse: 0.0847911\tvalid_1's rmse: 0.0890501\n",
      "[1800]\ttraining's rmse: 0.084785\tvalid_1's rmse: 0.0890498\n",
      "[1825]\ttraining's rmse: 0.0847788\tvalid_1's rmse: 0.0890489\n",
      "[1850]\ttraining's rmse: 0.0847723\tvalid_1's rmse: 0.0890479\n",
      "[1875]\ttraining's rmse: 0.0847664\tvalid_1's rmse: 0.0890469\n",
      "[1900]\ttraining's rmse: 0.0847626\tvalid_1's rmse: 0.0890469\n",
      "[1925]\ttraining's rmse: 0.0847572\tvalid_1's rmse: 0.0890462\n",
      "[1950]\ttraining's rmse: 0.0847532\tvalid_1's rmse: 0.0890455\n",
      "[1975]\ttraining's rmse: 0.0847491\tvalid_1's rmse: 0.0890451\n",
      "[2000]\ttraining's rmse: 0.0847451\tvalid_1's rmse: 0.0890448\n",
      "[2025]\ttraining's rmse: 0.0847408\tvalid_1's rmse: 0.089044\n",
      "[2050]\ttraining's rmse: 0.0847365\tvalid_1's rmse: 0.0890433\n",
      "[2075]\ttraining's rmse: 0.0847335\tvalid_1's rmse: 0.0890431\n",
      "[2100]\ttraining's rmse: 0.0847302\tvalid_1's rmse: 0.0890431\n",
      "[2125]\ttraining's rmse: 0.0847269\tvalid_1's rmse: 0.0890428\n",
      "[2150]\ttraining's rmse: 0.084723\tvalid_1's rmse: 0.0890429\n",
      "[2175]\ttraining's rmse: 0.0847183\tvalid_1's rmse: 0.0890424\n",
      "[2200]\ttraining's rmse: 0.0847142\tvalid_1's rmse: 0.0890418\n",
      "[2225]\ttraining's rmse: 0.0847107\tvalid_1's rmse: 0.0890414\n",
      "[2250]\ttraining's rmse: 0.0847061\tvalid_1's rmse: 0.0890414\n",
      "[2275]\ttraining's rmse: 0.0847033\tvalid_1's rmse: 0.0890415\n",
      "[2300]\ttraining's rmse: 0.0847002\tvalid_1's rmse: 0.0890415\n",
      "Early stopping, best iteration is:\n",
      "[2263]\ttraining's rmse: 0.0847047\tvalid_1's rmse: 0.0890412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0897048\tvalid_1's rmse: 0.0856965\n",
      "[50]\ttraining's rmse: 0.0895789\tvalid_1's rmse: 0.0856469\n",
      "[75]\ttraining's rmse: 0.0894454\tvalid_1's rmse: 0.0855982\n",
      "[100]\ttraining's rmse: 0.0893277\tvalid_1's rmse: 0.0855581\n",
      "[125]\ttraining's rmse: 0.0892068\tvalid_1's rmse: 0.0855153\n",
      "[150]\ttraining's rmse: 0.0890946\tvalid_1's rmse: 0.0854754\n",
      "[175]\ttraining's rmse: 0.0890019\tvalid_1's rmse: 0.0854445\n",
      "[200]\ttraining's rmse: 0.0888985\tvalid_1's rmse: 0.0854129\n",
      "[225]\ttraining's rmse: 0.0888005\tvalid_1's rmse: 0.0853818\n",
      "[250]\ttraining's rmse: 0.0887176\tvalid_1's rmse: 0.0853547\n",
      "[275]\ttraining's rmse: 0.0886423\tvalid_1's rmse: 0.0853292\n",
      "[300]\ttraining's rmse: 0.0885659\tvalid_1's rmse: 0.0853077\n",
      "[325]\ttraining's rmse: 0.0884895\tvalid_1's rmse: 0.0852849\n",
      "[350]\ttraining's rmse: 0.0884168\tvalid_1's rmse: 0.0852637\n",
      "[375]\ttraining's rmse: 0.0883562\tvalid_1's rmse: 0.0852474\n",
      "[400]\ttraining's rmse: 0.0882882\tvalid_1's rmse: 0.0852346\n",
      "[425]\ttraining's rmse: 0.0882281\tvalid_1's rmse: 0.0852185\n",
      "[450]\ttraining's rmse: 0.0881698\tvalid_1's rmse: 0.0852047\n",
      "[475]\ttraining's rmse: 0.0881167\tvalid_1's rmse: 0.0851923\n",
      "[500]\ttraining's rmse: 0.0880716\tvalid_1's rmse: 0.0851801\n",
      "[525]\ttraining's rmse: 0.0880122\tvalid_1's rmse: 0.0851657\n",
      "[550]\ttraining's rmse: 0.0879576\tvalid_1's rmse: 0.0851539\n",
      "[575]\ttraining's rmse: 0.08791\tvalid_1's rmse: 0.0851468\n",
      "[600]\ttraining's rmse: 0.0878602\tvalid_1's rmse: 0.0851372\n",
      "[625]\ttraining's rmse: 0.0878208\tvalid_1's rmse: 0.085137\n",
      "[650]\ttraining's rmse: 0.0877714\tvalid_1's rmse: 0.0851365\n",
      "[675]\ttraining's rmse: 0.0877246\tvalid_1's rmse: 0.085129\n",
      "[700]\ttraining's rmse: 0.0876816\tvalid_1's rmse: 0.0851205\n",
      "[725]\ttraining's rmse: 0.0876421\tvalid_1's rmse: 0.0851235\n",
      "[750]\ttraining's rmse: 0.0876057\tvalid_1's rmse: 0.08512\n",
      "[775]\ttraining's rmse: 0.0875729\tvalid_1's rmse: 0.0851234\n",
      "[800]\ttraining's rmse: 0.0875325\tvalid_1's rmse: 0.0851244\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's rmse: 0.0876041\tvalid_1's rmse: 0.0851197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0850862\tvalid_1's rmse: 0.0879194\n",
      "[50]\ttraining's rmse: 0.0849499\tvalid_1's rmse: 0.0878635\n",
      "[75]\ttraining's rmse: 0.0848157\tvalid_1's rmse: 0.0878069\n",
      "[100]\ttraining's rmse: 0.0846924\tvalid_1's rmse: 0.0877602\n",
      "[125]\ttraining's rmse: 0.0845702\tvalid_1's rmse: 0.0877124\n",
      "[150]\ttraining's rmse: 0.0844585\tvalid_1's rmse: 0.0876684\n",
      "[175]\ttraining's rmse: 0.084364\tvalid_1's rmse: 0.0876301\n",
      "[200]\ttraining's rmse: 0.084266\tvalid_1's rmse: 0.0875923\n",
      "[225]\ttraining's rmse: 0.0841687\tvalid_1's rmse: 0.087556\n",
      "[250]\ttraining's rmse: 0.0840842\tvalid_1's rmse: 0.0875223\n",
      "[275]\ttraining's rmse: 0.0840034\tvalid_1's rmse: 0.0874927\n",
      "[300]\ttraining's rmse: 0.0839257\tvalid_1's rmse: 0.0874641\n",
      "[325]\ttraining's rmse: 0.0838499\tvalid_1's rmse: 0.0874393\n",
      "[350]\ttraining's rmse: 0.0837775\tvalid_1's rmse: 0.0874136\n",
      "[375]\ttraining's rmse: 0.0837127\tvalid_1's rmse: 0.0873934\n",
      "[400]\ttraining's rmse: 0.0836515\tvalid_1's rmse: 0.0873714\n",
      "[425]\ttraining's rmse: 0.0835921\tvalid_1's rmse: 0.0873496\n",
      "[450]\ttraining's rmse: 0.0835363\tvalid_1's rmse: 0.0873303\n",
      "[475]\ttraining's rmse: 0.0834824\tvalid_1's rmse: 0.0873113\n",
      "[500]\ttraining's rmse: 0.0834363\tvalid_1's rmse: 0.0872921\n",
      "[525]\ttraining's rmse: 0.0833801\tvalid_1's rmse: 0.0872749\n",
      "[550]\ttraining's rmse: 0.0833306\tvalid_1's rmse: 0.0872585\n",
      "[575]\ttraining's rmse: 0.0832833\tvalid_1's rmse: 0.0872438\n",
      "[600]\ttraining's rmse: 0.0832413\tvalid_1's rmse: 0.0872313\n",
      "[625]\ttraining's rmse: 0.0832053\tvalid_1's rmse: 0.0872186\n",
      "[650]\ttraining's rmse: 0.0831637\tvalid_1's rmse: 0.0872059\n",
      "[675]\ttraining's rmse: 0.0831226\tvalid_1's rmse: 0.0871935\n",
      "[700]\ttraining's rmse: 0.0830842\tvalid_1's rmse: 0.0871824\n",
      "[725]\ttraining's rmse: 0.0830487\tvalid_1's rmse: 0.0871729\n",
      "[750]\ttraining's rmse: 0.0830148\tvalid_1's rmse: 0.0871636\n",
      "[775]\ttraining's rmse: 0.0829875\tvalid_1's rmse: 0.0871511\n",
      "[800]\ttraining's rmse: 0.0829531\tvalid_1's rmse: 0.0871428\n",
      "[825]\ttraining's rmse: 0.0829233\tvalid_1's rmse: 0.0871345\n",
      "[850]\ttraining's rmse: 0.0828911\tvalid_1's rmse: 0.0871261\n",
      "[875]\ttraining's rmse: 0.0828648\tvalid_1's rmse: 0.0871184\n",
      "[900]\ttraining's rmse: 0.0828342\tvalid_1's rmse: 0.0871092\n",
      "[925]\ttraining's rmse: 0.082809\tvalid_1's rmse: 0.087101\n",
      "[950]\ttraining's rmse: 0.0827854\tvalid_1's rmse: 0.087095\n",
      "[975]\ttraining's rmse: 0.0827598\tvalid_1's rmse: 0.0870875\n",
      "[1000]\ttraining's rmse: 0.0827345\tvalid_1's rmse: 0.0870815\n",
      "[1025]\ttraining's rmse: 0.0827097\tvalid_1's rmse: 0.0870754\n",
      "[1050]\ttraining's rmse: 0.0826875\tvalid_1's rmse: 0.087069\n",
      "[1075]\ttraining's rmse: 0.0826661\tvalid_1's rmse: 0.0870652\n",
      "[1100]\ttraining's rmse: 0.082647\tvalid_1's rmse: 0.087059\n",
      "[1125]\ttraining's rmse: 0.0826307\tvalid_1's rmse: 0.0870546\n",
      "[1150]\ttraining's rmse: 0.0826129\tvalid_1's rmse: 0.0870488\n",
      "[1175]\ttraining's rmse: 0.0825953\tvalid_1's rmse: 0.0870446\n",
      "[1200]\ttraining's rmse: 0.0825798\tvalid_1's rmse: 0.0870384\n",
      "[1225]\ttraining's rmse: 0.0825633\tvalid_1's rmse: 0.087034\n",
      "[1250]\ttraining's rmse: 0.082549\tvalid_1's rmse: 0.0870291\n",
      "[1275]\ttraining's rmse: 0.082529\tvalid_1's rmse: 0.0870249\n",
      "[1300]\ttraining's rmse: 0.0825155\tvalid_1's rmse: 0.0870221\n",
      "[1325]\ttraining's rmse: 0.0825023\tvalid_1's rmse: 0.0870197\n",
      "[1350]\ttraining's rmse: 0.0824883\tvalid_1's rmse: 0.0870172\n",
      "[1375]\ttraining's rmse: 0.0824751\tvalid_1's rmse: 0.087014\n",
      "[1400]\ttraining's rmse: 0.0824641\tvalid_1's rmse: 0.0870106\n",
      "[1425]\ttraining's rmse: 0.0824489\tvalid_1's rmse: 0.0870082\n",
      "[1450]\ttraining's rmse: 0.0824347\tvalid_1's rmse: 0.0870053\n",
      "[1475]\ttraining's rmse: 0.0824251\tvalid_1's rmse: 0.0870019\n",
      "[1500]\ttraining's rmse: 0.0824156\tvalid_1's rmse: 0.0869998\n",
      "[1525]\ttraining's rmse: 0.082406\tvalid_1's rmse: 0.0869954\n",
      "[1550]\ttraining's rmse: 0.0823944\tvalid_1's rmse: 0.0869939\n",
      "[1575]\ttraining's rmse: 0.0823869\tvalid_1's rmse: 0.0869922\n",
      "[1600]\ttraining's rmse: 0.0823795\tvalid_1's rmse: 0.0869904\n",
      "[1625]\ttraining's rmse: 0.0823723\tvalid_1's rmse: 0.0869878\n",
      "[1650]\ttraining's rmse: 0.0823638\tvalid_1's rmse: 0.0869851\n",
      "[1675]\ttraining's rmse: 0.0823582\tvalid_1's rmse: 0.0869818\n",
      "[1700]\ttraining's rmse: 0.0823526\tvalid_1's rmse: 0.0869791\n",
      "[1725]\ttraining's rmse: 0.0823462\tvalid_1's rmse: 0.0869781\n",
      "[1750]\ttraining's rmse: 0.0823382\tvalid_1's rmse: 0.0869747\n",
      "[1775]\ttraining's rmse: 0.0823322\tvalid_1's rmse: 0.086972\n",
      "[1800]\ttraining's rmse: 0.0823267\tvalid_1's rmse: 0.0869709\n",
      "[1825]\ttraining's rmse: 0.0823208\tvalid_1's rmse: 0.0869695\n",
      "[1850]\ttraining's rmse: 0.0823153\tvalid_1's rmse: 0.0869681\n",
      "[1875]\ttraining's rmse: 0.0823103\tvalid_1's rmse: 0.0869681\n",
      "[1900]\ttraining's rmse: 0.0823053\tvalid_1's rmse: 0.0869659\n",
      "[1925]\ttraining's rmse: 0.0822989\tvalid_1's rmse: 0.0869647\n",
      "[1950]\ttraining's rmse: 0.0822945\tvalid_1's rmse: 0.086963\n",
      "[1975]\ttraining's rmse: 0.0822921\tvalid_1's rmse: 0.0869617\n",
      "[2000]\ttraining's rmse: 0.0822867\tvalid_1's rmse: 0.0869597\n",
      "[2025]\ttraining's rmse: 0.0822824\tvalid_1's rmse: 0.0869584\n",
      "[2050]\ttraining's rmse: 0.0822764\tvalid_1's rmse: 0.0869569\n",
      "[2075]\ttraining's rmse: 0.082272\tvalid_1's rmse: 0.0869562\n",
      "[2100]\ttraining's rmse: 0.0822683\tvalid_1's rmse: 0.0869552\n",
      "[2125]\ttraining's rmse: 0.0822654\tvalid_1's rmse: 0.0869549\n",
      "[2150]\ttraining's rmse: 0.0822633\tvalid_1's rmse: 0.086954\n",
      "[2175]\ttraining's rmse: 0.0822607\tvalid_1's rmse: 0.0869533\n",
      "[2200]\ttraining's rmse: 0.0822582\tvalid_1's rmse: 0.0869524\n",
      "[2225]\ttraining's rmse: 0.082256\tvalid_1's rmse: 0.0869516\n",
      "[2250]\ttraining's rmse: 0.0822521\tvalid_1's rmse: 0.086951\n",
      "[2275]\ttraining's rmse: 0.082248\tvalid_1's rmse: 0.0869501\n",
      "[2300]\ttraining's rmse: 0.0822453\tvalid_1's rmse: 0.0869487\n",
      "[2325]\ttraining's rmse: 0.0822418\tvalid_1's rmse: 0.0869483\n",
      "[2350]\ttraining's rmse: 0.0822385\tvalid_1's rmse: 0.0869473\n",
      "[2375]\ttraining's rmse: 0.0822361\tvalid_1's rmse: 0.0869461\n",
      "[2400]\ttraining's rmse: 0.082234\tvalid_1's rmse: 0.0869449\n",
      "[2425]\ttraining's rmse: 0.0822301\tvalid_1's rmse: 0.0869435\n",
      "[2450]\ttraining's rmse: 0.0822287\tvalid_1's rmse: 0.0869433\n",
      "[2475]\ttraining's rmse: 0.0822259\tvalid_1's rmse: 0.0869421\n",
      "[2500]\ttraining's rmse: 0.0822247\tvalid_1's rmse: 0.086942\n",
      "[2525]\ttraining's rmse: 0.0822233\tvalid_1's rmse: 0.0869419\n",
      "[2550]\ttraining's rmse: 0.0822203\tvalid_1's rmse: 0.0869419\n",
      "[2575]\ttraining's rmse: 0.0822188\tvalid_1's rmse: 0.0869421\n",
      "[2600]\ttraining's rmse: 0.0822169\tvalid_1's rmse: 0.0869419\n",
      "[2625]\ttraining's rmse: 0.0822156\tvalid_1's rmse: 0.0869411\n",
      "[2650]\ttraining's rmse: 0.0822123\tvalid_1's rmse: 0.0869412\n",
      "[2675]\ttraining's rmse: 0.0822105\tvalid_1's rmse: 0.0869404\n",
      "[2700]\ttraining's rmse: 0.0822083\tvalid_1's rmse: 0.0869402\n",
      "[2725]\ttraining's rmse: 0.0822071\tvalid_1's rmse: 0.0869404\n",
      "[2750]\ttraining's rmse: 0.082205\tvalid_1's rmse: 0.0869395\n",
      "[2775]\ttraining's rmse: 0.0822034\tvalid_1's rmse: 0.0869396\n",
      "[2800]\ttraining's rmse: 0.0822015\tvalid_1's rmse: 0.0869397\n",
      "Early stopping, best iteration is:\n",
      "[2757]\ttraining's rmse: 0.0822046\tvalid_1's rmse: 0.0869393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0854335\tvalid_1's rmse: 0.0872459\n",
      "[50]\ttraining's rmse: 0.085311\tvalid_1's rmse: 0.087189\n",
      "[75]\ttraining's rmse: 0.085182\tvalid_1's rmse: 0.0871338\n",
      "[100]\ttraining's rmse: 0.0850682\tvalid_1's rmse: 0.0870857\n",
      "[125]\ttraining's rmse: 0.0849504\tvalid_1's rmse: 0.0870373\n",
      "[150]\ttraining's rmse: 0.0848409\tvalid_1's rmse: 0.0869929\n",
      "[175]\ttraining's rmse: 0.0847493\tvalid_1's rmse: 0.0869556\n",
      "[200]\ttraining's rmse: 0.0846499\tvalid_1's rmse: 0.0869186\n",
      "[225]\ttraining's rmse: 0.0845579\tvalid_1's rmse: 0.0868843\n",
      "[250]\ttraining's rmse: 0.0844743\tvalid_1's rmse: 0.0868525\n",
      "[275]\ttraining's rmse: 0.0844012\tvalid_1's rmse: 0.0868238\n",
      "[300]\ttraining's rmse: 0.084325\tvalid_1's rmse: 0.0867953\n",
      "[325]\ttraining's rmse: 0.0842488\tvalid_1's rmse: 0.0867688\n",
      "[350]\ttraining's rmse: 0.0841757\tvalid_1's rmse: 0.0867437\n",
      "[375]\ttraining's rmse: 0.0841162\tvalid_1's rmse: 0.0867224\n",
      "[400]\ttraining's rmse: 0.0840526\tvalid_1's rmse: 0.0867017\n",
      "[425]\ttraining's rmse: 0.0839932\tvalid_1's rmse: 0.0866823\n",
      "[450]\ttraining's rmse: 0.0839366\tvalid_1's rmse: 0.0866626\n",
      "[475]\ttraining's rmse: 0.0838844\tvalid_1's rmse: 0.0866458\n",
      "[500]\ttraining's rmse: 0.083838\tvalid_1's rmse: 0.0866287\n",
      "[525]\ttraining's rmse: 0.0837817\tvalid_1's rmse: 0.0866112\n",
      "[550]\ttraining's rmse: 0.0837299\tvalid_1's rmse: 0.0865966\n",
      "[575]\ttraining's rmse: 0.0836832\tvalid_1's rmse: 0.086583\n",
      "[600]\ttraining's rmse: 0.083636\tvalid_1's rmse: 0.0865696\n",
      "[625]\ttraining's rmse: 0.0835985\tvalid_1's rmse: 0.0865573\n",
      "[650]\ttraining's rmse: 0.0835521\tvalid_1's rmse: 0.0865454\n",
      "[675]\ttraining's rmse: 0.0835075\tvalid_1's rmse: 0.0865336\n",
      "[700]\ttraining's rmse: 0.0834673\tvalid_1's rmse: 0.0865229\n",
      "[725]\ttraining's rmse: 0.0834282\tvalid_1's rmse: 0.0865133\n",
      "[750]\ttraining's rmse: 0.083392\tvalid_1's rmse: 0.0865044\n",
      "[775]\ttraining's rmse: 0.0833646\tvalid_1's rmse: 0.0864961\n",
      "[800]\ttraining's rmse: 0.0833269\tvalid_1's rmse: 0.0864875\n",
      "[825]\ttraining's rmse: 0.0832945\tvalid_1's rmse: 0.0864795\n",
      "[850]\ttraining's rmse: 0.0832642\tvalid_1's rmse: 0.0864724\n",
      "[875]\ttraining's rmse: 0.0832369\tvalid_1's rmse: 0.0864654\n",
      "[900]\ttraining's rmse: 0.083209\tvalid_1's rmse: 0.0864577\n",
      "[925]\ttraining's rmse: 0.0831803\tvalid_1's rmse: 0.0864517\n",
      "[950]\ttraining's rmse: 0.0831559\tvalid_1's rmse: 0.0864458\n",
      "[975]\ttraining's rmse: 0.0831311\tvalid_1's rmse: 0.0864404\n",
      "[1000]\ttraining's rmse: 0.0831092\tvalid_1's rmse: 0.0864351\n",
      "[1025]\ttraining's rmse: 0.0830833\tvalid_1's rmse: 0.0864307\n",
      "[1050]\ttraining's rmse: 0.0830613\tvalid_1's rmse: 0.0864258\n",
      "[1075]\ttraining's rmse: 0.0830368\tvalid_1's rmse: 0.0864217\n",
      "[1100]\ttraining's rmse: 0.0830181\tvalid_1's rmse: 0.0864179\n",
      "[1125]\ttraining's rmse: 0.0829968\tvalid_1's rmse: 0.0864147\n",
      "[1150]\ttraining's rmse: 0.0829772\tvalid_1's rmse: 0.0864118\n",
      "[1175]\ttraining's rmse: 0.0829597\tvalid_1's rmse: 0.0864093\n",
      "[1200]\ttraining's rmse: 0.0829424\tvalid_1's rmse: 0.0864059\n",
      "[1225]\ttraining's rmse: 0.0829252\tvalid_1's rmse: 0.0864034\n",
      "[1250]\ttraining's rmse: 0.0829094\tvalid_1's rmse: 0.0864005\n",
      "[1275]\ttraining's rmse: 0.0828914\tvalid_1's rmse: 0.0863988\n",
      "[1300]\ttraining's rmse: 0.0828781\tvalid_1's rmse: 0.086396\n",
      "[1325]\ttraining's rmse: 0.0828655\tvalid_1's rmse: 0.0863943\n",
      "[1350]\ttraining's rmse: 0.0828501\tvalid_1's rmse: 0.086392\n",
      "[1375]\ttraining's rmse: 0.082837\tvalid_1's rmse: 0.0863903\n",
      "[1400]\ttraining's rmse: 0.0828259\tvalid_1's rmse: 0.0863888\n",
      "[1425]\ttraining's rmse: 0.0828139\tvalid_1's rmse: 0.0863872\n",
      "[1450]\ttraining's rmse: 0.0828019\tvalid_1's rmse: 0.0863864\n",
      "[1475]\ttraining's rmse: 0.0827904\tvalid_1's rmse: 0.0863842\n",
      "[1500]\ttraining's rmse: 0.0827833\tvalid_1's rmse: 0.0863832\n",
      "[1525]\ttraining's rmse: 0.0827722\tvalid_1's rmse: 0.0863818\n",
      "[1550]\ttraining's rmse: 0.0827631\tvalid_1's rmse: 0.0863811\n",
      "[1575]\ttraining's rmse: 0.0827539\tvalid_1's rmse: 0.0863801\n",
      "[1600]\ttraining's rmse: 0.0827467\tvalid_1's rmse: 0.0863794\n",
      "[1625]\ttraining's rmse: 0.0827388\tvalid_1's rmse: 0.0863776\n",
      "[1650]\ttraining's rmse: 0.0827297\tvalid_1's rmse: 0.0863763\n",
      "[1675]\ttraining's rmse: 0.0827238\tvalid_1's rmse: 0.0863757\n",
      "[1700]\ttraining's rmse: 0.0827167\tvalid_1's rmse: 0.0863747\n",
      "[1725]\ttraining's rmse: 0.0827076\tvalid_1's rmse: 0.0863741\n",
      "[1750]\ttraining's rmse: 0.0826991\tvalid_1's rmse: 0.0863729\n",
      "[1775]\ttraining's rmse: 0.0826932\tvalid_1's rmse: 0.0863723\n",
      "[1800]\ttraining's rmse: 0.0826862\tvalid_1's rmse: 0.0863716\n",
      "[1825]\ttraining's rmse: 0.0826801\tvalid_1's rmse: 0.0863708\n",
      "[1850]\ttraining's rmse: 0.0826756\tvalid_1's rmse: 0.0863698\n",
      "[1875]\ttraining's rmse: 0.0826704\tvalid_1's rmse: 0.0863695\n",
      "[1900]\ttraining's rmse: 0.0826672\tvalid_1's rmse: 0.0863693\n",
      "[1925]\ttraining's rmse: 0.0826626\tvalid_1's rmse: 0.0863687\n",
      "[1950]\ttraining's rmse: 0.0826591\tvalid_1's rmse: 0.0863678\n",
      "[1975]\ttraining's rmse: 0.0826542\tvalid_1's rmse: 0.0863668\n",
      "[2000]\ttraining's rmse: 0.0826504\tvalid_1's rmse: 0.0863665\n",
      "[2025]\ttraining's rmse: 0.0826459\tvalid_1's rmse: 0.0863655\n",
      "[2050]\ttraining's rmse: 0.082641\tvalid_1's rmse: 0.0863648\n",
      "[2075]\ttraining's rmse: 0.082638\tvalid_1's rmse: 0.0863643\n",
      "[2100]\ttraining's rmse: 0.0826339\tvalid_1's rmse: 0.086364\n",
      "[2125]\ttraining's rmse: 0.0826303\tvalid_1's rmse: 0.0863636\n",
      "[2150]\ttraining's rmse: 0.082625\tvalid_1's rmse: 0.0863633\n",
      "[2175]\ttraining's rmse: 0.0826222\tvalid_1's rmse: 0.0863629\n",
      "[2200]\ttraining's rmse: 0.0826197\tvalid_1's rmse: 0.086363\n",
      "[2225]\ttraining's rmse: 0.0826169\tvalid_1's rmse: 0.086363\n",
      "[2250]\ttraining's rmse: 0.0826132\tvalid_1's rmse: 0.0863626\n",
      "[2275]\ttraining's rmse: 0.0826096\tvalid_1's rmse: 0.0863625\n",
      "[2300]\ttraining's rmse: 0.0826069\tvalid_1's rmse: 0.086362\n",
      "[2325]\ttraining's rmse: 0.082602\tvalid_1's rmse: 0.0863616\n",
      "[2350]\ttraining's rmse: 0.0825996\tvalid_1's rmse: 0.0863608\n",
      "[2375]\ttraining's rmse: 0.082597\tvalid_1's rmse: 0.0863604\n",
      "[2400]\ttraining's rmse: 0.0825931\tvalid_1's rmse: 0.0863607\n",
      "[2425]\ttraining's rmse: 0.0825912\tvalid_1's rmse: 0.0863608\n",
      "Early stopping, best iteration is:\n",
      "[2377]\ttraining's rmse: 0.0825969\tvalid_1's rmse: 0.0863604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0874611\tvalid_1's rmse: 0.0831282\n",
      "[50]\ttraining's rmse: 0.0873453\tvalid_1's rmse: 0.0830794\n",
      "[75]\ttraining's rmse: 0.087223\tvalid_1's rmse: 0.0830315\n",
      "[100]\ttraining's rmse: 0.0871184\tvalid_1's rmse: 0.0829898\n",
      "[125]\ttraining's rmse: 0.0870076\tvalid_1's rmse: 0.0829484\n",
      "[150]\ttraining's rmse: 0.086905\tvalid_1's rmse: 0.0829088\n",
      "[175]\ttraining's rmse: 0.0868227\tvalid_1's rmse: 0.0828824\n",
      "[200]\ttraining's rmse: 0.0867311\tvalid_1's rmse: 0.0828503\n",
      "[225]\ttraining's rmse: 0.0866422\tvalid_1's rmse: 0.0828195\n",
      "[250]\ttraining's rmse: 0.086567\tvalid_1's rmse: 0.0827941\n",
      "[275]\ttraining's rmse: 0.0864999\tvalid_1's rmse: 0.0827691\n",
      "[300]\ttraining's rmse: 0.0864307\tvalid_1's rmse: 0.0827461\n",
      "[325]\ttraining's rmse: 0.086361\tvalid_1's rmse: 0.0827248\n",
      "[350]\ttraining's rmse: 0.086293\tvalid_1's rmse: 0.0827032\n",
      "[375]\ttraining's rmse: 0.0862359\tvalid_1's rmse: 0.0826852\n",
      "[400]\ttraining's rmse: 0.0861781\tvalid_1's rmse: 0.0826694\n",
      "[425]\ttraining's rmse: 0.0861231\tvalid_1's rmse: 0.0826532\n",
      "[450]\ttraining's rmse: 0.0860716\tvalid_1's rmse: 0.0826403\n",
      "[475]\ttraining's rmse: 0.0860236\tvalid_1's rmse: 0.0826265\n",
      "[500]\ttraining's rmse: 0.0859844\tvalid_1's rmse: 0.0826149\n",
      "[525]\ttraining's rmse: 0.0859289\tvalid_1's rmse: 0.0826063\n",
      "[550]\ttraining's rmse: 0.0858795\tvalid_1's rmse: 0.0825933\n",
      "[575]\ttraining's rmse: 0.0858338\tvalid_1's rmse: 0.0825823\n",
      "[600]\ttraining's rmse: 0.0857895\tvalid_1's rmse: 0.0825731\n",
      "[625]\ttraining's rmse: 0.0857553\tvalid_1's rmse: 0.0825675\n",
      "[650]\ttraining's rmse: 0.0857103\tvalid_1's rmse: 0.0825593\n",
      "[675]\ttraining's rmse: 0.0856645\tvalid_1's rmse: 0.0825534\n",
      "[700]\ttraining's rmse: 0.0856259\tvalid_1's rmse: 0.0825449\n",
      "[725]\ttraining's rmse: 0.0855912\tvalid_1's rmse: 0.0825427\n",
      "[750]\ttraining's rmse: 0.0855572\tvalid_1's rmse: 0.0825444\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's rmse: 0.0855984\tvalid_1's rmse: 0.0825389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0888009\tvalid_1's rmse: 0.09046\n",
      "[50]\ttraining's rmse: 0.0886149\tvalid_1's rmse: 0.0904067\n",
      "[75]\ttraining's rmse: 0.0884349\tvalid_1's rmse: 0.0903545\n",
      "[100]\ttraining's rmse: 0.0882683\tvalid_1's rmse: 0.0903098\n",
      "[125]\ttraining's rmse: 0.0881031\tvalid_1's rmse: 0.0902638\n",
      "[150]\ttraining's rmse: 0.0879549\tvalid_1's rmse: 0.0902242\n",
      "[175]\ttraining's rmse: 0.0878298\tvalid_1's rmse: 0.0901877\n",
      "[200]\ttraining's rmse: 0.0876965\tvalid_1's rmse: 0.0901508\n",
      "[225]\ttraining's rmse: 0.0875705\tvalid_1's rmse: 0.0901151\n",
      "[250]\ttraining's rmse: 0.0874602\tvalid_1's rmse: 0.0900823\n",
      "[275]\ttraining's rmse: 0.0873561\tvalid_1's rmse: 0.0900531\n",
      "[300]\ttraining's rmse: 0.0872568\tvalid_1's rmse: 0.0900259\n",
      "[325]\ttraining's rmse: 0.0871576\tvalid_1's rmse: 0.090001\n",
      "[350]\ttraining's rmse: 0.0870621\tvalid_1's rmse: 0.0899752\n",
      "[375]\ttraining's rmse: 0.0869808\tvalid_1's rmse: 0.0899535\n",
      "[400]\ttraining's rmse: 0.0868975\tvalid_1's rmse: 0.0899318\n",
      "[425]\ttraining's rmse: 0.0868189\tvalid_1's rmse: 0.0899124\n",
      "[450]\ttraining's rmse: 0.0867476\tvalid_1's rmse: 0.0898934\n",
      "[475]\ttraining's rmse: 0.08668\tvalid_1's rmse: 0.0898759\n",
      "[500]\ttraining's rmse: 0.0866244\tvalid_1's rmse: 0.0898594\n",
      "[525]\ttraining's rmse: 0.0865549\tvalid_1's rmse: 0.0898421\n",
      "[550]\ttraining's rmse: 0.0864942\tvalid_1's rmse: 0.0898282\n",
      "[575]\ttraining's rmse: 0.0864351\tvalid_1's rmse: 0.0898152\n",
      "[600]\ttraining's rmse: 0.0863733\tvalid_1's rmse: 0.0897996\n",
      "[625]\ttraining's rmse: 0.0863237\tvalid_1's rmse: 0.0897866\n",
      "[650]\ttraining's rmse: 0.0862706\tvalid_1's rmse: 0.0897735\n",
      "[675]\ttraining's rmse: 0.0862198\tvalid_1's rmse: 0.0897603\n",
      "[700]\ttraining's rmse: 0.086172\tvalid_1's rmse: 0.0897493\n",
      "[725]\ttraining's rmse: 0.086127\tvalid_1's rmse: 0.0897384\n",
      "[750]\ttraining's rmse: 0.0860864\tvalid_1's rmse: 0.0897296\n",
      "[775]\ttraining's rmse: 0.0860522\tvalid_1's rmse: 0.0897201\n",
      "[800]\ttraining's rmse: 0.0860134\tvalid_1's rmse: 0.0897107\n",
      "[825]\ttraining's rmse: 0.0859771\tvalid_1's rmse: 0.0897029\n",
      "[850]\ttraining's rmse: 0.0859375\tvalid_1's rmse: 0.0896945\n",
      "[875]\ttraining's rmse: 0.0859042\tvalid_1's rmse: 0.089688\n",
      "[900]\ttraining's rmse: 0.0858686\tvalid_1's rmse: 0.0896805\n",
      "[925]\ttraining's rmse: 0.0858377\tvalid_1's rmse: 0.0896727\n",
      "[950]\ttraining's rmse: 0.0858086\tvalid_1's rmse: 0.0896645\n",
      "[975]\ttraining's rmse: 0.0857795\tvalid_1's rmse: 0.0896582\n",
      "[1000]\ttraining's rmse: 0.0857509\tvalid_1's rmse: 0.0896508\n",
      "[1025]\ttraining's rmse: 0.0857255\tvalid_1's rmse: 0.089644\n",
      "[1050]\ttraining's rmse: 0.0857008\tvalid_1's rmse: 0.0896368\n",
      "[1075]\ttraining's rmse: 0.0856742\tvalid_1's rmse: 0.089632\n",
      "[1100]\ttraining's rmse: 0.0856518\tvalid_1's rmse: 0.0896269\n",
      "[1125]\ttraining's rmse: 0.085628\tvalid_1's rmse: 0.0896227\n",
      "[1150]\ttraining's rmse: 0.0856043\tvalid_1's rmse: 0.0896177\n",
      "[1175]\ttraining's rmse: 0.0855821\tvalid_1's rmse: 0.0896126\n",
      "[1200]\ttraining's rmse: 0.0855627\tvalid_1's rmse: 0.0896069\n",
      "[1225]\ttraining's rmse: 0.0855435\tvalid_1's rmse: 0.0896027\n",
      "[1250]\ttraining's rmse: 0.0855254\tvalid_1's rmse: 0.089598\n",
      "[1275]\ttraining's rmse: 0.0855058\tvalid_1's rmse: 0.0895939\n",
      "[1300]\ttraining's rmse: 0.0854925\tvalid_1's rmse: 0.0895898\n",
      "[1325]\ttraining's rmse: 0.0854766\tvalid_1's rmse: 0.0895859\n",
      "[1350]\ttraining's rmse: 0.0854623\tvalid_1's rmse: 0.0895827\n",
      "[1375]\ttraining's rmse: 0.0854471\tvalid_1's rmse: 0.0895791\n",
      "[1400]\ttraining's rmse: 0.0854327\tvalid_1's rmse: 0.0895762\n",
      "[1425]\ttraining's rmse: 0.0854177\tvalid_1's rmse: 0.0895729\n",
      "[1450]\ttraining's rmse: 0.0854045\tvalid_1's rmse: 0.0895695\n",
      "[1475]\ttraining's rmse: 0.0853921\tvalid_1's rmse: 0.0895658\n",
      "[1500]\ttraining's rmse: 0.0853812\tvalid_1's rmse: 0.0895622\n",
      "[1525]\ttraining's rmse: 0.0853675\tvalid_1's rmse: 0.0895597\n",
      "[1550]\ttraining's rmse: 0.0853557\tvalid_1's rmse: 0.0895575\n",
      "[1575]\ttraining's rmse: 0.0853427\tvalid_1's rmse: 0.0895547\n",
      "[1600]\ttraining's rmse: 0.0853358\tvalid_1's rmse: 0.0895515\n",
      "[1625]\ttraining's rmse: 0.0853275\tvalid_1's rmse: 0.0895491\n",
      "[1650]\ttraining's rmse: 0.0853184\tvalid_1's rmse: 0.089547\n",
      "[1675]\ttraining's rmse: 0.0853124\tvalid_1's rmse: 0.0895448\n",
      "[1700]\ttraining's rmse: 0.0853053\tvalid_1's rmse: 0.0895424\n",
      "[1725]\ttraining's rmse: 0.0852978\tvalid_1's rmse: 0.089541\n",
      "[1750]\ttraining's rmse: 0.0852881\tvalid_1's rmse: 0.089538\n",
      "[1775]\ttraining's rmse: 0.0852808\tvalid_1's rmse: 0.0895363\n",
      "[1800]\ttraining's rmse: 0.085274\tvalid_1's rmse: 0.0895338\n",
      "[1825]\ttraining's rmse: 0.0852676\tvalid_1's rmse: 0.089531\n",
      "[1850]\ttraining's rmse: 0.0852611\tvalid_1's rmse: 0.0895289\n",
      "[1875]\ttraining's rmse: 0.0852559\tvalid_1's rmse: 0.0895275\n",
      "[1900]\ttraining's rmse: 0.0852489\tvalid_1's rmse: 0.0895266\n",
      "[1925]\ttraining's rmse: 0.0852435\tvalid_1's rmse: 0.0895246\n",
      "[1950]\ttraining's rmse: 0.0852382\tvalid_1's rmse: 0.0895219\n",
      "[1975]\ttraining's rmse: 0.0852329\tvalid_1's rmse: 0.0895203\n",
      "[2000]\ttraining's rmse: 0.0852291\tvalid_1's rmse: 0.0895197\n",
      "[2025]\ttraining's rmse: 0.0852251\tvalid_1's rmse: 0.0895184\n",
      "[2050]\ttraining's rmse: 0.0852197\tvalid_1's rmse: 0.0895173\n",
      "[2075]\ttraining's rmse: 0.0852143\tvalid_1's rmse: 0.089516\n",
      "[2100]\ttraining's rmse: 0.0852102\tvalid_1's rmse: 0.0895141\n",
      "[2125]\ttraining's rmse: 0.0852065\tvalid_1's rmse: 0.0895132\n",
      "[2150]\ttraining's rmse: 0.0852021\tvalid_1's rmse: 0.0895125\n",
      "[2175]\ttraining's rmse: 0.0851971\tvalid_1's rmse: 0.089511\n",
      "[2200]\ttraining's rmse: 0.0851923\tvalid_1's rmse: 0.0895104\n",
      "[2225]\ttraining's rmse: 0.0851886\tvalid_1's rmse: 0.0895082\n",
      "[2250]\ttraining's rmse: 0.085186\tvalid_1's rmse: 0.0895066\n",
      "[2275]\ttraining's rmse: 0.0851823\tvalid_1's rmse: 0.0895056\n",
      "[2300]\ttraining's rmse: 0.0851788\tvalid_1's rmse: 0.089505\n",
      "[2325]\ttraining's rmse: 0.0851757\tvalid_1's rmse: 0.0895046\n",
      "[2350]\ttraining's rmse: 0.0851728\tvalid_1's rmse: 0.089503\n",
      "[2375]\ttraining's rmse: 0.0851699\tvalid_1's rmse: 0.0895021\n",
      "[2400]\ttraining's rmse: 0.0851663\tvalid_1's rmse: 0.0895013\n",
      "[2425]\ttraining's rmse: 0.0851635\tvalid_1's rmse: 0.0895005\n",
      "[2450]\ttraining's rmse: 0.0851612\tvalid_1's rmse: 0.0895004\n",
      "[2475]\ttraining's rmse: 0.0851582\tvalid_1's rmse: 0.0894998\n",
      "[2500]\ttraining's rmse: 0.0851556\tvalid_1's rmse: 0.0894991\n",
      "[2525]\ttraining's rmse: 0.0851538\tvalid_1's rmse: 0.0894985\n",
      "[2550]\ttraining's rmse: 0.0851504\tvalid_1's rmse: 0.0894978\n",
      "[2575]\ttraining's rmse: 0.0851482\tvalid_1's rmse: 0.0894974\n",
      "[2600]\ttraining's rmse: 0.0851451\tvalid_1's rmse: 0.0894969\n",
      "[2625]\ttraining's rmse: 0.0851426\tvalid_1's rmse: 0.0894961\n",
      "[2650]\ttraining's rmse: 0.0851397\tvalid_1's rmse: 0.0894951\n",
      "[2675]\ttraining's rmse: 0.0851384\tvalid_1's rmse: 0.0894945\n",
      "[2700]\ttraining's rmse: 0.0851367\tvalid_1's rmse: 0.0894936\n",
      "[2725]\ttraining's rmse: 0.0851326\tvalid_1's rmse: 0.089493\n",
      "[2750]\ttraining's rmse: 0.0851309\tvalid_1's rmse: 0.0894926\n",
      "[2775]\ttraining's rmse: 0.085129\tvalid_1's rmse: 0.0894915\n",
      "[2800]\ttraining's rmse: 0.085128\tvalid_1's rmse: 0.0894913\n",
      "[2825]\ttraining's rmse: 0.0851249\tvalid_1's rmse: 0.0894907\n",
      "[2850]\ttraining's rmse: 0.0851234\tvalid_1's rmse: 0.0894903\n",
      "[2875]\ttraining's rmse: 0.0851216\tvalid_1's rmse: 0.0894904\n",
      "Early stopping, best iteration is:\n",
      "[2842]\ttraining's rmse: 0.0851241\tvalid_1's rmse: 0.0894902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0887512\tvalid_1's rmse: 0.0905605\n",
      "[50]\ttraining's rmse: 0.0885837\tvalid_1's rmse: 0.0905072\n",
      "[75]\ttraining's rmse: 0.0884165\tvalid_1's rmse: 0.090453\n",
      "[100]\ttraining's rmse: 0.0882647\tvalid_1's rmse: 0.0904052\n",
      "[125]\ttraining's rmse: 0.0881096\tvalid_1's rmse: 0.0903577\n",
      "[150]\ttraining's rmse: 0.0879689\tvalid_1's rmse: 0.090313\n",
      "[175]\ttraining's rmse: 0.0878475\tvalid_1's rmse: 0.090275\n",
      "[200]\ttraining's rmse: 0.0877244\tvalid_1's rmse: 0.0902359\n",
      "[225]\ttraining's rmse: 0.0876048\tvalid_1's rmse: 0.0902003\n",
      "[250]\ttraining's rmse: 0.0875015\tvalid_1's rmse: 0.090168\n",
      "[275]\ttraining's rmse: 0.087404\tvalid_1's rmse: 0.0901371\n",
      "[300]\ttraining's rmse: 0.0873084\tvalid_1's rmse: 0.0901088\n",
      "[325]\ttraining's rmse: 0.0872143\tvalid_1's rmse: 0.0900824\n",
      "[350]\ttraining's rmse: 0.0871225\tvalid_1's rmse: 0.0900568\n",
      "[375]\ttraining's rmse: 0.0870482\tvalid_1's rmse: 0.0900347\n",
      "[400]\ttraining's rmse: 0.0869674\tvalid_1's rmse: 0.0900133\n",
      "[425]\ttraining's rmse: 0.086894\tvalid_1's rmse: 0.0899916\n",
      "[450]\ttraining's rmse: 0.0868304\tvalid_1's rmse: 0.0899731\n",
      "[475]\ttraining's rmse: 0.0867699\tvalid_1's rmse: 0.0899561\n",
      "[500]\ttraining's rmse: 0.0867173\tvalid_1's rmse: 0.0899387\n",
      "[525]\ttraining's rmse: 0.0866503\tvalid_1's rmse: 0.0899218\n",
      "[550]\ttraining's rmse: 0.0865902\tvalid_1's rmse: 0.0899071\n",
      "[575]\ttraining's rmse: 0.0865355\tvalid_1's rmse: 0.0898929\n",
      "[600]\ttraining's rmse: 0.0864847\tvalid_1's rmse: 0.0898799\n",
      "[625]\ttraining's rmse: 0.08644\tvalid_1's rmse: 0.0898668\n",
      "[650]\ttraining's rmse: 0.0863888\tvalid_1's rmse: 0.0898551\n",
      "[675]\ttraining's rmse: 0.086339\tvalid_1's rmse: 0.0898446\n",
      "[700]\ttraining's rmse: 0.0862964\tvalid_1's rmse: 0.089833\n",
      "[725]\ttraining's rmse: 0.0862562\tvalid_1's rmse: 0.0898227\n",
      "[750]\ttraining's rmse: 0.0862163\tvalid_1's rmse: 0.0898124\n",
      "[775]\ttraining's rmse: 0.0861841\tvalid_1's rmse: 0.0898037\n",
      "[800]\ttraining's rmse: 0.086143\tvalid_1's rmse: 0.0897947\n",
      "[825]\ttraining's rmse: 0.0861099\tvalid_1's rmse: 0.089786\n",
      "[850]\ttraining's rmse: 0.0860754\tvalid_1's rmse: 0.0897783\n",
      "[875]\ttraining's rmse: 0.0860433\tvalid_1's rmse: 0.0897709\n",
      "[900]\ttraining's rmse: 0.0860096\tvalid_1's rmse: 0.0897636\n",
      "[925]\ttraining's rmse: 0.0859804\tvalid_1's rmse: 0.089757\n",
      "[950]\ttraining's rmse: 0.0859518\tvalid_1's rmse: 0.0897508\n",
      "[975]\ttraining's rmse: 0.0859256\tvalid_1's rmse: 0.089745\n",
      "[1000]\ttraining's rmse: 0.0859002\tvalid_1's rmse: 0.0897401\n",
      "[1025]\ttraining's rmse: 0.0858729\tvalid_1's rmse: 0.0897356\n",
      "[1050]\ttraining's rmse: 0.0858483\tvalid_1's rmse: 0.0897307\n",
      "[1075]\ttraining's rmse: 0.0858232\tvalid_1's rmse: 0.0897267\n",
      "[1100]\ttraining's rmse: 0.0858033\tvalid_1's rmse: 0.0897231\n",
      "[1125]\ttraining's rmse: 0.0857814\tvalid_1's rmse: 0.0897184\n",
      "[1150]\ttraining's rmse: 0.08576\tvalid_1's rmse: 0.0897143\n",
      "[1175]\ttraining's rmse: 0.0857396\tvalid_1's rmse: 0.089712\n",
      "[1200]\ttraining's rmse: 0.0857182\tvalid_1's rmse: 0.0897084\n",
      "[1225]\ttraining's rmse: 0.0856999\tvalid_1's rmse: 0.0897053\n",
      "[1250]\ttraining's rmse: 0.085683\tvalid_1's rmse: 0.0897026\n",
      "[1275]\ttraining's rmse: 0.085663\tvalid_1's rmse: 0.0897001\n",
      "[1300]\ttraining's rmse: 0.0856488\tvalid_1's rmse: 0.089697\n",
      "[1325]\ttraining's rmse: 0.0856334\tvalid_1's rmse: 0.0896949\n",
      "[1350]\ttraining's rmse: 0.085617\tvalid_1's rmse: 0.0896931\n",
      "[1375]\ttraining's rmse: 0.0856004\tvalid_1's rmse: 0.0896912\n",
      "[1400]\ttraining's rmse: 0.0855867\tvalid_1's rmse: 0.089689\n",
      "[1425]\ttraining's rmse: 0.08557\tvalid_1's rmse: 0.0896875\n",
      "[1450]\ttraining's rmse: 0.0855563\tvalid_1's rmse: 0.0896863\n",
      "[1475]\ttraining's rmse: 0.0855446\tvalid_1's rmse: 0.0896853\n",
      "[1500]\ttraining's rmse: 0.0855315\tvalid_1's rmse: 0.0896835\n",
      "[1525]\ttraining's rmse: 0.0855205\tvalid_1's rmse: 0.0896819\n",
      "[1550]\ttraining's rmse: 0.0855088\tvalid_1's rmse: 0.0896808\n",
      "[1575]\ttraining's rmse: 0.085498\tvalid_1's rmse: 0.0896791\n",
      "[1600]\ttraining's rmse: 0.0854894\tvalid_1's rmse: 0.0896779\n",
      "[1625]\ttraining's rmse: 0.0854784\tvalid_1's rmse: 0.0896763\n",
      "[1650]\ttraining's rmse: 0.0854694\tvalid_1's rmse: 0.0896757\n",
      "[1675]\ttraining's rmse: 0.0854621\tvalid_1's rmse: 0.0896748\n",
      "[1700]\ttraining's rmse: 0.0854542\tvalid_1's rmse: 0.0896736\n",
      "[1725]\ttraining's rmse: 0.0854483\tvalid_1's rmse: 0.0896728\n",
      "[1750]\ttraining's rmse: 0.08544\tvalid_1's rmse: 0.0896722\n",
      "[1775]\ttraining's rmse: 0.0854316\tvalid_1's rmse: 0.0896713\n",
      "[1800]\ttraining's rmse: 0.0854244\tvalid_1's rmse: 0.0896703\n",
      "[1825]\ttraining's rmse: 0.0854165\tvalid_1's rmse: 0.0896693\n",
      "[1850]\ttraining's rmse: 0.0854106\tvalid_1's rmse: 0.0896682\n",
      "[1875]\ttraining's rmse: 0.085404\tvalid_1's rmse: 0.0896674\n",
      "[1900]\ttraining's rmse: 0.0853997\tvalid_1's rmse: 0.0896666\n",
      "[1925]\ttraining's rmse: 0.085393\tvalid_1's rmse: 0.0896665\n",
      "[1950]\ttraining's rmse: 0.0853874\tvalid_1's rmse: 0.0896657\n",
      "[1975]\ttraining's rmse: 0.0853832\tvalid_1's rmse: 0.0896647\n",
      "[2000]\ttraining's rmse: 0.0853778\tvalid_1's rmse: 0.0896641\n",
      "[2025]\ttraining's rmse: 0.0853731\tvalid_1's rmse: 0.0896637\n",
      "[2050]\ttraining's rmse: 0.0853679\tvalid_1's rmse: 0.0896632\n",
      "[2075]\ttraining's rmse: 0.0853628\tvalid_1's rmse: 0.0896631\n",
      "[2100]\ttraining's rmse: 0.0853596\tvalid_1's rmse: 0.0896632\n",
      "[2125]\ttraining's rmse: 0.0853551\tvalid_1's rmse: 0.0896631\n",
      "[2150]\ttraining's rmse: 0.0853511\tvalid_1's rmse: 0.0896633\n",
      "Early stopping, best iteration is:\n",
      "[2123]\ttraining's rmse: 0.0853556\tvalid_1's rmse: 0.0896629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0903737\tvalid_1's rmse: 0.0873707\n",
      "[50]\ttraining's rmse: 0.0902469\tvalid_1's rmse: 0.087323\n",
      "[75]\ttraining's rmse: 0.090112\tvalid_1's rmse: 0.0872758\n",
      "[100]\ttraining's rmse: 0.0899903\tvalid_1's rmse: 0.0872331\n",
      "[125]\ttraining's rmse: 0.0898654\tvalid_1's rmse: 0.0871908\n",
      "[150]\ttraining's rmse: 0.0897504\tvalid_1's rmse: 0.0871537\n",
      "[175]\ttraining's rmse: 0.0896536\tvalid_1's rmse: 0.0871225\n",
      "[200]\ttraining's rmse: 0.0895466\tvalid_1's rmse: 0.0870904\n",
      "[225]\ttraining's rmse: 0.0894438\tvalid_1's rmse: 0.0870597\n",
      "[250]\ttraining's rmse: 0.0893563\tvalid_1's rmse: 0.0870314\n",
      "[275]\ttraining's rmse: 0.0892769\tvalid_1's rmse: 0.0870058\n",
      "[300]\ttraining's rmse: 0.0892004\tvalid_1's rmse: 0.0869814\n",
      "[325]\ttraining's rmse: 0.0891187\tvalid_1's rmse: 0.0869593\n",
      "[350]\ttraining's rmse: 0.0890423\tvalid_1's rmse: 0.0869379\n",
      "[375]\ttraining's rmse: 0.0889783\tvalid_1's rmse: 0.086924\n",
      "[400]\ttraining's rmse: 0.0889092\tvalid_1's rmse: 0.0869082\n",
      "[425]\ttraining's rmse: 0.088846\tvalid_1's rmse: 0.0868914\n",
      "[450]\ttraining's rmse: 0.0887876\tvalid_1's rmse: 0.0868784\n",
      "[475]\ttraining's rmse: 0.0887342\tvalid_1's rmse: 0.0868648\n",
      "[500]\ttraining's rmse: 0.0886889\tvalid_1's rmse: 0.0868518\n",
      "[525]\ttraining's rmse: 0.0886296\tvalid_1's rmse: 0.0868383\n",
      "[550]\ttraining's rmse: 0.0885734\tvalid_1's rmse: 0.0868318\n",
      "[575]\ttraining's rmse: 0.088521\tvalid_1's rmse: 0.0868256\n",
      "[600]\ttraining's rmse: 0.0884712\tvalid_1's rmse: 0.0868186\n",
      "[625]\ttraining's rmse: 0.0884319\tvalid_1's rmse: 0.0868091\n",
      "[650]\ttraining's rmse: 0.0883813\tvalid_1's rmse: 0.0868003\n",
      "[675]\ttraining's rmse: 0.0883313\tvalid_1's rmse: 0.0868008\n",
      "[700]\ttraining's rmse: 0.0882874\tvalid_1's rmse: 0.0867932\n",
      "[725]\ttraining's rmse: 0.0882472\tvalid_1's rmse: 0.0867919\n",
      "[750]\ttraining's rmse: 0.0882066\tvalid_1's rmse: 0.0867881\n",
      "[775]\ttraining's rmse: 0.0881733\tvalid_1's rmse: 0.0867873\n",
      "[800]\ttraining's rmse: 0.0881296\tvalid_1's rmse: 0.0867815\n",
      "[825]\ttraining's rmse: 0.088096\tvalid_1's rmse: 0.0867832\n",
      "[850]\ttraining's rmse: 0.0880581\tvalid_1's rmse: 0.0867785\n",
      "[875]\ttraining's rmse: 0.0880277\tvalid_1's rmse: 0.0867863\n",
      "[900]\ttraining's rmse: 0.0879929\tvalid_1's rmse: 0.0867901\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's rmse: 0.088049\tvalid_1's rmse: 0.0867774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0855737\tvalid_1's rmse: 0.0883409\n",
      "[50]\ttraining's rmse: 0.0854356\tvalid_1's rmse: 0.0882833\n",
      "[75]\ttraining's rmse: 0.0852958\tvalid_1's rmse: 0.0882268\n",
      "[100]\ttraining's rmse: 0.085169\tvalid_1's rmse: 0.088179\n",
      "[125]\ttraining's rmse: 0.0850427\tvalid_1's rmse: 0.0881294\n",
      "[150]\ttraining's rmse: 0.0849277\tvalid_1's rmse: 0.0880831\n",
      "[175]\ttraining's rmse: 0.0848326\tvalid_1's rmse: 0.0880451\n",
      "[200]\ttraining's rmse: 0.0847336\tvalid_1's rmse: 0.0880069\n",
      "[225]\ttraining's rmse: 0.0846318\tvalid_1's rmse: 0.0879694\n",
      "[250]\ttraining's rmse: 0.0845489\tvalid_1's rmse: 0.0879352\n",
      "[275]\ttraining's rmse: 0.0844672\tvalid_1's rmse: 0.0879047\n",
      "[300]\ttraining's rmse: 0.0843872\tvalid_1's rmse: 0.087875\n",
      "[325]\ttraining's rmse: 0.0843079\tvalid_1's rmse: 0.0878466\n",
      "[350]\ttraining's rmse: 0.0842334\tvalid_1's rmse: 0.0878192\n",
      "[375]\ttraining's rmse: 0.0841685\tvalid_1's rmse: 0.0877973\n",
      "[400]\ttraining's rmse: 0.0841001\tvalid_1's rmse: 0.0877747\n",
      "[425]\ttraining's rmse: 0.0840406\tvalid_1's rmse: 0.0877522\n",
      "[450]\ttraining's rmse: 0.0839869\tvalid_1's rmse: 0.0877326\n",
      "[475]\ttraining's rmse: 0.0839366\tvalid_1's rmse: 0.0877137\n",
      "[500]\ttraining's rmse: 0.0838887\tvalid_1's rmse: 0.0876944\n",
      "[525]\ttraining's rmse: 0.0838326\tvalid_1's rmse: 0.0876759\n",
      "[550]\ttraining's rmse: 0.0837813\tvalid_1's rmse: 0.0876596\n",
      "[575]\ttraining's rmse: 0.0837339\tvalid_1's rmse: 0.0876465\n",
      "[600]\ttraining's rmse: 0.0836876\tvalid_1's rmse: 0.0876312\n",
      "[625]\ttraining's rmse: 0.0836507\tvalid_1's rmse: 0.0876185\n",
      "[650]\ttraining's rmse: 0.0836079\tvalid_1's rmse: 0.0876051\n",
      "[675]\ttraining's rmse: 0.0835659\tvalid_1's rmse: 0.0875903\n",
      "[700]\ttraining's rmse: 0.0835274\tvalid_1's rmse: 0.087579\n",
      "[725]\ttraining's rmse: 0.0834918\tvalid_1's rmse: 0.0875691\n",
      "[750]\ttraining's rmse: 0.0834586\tvalid_1's rmse: 0.087558\n",
      "[775]\ttraining's rmse: 0.0834294\tvalid_1's rmse: 0.0875482\n",
      "[800]\ttraining's rmse: 0.0833912\tvalid_1's rmse: 0.0875381\n",
      "[825]\ttraining's rmse: 0.0833611\tvalid_1's rmse: 0.0875286\n",
      "[850]\ttraining's rmse: 0.0833294\tvalid_1's rmse: 0.0875214\n",
      "[875]\ttraining's rmse: 0.0833033\tvalid_1's rmse: 0.087514\n",
      "[900]\ttraining's rmse: 0.0832729\tvalid_1's rmse: 0.0875059\n",
      "[925]\ttraining's rmse: 0.0832435\tvalid_1's rmse: 0.0874973\n",
      "[950]\ttraining's rmse: 0.0832187\tvalid_1's rmse: 0.0874894\n",
      "[975]\ttraining's rmse: 0.083195\tvalid_1's rmse: 0.0874825\n",
      "[1000]\ttraining's rmse: 0.0831699\tvalid_1's rmse: 0.0874759\n",
      "[1025]\ttraining's rmse: 0.0831461\tvalid_1's rmse: 0.0874699\n",
      "[1050]\ttraining's rmse: 0.0831253\tvalid_1's rmse: 0.0874635\n",
      "[1075]\ttraining's rmse: 0.0831057\tvalid_1's rmse: 0.0874594\n",
      "[1100]\ttraining's rmse: 0.0830869\tvalid_1's rmse: 0.087455\n",
      "[1125]\ttraining's rmse: 0.0830703\tvalid_1's rmse: 0.0874497\n",
      "[1150]\ttraining's rmse: 0.0830504\tvalid_1's rmse: 0.0874439\n",
      "[1175]\ttraining's rmse: 0.0830321\tvalid_1's rmse: 0.0874406\n",
      "[1200]\ttraining's rmse: 0.0830156\tvalid_1's rmse: 0.0874358\n",
      "[1225]\ttraining's rmse: 0.0829992\tvalid_1's rmse: 0.0874322\n",
      "[1250]\ttraining's rmse: 0.0829837\tvalid_1's rmse: 0.0874277\n",
      "[1275]\ttraining's rmse: 0.0829652\tvalid_1's rmse: 0.0874236\n",
      "[1300]\ttraining's rmse: 0.0829512\tvalid_1's rmse: 0.0874177\n",
      "[1325]\ttraining's rmse: 0.0829362\tvalid_1's rmse: 0.0874153\n",
      "[1350]\ttraining's rmse: 0.0829204\tvalid_1's rmse: 0.0874112\n",
      "[1375]\ttraining's rmse: 0.0829057\tvalid_1's rmse: 0.0874073\n",
      "[1400]\ttraining's rmse: 0.0828942\tvalid_1's rmse: 0.0874036\n",
      "[1425]\ttraining's rmse: 0.082881\tvalid_1's rmse: 0.0874005\n",
      "[1450]\ttraining's rmse: 0.0828652\tvalid_1's rmse: 0.0873971\n",
      "[1475]\ttraining's rmse: 0.0828536\tvalid_1's rmse: 0.087394\n",
      "[1500]\ttraining's rmse: 0.0828444\tvalid_1's rmse: 0.0873912\n",
      "[1525]\ttraining's rmse: 0.082836\tvalid_1's rmse: 0.087388\n",
      "[1550]\ttraining's rmse: 0.0828248\tvalid_1's rmse: 0.087387\n",
      "[1575]\ttraining's rmse: 0.0828158\tvalid_1's rmse: 0.0873847\n",
      "[1600]\ttraining's rmse: 0.0828077\tvalid_1's rmse: 0.0873829\n",
      "[1625]\ttraining's rmse: 0.0827979\tvalid_1's rmse: 0.0873791\n",
      "[1650]\ttraining's rmse: 0.0827888\tvalid_1's rmse: 0.0873759\n",
      "[1675]\ttraining's rmse: 0.0827841\tvalid_1's rmse: 0.0873742\n",
      "[1700]\ttraining's rmse: 0.0827778\tvalid_1's rmse: 0.0873712\n",
      "[1725]\ttraining's rmse: 0.0827715\tvalid_1's rmse: 0.0873691\n",
      "[1750]\ttraining's rmse: 0.0827653\tvalid_1's rmse: 0.0873664\n",
      "[1775]\ttraining's rmse: 0.0827568\tvalid_1's rmse: 0.087365\n",
      "[1800]\ttraining's rmse: 0.0827503\tvalid_1's rmse: 0.087363\n",
      "[1825]\ttraining's rmse: 0.0827434\tvalid_1's rmse: 0.087362\n",
      "[1850]\ttraining's rmse: 0.082739\tvalid_1's rmse: 0.0873606\n",
      "[1875]\ttraining's rmse: 0.0827343\tvalid_1's rmse: 0.0873597\n",
      "[1900]\ttraining's rmse: 0.0827287\tvalid_1's rmse: 0.0873591\n",
      "[1925]\ttraining's rmse: 0.0827244\tvalid_1's rmse: 0.0873588\n",
      "[1950]\ttraining's rmse: 0.0827209\tvalid_1's rmse: 0.0873571\n",
      "[1975]\ttraining's rmse: 0.082716\tvalid_1's rmse: 0.0873553\n",
      "[2000]\ttraining's rmse: 0.0827112\tvalid_1's rmse: 0.0873541\n",
      "[2025]\ttraining's rmse: 0.0827085\tvalid_1's rmse: 0.0873526\n",
      "[2050]\ttraining's rmse: 0.0827025\tvalid_1's rmse: 0.0873513\n",
      "[2075]\ttraining's rmse: 0.0826993\tvalid_1's rmse: 0.0873509\n",
      "[2100]\ttraining's rmse: 0.0826964\tvalid_1's rmse: 0.08735\n",
      "[2125]\ttraining's rmse: 0.0826942\tvalid_1's rmse: 0.08735\n",
      "[2150]\ttraining's rmse: 0.082689\tvalid_1's rmse: 0.0873491\n",
      "[2175]\ttraining's rmse: 0.0826852\tvalid_1's rmse: 0.0873489\n",
      "[2200]\ttraining's rmse: 0.0826826\tvalid_1's rmse: 0.0873488\n",
      "[2225]\ttraining's rmse: 0.0826799\tvalid_1's rmse: 0.0873477\n",
      "[2250]\ttraining's rmse: 0.0826752\tvalid_1's rmse: 0.0873465\n",
      "[2275]\ttraining's rmse: 0.0826719\tvalid_1's rmse: 0.087346\n",
      "[2300]\ttraining's rmse: 0.0826687\tvalid_1's rmse: 0.0873449\n",
      "[2325]\ttraining's rmse: 0.0826659\tvalid_1's rmse: 0.087344\n",
      "[2350]\ttraining's rmse: 0.082663\tvalid_1's rmse: 0.0873431\n",
      "[2375]\ttraining's rmse: 0.0826592\tvalid_1's rmse: 0.0873417\n",
      "[2400]\ttraining's rmse: 0.0826553\tvalid_1's rmse: 0.0873406\n",
      "[2425]\ttraining's rmse: 0.0826535\tvalid_1's rmse: 0.0873397\n",
      "[2450]\ttraining's rmse: 0.0826516\tvalid_1's rmse: 0.0873394\n",
      "[2475]\ttraining's rmse: 0.0826487\tvalid_1's rmse: 0.0873386\n",
      "[2500]\ttraining's rmse: 0.0826464\tvalid_1's rmse: 0.0873374\n",
      "[2525]\ttraining's rmse: 0.0826409\tvalid_1's rmse: 0.0873366\n",
      "[2550]\ttraining's rmse: 0.0826348\tvalid_1's rmse: 0.0873362\n",
      "[2575]\ttraining's rmse: 0.0826326\tvalid_1's rmse: 0.0873362\n",
      "[2600]\ttraining's rmse: 0.0826301\tvalid_1's rmse: 0.0873357\n",
      "[2625]\ttraining's rmse: 0.0826284\tvalid_1's rmse: 0.0873346\n",
      "[2650]\ttraining's rmse: 0.0826255\tvalid_1's rmse: 0.0873337\n",
      "[2675]\ttraining's rmse: 0.0826232\tvalid_1's rmse: 0.0873333\n",
      "[2700]\ttraining's rmse: 0.0826213\tvalid_1's rmse: 0.0873328\n",
      "[2725]\ttraining's rmse: 0.0826197\tvalid_1's rmse: 0.087333\n",
      "[2750]\ttraining's rmse: 0.0826178\tvalid_1's rmse: 0.087333\n",
      "[2775]\ttraining's rmse: 0.082616\tvalid_1's rmse: 0.0873329\n",
      "[2800]\ttraining's rmse: 0.0826146\tvalid_1's rmse: 0.0873328\n",
      "[2825]\ttraining's rmse: 0.0826132\tvalid_1's rmse: 0.087333\n",
      "Early stopping, best iteration is:\n",
      "[2783]\ttraining's rmse: 0.0826152\tvalid_1's rmse: 0.0873326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0858565\tvalid_1's rmse: 0.0877948\n",
      "[50]\ttraining's rmse: 0.0857268\tvalid_1's rmse: 0.0877365\n",
      "[75]\ttraining's rmse: 0.0856008\tvalid_1's rmse: 0.0876804\n",
      "[100]\ttraining's rmse: 0.0854857\tvalid_1's rmse: 0.0876301\n",
      "[125]\ttraining's rmse: 0.0853669\tvalid_1's rmse: 0.0875794\n",
      "[150]\ttraining's rmse: 0.0852555\tvalid_1's rmse: 0.0875341\n",
      "[175]\ttraining's rmse: 0.0851641\tvalid_1's rmse: 0.0874969\n",
      "[200]\ttraining's rmse: 0.0850664\tvalid_1's rmse: 0.0874582\n",
      "[225]\ttraining's rmse: 0.084972\tvalid_1's rmse: 0.0874228\n",
      "[250]\ttraining's rmse: 0.0848919\tvalid_1's rmse: 0.0873905\n",
      "[275]\ttraining's rmse: 0.0848153\tvalid_1's rmse: 0.0873598\n",
      "[300]\ttraining's rmse: 0.0847368\tvalid_1's rmse: 0.0873325\n",
      "[325]\ttraining's rmse: 0.0846604\tvalid_1's rmse: 0.0873057\n",
      "[350]\ttraining's rmse: 0.0845853\tvalid_1's rmse: 0.0872792\n",
      "[375]\ttraining's rmse: 0.0845281\tvalid_1's rmse: 0.0872572\n",
      "[400]\ttraining's rmse: 0.0844601\tvalid_1's rmse: 0.0872352\n",
      "[425]\ttraining's rmse: 0.084401\tvalid_1's rmse: 0.0872141\n",
      "[450]\ttraining's rmse: 0.084347\tvalid_1's rmse: 0.0871945\n",
      "[475]\ttraining's rmse: 0.0842952\tvalid_1's rmse: 0.087176\n",
      "[500]\ttraining's rmse: 0.0842491\tvalid_1's rmse: 0.087159\n",
      "[525]\ttraining's rmse: 0.0841926\tvalid_1's rmse: 0.0871421\n",
      "[550]\ttraining's rmse: 0.0841395\tvalid_1's rmse: 0.0871267\n",
      "[575]\ttraining's rmse: 0.0840919\tvalid_1's rmse: 0.0871126\n",
      "[600]\ttraining's rmse: 0.0840451\tvalid_1's rmse: 0.0870984\n",
      "[625]\ttraining's rmse: 0.0840079\tvalid_1's rmse: 0.0870858\n",
      "[650]\ttraining's rmse: 0.0839601\tvalid_1's rmse: 0.0870725\n",
      "[675]\ttraining's rmse: 0.0839143\tvalid_1's rmse: 0.0870604\n",
      "[700]\ttraining's rmse: 0.0838745\tvalid_1's rmse: 0.0870495\n",
      "[725]\ttraining's rmse: 0.0838352\tvalid_1's rmse: 0.087039\n",
      "[750]\ttraining's rmse: 0.0838006\tvalid_1's rmse: 0.0870299\n",
      "[775]\ttraining's rmse: 0.083771\tvalid_1's rmse: 0.087021\n",
      "[800]\ttraining's rmse: 0.0837333\tvalid_1's rmse: 0.0870125\n",
      "[825]\ttraining's rmse: 0.0836995\tvalid_1's rmse: 0.0870042\n",
      "[850]\ttraining's rmse: 0.0836664\tvalid_1's rmse: 0.0869973\n",
      "[875]\ttraining's rmse: 0.0836378\tvalid_1's rmse: 0.0869909\n",
      "[900]\ttraining's rmse: 0.0836094\tvalid_1's rmse: 0.0869839\n",
      "[925]\ttraining's rmse: 0.0835803\tvalid_1's rmse: 0.0869778\n",
      "[950]\ttraining's rmse: 0.0835554\tvalid_1's rmse: 0.0869725\n",
      "[975]\ttraining's rmse: 0.0835316\tvalid_1's rmse: 0.0869669\n",
      "[1000]\ttraining's rmse: 0.0835072\tvalid_1's rmse: 0.0869614\n",
      "[1025]\ttraining's rmse: 0.0834819\tvalid_1's rmse: 0.0869568\n",
      "[1050]\ttraining's rmse: 0.0834599\tvalid_1's rmse: 0.0869521\n",
      "[1075]\ttraining's rmse: 0.083438\tvalid_1's rmse: 0.0869485\n",
      "[1100]\ttraining's rmse: 0.0834188\tvalid_1's rmse: 0.086945\n",
      "[1125]\ttraining's rmse: 0.0833979\tvalid_1's rmse: 0.086941\n",
      "[1150]\ttraining's rmse: 0.0833789\tvalid_1's rmse: 0.0869383\n",
      "[1175]\ttraining's rmse: 0.0833625\tvalid_1's rmse: 0.0869352\n",
      "[1200]\ttraining's rmse: 0.0833426\tvalid_1's rmse: 0.086932\n",
      "[1225]\ttraining's rmse: 0.0833263\tvalid_1's rmse: 0.0869296\n",
      "[1250]\ttraining's rmse: 0.0833122\tvalid_1's rmse: 0.086927\n",
      "[1275]\ttraining's rmse: 0.0832971\tvalid_1's rmse: 0.0869249\n",
      "[1300]\ttraining's rmse: 0.0832833\tvalid_1's rmse: 0.0869218\n",
      "[1325]\ttraining's rmse: 0.0832683\tvalid_1's rmse: 0.0869194\n",
      "[1350]\ttraining's rmse: 0.0832531\tvalid_1's rmse: 0.0869168\n",
      "[1375]\ttraining's rmse: 0.0832383\tvalid_1's rmse: 0.0869152\n",
      "[1400]\ttraining's rmse: 0.0832262\tvalid_1's rmse: 0.0869128\n",
      "[1425]\ttraining's rmse: 0.0832133\tvalid_1's rmse: 0.086911\n",
      "[1450]\ttraining's rmse: 0.0831995\tvalid_1's rmse: 0.0869097\n",
      "[1475]\ttraining's rmse: 0.0831882\tvalid_1's rmse: 0.0869078\n",
      "[1500]\ttraining's rmse: 0.0831771\tvalid_1's rmse: 0.0869066\n",
      "[1525]\ttraining's rmse: 0.0831675\tvalid_1's rmse: 0.0869049\n",
      "[1550]\ttraining's rmse: 0.083158\tvalid_1's rmse: 0.0869038\n",
      "[1575]\ttraining's rmse: 0.0831478\tvalid_1's rmse: 0.0869025\n",
      "[1600]\ttraining's rmse: 0.0831397\tvalid_1's rmse: 0.0869018\n",
      "[1625]\ttraining's rmse: 0.0831313\tvalid_1's rmse: 0.0869001\n",
      "[1650]\ttraining's rmse: 0.0831222\tvalid_1's rmse: 0.086899\n",
      "[1675]\ttraining's rmse: 0.0831158\tvalid_1's rmse: 0.0868981\n",
      "[1700]\ttraining's rmse: 0.083109\tvalid_1's rmse: 0.0868968\n",
      "[1725]\ttraining's rmse: 0.0831017\tvalid_1's rmse: 0.0868961\n",
      "[1750]\ttraining's rmse: 0.0830941\tvalid_1's rmse: 0.0868953\n",
      "[1775]\ttraining's rmse: 0.083086\tvalid_1's rmse: 0.0868954\n",
      "[1800]\ttraining's rmse: 0.0830791\tvalid_1's rmse: 0.0868945\n",
      "[1825]\ttraining's rmse: 0.0830724\tvalid_1's rmse: 0.0868943\n",
      "[1850]\ttraining's rmse: 0.0830673\tvalid_1's rmse: 0.0868937\n",
      "[1875]\ttraining's rmse: 0.0830614\tvalid_1's rmse: 0.0868933\n",
      "[1900]\ttraining's rmse: 0.083058\tvalid_1's rmse: 0.0868932\n",
      "[1925]\ttraining's rmse: 0.0830535\tvalid_1's rmse: 0.0868928\n",
      "[1950]\ttraining's rmse: 0.0830495\tvalid_1's rmse: 0.0868919\n",
      "[1975]\ttraining's rmse: 0.0830453\tvalid_1's rmse: 0.0868914\n",
      "[2000]\ttraining's rmse: 0.0830394\tvalid_1's rmse: 0.0868907\n",
      "[2025]\ttraining's rmse: 0.0830341\tvalid_1's rmse: 0.0868902\n",
      "[2050]\ttraining's rmse: 0.0830304\tvalid_1's rmse: 0.0868899\n",
      "[2075]\ttraining's rmse: 0.0830261\tvalid_1's rmse: 0.0868894\n",
      "[2100]\ttraining's rmse: 0.0830232\tvalid_1's rmse: 0.0868892\n",
      "[2125]\ttraining's rmse: 0.0830203\tvalid_1's rmse: 0.0868892\n",
      "Early stopping, best iteration is:\n",
      "[2097]\ttraining's rmse: 0.0830233\tvalid_1's rmse: 0.0868891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0879468\tvalid_1's rmse: 0.0835522\n",
      "[50]\ttraining's rmse: 0.0878275\tvalid_1's rmse: 0.083504\n",
      "[75]\ttraining's rmse: 0.0877051\tvalid_1's rmse: 0.083454\n",
      "[100]\ttraining's rmse: 0.0875935\tvalid_1's rmse: 0.0834099\n",
      "[125]\ttraining's rmse: 0.0874813\tvalid_1's rmse: 0.0833667\n",
      "[150]\ttraining's rmse: 0.0873743\tvalid_1's rmse: 0.0833272\n",
      "[175]\ttraining's rmse: 0.0872865\tvalid_1's rmse: 0.0832949\n",
      "[200]\ttraining's rmse: 0.0871907\tvalid_1's rmse: 0.0832645\n",
      "[225]\ttraining's rmse: 0.0871002\tvalid_1's rmse: 0.0832335\n",
      "[250]\ttraining's rmse: 0.087023\tvalid_1's rmse: 0.0832076\n",
      "[275]\ttraining's rmse: 0.0869553\tvalid_1's rmse: 0.083183\n",
      "[300]\ttraining's rmse: 0.086884\tvalid_1's rmse: 0.0831589\n",
      "[325]\ttraining's rmse: 0.0868125\tvalid_1's rmse: 0.0831355\n",
      "[350]\ttraining's rmse: 0.0867428\tvalid_1's rmse: 0.0831126\n",
      "[375]\ttraining's rmse: 0.086683\tvalid_1's rmse: 0.0830945\n",
      "[400]\ttraining's rmse: 0.0866219\tvalid_1's rmse: 0.0830835\n",
      "[425]\ttraining's rmse: 0.0865645\tvalid_1's rmse: 0.0830673\n",
      "[450]\ttraining's rmse: 0.0865113\tvalid_1's rmse: 0.083052\n",
      "[475]\ttraining's rmse: 0.0864615\tvalid_1's rmse: 0.0830377\n",
      "[500]\ttraining's rmse: 0.0864192\tvalid_1's rmse: 0.0830268\n",
      "[525]\ttraining's rmse: 0.0863645\tvalid_1's rmse: 0.0830177\n",
      "[550]\ttraining's rmse: 0.0863157\tvalid_1's rmse: 0.0830043\n",
      "[575]\ttraining's rmse: 0.0862697\tvalid_1's rmse: 0.082997\n",
      "[600]\ttraining's rmse: 0.086224\tvalid_1's rmse: 0.082987\n",
      "[625]\ttraining's rmse: 0.0861891\tvalid_1's rmse: 0.0829789\n",
      "[650]\ttraining's rmse: 0.0861443\tvalid_1's rmse: 0.0829682\n",
      "[675]\ttraining's rmse: 0.0860992\tvalid_1's rmse: 0.0829645\n",
      "[700]\ttraining's rmse: 0.0860585\tvalid_1's rmse: 0.0829654\n",
      "[725]\ttraining's rmse: 0.0860192\tvalid_1's rmse: 0.082973\n",
      "Early stopping, best iteration is:\n",
      "[681]\ttraining's rmse: 0.0860895\tvalid_1's rmse: 0.0829631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0894534\tvalid_1's rmse: 0.0910234\n",
      "[50]\ttraining's rmse: 0.0892645\tvalid_1's rmse: 0.0909715\n",
      "[75]\ttraining's rmse: 0.0890812\tvalid_1's rmse: 0.09092\n",
      "[100]\ttraining's rmse: 0.0889093\tvalid_1's rmse: 0.0908736\n",
      "[125]\ttraining's rmse: 0.0887388\tvalid_1's rmse: 0.090826\n",
      "[150]\ttraining's rmse: 0.0885815\tvalid_1's rmse: 0.0907828\n",
      "[175]\ttraining's rmse: 0.0884495\tvalid_1's rmse: 0.090746\n",
      "[200]\ttraining's rmse: 0.0883096\tvalid_1's rmse: 0.0907119\n",
      "[225]\ttraining's rmse: 0.0881769\tvalid_1's rmse: 0.0906771\n",
      "[250]\ttraining's rmse: 0.0880605\tvalid_1's rmse: 0.0906442\n",
      "[275]\ttraining's rmse: 0.087954\tvalid_1's rmse: 0.0906153\n",
      "[300]\ttraining's rmse: 0.0878451\tvalid_1's rmse: 0.0905872\n",
      "[325]\ttraining's rmse: 0.0877442\tvalid_1's rmse: 0.0905613\n",
      "[350]\ttraining's rmse: 0.0876449\tvalid_1's rmse: 0.0905346\n",
      "[375]\ttraining's rmse: 0.0875593\tvalid_1's rmse: 0.0905138\n",
      "[400]\ttraining's rmse: 0.0874633\tvalid_1's rmse: 0.0904918\n",
      "[425]\ttraining's rmse: 0.0873827\tvalid_1's rmse: 0.0904707\n",
      "[450]\ttraining's rmse: 0.0873071\tvalid_1's rmse: 0.0904514\n",
      "[475]\ttraining's rmse: 0.0872397\tvalid_1's rmse: 0.090432\n",
      "[500]\ttraining's rmse: 0.0871797\tvalid_1's rmse: 0.090415\n",
      "[525]\ttraining's rmse: 0.087109\tvalid_1's rmse: 0.0903988\n",
      "[550]\ttraining's rmse: 0.0870456\tvalid_1's rmse: 0.0903831\n",
      "[575]\ttraining's rmse: 0.0869864\tvalid_1's rmse: 0.0903698\n",
      "[600]\ttraining's rmse: 0.0869293\tvalid_1's rmse: 0.0903561\n",
      "[625]\ttraining's rmse: 0.0868825\tvalid_1's rmse: 0.0903438\n",
      "[650]\ttraining's rmse: 0.0868314\tvalid_1's rmse: 0.090332\n",
      "[675]\ttraining's rmse: 0.0867766\tvalid_1's rmse: 0.0903201\n",
      "[700]\ttraining's rmse: 0.0867294\tvalid_1's rmse: 0.0903091\n",
      "[725]\ttraining's rmse: 0.0866849\tvalid_1's rmse: 0.0902981\n",
      "[750]\ttraining's rmse: 0.0866422\tvalid_1's rmse: 0.0902886\n",
      "[775]\ttraining's rmse: 0.0866051\tvalid_1's rmse: 0.0902783\n",
      "[800]\ttraining's rmse: 0.0865583\tvalid_1's rmse: 0.0902701\n",
      "[825]\ttraining's rmse: 0.0865205\tvalid_1's rmse: 0.0902619\n",
      "[850]\ttraining's rmse: 0.0864818\tvalid_1's rmse: 0.0902527\n",
      "[875]\ttraining's rmse: 0.0864483\tvalid_1's rmse: 0.0902448\n",
      "[900]\ttraining's rmse: 0.0864082\tvalid_1's rmse: 0.090237\n",
      "[925]\ttraining's rmse: 0.0863758\tvalid_1's rmse: 0.0902286\n",
      "[950]\ttraining's rmse: 0.086344\tvalid_1's rmse: 0.090222\n",
      "[975]\ttraining's rmse: 0.0863149\tvalid_1's rmse: 0.0902154\n",
      "[1000]\ttraining's rmse: 0.0862877\tvalid_1's rmse: 0.0902087\n",
      "[1025]\ttraining's rmse: 0.0862598\tvalid_1's rmse: 0.0902019\n",
      "[1050]\ttraining's rmse: 0.0862342\tvalid_1's rmse: 0.0901961\n",
      "[1075]\ttraining's rmse: 0.0862095\tvalid_1's rmse: 0.0901903\n",
      "[1100]\ttraining's rmse: 0.0861858\tvalid_1's rmse: 0.0901844\n",
      "[1125]\ttraining's rmse: 0.0861633\tvalid_1's rmse: 0.0901787\n",
      "[1150]\ttraining's rmse: 0.0861431\tvalid_1's rmse: 0.0901734\n",
      "[1175]\ttraining's rmse: 0.0861228\tvalid_1's rmse: 0.0901695\n",
      "[1200]\ttraining's rmse: 0.0861054\tvalid_1's rmse: 0.0901639\n",
      "[1225]\ttraining's rmse: 0.0860857\tvalid_1's rmse: 0.090158\n",
      "[1250]\ttraining's rmse: 0.0860693\tvalid_1's rmse: 0.0901526\n",
      "[1275]\ttraining's rmse: 0.0860501\tvalid_1's rmse: 0.0901496\n",
      "[1300]\ttraining's rmse: 0.0860356\tvalid_1's rmse: 0.0901462\n",
      "[1325]\ttraining's rmse: 0.0860176\tvalid_1's rmse: 0.090142\n",
      "[1350]\ttraining's rmse: 0.0860034\tvalid_1's rmse: 0.0901386\n",
      "[1375]\ttraining's rmse: 0.0859861\tvalid_1's rmse: 0.0901352\n",
      "[1400]\ttraining's rmse: 0.0859729\tvalid_1's rmse: 0.0901316\n",
      "[1425]\ttraining's rmse: 0.0859578\tvalid_1's rmse: 0.0901291\n",
      "[1450]\ttraining's rmse: 0.0859419\tvalid_1's rmse: 0.0901263\n",
      "[1475]\ttraining's rmse: 0.085931\tvalid_1's rmse: 0.0901225\n",
      "[1500]\ttraining's rmse: 0.0859206\tvalid_1's rmse: 0.09012\n",
      "[1525]\ttraining's rmse: 0.0859086\tvalid_1's rmse: 0.0901164\n",
      "[1550]\ttraining's rmse: 0.0858966\tvalid_1's rmse: 0.0901133\n",
      "[1575]\ttraining's rmse: 0.0858846\tvalid_1's rmse: 0.0901108\n",
      "[1600]\ttraining's rmse: 0.0858744\tvalid_1's rmse: 0.0901079\n",
      "[1625]\ttraining's rmse: 0.0858636\tvalid_1's rmse: 0.0901048\n",
      "[1650]\ttraining's rmse: 0.0858532\tvalid_1's rmse: 0.0901015\n",
      "[1675]\ttraining's rmse: 0.0858456\tvalid_1's rmse: 0.0900994\n",
      "[1700]\ttraining's rmse: 0.0858399\tvalid_1's rmse: 0.0900966\n",
      "[1725]\ttraining's rmse: 0.0858321\tvalid_1's rmse: 0.0900953\n",
      "[1750]\ttraining's rmse: 0.0858233\tvalid_1's rmse: 0.0900937\n",
      "[1775]\ttraining's rmse: 0.085815\tvalid_1's rmse: 0.0900925\n",
      "[1800]\ttraining's rmse: 0.0858082\tvalid_1's rmse: 0.0900909\n",
      "[1825]\ttraining's rmse: 0.0858\tvalid_1's rmse: 0.090088\n",
      "[1850]\ttraining's rmse: 0.085794\tvalid_1's rmse: 0.0900856\n",
      "[1875]\ttraining's rmse: 0.0857883\tvalid_1's rmse: 0.0900835\n",
      "[1900]\ttraining's rmse: 0.0857795\tvalid_1's rmse: 0.0900819\n",
      "[1925]\ttraining's rmse: 0.0857718\tvalid_1's rmse: 0.0900805\n",
      "[1950]\ttraining's rmse: 0.0857668\tvalid_1's rmse: 0.090078\n",
      "[1975]\ttraining's rmse: 0.0857632\tvalid_1's rmse: 0.0900766\n",
      "[2000]\ttraining's rmse: 0.0857584\tvalid_1's rmse: 0.0900753\n",
      "[2025]\ttraining's rmse: 0.0857539\tvalid_1's rmse: 0.0900738\n",
      "[2050]\ttraining's rmse: 0.0857481\tvalid_1's rmse: 0.0900709\n",
      "[2075]\ttraining's rmse: 0.0857443\tvalid_1's rmse: 0.0900693\n",
      "[2100]\ttraining's rmse: 0.085739\tvalid_1's rmse: 0.0900679\n",
      "[2125]\ttraining's rmse: 0.0857343\tvalid_1's rmse: 0.0900669\n",
      "[2150]\ttraining's rmse: 0.0857315\tvalid_1's rmse: 0.0900664\n",
      "[2175]\ttraining's rmse: 0.0857286\tvalid_1's rmse: 0.0900656\n",
      "[2200]\ttraining's rmse: 0.0857226\tvalid_1's rmse: 0.0900648\n",
      "[2225]\ttraining's rmse: 0.0857183\tvalid_1's rmse: 0.090063\n",
      "[2250]\ttraining's rmse: 0.0857154\tvalid_1's rmse: 0.0900629\n",
      "[2275]\ttraining's rmse: 0.0857117\tvalid_1's rmse: 0.0900619\n",
      "[2300]\ttraining's rmse: 0.0857081\tvalid_1's rmse: 0.0900613\n",
      "[2325]\ttraining's rmse: 0.0857042\tvalid_1's rmse: 0.0900603\n",
      "[2350]\ttraining's rmse: 0.0857011\tvalid_1's rmse: 0.0900586\n",
      "[2375]\ttraining's rmse: 0.0856974\tvalid_1's rmse: 0.0900578\n",
      "[2400]\ttraining's rmse: 0.0856932\tvalid_1's rmse: 0.0900565\n",
      "[2425]\ttraining's rmse: 0.0856888\tvalid_1's rmse: 0.0900561\n",
      "[2450]\ttraining's rmse: 0.0856852\tvalid_1's rmse: 0.090055\n",
      "[2475]\ttraining's rmse: 0.0856816\tvalid_1's rmse: 0.0900551\n",
      "[2500]\ttraining's rmse: 0.085679\tvalid_1's rmse: 0.0900547\n",
      "[2525]\ttraining's rmse: 0.0856774\tvalid_1's rmse: 0.0900537\n",
      "[2550]\ttraining's rmse: 0.0856748\tvalid_1's rmse: 0.0900531\n",
      "[2575]\ttraining's rmse: 0.0856723\tvalid_1's rmse: 0.0900524\n",
      "[2600]\ttraining's rmse: 0.0856704\tvalid_1's rmse: 0.0900523\n",
      "[2625]\ttraining's rmse: 0.0856685\tvalid_1's rmse: 0.0900517\n",
      "[2650]\ttraining's rmse: 0.085667\tvalid_1's rmse: 0.0900512\n",
      "[2675]\ttraining's rmse: 0.0856648\tvalid_1's rmse: 0.0900503\n",
      "[2700]\ttraining's rmse: 0.0856628\tvalid_1's rmse: 0.0900499\n",
      "[2725]\ttraining's rmse: 0.0856605\tvalid_1's rmse: 0.0900496\n",
      "[2750]\ttraining's rmse: 0.0856588\tvalid_1's rmse: 0.0900495\n",
      "[2775]\ttraining's rmse: 0.085657\tvalid_1's rmse: 0.0900492\n",
      "[2800]\ttraining's rmse: 0.0856542\tvalid_1's rmse: 0.0900485\n",
      "[2825]\ttraining's rmse: 0.0856517\tvalid_1's rmse: 0.0900484\n",
      "[2850]\ttraining's rmse: 0.0856505\tvalid_1's rmse: 0.0900485\n",
      "[2875]\ttraining's rmse: 0.0856494\tvalid_1's rmse: 0.0900482\n",
      "[2900]\ttraining's rmse: 0.0856474\tvalid_1's rmse: 0.0900477\n",
      "[2925]\ttraining's rmse: 0.0856457\tvalid_1's rmse: 0.090047\n",
      "[2950]\ttraining's rmse: 0.0856447\tvalid_1's rmse: 0.0900468\n",
      "[2975]\ttraining's rmse: 0.085643\tvalid_1's rmse: 0.090047\n",
      "Early stopping, best iteration is:\n",
      "[2936]\ttraining's rmse: 0.0856453\tvalid_1's rmse: 0.0900467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0893076\tvalid_1's rmse: 0.091337\n",
      "[50]\ttraining's rmse: 0.0891407\tvalid_1's rmse: 0.0912813\n",
      "[75]\ttraining's rmse: 0.0889699\tvalid_1's rmse: 0.0912269\n",
      "[100]\ttraining's rmse: 0.0888175\tvalid_1's rmse: 0.0911791\n",
      "[125]\ttraining's rmse: 0.0886614\tvalid_1's rmse: 0.0911309\n",
      "[150]\ttraining's rmse: 0.0885212\tvalid_1's rmse: 0.0910863\n",
      "[175]\ttraining's rmse: 0.0884008\tvalid_1's rmse: 0.0910488\n",
      "[200]\ttraining's rmse: 0.0882783\tvalid_1's rmse: 0.0910105\n",
      "[225]\ttraining's rmse: 0.0881572\tvalid_1's rmse: 0.0909741\n",
      "[250]\ttraining's rmse: 0.0880548\tvalid_1's rmse: 0.0909414\n",
      "[275]\ttraining's rmse: 0.0879577\tvalid_1's rmse: 0.0909115\n",
      "[300]\ttraining's rmse: 0.0878604\tvalid_1's rmse: 0.0908829\n",
      "[325]\ttraining's rmse: 0.0877671\tvalid_1's rmse: 0.0908566\n",
      "[350]\ttraining's rmse: 0.0876771\tvalid_1's rmse: 0.0908321\n",
      "[375]\ttraining's rmse: 0.0876036\tvalid_1's rmse: 0.0908096\n",
      "[400]\ttraining's rmse: 0.0875225\tvalid_1's rmse: 0.090788\n",
      "[425]\ttraining's rmse: 0.0874495\tvalid_1's rmse: 0.0907672\n",
      "[450]\ttraining's rmse: 0.087384\tvalid_1's rmse: 0.090747\n",
      "[475]\ttraining's rmse: 0.0873209\tvalid_1's rmse: 0.0907283\n",
      "[500]\ttraining's rmse: 0.0872694\tvalid_1's rmse: 0.0907114\n",
      "[525]\ttraining's rmse: 0.0872043\tvalid_1's rmse: 0.0906938\n",
      "[550]\ttraining's rmse: 0.0871456\tvalid_1's rmse: 0.0906788\n",
      "[575]\ttraining's rmse: 0.0870898\tvalid_1's rmse: 0.0906638\n",
      "[600]\ttraining's rmse: 0.08704\tvalid_1's rmse: 0.0906499\n",
      "[625]\ttraining's rmse: 0.0869994\tvalid_1's rmse: 0.0906379\n",
      "[650]\ttraining's rmse: 0.0869444\tvalid_1's rmse: 0.0906245\n",
      "[675]\ttraining's rmse: 0.086895\tvalid_1's rmse: 0.0906132\n",
      "[700]\ttraining's rmse: 0.0868496\tvalid_1's rmse: 0.0906018\n",
      "[725]\ttraining's rmse: 0.0868083\tvalid_1's rmse: 0.0905912\n",
      "[750]\ttraining's rmse: 0.0867704\tvalid_1's rmse: 0.0905827\n",
      "[775]\ttraining's rmse: 0.0867371\tvalid_1's rmse: 0.0905727\n",
      "[800]\ttraining's rmse: 0.086694\tvalid_1's rmse: 0.0905639\n",
      "[825]\ttraining's rmse: 0.0866613\tvalid_1's rmse: 0.0905547\n",
      "[850]\ttraining's rmse: 0.086625\tvalid_1's rmse: 0.0905469\n",
      "[875]\ttraining's rmse: 0.0865941\tvalid_1's rmse: 0.0905403\n",
      "[900]\ttraining's rmse: 0.0865589\tvalid_1's rmse: 0.0905325\n",
      "[925]\ttraining's rmse: 0.0865283\tvalid_1's rmse: 0.0905262\n",
      "[950]\ttraining's rmse: 0.0864987\tvalid_1's rmse: 0.0905198\n",
      "[975]\ttraining's rmse: 0.0864721\tvalid_1's rmse: 0.0905148\n",
      "[1000]\ttraining's rmse: 0.0864471\tvalid_1's rmse: 0.0905094\n",
      "[1025]\ttraining's rmse: 0.0864206\tvalid_1's rmse: 0.0905053\n",
      "[1050]\ttraining's rmse: 0.0863986\tvalid_1's rmse: 0.0905001\n",
      "[1075]\ttraining's rmse: 0.0863748\tvalid_1's rmse: 0.0904966\n",
      "[1100]\ttraining's rmse: 0.0863524\tvalid_1's rmse: 0.090492\n",
      "[1125]\ttraining's rmse: 0.0863292\tvalid_1's rmse: 0.090487\n",
      "[1150]\ttraining's rmse: 0.0863062\tvalid_1's rmse: 0.0904832\n",
      "[1175]\ttraining's rmse: 0.0862885\tvalid_1's rmse: 0.0904807\n",
      "[1200]\ttraining's rmse: 0.0862708\tvalid_1's rmse: 0.0904769\n",
      "[1225]\ttraining's rmse: 0.0862529\tvalid_1's rmse: 0.0904735\n",
      "[1250]\ttraining's rmse: 0.0862365\tvalid_1's rmse: 0.0904707\n",
      "[1275]\ttraining's rmse: 0.0862186\tvalid_1's rmse: 0.0904688\n",
      "[1300]\ttraining's rmse: 0.086204\tvalid_1's rmse: 0.0904664\n",
      "[1325]\ttraining's rmse: 0.0861858\tvalid_1's rmse: 0.0904639\n",
      "[1350]\ttraining's rmse: 0.0861701\tvalid_1's rmse: 0.090462\n",
      "[1375]\ttraining's rmse: 0.0861544\tvalid_1's rmse: 0.0904607\n",
      "[1400]\ttraining's rmse: 0.0861401\tvalid_1's rmse: 0.0904577\n",
      "[1425]\ttraining's rmse: 0.086125\tvalid_1's rmse: 0.0904558\n",
      "[1450]\ttraining's rmse: 0.0861084\tvalid_1's rmse: 0.0904543\n",
      "[1475]\ttraining's rmse: 0.0860967\tvalid_1's rmse: 0.0904524\n",
      "[1500]\ttraining's rmse: 0.0860839\tvalid_1's rmse: 0.090451\n",
      "[1525]\ttraining's rmse: 0.0860713\tvalid_1's rmse: 0.09045\n",
      "[1550]\ttraining's rmse: 0.0860621\tvalid_1's rmse: 0.0904493\n",
      "[1575]\ttraining's rmse: 0.0860521\tvalid_1's rmse: 0.0904477\n",
      "[1600]\ttraining's rmse: 0.0860434\tvalid_1's rmse: 0.0904462\n",
      "[1625]\ttraining's rmse: 0.0860342\tvalid_1's rmse: 0.0904443\n",
      "[1650]\ttraining's rmse: 0.0860239\tvalid_1's rmse: 0.0904432\n",
      "[1675]\ttraining's rmse: 0.0860156\tvalid_1's rmse: 0.090442\n",
      "[1700]\ttraining's rmse: 0.0860078\tvalid_1's rmse: 0.0904406\n",
      "[1725]\ttraining's rmse: 0.0859997\tvalid_1's rmse: 0.0904398\n",
      "[1750]\ttraining's rmse: 0.0859928\tvalid_1's rmse: 0.0904391\n",
      "[1775]\ttraining's rmse: 0.0859847\tvalid_1's rmse: 0.0904387\n",
      "[1800]\ttraining's rmse: 0.0859769\tvalid_1's rmse: 0.0904381\n",
      "[1825]\ttraining's rmse: 0.0859689\tvalid_1's rmse: 0.0904376\n",
      "[1850]\ttraining's rmse: 0.0859625\tvalid_1's rmse: 0.0904369\n",
      "[1875]\ttraining's rmse: 0.085957\tvalid_1's rmse: 0.0904369\n",
      "[1900]\ttraining's rmse: 0.0859526\tvalid_1's rmse: 0.0904367\n",
      "[1925]\ttraining's rmse: 0.0859455\tvalid_1's rmse: 0.0904354\n",
      "[1950]\ttraining's rmse: 0.0859404\tvalid_1's rmse: 0.0904345\n",
      "[1975]\ttraining's rmse: 0.0859348\tvalid_1's rmse: 0.090434\n",
      "[2000]\ttraining's rmse: 0.0859301\tvalid_1's rmse: 0.0904336\n",
      "[2025]\ttraining's rmse: 0.0859267\tvalid_1's rmse: 0.090433\n",
      "[2050]\ttraining's rmse: 0.0859202\tvalid_1's rmse: 0.0904325\n",
      "[2075]\ttraining's rmse: 0.0859158\tvalid_1's rmse: 0.0904321\n",
      "[2100]\ttraining's rmse: 0.0859127\tvalid_1's rmse: 0.0904318\n",
      "[2125]\ttraining's rmse: 0.085908\tvalid_1's rmse: 0.0904312\n",
      "[2150]\ttraining's rmse: 0.0859044\tvalid_1's rmse: 0.0904311\n",
      "[2175]\ttraining's rmse: 0.0859009\tvalid_1's rmse: 0.090431\n",
      "[2200]\ttraining's rmse: 0.0858974\tvalid_1's rmse: 0.0904302\n",
      "[2225]\ttraining's rmse: 0.085894\tvalid_1's rmse: 0.0904301\n",
      "[2250]\ttraining's rmse: 0.0858901\tvalid_1's rmse: 0.09043\n",
      "[2275]\ttraining's rmse: 0.085887\tvalid_1's rmse: 0.0904302\n",
      "[2300]\ttraining's rmse: 0.085884\tvalid_1's rmse: 0.09043\n",
      "[2325]\ttraining's rmse: 0.0858784\tvalid_1's rmse: 0.0904294\n",
      "[2350]\ttraining's rmse: 0.0858763\tvalid_1's rmse: 0.0904291\n",
      "[2375]\ttraining's rmse: 0.0858731\tvalid_1's rmse: 0.0904287\n",
      "[2400]\ttraining's rmse: 0.0858707\tvalid_1's rmse: 0.0904287\n",
      "[2425]\ttraining's rmse: 0.0858688\tvalid_1's rmse: 0.0904284\n",
      "[2450]\ttraining's rmse: 0.0858651\tvalid_1's rmse: 0.0904283\n",
      "[2475]\ttraining's rmse: 0.0858619\tvalid_1's rmse: 0.0904286\n",
      "[2500]\ttraining's rmse: 0.0858594\tvalid_1's rmse: 0.0904285\n",
      "Early stopping, best iteration is:\n",
      "[2457]\ttraining's rmse: 0.0858639\tvalid_1's rmse: 0.0904282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0910297\tvalid_1's rmse: 0.0879134\n",
      "[50]\ttraining's rmse: 0.0908965\tvalid_1's rmse: 0.0878652\n",
      "[75]\ttraining's rmse: 0.0907526\tvalid_1's rmse: 0.0878166\n",
      "[100]\ttraining's rmse: 0.0906242\tvalid_1's rmse: 0.0877749\n",
      "[125]\ttraining's rmse: 0.0904931\tvalid_1's rmse: 0.0877328\n",
      "[150]\ttraining's rmse: 0.0903719\tvalid_1's rmse: 0.087696\n",
      "[175]\ttraining's rmse: 0.0902713\tvalid_1's rmse: 0.0876627\n",
      "[200]\ttraining's rmse: 0.0901609\tvalid_1's rmse: 0.0876321\n",
      "[225]\ttraining's rmse: 0.0900536\tvalid_1's rmse: 0.087601\n",
      "[250]\ttraining's rmse: 0.0899617\tvalid_1's rmse: 0.0875749\n",
      "[275]\ttraining's rmse: 0.0898788\tvalid_1's rmse: 0.087549\n",
      "[300]\ttraining's rmse: 0.0897924\tvalid_1's rmse: 0.0875259\n",
      "[325]\ttraining's rmse: 0.0897055\tvalid_1's rmse: 0.0875046\n",
      "[350]\ttraining's rmse: 0.0896248\tvalid_1's rmse: 0.0874815\n",
      "[375]\ttraining's rmse: 0.0895597\tvalid_1's rmse: 0.0874696\n",
      "[400]\ttraining's rmse: 0.0894873\tvalid_1's rmse: 0.0874522\n",
      "[425]\ttraining's rmse: 0.0894186\tvalid_1's rmse: 0.0874389\n",
      "[450]\ttraining's rmse: 0.0893544\tvalid_1's rmse: 0.0874246\n",
      "[475]\ttraining's rmse: 0.0892967\tvalid_1's rmse: 0.0874104\n",
      "[500]\ttraining's rmse: 0.0892495\tvalid_1's rmse: 0.0873985\n",
      "[525]\ttraining's rmse: 0.0891832\tvalid_1's rmse: 0.0873855\n",
      "[550]\ttraining's rmse: 0.0891255\tvalid_1's rmse: 0.0873834\n",
      "[575]\ttraining's rmse: 0.0890723\tvalid_1's rmse: 0.0873731\n",
      "[600]\ttraining's rmse: 0.0890204\tvalid_1's rmse: 0.0873649\n",
      "[625]\ttraining's rmse: 0.0889784\tvalid_1's rmse: 0.0873599\n",
      "[650]\ttraining's rmse: 0.0889247\tvalid_1's rmse: 0.0873516\n",
      "[675]\ttraining's rmse: 0.0888722\tvalid_1's rmse: 0.0873534\n",
      "[700]\ttraining's rmse: 0.0888275\tvalid_1's rmse: 0.0873533\n",
      "[725]\ttraining's rmse: 0.0887847\tvalid_1's rmse: 0.0873482\n",
      "[750]\ttraining's rmse: 0.0887447\tvalid_1's rmse: 0.0873422\n",
      "[775]\ttraining's rmse: 0.0887117\tvalid_1's rmse: 0.0873371\n",
      "[800]\ttraining's rmse: 0.088667\tvalid_1's rmse: 0.0873338\n",
      "[825]\ttraining's rmse: 0.0886313\tvalid_1's rmse: 0.0873402\n",
      "[850]\ttraining's rmse: 0.088595\tvalid_1's rmse: 0.0873353\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's rmse: 0.0886531\tvalid_1's rmse: 0.0873327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0858539\tvalid_1's rmse: 0.0886434\n",
      "[50]\ttraining's rmse: 0.0857141\tvalid_1's rmse: 0.0885852\n",
      "[75]\ttraining's rmse: 0.0855772\tvalid_1's rmse: 0.0885286\n",
      "[100]\ttraining's rmse: 0.0854503\tvalid_1's rmse: 0.0884791\n",
      "[125]\ttraining's rmse: 0.0853235\tvalid_1's rmse: 0.0884298\n",
      "[150]\ttraining's rmse: 0.0852061\tvalid_1's rmse: 0.0883835\n",
      "[175]\ttraining's rmse: 0.0851085\tvalid_1's rmse: 0.0883434\n",
      "[200]\ttraining's rmse: 0.0850055\tvalid_1's rmse: 0.0883041\n",
      "[225]\ttraining's rmse: 0.0849056\tvalid_1's rmse: 0.0882677\n",
      "[250]\ttraining's rmse: 0.0848222\tvalid_1's rmse: 0.0882337\n",
      "[275]\ttraining's rmse: 0.0847423\tvalid_1's rmse: 0.0882023\n",
      "[300]\ttraining's rmse: 0.0846608\tvalid_1's rmse: 0.0881726\n",
      "[325]\ttraining's rmse: 0.0845823\tvalid_1's rmse: 0.0881457\n",
      "[350]\ttraining's rmse: 0.0845105\tvalid_1's rmse: 0.0881204\n",
      "[375]\ttraining's rmse: 0.0844467\tvalid_1's rmse: 0.0880974\n",
      "[400]\ttraining's rmse: 0.0843796\tvalid_1's rmse: 0.0880746\n",
      "[425]\ttraining's rmse: 0.0843187\tvalid_1's rmse: 0.0880526\n",
      "[450]\ttraining's rmse: 0.0842593\tvalid_1's rmse: 0.0880327\n",
      "[475]\ttraining's rmse: 0.0842094\tvalid_1's rmse: 0.0880131\n",
      "[500]\ttraining's rmse: 0.0841654\tvalid_1's rmse: 0.0879962\n",
      "[525]\ttraining's rmse: 0.0841084\tvalid_1's rmse: 0.0879775\n",
      "[550]\ttraining's rmse: 0.084056\tvalid_1's rmse: 0.0879613\n",
      "[575]\ttraining's rmse: 0.0840102\tvalid_1's rmse: 0.0879465\n",
      "[600]\ttraining's rmse: 0.0839638\tvalid_1's rmse: 0.0879305\n",
      "[625]\ttraining's rmse: 0.0839264\tvalid_1's rmse: 0.0879175\n",
      "[650]\ttraining's rmse: 0.0838834\tvalid_1's rmse: 0.0879031\n",
      "[675]\ttraining's rmse: 0.0838391\tvalid_1's rmse: 0.0878887\n",
      "[700]\ttraining's rmse: 0.083801\tvalid_1's rmse: 0.0878765\n",
      "[725]\ttraining's rmse: 0.0837634\tvalid_1's rmse: 0.087866\n",
      "[750]\ttraining's rmse: 0.0837295\tvalid_1's rmse: 0.0878556\n",
      "[775]\ttraining's rmse: 0.0837006\tvalid_1's rmse: 0.0878445\n",
      "[800]\ttraining's rmse: 0.0836648\tvalid_1's rmse: 0.0878348\n",
      "[825]\ttraining's rmse: 0.0836353\tvalid_1's rmse: 0.0878245\n",
      "[850]\ttraining's rmse: 0.0836029\tvalid_1's rmse: 0.0878173\n",
      "[875]\ttraining's rmse: 0.0835732\tvalid_1's rmse: 0.0878083\n",
      "[900]\ttraining's rmse: 0.0835387\tvalid_1's rmse: 0.0878\n",
      "[925]\ttraining's rmse: 0.0835094\tvalid_1's rmse: 0.0877925\n",
      "[950]\ttraining's rmse: 0.0834862\tvalid_1's rmse: 0.0877854\n",
      "[975]\ttraining's rmse: 0.08346\tvalid_1's rmse: 0.0877784\n",
      "[1000]\ttraining's rmse: 0.0834354\tvalid_1's rmse: 0.0877726\n",
      "[1025]\ttraining's rmse: 0.0834086\tvalid_1's rmse: 0.0877653\n",
      "[1050]\ttraining's rmse: 0.0833858\tvalid_1's rmse: 0.0877575\n",
      "[1075]\ttraining's rmse: 0.0833659\tvalid_1's rmse: 0.0877527\n",
      "[1100]\ttraining's rmse: 0.0833475\tvalid_1's rmse: 0.0877481\n",
      "[1125]\ttraining's rmse: 0.0833317\tvalid_1's rmse: 0.0877423\n",
      "[1150]\ttraining's rmse: 0.0833135\tvalid_1's rmse: 0.0877367\n",
      "[1175]\ttraining's rmse: 0.0832981\tvalid_1's rmse: 0.0877328\n",
      "[1200]\ttraining's rmse: 0.0832832\tvalid_1's rmse: 0.0877276\n",
      "[1225]\ttraining's rmse: 0.0832675\tvalid_1's rmse: 0.087723\n",
      "[1250]\ttraining's rmse: 0.0832527\tvalid_1's rmse: 0.0877188\n",
      "[1275]\ttraining's rmse: 0.0832328\tvalid_1's rmse: 0.0877146\n",
      "[1300]\ttraining's rmse: 0.0832184\tvalid_1's rmse: 0.0877101\n",
      "[1325]\ttraining's rmse: 0.0832022\tvalid_1's rmse: 0.0877074\n",
      "[1350]\ttraining's rmse: 0.0831887\tvalid_1's rmse: 0.0877049\n",
      "[1375]\ttraining's rmse: 0.0831742\tvalid_1's rmse: 0.0877023\n",
      "[1400]\ttraining's rmse: 0.0831611\tvalid_1's rmse: 0.087699\n",
      "[1425]\ttraining's rmse: 0.0831494\tvalid_1's rmse: 0.0876957\n",
      "[1450]\ttraining's rmse: 0.0831336\tvalid_1's rmse: 0.0876925\n",
      "[1475]\ttraining's rmse: 0.0831222\tvalid_1's rmse: 0.0876892\n",
      "[1500]\ttraining's rmse: 0.0831134\tvalid_1's rmse: 0.0876867\n",
      "[1525]\ttraining's rmse: 0.0831051\tvalid_1's rmse: 0.087683\n",
      "[1550]\ttraining's rmse: 0.0830929\tvalid_1's rmse: 0.0876816\n",
      "[1575]\ttraining's rmse: 0.0830847\tvalid_1's rmse: 0.0876789\n",
      "[1600]\ttraining's rmse: 0.0830791\tvalid_1's rmse: 0.0876756\n",
      "[1625]\ttraining's rmse: 0.0830712\tvalid_1's rmse: 0.0876729\n",
      "[1650]\ttraining's rmse: 0.0830649\tvalid_1's rmse: 0.0876718\n",
      "[1675]\ttraining's rmse: 0.0830596\tvalid_1's rmse: 0.0876697\n",
      "[1700]\ttraining's rmse: 0.083052\tvalid_1's rmse: 0.0876671\n",
      "[1725]\ttraining's rmse: 0.0830443\tvalid_1's rmse: 0.0876655\n",
      "[1750]\ttraining's rmse: 0.0830364\tvalid_1's rmse: 0.0876623\n",
      "[1775]\ttraining's rmse: 0.0830304\tvalid_1's rmse: 0.0876611\n",
      "[1800]\ttraining's rmse: 0.0830234\tvalid_1's rmse: 0.0876595\n",
      "[1825]\ttraining's rmse: 0.0830181\tvalid_1's rmse: 0.0876576\n",
      "[1850]\ttraining's rmse: 0.0830128\tvalid_1's rmse: 0.0876566\n",
      "[1875]\ttraining's rmse: 0.0830076\tvalid_1's rmse: 0.0876557\n",
      "[1900]\ttraining's rmse: 0.0830029\tvalid_1's rmse: 0.0876551\n",
      "[1925]\ttraining's rmse: 0.0829978\tvalid_1's rmse: 0.0876542\n",
      "[1950]\ttraining's rmse: 0.0829922\tvalid_1's rmse: 0.0876528\n",
      "[1975]\ttraining's rmse: 0.082988\tvalid_1's rmse: 0.0876516\n",
      "[2000]\ttraining's rmse: 0.0829844\tvalid_1's rmse: 0.0876508\n",
      "[2025]\ttraining's rmse: 0.0829802\tvalid_1's rmse: 0.0876493\n",
      "[2050]\ttraining's rmse: 0.0829756\tvalid_1's rmse: 0.0876475\n",
      "[2075]\ttraining's rmse: 0.082972\tvalid_1's rmse: 0.0876468\n",
      "[2100]\ttraining's rmse: 0.0829686\tvalid_1's rmse: 0.0876464\n",
      "[2125]\ttraining's rmse: 0.0829652\tvalid_1's rmse: 0.0876456\n",
      "[2150]\ttraining's rmse: 0.0829616\tvalid_1's rmse: 0.0876456\n",
      "[2175]\ttraining's rmse: 0.0829581\tvalid_1's rmse: 0.0876448\n",
      "[2200]\ttraining's rmse: 0.082955\tvalid_1's rmse: 0.087644\n",
      "[2225]\ttraining's rmse: 0.0829513\tvalid_1's rmse: 0.0876421\n",
      "[2250]\ttraining's rmse: 0.0829489\tvalid_1's rmse: 0.0876414\n",
      "[2275]\ttraining's rmse: 0.0829458\tvalid_1's rmse: 0.0876402\n",
      "[2300]\ttraining's rmse: 0.0829423\tvalid_1's rmse: 0.0876397\n",
      "[2325]\ttraining's rmse: 0.0829394\tvalid_1's rmse: 0.0876382\n",
      "[2350]\ttraining's rmse: 0.0829371\tvalid_1's rmse: 0.0876383\n",
      "[2375]\ttraining's rmse: 0.0829349\tvalid_1's rmse: 0.0876382\n",
      "Early stopping, best iteration is:\n",
      "[2335]\ttraining's rmse: 0.0829384\tvalid_1's rmse: 0.087638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0861539\tvalid_1's rmse: 0.0880688\n",
      "[50]\ttraining's rmse: 0.0860262\tvalid_1's rmse: 0.0880087\n",
      "[75]\ttraining's rmse: 0.0858957\tvalid_1's rmse: 0.0879509\n",
      "[100]\ttraining's rmse: 0.0857785\tvalid_1's rmse: 0.0879006\n",
      "[125]\ttraining's rmse: 0.0856582\tvalid_1's rmse: 0.0878502\n",
      "[150]\ttraining's rmse: 0.0855499\tvalid_1's rmse: 0.0878033\n",
      "[175]\ttraining's rmse: 0.0854561\tvalid_1's rmse: 0.087766\n",
      "[200]\ttraining's rmse: 0.085356\tvalid_1's rmse: 0.0877281\n",
      "[225]\ttraining's rmse: 0.0852602\tvalid_1's rmse: 0.0876935\n",
      "[250]\ttraining's rmse: 0.0851782\tvalid_1's rmse: 0.0876608\n",
      "[275]\ttraining's rmse: 0.0851029\tvalid_1's rmse: 0.0876314\n",
      "[300]\ttraining's rmse: 0.085023\tvalid_1's rmse: 0.0876013\n",
      "[325]\ttraining's rmse: 0.0849471\tvalid_1's rmse: 0.0875746\n",
      "[350]\ttraining's rmse: 0.0848716\tvalid_1's rmse: 0.0875485\n",
      "[375]\ttraining's rmse: 0.0848088\tvalid_1's rmse: 0.087526\n",
      "[400]\ttraining's rmse: 0.0847427\tvalid_1's rmse: 0.0875037\n",
      "[425]\ttraining's rmse: 0.0846804\tvalid_1's rmse: 0.0874826\n",
      "[450]\ttraining's rmse: 0.0846232\tvalid_1's rmse: 0.0874632\n",
      "[475]\ttraining's rmse: 0.0845705\tvalid_1's rmse: 0.087446\n",
      "[500]\ttraining's rmse: 0.0845249\tvalid_1's rmse: 0.0874299\n",
      "[525]\ttraining's rmse: 0.084467\tvalid_1's rmse: 0.087413\n",
      "[550]\ttraining's rmse: 0.084412\tvalid_1's rmse: 0.0873966\n",
      "[575]\ttraining's rmse: 0.0843628\tvalid_1's rmse: 0.0873824\n",
      "[600]\ttraining's rmse: 0.084317\tvalid_1's rmse: 0.0873695\n",
      "[625]\ttraining's rmse: 0.0842805\tvalid_1's rmse: 0.0873574\n",
      "[650]\ttraining's rmse: 0.0842324\tvalid_1's rmse: 0.0873445\n",
      "[675]\ttraining's rmse: 0.0841853\tvalid_1's rmse: 0.0873326\n",
      "[700]\ttraining's rmse: 0.0841445\tvalid_1's rmse: 0.0873208\n",
      "[725]\ttraining's rmse: 0.084105\tvalid_1's rmse: 0.0873104\n",
      "[750]\ttraining's rmse: 0.0840683\tvalid_1's rmse: 0.0873014\n",
      "[775]\ttraining's rmse: 0.0840398\tvalid_1's rmse: 0.087293\n",
      "[800]\ttraining's rmse: 0.0840009\tvalid_1's rmse: 0.0872843\n",
      "[825]\ttraining's rmse: 0.0839672\tvalid_1's rmse: 0.0872756\n",
      "[850]\ttraining's rmse: 0.083936\tvalid_1's rmse: 0.0872686\n",
      "[875]\ttraining's rmse: 0.0839063\tvalid_1's rmse: 0.0872628\n",
      "[900]\ttraining's rmse: 0.0838743\tvalid_1's rmse: 0.0872554\n",
      "[925]\ttraining's rmse: 0.083846\tvalid_1's rmse: 0.0872487\n",
      "[950]\ttraining's rmse: 0.0838205\tvalid_1's rmse: 0.0872434\n",
      "[975]\ttraining's rmse: 0.0837951\tvalid_1's rmse: 0.0872375\n",
      "[1000]\ttraining's rmse: 0.0837725\tvalid_1's rmse: 0.0872327\n",
      "[1025]\ttraining's rmse: 0.0837448\tvalid_1's rmse: 0.0872278\n",
      "[1050]\ttraining's rmse: 0.0837214\tvalid_1's rmse: 0.087223\n",
      "[1075]\ttraining's rmse: 0.0836992\tvalid_1's rmse: 0.0872194\n",
      "[1100]\ttraining's rmse: 0.0836821\tvalid_1's rmse: 0.0872155\n",
      "[1125]\ttraining's rmse: 0.0836633\tvalid_1's rmse: 0.0872124\n",
      "[1150]\ttraining's rmse: 0.0836461\tvalid_1's rmse: 0.0872097\n",
      "[1175]\ttraining's rmse: 0.0836267\tvalid_1's rmse: 0.0872069\n",
      "[1200]\ttraining's rmse: 0.0836083\tvalid_1's rmse: 0.0872039\n",
      "[1225]\ttraining's rmse: 0.0835894\tvalid_1's rmse: 0.0872002\n",
      "[1250]\ttraining's rmse: 0.0835751\tvalid_1's rmse: 0.0871974\n",
      "[1275]\ttraining's rmse: 0.0835566\tvalid_1's rmse: 0.0871954\n",
      "[1300]\ttraining's rmse: 0.0835417\tvalid_1's rmse: 0.0871925\n",
      "[1325]\ttraining's rmse: 0.0835279\tvalid_1's rmse: 0.0871898\n",
      "[1350]\ttraining's rmse: 0.0835134\tvalid_1's rmse: 0.0871882\n",
      "[1375]\ttraining's rmse: 0.0835\tvalid_1's rmse: 0.0871864\n",
      "[1400]\ttraining's rmse: 0.0834892\tvalid_1's rmse: 0.0871842\n",
      "[1425]\ttraining's rmse: 0.083476\tvalid_1's rmse: 0.0871829\n",
      "[1450]\ttraining's rmse: 0.0834614\tvalid_1's rmse: 0.0871811\n",
      "[1475]\ttraining's rmse: 0.0834503\tvalid_1's rmse: 0.0871792\n",
      "[1500]\ttraining's rmse: 0.0834392\tvalid_1's rmse: 0.087178\n",
      "[1525]\ttraining's rmse: 0.0834293\tvalid_1's rmse: 0.0871774\n",
      "[1550]\ttraining's rmse: 0.0834196\tvalid_1's rmse: 0.0871768\n",
      "[1575]\ttraining's rmse: 0.0834097\tvalid_1's rmse: 0.0871751\n",
      "[1600]\ttraining's rmse: 0.0834016\tvalid_1's rmse: 0.0871745\n",
      "[1625]\ttraining's rmse: 0.0833917\tvalid_1's rmse: 0.0871729\n",
      "[1650]\ttraining's rmse: 0.0833842\tvalid_1's rmse: 0.0871722\n",
      "[1675]\ttraining's rmse: 0.0833778\tvalid_1's rmse: 0.087171\n",
      "[1700]\ttraining's rmse: 0.0833711\tvalid_1's rmse: 0.0871698\n",
      "[1725]\ttraining's rmse: 0.083364\tvalid_1's rmse: 0.0871684\n",
      "[1750]\ttraining's rmse: 0.0833551\tvalid_1's rmse: 0.0871672\n",
      "[1775]\ttraining's rmse: 0.0833478\tvalid_1's rmse: 0.0871664\n",
      "[1800]\ttraining's rmse: 0.0833417\tvalid_1's rmse: 0.087166\n",
      "[1825]\ttraining's rmse: 0.0833355\tvalid_1's rmse: 0.0871647\n",
      "[1850]\ttraining's rmse: 0.0833295\tvalid_1's rmse: 0.0871634\n",
      "[1875]\ttraining's rmse: 0.0833242\tvalid_1's rmse: 0.087163\n",
      "[1900]\ttraining's rmse: 0.0833196\tvalid_1's rmse: 0.0871634\n",
      "[1925]\ttraining's rmse: 0.0833147\tvalid_1's rmse: 0.0871628\n",
      "[1950]\ttraining's rmse: 0.0833107\tvalid_1's rmse: 0.0871624\n",
      "[1975]\ttraining's rmse: 0.0833067\tvalid_1's rmse: 0.0871618\n",
      "[2000]\ttraining's rmse: 0.0833027\tvalid_1's rmse: 0.0871614\n",
      "[2025]\ttraining's rmse: 0.0832995\tvalid_1's rmse: 0.087161\n",
      "[2050]\ttraining's rmse: 0.0832952\tvalid_1's rmse: 0.0871606\n",
      "[2075]\ttraining's rmse: 0.0832911\tvalid_1's rmse: 0.0871602\n",
      "[2100]\ttraining's rmse: 0.0832871\tvalid_1's rmse: 0.0871596\n",
      "[2125]\ttraining's rmse: 0.0832835\tvalid_1's rmse: 0.0871599\n",
      "[2150]\ttraining's rmse: 0.0832798\tvalid_1's rmse: 0.0871596\n",
      "[2175]\ttraining's rmse: 0.0832763\tvalid_1's rmse: 0.0871596\n",
      "[2200]\ttraining's rmse: 0.0832735\tvalid_1's rmse: 0.0871596\n",
      "[2225]\ttraining's rmse: 0.0832707\tvalid_1's rmse: 0.0871595\n",
      "[2250]\ttraining's rmse: 0.0832663\tvalid_1's rmse: 0.0871593\n",
      "[2275]\ttraining's rmse: 0.0832633\tvalid_1's rmse: 0.0871592\n",
      "[2300]\ttraining's rmse: 0.08326\tvalid_1's rmse: 0.0871587\n",
      "[2325]\ttraining's rmse: 0.0832563\tvalid_1's rmse: 0.0871586\n",
      "[2350]\ttraining's rmse: 0.0832535\tvalid_1's rmse: 0.0871585\n",
      "[2375]\ttraining's rmse: 0.0832508\tvalid_1's rmse: 0.087158\n",
      "[2400]\ttraining's rmse: 0.0832472\tvalid_1's rmse: 0.087158\n",
      "[2425]\ttraining's rmse: 0.0832437\tvalid_1's rmse: 0.0871578\n",
      "[2450]\ttraining's rmse: 0.0832419\tvalid_1's rmse: 0.0871578\n",
      "[2475]\ttraining's rmse: 0.0832398\tvalid_1's rmse: 0.0871582\n",
      "Early stopping, best iteration is:\n",
      "[2441]\ttraining's rmse: 0.0832424\tvalid_1's rmse: 0.0871576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0882369\tvalid_1's rmse: 0.0838432\n",
      "[50]\ttraining's rmse: 0.0881184\tvalid_1's rmse: 0.083793\n",
      "[75]\ttraining's rmse: 0.087994\tvalid_1's rmse: 0.0837427\n",
      "[100]\ttraining's rmse: 0.0878812\tvalid_1's rmse: 0.0836998\n",
      "[125]\ttraining's rmse: 0.087766\tvalid_1's rmse: 0.0836569\n",
      "[150]\ttraining's rmse: 0.0876608\tvalid_1's rmse: 0.0836183\n",
      "[175]\ttraining's rmse: 0.087574\tvalid_1's rmse: 0.083587\n",
      "[200]\ttraining's rmse: 0.087478\tvalid_1's rmse: 0.0835528\n",
      "[225]\ttraining's rmse: 0.0873863\tvalid_1's rmse: 0.0835204\n",
      "[250]\ttraining's rmse: 0.0873087\tvalid_1's rmse: 0.0834936\n",
      "[275]\ttraining's rmse: 0.087238\tvalid_1's rmse: 0.0834688\n",
      "[300]\ttraining's rmse: 0.0871643\tvalid_1's rmse: 0.0834432\n",
      "[325]\ttraining's rmse: 0.087092\tvalid_1's rmse: 0.0834203\n",
      "[350]\ttraining's rmse: 0.0870221\tvalid_1's rmse: 0.0833985\n",
      "[375]\ttraining's rmse: 0.0869646\tvalid_1's rmse: 0.0833811\n",
      "[400]\ttraining's rmse: 0.0869008\tvalid_1's rmse: 0.0833726\n",
      "[425]\ttraining's rmse: 0.0868433\tvalid_1's rmse: 0.0833578\n",
      "[450]\ttraining's rmse: 0.0867885\tvalid_1's rmse: 0.0833462\n",
      "[475]\ttraining's rmse: 0.0867391\tvalid_1's rmse: 0.0833315\n",
      "[500]\ttraining's rmse: 0.0866965\tvalid_1's rmse: 0.0833184\n",
      "[525]\ttraining's rmse: 0.0866395\tvalid_1's rmse: 0.0833085\n",
      "[550]\ttraining's rmse: 0.0865878\tvalid_1's rmse: 0.0832971\n",
      "[575]\ttraining's rmse: 0.0865431\tvalid_1's rmse: 0.0832899\n",
      "[600]\ttraining's rmse: 0.0864971\tvalid_1's rmse: 0.0832848\n",
      "[625]\ttraining's rmse: 0.0864602\tvalid_1's rmse: 0.0832865\n",
      "[650]\ttraining's rmse: 0.0864139\tvalid_1's rmse: 0.0832761\n",
      "[675]\ttraining's rmse: 0.0863662\tvalid_1's rmse: 0.0832725\n",
      "[700]\ttraining's rmse: 0.0863274\tvalid_1's rmse: 0.0832703\n",
      "[725]\ttraining's rmse: 0.0862892\tvalid_1's rmse: 0.0832674\n",
      "[750]\ttraining's rmse: 0.086254\tvalid_1's rmse: 0.0832655\n",
      "[775]\ttraining's rmse: 0.0862257\tvalid_1's rmse: 0.0832631\n",
      "[800]\ttraining's rmse: 0.0861876\tvalid_1's rmse: 0.083257\n",
      "[825]\ttraining's rmse: 0.0861533\tvalid_1's rmse: 0.0832558\n",
      "[850]\ttraining's rmse: 0.0861204\tvalid_1's rmse: 0.0832495\n",
      "[875]\ttraining's rmse: 0.0860913\tvalid_1's rmse: 0.0832453\n",
      "[900]\ttraining's rmse: 0.0860589\tvalid_1's rmse: 0.0832512\n",
      "[925]\ttraining's rmse: 0.0860304\tvalid_1's rmse: 0.0832531\n",
      "Early stopping, best iteration is:\n",
      "[877]\ttraining's rmse: 0.0860895\tvalid_1's rmse: 0.0832448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0901842\tvalid_1's rmse: 0.0919207\n",
      "[50]\ttraining's rmse: 0.0899937\tvalid_1's rmse: 0.091868\n",
      "[75]\ttraining's rmse: 0.0898024\tvalid_1's rmse: 0.0918159\n",
      "[100]\ttraining's rmse: 0.089627\tvalid_1's rmse: 0.0917721\n",
      "[125]\ttraining's rmse: 0.0894526\tvalid_1's rmse: 0.0917274\n",
      "[150]\ttraining's rmse: 0.0892963\tvalid_1's rmse: 0.0916858\n",
      "[175]\ttraining's rmse: 0.0891574\tvalid_1's rmse: 0.0916494\n",
      "[200]\ttraining's rmse: 0.0890147\tvalid_1's rmse: 0.0916129\n",
      "[225]\ttraining's rmse: 0.0888813\tvalid_1's rmse: 0.0915773\n",
      "[250]\ttraining's rmse: 0.0887636\tvalid_1's rmse: 0.0915449\n",
      "[275]\ttraining's rmse: 0.088655\tvalid_1's rmse: 0.0915158\n",
      "[300]\ttraining's rmse: 0.0885419\tvalid_1's rmse: 0.0914874\n",
      "[325]\ttraining's rmse: 0.0884384\tvalid_1's rmse: 0.0914603\n",
      "[350]\ttraining's rmse: 0.0883392\tvalid_1's rmse: 0.091434\n",
      "[375]\ttraining's rmse: 0.0882522\tvalid_1's rmse: 0.0914152\n",
      "[400]\ttraining's rmse: 0.0881629\tvalid_1's rmse: 0.0913935\n",
      "[425]\ttraining's rmse: 0.0880832\tvalid_1's rmse: 0.0913744\n",
      "[450]\ttraining's rmse: 0.0880071\tvalid_1's rmse: 0.0913526\n",
      "[475]\ttraining's rmse: 0.0879372\tvalid_1's rmse: 0.0913361\n",
      "[500]\ttraining's rmse: 0.087876\tvalid_1's rmse: 0.0913186\n",
      "[525]\ttraining's rmse: 0.0878023\tvalid_1's rmse: 0.0913009\n",
      "[550]\ttraining's rmse: 0.0877402\tvalid_1's rmse: 0.0912857\n",
      "[575]\ttraining's rmse: 0.087679\tvalid_1's rmse: 0.0912708\n",
      "[600]\ttraining's rmse: 0.0876204\tvalid_1's rmse: 0.0912564\n",
      "[625]\ttraining's rmse: 0.0875729\tvalid_1's rmse: 0.0912437\n",
      "[650]\ttraining's rmse: 0.0875177\tvalid_1's rmse: 0.0912322\n",
      "[675]\ttraining's rmse: 0.0874652\tvalid_1's rmse: 0.0912209\n",
      "[700]\ttraining's rmse: 0.0874164\tvalid_1's rmse: 0.0912073\n",
      "[725]\ttraining's rmse: 0.0873697\tvalid_1's rmse: 0.0911966\n",
      "[750]\ttraining's rmse: 0.0873267\tvalid_1's rmse: 0.0911873\n",
      "[775]\ttraining's rmse: 0.087289\tvalid_1's rmse: 0.0911773\n",
      "[800]\ttraining's rmse: 0.0872437\tvalid_1's rmse: 0.091168\n",
      "[825]\ttraining's rmse: 0.0872036\tvalid_1's rmse: 0.0911603\n",
      "[850]\ttraining's rmse: 0.0871616\tvalid_1's rmse: 0.0911514\n",
      "[875]\ttraining's rmse: 0.0871258\tvalid_1's rmse: 0.0911439\n",
      "[900]\ttraining's rmse: 0.0870885\tvalid_1's rmse: 0.0911359\n",
      "[925]\ttraining's rmse: 0.0870571\tvalid_1's rmse: 0.0911278\n",
      "[950]\ttraining's rmse: 0.0870252\tvalid_1's rmse: 0.0911205\n",
      "[975]\ttraining's rmse: 0.0870012\tvalid_1's rmse: 0.0911143\n",
      "[1000]\ttraining's rmse: 0.0869699\tvalid_1's rmse: 0.0911074\n",
      "[1025]\ttraining's rmse: 0.0869423\tvalid_1's rmse: 0.091101\n",
      "[1050]\ttraining's rmse: 0.0869159\tvalid_1's rmse: 0.0910941\n",
      "[1075]\ttraining's rmse: 0.0868889\tvalid_1's rmse: 0.0910892\n",
      "[1100]\ttraining's rmse: 0.0868654\tvalid_1's rmse: 0.0910839\n",
      "[1125]\ttraining's rmse: 0.0868418\tvalid_1's rmse: 0.0910781\n",
      "[1150]\ttraining's rmse: 0.0868186\tvalid_1's rmse: 0.0910737\n",
      "[1175]\ttraining's rmse: 0.0867973\tvalid_1's rmse: 0.0910702\n",
      "[1200]\ttraining's rmse: 0.0867804\tvalid_1's rmse: 0.091064\n",
      "[1225]\ttraining's rmse: 0.0867577\tvalid_1's rmse: 0.0910609\n",
      "[1250]\ttraining's rmse: 0.0867422\tvalid_1's rmse: 0.0910573\n",
      "[1275]\ttraining's rmse: 0.0867211\tvalid_1's rmse: 0.0910533\n",
      "[1300]\ttraining's rmse: 0.0867065\tvalid_1's rmse: 0.091049\n",
      "[1325]\ttraining's rmse: 0.0866891\tvalid_1's rmse: 0.0910459\n",
      "[1350]\ttraining's rmse: 0.0866744\tvalid_1's rmse: 0.0910424\n",
      "[1375]\ttraining's rmse: 0.086657\tvalid_1's rmse: 0.091039\n",
      "[1400]\ttraining's rmse: 0.0866421\tvalid_1's rmse: 0.0910346\n",
      "[1425]\ttraining's rmse: 0.0866258\tvalid_1's rmse: 0.0910301\n",
      "[1450]\ttraining's rmse: 0.0866082\tvalid_1's rmse: 0.0910281\n",
      "[1475]\ttraining's rmse: 0.0865942\tvalid_1's rmse: 0.0910242\n",
      "[1500]\ttraining's rmse: 0.0865815\tvalid_1's rmse: 0.0910216\n",
      "[1525]\ttraining's rmse: 0.0865688\tvalid_1's rmse: 0.0910185\n",
      "[1550]\ttraining's rmse: 0.0865577\tvalid_1's rmse: 0.0910166\n",
      "[1575]\ttraining's rmse: 0.0865449\tvalid_1's rmse: 0.0910129\n",
      "[1600]\ttraining's rmse: 0.0865379\tvalid_1's rmse: 0.0910104\n",
      "[1625]\ttraining's rmse: 0.0865276\tvalid_1's rmse: 0.091007\n",
      "[1650]\ttraining's rmse: 0.0865185\tvalid_1's rmse: 0.0910042\n",
      "[1675]\ttraining's rmse: 0.0865119\tvalid_1's rmse: 0.0910007\n",
      "[1700]\ttraining's rmse: 0.086504\tvalid_1's rmse: 0.0909977\n",
      "[1725]\ttraining's rmse: 0.0864986\tvalid_1's rmse: 0.0909952\n",
      "[1750]\ttraining's rmse: 0.0864923\tvalid_1's rmse: 0.0909937\n",
      "[1775]\ttraining's rmse: 0.0864821\tvalid_1's rmse: 0.0909926\n",
      "[1800]\ttraining's rmse: 0.0864757\tvalid_1's rmse: 0.0909908\n",
      "[1825]\ttraining's rmse: 0.086469\tvalid_1's rmse: 0.0909882\n",
      "[1850]\ttraining's rmse: 0.0864635\tvalid_1's rmse: 0.0909864\n",
      "[1875]\ttraining's rmse: 0.086457\tvalid_1's rmse: 0.0909854\n",
      "[1900]\ttraining's rmse: 0.0864508\tvalid_1's rmse: 0.0909842\n",
      "[1925]\ttraining's rmse: 0.0864441\tvalid_1's rmse: 0.0909819\n",
      "[1950]\ttraining's rmse: 0.0864388\tvalid_1's rmse: 0.0909803\n",
      "[1975]\ttraining's rmse: 0.0864343\tvalid_1's rmse: 0.0909791\n",
      "[2000]\ttraining's rmse: 0.0864266\tvalid_1's rmse: 0.0909771\n",
      "[2025]\ttraining's rmse: 0.0864215\tvalid_1's rmse: 0.090976\n",
      "[2050]\ttraining's rmse: 0.0864152\tvalid_1's rmse: 0.0909746\n",
      "[2075]\ttraining's rmse: 0.0864119\tvalid_1's rmse: 0.0909734\n",
      "[2100]\ttraining's rmse: 0.0864072\tvalid_1's rmse: 0.090972\n",
      "[2125]\ttraining's rmse: 0.086402\tvalid_1's rmse: 0.0909705\n",
      "[2150]\ttraining's rmse: 0.0863973\tvalid_1's rmse: 0.0909692\n",
      "[2175]\ttraining's rmse: 0.0863923\tvalid_1's rmse: 0.0909686\n",
      "[2200]\ttraining's rmse: 0.0863881\tvalid_1's rmse: 0.0909679\n",
      "[2225]\ttraining's rmse: 0.0863839\tvalid_1's rmse: 0.0909661\n",
      "[2250]\ttraining's rmse: 0.0863808\tvalid_1's rmse: 0.0909655\n",
      "[2275]\ttraining's rmse: 0.0863747\tvalid_1's rmse: 0.0909648\n",
      "[2300]\ttraining's rmse: 0.0863705\tvalid_1's rmse: 0.0909634\n",
      "[2325]\ttraining's rmse: 0.086366\tvalid_1's rmse: 0.0909629\n",
      "[2350]\ttraining's rmse: 0.0863618\tvalid_1's rmse: 0.0909624\n",
      "[2375]\ttraining's rmse: 0.0863593\tvalid_1's rmse: 0.0909614\n",
      "[2400]\ttraining's rmse: 0.0863553\tvalid_1's rmse: 0.0909607\n",
      "[2425]\ttraining's rmse: 0.0863518\tvalid_1's rmse: 0.0909601\n",
      "[2450]\ttraining's rmse: 0.0863491\tvalid_1's rmse: 0.0909597\n",
      "[2475]\ttraining's rmse: 0.0863451\tvalid_1's rmse: 0.0909597\n",
      "[2500]\ttraining's rmse: 0.0863427\tvalid_1's rmse: 0.0909585\n",
      "[2525]\ttraining's rmse: 0.0863401\tvalid_1's rmse: 0.0909572\n",
      "[2550]\ttraining's rmse: 0.0863366\tvalid_1's rmse: 0.0909565\n",
      "[2575]\ttraining's rmse: 0.0863343\tvalid_1's rmse: 0.0909556\n",
      "[2600]\ttraining's rmse: 0.0863312\tvalid_1's rmse: 0.090955\n",
      "[2625]\ttraining's rmse: 0.0863288\tvalid_1's rmse: 0.0909541\n",
      "[2650]\ttraining's rmse: 0.0863258\tvalid_1's rmse: 0.0909531\n",
      "[2675]\ttraining's rmse: 0.0863241\tvalid_1's rmse: 0.0909531\n",
      "[2700]\ttraining's rmse: 0.0863222\tvalid_1's rmse: 0.0909529\n",
      "[2725]\ttraining's rmse: 0.0863194\tvalid_1's rmse: 0.0909518\n",
      "[2750]\ttraining's rmse: 0.0863172\tvalid_1's rmse: 0.0909506\n",
      "[2775]\ttraining's rmse: 0.0863144\tvalid_1's rmse: 0.0909505\n",
      "[2800]\ttraining's rmse: 0.0863124\tvalid_1's rmse: 0.0909503\n",
      "[2825]\ttraining's rmse: 0.08631\tvalid_1's rmse: 0.0909504\n",
      "[2850]\ttraining's rmse: 0.0863088\tvalid_1's rmse: 0.0909506\n",
      "Early stopping, best iteration is:\n",
      "[2810]\ttraining's rmse: 0.0863112\tvalid_1's rmse: 0.0909502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0902566\tvalid_1's rmse: 0.0917964\n",
      "[50]\ttraining's rmse: 0.0900849\tvalid_1's rmse: 0.0917406\n",
      "[75]\ttraining's rmse: 0.0899077\tvalid_1's rmse: 0.0916847\n",
      "[100]\ttraining's rmse: 0.0897481\tvalid_1's rmse: 0.0916372\n",
      "[125]\ttraining's rmse: 0.0895869\tvalid_1's rmse: 0.0915882\n",
      "[150]\ttraining's rmse: 0.089444\tvalid_1's rmse: 0.0915423\n",
      "[175]\ttraining's rmse: 0.0893237\tvalid_1's rmse: 0.0915038\n",
      "[200]\ttraining's rmse: 0.0891915\tvalid_1's rmse: 0.0914651\n",
      "[225]\ttraining's rmse: 0.0890681\tvalid_1's rmse: 0.0914304\n",
      "[250]\ttraining's rmse: 0.0889594\tvalid_1's rmse: 0.0913961\n",
      "[275]\ttraining's rmse: 0.0888588\tvalid_1's rmse: 0.0913673\n",
      "[300]\ttraining's rmse: 0.0887617\tvalid_1's rmse: 0.0913392\n",
      "[325]\ttraining's rmse: 0.0886663\tvalid_1's rmse: 0.0913114\n",
      "[350]\ttraining's rmse: 0.0885725\tvalid_1's rmse: 0.0912867\n",
      "[375]\ttraining's rmse: 0.0884962\tvalid_1's rmse: 0.0912658\n",
      "[400]\ttraining's rmse: 0.0884143\tvalid_1's rmse: 0.0912457\n",
      "[425]\ttraining's rmse: 0.088341\tvalid_1's rmse: 0.0912255\n",
      "[450]\ttraining's rmse: 0.0882727\tvalid_1's rmse: 0.0912072\n",
      "[475]\ttraining's rmse: 0.0882084\tvalid_1's rmse: 0.0911889\n",
      "[500]\ttraining's rmse: 0.0881534\tvalid_1's rmse: 0.0911723\n",
      "[525]\ttraining's rmse: 0.0880871\tvalid_1's rmse: 0.0911549\n",
      "[550]\ttraining's rmse: 0.0880237\tvalid_1's rmse: 0.0911403\n",
      "[575]\ttraining's rmse: 0.0879687\tvalid_1's rmse: 0.0911264\n",
      "[600]\ttraining's rmse: 0.0879141\tvalid_1's rmse: 0.091114\n",
      "[625]\ttraining's rmse: 0.0878704\tvalid_1's rmse: 0.0911012\n",
      "[650]\ttraining's rmse: 0.0878182\tvalid_1's rmse: 0.0910885\n",
      "[675]\ttraining's rmse: 0.08777\tvalid_1's rmse: 0.0910782\n",
      "[700]\ttraining's rmse: 0.0877238\tvalid_1's rmse: 0.0910659\n",
      "[725]\ttraining's rmse: 0.0876831\tvalid_1's rmse: 0.0910568\n",
      "[750]\ttraining's rmse: 0.0876453\tvalid_1's rmse: 0.0910485\n",
      "[775]\ttraining's rmse: 0.0876105\tvalid_1's rmse: 0.0910395\n",
      "[800]\ttraining's rmse: 0.0875664\tvalid_1's rmse: 0.0910305\n",
      "[825]\ttraining's rmse: 0.0875342\tvalid_1's rmse: 0.0910232\n",
      "[850]\ttraining's rmse: 0.0874995\tvalid_1's rmse: 0.0910159\n",
      "[875]\ttraining's rmse: 0.0874686\tvalid_1's rmse: 0.0910091\n",
      "[900]\ttraining's rmse: 0.0874314\tvalid_1's rmse: 0.0910023\n",
      "[925]\ttraining's rmse: 0.0873968\tvalid_1's rmse: 0.090996\n",
      "[950]\ttraining's rmse: 0.0873679\tvalid_1's rmse: 0.0909903\n",
      "[975]\ttraining's rmse: 0.0873409\tvalid_1's rmse: 0.0909847\n",
      "[1000]\ttraining's rmse: 0.0873156\tvalid_1's rmse: 0.0909794\n",
      "[1025]\ttraining's rmse: 0.0872872\tvalid_1's rmse: 0.0909752\n",
      "[1050]\ttraining's rmse: 0.0872643\tvalid_1's rmse: 0.0909706\n",
      "[1075]\ttraining's rmse: 0.0872396\tvalid_1's rmse: 0.090967\n",
      "[1100]\ttraining's rmse: 0.0872179\tvalid_1's rmse: 0.090963\n",
      "[1125]\ttraining's rmse: 0.0871966\tvalid_1's rmse: 0.0909599\n",
      "[1150]\ttraining's rmse: 0.0871752\tvalid_1's rmse: 0.090957\n",
      "[1175]\ttraining's rmse: 0.0871568\tvalid_1's rmse: 0.0909552\n",
      "[1200]\ttraining's rmse: 0.0871344\tvalid_1's rmse: 0.0909515\n",
      "[1225]\ttraining's rmse: 0.0871161\tvalid_1's rmse: 0.0909483\n",
      "[1250]\ttraining's rmse: 0.0870992\tvalid_1's rmse: 0.0909452\n",
      "[1275]\ttraining's rmse: 0.0870783\tvalid_1's rmse: 0.090943\n",
      "[1300]\ttraining's rmse: 0.0870634\tvalid_1's rmse: 0.0909406\n",
      "[1325]\ttraining's rmse: 0.0870459\tvalid_1's rmse: 0.0909388\n",
      "[1350]\ttraining's rmse: 0.0870286\tvalid_1's rmse: 0.0909366\n",
      "[1375]\ttraining's rmse: 0.0870108\tvalid_1's rmse: 0.0909342\n",
      "[1400]\ttraining's rmse: 0.0869965\tvalid_1's rmse: 0.0909329\n",
      "[1425]\ttraining's rmse: 0.0869805\tvalid_1's rmse: 0.0909319\n",
      "[1450]\ttraining's rmse: 0.0869648\tvalid_1's rmse: 0.0909302\n",
      "[1475]\ttraining's rmse: 0.0869516\tvalid_1's rmse: 0.0909289\n",
      "[1500]\ttraining's rmse: 0.0869398\tvalid_1's rmse: 0.0909278\n",
      "[1525]\ttraining's rmse: 0.0869285\tvalid_1's rmse: 0.0909265\n",
      "[1550]\ttraining's rmse: 0.0869178\tvalid_1's rmse: 0.0909257\n",
      "[1575]\ttraining's rmse: 0.0869065\tvalid_1's rmse: 0.0909246\n",
      "[1600]\ttraining's rmse: 0.0868963\tvalid_1's rmse: 0.0909241\n",
      "[1625]\ttraining's rmse: 0.0868863\tvalid_1's rmse: 0.0909223\n",
      "[1650]\ttraining's rmse: 0.0868772\tvalid_1's rmse: 0.0909217\n",
      "[1675]\ttraining's rmse: 0.0868692\tvalid_1's rmse: 0.0909201\n",
      "[1700]\ttraining's rmse: 0.086861\tvalid_1's rmse: 0.0909187\n",
      "[1725]\ttraining's rmse: 0.0868531\tvalid_1's rmse: 0.0909182\n",
      "[1750]\ttraining's rmse: 0.0868431\tvalid_1's rmse: 0.0909175\n",
      "[1775]\ttraining's rmse: 0.0868357\tvalid_1's rmse: 0.0909168\n",
      "[1800]\ttraining's rmse: 0.0868266\tvalid_1's rmse: 0.0909163\n",
      "[1825]\ttraining's rmse: 0.0868173\tvalid_1's rmse: 0.0909167\n",
      "[1850]\ttraining's rmse: 0.0868101\tvalid_1's rmse: 0.090916\n",
      "[1875]\ttraining's rmse: 0.0868045\tvalid_1's rmse: 0.0909157\n",
      "[1900]\ttraining's rmse: 0.0867996\tvalid_1's rmse: 0.0909152\n",
      "[1925]\ttraining's rmse: 0.0867939\tvalid_1's rmse: 0.0909147\n",
      "[1950]\ttraining's rmse: 0.0867892\tvalid_1's rmse: 0.0909137\n",
      "[1975]\ttraining's rmse: 0.0867835\tvalid_1's rmse: 0.0909133\n",
      "[2000]\ttraining's rmse: 0.0867778\tvalid_1's rmse: 0.0909126\n",
      "[2025]\ttraining's rmse: 0.0867728\tvalid_1's rmse: 0.0909118\n",
      "[2050]\ttraining's rmse: 0.0867679\tvalid_1's rmse: 0.0909117\n",
      "[2075]\ttraining's rmse: 0.0867635\tvalid_1's rmse: 0.0909112\n",
      "[2100]\ttraining's rmse: 0.0867601\tvalid_1's rmse: 0.0909111\n",
      "[2125]\ttraining's rmse: 0.0867556\tvalid_1's rmse: 0.090911\n",
      "[2150]\ttraining's rmse: 0.0867513\tvalid_1's rmse: 0.0909112\n",
      "[2175]\ttraining's rmse: 0.0867478\tvalid_1's rmse: 0.0909111\n",
      "[2200]\ttraining's rmse: 0.0867435\tvalid_1's rmse: 0.0909106\n",
      "[2225]\ttraining's rmse: 0.0867382\tvalid_1's rmse: 0.0909097\n",
      "[2250]\ttraining's rmse: 0.0867356\tvalid_1's rmse: 0.0909095\n",
      "[2275]\ttraining's rmse: 0.0867312\tvalid_1's rmse: 0.0909096\n",
      "[2300]\ttraining's rmse: 0.0867274\tvalid_1's rmse: 0.0909096\n",
      "[2325]\ttraining's rmse: 0.0867239\tvalid_1's rmse: 0.0909096\n",
      "Early stopping, best iteration is:\n",
      "[2285]\ttraining's rmse: 0.0867292\tvalid_1's rmse: 0.0909092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0917103\tvalid_1's rmse: 0.0889291\n",
      "[50]\ttraining's rmse: 0.0915737\tvalid_1's rmse: 0.0888814\n",
      "[75]\ttraining's rmse: 0.0914265\tvalid_1's rmse: 0.0888286\n",
      "[100]\ttraining's rmse: 0.091296\tvalid_1's rmse: 0.0887862\n",
      "[125]\ttraining's rmse: 0.0911649\tvalid_1's rmse: 0.0887427\n",
      "[150]\ttraining's rmse: 0.0910439\tvalid_1's rmse: 0.0887028\n",
      "[175]\ttraining's rmse: 0.0909419\tvalid_1's rmse: 0.0886716\n",
      "[200]\ttraining's rmse: 0.0908289\tvalid_1's rmse: 0.0886388\n",
      "[225]\ttraining's rmse: 0.0907201\tvalid_1's rmse: 0.0886091\n",
      "[250]\ttraining's rmse: 0.0906284\tvalid_1's rmse: 0.0885826\n",
      "[275]\ttraining's rmse: 0.090546\tvalid_1's rmse: 0.0885567\n",
      "[300]\ttraining's rmse: 0.0904616\tvalid_1's rmse: 0.088535\n",
      "[325]\ttraining's rmse: 0.0903743\tvalid_1's rmse: 0.0885143\n",
      "[350]\ttraining's rmse: 0.0902915\tvalid_1's rmse: 0.0884933\n",
      "[375]\ttraining's rmse: 0.0902238\tvalid_1's rmse: 0.0884797\n",
      "[400]\ttraining's rmse: 0.0901475\tvalid_1's rmse: 0.0884617\n",
      "[425]\ttraining's rmse: 0.0900808\tvalid_1's rmse: 0.0884456\n",
      "[450]\ttraining's rmse: 0.0900206\tvalid_1's rmse: 0.0884339\n",
      "[475]\ttraining's rmse: 0.0899621\tvalid_1's rmse: 0.0884202\n",
      "[500]\ttraining's rmse: 0.0899124\tvalid_1's rmse: 0.0884069\n",
      "[525]\ttraining's rmse: 0.0898459\tvalid_1's rmse: 0.0883956\n",
      "[550]\ttraining's rmse: 0.089786\tvalid_1's rmse: 0.0883812\n",
      "[575]\ttraining's rmse: 0.0897326\tvalid_1's rmse: 0.0883721\n",
      "[600]\ttraining's rmse: 0.0896791\tvalid_1's rmse: 0.0883639\n",
      "[625]\ttraining's rmse: 0.0896345\tvalid_1's rmse: 0.0883549\n",
      "[650]\ttraining's rmse: 0.0895823\tvalid_1's rmse: 0.0883466\n",
      "[675]\ttraining's rmse: 0.0895297\tvalid_1's rmse: 0.0883447\n",
      "[700]\ttraining's rmse: 0.089484\tvalid_1's rmse: 0.0883387\n",
      "[725]\ttraining's rmse: 0.0894419\tvalid_1's rmse: 0.0883391\n",
      "[750]\ttraining's rmse: 0.0893995\tvalid_1's rmse: 0.0883341\n",
      "[775]\ttraining's rmse: 0.0893661\tvalid_1's rmse: 0.088332\n",
      "[800]\ttraining's rmse: 0.0893213\tvalid_1's rmse: 0.0883281\n",
      "[825]\ttraining's rmse: 0.0892884\tvalid_1's rmse: 0.0883287\n",
      "[850]\ttraining's rmse: 0.0892518\tvalid_1's rmse: 0.0883263\n",
      "[875]\ttraining's rmse: 0.0892196\tvalid_1's rmse: 0.0883253\n",
      "[900]\ttraining's rmse: 0.0891847\tvalid_1's rmse: 0.0883233\n",
      "[925]\ttraining's rmse: 0.0891494\tvalid_1's rmse: 0.0883306\n",
      "[950]\ttraining's rmse: 0.0891193\tvalid_1's rmse: 0.0883271\n",
      "Early stopping, best iteration is:\n",
      "[909]\ttraining's rmse: 0.0891735\tvalid_1's rmse: 0.0883221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0862045\tvalid_1's rmse: 0.0891377\n",
      "[50]\ttraining's rmse: 0.0860642\tvalid_1's rmse: 0.0890796\n",
      "[75]\ttraining's rmse: 0.0859263\tvalid_1's rmse: 0.0890245\n",
      "[100]\ttraining's rmse: 0.0857993\tvalid_1's rmse: 0.0889749\n",
      "[125]\ttraining's rmse: 0.0856681\tvalid_1's rmse: 0.0889233\n",
      "[150]\ttraining's rmse: 0.0855513\tvalid_1's rmse: 0.0888764\n",
      "[175]\ttraining's rmse: 0.0854534\tvalid_1's rmse: 0.0888365\n",
      "[200]\ttraining's rmse: 0.0853505\tvalid_1's rmse: 0.0887969\n",
      "[225]\ttraining's rmse: 0.0852502\tvalid_1's rmse: 0.0887587\n",
      "[250]\ttraining's rmse: 0.0851653\tvalid_1's rmse: 0.0887241\n",
      "[275]\ttraining's rmse: 0.085086\tvalid_1's rmse: 0.088693\n",
      "[300]\ttraining's rmse: 0.0850093\tvalid_1's rmse: 0.0886646\n",
      "[325]\ttraining's rmse: 0.084931\tvalid_1's rmse: 0.0886367\n",
      "[350]\ttraining's rmse: 0.0848538\tvalid_1's rmse: 0.0886095\n",
      "[375]\ttraining's rmse: 0.0847867\tvalid_1's rmse: 0.0885843\n",
      "[400]\ttraining's rmse: 0.0847189\tvalid_1's rmse: 0.0885615\n",
      "[425]\ttraining's rmse: 0.0846582\tvalid_1's rmse: 0.0885386\n",
      "[450]\ttraining's rmse: 0.084599\tvalid_1's rmse: 0.088517\n",
      "[475]\ttraining's rmse: 0.0845461\tvalid_1's rmse: 0.0884959\n",
      "[500]\ttraining's rmse: 0.0844999\tvalid_1's rmse: 0.0884771\n",
      "[525]\ttraining's rmse: 0.0844439\tvalid_1's rmse: 0.0884586\n",
      "[550]\ttraining's rmse: 0.0843917\tvalid_1's rmse: 0.0884419\n",
      "[575]\ttraining's rmse: 0.0843462\tvalid_1's rmse: 0.0884275\n",
      "[600]\ttraining's rmse: 0.0843024\tvalid_1's rmse: 0.0884123\n",
      "[625]\ttraining's rmse: 0.0842631\tvalid_1's rmse: 0.0883992\n",
      "[650]\ttraining's rmse: 0.0842144\tvalid_1's rmse: 0.0883838\n",
      "[675]\ttraining's rmse: 0.0841717\tvalid_1's rmse: 0.0883718\n",
      "[700]\ttraining's rmse: 0.0841339\tvalid_1's rmse: 0.0883593\n",
      "[725]\ttraining's rmse: 0.0841002\tvalid_1's rmse: 0.0883478\n",
      "[750]\ttraining's rmse: 0.0840646\tvalid_1's rmse: 0.0883369\n",
      "[775]\ttraining's rmse: 0.0840377\tvalid_1's rmse: 0.0883272\n",
      "[800]\ttraining's rmse: 0.0840028\tvalid_1's rmse: 0.0883191\n",
      "[825]\ttraining's rmse: 0.0839725\tvalid_1's rmse: 0.0883086\n",
      "[850]\ttraining's rmse: 0.0839394\tvalid_1's rmse: 0.0882999\n",
      "[875]\ttraining's rmse: 0.0839109\tvalid_1's rmse: 0.0882921\n",
      "[900]\ttraining's rmse: 0.0838802\tvalid_1's rmse: 0.0882822\n",
      "[925]\ttraining's rmse: 0.0838526\tvalid_1's rmse: 0.088275\n",
      "[950]\ttraining's rmse: 0.0838271\tvalid_1's rmse: 0.088267\n",
      "[975]\ttraining's rmse: 0.0838009\tvalid_1's rmse: 0.0882596\n",
      "[1000]\ttraining's rmse: 0.0837772\tvalid_1's rmse: 0.088253\n",
      "[1025]\ttraining's rmse: 0.0837514\tvalid_1's rmse: 0.0882459\n",
      "[1050]\ttraining's rmse: 0.0837298\tvalid_1's rmse: 0.0882397\n",
      "[1075]\ttraining's rmse: 0.0837092\tvalid_1's rmse: 0.0882351\n",
      "[1100]\ttraining's rmse: 0.0836908\tvalid_1's rmse: 0.0882301\n",
      "[1125]\ttraining's rmse: 0.0836721\tvalid_1's rmse: 0.0882248\n",
      "[1150]\ttraining's rmse: 0.0836517\tvalid_1's rmse: 0.0882194\n",
      "[1175]\ttraining's rmse: 0.0836341\tvalid_1's rmse: 0.088215\n",
      "[1200]\ttraining's rmse: 0.0836161\tvalid_1's rmse: 0.0882107\n",
      "[1225]\ttraining's rmse: 0.083599\tvalid_1's rmse: 0.0882052\n",
      "[1250]\ttraining's rmse: 0.0835829\tvalid_1's rmse: 0.0882009\n",
      "[1275]\ttraining's rmse: 0.0835613\tvalid_1's rmse: 0.0881967\n",
      "[1300]\ttraining's rmse: 0.0835487\tvalid_1's rmse: 0.0881927\n",
      "[1325]\ttraining's rmse: 0.0835338\tvalid_1's rmse: 0.0881884\n",
      "[1350]\ttraining's rmse: 0.0835204\tvalid_1's rmse: 0.0881851\n",
      "[1375]\ttraining's rmse: 0.0835061\tvalid_1's rmse: 0.0881821\n",
      "[1400]\ttraining's rmse: 0.0834944\tvalid_1's rmse: 0.0881785\n",
      "[1425]\ttraining's rmse: 0.0834793\tvalid_1's rmse: 0.0881747\n",
      "[1450]\ttraining's rmse: 0.0834653\tvalid_1's rmse: 0.0881718\n",
      "[1475]\ttraining's rmse: 0.0834534\tvalid_1's rmse: 0.088169\n",
      "[1500]\ttraining's rmse: 0.0834443\tvalid_1's rmse: 0.0881665\n",
      "[1525]\ttraining's rmse: 0.0834334\tvalid_1's rmse: 0.0881643\n",
      "[1550]\ttraining's rmse: 0.0834224\tvalid_1's rmse: 0.0881626\n",
      "[1575]\ttraining's rmse: 0.0834112\tvalid_1's rmse: 0.0881603\n",
      "[1600]\ttraining's rmse: 0.0834037\tvalid_1's rmse: 0.0881583\n",
      "[1625]\ttraining's rmse: 0.0833976\tvalid_1's rmse: 0.0881556\n",
      "[1650]\ttraining's rmse: 0.0833899\tvalid_1's rmse: 0.0881524\n",
      "[1675]\ttraining's rmse: 0.0833841\tvalid_1's rmse: 0.0881498\n",
      "[1700]\ttraining's rmse: 0.0833777\tvalid_1's rmse: 0.0881474\n",
      "[1725]\ttraining's rmse: 0.0833713\tvalid_1's rmse: 0.0881452\n",
      "[1750]\ttraining's rmse: 0.0833629\tvalid_1's rmse: 0.0881419\n",
      "[1775]\ttraining's rmse: 0.0833561\tvalid_1's rmse: 0.0881402\n",
      "[1800]\ttraining's rmse: 0.0833491\tvalid_1's rmse: 0.0881383\n",
      "[1825]\ttraining's rmse: 0.0833439\tvalid_1's rmse: 0.0881368\n",
      "[1850]\ttraining's rmse: 0.0833379\tvalid_1's rmse: 0.0881353\n",
      "[1875]\ttraining's rmse: 0.0833308\tvalid_1's rmse: 0.0881332\n",
      "[1900]\ttraining's rmse: 0.0833267\tvalid_1's rmse: 0.0881321\n",
      "[1925]\ttraining's rmse: 0.0833225\tvalid_1's rmse: 0.0881308\n",
      "[1950]\ttraining's rmse: 0.083318\tvalid_1's rmse: 0.0881302\n",
      "[1975]\ttraining's rmse: 0.0833151\tvalid_1's rmse: 0.0881288\n",
      "[2000]\ttraining's rmse: 0.0833094\tvalid_1's rmse: 0.088128\n",
      "[2025]\ttraining's rmse: 0.0833049\tvalid_1's rmse: 0.0881265\n",
      "[2050]\ttraining's rmse: 0.083301\tvalid_1's rmse: 0.0881253\n",
      "[2075]\ttraining's rmse: 0.0832961\tvalid_1's rmse: 0.0881236\n",
      "[2100]\ttraining's rmse: 0.083293\tvalid_1's rmse: 0.0881231\n",
      "[2125]\ttraining's rmse: 0.0832903\tvalid_1's rmse: 0.0881216\n",
      "[2150]\ttraining's rmse: 0.0832853\tvalid_1's rmse: 0.088121\n",
      "[2175]\ttraining's rmse: 0.0832817\tvalid_1's rmse: 0.0881207\n",
      "[2200]\ttraining's rmse: 0.0832752\tvalid_1's rmse: 0.0881204\n",
      "[2225]\ttraining's rmse: 0.0832726\tvalid_1's rmse: 0.0881194\n",
      "[2250]\ttraining's rmse: 0.0832685\tvalid_1's rmse: 0.0881188\n",
      "[2275]\ttraining's rmse: 0.0832659\tvalid_1's rmse: 0.0881187\n",
      "[2300]\ttraining's rmse: 0.0832631\tvalid_1's rmse: 0.088117\n",
      "[2325]\ttraining's rmse: 0.0832592\tvalid_1's rmse: 0.0881164\n",
      "[2350]\ttraining's rmse: 0.0832568\tvalid_1's rmse: 0.0881157\n",
      "[2375]\ttraining's rmse: 0.0832545\tvalid_1's rmse: 0.0881146\n",
      "[2400]\ttraining's rmse: 0.0832508\tvalid_1's rmse: 0.088114\n",
      "[2425]\ttraining's rmse: 0.0832483\tvalid_1's rmse: 0.0881135\n",
      "[2450]\ttraining's rmse: 0.083246\tvalid_1's rmse: 0.0881129\n",
      "[2475]\ttraining's rmse: 0.0832413\tvalid_1's rmse: 0.0881125\n",
      "[2500]\ttraining's rmse: 0.0832397\tvalid_1's rmse: 0.0881121\n",
      "[2525]\ttraining's rmse: 0.0832359\tvalid_1's rmse: 0.0881116\n",
      "[2550]\ttraining's rmse: 0.0832338\tvalid_1's rmse: 0.0881114\n",
      "[2575]\ttraining's rmse: 0.083232\tvalid_1's rmse: 0.0881109\n",
      "[2600]\ttraining's rmse: 0.0832295\tvalid_1's rmse: 0.0881103\n",
      "[2625]\ttraining's rmse: 0.0832266\tvalid_1's rmse: 0.0881094\n",
      "[2650]\ttraining's rmse: 0.0832241\tvalid_1's rmse: 0.0881082\n",
      "[2675]\ttraining's rmse: 0.0832221\tvalid_1's rmse: 0.0881078\n",
      "[2700]\ttraining's rmse: 0.0832189\tvalid_1's rmse: 0.0881074\n",
      "[2725]\ttraining's rmse: 0.0832169\tvalid_1's rmse: 0.0881073\n",
      "[2750]\ttraining's rmse: 0.0832156\tvalid_1's rmse: 0.0881061\n",
      "[2775]\ttraining's rmse: 0.0832133\tvalid_1's rmse: 0.088106\n",
      "[2800]\ttraining's rmse: 0.0832104\tvalid_1's rmse: 0.0881059\n",
      "[2825]\ttraining's rmse: 0.0832088\tvalid_1's rmse: 0.088106\n",
      "[2850]\ttraining's rmse: 0.0832066\tvalid_1's rmse: 0.088106\n",
      "[2875]\ttraining's rmse: 0.0832032\tvalid_1's rmse: 0.0881053\n",
      "[2900]\ttraining's rmse: 0.0832014\tvalid_1's rmse: 0.0881053\n",
      "[2925]\ttraining's rmse: 0.0831999\tvalid_1's rmse: 0.0881055\n",
      "Early stopping, best iteration is:\n",
      "[2881]\ttraining's rmse: 0.0832025\tvalid_1's rmse: 0.0881051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0866206\tvalid_1's rmse: 0.0883268\n",
      "[50]\ttraining's rmse: 0.0864919\tvalid_1's rmse: 0.0882687\n",
      "[75]\ttraining's rmse: 0.0863592\tvalid_1's rmse: 0.0882114\n",
      "[100]\ttraining's rmse: 0.086241\tvalid_1's rmse: 0.08816\n",
      "[125]\ttraining's rmse: 0.0861183\tvalid_1's rmse: 0.0881097\n",
      "[150]\ttraining's rmse: 0.086008\tvalid_1's rmse: 0.0880626\n",
      "[175]\ttraining's rmse: 0.0859161\tvalid_1's rmse: 0.0880254\n",
      "[200]\ttraining's rmse: 0.0858149\tvalid_1's rmse: 0.0879857\n",
      "[225]\ttraining's rmse: 0.0857188\tvalid_1's rmse: 0.0879507\n",
      "[250]\ttraining's rmse: 0.0856368\tvalid_1's rmse: 0.0879171\n",
      "[275]\ttraining's rmse: 0.0855566\tvalid_1's rmse: 0.0878863\n",
      "[300]\ttraining's rmse: 0.0854787\tvalid_1's rmse: 0.0878574\n",
      "[325]\ttraining's rmse: 0.0854011\tvalid_1's rmse: 0.0878287\n",
      "[350]\ttraining's rmse: 0.0853254\tvalid_1's rmse: 0.0878028\n",
      "[375]\ttraining's rmse: 0.0852643\tvalid_1's rmse: 0.0877813\n",
      "[400]\ttraining's rmse: 0.0851964\tvalid_1's rmse: 0.0877588\n",
      "[425]\ttraining's rmse: 0.085133\tvalid_1's rmse: 0.087738\n",
      "[450]\ttraining's rmse: 0.0850741\tvalid_1's rmse: 0.0877168\n",
      "[475]\ttraining's rmse: 0.085021\tvalid_1's rmse: 0.0876991\n",
      "[500]\ttraining's rmse: 0.0849734\tvalid_1's rmse: 0.0876815\n",
      "[525]\ttraining's rmse: 0.0849154\tvalid_1's rmse: 0.087665\n",
      "[550]\ttraining's rmse: 0.0848621\tvalid_1's rmse: 0.0876509\n",
      "[575]\ttraining's rmse: 0.0848144\tvalid_1's rmse: 0.0876367\n",
      "[600]\ttraining's rmse: 0.0847663\tvalid_1's rmse: 0.0876232\n",
      "[625]\ttraining's rmse: 0.0847279\tvalid_1's rmse: 0.087611\n",
      "[650]\ttraining's rmse: 0.0846797\tvalid_1's rmse: 0.0875981\n",
      "[675]\ttraining's rmse: 0.0846325\tvalid_1's rmse: 0.0875865\n",
      "[700]\ttraining's rmse: 0.0845899\tvalid_1's rmse: 0.0875757\n",
      "[725]\ttraining's rmse: 0.0845499\tvalid_1's rmse: 0.087565\n",
      "[750]\ttraining's rmse: 0.0845136\tvalid_1's rmse: 0.0875566\n",
      "[775]\ttraining's rmse: 0.0844844\tvalid_1's rmse: 0.0875474\n",
      "[800]\ttraining's rmse: 0.0844453\tvalid_1's rmse: 0.0875394\n",
      "[825]\ttraining's rmse: 0.084412\tvalid_1's rmse: 0.0875312\n",
      "[850]\ttraining's rmse: 0.0843796\tvalid_1's rmse: 0.0875237\n",
      "[875]\ttraining's rmse: 0.0843502\tvalid_1's rmse: 0.0875172\n",
      "[900]\ttraining's rmse: 0.0843192\tvalid_1's rmse: 0.087511\n",
      "[925]\ttraining's rmse: 0.0842893\tvalid_1's rmse: 0.0875052\n",
      "[950]\ttraining's rmse: 0.0842643\tvalid_1's rmse: 0.0874995\n",
      "[975]\ttraining's rmse: 0.0842397\tvalid_1's rmse: 0.0874939\n",
      "[1000]\ttraining's rmse: 0.0842166\tvalid_1's rmse: 0.087489\n",
      "[1025]\ttraining's rmse: 0.0841882\tvalid_1's rmse: 0.0874843\n",
      "[1050]\ttraining's rmse: 0.0841672\tvalid_1's rmse: 0.0874797\n",
      "[1075]\ttraining's rmse: 0.0841425\tvalid_1's rmse: 0.0874756\n",
      "[1100]\ttraining's rmse: 0.0841232\tvalid_1's rmse: 0.087471\n",
      "[1125]\ttraining's rmse: 0.0841031\tvalid_1's rmse: 0.0874679\n",
      "[1150]\ttraining's rmse: 0.084083\tvalid_1's rmse: 0.087464\n",
      "[1175]\ttraining's rmse: 0.0840662\tvalid_1's rmse: 0.0874611\n",
      "[1200]\ttraining's rmse: 0.0840468\tvalid_1's rmse: 0.0874578\n",
      "[1225]\ttraining's rmse: 0.0840293\tvalid_1's rmse: 0.0874551\n",
      "[1250]\ttraining's rmse: 0.0840142\tvalid_1's rmse: 0.0874525\n",
      "[1275]\ttraining's rmse: 0.083996\tvalid_1's rmse: 0.0874499\n",
      "[1300]\ttraining's rmse: 0.0839814\tvalid_1's rmse: 0.0874475\n",
      "[1325]\ttraining's rmse: 0.0839677\tvalid_1's rmse: 0.0874449\n",
      "[1350]\ttraining's rmse: 0.0839527\tvalid_1's rmse: 0.0874427\n",
      "[1375]\ttraining's rmse: 0.0839372\tvalid_1's rmse: 0.0874409\n",
      "[1400]\ttraining's rmse: 0.0839254\tvalid_1's rmse: 0.0874385\n",
      "[1425]\ttraining's rmse: 0.0839123\tvalid_1's rmse: 0.087437\n",
      "[1450]\ttraining's rmse: 0.0839003\tvalid_1's rmse: 0.0874351\n",
      "[1475]\ttraining's rmse: 0.0838877\tvalid_1's rmse: 0.0874333\n",
      "[1500]\ttraining's rmse: 0.083876\tvalid_1's rmse: 0.0874318\n",
      "[1525]\ttraining's rmse: 0.0838631\tvalid_1's rmse: 0.0874304\n",
      "[1550]\ttraining's rmse: 0.0838525\tvalid_1's rmse: 0.0874297\n",
      "[1575]\ttraining's rmse: 0.0838415\tvalid_1's rmse: 0.087428\n",
      "[1600]\ttraining's rmse: 0.0838323\tvalid_1's rmse: 0.087427\n",
      "[1625]\ttraining's rmse: 0.0838223\tvalid_1's rmse: 0.0874258\n",
      "[1650]\ttraining's rmse: 0.0838122\tvalid_1's rmse: 0.0874249\n",
      "[1675]\ttraining's rmse: 0.0838059\tvalid_1's rmse: 0.0874239\n",
      "[1700]\ttraining's rmse: 0.0838008\tvalid_1's rmse: 0.0874234\n",
      "[1725]\ttraining's rmse: 0.0837912\tvalid_1's rmse: 0.0874224\n",
      "[1750]\ttraining's rmse: 0.0837814\tvalid_1's rmse: 0.0874217\n",
      "[1775]\ttraining's rmse: 0.0837731\tvalid_1's rmse: 0.0874213\n",
      "[1800]\ttraining's rmse: 0.0837663\tvalid_1's rmse: 0.0874204\n",
      "[1825]\ttraining's rmse: 0.0837593\tvalid_1's rmse: 0.0874193\n",
      "[1850]\ttraining's rmse: 0.0837538\tvalid_1's rmse: 0.0874183\n",
      "[1875]\ttraining's rmse: 0.083748\tvalid_1's rmse: 0.0874185\n",
      "[1900]\ttraining's rmse: 0.0837442\tvalid_1's rmse: 0.0874186\n",
      "[1925]\ttraining's rmse: 0.0837386\tvalid_1's rmse: 0.0874182\n",
      "[1950]\ttraining's rmse: 0.0837354\tvalid_1's rmse: 0.0874175\n",
      "[1975]\ttraining's rmse: 0.0837322\tvalid_1's rmse: 0.0874174\n",
      "[2000]\ttraining's rmse: 0.0837263\tvalid_1's rmse: 0.0874169\n",
      "[2025]\ttraining's rmse: 0.0837221\tvalid_1's rmse: 0.0874166\n",
      "[2050]\ttraining's rmse: 0.0837177\tvalid_1's rmse: 0.0874165\n",
      "[2075]\ttraining's rmse: 0.0837133\tvalid_1's rmse: 0.087416\n",
      "[2100]\ttraining's rmse: 0.0837101\tvalid_1's rmse: 0.0874155\n",
      "[2125]\ttraining's rmse: 0.0837064\tvalid_1's rmse: 0.0874153\n",
      "[2150]\ttraining's rmse: 0.0837009\tvalid_1's rmse: 0.0874151\n",
      "[2175]\ttraining's rmse: 0.0836963\tvalid_1's rmse: 0.0874151\n",
      "[2200]\ttraining's rmse: 0.0836936\tvalid_1's rmse: 0.0874148\n",
      "[2225]\ttraining's rmse: 0.0836905\tvalid_1's rmse: 0.0874145\n",
      "[2250]\ttraining's rmse: 0.0836875\tvalid_1's rmse: 0.0874143\n",
      "[2275]\ttraining's rmse: 0.0836846\tvalid_1's rmse: 0.0874144\n",
      "[2300]\ttraining's rmse: 0.0836819\tvalid_1's rmse: 0.0874143\n",
      "[2325]\ttraining's rmse: 0.0836771\tvalid_1's rmse: 0.0874133\n",
      "[2350]\ttraining's rmse: 0.0836745\tvalid_1's rmse: 0.0874127\n",
      "[2375]\ttraining's rmse: 0.0836718\tvalid_1's rmse: 0.0874128\n",
      "[2400]\ttraining's rmse: 0.0836697\tvalid_1's rmse: 0.0874132\n",
      "Early stopping, best iteration is:\n",
      "[2367]\ttraining's rmse: 0.0836727\tvalid_1's rmse: 0.0874126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0886091\tvalid_1's rmse: 0.0842905\n",
      "[50]\ttraining's rmse: 0.0884865\tvalid_1's rmse: 0.0842399\n",
      "[75]\ttraining's rmse: 0.0883617\tvalid_1's rmse: 0.0841902\n",
      "[100]\ttraining's rmse: 0.0882487\tvalid_1's rmse: 0.0841457\n",
      "[125]\ttraining's rmse: 0.0881315\tvalid_1's rmse: 0.0841028\n",
      "[150]\ttraining's rmse: 0.0880234\tvalid_1's rmse: 0.0840634\n",
      "[175]\ttraining's rmse: 0.0879353\tvalid_1's rmse: 0.0840308\n",
      "[200]\ttraining's rmse: 0.0878409\tvalid_1's rmse: 0.0839986\n",
      "[225]\ttraining's rmse: 0.0877496\tvalid_1's rmse: 0.0839667\n",
      "[250]\ttraining's rmse: 0.0876708\tvalid_1's rmse: 0.0839395\n",
      "[275]\ttraining's rmse: 0.0875983\tvalid_1's rmse: 0.0839138\n",
      "[300]\ttraining's rmse: 0.0875239\tvalid_1's rmse: 0.0838897\n",
      "[325]\ttraining's rmse: 0.087452\tvalid_1's rmse: 0.0838658\n",
      "[350]\ttraining's rmse: 0.0873822\tvalid_1's rmse: 0.0838436\n",
      "[375]\ttraining's rmse: 0.0873229\tvalid_1's rmse: 0.0838271\n",
      "[400]\ttraining's rmse: 0.0872599\tvalid_1's rmse: 0.0838139\n",
      "[425]\ttraining's rmse: 0.0872008\tvalid_1's rmse: 0.0837968\n",
      "[450]\ttraining's rmse: 0.0871459\tvalid_1's rmse: 0.0837801\n",
      "[475]\ttraining's rmse: 0.0870952\tvalid_1's rmse: 0.0837651\n",
      "[500]\ttraining's rmse: 0.087053\tvalid_1's rmse: 0.0837513\n",
      "[525]\ttraining's rmse: 0.086996\tvalid_1's rmse: 0.0837421\n",
      "[550]\ttraining's rmse: 0.0869434\tvalid_1's rmse: 0.0837316\n",
      "[575]\ttraining's rmse: 0.0868933\tvalid_1's rmse: 0.0837241\n",
      "[600]\ttraining's rmse: 0.0868458\tvalid_1's rmse: 0.0837153\n",
      "[625]\ttraining's rmse: 0.0868089\tvalid_1's rmse: 0.0837207\n",
      "[650]\ttraining's rmse: 0.086762\tvalid_1's rmse: 0.0837279\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's rmse: 0.0868458\tvalid_1's rmse: 0.0837153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0846299\tvalid_1's rmse: 0.0870998\n",
      "[50]\ttraining's rmse: 0.0845004\tvalid_1's rmse: 0.0870482\n",
      "[75]\ttraining's rmse: 0.084373\tvalid_1's rmse: 0.0869963\n",
      "[100]\ttraining's rmse: 0.0842539\tvalid_1's rmse: 0.0869522\n",
      "[125]\ttraining's rmse: 0.0841337\tvalid_1's rmse: 0.0869068\n",
      "[150]\ttraining's rmse: 0.0840261\tvalid_1's rmse: 0.0868647\n",
      "[175]\ttraining's rmse: 0.0839379\tvalid_1's rmse: 0.0868284\n",
      "[200]\ttraining's rmse: 0.0838433\tvalid_1's rmse: 0.0867932\n",
      "[225]\ttraining's rmse: 0.0837477\tvalid_1's rmse: 0.0867566\n",
      "[250]\ttraining's rmse: 0.0836693\tvalid_1's rmse: 0.0867242\n",
      "[275]\ttraining's rmse: 0.0835939\tvalid_1's rmse: 0.0866967\n",
      "[300]\ttraining's rmse: 0.0835226\tvalid_1's rmse: 0.0866685\n",
      "[325]\ttraining's rmse: 0.0834471\tvalid_1's rmse: 0.0866425\n",
      "[350]\ttraining's rmse: 0.0833771\tvalid_1's rmse: 0.0866175\n",
      "[375]\ttraining's rmse: 0.0833144\tvalid_1's rmse: 0.0865975\n",
      "[400]\ttraining's rmse: 0.0832516\tvalid_1's rmse: 0.0865777\n",
      "[425]\ttraining's rmse: 0.0831943\tvalid_1's rmse: 0.0865586\n",
      "[450]\ttraining's rmse: 0.0831421\tvalid_1's rmse: 0.086538\n",
      "[475]\ttraining's rmse: 0.0830918\tvalid_1's rmse: 0.0865198\n",
      "[500]\ttraining's rmse: 0.0830484\tvalid_1's rmse: 0.0865035\n",
      "[525]\ttraining's rmse: 0.0829967\tvalid_1's rmse: 0.0864872\n",
      "[550]\ttraining's rmse: 0.0829512\tvalid_1's rmse: 0.0864721\n",
      "[575]\ttraining's rmse: 0.0829066\tvalid_1's rmse: 0.0864591\n",
      "[600]\ttraining's rmse: 0.0828637\tvalid_1's rmse: 0.0864454\n",
      "[625]\ttraining's rmse: 0.0828313\tvalid_1's rmse: 0.0864332\n",
      "[650]\ttraining's rmse: 0.0827907\tvalid_1's rmse: 0.08642\n",
      "[675]\ttraining's rmse: 0.0827522\tvalid_1's rmse: 0.0864081\n",
      "[700]\ttraining's rmse: 0.0827145\tvalid_1's rmse: 0.0863981\n",
      "[725]\ttraining's rmse: 0.0826782\tvalid_1's rmse: 0.0863893\n",
      "[750]\ttraining's rmse: 0.0826429\tvalid_1's rmse: 0.08638\n",
      "[775]\ttraining's rmse: 0.0826175\tvalid_1's rmse: 0.0863712\n",
      "[800]\ttraining's rmse: 0.0825842\tvalid_1's rmse: 0.086364\n",
      "[825]\ttraining's rmse: 0.0825533\tvalid_1's rmse: 0.0863549\n",
      "[850]\ttraining's rmse: 0.0825223\tvalid_1's rmse: 0.0863481\n",
      "[875]\ttraining's rmse: 0.082494\tvalid_1's rmse: 0.0863397\n",
      "[900]\ttraining's rmse: 0.0824618\tvalid_1's rmse: 0.0863339\n",
      "[925]\ttraining's rmse: 0.0824383\tvalid_1's rmse: 0.0863273\n",
      "[950]\ttraining's rmse: 0.0824155\tvalid_1's rmse: 0.0863206\n",
      "[975]\ttraining's rmse: 0.0823916\tvalid_1's rmse: 0.0863155\n",
      "[1000]\ttraining's rmse: 0.0823674\tvalid_1's rmse: 0.0863105\n",
      "[1025]\ttraining's rmse: 0.0823451\tvalid_1's rmse: 0.0863047\n",
      "[1050]\ttraining's rmse: 0.0823243\tvalid_1's rmse: 0.0862986\n",
      "[1075]\ttraining's rmse: 0.0823042\tvalid_1's rmse: 0.0862943\n",
      "[1100]\ttraining's rmse: 0.0822872\tvalid_1's rmse: 0.0862897\n",
      "[1125]\ttraining's rmse: 0.0822707\tvalid_1's rmse: 0.0862856\n",
      "[1150]\ttraining's rmse: 0.0822516\tvalid_1's rmse: 0.0862818\n",
      "[1175]\ttraining's rmse: 0.0822368\tvalid_1's rmse: 0.086279\n",
      "[1200]\ttraining's rmse: 0.0822196\tvalid_1's rmse: 0.0862724\n",
      "[1225]\ttraining's rmse: 0.0822034\tvalid_1's rmse: 0.0862678\n",
      "[1250]\ttraining's rmse: 0.0821863\tvalid_1's rmse: 0.0862637\n",
      "[1275]\ttraining's rmse: 0.0821675\tvalid_1's rmse: 0.0862605\n",
      "[1300]\ttraining's rmse: 0.0821537\tvalid_1's rmse: 0.0862561\n",
      "[1325]\ttraining's rmse: 0.0821416\tvalid_1's rmse: 0.086253\n",
      "[1350]\ttraining's rmse: 0.0821277\tvalid_1's rmse: 0.0862501\n",
      "[1375]\ttraining's rmse: 0.0821157\tvalid_1's rmse: 0.086246\n",
      "[1400]\ttraining's rmse: 0.0821037\tvalid_1's rmse: 0.0862419\n",
      "[1425]\ttraining's rmse: 0.0820903\tvalid_1's rmse: 0.086239\n",
      "[1450]\ttraining's rmse: 0.0820764\tvalid_1's rmse: 0.0862367\n",
      "[1475]\ttraining's rmse: 0.0820667\tvalid_1's rmse: 0.0862332\n",
      "[1500]\ttraining's rmse: 0.0820588\tvalid_1's rmse: 0.0862307\n",
      "[1525]\ttraining's rmse: 0.0820486\tvalid_1's rmse: 0.0862282\n",
      "[1550]\ttraining's rmse: 0.0820376\tvalid_1's rmse: 0.0862263\n",
      "[1575]\ttraining's rmse: 0.0820298\tvalid_1's rmse: 0.086225\n",
      "[1600]\ttraining's rmse: 0.0820218\tvalid_1's rmse: 0.0862218\n",
      "[1625]\ttraining's rmse: 0.0820159\tvalid_1's rmse: 0.0862193\n",
      "[1650]\ttraining's rmse: 0.0820091\tvalid_1's rmse: 0.0862157\n",
      "[1675]\ttraining's rmse: 0.0820029\tvalid_1's rmse: 0.0862142\n",
      "[1700]\ttraining's rmse: 0.0819949\tvalid_1's rmse: 0.0862113\n",
      "[1725]\ttraining's rmse: 0.0819893\tvalid_1's rmse: 0.0862103\n",
      "[1750]\ttraining's rmse: 0.081984\tvalid_1's rmse: 0.0862089\n",
      "[1775]\ttraining's rmse: 0.0819784\tvalid_1's rmse: 0.0862072\n",
      "[1800]\ttraining's rmse: 0.0819737\tvalid_1's rmse: 0.0862063\n",
      "[1825]\ttraining's rmse: 0.0819678\tvalid_1's rmse: 0.0862047\n",
      "[1850]\ttraining's rmse: 0.0819628\tvalid_1's rmse: 0.0862021\n",
      "[1875]\ttraining's rmse: 0.0819564\tvalid_1's rmse: 0.0862009\n",
      "[1900]\ttraining's rmse: 0.0819509\tvalid_1's rmse: 0.0861994\n",
      "[1925]\ttraining's rmse: 0.0819455\tvalid_1's rmse: 0.0861983\n",
      "[1950]\ttraining's rmse: 0.0819414\tvalid_1's rmse: 0.0861974\n",
      "[1975]\ttraining's rmse: 0.0819377\tvalid_1's rmse: 0.0861958\n",
      "[2000]\ttraining's rmse: 0.0819345\tvalid_1's rmse: 0.0861944\n",
      "[2025]\ttraining's rmse: 0.0819298\tvalid_1's rmse: 0.0861929\n",
      "[2050]\ttraining's rmse: 0.081926\tvalid_1's rmse: 0.0861917\n",
      "[2075]\ttraining's rmse: 0.0819229\tvalid_1's rmse: 0.0861899\n",
      "[2100]\ttraining's rmse: 0.08192\tvalid_1's rmse: 0.0861886\n",
      "[2125]\ttraining's rmse: 0.0819177\tvalid_1's rmse: 0.0861873\n",
      "[2150]\ttraining's rmse: 0.0819143\tvalid_1's rmse: 0.0861866\n",
      "[2175]\ttraining's rmse: 0.0819125\tvalid_1's rmse: 0.0861863\n",
      "[2200]\ttraining's rmse: 0.0819093\tvalid_1's rmse: 0.0861857\n",
      "[2225]\ttraining's rmse: 0.0819062\tvalid_1's rmse: 0.0861851\n",
      "[2250]\ttraining's rmse: 0.0819033\tvalid_1's rmse: 0.0861842\n",
      "[2275]\ttraining's rmse: 0.0819001\tvalid_1's rmse: 0.0861832\n",
      "[2300]\ttraining's rmse: 0.0818978\tvalid_1's rmse: 0.0861829\n",
      "[2325]\ttraining's rmse: 0.0818944\tvalid_1's rmse: 0.0861814\n",
      "[2350]\ttraining's rmse: 0.0818914\tvalid_1's rmse: 0.0861808\n",
      "[2375]\ttraining's rmse: 0.0818895\tvalid_1's rmse: 0.0861808\n",
      "[2400]\ttraining's rmse: 0.0818876\tvalid_1's rmse: 0.0861798\n",
      "[2425]\ttraining's rmse: 0.0818851\tvalid_1's rmse: 0.0861792\n",
      "[2450]\ttraining's rmse: 0.0818837\tvalid_1's rmse: 0.0861785\n",
      "[2475]\ttraining's rmse: 0.0818807\tvalid_1's rmse: 0.0861785\n",
      "[2500]\ttraining's rmse: 0.0818787\tvalid_1's rmse: 0.086178\n",
      "[2525]\ttraining's rmse: 0.0818751\tvalid_1's rmse: 0.0861772\n",
      "[2550]\ttraining's rmse: 0.0818735\tvalid_1's rmse: 0.0861774\n",
      "Early stopping, best iteration is:\n",
      "[2514]\ttraining's rmse: 0.0818755\tvalid_1's rmse: 0.0861772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0846948\tvalid_1's rmse: 0.086992\n",
      "[50]\ttraining's rmse: 0.0845787\tvalid_1's rmse: 0.0869399\n",
      "[75]\ttraining's rmse: 0.0844586\tvalid_1's rmse: 0.0868882\n",
      "[100]\ttraining's rmse: 0.0843493\tvalid_1's rmse: 0.0868416\n",
      "[125]\ttraining's rmse: 0.0842369\tvalid_1's rmse: 0.0867956\n",
      "[150]\ttraining's rmse: 0.0841356\tvalid_1's rmse: 0.0867526\n",
      "[175]\ttraining's rmse: 0.0840522\tvalid_1's rmse: 0.0867173\n",
      "[200]\ttraining's rmse: 0.0839609\tvalid_1's rmse: 0.0866811\n",
      "[225]\ttraining's rmse: 0.0838735\tvalid_1's rmse: 0.0866478\n",
      "[250]\ttraining's rmse: 0.0837984\tvalid_1's rmse: 0.0866167\n",
      "[275]\ttraining's rmse: 0.083731\tvalid_1's rmse: 0.0865891\n",
      "[300]\ttraining's rmse: 0.0836613\tvalid_1's rmse: 0.0865625\n",
      "[325]\ttraining's rmse: 0.0835895\tvalid_1's rmse: 0.0865362\n",
      "[350]\ttraining's rmse: 0.0835206\tvalid_1's rmse: 0.0865122\n",
      "[375]\ttraining's rmse: 0.0834635\tvalid_1's rmse: 0.0864918\n",
      "[400]\ttraining's rmse: 0.0834057\tvalid_1's rmse: 0.0864724\n",
      "[425]\ttraining's rmse: 0.083349\tvalid_1's rmse: 0.0864535\n",
      "[450]\ttraining's rmse: 0.0832976\tvalid_1's rmse: 0.086436\n",
      "[475]\ttraining's rmse: 0.083249\tvalid_1's rmse: 0.0864194\n",
      "[500]\ttraining's rmse: 0.0832067\tvalid_1's rmse: 0.0864032\n",
      "[525]\ttraining's rmse: 0.083154\tvalid_1's rmse: 0.0863872\n",
      "[550]\ttraining's rmse: 0.0831055\tvalid_1's rmse: 0.0863725\n",
      "[575]\ttraining's rmse: 0.0830622\tvalid_1's rmse: 0.086359\n",
      "[600]\ttraining's rmse: 0.0830199\tvalid_1's rmse: 0.0863463\n",
      "[625]\ttraining's rmse: 0.082985\tvalid_1's rmse: 0.0863336\n",
      "[650]\ttraining's rmse: 0.0829408\tvalid_1's rmse: 0.0863214\n",
      "[675]\ttraining's rmse: 0.0828985\tvalid_1's rmse: 0.0863105\n",
      "[700]\ttraining's rmse: 0.0828609\tvalid_1's rmse: 0.0863003\n",
      "[725]\ttraining's rmse: 0.0828254\tvalid_1's rmse: 0.0862908\n",
      "[750]\ttraining's rmse: 0.0827944\tvalid_1's rmse: 0.0862817\n",
      "[775]\ttraining's rmse: 0.0827674\tvalid_1's rmse: 0.0862731\n",
      "[800]\ttraining's rmse: 0.0827318\tvalid_1's rmse: 0.0862651\n",
      "[825]\ttraining's rmse: 0.0827029\tvalid_1's rmse: 0.0862567\n",
      "[850]\ttraining's rmse: 0.0826738\tvalid_1's rmse: 0.0862502\n",
      "[875]\ttraining's rmse: 0.082649\tvalid_1's rmse: 0.086244\n",
      "[900]\ttraining's rmse: 0.0826226\tvalid_1's rmse: 0.0862373\n",
      "[925]\ttraining's rmse: 0.0825977\tvalid_1's rmse: 0.0862308\n",
      "[950]\ttraining's rmse: 0.0825725\tvalid_1's rmse: 0.0862243\n",
      "[975]\ttraining's rmse: 0.0825519\tvalid_1's rmse: 0.0862196\n",
      "[1000]\ttraining's rmse: 0.08253\tvalid_1's rmse: 0.0862147\n",
      "[1025]\ttraining's rmse: 0.0825054\tvalid_1's rmse: 0.0862099\n",
      "[1050]\ttraining's rmse: 0.0824864\tvalid_1's rmse: 0.0862048\n",
      "[1075]\ttraining's rmse: 0.0824676\tvalid_1's rmse: 0.0862012\n",
      "[1100]\ttraining's rmse: 0.082447\tvalid_1's rmse: 0.0861967\n",
      "[1125]\ttraining's rmse: 0.08243\tvalid_1's rmse: 0.0861927\n",
      "[1150]\ttraining's rmse: 0.082412\tvalid_1's rmse: 0.0861889\n",
      "[1175]\ttraining's rmse: 0.082397\tvalid_1's rmse: 0.0861858\n",
      "[1200]\ttraining's rmse: 0.0823812\tvalid_1's rmse: 0.0861816\n",
      "[1225]\ttraining's rmse: 0.082364\tvalid_1's rmse: 0.0861791\n",
      "[1250]\ttraining's rmse: 0.0823497\tvalid_1's rmse: 0.0861762\n",
      "[1275]\ttraining's rmse: 0.0823331\tvalid_1's rmse: 0.0861738\n",
      "[1300]\ttraining's rmse: 0.0823199\tvalid_1's rmse: 0.0861713\n",
      "[1325]\ttraining's rmse: 0.0823062\tvalid_1's rmse: 0.0861693\n",
      "[1350]\ttraining's rmse: 0.0822944\tvalid_1's rmse: 0.0861677\n",
      "[1375]\ttraining's rmse: 0.0822816\tvalid_1's rmse: 0.0861661\n",
      "[1400]\ttraining's rmse: 0.0822716\tvalid_1's rmse: 0.0861636\n",
      "[1425]\ttraining's rmse: 0.0822607\tvalid_1's rmse: 0.0861623\n",
      "[1450]\ttraining's rmse: 0.0822481\tvalid_1's rmse: 0.0861602\n",
      "[1475]\ttraining's rmse: 0.0822396\tvalid_1's rmse: 0.0861585\n",
      "[1500]\ttraining's rmse: 0.0822305\tvalid_1's rmse: 0.0861574\n",
      "[1525]\ttraining's rmse: 0.0822202\tvalid_1's rmse: 0.0861557\n",
      "[1550]\ttraining's rmse: 0.0822121\tvalid_1's rmse: 0.0861543\n",
      "[1575]\ttraining's rmse: 0.0822035\tvalid_1's rmse: 0.0861523\n",
      "[1600]\ttraining's rmse: 0.0821972\tvalid_1's rmse: 0.0861513\n",
      "[1625]\ttraining's rmse: 0.082189\tvalid_1's rmse: 0.0861495\n",
      "[1650]\ttraining's rmse: 0.0821822\tvalid_1's rmse: 0.0861482\n",
      "[1675]\ttraining's rmse: 0.0821766\tvalid_1's rmse: 0.086147\n",
      "[1700]\ttraining's rmse: 0.0821719\tvalid_1's rmse: 0.086146\n",
      "[1725]\ttraining's rmse: 0.0821657\tvalid_1's rmse: 0.0861449\n",
      "[1750]\ttraining's rmse: 0.0821581\tvalid_1's rmse: 0.0861441\n",
      "[1775]\ttraining's rmse: 0.0821517\tvalid_1's rmse: 0.0861438\n",
      "[1800]\ttraining's rmse: 0.0821449\tvalid_1's rmse: 0.0861426\n",
      "[1825]\ttraining's rmse: 0.0821391\tvalid_1's rmse: 0.0861412\n",
      "[1850]\ttraining's rmse: 0.0821336\tvalid_1's rmse: 0.0861398\n",
      "[1875]\ttraining's rmse: 0.0821282\tvalid_1's rmse: 0.0861389\n",
      "[1900]\ttraining's rmse: 0.0821246\tvalid_1's rmse: 0.0861387\n",
      "[1925]\ttraining's rmse: 0.0821196\tvalid_1's rmse: 0.0861383\n",
      "[1950]\ttraining's rmse: 0.0821164\tvalid_1's rmse: 0.0861374\n",
      "[1975]\ttraining's rmse: 0.0821117\tvalid_1's rmse: 0.0861366\n",
      "[2000]\ttraining's rmse: 0.0821068\tvalid_1's rmse: 0.0861363\n",
      "[2025]\ttraining's rmse: 0.0821028\tvalid_1's rmse: 0.0861359\n",
      "[2050]\ttraining's rmse: 0.0820987\tvalid_1's rmse: 0.0861359\n",
      "[2075]\ttraining's rmse: 0.0820958\tvalid_1's rmse: 0.0861352\n",
      "[2100]\ttraining's rmse: 0.0820935\tvalid_1's rmse: 0.086135\n",
      "[2125]\ttraining's rmse: 0.0820906\tvalid_1's rmse: 0.0861349\n",
      "[2150]\ttraining's rmse: 0.0820865\tvalid_1's rmse: 0.0861347\n",
      "[2175]\ttraining's rmse: 0.0820831\tvalid_1's rmse: 0.0861344\n",
      "[2200]\ttraining's rmse: 0.0820798\tvalid_1's rmse: 0.0861343\n",
      "[2225]\ttraining's rmse: 0.0820764\tvalid_1's rmse: 0.0861335\n",
      "[2250]\ttraining's rmse: 0.0820727\tvalid_1's rmse: 0.0861334\n",
      "[2275]\ttraining's rmse: 0.0820697\tvalid_1's rmse: 0.0861333\n",
      "[2300]\ttraining's rmse: 0.0820652\tvalid_1's rmse: 0.0861325\n",
      "[2325]\ttraining's rmse: 0.082062\tvalid_1's rmse: 0.0861328\n",
      "Early stopping, best iteration is:\n",
      "[2299]\ttraining's rmse: 0.0820653\tvalid_1's rmse: 0.0861324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0869275\tvalid_1's rmse: 0.0824555\n",
      "[50]\ttraining's rmse: 0.0868179\tvalid_1's rmse: 0.0824102\n",
      "[75]\ttraining's rmse: 0.0867051\tvalid_1's rmse: 0.0823655\n",
      "[100]\ttraining's rmse: 0.086603\tvalid_1's rmse: 0.0823256\n",
      "[125]\ttraining's rmse: 0.0864969\tvalid_1's rmse: 0.0822852\n",
      "[150]\ttraining's rmse: 0.0863994\tvalid_1's rmse: 0.0822483\n",
      "[175]\ttraining's rmse: 0.0863196\tvalid_1's rmse: 0.0822177\n",
      "[200]\ttraining's rmse: 0.0862293\tvalid_1's rmse: 0.0821868\n",
      "[225]\ttraining's rmse: 0.0861443\tvalid_1's rmse: 0.0821559\n",
      "[250]\ttraining's rmse: 0.0860734\tvalid_1's rmse: 0.0821303\n",
      "[275]\ttraining's rmse: 0.086009\tvalid_1's rmse: 0.0821066\n",
      "[300]\ttraining's rmse: 0.0859432\tvalid_1's rmse: 0.0820837\n",
      "[325]\ttraining's rmse: 0.0858769\tvalid_1's rmse: 0.0820643\n",
      "[350]\ttraining's rmse: 0.0858116\tvalid_1's rmse: 0.0820429\n",
      "[375]\ttraining's rmse: 0.0857583\tvalid_1's rmse: 0.0820268\n",
      "[400]\ttraining's rmse: 0.0856993\tvalid_1's rmse: 0.0820151\n",
      "[425]\ttraining's rmse: 0.0856459\tvalid_1's rmse: 0.0820038\n",
      "[450]\ttraining's rmse: 0.0855952\tvalid_1's rmse: 0.0819893\n",
      "[475]\ttraining's rmse: 0.0855497\tvalid_1's rmse: 0.0819769\n",
      "[500]\ttraining's rmse: 0.0855113\tvalid_1's rmse: 0.0819652\n",
      "[525]\ttraining's rmse: 0.0854576\tvalid_1's rmse: 0.0819522\n",
      "[550]\ttraining's rmse: 0.0854127\tvalid_1's rmse: 0.0819402\n",
      "[575]\ttraining's rmse: 0.0853685\tvalid_1's rmse: 0.0819349\n",
      "[600]\ttraining's rmse: 0.0853244\tvalid_1's rmse: 0.0819257\n",
      "[625]\ttraining's rmse: 0.0852905\tvalid_1's rmse: 0.0819164\n",
      "[650]\ttraining's rmse: 0.0852468\tvalid_1's rmse: 0.0819213\n",
      "[675]\ttraining's rmse: 0.0852045\tvalid_1's rmse: 0.081913\n",
      "[700]\ttraining's rmse: 0.0851661\tvalid_1's rmse: 0.081905\n",
      "[725]\ttraining's rmse: 0.0851314\tvalid_1's rmse: 0.0819072\n",
      "[750]\ttraining's rmse: 0.085099\tvalid_1's rmse: 0.0819122\n",
      "[775]\ttraining's rmse: 0.0850712\tvalid_1's rmse: 0.0819163\n",
      "Early stopping, best iteration is:\n",
      "[746]\ttraining's rmse: 0.0851057\tvalid_1's rmse: 0.0819012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0841729\tvalid_1's rmse: 0.0866084\n",
      "[50]\ttraining's rmse: 0.0840424\tvalid_1's rmse: 0.0865573\n",
      "[75]\ttraining's rmse: 0.0839152\tvalid_1's rmse: 0.0865058\n",
      "[100]\ttraining's rmse: 0.0837999\tvalid_1's rmse: 0.086462\n",
      "[125]\ttraining's rmse: 0.0836837\tvalid_1's rmse: 0.0864164\n",
      "[150]\ttraining's rmse: 0.083576\tvalid_1's rmse: 0.0863734\n",
      "[175]\ttraining's rmse: 0.0834856\tvalid_1's rmse: 0.0863372\n",
      "[200]\ttraining's rmse: 0.0833911\tvalid_1's rmse: 0.0863029\n",
      "[225]\ttraining's rmse: 0.0832982\tvalid_1's rmse: 0.0862677\n",
      "[250]\ttraining's rmse: 0.0832211\tvalid_1's rmse: 0.0862367\n",
      "[275]\ttraining's rmse: 0.0831478\tvalid_1's rmse: 0.0862072\n",
      "[300]\ttraining's rmse: 0.0830742\tvalid_1's rmse: 0.0861794\n",
      "[325]\ttraining's rmse: 0.0830018\tvalid_1's rmse: 0.0861534\n",
      "[350]\ttraining's rmse: 0.0829318\tvalid_1's rmse: 0.086129\n",
      "[375]\ttraining's rmse: 0.0828737\tvalid_1's rmse: 0.0861081\n",
      "[400]\ttraining's rmse: 0.0828095\tvalid_1's rmse: 0.0860867\n",
      "[425]\ttraining's rmse: 0.0827516\tvalid_1's rmse: 0.086067\n",
      "[450]\ttraining's rmse: 0.0827004\tvalid_1's rmse: 0.0860478\n",
      "[475]\ttraining's rmse: 0.0826543\tvalid_1's rmse: 0.086031\n",
      "[500]\ttraining's rmse: 0.0826119\tvalid_1's rmse: 0.0860122\n",
      "[525]\ttraining's rmse: 0.0825567\tvalid_1's rmse: 0.0859949\n",
      "[550]\ttraining's rmse: 0.0825123\tvalid_1's rmse: 0.0859796\n",
      "[575]\ttraining's rmse: 0.0824667\tvalid_1's rmse: 0.0859656\n",
      "[600]\ttraining's rmse: 0.0824265\tvalid_1's rmse: 0.0859524\n",
      "[625]\ttraining's rmse: 0.0823917\tvalid_1's rmse: 0.0859412\n",
      "[650]\ttraining's rmse: 0.0823493\tvalid_1's rmse: 0.0859283\n",
      "[675]\ttraining's rmse: 0.0823078\tvalid_1's rmse: 0.0859155\n",
      "[700]\ttraining's rmse: 0.08227\tvalid_1's rmse: 0.0859038\n",
      "[725]\ttraining's rmse: 0.082235\tvalid_1's rmse: 0.0858935\n",
      "[750]\ttraining's rmse: 0.0822023\tvalid_1's rmse: 0.0858832\n",
      "[775]\ttraining's rmse: 0.0821767\tvalid_1's rmse: 0.0858729\n",
      "[800]\ttraining's rmse: 0.082141\tvalid_1's rmse: 0.0858638\n",
      "[825]\ttraining's rmse: 0.0821109\tvalid_1's rmse: 0.0858544\n",
      "[850]\ttraining's rmse: 0.0820796\tvalid_1's rmse: 0.085847\n",
      "[875]\ttraining's rmse: 0.0820536\tvalid_1's rmse: 0.0858395\n",
      "[900]\ttraining's rmse: 0.0820249\tvalid_1's rmse: 0.0858322\n",
      "[925]\ttraining's rmse: 0.0820004\tvalid_1's rmse: 0.0858259\n",
      "[950]\ttraining's rmse: 0.0819752\tvalid_1's rmse: 0.0858191\n",
      "[975]\ttraining's rmse: 0.0819508\tvalid_1's rmse: 0.085813\n",
      "[1000]\ttraining's rmse: 0.0819292\tvalid_1's rmse: 0.0858081\n",
      "[1025]\ttraining's rmse: 0.0819041\tvalid_1's rmse: 0.085801\n",
      "[1050]\ttraining's rmse: 0.0818814\tvalid_1's rmse: 0.0857939\n",
      "[1075]\ttraining's rmse: 0.0818625\tvalid_1's rmse: 0.0857898\n",
      "[1100]\ttraining's rmse: 0.0818455\tvalid_1's rmse: 0.0857847\n",
      "[1125]\ttraining's rmse: 0.0818272\tvalid_1's rmse: 0.0857777\n",
      "[1150]\ttraining's rmse: 0.0818085\tvalid_1's rmse: 0.0857724\n",
      "[1175]\ttraining's rmse: 0.081791\tvalid_1's rmse: 0.0857678\n",
      "[1200]\ttraining's rmse: 0.0817763\tvalid_1's rmse: 0.0857631\n",
      "[1225]\ttraining's rmse: 0.0817564\tvalid_1's rmse: 0.0857589\n",
      "[1250]\ttraining's rmse: 0.0817403\tvalid_1's rmse: 0.0857536\n",
      "[1275]\ttraining's rmse: 0.0817229\tvalid_1's rmse: 0.0857488\n",
      "[1300]\ttraining's rmse: 0.0817119\tvalid_1's rmse: 0.0857429\n",
      "[1325]\ttraining's rmse: 0.0816993\tvalid_1's rmse: 0.0857396\n",
      "[1350]\ttraining's rmse: 0.0816865\tvalid_1's rmse: 0.0857353\n",
      "[1375]\ttraining's rmse: 0.081674\tvalid_1's rmse: 0.0857322\n",
      "[1400]\ttraining's rmse: 0.0816651\tvalid_1's rmse: 0.0857286\n",
      "[1425]\ttraining's rmse: 0.0816521\tvalid_1's rmse: 0.0857252\n",
      "[1450]\ttraining's rmse: 0.0816396\tvalid_1's rmse: 0.0857229\n",
      "[1475]\ttraining's rmse: 0.0816321\tvalid_1's rmse: 0.0857194\n",
      "[1500]\ttraining's rmse: 0.0816238\tvalid_1's rmse: 0.0857159\n",
      "[1525]\ttraining's rmse: 0.0816146\tvalid_1's rmse: 0.0857124\n",
      "[1550]\ttraining's rmse: 0.081606\tvalid_1's rmse: 0.0857119\n",
      "[1575]\ttraining's rmse: 0.0815983\tvalid_1's rmse: 0.0857088\n",
      "[1600]\ttraining's rmse: 0.0815919\tvalid_1's rmse: 0.0857071\n",
      "[1625]\ttraining's rmse: 0.0815844\tvalid_1's rmse: 0.0857043\n",
      "[1650]\ttraining's rmse: 0.0815778\tvalid_1's rmse: 0.0857016\n",
      "[1675]\ttraining's rmse: 0.0815716\tvalid_1's rmse: 0.0857005\n",
      "[1700]\ttraining's rmse: 0.0815655\tvalid_1's rmse: 0.0856987\n",
      "[1725]\ttraining's rmse: 0.0815605\tvalid_1's rmse: 0.0856966\n",
      "[1750]\ttraining's rmse: 0.0815546\tvalid_1's rmse: 0.0856931\n",
      "[1775]\ttraining's rmse: 0.0815486\tvalid_1's rmse: 0.0856918\n",
      "[1800]\ttraining's rmse: 0.0815419\tvalid_1's rmse: 0.0856894\n",
      "[1825]\ttraining's rmse: 0.0815371\tvalid_1's rmse: 0.0856882\n",
      "[1850]\ttraining's rmse: 0.0815313\tvalid_1's rmse: 0.0856862\n",
      "[1875]\ttraining's rmse: 0.0815267\tvalid_1's rmse: 0.0856847\n",
      "[1900]\ttraining's rmse: 0.0815229\tvalid_1's rmse: 0.0856836\n",
      "[1925]\ttraining's rmse: 0.0815182\tvalid_1's rmse: 0.0856824\n",
      "[1950]\ttraining's rmse: 0.0815131\tvalid_1's rmse: 0.085681\n",
      "[1975]\ttraining's rmse: 0.0815087\tvalid_1's rmse: 0.0856786\n",
      "[2000]\ttraining's rmse: 0.0815042\tvalid_1's rmse: 0.085677\n",
      "[2025]\ttraining's rmse: 0.0815005\tvalid_1's rmse: 0.0856762\n",
      "[2050]\ttraining's rmse: 0.0814971\tvalid_1's rmse: 0.0856756\n",
      "[2075]\ttraining's rmse: 0.0814952\tvalid_1's rmse: 0.0856752\n",
      "[2100]\ttraining's rmse: 0.0814926\tvalid_1's rmse: 0.0856751\n",
      "[2125]\ttraining's rmse: 0.0814891\tvalid_1's rmse: 0.085674\n",
      "[2150]\ttraining's rmse: 0.0814841\tvalid_1's rmse: 0.0856731\n",
      "[2175]\ttraining's rmse: 0.0814811\tvalid_1's rmse: 0.0856726\n",
      "[2200]\ttraining's rmse: 0.0814784\tvalid_1's rmse: 0.0856717\n",
      "[2225]\ttraining's rmse: 0.0814752\tvalid_1's rmse: 0.0856697\n",
      "[2250]\ttraining's rmse: 0.0814728\tvalid_1's rmse: 0.0856693\n",
      "[2275]\ttraining's rmse: 0.0814706\tvalid_1's rmse: 0.0856687\n",
      "[2300]\ttraining's rmse: 0.0814681\tvalid_1's rmse: 0.0856674\n",
      "[2325]\ttraining's rmse: 0.0814662\tvalid_1's rmse: 0.0856666\n",
      "[2350]\ttraining's rmse: 0.0814639\tvalid_1's rmse: 0.085666\n",
      "[2375]\ttraining's rmse: 0.0814615\tvalid_1's rmse: 0.0856663\n",
      "[2400]\ttraining's rmse: 0.0814589\tvalid_1's rmse: 0.0856656\n",
      "[2425]\ttraining's rmse: 0.0814571\tvalid_1's rmse: 0.0856653\n",
      "[2450]\ttraining's rmse: 0.0814544\tvalid_1's rmse: 0.085665\n",
      "[2475]\ttraining's rmse: 0.0814516\tvalid_1's rmse: 0.0856643\n",
      "[2500]\ttraining's rmse: 0.0814492\tvalid_1's rmse: 0.0856633\n",
      "[2525]\ttraining's rmse: 0.0814476\tvalid_1's rmse: 0.0856633\n",
      "[2550]\ttraining's rmse: 0.0814436\tvalid_1's rmse: 0.0856628\n",
      "[2575]\ttraining's rmse: 0.0814401\tvalid_1's rmse: 0.0856629\n",
      "[2600]\ttraining's rmse: 0.0814377\tvalid_1's rmse: 0.0856621\n",
      "[2625]\ttraining's rmse: 0.0814357\tvalid_1's rmse: 0.0856613\n",
      "[2650]\ttraining's rmse: 0.0814337\tvalid_1's rmse: 0.0856612\n",
      "[2675]\ttraining's rmse: 0.0814311\tvalid_1's rmse: 0.0856607\n",
      "[2700]\ttraining's rmse: 0.0814287\tvalid_1's rmse: 0.0856602\n",
      "[2725]\ttraining's rmse: 0.0814263\tvalid_1's rmse: 0.0856596\n",
      "[2750]\ttraining's rmse: 0.0814241\tvalid_1's rmse: 0.0856579\n",
      "[2775]\ttraining's rmse: 0.0814224\tvalid_1's rmse: 0.0856577\n",
      "[2800]\ttraining's rmse: 0.0814204\tvalid_1's rmse: 0.0856573\n",
      "[2825]\ttraining's rmse: 0.0814185\tvalid_1's rmse: 0.0856572\n",
      "[2850]\ttraining's rmse: 0.0814173\tvalid_1's rmse: 0.0856579\n",
      "Early stopping, best iteration is:\n",
      "[2822]\ttraining's rmse: 0.0814185\tvalid_1's rmse: 0.0856572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0842427\tvalid_1's rmse: 0.0864846\n",
      "[50]\ttraining's rmse: 0.0841266\tvalid_1's rmse: 0.0864325\n",
      "[75]\ttraining's rmse: 0.084007\tvalid_1's rmse: 0.0863817\n",
      "[100]\ttraining's rmse: 0.0838979\tvalid_1's rmse: 0.0863352\n",
      "[125]\ttraining's rmse: 0.0837855\tvalid_1's rmse: 0.0862887\n",
      "[150]\ttraining's rmse: 0.0836833\tvalid_1's rmse: 0.0862453\n",
      "[175]\ttraining's rmse: 0.0835964\tvalid_1's rmse: 0.08621\n",
      "[200]\ttraining's rmse: 0.0835028\tvalid_1's rmse: 0.0861739\n",
      "[225]\ttraining's rmse: 0.0834139\tvalid_1's rmse: 0.0861409\n",
      "[250]\ttraining's rmse: 0.083336\tvalid_1's rmse: 0.0861103\n",
      "[275]\ttraining's rmse: 0.0832668\tvalid_1's rmse: 0.0860835\n",
      "[300]\ttraining's rmse: 0.0831964\tvalid_1's rmse: 0.0860562\n",
      "[325]\ttraining's rmse: 0.0831236\tvalid_1's rmse: 0.0860313\n",
      "[350]\ttraining's rmse: 0.0830539\tvalid_1's rmse: 0.0860078\n",
      "[375]\ttraining's rmse: 0.0829974\tvalid_1's rmse: 0.0859869\n",
      "[400]\ttraining's rmse: 0.0829336\tvalid_1's rmse: 0.0859669\n",
      "[425]\ttraining's rmse: 0.082879\tvalid_1's rmse: 0.0859474\n",
      "[450]\ttraining's rmse: 0.0828287\tvalid_1's rmse: 0.0859294\n",
      "[475]\ttraining's rmse: 0.082781\tvalid_1's rmse: 0.0859122\n",
      "[500]\ttraining's rmse: 0.0827371\tvalid_1's rmse: 0.0858968\n",
      "[525]\ttraining's rmse: 0.0826828\tvalid_1's rmse: 0.0858809\n",
      "[550]\ttraining's rmse: 0.0826346\tvalid_1's rmse: 0.0858667\n",
      "[575]\ttraining's rmse: 0.0825891\tvalid_1's rmse: 0.0858524\n",
      "[600]\ttraining's rmse: 0.0825462\tvalid_1's rmse: 0.0858397\n",
      "[625]\ttraining's rmse: 0.0825124\tvalid_1's rmse: 0.0858278\n",
      "[650]\ttraining's rmse: 0.0824693\tvalid_1's rmse: 0.0858156\n",
      "[675]\ttraining's rmse: 0.0824273\tvalid_1's rmse: 0.0858039\n",
      "[700]\ttraining's rmse: 0.0823906\tvalid_1's rmse: 0.0857924\n",
      "[725]\ttraining's rmse: 0.0823568\tvalid_1's rmse: 0.0857828\n",
      "[750]\ttraining's rmse: 0.0823237\tvalid_1's rmse: 0.0857734\n",
      "[775]\ttraining's rmse: 0.0822949\tvalid_1's rmse: 0.0857647\n",
      "[800]\ttraining's rmse: 0.0822604\tvalid_1's rmse: 0.0857574\n",
      "[825]\ttraining's rmse: 0.0822314\tvalid_1's rmse: 0.0857495\n",
      "[850]\ttraining's rmse: 0.0822019\tvalid_1's rmse: 0.0857426\n",
      "[875]\ttraining's rmse: 0.0821768\tvalid_1's rmse: 0.0857359\n",
      "[900]\ttraining's rmse: 0.0821494\tvalid_1's rmse: 0.08573\n",
      "[925]\ttraining's rmse: 0.0821227\tvalid_1's rmse: 0.0857241\n",
      "[950]\ttraining's rmse: 0.0820966\tvalid_1's rmse: 0.0857179\n",
      "[975]\ttraining's rmse: 0.0820744\tvalid_1's rmse: 0.0857121\n",
      "[1000]\ttraining's rmse: 0.0820526\tvalid_1's rmse: 0.085707\n",
      "[1025]\ttraining's rmse: 0.082027\tvalid_1's rmse: 0.0857023\n",
      "[1050]\ttraining's rmse: 0.0820066\tvalid_1's rmse: 0.0856975\n",
      "[1075]\ttraining's rmse: 0.081986\tvalid_1's rmse: 0.0856942\n",
      "[1100]\ttraining's rmse: 0.0819697\tvalid_1's rmse: 0.0856904\n",
      "[1125]\ttraining's rmse: 0.0819526\tvalid_1's rmse: 0.0856868\n",
      "[1150]\ttraining's rmse: 0.0819315\tvalid_1's rmse: 0.0856826\n",
      "[1175]\ttraining's rmse: 0.0819129\tvalid_1's rmse: 0.0856791\n",
      "[1200]\ttraining's rmse: 0.0818965\tvalid_1's rmse: 0.0856753\n",
      "[1225]\ttraining's rmse: 0.0818796\tvalid_1's rmse: 0.0856719\n",
      "[1250]\ttraining's rmse: 0.0818662\tvalid_1's rmse: 0.0856688\n",
      "[1275]\ttraining's rmse: 0.0818482\tvalid_1's rmse: 0.0856668\n",
      "[1300]\ttraining's rmse: 0.0818346\tvalid_1's rmse: 0.0856644\n",
      "[1325]\ttraining's rmse: 0.0818203\tvalid_1's rmse: 0.0856622\n",
      "[1350]\ttraining's rmse: 0.0818056\tvalid_1's rmse: 0.08566\n",
      "[1375]\ttraining's rmse: 0.0817933\tvalid_1's rmse: 0.0856584\n",
      "[1400]\ttraining's rmse: 0.0817821\tvalid_1's rmse: 0.0856567\n",
      "[1425]\ttraining's rmse: 0.0817695\tvalid_1's rmse: 0.0856557\n",
      "[1450]\ttraining's rmse: 0.0817575\tvalid_1's rmse: 0.0856536\n",
      "[1475]\ttraining's rmse: 0.0817473\tvalid_1's rmse: 0.0856514\n",
      "[1500]\ttraining's rmse: 0.0817384\tvalid_1's rmse: 0.0856499\n",
      "[1525]\ttraining's rmse: 0.0817282\tvalid_1's rmse: 0.0856485\n",
      "[1550]\ttraining's rmse: 0.0817209\tvalid_1's rmse: 0.0856475\n",
      "[1575]\ttraining's rmse: 0.0817122\tvalid_1's rmse: 0.0856466\n",
      "[1600]\ttraining's rmse: 0.0817052\tvalid_1's rmse: 0.0856461\n",
      "[1625]\ttraining's rmse: 0.0816961\tvalid_1's rmse: 0.0856441\n",
      "[1650]\ttraining's rmse: 0.0816887\tvalid_1's rmse: 0.085643\n",
      "[1675]\ttraining's rmse: 0.0816828\tvalid_1's rmse: 0.085642\n",
      "[1700]\ttraining's rmse: 0.0816766\tvalid_1's rmse: 0.0856411\n",
      "[1725]\ttraining's rmse: 0.0816707\tvalid_1's rmse: 0.0856403\n",
      "[1750]\ttraining's rmse: 0.081663\tvalid_1's rmse: 0.0856385\n",
      "[1775]\ttraining's rmse: 0.0816566\tvalid_1's rmse: 0.0856373\n",
      "[1800]\ttraining's rmse: 0.0816517\tvalid_1's rmse: 0.0856366\n",
      "[1825]\ttraining's rmse: 0.0816458\tvalid_1's rmse: 0.0856357\n",
      "[1850]\ttraining's rmse: 0.0816393\tvalid_1's rmse: 0.0856347\n",
      "[1875]\ttraining's rmse: 0.0816347\tvalid_1's rmse: 0.0856342\n",
      "[1900]\ttraining's rmse: 0.0816305\tvalid_1's rmse: 0.0856343\n",
      "[1925]\ttraining's rmse: 0.081626\tvalid_1's rmse: 0.0856337\n",
      "[1950]\ttraining's rmse: 0.0816225\tvalid_1's rmse: 0.0856326\n",
      "[1975]\ttraining's rmse: 0.0816175\tvalid_1's rmse: 0.0856317\n",
      "[2000]\ttraining's rmse: 0.0816128\tvalid_1's rmse: 0.0856314\n",
      "[2025]\ttraining's rmse: 0.0816072\tvalid_1's rmse: 0.0856305\n",
      "[2050]\ttraining's rmse: 0.0816026\tvalid_1's rmse: 0.0856298\n",
      "[2075]\ttraining's rmse: 0.0815989\tvalid_1's rmse: 0.0856294\n",
      "[2100]\ttraining's rmse: 0.0815948\tvalid_1's rmse: 0.0856289\n",
      "[2125]\ttraining's rmse: 0.0815926\tvalid_1's rmse: 0.0856287\n",
      "[2150]\ttraining's rmse: 0.0815888\tvalid_1's rmse: 0.0856284\n",
      "[2175]\ttraining's rmse: 0.0815847\tvalid_1's rmse: 0.0856284\n",
      "Early stopping, best iteration is:\n",
      "[2136]\ttraining's rmse: 0.08159\tvalid_1's rmse: 0.0856282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0864281\tvalid_1's rmse: 0.0820489\n",
      "[50]\ttraining's rmse: 0.086318\tvalid_1's rmse: 0.0820026\n",
      "[75]\ttraining's rmse: 0.0862038\tvalid_1's rmse: 0.081955\n",
      "[100]\ttraining's rmse: 0.0860984\tvalid_1's rmse: 0.0819148\n",
      "[125]\ttraining's rmse: 0.0859924\tvalid_1's rmse: 0.0818733\n",
      "[150]\ttraining's rmse: 0.0858943\tvalid_1's rmse: 0.0818367\n",
      "[175]\ttraining's rmse: 0.0858144\tvalid_1's rmse: 0.0818073\n",
      "[200]\ttraining's rmse: 0.0857242\tvalid_1's rmse: 0.0817767\n",
      "[225]\ttraining's rmse: 0.0856392\tvalid_1's rmse: 0.0817473\n",
      "[250]\ttraining's rmse: 0.0855643\tvalid_1's rmse: 0.0817276\n",
      "[275]\ttraining's rmse: 0.0855015\tvalid_1's rmse: 0.0817049\n",
      "[300]\ttraining's rmse: 0.0854349\tvalid_1's rmse: 0.0816817\n",
      "[325]\ttraining's rmse: 0.0853691\tvalid_1's rmse: 0.0816599\n",
      "[350]\ttraining's rmse: 0.0853041\tvalid_1's rmse: 0.0816393\n",
      "[375]\ttraining's rmse: 0.0852509\tvalid_1's rmse: 0.081623\n",
      "[400]\ttraining's rmse: 0.085192\tvalid_1's rmse: 0.0816109\n",
      "[425]\ttraining's rmse: 0.0851385\tvalid_1's rmse: 0.0816017\n",
      "[450]\ttraining's rmse: 0.0850902\tvalid_1's rmse: 0.0815865\n",
      "[475]\ttraining's rmse: 0.0850435\tvalid_1's rmse: 0.0815721\n",
      "[500]\ttraining's rmse: 0.0850033\tvalid_1's rmse: 0.0815597\n",
      "[525]\ttraining's rmse: 0.0849526\tvalid_1's rmse: 0.0815589\n",
      "[550]\ttraining's rmse: 0.084907\tvalid_1's rmse: 0.0815468\n",
      "[575]\ttraining's rmse: 0.0848632\tvalid_1's rmse: 0.0815362\n",
      "[600]\ttraining's rmse: 0.0848203\tvalid_1's rmse: 0.0815309\n",
      "[625]\ttraining's rmse: 0.0847873\tvalid_1's rmse: 0.0815256\n",
      "[650]\ttraining's rmse: 0.0847449\tvalid_1's rmse: 0.0815277\n",
      "[675]\ttraining's rmse: 0.0847029\tvalid_1's rmse: 0.0815198\n",
      "[700]\ttraining's rmse: 0.0846662\tvalid_1's rmse: 0.0815119\n",
      "[725]\ttraining's rmse: 0.0846301\tvalid_1's rmse: 0.0815165\n",
      "[750]\ttraining's rmse: 0.084595\tvalid_1's rmse: 0.0815229\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 0.0846521\tvalid_1's rmse: 0.0815092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0855056\tvalid_1's rmse: 0.0879479\n",
      "[50]\ttraining's rmse: 0.0853792\tvalid_1's rmse: 0.0878983\n",
      "[75]\ttraining's rmse: 0.0852496\tvalid_1's rmse: 0.0878461\n",
      "[100]\ttraining's rmse: 0.0851255\tvalid_1's rmse: 0.0878014\n",
      "[125]\ttraining's rmse: 0.0850029\tvalid_1's rmse: 0.0877537\n",
      "[150]\ttraining's rmse: 0.084891\tvalid_1's rmse: 0.0877107\n",
      "[175]\ttraining's rmse: 0.0847986\tvalid_1's rmse: 0.0876737\n",
      "[200]\ttraining's rmse: 0.0847006\tvalid_1's rmse: 0.0876366\n",
      "[225]\ttraining's rmse: 0.0846046\tvalid_1's rmse: 0.0876021\n",
      "[250]\ttraining's rmse: 0.0845182\tvalid_1's rmse: 0.0875697\n",
      "[275]\ttraining's rmse: 0.0844415\tvalid_1's rmse: 0.0875419\n",
      "[300]\ttraining's rmse: 0.0843646\tvalid_1's rmse: 0.0875137\n",
      "[325]\ttraining's rmse: 0.0842868\tvalid_1's rmse: 0.0874882\n",
      "[350]\ttraining's rmse: 0.0842132\tvalid_1's rmse: 0.0874636\n",
      "[375]\ttraining's rmse: 0.0841518\tvalid_1's rmse: 0.0874427\n",
      "[400]\ttraining's rmse: 0.0840844\tvalid_1's rmse: 0.087422\n",
      "[425]\ttraining's rmse: 0.0840255\tvalid_1's rmse: 0.0874027\n",
      "[450]\ttraining's rmse: 0.0839691\tvalid_1's rmse: 0.0873837\n",
      "[475]\ttraining's rmse: 0.0839219\tvalid_1's rmse: 0.0873656\n",
      "[500]\ttraining's rmse: 0.0838741\tvalid_1's rmse: 0.0873485\n",
      "[525]\ttraining's rmse: 0.0838199\tvalid_1's rmse: 0.0873323\n",
      "[550]\ttraining's rmse: 0.0837701\tvalid_1's rmse: 0.0873177\n",
      "[575]\ttraining's rmse: 0.0837219\tvalid_1's rmse: 0.0873039\n",
      "[600]\ttraining's rmse: 0.0836773\tvalid_1's rmse: 0.0872905\n",
      "[625]\ttraining's rmse: 0.0836407\tvalid_1's rmse: 0.0872796\n",
      "[650]\ttraining's rmse: 0.083599\tvalid_1's rmse: 0.0872677\n",
      "[675]\ttraining's rmse: 0.0835544\tvalid_1's rmse: 0.0872568\n",
      "[700]\ttraining's rmse: 0.0835171\tvalid_1's rmse: 0.087246\n",
      "[725]\ttraining's rmse: 0.0834803\tvalid_1's rmse: 0.0872359\n",
      "[750]\ttraining's rmse: 0.0834468\tvalid_1's rmse: 0.087227\n",
      "[775]\ttraining's rmse: 0.0834182\tvalid_1's rmse: 0.0872169\n",
      "[800]\ttraining's rmse: 0.0833822\tvalid_1's rmse: 0.0872087\n",
      "[825]\ttraining's rmse: 0.0833541\tvalid_1's rmse: 0.0872011\n",
      "[850]\ttraining's rmse: 0.0833202\tvalid_1's rmse: 0.0871933\n",
      "[875]\ttraining's rmse: 0.0832892\tvalid_1's rmse: 0.0871845\n",
      "[900]\ttraining's rmse: 0.0832585\tvalid_1's rmse: 0.0871787\n",
      "[925]\ttraining's rmse: 0.083232\tvalid_1's rmse: 0.0871719\n",
      "[950]\ttraining's rmse: 0.083207\tvalid_1's rmse: 0.087165\n",
      "[975]\ttraining's rmse: 0.0831828\tvalid_1's rmse: 0.087157\n",
      "[1000]\ttraining's rmse: 0.0831609\tvalid_1's rmse: 0.0871521\n",
      "[1025]\ttraining's rmse: 0.0831401\tvalid_1's rmse: 0.0871446\n",
      "[1050]\ttraining's rmse: 0.0831196\tvalid_1's rmse: 0.0871379\n",
      "[1075]\ttraining's rmse: 0.083095\tvalid_1's rmse: 0.0871326\n",
      "[1100]\ttraining's rmse: 0.0830768\tvalid_1's rmse: 0.0871275\n",
      "[1125]\ttraining's rmse: 0.0830594\tvalid_1's rmse: 0.0871221\n",
      "[1150]\ttraining's rmse: 0.0830393\tvalid_1's rmse: 0.0871166\n",
      "[1175]\ttraining's rmse: 0.0830199\tvalid_1's rmse: 0.0871131\n",
      "[1200]\ttraining's rmse: 0.0830017\tvalid_1's rmse: 0.0871087\n",
      "[1225]\ttraining's rmse: 0.0829846\tvalid_1's rmse: 0.0871046\n",
      "[1250]\ttraining's rmse: 0.0829701\tvalid_1's rmse: 0.0871005\n",
      "[1275]\ttraining's rmse: 0.0829526\tvalid_1's rmse: 0.087096\n",
      "[1300]\ttraining's rmse: 0.0829399\tvalid_1's rmse: 0.0870914\n",
      "[1325]\ttraining's rmse: 0.0829243\tvalid_1's rmse: 0.0870885\n",
      "[1350]\ttraining's rmse: 0.0829107\tvalid_1's rmse: 0.087086\n",
      "[1375]\ttraining's rmse: 0.0828955\tvalid_1's rmse: 0.0870823\n",
      "[1400]\ttraining's rmse: 0.0828846\tvalid_1's rmse: 0.0870784\n",
      "[1425]\ttraining's rmse: 0.0828714\tvalid_1's rmse: 0.0870758\n",
      "[1450]\ttraining's rmse: 0.0828605\tvalid_1's rmse: 0.0870724\n",
      "[1475]\ttraining's rmse: 0.0828506\tvalid_1's rmse: 0.0870701\n",
      "[1500]\ttraining's rmse: 0.0828395\tvalid_1's rmse: 0.0870681\n",
      "[1525]\ttraining's rmse: 0.0828291\tvalid_1's rmse: 0.0870657\n",
      "[1550]\ttraining's rmse: 0.0828187\tvalid_1's rmse: 0.0870638\n",
      "[1575]\ttraining's rmse: 0.0828101\tvalid_1's rmse: 0.0870615\n",
      "[1600]\ttraining's rmse: 0.0828026\tvalid_1's rmse: 0.0870601\n",
      "[1625]\ttraining's rmse: 0.0827954\tvalid_1's rmse: 0.0870579\n",
      "[1650]\ttraining's rmse: 0.0827876\tvalid_1's rmse: 0.087055\n",
      "[1675]\ttraining's rmse: 0.0827811\tvalid_1's rmse: 0.0870527\n",
      "[1700]\ttraining's rmse: 0.0827759\tvalid_1's rmse: 0.0870506\n",
      "[1725]\ttraining's rmse: 0.0827692\tvalid_1's rmse: 0.0870493\n",
      "[1750]\ttraining's rmse: 0.082762\tvalid_1's rmse: 0.0870474\n",
      "[1775]\ttraining's rmse: 0.0827559\tvalid_1's rmse: 0.0870456\n",
      "[1800]\ttraining's rmse: 0.0827511\tvalid_1's rmse: 0.0870443\n",
      "[1825]\ttraining's rmse: 0.0827447\tvalid_1's rmse: 0.0870416\n",
      "[1850]\ttraining's rmse: 0.0827392\tvalid_1's rmse: 0.0870394\n",
      "[1875]\ttraining's rmse: 0.0827348\tvalid_1's rmse: 0.0870385\n",
      "[1900]\ttraining's rmse: 0.0827306\tvalid_1's rmse: 0.0870377\n",
      "[1925]\ttraining's rmse: 0.0827256\tvalid_1's rmse: 0.0870352\n",
      "[1950]\ttraining's rmse: 0.0827217\tvalid_1's rmse: 0.0870336\n",
      "[1975]\ttraining's rmse: 0.0827168\tvalid_1's rmse: 0.087032\n",
      "[2000]\ttraining's rmse: 0.0827117\tvalid_1's rmse: 0.0870313\n",
      "[2025]\ttraining's rmse: 0.0827088\tvalid_1's rmse: 0.087031\n",
      "[2050]\ttraining's rmse: 0.0827045\tvalid_1's rmse: 0.0870307\n",
      "[2075]\ttraining's rmse: 0.0827009\tvalid_1's rmse: 0.0870297\n",
      "[2100]\ttraining's rmse: 0.0826975\tvalid_1's rmse: 0.0870278\n",
      "[2125]\ttraining's rmse: 0.0826944\tvalid_1's rmse: 0.0870267\n",
      "[2150]\ttraining's rmse: 0.0826901\tvalid_1's rmse: 0.0870255\n",
      "[2175]\ttraining's rmse: 0.0826873\tvalid_1's rmse: 0.0870247\n",
      "[2200]\ttraining's rmse: 0.0826845\tvalid_1's rmse: 0.0870242\n",
      "[2225]\ttraining's rmse: 0.0826822\tvalid_1's rmse: 0.0870236\n",
      "[2250]\ttraining's rmse: 0.0826787\tvalid_1's rmse: 0.0870221\n",
      "[2275]\ttraining's rmse: 0.0826758\tvalid_1's rmse: 0.0870207\n",
      "[2300]\ttraining's rmse: 0.0826732\tvalid_1's rmse: 0.08702\n",
      "[2325]\ttraining's rmse: 0.0826704\tvalid_1's rmse: 0.0870184\n",
      "[2350]\ttraining's rmse: 0.0826683\tvalid_1's rmse: 0.0870176\n",
      "[2375]\ttraining's rmse: 0.0826652\tvalid_1's rmse: 0.0870167\n",
      "[2400]\ttraining's rmse: 0.0826624\tvalid_1's rmse: 0.0870161\n",
      "[2425]\ttraining's rmse: 0.0826594\tvalid_1's rmse: 0.0870159\n",
      "[2450]\ttraining's rmse: 0.0826571\tvalid_1's rmse: 0.0870153\n",
      "[2475]\ttraining's rmse: 0.082655\tvalid_1's rmse: 0.0870149\n",
      "[2500]\ttraining's rmse: 0.082652\tvalid_1's rmse: 0.0870146\n",
      "[2525]\ttraining's rmse: 0.08265\tvalid_1's rmse: 0.0870135\n",
      "[2550]\ttraining's rmse: 0.082647\tvalid_1's rmse: 0.0870128\n",
      "[2575]\ttraining's rmse: 0.0826449\tvalid_1's rmse: 0.0870128\n",
      "[2600]\ttraining's rmse: 0.0826428\tvalid_1's rmse: 0.0870126\n",
      "[2625]\ttraining's rmse: 0.0826411\tvalid_1's rmse: 0.0870118\n",
      "[2650]\ttraining's rmse: 0.0826391\tvalid_1's rmse: 0.0870108\n",
      "[2675]\ttraining's rmse: 0.0826375\tvalid_1's rmse: 0.0870102\n",
      "[2700]\ttraining's rmse: 0.0826365\tvalid_1's rmse: 0.0870102\n",
      "[2725]\ttraining's rmse: 0.0826348\tvalid_1's rmse: 0.0870096\n",
      "[2750]\ttraining's rmse: 0.0826327\tvalid_1's rmse: 0.0870093\n",
      "[2775]\ttraining's rmse: 0.0826297\tvalid_1's rmse: 0.0870085\n",
      "[2800]\ttraining's rmse: 0.0826275\tvalid_1's rmse: 0.0870079\n",
      "[2825]\ttraining's rmse: 0.0826254\tvalid_1's rmse: 0.0870078\n",
      "[2850]\ttraining's rmse: 0.0826242\tvalid_1's rmse: 0.087008\n",
      "Early stopping, best iteration is:\n",
      "[2815]\ttraining's rmse: 0.0826259\tvalid_1's rmse: 0.0870076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0855288\tvalid_1's rmse: 0.0879192\n",
      "[50]\ttraining's rmse: 0.0854094\tvalid_1's rmse: 0.0878672\n",
      "[75]\ttraining's rmse: 0.0852863\tvalid_1's rmse: 0.0878165\n",
      "[100]\ttraining's rmse: 0.0851753\tvalid_1's rmse: 0.0877704\n",
      "[125]\ttraining's rmse: 0.0850576\tvalid_1's rmse: 0.0877243\n",
      "[150]\ttraining's rmse: 0.0849504\tvalid_1's rmse: 0.0876801\n",
      "[175]\ttraining's rmse: 0.0848613\tvalid_1's rmse: 0.0876443\n",
      "[200]\ttraining's rmse: 0.0847647\tvalid_1's rmse: 0.0876088\n",
      "[225]\ttraining's rmse: 0.0846708\tvalid_1's rmse: 0.0875758\n",
      "[250]\ttraining's rmse: 0.0845907\tvalid_1's rmse: 0.0875465\n",
      "[275]\ttraining's rmse: 0.0845186\tvalid_1's rmse: 0.087519\n",
      "[300]\ttraining's rmse: 0.0844451\tvalid_1's rmse: 0.0874925\n",
      "[325]\ttraining's rmse: 0.0843703\tvalid_1's rmse: 0.0874671\n",
      "[350]\ttraining's rmse: 0.0842971\tvalid_1's rmse: 0.0874425\n",
      "[375]\ttraining's rmse: 0.0842379\tvalid_1's rmse: 0.0874219\n",
      "[400]\ttraining's rmse: 0.0841754\tvalid_1's rmse: 0.0874016\n",
      "[425]\ttraining's rmse: 0.0841177\tvalid_1's rmse: 0.0873832\n",
      "[450]\ttraining's rmse: 0.0840644\tvalid_1's rmse: 0.0873643\n",
      "[475]\ttraining's rmse: 0.0840167\tvalid_1's rmse: 0.0873476\n",
      "[500]\ttraining's rmse: 0.0839746\tvalid_1's rmse: 0.0873323\n",
      "[525]\ttraining's rmse: 0.0839208\tvalid_1's rmse: 0.0873173\n",
      "[550]\ttraining's rmse: 0.0838699\tvalid_1's rmse: 0.0873029\n",
      "[575]\ttraining's rmse: 0.0838221\tvalid_1's rmse: 0.0872892\n",
      "[600]\ttraining's rmse: 0.0837778\tvalid_1's rmse: 0.0872758\n",
      "[625]\ttraining's rmse: 0.083743\tvalid_1's rmse: 0.0872647\n",
      "[650]\ttraining's rmse: 0.0836982\tvalid_1's rmse: 0.0872522\n",
      "[675]\ttraining's rmse: 0.0836522\tvalid_1's rmse: 0.0872408\n",
      "[700]\ttraining's rmse: 0.0836142\tvalid_1's rmse: 0.087231\n",
      "[725]\ttraining's rmse: 0.083577\tvalid_1's rmse: 0.0872222\n",
      "[750]\ttraining's rmse: 0.0835462\tvalid_1's rmse: 0.0872129\n",
      "[775]\ttraining's rmse: 0.0835192\tvalid_1's rmse: 0.0872045\n",
      "[800]\ttraining's rmse: 0.0834809\tvalid_1's rmse: 0.0871963\n",
      "[825]\ttraining's rmse: 0.0834507\tvalid_1's rmse: 0.0871887\n",
      "[850]\ttraining's rmse: 0.08342\tvalid_1's rmse: 0.0871821\n",
      "[875]\ttraining's rmse: 0.0833921\tvalid_1's rmse: 0.0871761\n",
      "[900]\ttraining's rmse: 0.0833613\tvalid_1's rmse: 0.087169\n",
      "[925]\ttraining's rmse: 0.083334\tvalid_1's rmse: 0.087163\n",
      "[950]\ttraining's rmse: 0.0833086\tvalid_1's rmse: 0.0871586\n",
      "[975]\ttraining's rmse: 0.0832842\tvalid_1's rmse: 0.087153\n",
      "[1000]\ttraining's rmse: 0.0832626\tvalid_1's rmse: 0.087148\n",
      "[1025]\ttraining's rmse: 0.0832369\tvalid_1's rmse: 0.087143\n",
      "[1050]\ttraining's rmse: 0.0832153\tvalid_1's rmse: 0.0871388\n",
      "[1075]\ttraining's rmse: 0.0831926\tvalid_1's rmse: 0.0871347\n",
      "[1100]\ttraining's rmse: 0.0831753\tvalid_1's rmse: 0.0871308\n",
      "[1125]\ttraining's rmse: 0.0831557\tvalid_1's rmse: 0.0871269\n",
      "[1150]\ttraining's rmse: 0.0831376\tvalid_1's rmse: 0.0871237\n",
      "[1175]\ttraining's rmse: 0.0831201\tvalid_1's rmse: 0.0871204\n",
      "[1200]\ttraining's rmse: 0.0831045\tvalid_1's rmse: 0.0871178\n",
      "[1225]\ttraining's rmse: 0.083089\tvalid_1's rmse: 0.0871148\n",
      "[1250]\ttraining's rmse: 0.0830728\tvalid_1's rmse: 0.0871118\n",
      "[1275]\ttraining's rmse: 0.0830575\tvalid_1's rmse: 0.0871096\n",
      "[1300]\ttraining's rmse: 0.083046\tvalid_1's rmse: 0.0871072\n",
      "[1325]\ttraining's rmse: 0.0830331\tvalid_1's rmse: 0.0871053\n",
      "[1350]\ttraining's rmse: 0.0830199\tvalid_1's rmse: 0.0871034\n",
      "[1375]\ttraining's rmse: 0.0830063\tvalid_1's rmse: 0.0871019\n",
      "[1400]\ttraining's rmse: 0.0829959\tvalid_1's rmse: 0.0870999\n",
      "[1425]\ttraining's rmse: 0.0829843\tvalid_1's rmse: 0.0870986\n",
      "[1450]\ttraining's rmse: 0.0829704\tvalid_1's rmse: 0.0870971\n",
      "[1475]\ttraining's rmse: 0.0829591\tvalid_1's rmse: 0.0870958\n",
      "[1500]\ttraining's rmse: 0.0829494\tvalid_1's rmse: 0.0870945\n",
      "[1525]\ttraining's rmse: 0.0829386\tvalid_1's rmse: 0.0870933\n",
      "[1550]\ttraining's rmse: 0.0829291\tvalid_1's rmse: 0.087093\n",
      "[1575]\ttraining's rmse: 0.0829205\tvalid_1's rmse: 0.0870914\n",
      "[1600]\ttraining's rmse: 0.0829133\tvalid_1's rmse: 0.0870909\n",
      "[1625]\ttraining's rmse: 0.0829044\tvalid_1's rmse: 0.0870897\n",
      "[1650]\ttraining's rmse: 0.0828968\tvalid_1's rmse: 0.0870883\n",
      "[1675]\ttraining's rmse: 0.0828903\tvalid_1's rmse: 0.0870874\n",
      "[1700]\ttraining's rmse: 0.0828844\tvalid_1's rmse: 0.0870864\n",
      "[1725]\ttraining's rmse: 0.0828769\tvalid_1's rmse: 0.0870849\n",
      "[1750]\ttraining's rmse: 0.0828707\tvalid_1's rmse: 0.087085\n",
      "[1775]\ttraining's rmse: 0.0828647\tvalid_1's rmse: 0.0870844\n",
      "[1800]\ttraining's rmse: 0.0828577\tvalid_1's rmse: 0.0870841\n",
      "[1825]\ttraining's rmse: 0.0828506\tvalid_1's rmse: 0.0870835\n",
      "[1850]\ttraining's rmse: 0.0828452\tvalid_1's rmse: 0.0870826\n",
      "[1875]\ttraining's rmse: 0.0828403\tvalid_1's rmse: 0.0870821\n",
      "[1900]\ttraining's rmse: 0.082836\tvalid_1's rmse: 0.0870819\n",
      "[1925]\ttraining's rmse: 0.0828311\tvalid_1's rmse: 0.0870816\n",
      "[1950]\ttraining's rmse: 0.0828279\tvalid_1's rmse: 0.0870813\n",
      "[1975]\ttraining's rmse: 0.0828245\tvalid_1's rmse: 0.0870812\n",
      "[2000]\ttraining's rmse: 0.0828198\tvalid_1's rmse: 0.0870806\n",
      "[2025]\ttraining's rmse: 0.0828165\tvalid_1's rmse: 0.0870803\n",
      "[2050]\ttraining's rmse: 0.0828124\tvalid_1's rmse: 0.0870801\n",
      "[2075]\ttraining's rmse: 0.0828086\tvalid_1's rmse: 0.0870795\n",
      "[2100]\ttraining's rmse: 0.0828051\tvalid_1's rmse: 0.0870794\n",
      "[2125]\ttraining's rmse: 0.0828025\tvalid_1's rmse: 0.0870796\n",
      "[2150]\ttraining's rmse: 0.0827983\tvalid_1's rmse: 0.0870794\n",
      "[2175]\ttraining's rmse: 0.0827948\tvalid_1's rmse: 0.0870796\n",
      "Early stopping, best iteration is:\n",
      "[2134]\ttraining's rmse: 0.082801\tvalid_1's rmse: 0.0870792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0878084\tvalid_1's rmse: 0.0832833\n",
      "[50]\ttraining's rmse: 0.0876992\tvalid_1's rmse: 0.0832385\n",
      "[75]\ttraining's rmse: 0.0875824\tvalid_1's rmse: 0.0831903\n",
      "[100]\ttraining's rmse: 0.0874791\tvalid_1's rmse: 0.08315\n",
      "[125]\ttraining's rmse: 0.0873726\tvalid_1's rmse: 0.0831088\n",
      "[150]\ttraining's rmse: 0.0872746\tvalid_1's rmse: 0.0830724\n",
      "[175]\ttraining's rmse: 0.087192\tvalid_1's rmse: 0.08304\n",
      "[200]\ttraining's rmse: 0.0871027\tvalid_1's rmse: 0.0830091\n",
      "[225]\ttraining's rmse: 0.0870175\tvalid_1's rmse: 0.0829821\n",
      "[250]\ttraining's rmse: 0.0869461\tvalid_1's rmse: 0.0829557\n",
      "[275]\ttraining's rmse: 0.0868803\tvalid_1's rmse: 0.0829316\n",
      "[300]\ttraining's rmse: 0.0868148\tvalid_1's rmse: 0.0829089\n",
      "[325]\ttraining's rmse: 0.0867486\tvalid_1's rmse: 0.0828864\n",
      "[350]\ttraining's rmse: 0.086684\tvalid_1's rmse: 0.0828647\n",
      "[375]\ttraining's rmse: 0.0866311\tvalid_1's rmse: 0.0828467\n",
      "[400]\ttraining's rmse: 0.0865734\tvalid_1's rmse: 0.0828315\n",
      "[425]\ttraining's rmse: 0.0865195\tvalid_1's rmse: 0.0828192\n",
      "[450]\ttraining's rmse: 0.0864697\tvalid_1's rmse: 0.0828021\n",
      "[475]\ttraining's rmse: 0.0864204\tvalid_1's rmse: 0.0827885\n",
      "[500]\ttraining's rmse: 0.086382\tvalid_1's rmse: 0.0827753\n",
      "[525]\ttraining's rmse: 0.0863293\tvalid_1's rmse: 0.0827638\n",
      "[550]\ttraining's rmse: 0.0862814\tvalid_1's rmse: 0.0827543\n",
      "[575]\ttraining's rmse: 0.0862369\tvalid_1's rmse: 0.0827468\n",
      "[600]\ttraining's rmse: 0.0861927\tvalid_1's rmse: 0.0827374\n",
      "[625]\ttraining's rmse: 0.0861591\tvalid_1's rmse: 0.0827335\n",
      "[650]\ttraining's rmse: 0.0861157\tvalid_1's rmse: 0.0827243\n",
      "[675]\ttraining's rmse: 0.086074\tvalid_1's rmse: 0.0827215\n",
      "[700]\ttraining's rmse: 0.0860368\tvalid_1's rmse: 0.0827187\n",
      "[725]\ttraining's rmse: 0.0859998\tvalid_1's rmse: 0.0827231\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0860466\tvalid_1's rmse: 0.082715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0846323\tvalid_1's rmse: 0.0871991\n",
      "[50]\ttraining's rmse: 0.0845081\tvalid_1's rmse: 0.0871484\n",
      "[75]\ttraining's rmse: 0.0843802\tvalid_1's rmse: 0.0870932\n",
      "[100]\ttraining's rmse: 0.0842615\tvalid_1's rmse: 0.0870475\n",
      "[125]\ttraining's rmse: 0.084143\tvalid_1's rmse: 0.0870028\n",
      "[150]\ttraining's rmse: 0.0840332\tvalid_1's rmse: 0.0869596\n",
      "[175]\ttraining's rmse: 0.0839433\tvalid_1's rmse: 0.0869233\n",
      "[200]\ttraining's rmse: 0.0838483\tvalid_1's rmse: 0.0868877\n",
      "[225]\ttraining's rmse: 0.0837535\tvalid_1's rmse: 0.0868538\n",
      "[250]\ttraining's rmse: 0.0836743\tvalid_1's rmse: 0.0868226\n",
      "[275]\ttraining's rmse: 0.0836007\tvalid_1's rmse: 0.0867947\n",
      "[300]\ttraining's rmse: 0.0835275\tvalid_1's rmse: 0.0867673\n",
      "[325]\ttraining's rmse: 0.0834557\tvalid_1's rmse: 0.0867427\n",
      "[350]\ttraining's rmse: 0.0833868\tvalid_1's rmse: 0.0867176\n",
      "[375]\ttraining's rmse: 0.0833287\tvalid_1's rmse: 0.0866956\n",
      "[400]\ttraining's rmse: 0.0832649\tvalid_1's rmse: 0.0866743\n",
      "[425]\ttraining's rmse: 0.0832088\tvalid_1's rmse: 0.0866528\n",
      "[450]\ttraining's rmse: 0.0831573\tvalid_1's rmse: 0.0866339\n",
      "[475]\ttraining's rmse: 0.0831084\tvalid_1's rmse: 0.0866159\n",
      "[500]\ttraining's rmse: 0.0830642\tvalid_1's rmse: 0.0865995\n",
      "[525]\ttraining's rmse: 0.0830117\tvalid_1's rmse: 0.0865833\n",
      "[550]\ttraining's rmse: 0.0829645\tvalid_1's rmse: 0.0865678\n",
      "[575]\ttraining's rmse: 0.0829191\tvalid_1's rmse: 0.0865535\n",
      "[600]\ttraining's rmse: 0.0828776\tvalid_1's rmse: 0.0865408\n",
      "[625]\ttraining's rmse: 0.0828435\tvalid_1's rmse: 0.0865293\n",
      "[650]\ttraining's rmse: 0.0828008\tvalid_1's rmse: 0.0865169\n",
      "[675]\ttraining's rmse: 0.0827578\tvalid_1's rmse: 0.0865046\n",
      "[700]\ttraining's rmse: 0.0827214\tvalid_1's rmse: 0.086491\n",
      "[725]\ttraining's rmse: 0.0826858\tvalid_1's rmse: 0.0864803\n",
      "[750]\ttraining's rmse: 0.0826523\tvalid_1's rmse: 0.0864713\n",
      "[775]\ttraining's rmse: 0.0826272\tvalid_1's rmse: 0.0864615\n",
      "[800]\ttraining's rmse: 0.0825934\tvalid_1's rmse: 0.086453\n",
      "[825]\ttraining's rmse: 0.0825655\tvalid_1's rmse: 0.0864444\n",
      "[850]\ttraining's rmse: 0.0825337\tvalid_1's rmse: 0.0864361\n",
      "[875]\ttraining's rmse: 0.0825087\tvalid_1's rmse: 0.0864282\n",
      "[900]\ttraining's rmse: 0.0824792\tvalid_1's rmse: 0.0864208\n",
      "[925]\ttraining's rmse: 0.0824535\tvalid_1's rmse: 0.0864131\n",
      "[950]\ttraining's rmse: 0.08243\tvalid_1's rmse: 0.0864063\n",
      "[975]\ttraining's rmse: 0.0824081\tvalid_1's rmse: 0.0864004\n",
      "[1000]\ttraining's rmse: 0.0823826\tvalid_1's rmse: 0.0863939\n",
      "[1025]\ttraining's rmse: 0.0823597\tvalid_1's rmse: 0.0863875\n",
      "[1050]\ttraining's rmse: 0.0823389\tvalid_1's rmse: 0.0863807\n",
      "[1075]\ttraining's rmse: 0.0823181\tvalid_1's rmse: 0.0863763\n",
      "[1100]\ttraining's rmse: 0.0822982\tvalid_1's rmse: 0.0863717\n",
      "[1125]\ttraining's rmse: 0.0822817\tvalid_1's rmse: 0.0863655\n",
      "[1150]\ttraining's rmse: 0.082264\tvalid_1's rmse: 0.0863609\n",
      "[1175]\ttraining's rmse: 0.0822476\tvalid_1's rmse: 0.0863574\n",
      "[1200]\ttraining's rmse: 0.0822304\tvalid_1's rmse: 0.086352\n",
      "[1225]\ttraining's rmse: 0.0822157\tvalid_1's rmse: 0.0863483\n",
      "[1250]\ttraining's rmse: 0.0821997\tvalid_1's rmse: 0.0863455\n",
      "[1275]\ttraining's rmse: 0.0821801\tvalid_1's rmse: 0.0863414\n",
      "[1300]\ttraining's rmse: 0.0821677\tvalid_1's rmse: 0.0863376\n",
      "[1325]\ttraining's rmse: 0.0821546\tvalid_1's rmse: 0.086334\n",
      "[1350]\ttraining's rmse: 0.0821407\tvalid_1's rmse: 0.0863307\n",
      "[1375]\ttraining's rmse: 0.0821269\tvalid_1's rmse: 0.0863275\n",
      "[1400]\ttraining's rmse: 0.0821171\tvalid_1's rmse: 0.0863228\n",
      "[1425]\ttraining's rmse: 0.0821041\tvalid_1's rmse: 0.0863207\n",
      "[1450]\ttraining's rmse: 0.082094\tvalid_1's rmse: 0.0863185\n",
      "[1475]\ttraining's rmse: 0.0820841\tvalid_1's rmse: 0.0863148\n",
      "[1500]\ttraining's rmse: 0.0820722\tvalid_1's rmse: 0.0863125\n",
      "[1525]\ttraining's rmse: 0.0820614\tvalid_1's rmse: 0.0863106\n",
      "[1550]\ttraining's rmse: 0.0820516\tvalid_1's rmse: 0.0863084\n",
      "[1575]\ttraining's rmse: 0.0820436\tvalid_1's rmse: 0.0863049\n",
      "[1600]\ttraining's rmse: 0.0820352\tvalid_1's rmse: 0.0863014\n",
      "[1625]\ttraining's rmse: 0.0820273\tvalid_1's rmse: 0.0862979\n",
      "[1650]\ttraining's rmse: 0.0820211\tvalid_1's rmse: 0.0862955\n",
      "[1675]\ttraining's rmse: 0.0820152\tvalid_1's rmse: 0.0862941\n",
      "[1700]\ttraining's rmse: 0.0820077\tvalid_1's rmse: 0.086292\n",
      "[1725]\ttraining's rmse: 0.082002\tvalid_1's rmse: 0.0862905\n",
      "[1750]\ttraining's rmse: 0.0819959\tvalid_1's rmse: 0.0862885\n",
      "[1775]\ttraining's rmse: 0.0819912\tvalid_1's rmse: 0.0862864\n",
      "[1800]\ttraining's rmse: 0.081986\tvalid_1's rmse: 0.0862832\n",
      "[1825]\ttraining's rmse: 0.0819805\tvalid_1's rmse: 0.0862824\n",
      "[1850]\ttraining's rmse: 0.0819755\tvalid_1's rmse: 0.0862806\n",
      "[1875]\ttraining's rmse: 0.0819694\tvalid_1's rmse: 0.0862792\n",
      "[1900]\ttraining's rmse: 0.0819658\tvalid_1's rmse: 0.0862773\n",
      "[1925]\ttraining's rmse: 0.0819619\tvalid_1's rmse: 0.0862767\n",
      "[1950]\ttraining's rmse: 0.0819582\tvalid_1's rmse: 0.0862754\n",
      "[1975]\ttraining's rmse: 0.0819538\tvalid_1's rmse: 0.0862731\n",
      "[2000]\ttraining's rmse: 0.0819493\tvalid_1's rmse: 0.0862718\n",
      "[2025]\ttraining's rmse: 0.0819454\tvalid_1's rmse: 0.0862703\n",
      "[2050]\ttraining's rmse: 0.081942\tvalid_1's rmse: 0.0862687\n",
      "[2075]\ttraining's rmse: 0.0819388\tvalid_1's rmse: 0.0862677\n",
      "[2100]\ttraining's rmse: 0.0819363\tvalid_1's rmse: 0.0862667\n",
      "[2125]\ttraining's rmse: 0.0819339\tvalid_1's rmse: 0.0862653\n",
      "[2150]\ttraining's rmse: 0.0819288\tvalid_1's rmse: 0.0862652\n",
      "[2175]\ttraining's rmse: 0.081926\tvalid_1's rmse: 0.0862645\n",
      "[2200]\ttraining's rmse: 0.0819238\tvalid_1's rmse: 0.0862638\n",
      "[2225]\ttraining's rmse: 0.081921\tvalid_1's rmse: 0.0862623\n",
      "[2250]\ttraining's rmse: 0.0819178\tvalid_1's rmse: 0.0862607\n",
      "[2275]\ttraining's rmse: 0.0819139\tvalid_1's rmse: 0.0862603\n",
      "[2300]\ttraining's rmse: 0.0819111\tvalid_1's rmse: 0.0862596\n",
      "[2325]\ttraining's rmse: 0.0819083\tvalid_1's rmse: 0.0862587\n",
      "[2350]\ttraining's rmse: 0.0819067\tvalid_1's rmse: 0.0862578\n",
      "[2375]\ttraining's rmse: 0.0819047\tvalid_1's rmse: 0.0862574\n",
      "[2400]\ttraining's rmse: 0.0819008\tvalid_1's rmse: 0.0862567\n",
      "[2425]\ttraining's rmse: 0.0818977\tvalid_1's rmse: 0.0862565\n",
      "[2450]\ttraining's rmse: 0.0818958\tvalid_1's rmse: 0.086256\n",
      "[2475]\ttraining's rmse: 0.0818938\tvalid_1's rmse: 0.086256\n",
      "[2500]\ttraining's rmse: 0.081891\tvalid_1's rmse: 0.086255\n",
      "[2525]\ttraining's rmse: 0.0818893\tvalid_1's rmse: 0.0862542\n",
      "[2550]\ttraining's rmse: 0.0818876\tvalid_1's rmse: 0.0862539\n",
      "[2575]\ttraining's rmse: 0.0818847\tvalid_1's rmse: 0.0862542\n",
      "Early stopping, best iteration is:\n",
      "[2533]\ttraining's rmse: 0.0818885\tvalid_1's rmse: 0.0862538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0847075\tvalid_1's rmse: 0.0870658\n",
      "[50]\ttraining's rmse: 0.0845884\tvalid_1's rmse: 0.0870118\n",
      "[75]\ttraining's rmse: 0.0844658\tvalid_1's rmse: 0.0869589\n",
      "[100]\ttraining's rmse: 0.0843559\tvalid_1's rmse: 0.0869123\n",
      "[125]\ttraining's rmse: 0.0842442\tvalid_1's rmse: 0.0868664\n",
      "[150]\ttraining's rmse: 0.0841389\tvalid_1's rmse: 0.0868229\n",
      "[175]\ttraining's rmse: 0.0840556\tvalid_1's rmse: 0.0867882\n",
      "[200]\ttraining's rmse: 0.0839634\tvalid_1's rmse: 0.086754\n",
      "[225]\ttraining's rmse: 0.0838732\tvalid_1's rmse: 0.0867207\n",
      "[250]\ttraining's rmse: 0.0837961\tvalid_1's rmse: 0.0866909\n",
      "[275]\ttraining's rmse: 0.0837246\tvalid_1's rmse: 0.0866626\n",
      "[300]\ttraining's rmse: 0.083653\tvalid_1's rmse: 0.0866376\n",
      "[325]\ttraining's rmse: 0.083581\tvalid_1's rmse: 0.0866118\n",
      "[350]\ttraining's rmse: 0.0835103\tvalid_1's rmse: 0.0865878\n",
      "[375]\ttraining's rmse: 0.0834523\tvalid_1's rmse: 0.0865682\n",
      "[400]\ttraining's rmse: 0.0833907\tvalid_1's rmse: 0.0865478\n",
      "[425]\ttraining's rmse: 0.0833352\tvalid_1's rmse: 0.0865287\n",
      "[450]\ttraining's rmse: 0.0832831\tvalid_1's rmse: 0.0865101\n",
      "[475]\ttraining's rmse: 0.0832347\tvalid_1's rmse: 0.0864938\n",
      "[500]\ttraining's rmse: 0.0831932\tvalid_1's rmse: 0.0864793\n",
      "[525]\ttraining's rmse: 0.0831386\tvalid_1's rmse: 0.0864645\n",
      "[550]\ttraining's rmse: 0.0830895\tvalid_1's rmse: 0.0864502\n",
      "[575]\ttraining's rmse: 0.0830455\tvalid_1's rmse: 0.0864365\n",
      "[600]\ttraining's rmse: 0.0830014\tvalid_1's rmse: 0.0864245\n",
      "[625]\ttraining's rmse: 0.0829671\tvalid_1's rmse: 0.0864123\n",
      "[650]\ttraining's rmse: 0.0829233\tvalid_1's rmse: 0.086401\n",
      "[675]\ttraining's rmse: 0.0828786\tvalid_1's rmse: 0.0863901\n",
      "[700]\ttraining's rmse: 0.0828387\tvalid_1's rmse: 0.0863794\n",
      "[725]\ttraining's rmse: 0.0828042\tvalid_1's rmse: 0.0863707\n",
      "[750]\ttraining's rmse: 0.0827721\tvalid_1's rmse: 0.0863615\n",
      "[775]\ttraining's rmse: 0.0827448\tvalid_1's rmse: 0.0863521\n",
      "[800]\ttraining's rmse: 0.0827086\tvalid_1's rmse: 0.0863441\n",
      "[825]\ttraining's rmse: 0.0826768\tvalid_1's rmse: 0.0863361\n",
      "[850]\ttraining's rmse: 0.0826489\tvalid_1's rmse: 0.0863296\n",
      "[875]\ttraining's rmse: 0.0826236\tvalid_1's rmse: 0.0863233\n",
      "[900]\ttraining's rmse: 0.0825925\tvalid_1's rmse: 0.0863161\n",
      "[925]\ttraining's rmse: 0.0825652\tvalid_1's rmse: 0.0863108\n",
      "[950]\ttraining's rmse: 0.0825396\tvalid_1's rmse: 0.0863049\n",
      "[975]\ttraining's rmse: 0.0825156\tvalid_1's rmse: 0.0862992\n",
      "[1000]\ttraining's rmse: 0.0824939\tvalid_1's rmse: 0.0862943\n",
      "[1025]\ttraining's rmse: 0.0824676\tvalid_1's rmse: 0.0862895\n",
      "[1050]\ttraining's rmse: 0.0824449\tvalid_1's rmse: 0.0862844\n",
      "[1075]\ttraining's rmse: 0.0824217\tvalid_1's rmse: 0.0862802\n",
      "[1100]\ttraining's rmse: 0.0824022\tvalid_1's rmse: 0.0862759\n",
      "[1125]\ttraining's rmse: 0.0823839\tvalid_1's rmse: 0.0862727\n",
      "[1150]\ttraining's rmse: 0.0823661\tvalid_1's rmse: 0.0862691\n",
      "[1175]\ttraining's rmse: 0.0823512\tvalid_1's rmse: 0.0862654\n",
      "[1200]\ttraining's rmse: 0.0823351\tvalid_1's rmse: 0.0862627\n",
      "[1225]\ttraining's rmse: 0.0823206\tvalid_1's rmse: 0.08626\n",
      "[1250]\ttraining's rmse: 0.0823049\tvalid_1's rmse: 0.086257\n",
      "[1275]\ttraining's rmse: 0.0822871\tvalid_1's rmse: 0.0862546\n",
      "[1300]\ttraining's rmse: 0.0822747\tvalid_1's rmse: 0.0862515\n",
      "[1325]\ttraining's rmse: 0.0822595\tvalid_1's rmse: 0.0862492\n",
      "[1350]\ttraining's rmse: 0.082247\tvalid_1's rmse: 0.0862475\n",
      "[1375]\ttraining's rmse: 0.0822351\tvalid_1's rmse: 0.0862459\n",
      "[1400]\ttraining's rmse: 0.0822242\tvalid_1's rmse: 0.0862434\n",
      "[1425]\ttraining's rmse: 0.0822118\tvalid_1's rmse: 0.0862418\n",
      "[1450]\ttraining's rmse: 0.0821958\tvalid_1's rmse: 0.0862405\n",
      "[1475]\ttraining's rmse: 0.0821855\tvalid_1's rmse: 0.0862389\n",
      "[1500]\ttraining's rmse: 0.0821764\tvalid_1's rmse: 0.0862374\n",
      "[1525]\ttraining's rmse: 0.0821678\tvalid_1's rmse: 0.0862361\n",
      "[1550]\ttraining's rmse: 0.0821578\tvalid_1's rmse: 0.0862349\n",
      "[1575]\ttraining's rmse: 0.0821488\tvalid_1's rmse: 0.0862334\n",
      "[1600]\ttraining's rmse: 0.0821407\tvalid_1's rmse: 0.0862326\n",
      "[1625]\ttraining's rmse: 0.0821313\tvalid_1's rmse: 0.0862312\n",
      "[1650]\ttraining's rmse: 0.0821247\tvalid_1's rmse: 0.0862306\n",
      "[1675]\ttraining's rmse: 0.0821188\tvalid_1's rmse: 0.0862292\n",
      "[1700]\ttraining's rmse: 0.0821135\tvalid_1's rmse: 0.0862279\n",
      "[1725]\ttraining's rmse: 0.0821051\tvalid_1's rmse: 0.086226\n",
      "[1750]\ttraining's rmse: 0.0820978\tvalid_1's rmse: 0.0862249\n",
      "[1775]\ttraining's rmse: 0.0820931\tvalid_1's rmse: 0.0862245\n",
      "[1800]\ttraining's rmse: 0.0820871\tvalid_1's rmse: 0.0862239\n",
      "[1825]\ttraining's rmse: 0.0820812\tvalid_1's rmse: 0.0862228\n",
      "[1850]\ttraining's rmse: 0.0820741\tvalid_1's rmse: 0.0862222\n",
      "[1875]\ttraining's rmse: 0.0820696\tvalid_1's rmse: 0.086222\n",
      "[1900]\ttraining's rmse: 0.0820651\tvalid_1's rmse: 0.0862218\n",
      "[1925]\ttraining's rmse: 0.0820598\tvalid_1's rmse: 0.0862215\n",
      "[1950]\ttraining's rmse: 0.0820562\tvalid_1's rmse: 0.0862206\n",
      "[1975]\ttraining's rmse: 0.0820509\tvalid_1's rmse: 0.0862191\n",
      "[2000]\ttraining's rmse: 0.0820469\tvalid_1's rmse: 0.0862188\n",
      "[2025]\ttraining's rmse: 0.0820423\tvalid_1's rmse: 0.086218\n",
      "[2050]\ttraining's rmse: 0.0820389\tvalid_1's rmse: 0.0862179\n",
      "[2075]\ttraining's rmse: 0.0820363\tvalid_1's rmse: 0.086218\n",
      "[2100]\ttraining's rmse: 0.0820323\tvalid_1's rmse: 0.0862177\n",
      "[2125]\ttraining's rmse: 0.0820292\tvalid_1's rmse: 0.0862177\n",
      "[2150]\ttraining's rmse: 0.0820252\tvalid_1's rmse: 0.0862175\n",
      "[2175]\ttraining's rmse: 0.082022\tvalid_1's rmse: 0.086217\n",
      "[2200]\ttraining's rmse: 0.0820187\tvalid_1's rmse: 0.0862165\n",
      "[2225]\ttraining's rmse: 0.0820156\tvalid_1's rmse: 0.0862159\n",
      "[2250]\ttraining's rmse: 0.0820125\tvalid_1's rmse: 0.0862159\n",
      "[2275]\ttraining's rmse: 0.0820095\tvalid_1's rmse: 0.0862156\n",
      "[2300]\ttraining's rmse: 0.0820067\tvalid_1's rmse: 0.0862149\n",
      "[2325]\ttraining's rmse: 0.0820019\tvalid_1's rmse: 0.0862148\n",
      "[2350]\ttraining's rmse: 0.0819998\tvalid_1's rmse: 0.0862144\n",
      "[2375]\ttraining's rmse: 0.0819966\tvalid_1's rmse: 0.0862144\n",
      "[2400]\ttraining's rmse: 0.0819946\tvalid_1's rmse: 0.0862146\n",
      "Early stopping, best iteration is:\n",
      "[2362]\ttraining's rmse: 0.0819986\tvalid_1's rmse: 0.0862142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0870135\tvalid_1's rmse: 0.082378\n",
      "[50]\ttraining's rmse: 0.0869034\tvalid_1's rmse: 0.0823315\n",
      "[75]\ttraining's rmse: 0.0867871\tvalid_1's rmse: 0.0822834\n",
      "[100]\ttraining's rmse: 0.0866818\tvalid_1's rmse: 0.0822417\n",
      "[125]\ttraining's rmse: 0.0865757\tvalid_1's rmse: 0.0822007\n",
      "[150]\ttraining's rmse: 0.0864767\tvalid_1's rmse: 0.0821645\n",
      "[175]\ttraining's rmse: 0.0863942\tvalid_1's rmse: 0.0821337\n",
      "[200]\ttraining's rmse: 0.0863036\tvalid_1's rmse: 0.0821027\n",
      "[225]\ttraining's rmse: 0.0862192\tvalid_1's rmse: 0.082073\n",
      "[250]\ttraining's rmse: 0.0861463\tvalid_1's rmse: 0.082046\n",
      "[275]\ttraining's rmse: 0.0860818\tvalid_1's rmse: 0.0820237\n",
      "[300]\ttraining's rmse: 0.0860166\tvalid_1's rmse: 0.0820018\n",
      "[325]\ttraining's rmse: 0.0859496\tvalid_1's rmse: 0.0819797\n",
      "[350]\ttraining's rmse: 0.0858845\tvalid_1's rmse: 0.0819595\n",
      "[375]\ttraining's rmse: 0.0858282\tvalid_1's rmse: 0.0819481\n",
      "[400]\ttraining's rmse: 0.0857685\tvalid_1's rmse: 0.0819355\n",
      "[425]\ttraining's rmse: 0.0857137\tvalid_1's rmse: 0.0819255\n",
      "[450]\ttraining's rmse: 0.0856635\tvalid_1's rmse: 0.0819143\n",
      "[475]\ttraining's rmse: 0.0856162\tvalid_1's rmse: 0.0819061\n",
      "[500]\ttraining's rmse: 0.085577\tvalid_1's rmse: 0.0818929\n",
      "[525]\ttraining's rmse: 0.0855247\tvalid_1's rmse: 0.0818861\n",
      "[550]\ttraining's rmse: 0.0854787\tvalid_1's rmse: 0.081873\n",
      "[575]\ttraining's rmse: 0.0854365\tvalid_1's rmse: 0.0818618\n",
      "[600]\ttraining's rmse: 0.0853923\tvalid_1's rmse: 0.0818548\n",
      "[625]\ttraining's rmse: 0.0853588\tvalid_1's rmse: 0.0818452\n",
      "[650]\ttraining's rmse: 0.0853158\tvalid_1's rmse: 0.0818483\n",
      "[675]\ttraining's rmse: 0.0852716\tvalid_1's rmse: 0.081842\n",
      "[700]\ttraining's rmse: 0.0852342\tvalid_1's rmse: 0.0818395\n",
      "[725]\ttraining's rmse: 0.0851973\tvalid_1's rmse: 0.0818407\n",
      "[750]\ttraining's rmse: 0.0851614\tvalid_1's rmse: 0.0818325\n",
      "[775]\ttraining's rmse: 0.085133\tvalid_1's rmse: 0.0818418\n",
      "[800]\ttraining's rmse: 0.0850965\tvalid_1's rmse: 0.0818365\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's rmse: 0.0851601\tvalid_1's rmse: 0.0818323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0864176\tvalid_1's rmse: 0.0889618\n",
      "[50]\ttraining's rmse: 0.0862771\tvalid_1's rmse: 0.0889121\n",
      "[75]\ttraining's rmse: 0.0861377\tvalid_1's rmse: 0.0888585\n",
      "[100]\ttraining's rmse: 0.0860067\tvalid_1's rmse: 0.088814\n",
      "[125]\ttraining's rmse: 0.0858813\tvalid_1's rmse: 0.0887684\n",
      "[150]\ttraining's rmse: 0.0857617\tvalid_1's rmse: 0.088724\n",
      "[175]\ttraining's rmse: 0.0856631\tvalid_1's rmse: 0.0886883\n",
      "[200]\ttraining's rmse: 0.0855576\tvalid_1's rmse: 0.0886505\n",
      "[225]\ttraining's rmse: 0.0854572\tvalid_1's rmse: 0.0886149\n",
      "[250]\ttraining's rmse: 0.085368\tvalid_1's rmse: 0.0885832\n",
      "[275]\ttraining's rmse: 0.0852845\tvalid_1's rmse: 0.0885562\n",
      "[300]\ttraining's rmse: 0.0852037\tvalid_1's rmse: 0.0885286\n",
      "[325]\ttraining's rmse: 0.0851214\tvalid_1's rmse: 0.0885034\n",
      "[350]\ttraining's rmse: 0.0850436\tvalid_1's rmse: 0.0884785\n",
      "[375]\ttraining's rmse: 0.0849797\tvalid_1's rmse: 0.0884592\n",
      "[400]\ttraining's rmse: 0.0849086\tvalid_1's rmse: 0.0884382\n",
      "[425]\ttraining's rmse: 0.0848451\tvalid_1's rmse: 0.0884168\n",
      "[450]\ttraining's rmse: 0.0847867\tvalid_1's rmse: 0.0883979\n",
      "[475]\ttraining's rmse: 0.0847309\tvalid_1's rmse: 0.0883796\n",
      "[500]\ttraining's rmse: 0.0846864\tvalid_1's rmse: 0.0883639\n",
      "[525]\ttraining's rmse: 0.0846258\tvalid_1's rmse: 0.0883474\n",
      "[550]\ttraining's rmse: 0.0845734\tvalid_1's rmse: 0.088332\n",
      "[575]\ttraining's rmse: 0.0845267\tvalid_1's rmse: 0.0883187\n",
      "[600]\ttraining's rmse: 0.084479\tvalid_1's rmse: 0.088306\n",
      "[625]\ttraining's rmse: 0.0844411\tvalid_1's rmse: 0.0882948\n",
      "[650]\ttraining's rmse: 0.0843973\tvalid_1's rmse: 0.0882816\n",
      "[675]\ttraining's rmse: 0.0843524\tvalid_1's rmse: 0.0882698\n",
      "[700]\ttraining's rmse: 0.084314\tvalid_1's rmse: 0.0882588\n",
      "[725]\ttraining's rmse: 0.0842745\tvalid_1's rmse: 0.0882485\n",
      "[750]\ttraining's rmse: 0.0842384\tvalid_1's rmse: 0.0882394\n",
      "[775]\ttraining's rmse: 0.0842105\tvalid_1's rmse: 0.0882298\n",
      "[800]\ttraining's rmse: 0.0841748\tvalid_1's rmse: 0.0882206\n",
      "[825]\ttraining's rmse: 0.0841455\tvalid_1's rmse: 0.0882108\n",
      "[850]\ttraining's rmse: 0.084113\tvalid_1's rmse: 0.0882033\n",
      "[875]\ttraining's rmse: 0.0840865\tvalid_1's rmse: 0.0881951\n",
      "[900]\ttraining's rmse: 0.0840572\tvalid_1's rmse: 0.0881877\n",
      "[925]\ttraining's rmse: 0.0840292\tvalid_1's rmse: 0.0881799\n",
      "[950]\ttraining's rmse: 0.0840026\tvalid_1's rmse: 0.0881721\n",
      "[975]\ttraining's rmse: 0.0839756\tvalid_1's rmse: 0.0881652\n",
      "[1000]\ttraining's rmse: 0.0839511\tvalid_1's rmse: 0.0881589\n",
      "[1025]\ttraining's rmse: 0.0839257\tvalid_1's rmse: 0.0881519\n",
      "[1050]\ttraining's rmse: 0.0839062\tvalid_1's rmse: 0.0881448\n",
      "[1075]\ttraining's rmse: 0.0838825\tvalid_1's rmse: 0.0881393\n",
      "[1100]\ttraining's rmse: 0.0838622\tvalid_1's rmse: 0.0881338\n",
      "[1125]\ttraining's rmse: 0.0838427\tvalid_1's rmse: 0.0881283\n",
      "[1150]\ttraining's rmse: 0.0838247\tvalid_1's rmse: 0.0881233\n",
      "[1175]\ttraining's rmse: 0.0838068\tvalid_1's rmse: 0.088119\n",
      "[1200]\ttraining's rmse: 0.0837864\tvalid_1's rmse: 0.088114\n",
      "[1225]\ttraining's rmse: 0.0837683\tvalid_1's rmse: 0.0881083\n",
      "[1250]\ttraining's rmse: 0.0837534\tvalid_1's rmse: 0.088105\n",
      "[1275]\ttraining's rmse: 0.0837342\tvalid_1's rmse: 0.0881011\n",
      "[1300]\ttraining's rmse: 0.0837236\tvalid_1's rmse: 0.0880975\n",
      "[1325]\ttraining's rmse: 0.0837084\tvalid_1's rmse: 0.0880929\n",
      "[1350]\ttraining's rmse: 0.0836954\tvalid_1's rmse: 0.0880901\n",
      "[1375]\ttraining's rmse: 0.0836805\tvalid_1's rmse: 0.0880866\n",
      "[1400]\ttraining's rmse: 0.0836672\tvalid_1's rmse: 0.0880823\n",
      "[1425]\ttraining's rmse: 0.0836485\tvalid_1's rmse: 0.0880789\n",
      "[1450]\ttraining's rmse: 0.0836343\tvalid_1's rmse: 0.0880754\n",
      "[1475]\ttraining's rmse: 0.0836227\tvalid_1's rmse: 0.0880716\n",
      "[1500]\ttraining's rmse: 0.0836099\tvalid_1's rmse: 0.0880689\n",
      "[1525]\ttraining's rmse: 0.0836003\tvalid_1's rmse: 0.0880659\n",
      "[1550]\ttraining's rmse: 0.0835925\tvalid_1's rmse: 0.0880644\n",
      "[1575]\ttraining's rmse: 0.0835833\tvalid_1's rmse: 0.0880611\n",
      "[1600]\ttraining's rmse: 0.0835751\tvalid_1's rmse: 0.0880578\n",
      "[1625]\ttraining's rmse: 0.0835665\tvalid_1's rmse: 0.088055\n",
      "[1650]\ttraining's rmse: 0.0835578\tvalid_1's rmse: 0.0880529\n",
      "[1675]\ttraining's rmse: 0.0835476\tvalid_1's rmse: 0.0880514\n",
      "[1700]\ttraining's rmse: 0.0835405\tvalid_1's rmse: 0.0880492\n",
      "[1725]\ttraining's rmse: 0.083534\tvalid_1's rmse: 0.0880477\n",
      "[1750]\ttraining's rmse: 0.0835264\tvalid_1's rmse: 0.0880448\n",
      "[1775]\ttraining's rmse: 0.08352\tvalid_1's rmse: 0.0880449\n",
      "[1800]\ttraining's rmse: 0.0835147\tvalid_1's rmse: 0.088044\n",
      "[1825]\ttraining's rmse: 0.0835086\tvalid_1's rmse: 0.0880419\n",
      "[1850]\ttraining's rmse: 0.083502\tvalid_1's rmse: 0.0880405\n",
      "[1875]\ttraining's rmse: 0.0834958\tvalid_1's rmse: 0.0880399\n",
      "[1900]\ttraining's rmse: 0.0834907\tvalid_1's rmse: 0.088039\n",
      "[1925]\ttraining's rmse: 0.0834868\tvalid_1's rmse: 0.088038\n",
      "[1950]\ttraining's rmse: 0.0834829\tvalid_1's rmse: 0.088036\n",
      "[1975]\ttraining's rmse: 0.0834789\tvalid_1's rmse: 0.088034\n",
      "[2000]\ttraining's rmse: 0.0834729\tvalid_1's rmse: 0.0880329\n",
      "[2025]\ttraining's rmse: 0.0834686\tvalid_1's rmse: 0.0880313\n",
      "[2050]\ttraining's rmse: 0.0834652\tvalid_1's rmse: 0.0880298\n",
      "[2075]\ttraining's rmse: 0.0834618\tvalid_1's rmse: 0.0880297\n",
      "[2100]\ttraining's rmse: 0.0834578\tvalid_1's rmse: 0.0880286\n",
      "[2125]\ttraining's rmse: 0.083454\tvalid_1's rmse: 0.0880274\n",
      "[2150]\ttraining's rmse: 0.0834497\tvalid_1's rmse: 0.0880257\n",
      "[2175]\ttraining's rmse: 0.0834462\tvalid_1's rmse: 0.0880249\n",
      "[2200]\ttraining's rmse: 0.0834434\tvalid_1's rmse: 0.0880246\n",
      "[2225]\ttraining's rmse: 0.083439\tvalid_1's rmse: 0.0880234\n",
      "[2250]\ttraining's rmse: 0.083434\tvalid_1's rmse: 0.0880223\n",
      "[2275]\ttraining's rmse: 0.0834299\tvalid_1's rmse: 0.0880211\n",
      "[2300]\ttraining's rmse: 0.0834274\tvalid_1's rmse: 0.0880203\n",
      "[2325]\ttraining's rmse: 0.0834238\tvalid_1's rmse: 0.0880193\n",
      "[2350]\ttraining's rmse: 0.0834208\tvalid_1's rmse: 0.0880187\n",
      "[2375]\ttraining's rmse: 0.0834176\tvalid_1's rmse: 0.0880182\n",
      "[2400]\ttraining's rmse: 0.0834144\tvalid_1's rmse: 0.0880177\n",
      "[2425]\ttraining's rmse: 0.0834121\tvalid_1's rmse: 0.0880167\n",
      "[2450]\ttraining's rmse: 0.0834105\tvalid_1's rmse: 0.088016\n",
      "[2475]\ttraining's rmse: 0.0834073\tvalid_1's rmse: 0.0880158\n",
      "[2500]\ttraining's rmse: 0.0834045\tvalid_1's rmse: 0.0880161\n",
      "[2525]\ttraining's rmse: 0.0834019\tvalid_1's rmse: 0.0880153\n",
      "[2550]\ttraining's rmse: 0.0833989\tvalid_1's rmse: 0.0880147\n",
      "[2575]\ttraining's rmse: 0.083396\tvalid_1's rmse: 0.0880144\n",
      "[2600]\ttraining's rmse: 0.0833945\tvalid_1's rmse: 0.0880141\n",
      "[2625]\ttraining's rmse: 0.0833928\tvalid_1's rmse: 0.0880133\n",
      "[2650]\ttraining's rmse: 0.0833905\tvalid_1's rmse: 0.0880123\n",
      "[2675]\ttraining's rmse: 0.0833888\tvalid_1's rmse: 0.0880114\n",
      "[2700]\ttraining's rmse: 0.083388\tvalid_1's rmse: 0.0880113\n",
      "[2725]\ttraining's rmse: 0.0833859\tvalid_1's rmse: 0.088011\n",
      "[2750]\ttraining's rmse: 0.0833834\tvalid_1's rmse: 0.0880104\n",
      "[2775]\ttraining's rmse: 0.0833808\tvalid_1's rmse: 0.0880105\n",
      "Early stopping, best iteration is:\n",
      "[2743]\ttraining's rmse: 0.0833844\tvalid_1's rmse: 0.0880103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0864426\tvalid_1's rmse: 0.0889451\n",
      "[50]\ttraining's rmse: 0.0863188\tvalid_1's rmse: 0.0888921\n",
      "[75]\ttraining's rmse: 0.0861918\tvalid_1's rmse: 0.0888398\n",
      "[100]\ttraining's rmse: 0.0860792\tvalid_1's rmse: 0.0887933\n",
      "[125]\ttraining's rmse: 0.0859604\tvalid_1's rmse: 0.0887473\n",
      "[150]\ttraining's rmse: 0.0858492\tvalid_1's rmse: 0.0887031\n",
      "[175]\ttraining's rmse: 0.0857592\tvalid_1's rmse: 0.0886679\n",
      "[200]\ttraining's rmse: 0.0856606\tvalid_1's rmse: 0.0886311\n",
      "[225]\ttraining's rmse: 0.0855642\tvalid_1's rmse: 0.0885959\n",
      "[250]\ttraining's rmse: 0.0854837\tvalid_1's rmse: 0.088566\n",
      "[275]\ttraining's rmse: 0.0854079\tvalid_1's rmse: 0.0885366\n",
      "[300]\ttraining's rmse: 0.0853329\tvalid_1's rmse: 0.0885105\n",
      "[325]\ttraining's rmse: 0.0852559\tvalid_1's rmse: 0.0884846\n",
      "[350]\ttraining's rmse: 0.0851819\tvalid_1's rmse: 0.0884595\n",
      "[375]\ttraining's rmse: 0.0851225\tvalid_1's rmse: 0.0884393\n",
      "[400]\ttraining's rmse: 0.0850568\tvalid_1's rmse: 0.0884196\n",
      "[425]\ttraining's rmse: 0.0849967\tvalid_1's rmse: 0.0884\n",
      "[450]\ttraining's rmse: 0.0849403\tvalid_1's rmse: 0.0883814\n",
      "[475]\ttraining's rmse: 0.0848872\tvalid_1's rmse: 0.0883646\n",
      "[500]\ttraining's rmse: 0.0848443\tvalid_1's rmse: 0.0883498\n",
      "[525]\ttraining's rmse: 0.0847888\tvalid_1's rmse: 0.0883339\n",
      "[550]\ttraining's rmse: 0.0847385\tvalid_1's rmse: 0.0883192\n",
      "[575]\ttraining's rmse: 0.0846914\tvalid_1's rmse: 0.0883063\n",
      "[600]\ttraining's rmse: 0.0846454\tvalid_1's rmse: 0.0882941\n",
      "[625]\ttraining's rmse: 0.0846096\tvalid_1's rmse: 0.0882823\n",
      "[650]\ttraining's rmse: 0.0845654\tvalid_1's rmse: 0.0882711\n",
      "[675]\ttraining's rmse: 0.0845201\tvalid_1's rmse: 0.0882599\n",
      "[700]\ttraining's rmse: 0.0844788\tvalid_1's rmse: 0.0882494\n",
      "[725]\ttraining's rmse: 0.0844419\tvalid_1's rmse: 0.0882398\n",
      "[750]\ttraining's rmse: 0.0844083\tvalid_1's rmse: 0.0882313\n",
      "[775]\ttraining's rmse: 0.0843807\tvalid_1's rmse: 0.088223\n",
      "[800]\ttraining's rmse: 0.0843429\tvalid_1's rmse: 0.0882152\n",
      "[825]\ttraining's rmse: 0.0843119\tvalid_1's rmse: 0.0882064\n",
      "[850]\ttraining's rmse: 0.0842809\tvalid_1's rmse: 0.0881998\n",
      "[875]\ttraining's rmse: 0.0842533\tvalid_1's rmse: 0.0881934\n",
      "[900]\ttraining's rmse: 0.0842239\tvalid_1's rmse: 0.0881868\n",
      "[925]\ttraining's rmse: 0.0841948\tvalid_1's rmse: 0.0881823\n",
      "[950]\ttraining's rmse: 0.0841681\tvalid_1's rmse: 0.0881766\n",
      "[975]\ttraining's rmse: 0.084144\tvalid_1's rmse: 0.0881717\n",
      "[1000]\ttraining's rmse: 0.0841197\tvalid_1's rmse: 0.088167\n",
      "[1025]\ttraining's rmse: 0.0840927\tvalid_1's rmse: 0.0881621\n",
      "[1050]\ttraining's rmse: 0.0840708\tvalid_1's rmse: 0.0881573\n",
      "[1075]\ttraining's rmse: 0.0840495\tvalid_1's rmse: 0.0881538\n",
      "[1100]\ttraining's rmse: 0.0840341\tvalid_1's rmse: 0.0881502\n",
      "[1125]\ttraining's rmse: 0.0840143\tvalid_1's rmse: 0.0881471\n",
      "[1150]\ttraining's rmse: 0.0839967\tvalid_1's rmse: 0.088144\n",
      "[1175]\ttraining's rmse: 0.0839779\tvalid_1's rmse: 0.0881408\n",
      "[1200]\ttraining's rmse: 0.0839607\tvalid_1's rmse: 0.0881373\n",
      "[1225]\ttraining's rmse: 0.0839436\tvalid_1's rmse: 0.0881344\n",
      "[1250]\ttraining's rmse: 0.083929\tvalid_1's rmse: 0.0881316\n",
      "[1275]\ttraining's rmse: 0.0839133\tvalid_1's rmse: 0.0881296\n",
      "[1300]\ttraining's rmse: 0.0838985\tvalid_1's rmse: 0.0881269\n",
      "[1325]\ttraining's rmse: 0.0838844\tvalid_1's rmse: 0.0881245\n",
      "[1350]\ttraining's rmse: 0.0838691\tvalid_1's rmse: 0.0881227\n",
      "[1375]\ttraining's rmse: 0.0838539\tvalid_1's rmse: 0.0881215\n",
      "[1400]\ttraining's rmse: 0.0838418\tvalid_1's rmse: 0.0881194\n",
      "[1425]\ttraining's rmse: 0.0838279\tvalid_1's rmse: 0.0881185\n",
      "[1450]\ttraining's rmse: 0.0838144\tvalid_1's rmse: 0.0881175\n",
      "[1475]\ttraining's rmse: 0.0838038\tvalid_1's rmse: 0.0881156\n",
      "[1500]\ttraining's rmse: 0.083794\tvalid_1's rmse: 0.0881143\n",
      "[1525]\ttraining's rmse: 0.0837823\tvalid_1's rmse: 0.0881134\n",
      "[1550]\ttraining's rmse: 0.083772\tvalid_1's rmse: 0.0881127\n",
      "[1575]\ttraining's rmse: 0.0837619\tvalid_1's rmse: 0.0881124\n",
      "[1600]\ttraining's rmse: 0.0837538\tvalid_1's rmse: 0.0881119\n",
      "[1625]\ttraining's rmse: 0.0837449\tvalid_1's rmse: 0.08811\n",
      "[1650]\ttraining's rmse: 0.0837368\tvalid_1's rmse: 0.088109\n",
      "[1675]\ttraining's rmse: 0.0837297\tvalid_1's rmse: 0.088108\n",
      "[1700]\ttraining's rmse: 0.0837227\tvalid_1's rmse: 0.0881066\n",
      "[1725]\ttraining's rmse: 0.0837152\tvalid_1's rmse: 0.0881054\n",
      "[1750]\ttraining's rmse: 0.083708\tvalid_1's rmse: 0.0881053\n",
      "[1775]\ttraining's rmse: 0.0837017\tvalid_1's rmse: 0.0881048\n",
      "[1800]\ttraining's rmse: 0.0836967\tvalid_1's rmse: 0.0881043\n",
      "[1825]\ttraining's rmse: 0.0836907\tvalid_1's rmse: 0.0881035\n",
      "[1850]\ttraining's rmse: 0.0836861\tvalid_1's rmse: 0.0881027\n",
      "[1875]\ttraining's rmse: 0.0836811\tvalid_1's rmse: 0.0881027\n",
      "[1900]\ttraining's rmse: 0.0836755\tvalid_1's rmse: 0.0881026\n",
      "[1925]\ttraining's rmse: 0.0836705\tvalid_1's rmse: 0.0881022\n",
      "[1950]\ttraining's rmse: 0.0836659\tvalid_1's rmse: 0.0881016\n",
      "[1975]\ttraining's rmse: 0.0836607\tvalid_1's rmse: 0.0881009\n",
      "[2000]\ttraining's rmse: 0.0836561\tvalid_1's rmse: 0.0881001\n",
      "[2025]\ttraining's rmse: 0.0836531\tvalid_1's rmse: 0.0881\n",
      "[2050]\ttraining's rmse: 0.0836494\tvalid_1's rmse: 0.0880999\n",
      "[2075]\ttraining's rmse: 0.083647\tvalid_1's rmse: 0.0880995\n",
      "[2100]\ttraining's rmse: 0.0836436\tvalid_1's rmse: 0.0880989\n",
      "[2125]\ttraining's rmse: 0.0836399\tvalid_1's rmse: 0.088099\n",
      "[2150]\ttraining's rmse: 0.0836344\tvalid_1's rmse: 0.0880986\n",
      "[2175]\ttraining's rmse: 0.0836315\tvalid_1's rmse: 0.0880983\n",
      "[2200]\ttraining's rmse: 0.0836279\tvalid_1's rmse: 0.0880977\n",
      "[2225]\ttraining's rmse: 0.0836238\tvalid_1's rmse: 0.0880975\n",
      "[2250]\ttraining's rmse: 0.0836198\tvalid_1's rmse: 0.0880975\n",
      "[2275]\ttraining's rmse: 0.0836154\tvalid_1's rmse: 0.0880975\n",
      "[2300]\ttraining's rmse: 0.0836124\tvalid_1's rmse: 0.088097\n",
      "[2325]\ttraining's rmse: 0.0836085\tvalid_1's rmse: 0.088097\n",
      "[2350]\ttraining's rmse: 0.0836042\tvalid_1's rmse: 0.0880963\n",
      "[2375]\ttraining's rmse: 0.0836016\tvalid_1's rmse: 0.0880964\n",
      "[2400]\ttraining's rmse: 0.0835986\tvalid_1's rmse: 0.0880961\n",
      "[2425]\ttraining's rmse: 0.0835962\tvalid_1's rmse: 0.088096\n",
      "[2450]\ttraining's rmse: 0.0835938\tvalid_1's rmse: 0.0880961\n",
      "Early stopping, best iteration is:\n",
      "[2423]\ttraining's rmse: 0.0835967\tvalid_1's rmse: 0.088096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0888254\tvalid_1's rmse: 0.084096\n",
      "[50]\ttraining's rmse: 0.0887082\tvalid_1's rmse: 0.0840527\n",
      "[75]\ttraining's rmse: 0.0885838\tvalid_1's rmse: 0.0840031\n",
      "[100]\ttraining's rmse: 0.0884749\tvalid_1's rmse: 0.0839616\n",
      "[125]\ttraining's rmse: 0.0883612\tvalid_1's rmse: 0.0839202\n",
      "[150]\ttraining's rmse: 0.0882565\tvalid_1's rmse: 0.0838815\n",
      "[175]\ttraining's rmse: 0.0881694\tvalid_1's rmse: 0.083857\n",
      "[200]\ttraining's rmse: 0.0880713\tvalid_1's rmse: 0.0838237\n",
      "[225]\ttraining's rmse: 0.0879787\tvalid_1's rmse: 0.083793\n",
      "[250]\ttraining's rmse: 0.0879028\tvalid_1's rmse: 0.0837658\n",
      "[275]\ttraining's rmse: 0.0878334\tvalid_1's rmse: 0.0837405\n",
      "[300]\ttraining's rmse: 0.0877656\tvalid_1's rmse: 0.0837168\n",
      "[325]\ttraining's rmse: 0.0876936\tvalid_1's rmse: 0.0836946\n",
      "[350]\ttraining's rmse: 0.0876245\tvalid_1's rmse: 0.0836716\n",
      "[375]\ttraining's rmse: 0.0875697\tvalid_1's rmse: 0.083659\n",
      "[400]\ttraining's rmse: 0.0875071\tvalid_1's rmse: 0.0836456\n",
      "[425]\ttraining's rmse: 0.0874485\tvalid_1's rmse: 0.0836348\n",
      "[450]\ttraining's rmse: 0.0873952\tvalid_1's rmse: 0.0836214\n",
      "[475]\ttraining's rmse: 0.0873435\tvalid_1's rmse: 0.0836085\n",
      "[500]\ttraining's rmse: 0.0873033\tvalid_1's rmse: 0.0835966\n",
      "[525]\ttraining's rmse: 0.0872471\tvalid_1's rmse: 0.0835899\n",
      "[550]\ttraining's rmse: 0.0871968\tvalid_1's rmse: 0.0835804\n",
      "[575]\ttraining's rmse: 0.0871495\tvalid_1's rmse: 0.0835692\n",
      "[600]\ttraining's rmse: 0.0871047\tvalid_1's rmse: 0.0835633\n",
      "[625]\ttraining's rmse: 0.0870693\tvalid_1's rmse: 0.0835543\n",
      "[650]\ttraining's rmse: 0.0870243\tvalid_1's rmse: 0.0835538\n",
      "[675]\ttraining's rmse: 0.086979\tvalid_1's rmse: 0.0835448\n",
      "[700]\ttraining's rmse: 0.0869394\tvalid_1's rmse: 0.0835367\n",
      "[725]\ttraining's rmse: 0.0869008\tvalid_1's rmse: 0.0835347\n",
      "[750]\ttraining's rmse: 0.0868657\tvalid_1's rmse: 0.0835375\n",
      "[775]\ttraining's rmse: 0.0868369\tvalid_1's rmse: 0.0835375\n",
      "Early stopping, best iteration is:\n",
      "[738]\ttraining's rmse: 0.086882\tvalid_1's rmse: 0.0835306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0851025\tvalid_1's rmse: 0.0876721\n",
      "[50]\ttraining's rmse: 0.0849717\tvalid_1's rmse: 0.0876196\n",
      "[75]\ttraining's rmse: 0.0848442\tvalid_1's rmse: 0.0875663\n",
      "[100]\ttraining's rmse: 0.0847251\tvalid_1's rmse: 0.0875217\n",
      "[125]\ttraining's rmse: 0.0846051\tvalid_1's rmse: 0.0874732\n",
      "[150]\ttraining's rmse: 0.0844956\tvalid_1's rmse: 0.0874293\n",
      "[175]\ttraining's rmse: 0.0844065\tvalid_1's rmse: 0.0873926\n",
      "[200]\ttraining's rmse: 0.0843107\tvalid_1's rmse: 0.0873545\n",
      "[225]\ttraining's rmse: 0.0842166\tvalid_1's rmse: 0.0873184\n",
      "[250]\ttraining's rmse: 0.0841366\tvalid_1's rmse: 0.0872851\n",
      "[275]\ttraining's rmse: 0.0840618\tvalid_1's rmse: 0.0872553\n",
      "[300]\ttraining's rmse: 0.0839845\tvalid_1's rmse: 0.0872275\n",
      "[325]\ttraining's rmse: 0.0839064\tvalid_1's rmse: 0.0872016\n",
      "[350]\ttraining's rmse: 0.0838372\tvalid_1's rmse: 0.0871739\n",
      "[375]\ttraining's rmse: 0.0837774\tvalid_1's rmse: 0.0871522\n",
      "[400]\ttraining's rmse: 0.0837162\tvalid_1's rmse: 0.0871297\n",
      "[425]\ttraining's rmse: 0.0836576\tvalid_1's rmse: 0.0871091\n",
      "[450]\ttraining's rmse: 0.0836033\tvalid_1's rmse: 0.087089\n",
      "[475]\ttraining's rmse: 0.0835531\tvalid_1's rmse: 0.0870701\n",
      "[500]\ttraining's rmse: 0.0835125\tvalid_1's rmse: 0.0870538\n",
      "[525]\ttraining's rmse: 0.0834612\tvalid_1's rmse: 0.087037\n",
      "[550]\ttraining's rmse: 0.0834114\tvalid_1's rmse: 0.0870213\n",
      "[575]\ttraining's rmse: 0.0833658\tvalid_1's rmse: 0.0870065\n",
      "[600]\ttraining's rmse: 0.0833247\tvalid_1's rmse: 0.0869922\n",
      "[625]\ttraining's rmse: 0.0832883\tvalid_1's rmse: 0.0869796\n",
      "[650]\ttraining's rmse: 0.0832465\tvalid_1's rmse: 0.0869662\n",
      "[675]\ttraining's rmse: 0.0832053\tvalid_1's rmse: 0.0869539\n",
      "[700]\ttraining's rmse: 0.0831681\tvalid_1's rmse: 0.0869426\n",
      "[725]\ttraining's rmse: 0.0831351\tvalid_1's rmse: 0.0869333\n",
      "[750]\ttraining's rmse: 0.0831036\tvalid_1's rmse: 0.0869245\n",
      "[775]\ttraining's rmse: 0.0830737\tvalid_1's rmse: 0.0869141\n",
      "[800]\ttraining's rmse: 0.0830398\tvalid_1's rmse: 0.0869041\n",
      "[825]\ttraining's rmse: 0.0830097\tvalid_1's rmse: 0.0868953\n",
      "[850]\ttraining's rmse: 0.0829771\tvalid_1's rmse: 0.0868874\n",
      "[875]\ttraining's rmse: 0.0829515\tvalid_1's rmse: 0.0868798\n",
      "[900]\ttraining's rmse: 0.0829226\tvalid_1's rmse: 0.0868725\n",
      "[925]\ttraining's rmse: 0.0828946\tvalid_1's rmse: 0.0868637\n",
      "[950]\ttraining's rmse: 0.0828721\tvalid_1's rmse: 0.0868568\n",
      "[975]\ttraining's rmse: 0.0828477\tvalid_1's rmse: 0.0868507\n",
      "[1000]\ttraining's rmse: 0.0828237\tvalid_1's rmse: 0.0868441\n",
      "[1025]\ttraining's rmse: 0.0828008\tvalid_1's rmse: 0.0868373\n",
      "[1050]\ttraining's rmse: 0.08278\tvalid_1's rmse: 0.08683\n",
      "[1075]\ttraining's rmse: 0.0827597\tvalid_1's rmse: 0.086826\n",
      "[1100]\ttraining's rmse: 0.0827428\tvalid_1's rmse: 0.08682\n",
      "[1125]\ttraining's rmse: 0.0827264\tvalid_1's rmse: 0.0868136\n",
      "[1150]\ttraining's rmse: 0.0827057\tvalid_1's rmse: 0.0868091\n",
      "[1175]\ttraining's rmse: 0.0826878\tvalid_1's rmse: 0.086805\n",
      "[1200]\ttraining's rmse: 0.082672\tvalid_1's rmse: 0.0867988\n",
      "[1225]\ttraining's rmse: 0.0826565\tvalid_1's rmse: 0.0867949\n",
      "[1250]\ttraining's rmse: 0.0826398\tvalid_1's rmse: 0.086791\n",
      "[1275]\ttraining's rmse: 0.0826206\tvalid_1's rmse: 0.0867879\n",
      "[1300]\ttraining's rmse: 0.0826072\tvalid_1's rmse: 0.0867832\n",
      "[1325]\ttraining's rmse: 0.0825908\tvalid_1's rmse: 0.086779\n",
      "[1350]\ttraining's rmse: 0.0825759\tvalid_1's rmse: 0.0867763\n",
      "[1375]\ttraining's rmse: 0.0825623\tvalid_1's rmse: 0.0867727\n",
      "[1400]\ttraining's rmse: 0.0825508\tvalid_1's rmse: 0.0867695\n",
      "[1425]\ttraining's rmse: 0.082536\tvalid_1's rmse: 0.0867665\n",
      "[1450]\ttraining's rmse: 0.0825245\tvalid_1's rmse: 0.0867641\n",
      "[1475]\ttraining's rmse: 0.082515\tvalid_1's rmse: 0.0867609\n",
      "[1500]\ttraining's rmse: 0.0825063\tvalid_1's rmse: 0.086759\n",
      "[1525]\ttraining's rmse: 0.0824952\tvalid_1's rmse: 0.0867558\n",
      "[1550]\ttraining's rmse: 0.0824842\tvalid_1's rmse: 0.0867545\n",
      "[1575]\ttraining's rmse: 0.0824782\tvalid_1's rmse: 0.0867506\n",
      "[1600]\ttraining's rmse: 0.0824714\tvalid_1's rmse: 0.0867486\n",
      "[1625]\ttraining's rmse: 0.0824649\tvalid_1's rmse: 0.0867458\n",
      "[1650]\ttraining's rmse: 0.0824569\tvalid_1's rmse: 0.0867429\n",
      "[1675]\ttraining's rmse: 0.0824517\tvalid_1's rmse: 0.0867401\n",
      "[1700]\ttraining's rmse: 0.0824456\tvalid_1's rmse: 0.0867378\n",
      "[1725]\ttraining's rmse: 0.0824379\tvalid_1's rmse: 0.0867361\n",
      "[1750]\ttraining's rmse: 0.0824318\tvalid_1's rmse: 0.0867345\n",
      "[1775]\ttraining's rmse: 0.0824255\tvalid_1's rmse: 0.0867321\n",
      "[1800]\ttraining's rmse: 0.0824196\tvalid_1's rmse: 0.0867305\n",
      "[1825]\ttraining's rmse: 0.0824142\tvalid_1's rmse: 0.0867287\n",
      "[1850]\ttraining's rmse: 0.0824105\tvalid_1's rmse: 0.0867264\n",
      "[1875]\ttraining's rmse: 0.0824069\tvalid_1's rmse: 0.086725\n",
      "[1900]\ttraining's rmse: 0.0823999\tvalid_1's rmse: 0.0867237\n",
      "[1925]\ttraining's rmse: 0.082395\tvalid_1's rmse: 0.0867224\n",
      "[1950]\ttraining's rmse: 0.0823899\tvalid_1's rmse: 0.0867199\n",
      "[1975]\ttraining's rmse: 0.0823855\tvalid_1's rmse: 0.0867174\n",
      "[2000]\ttraining's rmse: 0.0823821\tvalid_1's rmse: 0.0867157\n",
      "[2025]\ttraining's rmse: 0.0823773\tvalid_1's rmse: 0.0867136\n",
      "[2050]\ttraining's rmse: 0.0823735\tvalid_1's rmse: 0.0867126\n",
      "[2075]\ttraining's rmse: 0.0823706\tvalid_1's rmse: 0.0867109\n",
      "[2100]\ttraining's rmse: 0.082367\tvalid_1's rmse: 0.0867096\n",
      "[2125]\ttraining's rmse: 0.0823642\tvalid_1's rmse: 0.0867082\n",
      "[2150]\ttraining's rmse: 0.0823594\tvalid_1's rmse: 0.0867083\n",
      "[2175]\ttraining's rmse: 0.0823564\tvalid_1's rmse: 0.0867078\n",
      "[2200]\ttraining's rmse: 0.0823539\tvalid_1's rmse: 0.0867065\n",
      "[2225]\ttraining's rmse: 0.0823507\tvalid_1's rmse: 0.0867051\n",
      "[2250]\ttraining's rmse: 0.0823478\tvalid_1's rmse: 0.0867045\n",
      "[2275]\ttraining's rmse: 0.0823444\tvalid_1's rmse: 0.0867041\n",
      "[2300]\ttraining's rmse: 0.0823424\tvalid_1's rmse: 0.0867035\n",
      "[2325]\ttraining's rmse: 0.0823394\tvalid_1's rmse: 0.0867024\n",
      "[2350]\ttraining's rmse: 0.082336\tvalid_1's rmse: 0.0867022\n",
      "[2375]\ttraining's rmse: 0.082332\tvalid_1's rmse: 0.0867016\n",
      "[2400]\ttraining's rmse: 0.0823286\tvalid_1's rmse: 0.0867009\n",
      "[2425]\ttraining's rmse: 0.0823238\tvalid_1's rmse: 0.0867004\n",
      "[2450]\ttraining's rmse: 0.0823214\tvalid_1's rmse: 0.0866997\n",
      "[2475]\ttraining's rmse: 0.0823193\tvalid_1's rmse: 0.0866991\n",
      "[2500]\ttraining's rmse: 0.0823159\tvalid_1's rmse: 0.0866992\n",
      "[2525]\ttraining's rmse: 0.0823139\tvalid_1's rmse: 0.0866987\n",
      "[2550]\ttraining's rmse: 0.0823114\tvalid_1's rmse: 0.0866974\n",
      "[2575]\ttraining's rmse: 0.0823095\tvalid_1's rmse: 0.0866971\n",
      "[2600]\ttraining's rmse: 0.082307\tvalid_1's rmse: 0.086697\n",
      "[2625]\ttraining's rmse: 0.0823053\tvalid_1's rmse: 0.0866964\n",
      "[2650]\ttraining's rmse: 0.082302\tvalid_1's rmse: 0.0866949\n",
      "[2675]\ttraining's rmse: 0.0823002\tvalid_1's rmse: 0.0866938\n",
      "[2700]\ttraining's rmse: 0.0822981\tvalid_1's rmse: 0.086693\n",
      "[2725]\ttraining's rmse: 0.0822971\tvalid_1's rmse: 0.0866929\n",
      "[2750]\ttraining's rmse: 0.082295\tvalid_1's rmse: 0.0866926\n",
      "[2775]\ttraining's rmse: 0.0822932\tvalid_1's rmse: 0.0866914\n",
      "[2800]\ttraining's rmse: 0.0822917\tvalid_1's rmse: 0.0866912\n",
      "[2825]\ttraining's rmse: 0.0822899\tvalid_1's rmse: 0.0866916\n",
      "Early stopping, best iteration is:\n",
      "[2791]\ttraining's rmse: 0.0822921\tvalid_1's rmse: 0.0866911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0851385\tvalid_1's rmse: 0.0876132\n",
      "[50]\ttraining's rmse: 0.0850195\tvalid_1's rmse: 0.0875599\n",
      "[75]\ttraining's rmse: 0.0848952\tvalid_1's rmse: 0.087507\n",
      "[100]\ttraining's rmse: 0.0847859\tvalid_1's rmse: 0.0874597\n",
      "[125]\ttraining's rmse: 0.0846711\tvalid_1's rmse: 0.0874133\n",
      "[150]\ttraining's rmse: 0.0845698\tvalid_1's rmse: 0.0873694\n",
      "[175]\ttraining's rmse: 0.0844825\tvalid_1's rmse: 0.0873332\n",
      "[200]\ttraining's rmse: 0.0843879\tvalid_1's rmse: 0.0872961\n",
      "[225]\ttraining's rmse: 0.0842969\tvalid_1's rmse: 0.0872614\n",
      "[250]\ttraining's rmse: 0.0842212\tvalid_1's rmse: 0.0872305\n",
      "[275]\ttraining's rmse: 0.0841492\tvalid_1's rmse: 0.0872023\n",
      "[300]\ttraining's rmse: 0.0840776\tvalid_1's rmse: 0.0871755\n",
      "[325]\ttraining's rmse: 0.0840037\tvalid_1's rmse: 0.087149\n",
      "[350]\ttraining's rmse: 0.0839293\tvalid_1's rmse: 0.0871241\n",
      "[375]\ttraining's rmse: 0.0838722\tvalid_1's rmse: 0.0871035\n",
      "[400]\ttraining's rmse: 0.0838081\tvalid_1's rmse: 0.0870832\n",
      "[425]\ttraining's rmse: 0.0837503\tvalid_1's rmse: 0.0870632\n",
      "[450]\ttraining's rmse: 0.0836969\tvalid_1's rmse: 0.0870443\n",
      "[475]\ttraining's rmse: 0.0836465\tvalid_1's rmse: 0.0870274\n",
      "[500]\ttraining's rmse: 0.0836043\tvalid_1's rmse: 0.087012\n",
      "[525]\ttraining's rmse: 0.083549\tvalid_1's rmse: 0.0869952\n",
      "[550]\ttraining's rmse: 0.0834966\tvalid_1's rmse: 0.08698\n",
      "[575]\ttraining's rmse: 0.0834503\tvalid_1's rmse: 0.086966\n",
      "[600]\ttraining's rmse: 0.0834062\tvalid_1's rmse: 0.0869528\n",
      "[625]\ttraining's rmse: 0.0833721\tvalid_1's rmse: 0.0869405\n",
      "[650]\ttraining's rmse: 0.0833263\tvalid_1's rmse: 0.0869278\n",
      "[675]\ttraining's rmse: 0.0832834\tvalid_1's rmse: 0.0869161\n",
      "[700]\ttraining's rmse: 0.0832437\tvalid_1's rmse: 0.086905\n",
      "[725]\ttraining's rmse: 0.0832086\tvalid_1's rmse: 0.0868956\n",
      "[750]\ttraining's rmse: 0.083175\tvalid_1's rmse: 0.0868871\n",
      "[775]\ttraining's rmse: 0.0831458\tvalid_1's rmse: 0.0868787\n",
      "[800]\ttraining's rmse: 0.0831084\tvalid_1's rmse: 0.0868705\n",
      "[825]\ttraining's rmse: 0.0830775\tvalid_1's rmse: 0.0868618\n",
      "[850]\ttraining's rmse: 0.0830488\tvalid_1's rmse: 0.0868541\n",
      "[875]\ttraining's rmse: 0.0830194\tvalid_1's rmse: 0.0868478\n",
      "[900]\ttraining's rmse: 0.0829902\tvalid_1's rmse: 0.086841\n",
      "[925]\ttraining's rmse: 0.082964\tvalid_1's rmse: 0.0868348\n",
      "[950]\ttraining's rmse: 0.0829394\tvalid_1's rmse: 0.0868292\n",
      "[975]\ttraining's rmse: 0.0829136\tvalid_1's rmse: 0.0868232\n",
      "[1000]\ttraining's rmse: 0.0828931\tvalid_1's rmse: 0.0868181\n",
      "[1025]\ttraining's rmse: 0.0828674\tvalid_1's rmse: 0.0868132\n",
      "[1050]\ttraining's rmse: 0.0828468\tvalid_1's rmse: 0.0868088\n",
      "[1075]\ttraining's rmse: 0.0828243\tvalid_1's rmse: 0.0868051\n",
      "[1100]\ttraining's rmse: 0.0828076\tvalid_1's rmse: 0.0868017\n",
      "[1125]\ttraining's rmse: 0.0827874\tvalid_1's rmse: 0.0867981\n",
      "[1150]\ttraining's rmse: 0.0827687\tvalid_1's rmse: 0.0867946\n",
      "[1175]\ttraining's rmse: 0.0827525\tvalid_1's rmse: 0.0867911\n",
      "[1200]\ttraining's rmse: 0.0827351\tvalid_1's rmse: 0.0867879\n",
      "[1225]\ttraining's rmse: 0.0827194\tvalid_1's rmse: 0.0867844\n",
      "[1250]\ttraining's rmse: 0.0827045\tvalid_1's rmse: 0.086781\n",
      "[1275]\ttraining's rmse: 0.0826874\tvalid_1's rmse: 0.0867792\n",
      "[1300]\ttraining's rmse: 0.0826717\tvalid_1's rmse: 0.0867765\n",
      "[1325]\ttraining's rmse: 0.082658\tvalid_1's rmse: 0.086774\n",
      "[1350]\ttraining's rmse: 0.0826429\tvalid_1's rmse: 0.086772\n",
      "[1375]\ttraining's rmse: 0.0826286\tvalid_1's rmse: 0.0867703\n",
      "[1400]\ttraining's rmse: 0.0826185\tvalid_1's rmse: 0.0867678\n",
      "[1425]\ttraining's rmse: 0.082605\tvalid_1's rmse: 0.0867656\n",
      "[1450]\ttraining's rmse: 0.0825907\tvalid_1's rmse: 0.0867643\n",
      "[1475]\ttraining's rmse: 0.0825802\tvalid_1's rmse: 0.0867621\n",
      "[1500]\ttraining's rmse: 0.0825715\tvalid_1's rmse: 0.0867605\n",
      "[1525]\ttraining's rmse: 0.0825616\tvalid_1's rmse: 0.0867595\n",
      "[1550]\ttraining's rmse: 0.0825515\tvalid_1's rmse: 0.0867585\n",
      "[1575]\ttraining's rmse: 0.0825429\tvalid_1's rmse: 0.086757\n",
      "[1600]\ttraining's rmse: 0.0825369\tvalid_1's rmse: 0.0867566\n",
      "[1625]\ttraining's rmse: 0.0825291\tvalid_1's rmse: 0.0867552\n",
      "[1650]\ttraining's rmse: 0.0825212\tvalid_1's rmse: 0.0867536\n",
      "[1675]\ttraining's rmse: 0.0825148\tvalid_1's rmse: 0.0867527\n",
      "[1700]\ttraining's rmse: 0.082508\tvalid_1's rmse: 0.0867513\n",
      "[1725]\ttraining's rmse: 0.0825003\tvalid_1's rmse: 0.0867507\n",
      "[1750]\ttraining's rmse: 0.0824929\tvalid_1's rmse: 0.0867494\n",
      "[1775]\ttraining's rmse: 0.082488\tvalid_1's rmse: 0.0867489\n",
      "[1800]\ttraining's rmse: 0.0824817\tvalid_1's rmse: 0.0867482\n",
      "[1825]\ttraining's rmse: 0.0824761\tvalid_1's rmse: 0.086747\n",
      "[1850]\ttraining's rmse: 0.0824703\tvalid_1's rmse: 0.086746\n",
      "[1875]\ttraining's rmse: 0.0824642\tvalid_1's rmse: 0.0867452\n",
      "[1900]\ttraining's rmse: 0.0824603\tvalid_1's rmse: 0.0867449\n",
      "[1925]\ttraining's rmse: 0.0824555\tvalid_1's rmse: 0.0867442\n",
      "[1950]\ttraining's rmse: 0.0824523\tvalid_1's rmse: 0.0867436\n",
      "[1975]\ttraining's rmse: 0.0824492\tvalid_1's rmse: 0.0867431\n",
      "[2000]\ttraining's rmse: 0.0824447\tvalid_1's rmse: 0.0867427\n",
      "[2025]\ttraining's rmse: 0.0824405\tvalid_1's rmse: 0.0867422\n",
      "[2050]\ttraining's rmse: 0.0824371\tvalid_1's rmse: 0.0867417\n",
      "[2075]\ttraining's rmse: 0.0824336\tvalid_1's rmse: 0.0867413\n",
      "[2100]\ttraining's rmse: 0.0824301\tvalid_1's rmse: 0.086741\n",
      "[2125]\ttraining's rmse: 0.0824276\tvalid_1's rmse: 0.0867409\n",
      "[2150]\ttraining's rmse: 0.0824241\tvalid_1's rmse: 0.0867407\n",
      "[2175]\ttraining's rmse: 0.0824222\tvalid_1's rmse: 0.0867405\n",
      "[2200]\ttraining's rmse: 0.0824194\tvalid_1's rmse: 0.0867405\n",
      "[2225]\ttraining's rmse: 0.0824163\tvalid_1's rmse: 0.0867404\n",
      "[2250]\ttraining's rmse: 0.0824137\tvalid_1's rmse: 0.0867403\n",
      "[2275]\ttraining's rmse: 0.0824091\tvalid_1's rmse: 0.0867399\n",
      "[2300]\ttraining's rmse: 0.0824056\tvalid_1's rmse: 0.0867395\n",
      "[2325]\ttraining's rmse: 0.0824019\tvalid_1's rmse: 0.0867389\n",
      "[2350]\ttraining's rmse: 0.0823981\tvalid_1's rmse: 0.0867387\n",
      "[2375]\ttraining's rmse: 0.0823944\tvalid_1's rmse: 0.0867385\n",
      "[2400]\ttraining's rmse: 0.0823916\tvalid_1's rmse: 0.0867389\n",
      "[2425]\ttraining's rmse: 0.0823883\tvalid_1's rmse: 0.0867388\n",
      "Early stopping, best iteration is:\n",
      "[2377]\ttraining's rmse: 0.0823943\tvalid_1's rmse: 0.0867385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0875227\tvalid_1's rmse: 0.0827703\n",
      "[50]\ttraining's rmse: 0.0874057\tvalid_1's rmse: 0.0827229\n",
      "[75]\ttraining's rmse: 0.0872865\tvalid_1's rmse: 0.0826741\n",
      "[100]\ttraining's rmse: 0.0871809\tvalid_1's rmse: 0.082632\n",
      "[125]\ttraining's rmse: 0.087071\tvalid_1's rmse: 0.0825905\n",
      "[150]\ttraining's rmse: 0.0869693\tvalid_1's rmse: 0.0825542\n",
      "[175]\ttraining's rmse: 0.0868885\tvalid_1's rmse: 0.0825236\n",
      "[200]\ttraining's rmse: 0.0867982\tvalid_1's rmse: 0.0824927\n",
      "[225]\ttraining's rmse: 0.0867126\tvalid_1's rmse: 0.0824605\n",
      "[250]\ttraining's rmse: 0.0866392\tvalid_1's rmse: 0.0824345\n",
      "[275]\ttraining's rmse: 0.0865727\tvalid_1's rmse: 0.0824108\n",
      "[300]\ttraining's rmse: 0.0865057\tvalid_1's rmse: 0.0823869\n",
      "[325]\ttraining's rmse: 0.0864368\tvalid_1's rmse: 0.0823646\n",
      "[350]\ttraining's rmse: 0.0863689\tvalid_1's rmse: 0.0823429\n",
      "[375]\ttraining's rmse: 0.0863143\tvalid_1's rmse: 0.0823249\n",
      "[400]\ttraining's rmse: 0.086256\tvalid_1's rmse: 0.0823092\n",
      "[425]\ttraining's rmse: 0.0862018\tvalid_1's rmse: 0.0822968\n",
      "[450]\ttraining's rmse: 0.0861518\tvalid_1's rmse: 0.0822816\n",
      "[475]\ttraining's rmse: 0.086105\tvalid_1's rmse: 0.0822675\n",
      "[500]\ttraining's rmse: 0.0860649\tvalid_1's rmse: 0.0822566\n",
      "[525]\ttraining's rmse: 0.0860106\tvalid_1's rmse: 0.0822589\n",
      "[550]\ttraining's rmse: 0.085961\tvalid_1's rmse: 0.0822463\n",
      "[575]\ttraining's rmse: 0.0859143\tvalid_1's rmse: 0.0822416\n",
      "[600]\ttraining's rmse: 0.0858698\tvalid_1's rmse: 0.0822321\n",
      "[625]\ttraining's rmse: 0.0858345\tvalid_1's rmse: 0.0822281\n",
      "[650]\ttraining's rmse: 0.0857895\tvalid_1's rmse: 0.0822272\n",
      "[675]\ttraining's rmse: 0.0857459\tvalid_1's rmse: 0.0822241\n",
      "[700]\ttraining's rmse: 0.0857049\tvalid_1's rmse: 0.0822221\n",
      "[725]\ttraining's rmse: 0.085669\tvalid_1's rmse: 0.082236\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0857161\tvalid_1's rmse: 0.082217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0872307\tvalid_1's rmse: 0.0896491\n",
      "[50]\ttraining's rmse: 0.0870858\tvalid_1's rmse: 0.0895961\n",
      "[75]\ttraining's rmse: 0.0869425\tvalid_1's rmse: 0.0895414\n",
      "[100]\ttraining's rmse: 0.0868085\tvalid_1's rmse: 0.0894957\n",
      "[125]\ttraining's rmse: 0.0866734\tvalid_1's rmse: 0.0894502\n",
      "[150]\ttraining's rmse: 0.0865486\tvalid_1's rmse: 0.0894082\n",
      "[175]\ttraining's rmse: 0.0864467\tvalid_1's rmse: 0.089373\n",
      "[200]\ttraining's rmse: 0.0863387\tvalid_1's rmse: 0.0893361\n",
      "[225]\ttraining's rmse: 0.0862279\tvalid_1's rmse: 0.0893014\n",
      "[250]\ttraining's rmse: 0.0861381\tvalid_1's rmse: 0.0892715\n",
      "[275]\ttraining's rmse: 0.0860562\tvalid_1's rmse: 0.0892432\n",
      "[300]\ttraining's rmse: 0.0859735\tvalid_1's rmse: 0.0892145\n",
      "[325]\ttraining's rmse: 0.08589\tvalid_1's rmse: 0.0891871\n",
      "[350]\ttraining's rmse: 0.085808\tvalid_1's rmse: 0.0891622\n",
      "[375]\ttraining's rmse: 0.0857393\tvalid_1's rmse: 0.0891425\n",
      "[400]\ttraining's rmse: 0.0856668\tvalid_1's rmse: 0.0891217\n",
      "[425]\ttraining's rmse: 0.0855995\tvalid_1's rmse: 0.0890999\n",
      "[450]\ttraining's rmse: 0.08554\tvalid_1's rmse: 0.0890793\n",
      "[475]\ttraining's rmse: 0.0854854\tvalid_1's rmse: 0.089062\n",
      "[500]\ttraining's rmse: 0.085435\tvalid_1's rmse: 0.0890456\n",
      "[525]\ttraining's rmse: 0.0853753\tvalid_1's rmse: 0.0890291\n",
      "[550]\ttraining's rmse: 0.0853245\tvalid_1's rmse: 0.0890135\n",
      "[575]\ttraining's rmse: 0.085275\tvalid_1's rmse: 0.0889996\n",
      "[600]\ttraining's rmse: 0.0852264\tvalid_1's rmse: 0.0889871\n",
      "[625]\ttraining's rmse: 0.0851861\tvalid_1's rmse: 0.0889747\n",
      "[650]\ttraining's rmse: 0.0851407\tvalid_1's rmse: 0.0889626\n",
      "[675]\ttraining's rmse: 0.0850937\tvalid_1's rmse: 0.0889496\n",
      "[700]\ttraining's rmse: 0.085054\tvalid_1's rmse: 0.0889389\n",
      "[725]\ttraining's rmse: 0.0850103\tvalid_1's rmse: 0.0889277\n",
      "[750]\ttraining's rmse: 0.084974\tvalid_1's rmse: 0.0889185\n",
      "[775]\ttraining's rmse: 0.084944\tvalid_1's rmse: 0.0889087\n",
      "[800]\ttraining's rmse: 0.0849057\tvalid_1's rmse: 0.0889002\n",
      "[825]\ttraining's rmse: 0.0848732\tvalid_1's rmse: 0.0888918\n",
      "[850]\ttraining's rmse: 0.0848395\tvalid_1's rmse: 0.0888841\n",
      "[875]\ttraining's rmse: 0.0848125\tvalid_1's rmse: 0.0888759\n",
      "[900]\ttraining's rmse: 0.0847836\tvalid_1's rmse: 0.0888695\n",
      "[925]\ttraining's rmse: 0.0847559\tvalid_1's rmse: 0.0888621\n",
      "[950]\ttraining's rmse: 0.0847291\tvalid_1's rmse: 0.088854\n",
      "[975]\ttraining's rmse: 0.0847033\tvalid_1's rmse: 0.0888488\n",
      "[1000]\ttraining's rmse: 0.084678\tvalid_1's rmse: 0.0888429\n",
      "[1025]\ttraining's rmse: 0.0846498\tvalid_1's rmse: 0.0888371\n",
      "[1050]\ttraining's rmse: 0.0846254\tvalid_1's rmse: 0.0888308\n",
      "[1075]\ttraining's rmse: 0.0846007\tvalid_1's rmse: 0.0888267\n",
      "[1100]\ttraining's rmse: 0.0845822\tvalid_1's rmse: 0.0888219\n",
      "[1125]\ttraining's rmse: 0.0845623\tvalid_1's rmse: 0.0888163\n",
      "[1150]\ttraining's rmse: 0.0845427\tvalid_1's rmse: 0.0888111\n",
      "[1175]\ttraining's rmse: 0.0845228\tvalid_1's rmse: 0.0888073\n",
      "[1200]\ttraining's rmse: 0.084507\tvalid_1's rmse: 0.0888026\n",
      "[1225]\ttraining's rmse: 0.0844902\tvalid_1's rmse: 0.0887986\n",
      "[1250]\ttraining's rmse: 0.0844729\tvalid_1's rmse: 0.0887946\n",
      "[1275]\ttraining's rmse: 0.0844526\tvalid_1's rmse: 0.0887908\n",
      "[1300]\ttraining's rmse: 0.0844384\tvalid_1's rmse: 0.0887871\n",
      "[1325]\ttraining's rmse: 0.0844225\tvalid_1's rmse: 0.0887828\n",
      "[1350]\ttraining's rmse: 0.0844075\tvalid_1's rmse: 0.0887791\n",
      "[1375]\ttraining's rmse: 0.0843916\tvalid_1's rmse: 0.0887754\n",
      "[1400]\ttraining's rmse: 0.0843801\tvalid_1's rmse: 0.0887709\n",
      "[1425]\ttraining's rmse: 0.084365\tvalid_1's rmse: 0.0887675\n",
      "[1450]\ttraining's rmse: 0.084348\tvalid_1's rmse: 0.088764\n",
      "[1475]\ttraining's rmse: 0.0843362\tvalid_1's rmse: 0.0887615\n",
      "[1500]\ttraining's rmse: 0.0843244\tvalid_1's rmse: 0.0887578\n",
      "[1525]\ttraining's rmse: 0.0843129\tvalid_1's rmse: 0.0887557\n",
      "[1550]\ttraining's rmse: 0.0842988\tvalid_1's rmse: 0.0887535\n",
      "[1575]\ttraining's rmse: 0.0842907\tvalid_1's rmse: 0.0887517\n",
      "[1600]\ttraining's rmse: 0.0842827\tvalid_1's rmse: 0.0887485\n",
      "[1625]\ttraining's rmse: 0.0842728\tvalid_1's rmse: 0.0887456\n",
      "[1650]\ttraining's rmse: 0.0842642\tvalid_1's rmse: 0.0887432\n",
      "[1675]\ttraining's rmse: 0.0842565\tvalid_1's rmse: 0.0887403\n",
      "[1700]\ttraining's rmse: 0.0842498\tvalid_1's rmse: 0.0887379\n",
      "[1725]\ttraining's rmse: 0.0842414\tvalid_1's rmse: 0.0887359\n",
      "[1750]\ttraining's rmse: 0.0842332\tvalid_1's rmse: 0.0887339\n",
      "[1775]\ttraining's rmse: 0.0842278\tvalid_1's rmse: 0.0887316\n",
      "[1800]\ttraining's rmse: 0.0842222\tvalid_1's rmse: 0.0887295\n",
      "[1825]\ttraining's rmse: 0.0842156\tvalid_1's rmse: 0.0887284\n",
      "[1850]\ttraining's rmse: 0.0842091\tvalid_1's rmse: 0.0887261\n",
      "[1875]\ttraining's rmse: 0.0842033\tvalid_1's rmse: 0.0887241\n",
      "[1900]\ttraining's rmse: 0.0841987\tvalid_1's rmse: 0.0887231\n",
      "[1925]\ttraining's rmse: 0.0841937\tvalid_1's rmse: 0.0887225\n",
      "[1950]\ttraining's rmse: 0.0841884\tvalid_1's rmse: 0.0887206\n",
      "[1975]\ttraining's rmse: 0.0841841\tvalid_1's rmse: 0.0887195\n",
      "[2000]\ttraining's rmse: 0.0841783\tvalid_1's rmse: 0.0887174\n",
      "[2025]\ttraining's rmse: 0.0841749\tvalid_1's rmse: 0.0887166\n",
      "[2050]\ttraining's rmse: 0.084172\tvalid_1's rmse: 0.0887159\n",
      "[2075]\ttraining's rmse: 0.0841681\tvalid_1's rmse: 0.0887125\n",
      "[2100]\ttraining's rmse: 0.0841649\tvalid_1's rmse: 0.088711\n",
      "[2125]\ttraining's rmse: 0.0841619\tvalid_1's rmse: 0.0887102\n",
      "[2150]\ttraining's rmse: 0.0841594\tvalid_1's rmse: 0.0887096\n",
      "[2175]\ttraining's rmse: 0.0841555\tvalid_1's rmse: 0.0887078\n",
      "[2200]\ttraining's rmse: 0.0841521\tvalid_1's rmse: 0.0887071\n",
      "[2225]\ttraining's rmse: 0.0841487\tvalid_1's rmse: 0.0887059\n",
      "[2250]\ttraining's rmse: 0.0841463\tvalid_1's rmse: 0.088705\n",
      "[2275]\ttraining's rmse: 0.0841432\tvalid_1's rmse: 0.0887043\n",
      "[2300]\ttraining's rmse: 0.0841404\tvalid_1's rmse: 0.0887037\n",
      "[2325]\ttraining's rmse: 0.0841365\tvalid_1's rmse: 0.0887022\n",
      "[2350]\ttraining's rmse: 0.0841335\tvalid_1's rmse: 0.088701\n",
      "[2375]\ttraining's rmse: 0.0841301\tvalid_1's rmse: 0.0886996\n",
      "[2400]\ttraining's rmse: 0.0841278\tvalid_1's rmse: 0.0886995\n",
      "[2425]\ttraining's rmse: 0.0841246\tvalid_1's rmse: 0.0886989\n",
      "[2450]\ttraining's rmse: 0.0841219\tvalid_1's rmse: 0.0886981\n",
      "[2475]\ttraining's rmse: 0.084119\tvalid_1's rmse: 0.0886973\n",
      "[2500]\ttraining's rmse: 0.0841165\tvalid_1's rmse: 0.0886973\n",
      "[2525]\ttraining's rmse: 0.0841136\tvalid_1's rmse: 0.0886971\n",
      "[2550]\ttraining's rmse: 0.0841113\tvalid_1's rmse: 0.0886964\n",
      "[2575]\ttraining's rmse: 0.0841086\tvalid_1's rmse: 0.0886959\n",
      "[2600]\ttraining's rmse: 0.0841062\tvalid_1's rmse: 0.0886956\n",
      "[2625]\ttraining's rmse: 0.0841051\tvalid_1's rmse: 0.088695\n",
      "[2650]\ttraining's rmse: 0.0841032\tvalid_1's rmse: 0.0886947\n",
      "[2675]\ttraining's rmse: 0.0841019\tvalid_1's rmse: 0.0886946\n",
      "[2700]\ttraining's rmse: 0.0841001\tvalid_1's rmse: 0.0886933\n",
      "[2725]\ttraining's rmse: 0.084098\tvalid_1's rmse: 0.0886934\n",
      "[2750]\ttraining's rmse: 0.0840965\tvalid_1's rmse: 0.0886921\n",
      "[2775]\ttraining's rmse: 0.0840942\tvalid_1's rmse: 0.0886916\n",
      "[2800]\ttraining's rmse: 0.0840935\tvalid_1's rmse: 0.0886916\n",
      "Early stopping, best iteration is:\n",
      "[2768]\ttraining's rmse: 0.0840949\tvalid_1's rmse: 0.0886915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0871956\tvalid_1's rmse: 0.0897457\n",
      "[50]\ttraining's rmse: 0.087069\tvalid_1's rmse: 0.0896924\n",
      "[75]\ttraining's rmse: 0.0869387\tvalid_1's rmse: 0.0896371\n",
      "[100]\ttraining's rmse: 0.0868215\tvalid_1's rmse: 0.089588\n",
      "[125]\ttraining's rmse: 0.0866989\tvalid_1's rmse: 0.0895406\n",
      "[150]\ttraining's rmse: 0.0865851\tvalid_1's rmse: 0.0894951\n",
      "[175]\ttraining's rmse: 0.0864902\tvalid_1's rmse: 0.0894569\n",
      "[200]\ttraining's rmse: 0.0863875\tvalid_1's rmse: 0.0894182\n",
      "[225]\ttraining's rmse: 0.0862891\tvalid_1's rmse: 0.0893826\n",
      "[250]\ttraining's rmse: 0.0862074\tvalid_1's rmse: 0.0893518\n",
      "[275]\ttraining's rmse: 0.0861312\tvalid_1's rmse: 0.089324\n",
      "[300]\ttraining's rmse: 0.0860558\tvalid_1's rmse: 0.0892965\n",
      "[325]\ttraining's rmse: 0.0859766\tvalid_1's rmse: 0.0892688\n",
      "[350]\ttraining's rmse: 0.0859011\tvalid_1's rmse: 0.0892437\n",
      "[375]\ttraining's rmse: 0.0858406\tvalid_1's rmse: 0.0892223\n",
      "[400]\ttraining's rmse: 0.0857717\tvalid_1's rmse: 0.089202\n",
      "[425]\ttraining's rmse: 0.0857138\tvalid_1's rmse: 0.0891826\n",
      "[450]\ttraining's rmse: 0.0856587\tvalid_1's rmse: 0.0891645\n",
      "[475]\ttraining's rmse: 0.0856061\tvalid_1's rmse: 0.0891471\n",
      "[500]\ttraining's rmse: 0.0855607\tvalid_1's rmse: 0.0891311\n",
      "[525]\ttraining's rmse: 0.0855017\tvalid_1's rmse: 0.0891138\n",
      "[550]\ttraining's rmse: 0.0854496\tvalid_1's rmse: 0.0890996\n",
      "[575]\ttraining's rmse: 0.0854\tvalid_1's rmse: 0.0890857\n",
      "[600]\ttraining's rmse: 0.0853531\tvalid_1's rmse: 0.0890716\n",
      "[625]\ttraining's rmse: 0.085317\tvalid_1's rmse: 0.0890602\n",
      "[650]\ttraining's rmse: 0.0852696\tvalid_1's rmse: 0.0890474\n",
      "[675]\ttraining's rmse: 0.0852249\tvalid_1's rmse: 0.089036\n",
      "[700]\ttraining's rmse: 0.085184\tvalid_1's rmse: 0.0890248\n",
      "[725]\ttraining's rmse: 0.0851452\tvalid_1's rmse: 0.0890148\n",
      "[750]\ttraining's rmse: 0.0851095\tvalid_1's rmse: 0.0890053\n",
      "[775]\ttraining's rmse: 0.085081\tvalid_1's rmse: 0.0889965\n",
      "[800]\ttraining's rmse: 0.0850415\tvalid_1's rmse: 0.0889881\n",
      "[825]\ttraining's rmse: 0.0850102\tvalid_1's rmse: 0.08898\n",
      "[850]\ttraining's rmse: 0.0849782\tvalid_1's rmse: 0.088974\n",
      "[875]\ttraining's rmse: 0.0849487\tvalid_1's rmse: 0.0889678\n",
      "[900]\ttraining's rmse: 0.0849161\tvalid_1's rmse: 0.0889609\n",
      "[925]\ttraining's rmse: 0.084888\tvalid_1's rmse: 0.088955\n",
      "[950]\ttraining's rmse: 0.0848617\tvalid_1's rmse: 0.0889496\n",
      "[975]\ttraining's rmse: 0.0848347\tvalid_1's rmse: 0.088944\n",
      "[1000]\ttraining's rmse: 0.0848127\tvalid_1's rmse: 0.0889389\n",
      "[1025]\ttraining's rmse: 0.0847881\tvalid_1's rmse: 0.0889341\n",
      "[1050]\ttraining's rmse: 0.0847657\tvalid_1's rmse: 0.0889293\n",
      "[1075]\ttraining's rmse: 0.0847427\tvalid_1's rmse: 0.0889268\n",
      "[1100]\ttraining's rmse: 0.0847253\tvalid_1's rmse: 0.0889227\n",
      "[1125]\ttraining's rmse: 0.0847041\tvalid_1's rmse: 0.0889185\n",
      "[1150]\ttraining's rmse: 0.0846825\tvalid_1's rmse: 0.0889157\n",
      "[1175]\ttraining's rmse: 0.0846624\tvalid_1's rmse: 0.0889129\n",
      "[1200]\ttraining's rmse: 0.0846449\tvalid_1's rmse: 0.0889097\n",
      "[1225]\ttraining's rmse: 0.0846278\tvalid_1's rmse: 0.0889074\n",
      "[1250]\ttraining's rmse: 0.0846125\tvalid_1's rmse: 0.0889044\n",
      "[1275]\ttraining's rmse: 0.0845937\tvalid_1's rmse: 0.088903\n",
      "[1300]\ttraining's rmse: 0.0845797\tvalid_1's rmse: 0.0889009\n",
      "[1325]\ttraining's rmse: 0.0845645\tvalid_1's rmse: 0.0888989\n",
      "[1350]\ttraining's rmse: 0.084547\tvalid_1's rmse: 0.0888969\n",
      "[1375]\ttraining's rmse: 0.0845316\tvalid_1's rmse: 0.0888958\n",
      "[1400]\ttraining's rmse: 0.0845192\tvalid_1's rmse: 0.088894\n",
      "[1425]\ttraining's rmse: 0.0845045\tvalid_1's rmse: 0.088893\n",
      "[1450]\ttraining's rmse: 0.0844915\tvalid_1's rmse: 0.0888921\n",
      "[1475]\ttraining's rmse: 0.0844799\tvalid_1's rmse: 0.0888904\n",
      "[1500]\ttraining's rmse: 0.0844699\tvalid_1's rmse: 0.088889\n",
      "[1525]\ttraining's rmse: 0.0844583\tvalid_1's rmse: 0.0888884\n",
      "[1550]\ttraining's rmse: 0.0844486\tvalid_1's rmse: 0.0888877\n",
      "[1575]\ttraining's rmse: 0.0844409\tvalid_1's rmse: 0.0888868\n",
      "[1600]\ttraining's rmse: 0.0844324\tvalid_1's rmse: 0.0888868\n",
      "[1625]\ttraining's rmse: 0.0844224\tvalid_1's rmse: 0.0888856\n",
      "[1650]\ttraining's rmse: 0.0844142\tvalid_1's rmse: 0.088885\n",
      "[1675]\ttraining's rmse: 0.0844081\tvalid_1's rmse: 0.0888837\n",
      "[1700]\ttraining's rmse: 0.0844015\tvalid_1's rmse: 0.088882\n",
      "[1725]\ttraining's rmse: 0.0843931\tvalid_1's rmse: 0.0888811\n",
      "[1750]\ttraining's rmse: 0.0843835\tvalid_1's rmse: 0.0888805\n",
      "[1775]\ttraining's rmse: 0.0843747\tvalid_1's rmse: 0.0888795\n",
      "[1800]\ttraining's rmse: 0.0843695\tvalid_1's rmse: 0.0888786\n",
      "[1825]\ttraining's rmse: 0.0843628\tvalid_1's rmse: 0.0888777\n",
      "[1850]\ttraining's rmse: 0.084356\tvalid_1's rmse: 0.0888769\n",
      "[1875]\ttraining's rmse: 0.0843493\tvalid_1's rmse: 0.0888761\n",
      "[1900]\ttraining's rmse: 0.0843453\tvalid_1's rmse: 0.0888758\n",
      "[1925]\ttraining's rmse: 0.0843405\tvalid_1's rmse: 0.0888758\n",
      "[1950]\ttraining's rmse: 0.0843353\tvalid_1's rmse: 0.0888749\n",
      "[1975]\ttraining's rmse: 0.0843313\tvalid_1's rmse: 0.088874\n",
      "[2000]\ttraining's rmse: 0.0843261\tvalid_1's rmse: 0.0888738\n",
      "[2025]\ttraining's rmse: 0.0843223\tvalid_1's rmse: 0.0888733\n",
      "[2050]\ttraining's rmse: 0.0843176\tvalid_1's rmse: 0.088873\n",
      "[2075]\ttraining's rmse: 0.084314\tvalid_1's rmse: 0.0888728\n",
      "[2100]\ttraining's rmse: 0.0843098\tvalid_1's rmse: 0.0888725\n",
      "[2125]\ttraining's rmse: 0.0843059\tvalid_1's rmse: 0.0888721\n",
      "[2150]\ttraining's rmse: 0.0843016\tvalid_1's rmse: 0.0888719\n",
      "[2175]\ttraining's rmse: 0.0842984\tvalid_1's rmse: 0.0888718\n",
      "[2200]\ttraining's rmse: 0.0842953\tvalid_1's rmse: 0.0888716\n",
      "[2225]\ttraining's rmse: 0.084292\tvalid_1's rmse: 0.0888712\n",
      "[2250]\ttraining's rmse: 0.084288\tvalid_1's rmse: 0.0888713\n",
      "[2275]\ttraining's rmse: 0.0842845\tvalid_1's rmse: 0.0888711\n",
      "[2300]\ttraining's rmse: 0.0842815\tvalid_1's rmse: 0.0888708\n",
      "[2325]\ttraining's rmse: 0.0842779\tvalid_1's rmse: 0.0888708\n",
      "[2350]\ttraining's rmse: 0.0842751\tvalid_1's rmse: 0.0888706\n",
      "[2375]\ttraining's rmse: 0.0842718\tvalid_1's rmse: 0.0888705\n",
      "[2400]\ttraining's rmse: 0.0842684\tvalid_1's rmse: 0.0888705\n",
      "[2425]\ttraining's rmse: 0.0842659\tvalid_1's rmse: 0.0888706\n",
      "Early stopping, best iteration is:\n",
      "[2384]\ttraining's rmse: 0.0842703\tvalid_1's rmse: 0.0888703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0895622\tvalid_1's rmse: 0.0849336\n",
      "[50]\ttraining's rmse: 0.0894398\tvalid_1's rmse: 0.0848861\n",
      "[75]\ttraining's rmse: 0.0893118\tvalid_1's rmse: 0.0848372\n",
      "[100]\ttraining's rmse: 0.0891954\tvalid_1's rmse: 0.0847953\n",
      "[125]\ttraining's rmse: 0.0890754\tvalid_1's rmse: 0.0847501\n",
      "[150]\ttraining's rmse: 0.0889668\tvalid_1's rmse: 0.0847118\n",
      "[175]\ttraining's rmse: 0.0888728\tvalid_1's rmse: 0.0846828\n",
      "[200]\ttraining's rmse: 0.088771\tvalid_1's rmse: 0.084649\n",
      "[225]\ttraining's rmse: 0.0886733\tvalid_1's rmse: 0.0846192\n",
      "[250]\ttraining's rmse: 0.0885899\tvalid_1's rmse: 0.0845917\n",
      "[275]\ttraining's rmse: 0.0885169\tvalid_1's rmse: 0.0845665\n",
      "[300]\ttraining's rmse: 0.0884448\tvalid_1's rmse: 0.0845446\n",
      "[325]\ttraining's rmse: 0.0883681\tvalid_1's rmse: 0.084522\n",
      "[350]\ttraining's rmse: 0.0882962\tvalid_1's rmse: 0.0845008\n",
      "[375]\ttraining's rmse: 0.0882378\tvalid_1's rmse: 0.0844851\n",
      "[400]\ttraining's rmse: 0.0881724\tvalid_1's rmse: 0.0844722\n",
      "[425]\ttraining's rmse: 0.0881115\tvalid_1's rmse: 0.0844562\n",
      "[450]\ttraining's rmse: 0.0880561\tvalid_1's rmse: 0.0844431\n",
      "[475]\ttraining's rmse: 0.0880028\tvalid_1's rmse: 0.0844295\n",
      "[500]\ttraining's rmse: 0.0879601\tvalid_1's rmse: 0.0844165\n",
      "[525]\ttraining's rmse: 0.0879017\tvalid_1's rmse: 0.0844019\n",
      "[550]\ttraining's rmse: 0.0878484\tvalid_1's rmse: 0.0843885\n",
      "[575]\ttraining's rmse: 0.0877992\tvalid_1's rmse: 0.0843778\n",
      "[600]\ttraining's rmse: 0.0877506\tvalid_1's rmse: 0.0843753\n",
      "[625]\ttraining's rmse: 0.0877115\tvalid_1's rmse: 0.0843708\n",
      "[650]\ttraining's rmse: 0.0876642\tvalid_1's rmse: 0.0843646\n",
      "[675]\ttraining's rmse: 0.087615\tvalid_1's rmse: 0.0843567\n",
      "[700]\ttraining's rmse: 0.0875728\tvalid_1's rmse: 0.0843473\n",
      "[725]\ttraining's rmse: 0.0875338\tvalid_1's rmse: 0.0843452\n",
      "[750]\ttraining's rmse: 0.0874951\tvalid_1's rmse: 0.0843572\n",
      "[775]\ttraining's rmse: 0.0874642\tvalid_1's rmse: 0.0843582\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.087517\tvalid_1's rmse: 0.0843423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0855276\tvalid_1's rmse: 0.088288\n",
      "[50]\ttraining's rmse: 0.0853975\tvalid_1's rmse: 0.0882325\n",
      "[75]\ttraining's rmse: 0.085268\tvalid_1's rmse: 0.0881792\n",
      "[100]\ttraining's rmse: 0.0851474\tvalid_1's rmse: 0.0881322\n",
      "[125]\ttraining's rmse: 0.0850285\tvalid_1's rmse: 0.0880864\n",
      "[150]\ttraining's rmse: 0.084915\tvalid_1's rmse: 0.0880428\n",
      "[175]\ttraining's rmse: 0.0848255\tvalid_1's rmse: 0.0880056\n",
      "[200]\ttraining's rmse: 0.0847283\tvalid_1's rmse: 0.0879691\n",
      "[225]\ttraining's rmse: 0.0846337\tvalid_1's rmse: 0.0879327\n",
      "[250]\ttraining's rmse: 0.0845532\tvalid_1's rmse: 0.087898\n",
      "[275]\ttraining's rmse: 0.0844776\tvalid_1's rmse: 0.0878679\n",
      "[300]\ttraining's rmse: 0.0844032\tvalid_1's rmse: 0.0878394\n",
      "[325]\ttraining's rmse: 0.084328\tvalid_1's rmse: 0.0878143\n",
      "[350]\ttraining's rmse: 0.0842589\tvalid_1's rmse: 0.0877891\n",
      "[375]\ttraining's rmse: 0.0841976\tvalid_1's rmse: 0.087768\n",
      "[400]\ttraining's rmse: 0.084134\tvalid_1's rmse: 0.0877443\n",
      "[425]\ttraining's rmse: 0.0840763\tvalid_1's rmse: 0.0877238\n",
      "[450]\ttraining's rmse: 0.0840248\tvalid_1's rmse: 0.0877037\n",
      "[475]\ttraining's rmse: 0.0839766\tvalid_1's rmse: 0.0876836\n",
      "[500]\ttraining's rmse: 0.083935\tvalid_1's rmse: 0.0876667\n",
      "[525]\ttraining's rmse: 0.083882\tvalid_1's rmse: 0.087649\n",
      "[550]\ttraining's rmse: 0.0838335\tvalid_1's rmse: 0.0876348\n",
      "[575]\ttraining's rmse: 0.0837892\tvalid_1's rmse: 0.0876209\n",
      "[600]\ttraining's rmse: 0.0837453\tvalid_1's rmse: 0.0876059\n",
      "[625]\ttraining's rmse: 0.0837108\tvalid_1's rmse: 0.0875939\n",
      "[650]\ttraining's rmse: 0.0836672\tvalid_1's rmse: 0.0875815\n",
      "[675]\ttraining's rmse: 0.0836267\tvalid_1's rmse: 0.0875691\n",
      "[700]\ttraining's rmse: 0.0835892\tvalid_1's rmse: 0.0875576\n",
      "[725]\ttraining's rmse: 0.0835552\tvalid_1's rmse: 0.0875477\n",
      "[750]\ttraining's rmse: 0.083521\tvalid_1's rmse: 0.0875373\n",
      "[775]\ttraining's rmse: 0.0834939\tvalid_1's rmse: 0.087525\n",
      "[800]\ttraining's rmse: 0.0834608\tvalid_1's rmse: 0.0875151\n",
      "[825]\ttraining's rmse: 0.0834321\tvalid_1's rmse: 0.0875064\n",
      "[850]\ttraining's rmse: 0.0833977\tvalid_1's rmse: 0.0874979\n",
      "[875]\ttraining's rmse: 0.0833716\tvalid_1's rmse: 0.0874899\n",
      "[900]\ttraining's rmse: 0.0833402\tvalid_1's rmse: 0.087482\n",
      "[925]\ttraining's rmse: 0.0833144\tvalid_1's rmse: 0.0874743\n",
      "[950]\ttraining's rmse: 0.0832897\tvalid_1's rmse: 0.0874677\n",
      "[975]\ttraining's rmse: 0.0832678\tvalid_1's rmse: 0.0874609\n",
      "[1000]\ttraining's rmse: 0.0832433\tvalid_1's rmse: 0.0874538\n",
      "[1025]\ttraining's rmse: 0.0832201\tvalid_1's rmse: 0.0874474\n",
      "[1050]\ttraining's rmse: 0.083199\tvalid_1's rmse: 0.0874406\n",
      "[1075]\ttraining's rmse: 0.0831764\tvalid_1's rmse: 0.0874359\n",
      "[1100]\ttraining's rmse: 0.0831591\tvalid_1's rmse: 0.0874306\n",
      "[1125]\ttraining's rmse: 0.083143\tvalid_1's rmse: 0.0874257\n",
      "[1150]\ttraining's rmse: 0.0831243\tvalid_1's rmse: 0.0874206\n",
      "[1175]\ttraining's rmse: 0.0831065\tvalid_1's rmse: 0.0874159\n",
      "[1200]\ttraining's rmse: 0.0830894\tvalid_1's rmse: 0.087411\n",
      "[1225]\ttraining's rmse: 0.0830723\tvalid_1's rmse: 0.0874065\n",
      "[1250]\ttraining's rmse: 0.0830546\tvalid_1's rmse: 0.0874019\n",
      "[1275]\ttraining's rmse: 0.0830375\tvalid_1's rmse: 0.0873983\n",
      "[1300]\ttraining's rmse: 0.0830256\tvalid_1's rmse: 0.0873942\n",
      "[1325]\ttraining's rmse: 0.0830111\tvalid_1's rmse: 0.08739\n",
      "[1350]\ttraining's rmse: 0.0829968\tvalid_1's rmse: 0.0873865\n",
      "[1375]\ttraining's rmse: 0.0829811\tvalid_1's rmse: 0.0873819\n",
      "[1400]\ttraining's rmse: 0.0829709\tvalid_1's rmse: 0.0873785\n",
      "[1425]\ttraining's rmse: 0.0829572\tvalid_1's rmse: 0.0873748\n",
      "[1450]\ttraining's rmse: 0.0829456\tvalid_1's rmse: 0.087373\n",
      "[1475]\ttraining's rmse: 0.082935\tvalid_1's rmse: 0.0873695\n",
      "[1500]\ttraining's rmse: 0.0829262\tvalid_1's rmse: 0.0873664\n",
      "[1525]\ttraining's rmse: 0.0829176\tvalid_1's rmse: 0.0873642\n",
      "[1550]\ttraining's rmse: 0.0829091\tvalid_1's rmse: 0.0873614\n",
      "[1575]\ttraining's rmse: 0.0829009\tvalid_1's rmse: 0.087359\n",
      "[1600]\ttraining's rmse: 0.0828919\tvalid_1's rmse: 0.0873555\n",
      "[1625]\ttraining's rmse: 0.0828848\tvalid_1's rmse: 0.0873534\n",
      "[1650]\ttraining's rmse: 0.0828778\tvalid_1's rmse: 0.0873509\n",
      "[1675]\ttraining's rmse: 0.0828714\tvalid_1's rmse: 0.08735\n",
      "[1700]\ttraining's rmse: 0.0828633\tvalid_1's rmse: 0.0873473\n",
      "[1725]\ttraining's rmse: 0.0828574\tvalid_1's rmse: 0.0873455\n",
      "[1750]\ttraining's rmse: 0.0828498\tvalid_1's rmse: 0.0873433\n",
      "[1775]\ttraining's rmse: 0.0828444\tvalid_1's rmse: 0.087342\n",
      "[1800]\ttraining's rmse: 0.0828384\tvalid_1's rmse: 0.0873407\n",
      "[1825]\ttraining's rmse: 0.0828315\tvalid_1's rmse: 0.0873397\n",
      "[1850]\ttraining's rmse: 0.0828255\tvalid_1's rmse: 0.0873375\n",
      "[1875]\ttraining's rmse: 0.0828196\tvalid_1's rmse: 0.0873359\n",
      "[1900]\ttraining's rmse: 0.0828152\tvalid_1's rmse: 0.0873351\n",
      "[1925]\ttraining's rmse: 0.0828101\tvalid_1's rmse: 0.0873342\n",
      "[1950]\ttraining's rmse: 0.0828071\tvalid_1's rmse: 0.087333\n",
      "[1975]\ttraining's rmse: 0.0828038\tvalid_1's rmse: 0.087332\n",
      "[2000]\ttraining's rmse: 0.0828005\tvalid_1's rmse: 0.087331\n",
      "[2025]\ttraining's rmse: 0.082796\tvalid_1's rmse: 0.0873296\n",
      "[2050]\ttraining's rmse: 0.0827912\tvalid_1's rmse: 0.0873276\n",
      "[2075]\ttraining's rmse: 0.0827857\tvalid_1's rmse: 0.0873269\n",
      "[2100]\ttraining's rmse: 0.082782\tvalid_1's rmse: 0.0873257\n",
      "[2125]\ttraining's rmse: 0.082779\tvalid_1's rmse: 0.0873241\n",
      "[2150]\ttraining's rmse: 0.0827753\tvalid_1's rmse: 0.0873241\n",
      "[2175]\ttraining's rmse: 0.082771\tvalid_1's rmse: 0.0873224\n",
      "[2200]\ttraining's rmse: 0.0827666\tvalid_1's rmse: 0.0873215\n",
      "[2225]\ttraining's rmse: 0.082763\tvalid_1's rmse: 0.0873197\n",
      "[2250]\ttraining's rmse: 0.0827601\tvalid_1's rmse: 0.0873192\n",
      "[2275]\ttraining's rmse: 0.0827567\tvalid_1's rmse: 0.087318\n",
      "[2300]\ttraining's rmse: 0.082754\tvalid_1's rmse: 0.0873174\n",
      "[2325]\ttraining's rmse: 0.0827501\tvalid_1's rmse: 0.0873169\n",
      "[2350]\ttraining's rmse: 0.0827478\tvalid_1's rmse: 0.0873166\n",
      "[2375]\ttraining's rmse: 0.0827455\tvalid_1's rmse: 0.0873167\n",
      "[2400]\ttraining's rmse: 0.0827437\tvalid_1's rmse: 0.0873163\n",
      "[2425]\ttraining's rmse: 0.0827402\tvalid_1's rmse: 0.0873161\n",
      "[2450]\ttraining's rmse: 0.0827387\tvalid_1's rmse: 0.0873153\n",
      "[2475]\ttraining's rmse: 0.0827364\tvalid_1's rmse: 0.0873155\n",
      "[2500]\ttraining's rmse: 0.0827346\tvalid_1's rmse: 0.0873146\n",
      "[2525]\ttraining's rmse: 0.0827329\tvalid_1's rmse: 0.0873142\n",
      "[2550]\ttraining's rmse: 0.0827311\tvalid_1's rmse: 0.0873143\n",
      "[2575]\ttraining's rmse: 0.0827291\tvalid_1's rmse: 0.0873138\n",
      "[2600]\ttraining's rmse: 0.0827267\tvalid_1's rmse: 0.0873138\n",
      "[2625]\ttraining's rmse: 0.0827247\tvalid_1's rmse: 0.0873129\n",
      "[2650]\ttraining's rmse: 0.0827238\tvalid_1's rmse: 0.087312\n",
      "[2675]\ttraining's rmse: 0.0827227\tvalid_1's rmse: 0.0873113\n",
      "[2700]\ttraining's rmse: 0.0827202\tvalid_1's rmse: 0.0873104\n",
      "[2725]\ttraining's rmse: 0.0827176\tvalid_1's rmse: 0.0873094\n",
      "[2750]\ttraining's rmse: 0.0827153\tvalid_1's rmse: 0.0873091\n",
      "[2775]\ttraining's rmse: 0.0827118\tvalid_1's rmse: 0.0873089\n",
      "[2800]\ttraining's rmse: 0.0827096\tvalid_1's rmse: 0.0873088\n",
      "[2825]\ttraining's rmse: 0.0827081\tvalid_1's rmse: 0.0873088\n",
      "[2850]\ttraining's rmse: 0.0827066\tvalid_1's rmse: 0.0873092\n",
      "Early stopping, best iteration is:\n",
      "[2803]\ttraining's rmse: 0.0827092\tvalid_1's rmse: 0.0873085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0856501\tvalid_1's rmse: 0.0880404\n",
      "[50]\ttraining's rmse: 0.0855293\tvalid_1's rmse: 0.0879864\n",
      "[75]\ttraining's rmse: 0.0854078\tvalid_1's rmse: 0.0879343\n",
      "[100]\ttraining's rmse: 0.0852965\tvalid_1's rmse: 0.0878854\n",
      "[125]\ttraining's rmse: 0.0851769\tvalid_1's rmse: 0.0878369\n",
      "[150]\ttraining's rmse: 0.0850684\tvalid_1's rmse: 0.0877917\n",
      "[175]\ttraining's rmse: 0.0849842\tvalid_1's rmse: 0.087756\n",
      "[200]\ttraining's rmse: 0.0848888\tvalid_1's rmse: 0.0877192\n",
      "[225]\ttraining's rmse: 0.0847971\tvalid_1's rmse: 0.0876841\n",
      "[250]\ttraining's rmse: 0.0847169\tvalid_1's rmse: 0.0876524\n",
      "[275]\ttraining's rmse: 0.0846445\tvalid_1's rmse: 0.0876239\n",
      "[300]\ttraining's rmse: 0.0845711\tvalid_1's rmse: 0.0875968\n",
      "[325]\ttraining's rmse: 0.0844995\tvalid_1's rmse: 0.0875709\n",
      "[350]\ttraining's rmse: 0.0844263\tvalid_1's rmse: 0.0875465\n",
      "[375]\ttraining's rmse: 0.0843669\tvalid_1's rmse: 0.0875254\n",
      "[400]\ttraining's rmse: 0.0843027\tvalid_1's rmse: 0.0875051\n",
      "[425]\ttraining's rmse: 0.0842439\tvalid_1's rmse: 0.0874853\n",
      "[450]\ttraining's rmse: 0.0841901\tvalid_1's rmse: 0.0874676\n",
      "[475]\ttraining's rmse: 0.0841398\tvalid_1's rmse: 0.0874512\n",
      "[500]\ttraining's rmse: 0.0840974\tvalid_1's rmse: 0.0874357\n",
      "[525]\ttraining's rmse: 0.0840427\tvalid_1's rmse: 0.0874196\n",
      "[550]\ttraining's rmse: 0.0839905\tvalid_1's rmse: 0.0874046\n",
      "[575]\ttraining's rmse: 0.0839432\tvalid_1's rmse: 0.0873912\n",
      "[600]\ttraining's rmse: 0.0838995\tvalid_1's rmse: 0.0873782\n",
      "[625]\ttraining's rmse: 0.0838652\tvalid_1's rmse: 0.087367\n",
      "[650]\ttraining's rmse: 0.0838208\tvalid_1's rmse: 0.0873545\n",
      "[675]\ttraining's rmse: 0.0837769\tvalid_1's rmse: 0.0873429\n",
      "[700]\ttraining's rmse: 0.0837389\tvalid_1's rmse: 0.0873324\n",
      "[725]\ttraining's rmse: 0.0837038\tvalid_1's rmse: 0.0873222\n",
      "[750]\ttraining's rmse: 0.0836684\tvalid_1's rmse: 0.0873131\n",
      "[775]\ttraining's rmse: 0.0836386\tvalid_1's rmse: 0.0873047\n",
      "[800]\ttraining's rmse: 0.0836022\tvalid_1's rmse: 0.0872963\n",
      "[825]\ttraining's rmse: 0.0835709\tvalid_1's rmse: 0.0872872\n",
      "[850]\ttraining's rmse: 0.0835424\tvalid_1's rmse: 0.087281\n",
      "[875]\ttraining's rmse: 0.0835167\tvalid_1's rmse: 0.0872747\n",
      "[900]\ttraining's rmse: 0.0834887\tvalid_1's rmse: 0.0872678\n",
      "[925]\ttraining's rmse: 0.0834627\tvalid_1's rmse: 0.087262\n",
      "[950]\ttraining's rmse: 0.083439\tvalid_1's rmse: 0.0872571\n",
      "[975]\ttraining's rmse: 0.0834147\tvalid_1's rmse: 0.0872511\n",
      "[1000]\ttraining's rmse: 0.0833943\tvalid_1's rmse: 0.0872464\n",
      "[1025]\ttraining's rmse: 0.0833685\tvalid_1's rmse: 0.0872421\n",
      "[1050]\ttraining's rmse: 0.0833486\tvalid_1's rmse: 0.0872381\n",
      "[1075]\ttraining's rmse: 0.0833258\tvalid_1's rmse: 0.0872343\n",
      "[1100]\ttraining's rmse: 0.0833078\tvalid_1's rmse: 0.0872301\n",
      "[1125]\ttraining's rmse: 0.0832882\tvalid_1's rmse: 0.0872269\n",
      "[1150]\ttraining's rmse: 0.0832689\tvalid_1's rmse: 0.0872232\n",
      "[1175]\ttraining's rmse: 0.0832535\tvalid_1's rmse: 0.0872202\n",
      "[1200]\ttraining's rmse: 0.0832357\tvalid_1's rmse: 0.0872169\n",
      "[1225]\ttraining's rmse: 0.083217\tvalid_1's rmse: 0.0872139\n",
      "[1250]\ttraining's rmse: 0.0832033\tvalid_1's rmse: 0.0872112\n",
      "[1275]\ttraining's rmse: 0.0831853\tvalid_1's rmse: 0.0872091\n",
      "[1300]\ttraining's rmse: 0.0831729\tvalid_1's rmse: 0.0872074\n",
      "[1325]\ttraining's rmse: 0.0831581\tvalid_1's rmse: 0.087205\n",
      "[1350]\ttraining's rmse: 0.0831445\tvalid_1's rmse: 0.0872035\n",
      "[1375]\ttraining's rmse: 0.0831306\tvalid_1's rmse: 0.0872014\n",
      "[1400]\ttraining's rmse: 0.083119\tvalid_1's rmse: 0.087199\n",
      "[1425]\ttraining's rmse: 0.0831084\tvalid_1's rmse: 0.087198\n",
      "[1450]\ttraining's rmse: 0.0830955\tvalid_1's rmse: 0.0871967\n",
      "[1475]\ttraining's rmse: 0.0830847\tvalid_1's rmse: 0.0871947\n",
      "[1500]\ttraining's rmse: 0.0830759\tvalid_1's rmse: 0.087193\n",
      "[1525]\ttraining's rmse: 0.0830653\tvalid_1's rmse: 0.0871916\n",
      "[1550]\ttraining's rmse: 0.0830552\tvalid_1's rmse: 0.0871904\n",
      "[1575]\ttraining's rmse: 0.0830458\tvalid_1's rmse: 0.0871891\n",
      "[1600]\ttraining's rmse: 0.0830381\tvalid_1's rmse: 0.0871885\n",
      "[1625]\ttraining's rmse: 0.0830297\tvalid_1's rmse: 0.0871873\n",
      "[1650]\ttraining's rmse: 0.0830218\tvalid_1's rmse: 0.0871864\n",
      "[1675]\ttraining's rmse: 0.0830156\tvalid_1's rmse: 0.0871855\n",
      "[1700]\ttraining's rmse: 0.0830092\tvalid_1's rmse: 0.087184\n",
      "[1725]\ttraining's rmse: 0.0830032\tvalid_1's rmse: 0.0871833\n",
      "[1750]\ttraining's rmse: 0.082996\tvalid_1's rmse: 0.0871827\n",
      "[1775]\ttraining's rmse: 0.0829893\tvalid_1's rmse: 0.0871817\n",
      "[1800]\ttraining's rmse: 0.082984\tvalid_1's rmse: 0.0871811\n",
      "[1825]\ttraining's rmse: 0.0829786\tvalid_1's rmse: 0.08718\n",
      "[1850]\ttraining's rmse: 0.0829722\tvalid_1's rmse: 0.0871788\n",
      "[1875]\ttraining's rmse: 0.0829681\tvalid_1's rmse: 0.0871783\n",
      "[1900]\ttraining's rmse: 0.0829633\tvalid_1's rmse: 0.0871775\n",
      "[1925]\ttraining's rmse: 0.0829591\tvalid_1's rmse: 0.0871771\n",
      "[1950]\ttraining's rmse: 0.082954\tvalid_1's rmse: 0.0871763\n",
      "[1975]\ttraining's rmse: 0.0829512\tvalid_1's rmse: 0.0871758\n",
      "[2000]\ttraining's rmse: 0.082947\tvalid_1's rmse: 0.0871757\n",
      "[2025]\ttraining's rmse: 0.0829433\tvalid_1's rmse: 0.0871753\n",
      "[2050]\ttraining's rmse: 0.0829397\tvalid_1's rmse: 0.0871751\n",
      "[2075]\ttraining's rmse: 0.0829359\tvalid_1's rmse: 0.0871744\n",
      "[2100]\ttraining's rmse: 0.0829324\tvalid_1's rmse: 0.0871742\n",
      "[2125]\ttraining's rmse: 0.0829296\tvalid_1's rmse: 0.0871742\n",
      "[2150]\ttraining's rmse: 0.082926\tvalid_1's rmse: 0.0871741\n",
      "[2175]\ttraining's rmse: 0.0829218\tvalid_1's rmse: 0.087174\n",
      "[2200]\ttraining's rmse: 0.082919\tvalid_1's rmse: 0.0871738\n",
      "[2225]\ttraining's rmse: 0.0829155\tvalid_1's rmse: 0.0871734\n",
      "[2250]\ttraining's rmse: 0.0829118\tvalid_1's rmse: 0.0871733\n",
      "[2275]\ttraining's rmse: 0.0829088\tvalid_1's rmse: 0.0871729\n",
      "[2300]\ttraining's rmse: 0.0829063\tvalid_1's rmse: 0.0871728\n",
      "[2325]\ttraining's rmse: 0.082904\tvalid_1's rmse: 0.0871727\n",
      "[2350]\ttraining's rmse: 0.0829005\tvalid_1's rmse: 0.0871723\n",
      "[2375]\ttraining's rmse: 0.0828974\tvalid_1's rmse: 0.0871723\n",
      "[2400]\ttraining's rmse: 0.0828941\tvalid_1's rmse: 0.0871723\n",
      "[2425]\ttraining's rmse: 0.0828918\tvalid_1's rmse: 0.0871723\n",
      "Early stopping, best iteration is:\n",
      "[2386]\ttraining's rmse: 0.0828956\tvalid_1's rmse: 0.087172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0880402\tvalid_1's rmse: 0.0831838\n",
      "[50]\ttraining's rmse: 0.0879227\tvalid_1's rmse: 0.0831351\n",
      "[75]\ttraining's rmse: 0.0878029\tvalid_1's rmse: 0.0830872\n",
      "[100]\ttraining's rmse: 0.0876952\tvalid_1's rmse: 0.0830456\n",
      "[125]\ttraining's rmse: 0.0875853\tvalid_1's rmse: 0.0830097\n",
      "[150]\ttraining's rmse: 0.0874858\tvalid_1's rmse: 0.0829732\n",
      "[175]\ttraining's rmse: 0.0874002\tvalid_1's rmse: 0.0829426\n",
      "[200]\ttraining's rmse: 0.0873072\tvalid_1's rmse: 0.0829144\n",
      "[225]\ttraining's rmse: 0.087218\tvalid_1's rmse: 0.082884\n",
      "[250]\ttraining's rmse: 0.0871461\tvalid_1's rmse: 0.0828603\n",
      "[275]\ttraining's rmse: 0.0870779\tvalid_1's rmse: 0.082835\n",
      "[300]\ttraining's rmse: 0.087008\tvalid_1's rmse: 0.0828119\n",
      "[325]\ttraining's rmse: 0.0869399\tvalid_1's rmse: 0.0827885\n",
      "[350]\ttraining's rmse: 0.0868719\tvalid_1's rmse: 0.0827677\n",
      "[375]\ttraining's rmse: 0.0868176\tvalid_1's rmse: 0.0827513\n",
      "[400]\ttraining's rmse: 0.086756\tvalid_1's rmse: 0.0827374\n",
      "[425]\ttraining's rmse: 0.0866994\tvalid_1's rmse: 0.0827213\n",
      "[450]\ttraining's rmse: 0.0866495\tvalid_1's rmse: 0.0827057\n",
      "[475]\ttraining's rmse: 0.086601\tvalid_1's rmse: 0.0826958\n",
      "[500]\ttraining's rmse: 0.0865605\tvalid_1's rmse: 0.0826847\n",
      "[525]\ttraining's rmse: 0.0865053\tvalid_1's rmse: 0.0826705\n",
      "[550]\ttraining's rmse: 0.0864565\tvalid_1's rmse: 0.0826628\n",
      "[575]\ttraining's rmse: 0.086411\tvalid_1's rmse: 0.0826513\n",
      "[600]\ttraining's rmse: 0.0863668\tvalid_1's rmse: 0.0826465\n",
      "[625]\ttraining's rmse: 0.0863314\tvalid_1's rmse: 0.0826446\n",
      "[650]\ttraining's rmse: 0.0862887\tvalid_1's rmse: 0.0826395\n",
      "[675]\ttraining's rmse: 0.0862448\tvalid_1's rmse: 0.0826362\n",
      "[700]\ttraining's rmse: 0.0862054\tvalid_1's rmse: 0.0826266\n",
      "[725]\ttraining's rmse: 0.0861679\tvalid_1's rmse: 0.0826256\n",
      "[750]\ttraining's rmse: 0.0861339\tvalid_1's rmse: 0.0826304\n",
      "[775]\ttraining's rmse: 0.0861051\tvalid_1's rmse: 0.082631\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0861526\tvalid_1's rmse: 0.0826219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0882839\tvalid_1's rmse: 0.0904343\n",
      "[50]\ttraining's rmse: 0.0881373\tvalid_1's rmse: 0.0903812\n",
      "[75]\ttraining's rmse: 0.0879898\tvalid_1's rmse: 0.0903277\n",
      "[100]\ttraining's rmse: 0.0878535\tvalid_1's rmse: 0.090281\n",
      "[125]\ttraining's rmse: 0.0877192\tvalid_1's rmse: 0.0902346\n",
      "[150]\ttraining's rmse: 0.0875942\tvalid_1's rmse: 0.0901903\n",
      "[175]\ttraining's rmse: 0.0874909\tvalid_1's rmse: 0.0901525\n",
      "[200]\ttraining's rmse: 0.0873819\tvalid_1's rmse: 0.0901145\n",
      "[225]\ttraining's rmse: 0.0872721\tvalid_1's rmse: 0.0900795\n",
      "[250]\ttraining's rmse: 0.0871829\tvalid_1's rmse: 0.0900494\n",
      "[275]\ttraining's rmse: 0.0870988\tvalid_1's rmse: 0.0900216\n",
      "[300]\ttraining's rmse: 0.0870142\tvalid_1's rmse: 0.0899918\n",
      "[325]\ttraining's rmse: 0.0869298\tvalid_1's rmse: 0.0899646\n",
      "[350]\ttraining's rmse: 0.0868471\tvalid_1's rmse: 0.0899402\n",
      "[375]\ttraining's rmse: 0.0867782\tvalid_1's rmse: 0.0899203\n",
      "[400]\ttraining's rmse: 0.0867028\tvalid_1's rmse: 0.0898985\n",
      "[425]\ttraining's rmse: 0.0866311\tvalid_1's rmse: 0.0898784\n",
      "[450]\ttraining's rmse: 0.0865702\tvalid_1's rmse: 0.0898599\n",
      "[475]\ttraining's rmse: 0.0865106\tvalid_1's rmse: 0.0898423\n",
      "[500]\ttraining's rmse: 0.0864609\tvalid_1's rmse: 0.0898269\n",
      "[525]\ttraining's rmse: 0.0864017\tvalid_1's rmse: 0.0898092\n",
      "[550]\ttraining's rmse: 0.0863487\tvalid_1's rmse: 0.0897944\n",
      "[575]\ttraining's rmse: 0.0862952\tvalid_1's rmse: 0.0897813\n",
      "[600]\ttraining's rmse: 0.0862448\tvalid_1's rmse: 0.0897667\n",
      "[625]\ttraining's rmse: 0.0862056\tvalid_1's rmse: 0.0897546\n",
      "[650]\ttraining's rmse: 0.0861594\tvalid_1's rmse: 0.0897422\n",
      "[675]\ttraining's rmse: 0.0861107\tvalid_1's rmse: 0.089729\n",
      "[700]\ttraining's rmse: 0.0860698\tvalid_1's rmse: 0.0897183\n",
      "[725]\ttraining's rmse: 0.0860307\tvalid_1's rmse: 0.0897085\n",
      "[750]\ttraining's rmse: 0.0859914\tvalid_1's rmse: 0.0896989\n",
      "[775]\ttraining's rmse: 0.0859635\tvalid_1's rmse: 0.0896886\n",
      "[800]\ttraining's rmse: 0.0859253\tvalid_1's rmse: 0.0896798\n",
      "[825]\ttraining's rmse: 0.0858925\tvalid_1's rmse: 0.0896705\n",
      "[850]\ttraining's rmse: 0.0858561\tvalid_1's rmse: 0.0896623\n",
      "[875]\ttraining's rmse: 0.0858266\tvalid_1's rmse: 0.0896545\n",
      "[900]\ttraining's rmse: 0.0857948\tvalid_1's rmse: 0.0896456\n",
      "[925]\ttraining's rmse: 0.0857646\tvalid_1's rmse: 0.0896377\n",
      "[950]\ttraining's rmse: 0.0857358\tvalid_1's rmse: 0.0896318\n",
      "[975]\ttraining's rmse: 0.0857098\tvalid_1's rmse: 0.0896246\n",
      "[1000]\ttraining's rmse: 0.0856826\tvalid_1's rmse: 0.0896191\n",
      "[1025]\ttraining's rmse: 0.0856567\tvalid_1's rmse: 0.0896125\n",
      "[1050]\ttraining's rmse: 0.0856335\tvalid_1's rmse: 0.0896066\n",
      "[1075]\ttraining's rmse: 0.0856121\tvalid_1's rmse: 0.0896018\n",
      "[1100]\ttraining's rmse: 0.0855898\tvalid_1's rmse: 0.0895967\n",
      "[1125]\ttraining's rmse: 0.0855705\tvalid_1's rmse: 0.0895913\n",
      "[1150]\ttraining's rmse: 0.0855508\tvalid_1's rmse: 0.0895865\n",
      "[1175]\ttraining's rmse: 0.0855321\tvalid_1's rmse: 0.0895826\n",
      "[1200]\ttraining's rmse: 0.0855151\tvalid_1's rmse: 0.0895778\n",
      "[1225]\ttraining's rmse: 0.0854965\tvalid_1's rmse: 0.0895742\n",
      "[1250]\ttraining's rmse: 0.0854822\tvalid_1's rmse: 0.0895694\n",
      "[1275]\ttraining's rmse: 0.085462\tvalid_1's rmse: 0.089566\n",
      "[1300]\ttraining's rmse: 0.0854459\tvalid_1's rmse: 0.0895608\n",
      "[1325]\ttraining's rmse: 0.0854289\tvalid_1's rmse: 0.0895578\n",
      "[1350]\ttraining's rmse: 0.0854149\tvalid_1's rmse: 0.0895542\n",
      "[1375]\ttraining's rmse: 0.0853983\tvalid_1's rmse: 0.0895503\n",
      "[1400]\ttraining's rmse: 0.0853872\tvalid_1's rmse: 0.0895466\n",
      "[1425]\ttraining's rmse: 0.0853698\tvalid_1's rmse: 0.0895438\n",
      "[1450]\ttraining's rmse: 0.0853541\tvalid_1's rmse: 0.0895414\n",
      "[1475]\ttraining's rmse: 0.085343\tvalid_1's rmse: 0.0895377\n",
      "[1500]\ttraining's rmse: 0.0853326\tvalid_1's rmse: 0.0895348\n",
      "[1525]\ttraining's rmse: 0.085323\tvalid_1's rmse: 0.0895323\n",
      "[1550]\ttraining's rmse: 0.0853136\tvalid_1's rmse: 0.089531\n",
      "[1575]\ttraining's rmse: 0.0853032\tvalid_1's rmse: 0.0895286\n",
      "[1600]\ttraining's rmse: 0.0852947\tvalid_1's rmse: 0.0895263\n",
      "[1625]\ttraining's rmse: 0.085288\tvalid_1's rmse: 0.0895236\n",
      "[1650]\ttraining's rmse: 0.0852802\tvalid_1's rmse: 0.089521\n",
      "[1675]\ttraining's rmse: 0.0852731\tvalid_1's rmse: 0.0895181\n",
      "[1700]\ttraining's rmse: 0.0852655\tvalid_1's rmse: 0.0895161\n",
      "[1725]\ttraining's rmse: 0.0852558\tvalid_1's rmse: 0.089515\n",
      "[1750]\ttraining's rmse: 0.0852479\tvalid_1's rmse: 0.0895133\n",
      "[1775]\ttraining's rmse: 0.0852405\tvalid_1's rmse: 0.0895124\n",
      "[1800]\ttraining's rmse: 0.0852331\tvalid_1's rmse: 0.08951\n",
      "[1825]\ttraining's rmse: 0.0852259\tvalid_1's rmse: 0.0895083\n",
      "[1850]\ttraining's rmse: 0.0852213\tvalid_1's rmse: 0.0895066\n",
      "[1875]\ttraining's rmse: 0.0852146\tvalid_1's rmse: 0.089504\n",
      "[1900]\ttraining's rmse: 0.0852098\tvalid_1's rmse: 0.0895032\n",
      "[1925]\ttraining's rmse: 0.0852051\tvalid_1's rmse: 0.0895016\n",
      "[1950]\ttraining's rmse: 0.0852\tvalid_1's rmse: 0.0894989\n",
      "[1975]\ttraining's rmse: 0.0851941\tvalid_1's rmse: 0.0894975\n",
      "[2000]\ttraining's rmse: 0.0851883\tvalid_1's rmse: 0.0894957\n",
      "[2025]\ttraining's rmse: 0.0851841\tvalid_1's rmse: 0.0894933\n",
      "[2050]\ttraining's rmse: 0.0851798\tvalid_1's rmse: 0.0894919\n",
      "[2075]\ttraining's rmse: 0.0851748\tvalid_1's rmse: 0.0894905\n",
      "[2100]\ttraining's rmse: 0.0851707\tvalid_1's rmse: 0.089489\n",
      "[2125]\ttraining's rmse: 0.0851674\tvalid_1's rmse: 0.0894886\n",
      "[2150]\ttraining's rmse: 0.0851644\tvalid_1's rmse: 0.0894879\n",
      "[2175]\ttraining's rmse: 0.0851612\tvalid_1's rmse: 0.0894862\n",
      "[2200]\ttraining's rmse: 0.0851558\tvalid_1's rmse: 0.0894849\n",
      "[2225]\ttraining's rmse: 0.0851526\tvalid_1's rmse: 0.0894839\n",
      "[2250]\ttraining's rmse: 0.0851504\tvalid_1's rmse: 0.0894826\n",
      "[2275]\ttraining's rmse: 0.0851466\tvalid_1's rmse: 0.0894828\n",
      "[2300]\ttraining's rmse: 0.0851425\tvalid_1's rmse: 0.0894813\n",
      "[2325]\ttraining's rmse: 0.0851379\tvalid_1's rmse: 0.0894797\n",
      "[2350]\ttraining's rmse: 0.0851341\tvalid_1's rmse: 0.0894783\n",
      "[2375]\ttraining's rmse: 0.0851317\tvalid_1's rmse: 0.0894778\n",
      "[2400]\ttraining's rmse: 0.0851288\tvalid_1's rmse: 0.0894768\n",
      "[2425]\ttraining's rmse: 0.0851272\tvalid_1's rmse: 0.0894763\n",
      "[2450]\ttraining's rmse: 0.0851248\tvalid_1's rmse: 0.0894757\n",
      "[2475]\ttraining's rmse: 0.085123\tvalid_1's rmse: 0.0894755\n",
      "[2500]\ttraining's rmse: 0.0851196\tvalid_1's rmse: 0.0894749\n",
      "[2525]\ttraining's rmse: 0.0851176\tvalid_1's rmse: 0.0894736\n",
      "[2550]\ttraining's rmse: 0.085114\tvalid_1's rmse: 0.0894732\n",
      "[2575]\ttraining's rmse: 0.0851117\tvalid_1's rmse: 0.0894726\n",
      "[2600]\ttraining's rmse: 0.0851101\tvalid_1's rmse: 0.0894718\n",
      "[2625]\ttraining's rmse: 0.0851076\tvalid_1's rmse: 0.0894703\n",
      "[2650]\ttraining's rmse: 0.085106\tvalid_1's rmse: 0.0894696\n",
      "[2675]\ttraining's rmse: 0.0851031\tvalid_1's rmse: 0.0894681\n",
      "[2700]\ttraining's rmse: 0.0851016\tvalid_1's rmse: 0.0894678\n",
      "[2725]\ttraining's rmse: 0.085098\tvalid_1's rmse: 0.089468\n",
      "[2750]\ttraining's rmse: 0.0850964\tvalid_1's rmse: 0.0894679\n",
      "[2775]\ttraining's rmse: 0.0850943\tvalid_1's rmse: 0.0894674\n",
      "[2800]\ttraining's rmse: 0.0850928\tvalid_1's rmse: 0.0894663\n",
      "[2825]\ttraining's rmse: 0.0850912\tvalid_1's rmse: 0.0894666\n",
      "[2850]\ttraining's rmse: 0.085089\tvalid_1's rmse: 0.0894665\n",
      "Early stopping, best iteration is:\n",
      "[2800]\ttraining's rmse: 0.0850928\tvalid_1's rmse: 0.0894663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0881969\tvalid_1's rmse: 0.0906337\n",
      "[50]\ttraining's rmse: 0.0880682\tvalid_1's rmse: 0.0905794\n",
      "[75]\ttraining's rmse: 0.0879346\tvalid_1's rmse: 0.0905247\n",
      "[100]\ttraining's rmse: 0.0878168\tvalid_1's rmse: 0.0904768\n",
      "[125]\ttraining's rmse: 0.0876919\tvalid_1's rmse: 0.0904281\n",
      "[150]\ttraining's rmse: 0.0875783\tvalid_1's rmse: 0.0903849\n",
      "[175]\ttraining's rmse: 0.0874833\tvalid_1's rmse: 0.0903495\n",
      "[200]\ttraining's rmse: 0.0873807\tvalid_1's rmse: 0.0903127\n",
      "[225]\ttraining's rmse: 0.0872792\tvalid_1's rmse: 0.0902767\n",
      "[250]\ttraining's rmse: 0.0871953\tvalid_1's rmse: 0.090245\n",
      "[275]\ttraining's rmse: 0.0871186\tvalid_1's rmse: 0.0902166\n",
      "[300]\ttraining's rmse: 0.0870398\tvalid_1's rmse: 0.0901887\n",
      "[325]\ttraining's rmse: 0.0869573\tvalid_1's rmse: 0.0901612\n",
      "[350]\ttraining's rmse: 0.0868801\tvalid_1's rmse: 0.0901355\n",
      "[375]\ttraining's rmse: 0.0868173\tvalid_1's rmse: 0.0901148\n",
      "[400]\ttraining's rmse: 0.0867502\tvalid_1's rmse: 0.0900947\n",
      "[425]\ttraining's rmse: 0.0866856\tvalid_1's rmse: 0.090075\n",
      "[450]\ttraining's rmse: 0.0866287\tvalid_1's rmse: 0.090056\n",
      "[475]\ttraining's rmse: 0.0865768\tvalid_1's rmse: 0.090039\n",
      "[500]\ttraining's rmse: 0.0865324\tvalid_1's rmse: 0.0900236\n",
      "[525]\ttraining's rmse: 0.0864752\tvalid_1's rmse: 0.0900075\n",
      "[550]\ttraining's rmse: 0.086423\tvalid_1's rmse: 0.0899922\n",
      "[575]\ttraining's rmse: 0.0863731\tvalid_1's rmse: 0.0899777\n",
      "[600]\ttraining's rmse: 0.0863267\tvalid_1's rmse: 0.0899653\n",
      "[625]\ttraining's rmse: 0.0862901\tvalid_1's rmse: 0.0899533\n",
      "[650]\ttraining's rmse: 0.086243\tvalid_1's rmse: 0.0899405\n",
      "[675]\ttraining's rmse: 0.0861949\tvalid_1's rmse: 0.0899284\n",
      "[700]\ttraining's rmse: 0.0861533\tvalid_1's rmse: 0.0899165\n",
      "[725]\ttraining's rmse: 0.0861158\tvalid_1's rmse: 0.0899074\n",
      "[750]\ttraining's rmse: 0.0860807\tvalid_1's rmse: 0.089898\n",
      "[775]\ttraining's rmse: 0.0860496\tvalid_1's rmse: 0.0898888\n",
      "[800]\ttraining's rmse: 0.0860105\tvalid_1's rmse: 0.0898803\n",
      "[825]\ttraining's rmse: 0.085979\tvalid_1's rmse: 0.089873\n",
      "[850]\ttraining's rmse: 0.0859466\tvalid_1's rmse: 0.0898665\n",
      "[875]\ttraining's rmse: 0.0859168\tvalid_1's rmse: 0.0898603\n",
      "[900]\ttraining's rmse: 0.0858848\tvalid_1's rmse: 0.0898541\n",
      "[925]\ttraining's rmse: 0.085855\tvalid_1's rmse: 0.0898478\n",
      "[950]\ttraining's rmse: 0.0858271\tvalid_1's rmse: 0.0898426\n",
      "[975]\ttraining's rmse: 0.0858007\tvalid_1's rmse: 0.0898374\n",
      "[1000]\ttraining's rmse: 0.0857776\tvalid_1's rmse: 0.0898323\n",
      "[1025]\ttraining's rmse: 0.0857485\tvalid_1's rmse: 0.0898283\n",
      "[1050]\ttraining's rmse: 0.0857262\tvalid_1's rmse: 0.0898234\n",
      "[1075]\ttraining's rmse: 0.0857039\tvalid_1's rmse: 0.08982\n",
      "[1100]\ttraining's rmse: 0.085685\tvalid_1's rmse: 0.0898164\n",
      "[1125]\ttraining's rmse: 0.0856618\tvalid_1's rmse: 0.089813\n",
      "[1150]\ttraining's rmse: 0.0856393\tvalid_1's rmse: 0.0898092\n",
      "[1175]\ttraining's rmse: 0.085621\tvalid_1's rmse: 0.0898069\n",
      "[1200]\ttraining's rmse: 0.0856013\tvalid_1's rmse: 0.0898025\n",
      "[1225]\ttraining's rmse: 0.0855845\tvalid_1's rmse: 0.0897998\n",
      "[1250]\ttraining's rmse: 0.0855684\tvalid_1's rmse: 0.0897978\n",
      "[1275]\ttraining's rmse: 0.0855504\tvalid_1's rmse: 0.0897956\n",
      "[1300]\ttraining's rmse: 0.0855355\tvalid_1's rmse: 0.0897933\n",
      "[1325]\ttraining's rmse: 0.0855178\tvalid_1's rmse: 0.0897913\n",
      "[1350]\ttraining's rmse: 0.0855007\tvalid_1's rmse: 0.0897905\n",
      "[1375]\ttraining's rmse: 0.0854846\tvalid_1's rmse: 0.0897888\n",
      "[1400]\ttraining's rmse: 0.0854713\tvalid_1's rmse: 0.0897868\n",
      "[1425]\ttraining's rmse: 0.0854563\tvalid_1's rmse: 0.0897852\n",
      "[1450]\ttraining's rmse: 0.0854413\tvalid_1's rmse: 0.0897841\n",
      "[1475]\ttraining's rmse: 0.0854313\tvalid_1's rmse: 0.0897824\n",
      "[1500]\ttraining's rmse: 0.0854192\tvalid_1's rmse: 0.0897814\n",
      "[1525]\ttraining's rmse: 0.0854067\tvalid_1's rmse: 0.0897792\n",
      "[1550]\ttraining's rmse: 0.0853961\tvalid_1's rmse: 0.0897785\n",
      "[1575]\ttraining's rmse: 0.0853857\tvalid_1's rmse: 0.089778\n",
      "[1600]\ttraining's rmse: 0.085377\tvalid_1's rmse: 0.0897777\n",
      "[1625]\ttraining's rmse: 0.0853679\tvalid_1's rmse: 0.0897766\n",
      "[1650]\ttraining's rmse: 0.0853582\tvalid_1's rmse: 0.0897753\n",
      "[1675]\ttraining's rmse: 0.0853505\tvalid_1's rmse: 0.0897742\n",
      "[1700]\ttraining's rmse: 0.0853432\tvalid_1's rmse: 0.0897728\n",
      "[1725]\ttraining's rmse: 0.0853354\tvalid_1's rmse: 0.0897714\n",
      "[1750]\ttraining's rmse: 0.085327\tvalid_1's rmse: 0.0897706\n",
      "[1775]\ttraining's rmse: 0.085321\tvalid_1's rmse: 0.0897706\n",
      "[1800]\ttraining's rmse: 0.0853148\tvalid_1's rmse: 0.0897699\n",
      "[1825]\ttraining's rmse: 0.0853071\tvalid_1's rmse: 0.0897691\n",
      "[1850]\ttraining's rmse: 0.0852998\tvalid_1's rmse: 0.0897682\n",
      "[1875]\ttraining's rmse: 0.0852946\tvalid_1's rmse: 0.089768\n",
      "[1900]\ttraining's rmse: 0.0852885\tvalid_1's rmse: 0.0897672\n",
      "[1925]\ttraining's rmse: 0.0852829\tvalid_1's rmse: 0.0897666\n",
      "[1950]\ttraining's rmse: 0.0852782\tvalid_1's rmse: 0.0897659\n",
      "[1975]\ttraining's rmse: 0.0852726\tvalid_1's rmse: 0.0897654\n",
      "[2000]\ttraining's rmse: 0.0852671\tvalid_1's rmse: 0.0897645\n",
      "[2025]\ttraining's rmse: 0.0852627\tvalid_1's rmse: 0.0897643\n",
      "[2050]\ttraining's rmse: 0.0852584\tvalid_1's rmse: 0.0897637\n",
      "[2075]\ttraining's rmse: 0.0852538\tvalid_1's rmse: 0.0897631\n",
      "[2100]\ttraining's rmse: 0.0852492\tvalid_1's rmse: 0.0897628\n",
      "[2125]\ttraining's rmse: 0.085246\tvalid_1's rmse: 0.089763\n",
      "[2150]\ttraining's rmse: 0.0852422\tvalid_1's rmse: 0.0897632\n",
      "Early stopping, best iteration is:\n",
      "[2107]\ttraining's rmse: 0.0852479\tvalid_1's rmse: 0.0897627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0903964\tvalid_1's rmse: 0.0861606\n",
      "[50]\ttraining's rmse: 0.0902733\tvalid_1's rmse: 0.0861124\n",
      "[75]\ttraining's rmse: 0.0901392\tvalid_1's rmse: 0.0860647\n",
      "[100]\ttraining's rmse: 0.0900222\tvalid_1's rmse: 0.0860223\n",
      "[125]\ttraining's rmse: 0.0899006\tvalid_1's rmse: 0.0859791\n",
      "[150]\ttraining's rmse: 0.0897865\tvalid_1's rmse: 0.0859402\n",
      "[175]\ttraining's rmse: 0.0896904\tvalid_1's rmse: 0.0859154\n",
      "[200]\ttraining's rmse: 0.0895861\tvalid_1's rmse: 0.0858823\n",
      "[225]\ttraining's rmse: 0.0894867\tvalid_1's rmse: 0.0858501\n",
      "[250]\ttraining's rmse: 0.0894047\tvalid_1's rmse: 0.0858215\n",
      "[275]\ttraining's rmse: 0.0893283\tvalid_1's rmse: 0.085796\n",
      "[300]\ttraining's rmse: 0.0892512\tvalid_1's rmse: 0.0857719\n",
      "[325]\ttraining's rmse: 0.0891728\tvalid_1's rmse: 0.0857499\n",
      "[350]\ttraining's rmse: 0.0890966\tvalid_1's rmse: 0.0857279\n",
      "[375]\ttraining's rmse: 0.089036\tvalid_1's rmse: 0.0857123\n",
      "[400]\ttraining's rmse: 0.0889653\tvalid_1's rmse: 0.0856949\n",
      "[425]\ttraining's rmse: 0.0889021\tvalid_1's rmse: 0.0856857\n",
      "[450]\ttraining's rmse: 0.0888461\tvalid_1's rmse: 0.0856746\n",
      "[475]\ttraining's rmse: 0.088792\tvalid_1's rmse: 0.0856619\n",
      "[500]\ttraining's rmse: 0.0887489\tvalid_1's rmse: 0.0856484\n",
      "[525]\ttraining's rmse: 0.0886915\tvalid_1's rmse: 0.0856348\n",
      "[550]\ttraining's rmse: 0.0886397\tvalid_1's rmse: 0.0856216\n",
      "[575]\ttraining's rmse: 0.0885898\tvalid_1's rmse: 0.0856138\n",
      "[600]\ttraining's rmse: 0.0885399\tvalid_1's rmse: 0.0856092\n",
      "[625]\ttraining's rmse: 0.0885005\tvalid_1's rmse: 0.0856063\n",
      "[650]\ttraining's rmse: 0.0884507\tvalid_1's rmse: 0.0856021\n",
      "[675]\ttraining's rmse: 0.0884012\tvalid_1's rmse: 0.0855943\n",
      "[700]\ttraining's rmse: 0.0883598\tvalid_1's rmse: 0.0855864\n",
      "[725]\ttraining's rmse: 0.088319\tvalid_1's rmse: 0.0855987\n",
      "[750]\ttraining's rmse: 0.0882818\tvalid_1's rmse: 0.0856117\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0883519\tvalid_1's rmse: 0.0855856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.086041\tvalid_1's rmse: 0.0887003\n",
      "[50]\ttraining's rmse: 0.0859031\tvalid_1's rmse: 0.0886448\n",
      "[75]\ttraining's rmse: 0.0857702\tvalid_1's rmse: 0.0885894\n",
      "[100]\ttraining's rmse: 0.0856401\tvalid_1's rmse: 0.0885439\n",
      "[125]\ttraining's rmse: 0.0855174\tvalid_1's rmse: 0.0884971\n",
      "[150]\ttraining's rmse: 0.0854035\tvalid_1's rmse: 0.0884549\n",
      "[175]\ttraining's rmse: 0.08531\tvalid_1's rmse: 0.088417\n",
      "[200]\ttraining's rmse: 0.0852108\tvalid_1's rmse: 0.0883807\n",
      "[225]\ttraining's rmse: 0.0851137\tvalid_1's rmse: 0.0883443\n",
      "[250]\ttraining's rmse: 0.085033\tvalid_1's rmse: 0.0883109\n",
      "[275]\ttraining's rmse: 0.084954\tvalid_1's rmse: 0.0882804\n",
      "[300]\ttraining's rmse: 0.0848793\tvalid_1's rmse: 0.0882531\n",
      "[325]\ttraining's rmse: 0.084805\tvalid_1's rmse: 0.0882251\n",
      "[350]\ttraining's rmse: 0.0847321\tvalid_1's rmse: 0.0881988\n",
      "[375]\ttraining's rmse: 0.0846689\tvalid_1's rmse: 0.0881762\n",
      "[400]\ttraining's rmse: 0.0846066\tvalid_1's rmse: 0.0881553\n",
      "[425]\ttraining's rmse: 0.0845459\tvalid_1's rmse: 0.0881343\n",
      "[450]\ttraining's rmse: 0.0844901\tvalid_1's rmse: 0.0881135\n",
      "[475]\ttraining's rmse: 0.0844395\tvalid_1's rmse: 0.0880954\n",
      "[500]\ttraining's rmse: 0.0843963\tvalid_1's rmse: 0.0880779\n",
      "[525]\ttraining's rmse: 0.084341\tvalid_1's rmse: 0.0880584\n",
      "[550]\ttraining's rmse: 0.0842907\tvalid_1's rmse: 0.088043\n",
      "[575]\ttraining's rmse: 0.0842425\tvalid_1's rmse: 0.0880302\n",
      "[600]\ttraining's rmse: 0.0841996\tvalid_1's rmse: 0.0880171\n",
      "[625]\ttraining's rmse: 0.0841602\tvalid_1's rmse: 0.0880047\n",
      "[650]\ttraining's rmse: 0.0841173\tvalid_1's rmse: 0.0879924\n",
      "[675]\ttraining's rmse: 0.0840726\tvalid_1's rmse: 0.087979\n",
      "[700]\ttraining's rmse: 0.0840335\tvalid_1's rmse: 0.0879682\n",
      "[725]\ttraining's rmse: 0.0839954\tvalid_1's rmse: 0.087959\n",
      "[750]\ttraining's rmse: 0.0839607\tvalid_1's rmse: 0.0879492\n",
      "[775]\ttraining's rmse: 0.0839313\tvalid_1's rmse: 0.0879381\n",
      "[800]\ttraining's rmse: 0.0838974\tvalid_1's rmse: 0.0879293\n",
      "[825]\ttraining's rmse: 0.0838668\tvalid_1's rmse: 0.0879201\n",
      "[850]\ttraining's rmse: 0.083834\tvalid_1's rmse: 0.0879137\n",
      "[875]\ttraining's rmse: 0.0838079\tvalid_1's rmse: 0.0879066\n",
      "[900]\ttraining's rmse: 0.0837752\tvalid_1's rmse: 0.0878993\n",
      "[925]\ttraining's rmse: 0.0837482\tvalid_1's rmse: 0.0878919\n",
      "[950]\ttraining's rmse: 0.0837218\tvalid_1's rmse: 0.0878845\n",
      "[975]\ttraining's rmse: 0.0836995\tvalid_1's rmse: 0.0878785\n",
      "[1000]\ttraining's rmse: 0.0836746\tvalid_1's rmse: 0.087872\n",
      "[1025]\ttraining's rmse: 0.0836495\tvalid_1's rmse: 0.087866\n",
      "[1050]\ttraining's rmse: 0.0836281\tvalid_1's rmse: 0.0878596\n",
      "[1075]\ttraining's rmse: 0.0836062\tvalid_1's rmse: 0.0878548\n",
      "[1100]\ttraining's rmse: 0.0835868\tvalid_1's rmse: 0.0878497\n",
      "[1125]\ttraining's rmse: 0.083567\tvalid_1's rmse: 0.0878441\n",
      "[1150]\ttraining's rmse: 0.0835459\tvalid_1's rmse: 0.08784\n",
      "[1175]\ttraining's rmse: 0.0835264\tvalid_1's rmse: 0.0878346\n",
      "[1200]\ttraining's rmse: 0.08351\tvalid_1's rmse: 0.0878288\n",
      "[1225]\ttraining's rmse: 0.0834921\tvalid_1's rmse: 0.0878246\n",
      "[1250]\ttraining's rmse: 0.0834793\tvalid_1's rmse: 0.0878202\n",
      "[1275]\ttraining's rmse: 0.0834631\tvalid_1's rmse: 0.0878169\n",
      "[1300]\ttraining's rmse: 0.0834522\tvalid_1's rmse: 0.0878138\n",
      "[1325]\ttraining's rmse: 0.0834372\tvalid_1's rmse: 0.0878089\n",
      "[1350]\ttraining's rmse: 0.0834214\tvalid_1's rmse: 0.0878065\n",
      "[1375]\ttraining's rmse: 0.083405\tvalid_1's rmse: 0.0878035\n",
      "[1400]\ttraining's rmse: 0.0833935\tvalid_1's rmse: 0.087799\n",
      "[1425]\ttraining's rmse: 0.0833786\tvalid_1's rmse: 0.0877963\n",
      "[1450]\ttraining's rmse: 0.0833648\tvalid_1's rmse: 0.0877938\n",
      "[1475]\ttraining's rmse: 0.0833538\tvalid_1's rmse: 0.0877905\n",
      "[1500]\ttraining's rmse: 0.0833439\tvalid_1's rmse: 0.0877872\n",
      "[1525]\ttraining's rmse: 0.0833332\tvalid_1's rmse: 0.0877848\n",
      "[1550]\ttraining's rmse: 0.0833227\tvalid_1's rmse: 0.0877817\n",
      "[1575]\ttraining's rmse: 0.0833162\tvalid_1's rmse: 0.0877792\n",
      "[1600]\ttraining's rmse: 0.0833091\tvalid_1's rmse: 0.0877766\n",
      "[1625]\ttraining's rmse: 0.0833001\tvalid_1's rmse: 0.0877736\n",
      "[1650]\ttraining's rmse: 0.0832925\tvalid_1's rmse: 0.0877707\n",
      "[1675]\ttraining's rmse: 0.0832841\tvalid_1's rmse: 0.0877684\n",
      "[1700]\ttraining's rmse: 0.0832777\tvalid_1's rmse: 0.0877661\n",
      "[1725]\ttraining's rmse: 0.0832712\tvalid_1's rmse: 0.0877635\n",
      "[1750]\ttraining's rmse: 0.0832637\tvalid_1's rmse: 0.0877624\n",
      "[1775]\ttraining's rmse: 0.0832574\tvalid_1's rmse: 0.0877609\n",
      "[1800]\ttraining's rmse: 0.0832497\tvalid_1's rmse: 0.0877592\n",
      "[1825]\ttraining's rmse: 0.0832432\tvalid_1's rmse: 0.0877576\n",
      "[1850]\ttraining's rmse: 0.0832385\tvalid_1's rmse: 0.0877552\n",
      "[1875]\ttraining's rmse: 0.083233\tvalid_1's rmse: 0.0877533\n",
      "[1900]\ttraining's rmse: 0.0832269\tvalid_1's rmse: 0.0877527\n",
      "[1925]\ttraining's rmse: 0.0832209\tvalid_1's rmse: 0.0877513\n",
      "[1950]\ttraining's rmse: 0.0832166\tvalid_1's rmse: 0.087749\n",
      "[1975]\ttraining's rmse: 0.0832115\tvalid_1's rmse: 0.0877468\n",
      "[2000]\ttraining's rmse: 0.0832066\tvalid_1's rmse: 0.0877461\n",
      "[2025]\ttraining's rmse: 0.0832029\tvalid_1's rmse: 0.0877446\n",
      "[2050]\ttraining's rmse: 0.0831995\tvalid_1's rmse: 0.0877434\n",
      "[2075]\ttraining's rmse: 0.0831964\tvalid_1's rmse: 0.0877418\n",
      "[2100]\ttraining's rmse: 0.0831922\tvalid_1's rmse: 0.0877412\n",
      "[2125]\ttraining's rmse: 0.0831888\tvalid_1's rmse: 0.0877402\n",
      "[2150]\ttraining's rmse: 0.0831851\tvalid_1's rmse: 0.0877394\n",
      "[2175]\ttraining's rmse: 0.0831828\tvalid_1's rmse: 0.0877385\n",
      "[2200]\ttraining's rmse: 0.0831801\tvalid_1's rmse: 0.0877382\n",
      "[2225]\ttraining's rmse: 0.0831764\tvalid_1's rmse: 0.0877376\n",
      "[2250]\ttraining's rmse: 0.0831739\tvalid_1's rmse: 0.0877367\n",
      "[2275]\ttraining's rmse: 0.0831701\tvalid_1's rmse: 0.087736\n",
      "[2300]\ttraining's rmse: 0.083168\tvalid_1's rmse: 0.0877356\n",
      "[2325]\ttraining's rmse: 0.0831648\tvalid_1's rmse: 0.0877341\n",
      "[2350]\ttraining's rmse: 0.0831629\tvalid_1's rmse: 0.0877345\n",
      "[2375]\ttraining's rmse: 0.0831601\tvalid_1's rmse: 0.0877339\n",
      "[2400]\ttraining's rmse: 0.0831557\tvalid_1's rmse: 0.0877336\n",
      "[2425]\ttraining's rmse: 0.0831523\tvalid_1's rmse: 0.0877323\n",
      "[2450]\ttraining's rmse: 0.0831507\tvalid_1's rmse: 0.0877317\n",
      "[2475]\ttraining's rmse: 0.0831484\tvalid_1's rmse: 0.0877317\n",
      "[2500]\ttraining's rmse: 0.0831461\tvalid_1's rmse: 0.0877315\n",
      "[2525]\ttraining's rmse: 0.0831434\tvalid_1's rmse: 0.0877316\n",
      "[2550]\ttraining's rmse: 0.0831408\tvalid_1's rmse: 0.0877314\n",
      "[2575]\ttraining's rmse: 0.0831388\tvalid_1's rmse: 0.0877313\n",
      "[2600]\ttraining's rmse: 0.083137\tvalid_1's rmse: 0.08773\n",
      "[2625]\ttraining's rmse: 0.083136\tvalid_1's rmse: 0.087729\n",
      "[2650]\ttraining's rmse: 0.0831333\tvalid_1's rmse: 0.0877281\n",
      "[2675]\ttraining's rmse: 0.0831308\tvalid_1's rmse: 0.0877272\n",
      "[2700]\ttraining's rmse: 0.0831286\tvalid_1's rmse: 0.0877267\n",
      "[2725]\ttraining's rmse: 0.0831271\tvalid_1's rmse: 0.087727\n",
      "[2750]\ttraining's rmse: 0.0831252\tvalid_1's rmse: 0.0877271\n",
      "Early stopping, best iteration is:\n",
      "[2700]\ttraining's rmse: 0.0831286\tvalid_1's rmse: 0.0877267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0861948\tvalid_1's rmse: 0.0884112\n",
      "[50]\ttraining's rmse: 0.0860686\tvalid_1's rmse: 0.088355\n",
      "[75]\ttraining's rmse: 0.0859414\tvalid_1's rmse: 0.0883008\n",
      "[100]\ttraining's rmse: 0.0858282\tvalid_1's rmse: 0.0882527\n",
      "[125]\ttraining's rmse: 0.0857067\tvalid_1's rmse: 0.0882033\n",
      "[150]\ttraining's rmse: 0.0855971\tvalid_1's rmse: 0.0881594\n",
      "[175]\ttraining's rmse: 0.0855059\tvalid_1's rmse: 0.0881218\n",
      "[200]\ttraining's rmse: 0.0854092\tvalid_1's rmse: 0.0880844\n",
      "[225]\ttraining's rmse: 0.0853168\tvalid_1's rmse: 0.0880505\n",
      "[250]\ttraining's rmse: 0.0852371\tvalid_1's rmse: 0.0880189\n",
      "[275]\ttraining's rmse: 0.0851607\tvalid_1's rmse: 0.0879901\n",
      "[300]\ttraining's rmse: 0.085089\tvalid_1's rmse: 0.087964\n",
      "[325]\ttraining's rmse: 0.0850144\tvalid_1's rmse: 0.0879381\n",
      "[350]\ttraining's rmse: 0.0849399\tvalid_1's rmse: 0.0879127\n",
      "[375]\ttraining's rmse: 0.0848818\tvalid_1's rmse: 0.0878905\n",
      "[400]\ttraining's rmse: 0.0848157\tvalid_1's rmse: 0.087869\n",
      "[425]\ttraining's rmse: 0.0847533\tvalid_1's rmse: 0.0878493\n",
      "[450]\ttraining's rmse: 0.0846995\tvalid_1's rmse: 0.0878311\n",
      "[475]\ttraining's rmse: 0.0846469\tvalid_1's rmse: 0.0878139\n",
      "[500]\ttraining's rmse: 0.084601\tvalid_1's rmse: 0.0877962\n",
      "[525]\ttraining's rmse: 0.0845439\tvalid_1's rmse: 0.0877787\n",
      "[550]\ttraining's rmse: 0.0844918\tvalid_1's rmse: 0.0877638\n",
      "[575]\ttraining's rmse: 0.0844452\tvalid_1's rmse: 0.0877506\n",
      "[600]\ttraining's rmse: 0.0844014\tvalid_1's rmse: 0.0877386\n",
      "[625]\ttraining's rmse: 0.0843657\tvalid_1's rmse: 0.0877275\n",
      "[650]\ttraining's rmse: 0.0843173\tvalid_1's rmse: 0.0877148\n",
      "[675]\ttraining's rmse: 0.0842705\tvalid_1's rmse: 0.0877028\n",
      "[700]\ttraining's rmse: 0.0842312\tvalid_1's rmse: 0.0876921\n",
      "[725]\ttraining's rmse: 0.0841949\tvalid_1's rmse: 0.0876828\n",
      "[750]\ttraining's rmse: 0.084158\tvalid_1's rmse: 0.0876738\n",
      "[775]\ttraining's rmse: 0.0841307\tvalid_1's rmse: 0.087666\n",
      "[800]\ttraining's rmse: 0.0840929\tvalid_1's rmse: 0.0876588\n",
      "[825]\ttraining's rmse: 0.0840635\tvalid_1's rmse: 0.0876511\n",
      "[850]\ttraining's rmse: 0.0840334\tvalid_1's rmse: 0.0876441\n",
      "[875]\ttraining's rmse: 0.0840065\tvalid_1's rmse: 0.0876377\n",
      "[900]\ttraining's rmse: 0.0839748\tvalid_1's rmse: 0.0876306\n",
      "[925]\ttraining's rmse: 0.0839478\tvalid_1's rmse: 0.0876254\n",
      "[950]\ttraining's rmse: 0.0839247\tvalid_1's rmse: 0.0876199\n",
      "[975]\ttraining's rmse: 0.0838983\tvalid_1's rmse: 0.0876142\n",
      "[1000]\ttraining's rmse: 0.0838734\tvalid_1's rmse: 0.0876082\n",
      "[1025]\ttraining's rmse: 0.0838464\tvalid_1's rmse: 0.0876034\n",
      "[1050]\ttraining's rmse: 0.0838243\tvalid_1's rmse: 0.0875978\n",
      "[1075]\ttraining's rmse: 0.0838041\tvalid_1's rmse: 0.0875937\n",
      "[1100]\ttraining's rmse: 0.0837868\tvalid_1's rmse: 0.0875896\n",
      "[1125]\ttraining's rmse: 0.0837683\tvalid_1's rmse: 0.0875863\n",
      "[1150]\ttraining's rmse: 0.0837471\tvalid_1's rmse: 0.0875826\n",
      "[1175]\ttraining's rmse: 0.0837288\tvalid_1's rmse: 0.0875797\n",
      "[1200]\ttraining's rmse: 0.0837097\tvalid_1's rmse: 0.0875763\n",
      "[1225]\ttraining's rmse: 0.0836935\tvalid_1's rmse: 0.0875733\n",
      "[1250]\ttraining's rmse: 0.0836801\tvalid_1's rmse: 0.0875706\n",
      "[1275]\ttraining's rmse: 0.0836619\tvalid_1's rmse: 0.087568\n",
      "[1300]\ttraining's rmse: 0.0836482\tvalid_1's rmse: 0.0875654\n",
      "[1325]\ttraining's rmse: 0.0836342\tvalid_1's rmse: 0.0875637\n",
      "[1350]\ttraining's rmse: 0.0836201\tvalid_1's rmse: 0.0875616\n",
      "[1375]\ttraining's rmse: 0.0836063\tvalid_1's rmse: 0.0875602\n",
      "[1400]\ttraining's rmse: 0.0835949\tvalid_1's rmse: 0.0875576\n",
      "[1425]\ttraining's rmse: 0.083581\tvalid_1's rmse: 0.0875559\n",
      "[1450]\ttraining's rmse: 0.0835681\tvalid_1's rmse: 0.0875544\n",
      "[1475]\ttraining's rmse: 0.0835566\tvalid_1's rmse: 0.0875526\n",
      "[1500]\ttraining's rmse: 0.0835471\tvalid_1's rmse: 0.0875507\n",
      "[1525]\ttraining's rmse: 0.0835368\tvalid_1's rmse: 0.0875492\n",
      "[1550]\ttraining's rmse: 0.0835289\tvalid_1's rmse: 0.0875484\n",
      "[1575]\ttraining's rmse: 0.0835191\tvalid_1's rmse: 0.0875471\n",
      "[1600]\ttraining's rmse: 0.0835112\tvalid_1's rmse: 0.0875463\n",
      "[1625]\ttraining's rmse: 0.083502\tvalid_1's rmse: 0.0875448\n",
      "[1650]\ttraining's rmse: 0.0834931\tvalid_1's rmse: 0.0875443\n",
      "[1675]\ttraining's rmse: 0.0834863\tvalid_1's rmse: 0.0875427\n",
      "[1700]\ttraining's rmse: 0.0834795\tvalid_1's rmse: 0.087542\n",
      "[1725]\ttraining's rmse: 0.0834728\tvalid_1's rmse: 0.0875408\n",
      "[1750]\ttraining's rmse: 0.0834645\tvalid_1's rmse: 0.0875401\n",
      "[1775]\ttraining's rmse: 0.0834579\tvalid_1's rmse: 0.0875387\n",
      "[1800]\ttraining's rmse: 0.083451\tvalid_1's rmse: 0.0875376\n",
      "[1825]\ttraining's rmse: 0.0834434\tvalid_1's rmse: 0.0875362\n",
      "[1850]\ttraining's rmse: 0.0834375\tvalid_1's rmse: 0.0875355\n",
      "[1875]\ttraining's rmse: 0.0834326\tvalid_1's rmse: 0.087535\n",
      "[1900]\ttraining's rmse: 0.0834278\tvalid_1's rmse: 0.0875337\n",
      "[1925]\ttraining's rmse: 0.0834235\tvalid_1's rmse: 0.0875336\n",
      "[1950]\ttraining's rmse: 0.0834185\tvalid_1's rmse: 0.087533\n",
      "[1975]\ttraining's rmse: 0.0834124\tvalid_1's rmse: 0.0875319\n",
      "[2000]\ttraining's rmse: 0.0834092\tvalid_1's rmse: 0.0875316\n",
      "[2025]\ttraining's rmse: 0.0834051\tvalid_1's rmse: 0.087531\n",
      "[2050]\ttraining's rmse: 0.0833991\tvalid_1's rmse: 0.0875307\n",
      "[2075]\ttraining's rmse: 0.0833965\tvalid_1's rmse: 0.0875302\n",
      "[2100]\ttraining's rmse: 0.083393\tvalid_1's rmse: 0.0875298\n",
      "[2125]\ttraining's rmse: 0.0833884\tvalid_1's rmse: 0.0875293\n",
      "[2150]\ttraining's rmse: 0.0833829\tvalid_1's rmse: 0.0875286\n",
      "[2175]\ttraining's rmse: 0.0833802\tvalid_1's rmse: 0.0875285\n",
      "[2200]\ttraining's rmse: 0.0833769\tvalid_1's rmse: 0.0875281\n",
      "[2225]\ttraining's rmse: 0.0833742\tvalid_1's rmse: 0.0875278\n",
      "[2250]\ttraining's rmse: 0.0833712\tvalid_1's rmse: 0.0875276\n",
      "[2275]\ttraining's rmse: 0.083368\tvalid_1's rmse: 0.0875276\n",
      "[2300]\ttraining's rmse: 0.0833642\tvalid_1's rmse: 0.0875274\n",
      "[2325]\ttraining's rmse: 0.0833604\tvalid_1's rmse: 0.0875268\n",
      "[2350]\ttraining's rmse: 0.0833592\tvalid_1's rmse: 0.0875269\n",
      "Early stopping, best iteration is:\n",
      "[2310]\ttraining's rmse: 0.0833619\tvalid_1's rmse: 0.0875267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0884338\tvalid_1's rmse: 0.0838699\n",
      "[50]\ttraining's rmse: 0.0883143\tvalid_1's rmse: 0.0838208\n",
      "[75]\ttraining's rmse: 0.0881925\tvalid_1's rmse: 0.0837707\n",
      "[100]\ttraining's rmse: 0.0880852\tvalid_1's rmse: 0.0837295\n",
      "[125]\ttraining's rmse: 0.0879734\tvalid_1's rmse: 0.0836886\n",
      "[150]\ttraining's rmse: 0.0878714\tvalid_1's rmse: 0.0836522\n",
      "[175]\ttraining's rmse: 0.0877872\tvalid_1's rmse: 0.0836206\n",
      "[200]\ttraining's rmse: 0.0876953\tvalid_1's rmse: 0.0835886\n",
      "[225]\ttraining's rmse: 0.0876077\tvalid_1's rmse: 0.0835576\n",
      "[250]\ttraining's rmse: 0.0875311\tvalid_1's rmse: 0.083532\n",
      "[275]\ttraining's rmse: 0.0874603\tvalid_1's rmse: 0.0835071\n",
      "[300]\ttraining's rmse: 0.0873919\tvalid_1's rmse: 0.0834836\n",
      "[325]\ttraining's rmse: 0.0873239\tvalid_1's rmse: 0.0834629\n",
      "[350]\ttraining's rmse: 0.0872555\tvalid_1's rmse: 0.0834423\n",
      "[375]\ttraining's rmse: 0.0871993\tvalid_1's rmse: 0.0834244\n",
      "[400]\ttraining's rmse: 0.0871386\tvalid_1's rmse: 0.0834108\n",
      "[425]\ttraining's rmse: 0.0870817\tvalid_1's rmse: 0.0833946\n",
      "[450]\ttraining's rmse: 0.0870297\tvalid_1's rmse: 0.0833815\n",
      "[475]\ttraining's rmse: 0.086979\tvalid_1's rmse: 0.0833713\n",
      "[500]\ttraining's rmse: 0.0869366\tvalid_1's rmse: 0.08336\n",
      "[525]\ttraining's rmse: 0.0868805\tvalid_1's rmse: 0.0833509\n",
      "[550]\ttraining's rmse: 0.0868312\tvalid_1's rmse: 0.0833386\n",
      "[575]\ttraining's rmse: 0.0867864\tvalid_1's rmse: 0.0833281\n",
      "[600]\ttraining's rmse: 0.0867402\tvalid_1's rmse: 0.0833265\n",
      "[625]\ttraining's rmse: 0.0867044\tvalid_1's rmse: 0.0833223\n",
      "[650]\ttraining's rmse: 0.0866578\tvalid_1's rmse: 0.0833303\n",
      "[675]\ttraining's rmse: 0.0866128\tvalid_1's rmse: 0.0833261\n",
      "Early stopping, best iteration is:\n",
      "[627]\ttraining's rmse: 0.0867026\tvalid_1's rmse: 0.0833214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0893895\tvalid_1's rmse: 0.0911111\n",
      "[50]\ttraining's rmse: 0.0892032\tvalid_1's rmse: 0.0910588\n",
      "[75]\ttraining's rmse: 0.0890265\tvalid_1's rmse: 0.0910067\n",
      "[100]\ttraining's rmse: 0.0888604\tvalid_1's rmse: 0.09096\n",
      "[125]\ttraining's rmse: 0.0886962\tvalid_1's rmse: 0.0909129\n",
      "[150]\ttraining's rmse: 0.0885468\tvalid_1's rmse: 0.0908698\n",
      "[175]\ttraining's rmse: 0.0884174\tvalid_1's rmse: 0.0908309\n",
      "[200]\ttraining's rmse: 0.0882807\tvalid_1's rmse: 0.0907911\n",
      "[225]\ttraining's rmse: 0.0881534\tvalid_1's rmse: 0.0907541\n",
      "[250]\ttraining's rmse: 0.088043\tvalid_1's rmse: 0.0907201\n",
      "[275]\ttraining's rmse: 0.0879354\tvalid_1's rmse: 0.0906906\n",
      "[300]\ttraining's rmse: 0.0878327\tvalid_1's rmse: 0.0906635\n",
      "[325]\ttraining's rmse: 0.0877338\tvalid_1's rmse: 0.0906362\n",
      "[350]\ttraining's rmse: 0.0876351\tvalid_1's rmse: 0.0906107\n",
      "[375]\ttraining's rmse: 0.0875502\tvalid_1's rmse: 0.0905901\n",
      "[400]\ttraining's rmse: 0.0874637\tvalid_1's rmse: 0.0905688\n",
      "[425]\ttraining's rmse: 0.0873839\tvalid_1's rmse: 0.0905472\n",
      "[450]\ttraining's rmse: 0.0873126\tvalid_1's rmse: 0.0905265\n",
      "[475]\ttraining's rmse: 0.0872475\tvalid_1's rmse: 0.090508\n",
      "[500]\ttraining's rmse: 0.0871893\tvalid_1's rmse: 0.0904913\n",
      "[525]\ttraining's rmse: 0.0871195\tvalid_1's rmse: 0.0904722\n",
      "[550]\ttraining's rmse: 0.0870604\tvalid_1's rmse: 0.0904577\n",
      "[575]\ttraining's rmse: 0.0869987\tvalid_1's rmse: 0.0904418\n",
      "[600]\ttraining's rmse: 0.0869443\tvalid_1's rmse: 0.090428\n",
      "[625]\ttraining's rmse: 0.0868956\tvalid_1's rmse: 0.0904145\n",
      "[650]\ttraining's rmse: 0.0868435\tvalid_1's rmse: 0.0904007\n",
      "[675]\ttraining's rmse: 0.0867913\tvalid_1's rmse: 0.0903882\n",
      "[700]\ttraining's rmse: 0.0867438\tvalid_1's rmse: 0.0903778\n",
      "[725]\ttraining's rmse: 0.0867018\tvalid_1's rmse: 0.090367\n",
      "[750]\ttraining's rmse: 0.0866604\tvalid_1's rmse: 0.0903556\n",
      "[775]\ttraining's rmse: 0.0866256\tvalid_1's rmse: 0.0903462\n",
      "[800]\ttraining's rmse: 0.0865822\tvalid_1's rmse: 0.0903363\n",
      "[825]\ttraining's rmse: 0.0865475\tvalid_1's rmse: 0.090327\n",
      "[850]\ttraining's rmse: 0.0865083\tvalid_1's rmse: 0.0903181\n",
      "[875]\ttraining's rmse: 0.0864757\tvalid_1's rmse: 0.0903105\n",
      "[900]\ttraining's rmse: 0.0864419\tvalid_1's rmse: 0.090303\n",
      "[925]\ttraining's rmse: 0.0864107\tvalid_1's rmse: 0.0902959\n",
      "[950]\ttraining's rmse: 0.0863797\tvalid_1's rmse: 0.0902865\n",
      "[975]\ttraining's rmse: 0.0863516\tvalid_1's rmse: 0.0902804\n",
      "[1000]\ttraining's rmse: 0.0863245\tvalid_1's rmse: 0.0902737\n",
      "[1025]\ttraining's rmse: 0.086296\tvalid_1's rmse: 0.0902687\n",
      "[1050]\ttraining's rmse: 0.0862713\tvalid_1's rmse: 0.0902615\n",
      "[1075]\ttraining's rmse: 0.0862466\tvalid_1's rmse: 0.0902566\n",
      "[1100]\ttraining's rmse: 0.0862258\tvalid_1's rmse: 0.0902515\n",
      "[1125]\ttraining's rmse: 0.0862034\tvalid_1's rmse: 0.0902456\n",
      "[1150]\ttraining's rmse: 0.086179\tvalid_1's rmse: 0.0902398\n",
      "[1175]\ttraining's rmse: 0.086158\tvalid_1's rmse: 0.0902368\n",
      "[1200]\ttraining's rmse: 0.0861401\tvalid_1's rmse: 0.0902305\n",
      "[1225]\ttraining's rmse: 0.0861211\tvalid_1's rmse: 0.0902264\n",
      "[1250]\ttraining's rmse: 0.0861038\tvalid_1's rmse: 0.0902213\n",
      "[1275]\ttraining's rmse: 0.0860855\tvalid_1's rmse: 0.0902184\n",
      "[1300]\ttraining's rmse: 0.0860689\tvalid_1's rmse: 0.0902146\n",
      "[1325]\ttraining's rmse: 0.0860524\tvalid_1's rmse: 0.0902107\n",
      "[1350]\ttraining's rmse: 0.0860358\tvalid_1's rmse: 0.0902083\n",
      "[1375]\ttraining's rmse: 0.0860187\tvalid_1's rmse: 0.0902045\n",
      "[1400]\ttraining's rmse: 0.0860046\tvalid_1's rmse: 0.0902\n",
      "[1425]\ttraining's rmse: 0.0859897\tvalid_1's rmse: 0.0901983\n",
      "[1450]\ttraining's rmse: 0.0859758\tvalid_1's rmse: 0.0901941\n",
      "[1475]\ttraining's rmse: 0.0859618\tvalid_1's rmse: 0.0901915\n",
      "[1500]\ttraining's rmse: 0.0859496\tvalid_1's rmse: 0.0901873\n",
      "[1525]\ttraining's rmse: 0.0859386\tvalid_1's rmse: 0.0901846\n",
      "[1550]\ttraining's rmse: 0.0859275\tvalid_1's rmse: 0.0901823\n",
      "[1575]\ttraining's rmse: 0.0859175\tvalid_1's rmse: 0.090179\n",
      "[1600]\ttraining's rmse: 0.0859081\tvalid_1's rmse: 0.0901771\n",
      "[1625]\ttraining's rmse: 0.0858979\tvalid_1's rmse: 0.090173\n",
      "[1650]\ttraining's rmse: 0.0858875\tvalid_1's rmse: 0.0901686\n",
      "[1675]\ttraining's rmse: 0.0858796\tvalid_1's rmse: 0.0901652\n",
      "[1700]\ttraining's rmse: 0.0858733\tvalid_1's rmse: 0.0901637\n",
      "[1725]\ttraining's rmse: 0.0858643\tvalid_1's rmse: 0.0901615\n",
      "[1750]\ttraining's rmse: 0.0858573\tvalid_1's rmse: 0.0901589\n",
      "[1775]\ttraining's rmse: 0.0858492\tvalid_1's rmse: 0.0901576\n",
      "[1800]\ttraining's rmse: 0.0858427\tvalid_1's rmse: 0.0901557\n",
      "[1825]\ttraining's rmse: 0.0858369\tvalid_1's rmse: 0.090154\n",
      "[1850]\ttraining's rmse: 0.0858308\tvalid_1's rmse: 0.0901523\n",
      "[1875]\ttraining's rmse: 0.0858237\tvalid_1's rmse: 0.090151\n",
      "[1900]\ttraining's rmse: 0.0858179\tvalid_1's rmse: 0.0901496\n",
      "[1925]\ttraining's rmse: 0.0858127\tvalid_1's rmse: 0.0901482\n",
      "[1950]\ttraining's rmse: 0.085808\tvalid_1's rmse: 0.090145\n",
      "[1975]\ttraining's rmse: 0.0858024\tvalid_1's rmse: 0.0901432\n",
      "[2000]\ttraining's rmse: 0.0857985\tvalid_1's rmse: 0.0901421\n",
      "[2025]\ttraining's rmse: 0.0857937\tvalid_1's rmse: 0.09014\n",
      "[2050]\ttraining's rmse: 0.0857891\tvalid_1's rmse: 0.0901387\n",
      "[2075]\ttraining's rmse: 0.0857854\tvalid_1's rmse: 0.0901372\n",
      "[2100]\ttraining's rmse: 0.0857824\tvalid_1's rmse: 0.0901366\n",
      "[2125]\ttraining's rmse: 0.0857784\tvalid_1's rmse: 0.0901353\n",
      "[2150]\ttraining's rmse: 0.0857732\tvalid_1's rmse: 0.0901349\n",
      "[2175]\ttraining's rmse: 0.0857694\tvalid_1's rmse: 0.0901336\n",
      "[2200]\ttraining's rmse: 0.0857664\tvalid_1's rmse: 0.0901327\n",
      "[2225]\ttraining's rmse: 0.0857628\tvalid_1's rmse: 0.0901312\n",
      "[2250]\ttraining's rmse: 0.0857575\tvalid_1's rmse: 0.0901294\n",
      "[2275]\ttraining's rmse: 0.0857527\tvalid_1's rmse: 0.090129\n",
      "[2300]\ttraining's rmse: 0.0857484\tvalid_1's rmse: 0.0901277\n",
      "[2325]\ttraining's rmse: 0.0857447\tvalid_1's rmse: 0.0901265\n",
      "[2350]\ttraining's rmse: 0.0857424\tvalid_1's rmse: 0.0901255\n",
      "[2375]\ttraining's rmse: 0.0857399\tvalid_1's rmse: 0.0901244\n",
      "[2400]\ttraining's rmse: 0.0857366\tvalid_1's rmse: 0.090123\n",
      "[2425]\ttraining's rmse: 0.0857337\tvalid_1's rmse: 0.0901223\n",
      "[2450]\ttraining's rmse: 0.0857307\tvalid_1's rmse: 0.0901223\n",
      "[2475]\ttraining's rmse: 0.0857284\tvalid_1's rmse: 0.0901214\n",
      "[2500]\ttraining's rmse: 0.0857263\tvalid_1's rmse: 0.0901212\n",
      "[2525]\ttraining's rmse: 0.0857235\tvalid_1's rmse: 0.0901203\n",
      "[2550]\ttraining's rmse: 0.0857208\tvalid_1's rmse: 0.0901193\n",
      "[2575]\ttraining's rmse: 0.0857183\tvalid_1's rmse: 0.0901184\n",
      "[2600]\ttraining's rmse: 0.0857151\tvalid_1's rmse: 0.0901176\n",
      "[2625]\ttraining's rmse: 0.0857136\tvalid_1's rmse: 0.0901165\n",
      "[2650]\ttraining's rmse: 0.0857108\tvalid_1's rmse: 0.090116\n",
      "[2675]\ttraining's rmse: 0.0857082\tvalid_1's rmse: 0.0901156\n",
      "[2700]\ttraining's rmse: 0.0857058\tvalid_1's rmse: 0.0901146\n",
      "[2725]\ttraining's rmse: 0.0857035\tvalid_1's rmse: 0.0901135\n",
      "[2750]\ttraining's rmse: 0.0857003\tvalid_1's rmse: 0.0901124\n",
      "[2775]\ttraining's rmse: 0.0856984\tvalid_1's rmse: 0.0901118\n",
      "[2800]\ttraining's rmse: 0.0856961\tvalid_1's rmse: 0.0901117\n",
      "[2825]\ttraining's rmse: 0.085694\tvalid_1's rmse: 0.0901113\n",
      "[2850]\ttraining's rmse: 0.0856915\tvalid_1's rmse: 0.090111\n",
      "[2875]\ttraining's rmse: 0.0856906\tvalid_1's rmse: 0.0901112\n",
      "[2900]\ttraining's rmse: 0.0856888\tvalid_1's rmse: 0.0901106\n",
      "[2925]\ttraining's rmse: 0.0856876\tvalid_1's rmse: 0.0901103\n",
      "[2950]\ttraining's rmse: 0.0856864\tvalid_1's rmse: 0.0901101\n",
      "[2975]\ttraining's rmse: 0.0856842\tvalid_1's rmse: 0.0901095\n",
      "[3000]\ttraining's rmse: 0.0856823\tvalid_1's rmse: 0.0901091\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0856823\tvalid_1's rmse: 0.0901091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0893068\tvalid_1's rmse: 0.0912867\n",
      "[50]\ttraining's rmse: 0.0891414\tvalid_1's rmse: 0.0912326\n",
      "[75]\ttraining's rmse: 0.08897\tvalid_1's rmse: 0.0911775\n",
      "[100]\ttraining's rmse: 0.0888169\tvalid_1's rmse: 0.09113\n",
      "[125]\ttraining's rmse: 0.0886606\tvalid_1's rmse: 0.0910816\n",
      "[150]\ttraining's rmse: 0.0885187\tvalid_1's rmse: 0.0910353\n",
      "[175]\ttraining's rmse: 0.0883994\tvalid_1's rmse: 0.0909986\n",
      "[200]\ttraining's rmse: 0.0882715\tvalid_1's rmse: 0.0909604\n",
      "[225]\ttraining's rmse: 0.0881532\tvalid_1's rmse: 0.0909266\n",
      "[250]\ttraining's rmse: 0.0880466\tvalid_1's rmse: 0.0908926\n",
      "[275]\ttraining's rmse: 0.0879501\tvalid_1's rmse: 0.0908622\n",
      "[300]\ttraining's rmse: 0.0878539\tvalid_1's rmse: 0.0908348\n",
      "[325]\ttraining's rmse: 0.0877589\tvalid_1's rmse: 0.0908071\n",
      "[350]\ttraining's rmse: 0.0876689\tvalid_1's rmse: 0.0907822\n",
      "[375]\ttraining's rmse: 0.0875942\tvalid_1's rmse: 0.0907615\n",
      "[400]\ttraining's rmse: 0.0875151\tvalid_1's rmse: 0.0907404\n",
      "[425]\ttraining's rmse: 0.0874381\tvalid_1's rmse: 0.0907187\n",
      "[450]\ttraining's rmse: 0.0873733\tvalid_1's rmse: 0.0907015\n",
      "[475]\ttraining's rmse: 0.0873131\tvalid_1's rmse: 0.0906834\n",
      "[500]\ttraining's rmse: 0.0872621\tvalid_1's rmse: 0.0906673\n",
      "[525]\ttraining's rmse: 0.0871965\tvalid_1's rmse: 0.0906502\n",
      "[550]\ttraining's rmse: 0.0871348\tvalid_1's rmse: 0.0906351\n",
      "[575]\ttraining's rmse: 0.0870786\tvalid_1's rmse: 0.0906205\n",
      "[600]\ttraining's rmse: 0.0870272\tvalid_1's rmse: 0.0906071\n",
      "[625]\ttraining's rmse: 0.086984\tvalid_1's rmse: 0.0905946\n",
      "[650]\ttraining's rmse: 0.0869311\tvalid_1's rmse: 0.0905812\n",
      "[675]\ttraining's rmse: 0.0868802\tvalid_1's rmse: 0.0905692\n",
      "[700]\ttraining's rmse: 0.0868358\tvalid_1's rmse: 0.090558\n",
      "[725]\ttraining's rmse: 0.086795\tvalid_1's rmse: 0.0905477\n",
      "[750]\ttraining's rmse: 0.0867567\tvalid_1's rmse: 0.0905385\n",
      "[775]\ttraining's rmse: 0.0867243\tvalid_1's rmse: 0.0905292\n",
      "[800]\ttraining's rmse: 0.0866817\tvalid_1's rmse: 0.0905203\n",
      "[825]\ttraining's rmse: 0.0866485\tvalid_1's rmse: 0.0905124\n",
      "[850]\ttraining's rmse: 0.0866137\tvalid_1's rmse: 0.0905056\n",
      "[875]\ttraining's rmse: 0.086582\tvalid_1's rmse: 0.0904987\n",
      "[900]\ttraining's rmse: 0.0865482\tvalid_1's rmse: 0.0904915\n",
      "[925]\ttraining's rmse: 0.0865174\tvalid_1's rmse: 0.0904859\n",
      "[950]\ttraining's rmse: 0.0864879\tvalid_1's rmse: 0.0904803\n",
      "[975]\ttraining's rmse: 0.0864594\tvalid_1's rmse: 0.0904739\n",
      "[1000]\ttraining's rmse: 0.0864327\tvalid_1's rmse: 0.0904678\n",
      "[1025]\ttraining's rmse: 0.0864033\tvalid_1's rmse: 0.0904631\n",
      "[1050]\ttraining's rmse: 0.0863805\tvalid_1's rmse: 0.0904585\n",
      "[1075]\ttraining's rmse: 0.0863539\tvalid_1's rmse: 0.0904549\n",
      "[1100]\ttraining's rmse: 0.0863325\tvalid_1's rmse: 0.0904504\n",
      "[1125]\ttraining's rmse: 0.0863087\tvalid_1's rmse: 0.0904462\n",
      "[1150]\ttraining's rmse: 0.0862865\tvalid_1's rmse: 0.090442\n",
      "[1175]\ttraining's rmse: 0.0862683\tvalid_1's rmse: 0.0904393\n",
      "[1200]\ttraining's rmse: 0.0862493\tvalid_1's rmse: 0.0904354\n",
      "[1225]\ttraining's rmse: 0.086231\tvalid_1's rmse: 0.0904328\n",
      "[1250]\ttraining's rmse: 0.0862118\tvalid_1's rmse: 0.0904302\n",
      "[1275]\ttraining's rmse: 0.0861925\tvalid_1's rmse: 0.0904277\n",
      "[1300]\ttraining's rmse: 0.0861769\tvalid_1's rmse: 0.0904249\n",
      "[1325]\ttraining's rmse: 0.0861594\tvalid_1's rmse: 0.090423\n",
      "[1350]\ttraining's rmse: 0.0861438\tvalid_1's rmse: 0.090422\n",
      "[1375]\ttraining's rmse: 0.0861266\tvalid_1's rmse: 0.0904195\n",
      "[1400]\ttraining's rmse: 0.0861153\tvalid_1's rmse: 0.0904177\n",
      "[1425]\ttraining's rmse: 0.0861011\tvalid_1's rmse: 0.0904165\n",
      "[1450]\ttraining's rmse: 0.0860866\tvalid_1's rmse: 0.0904163\n",
      "[1475]\ttraining's rmse: 0.0860752\tvalid_1's rmse: 0.090415\n",
      "[1500]\ttraining's rmse: 0.0860639\tvalid_1's rmse: 0.0904137\n",
      "[1525]\ttraining's rmse: 0.086052\tvalid_1's rmse: 0.0904119\n",
      "[1550]\ttraining's rmse: 0.0860381\tvalid_1's rmse: 0.0904113\n",
      "[1575]\ttraining's rmse: 0.0860271\tvalid_1's rmse: 0.0904103\n",
      "[1600]\ttraining's rmse: 0.0860181\tvalid_1's rmse: 0.0904089\n",
      "[1625]\ttraining's rmse: 0.086007\tvalid_1's rmse: 0.0904071\n",
      "[1650]\ttraining's rmse: 0.0859973\tvalid_1's rmse: 0.0904063\n",
      "[1675]\ttraining's rmse: 0.0859901\tvalid_1's rmse: 0.0904055\n",
      "[1700]\ttraining's rmse: 0.0859829\tvalid_1's rmse: 0.090404\n",
      "[1725]\ttraining's rmse: 0.0859745\tvalid_1's rmse: 0.0904033\n",
      "[1750]\ttraining's rmse: 0.0859652\tvalid_1's rmse: 0.090403\n",
      "[1775]\ttraining's rmse: 0.0859577\tvalid_1's rmse: 0.0904017\n",
      "[1800]\ttraining's rmse: 0.0859503\tvalid_1's rmse: 0.0904009\n",
      "[1825]\ttraining's rmse: 0.0859434\tvalid_1's rmse: 0.0903999\n",
      "[1850]\ttraining's rmse: 0.0859375\tvalid_1's rmse: 0.0903991\n",
      "[1875]\ttraining's rmse: 0.0859299\tvalid_1's rmse: 0.0903982\n",
      "[1900]\ttraining's rmse: 0.0859239\tvalid_1's rmse: 0.0903979\n",
      "[1925]\ttraining's rmse: 0.0859188\tvalid_1's rmse: 0.0903973\n",
      "[1950]\ttraining's rmse: 0.0859149\tvalid_1's rmse: 0.0903968\n",
      "[1975]\ttraining's rmse: 0.0859108\tvalid_1's rmse: 0.0903964\n",
      "[2000]\ttraining's rmse: 0.0859053\tvalid_1's rmse: 0.090396\n",
      "[2025]\ttraining's rmse: 0.0858995\tvalid_1's rmse: 0.0903947\n",
      "[2050]\ttraining's rmse: 0.0858916\tvalid_1's rmse: 0.0903944\n",
      "[2075]\ttraining's rmse: 0.0858875\tvalid_1's rmse: 0.0903938\n",
      "[2100]\ttraining's rmse: 0.0858836\tvalid_1's rmse: 0.0903936\n",
      "[2125]\ttraining's rmse: 0.0858806\tvalid_1's rmse: 0.0903935\n",
      "[2150]\ttraining's rmse: 0.0858777\tvalid_1's rmse: 0.0903932\n",
      "[2175]\ttraining's rmse: 0.0858742\tvalid_1's rmse: 0.0903935\n",
      "Early stopping, best iteration is:\n",
      "[2149]\ttraining's rmse: 0.0858777\tvalid_1's rmse: 0.0903932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0910587\tvalid_1's rmse: 0.0878204\n",
      "[50]\ttraining's rmse: 0.0909289\tvalid_1's rmse: 0.0877736\n",
      "[75]\ttraining's rmse: 0.0907907\tvalid_1's rmse: 0.0877245\n",
      "[100]\ttraining's rmse: 0.0906703\tvalid_1's rmse: 0.0876828\n",
      "[125]\ttraining's rmse: 0.090544\tvalid_1's rmse: 0.0876421\n",
      "[150]\ttraining's rmse: 0.0904295\tvalid_1's rmse: 0.0876046\n",
      "[175]\ttraining's rmse: 0.0903323\tvalid_1's rmse: 0.0875742\n",
      "[200]\ttraining's rmse: 0.090226\tvalid_1's rmse: 0.0875436\n",
      "[225]\ttraining's rmse: 0.0901241\tvalid_1's rmse: 0.0875136\n",
      "[250]\ttraining's rmse: 0.0900385\tvalid_1's rmse: 0.0874877\n",
      "[275]\ttraining's rmse: 0.0899597\tvalid_1's rmse: 0.087464\n",
      "[300]\ttraining's rmse: 0.0898818\tvalid_1's rmse: 0.087441\n",
      "[325]\ttraining's rmse: 0.0898045\tvalid_1's rmse: 0.0874203\n",
      "[350]\ttraining's rmse: 0.0897273\tvalid_1's rmse: 0.0873997\n",
      "[375]\ttraining's rmse: 0.0896648\tvalid_1's rmse: 0.0873882\n",
      "[400]\ttraining's rmse: 0.0895958\tvalid_1's rmse: 0.0873706\n",
      "[425]\ttraining's rmse: 0.0895315\tvalid_1's rmse: 0.0873542\n",
      "[450]\ttraining's rmse: 0.089474\tvalid_1's rmse: 0.0873385\n",
      "[475]\ttraining's rmse: 0.0894172\tvalid_1's rmse: 0.0873248\n",
      "[500]\ttraining's rmse: 0.0893712\tvalid_1's rmse: 0.0873121\n",
      "[525]\ttraining's rmse: 0.0893091\tvalid_1's rmse: 0.087299\n",
      "[550]\ttraining's rmse: 0.0892566\tvalid_1's rmse: 0.0872866\n",
      "[575]\ttraining's rmse: 0.0892055\tvalid_1's rmse: 0.0872759\n",
      "[600]\ttraining's rmse: 0.0891557\tvalid_1's rmse: 0.0872709\n",
      "[625]\ttraining's rmse: 0.0891156\tvalid_1's rmse: 0.0872614\n",
      "[650]\ttraining's rmse: 0.0890629\tvalid_1's rmse: 0.087258\n",
      "[675]\ttraining's rmse: 0.0890115\tvalid_1's rmse: 0.0872509\n",
      "[700]\ttraining's rmse: 0.0889681\tvalid_1's rmse: 0.08725\n",
      "[725]\ttraining's rmse: 0.0889261\tvalid_1's rmse: 0.0872533\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0889797\tvalid_1's rmse: 0.087246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0865269\tvalid_1's rmse: 0.0891162\n",
      "[50]\ttraining's rmse: 0.0863859\tvalid_1's rmse: 0.0890595\n",
      "[75]\ttraining's rmse: 0.0862486\tvalid_1's rmse: 0.0890047\n",
      "[100]\ttraining's rmse: 0.0861229\tvalid_1's rmse: 0.0889573\n",
      "[125]\ttraining's rmse: 0.085997\tvalid_1's rmse: 0.0889096\n",
      "[150]\ttraining's rmse: 0.085882\tvalid_1's rmse: 0.0888636\n",
      "[175]\ttraining's rmse: 0.0857861\tvalid_1's rmse: 0.088826\n",
      "[200]\ttraining's rmse: 0.0856875\tvalid_1's rmse: 0.088789\n",
      "[225]\ttraining's rmse: 0.0855884\tvalid_1's rmse: 0.088752\n",
      "[250]\ttraining's rmse: 0.0855036\tvalid_1's rmse: 0.0887179\n",
      "[275]\ttraining's rmse: 0.0854271\tvalid_1's rmse: 0.0886879\n",
      "[300]\ttraining's rmse: 0.0853515\tvalid_1's rmse: 0.0886579\n",
      "[325]\ttraining's rmse: 0.0852752\tvalid_1's rmse: 0.0886309\n",
      "[350]\ttraining's rmse: 0.0852019\tvalid_1's rmse: 0.0886038\n",
      "[375]\ttraining's rmse: 0.0851362\tvalid_1's rmse: 0.088582\n",
      "[400]\ttraining's rmse: 0.0850689\tvalid_1's rmse: 0.0885581\n",
      "[425]\ttraining's rmse: 0.0850086\tvalid_1's rmse: 0.0885358\n",
      "[450]\ttraining's rmse: 0.0849534\tvalid_1's rmse: 0.0885159\n",
      "[475]\ttraining's rmse: 0.0848992\tvalid_1's rmse: 0.0884932\n",
      "[500]\ttraining's rmse: 0.0848534\tvalid_1's rmse: 0.0884764\n",
      "[525]\ttraining's rmse: 0.0847988\tvalid_1's rmse: 0.0884586\n",
      "[550]\ttraining's rmse: 0.0847457\tvalid_1's rmse: 0.0884421\n",
      "[575]\ttraining's rmse: 0.0846979\tvalid_1's rmse: 0.0884303\n",
      "[600]\ttraining's rmse: 0.0846511\tvalid_1's rmse: 0.0884152\n",
      "[625]\ttraining's rmse: 0.0846122\tvalid_1's rmse: 0.088404\n",
      "[650]\ttraining's rmse: 0.0845669\tvalid_1's rmse: 0.0883913\n",
      "[675]\ttraining's rmse: 0.0845244\tvalid_1's rmse: 0.0883768\n",
      "[700]\ttraining's rmse: 0.0844855\tvalid_1's rmse: 0.0883639\n",
      "[725]\ttraining's rmse: 0.0844484\tvalid_1's rmse: 0.0883528\n",
      "[750]\ttraining's rmse: 0.0844135\tvalid_1's rmse: 0.0883433\n",
      "[775]\ttraining's rmse: 0.0843845\tvalid_1's rmse: 0.0883313\n",
      "[800]\ttraining's rmse: 0.0843466\tvalid_1's rmse: 0.0883215\n",
      "[825]\ttraining's rmse: 0.0843164\tvalid_1's rmse: 0.0883118\n",
      "[850]\ttraining's rmse: 0.0842832\tvalid_1's rmse: 0.0883048\n",
      "[875]\ttraining's rmse: 0.0842563\tvalid_1's rmse: 0.0882956\n",
      "[900]\ttraining's rmse: 0.0842269\tvalid_1's rmse: 0.0882886\n",
      "[925]\ttraining's rmse: 0.0842018\tvalid_1's rmse: 0.0882824\n",
      "[950]\ttraining's rmse: 0.0841777\tvalid_1's rmse: 0.0882752\n",
      "[975]\ttraining's rmse: 0.0841525\tvalid_1's rmse: 0.0882687\n",
      "[1000]\ttraining's rmse: 0.0841267\tvalid_1's rmse: 0.0882618\n",
      "[1025]\ttraining's rmse: 0.0841023\tvalid_1's rmse: 0.088255\n",
      "[1050]\ttraining's rmse: 0.0840806\tvalid_1's rmse: 0.0882469\n",
      "[1075]\ttraining's rmse: 0.0840606\tvalid_1's rmse: 0.0882419\n",
      "[1100]\ttraining's rmse: 0.0840437\tvalid_1's rmse: 0.0882372\n",
      "[1125]\ttraining's rmse: 0.0840249\tvalid_1's rmse: 0.0882318\n",
      "[1150]\ttraining's rmse: 0.0840014\tvalid_1's rmse: 0.088226\n",
      "[1175]\ttraining's rmse: 0.0839817\tvalid_1's rmse: 0.0882214\n",
      "[1200]\ttraining's rmse: 0.0839624\tvalid_1's rmse: 0.0882167\n",
      "[1225]\ttraining's rmse: 0.0839446\tvalid_1's rmse: 0.0882122\n",
      "[1250]\ttraining's rmse: 0.0839287\tvalid_1's rmse: 0.0882074\n",
      "[1275]\ttraining's rmse: 0.0839092\tvalid_1's rmse: 0.0882032\n",
      "[1300]\ttraining's rmse: 0.0838971\tvalid_1's rmse: 0.0881979\n",
      "[1325]\ttraining's rmse: 0.0838813\tvalid_1's rmse: 0.0881946\n",
      "[1350]\ttraining's rmse: 0.0838664\tvalid_1's rmse: 0.0881918\n",
      "[1375]\ttraining's rmse: 0.083852\tvalid_1's rmse: 0.0881887\n",
      "[1400]\ttraining's rmse: 0.0838402\tvalid_1's rmse: 0.0881851\n",
      "[1425]\ttraining's rmse: 0.0838263\tvalid_1's rmse: 0.0881834\n",
      "[1450]\ttraining's rmse: 0.0838129\tvalid_1's rmse: 0.0881798\n",
      "[1475]\ttraining's rmse: 0.0838029\tvalid_1's rmse: 0.0881762\n",
      "[1500]\ttraining's rmse: 0.0837921\tvalid_1's rmse: 0.0881742\n",
      "[1525]\ttraining's rmse: 0.0837805\tvalid_1's rmse: 0.0881701\n",
      "[1550]\ttraining's rmse: 0.08377\tvalid_1's rmse: 0.0881684\n",
      "[1575]\ttraining's rmse: 0.0837609\tvalid_1's rmse: 0.0881659\n",
      "[1600]\ttraining's rmse: 0.0837537\tvalid_1's rmse: 0.0881633\n",
      "[1625]\ttraining's rmse: 0.0837446\tvalid_1's rmse: 0.0881598\n",
      "[1650]\ttraining's rmse: 0.0837347\tvalid_1's rmse: 0.0881573\n",
      "[1675]\ttraining's rmse: 0.0837272\tvalid_1's rmse: 0.0881548\n",
      "[1700]\ttraining's rmse: 0.0837203\tvalid_1's rmse: 0.088153\n",
      "[1725]\ttraining's rmse: 0.0837145\tvalid_1's rmse: 0.0881511\n",
      "[1750]\ttraining's rmse: 0.0837038\tvalid_1's rmse: 0.0881476\n",
      "[1775]\ttraining's rmse: 0.0836985\tvalid_1's rmse: 0.0881467\n",
      "[1800]\ttraining's rmse: 0.0836924\tvalid_1's rmse: 0.0881457\n",
      "[1825]\ttraining's rmse: 0.0836866\tvalid_1's rmse: 0.088143\n",
      "[1850]\ttraining's rmse: 0.0836804\tvalid_1's rmse: 0.0881407\n",
      "[1875]\ttraining's rmse: 0.0836758\tvalid_1's rmse: 0.0881386\n",
      "[1900]\ttraining's rmse: 0.0836714\tvalid_1's rmse: 0.0881367\n",
      "[1925]\ttraining's rmse: 0.0836674\tvalid_1's rmse: 0.0881354\n",
      "[1950]\ttraining's rmse: 0.0836621\tvalid_1's rmse: 0.0881343\n",
      "[1975]\ttraining's rmse: 0.0836583\tvalid_1's rmse: 0.0881332\n",
      "[2000]\ttraining's rmse: 0.0836544\tvalid_1's rmse: 0.0881321\n",
      "[2025]\ttraining's rmse: 0.0836508\tvalid_1's rmse: 0.088131\n",
      "[2050]\ttraining's rmse: 0.083647\tvalid_1's rmse: 0.088129\n",
      "[2075]\ttraining's rmse: 0.0836428\tvalid_1's rmse: 0.088129\n",
      "[2100]\ttraining's rmse: 0.0836387\tvalid_1's rmse: 0.0881273\n",
      "[2125]\ttraining's rmse: 0.0836357\tvalid_1's rmse: 0.0881266\n",
      "[2150]\ttraining's rmse: 0.0836325\tvalid_1's rmse: 0.0881266\n",
      "[2175]\ttraining's rmse: 0.0836278\tvalid_1's rmse: 0.0881254\n",
      "[2200]\ttraining's rmse: 0.0836247\tvalid_1's rmse: 0.0881252\n",
      "[2225]\ttraining's rmse: 0.0836212\tvalid_1's rmse: 0.0881241\n",
      "[2250]\ttraining's rmse: 0.0836168\tvalid_1's rmse: 0.0881233\n",
      "[2275]\ttraining's rmse: 0.0836144\tvalid_1's rmse: 0.088123\n",
      "[2300]\ttraining's rmse: 0.0836113\tvalid_1's rmse: 0.0881226\n",
      "[2325]\ttraining's rmse: 0.0836068\tvalid_1's rmse: 0.0881213\n",
      "[2350]\ttraining's rmse: 0.0836034\tvalid_1's rmse: 0.0881204\n",
      "[2375]\ttraining's rmse: 0.0836003\tvalid_1's rmse: 0.088119\n",
      "[2400]\ttraining's rmse: 0.0835961\tvalid_1's rmse: 0.0881185\n",
      "[2425]\ttraining's rmse: 0.0835931\tvalid_1's rmse: 0.0881179\n",
      "[2450]\ttraining's rmse: 0.0835912\tvalid_1's rmse: 0.0881175\n",
      "[2475]\ttraining's rmse: 0.083588\tvalid_1's rmse: 0.0881166\n",
      "[2500]\ttraining's rmse: 0.0835861\tvalid_1's rmse: 0.0881166\n",
      "[2525]\ttraining's rmse: 0.0835838\tvalid_1's rmse: 0.0881161\n",
      "[2550]\ttraining's rmse: 0.0835819\tvalid_1's rmse: 0.0881152\n",
      "[2575]\ttraining's rmse: 0.0835801\tvalid_1's rmse: 0.088115\n",
      "[2600]\ttraining's rmse: 0.0835765\tvalid_1's rmse: 0.0881149\n",
      "[2625]\ttraining's rmse: 0.0835744\tvalid_1's rmse: 0.0881138\n",
      "[2650]\ttraining's rmse: 0.0835712\tvalid_1's rmse: 0.088114\n",
      "[2675]\ttraining's rmse: 0.0835678\tvalid_1's rmse: 0.0881133\n",
      "[2700]\ttraining's rmse: 0.0835658\tvalid_1's rmse: 0.0881129\n",
      "[2725]\ttraining's rmse: 0.0835616\tvalid_1's rmse: 0.0881128\n",
      "[2750]\ttraining's rmse: 0.0835603\tvalid_1's rmse: 0.0881119\n",
      "[2775]\ttraining's rmse: 0.0835566\tvalid_1's rmse: 0.088112\n",
      "[2800]\ttraining's rmse: 0.0835538\tvalid_1's rmse: 0.0881116\n",
      "[2825]\ttraining's rmse: 0.0835526\tvalid_1's rmse: 0.0881116\n",
      "[2850]\ttraining's rmse: 0.0835496\tvalid_1's rmse: 0.0881119\n",
      "Early stopping, best iteration is:\n",
      "[2808]\ttraining's rmse: 0.0835535\tvalid_1's rmse: 0.0881112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.086613\tvalid_1's rmse: 0.0889523\n",
      "[50]\ttraining's rmse: 0.0864857\tvalid_1's rmse: 0.0888939\n",
      "[75]\ttraining's rmse: 0.0863563\tvalid_1's rmse: 0.0888403\n",
      "[100]\ttraining's rmse: 0.0862387\tvalid_1's rmse: 0.0887907\n",
      "[125]\ttraining's rmse: 0.0861173\tvalid_1's rmse: 0.0887416\n",
      "[150]\ttraining's rmse: 0.086008\tvalid_1's rmse: 0.0886968\n",
      "[175]\ttraining's rmse: 0.0859193\tvalid_1's rmse: 0.0886611\n",
      "[200]\ttraining's rmse: 0.0858161\tvalid_1's rmse: 0.0886231\n",
      "[225]\ttraining's rmse: 0.0857219\tvalid_1's rmse: 0.0885874\n",
      "[250]\ttraining's rmse: 0.0856388\tvalid_1's rmse: 0.0885541\n",
      "[275]\ttraining's rmse: 0.0855652\tvalid_1's rmse: 0.0885248\n",
      "[300]\ttraining's rmse: 0.0854868\tvalid_1's rmse: 0.0884976\n",
      "[325]\ttraining's rmse: 0.085408\tvalid_1's rmse: 0.0884706\n",
      "[350]\ttraining's rmse: 0.0853316\tvalid_1's rmse: 0.0884448\n",
      "[375]\ttraining's rmse: 0.08527\tvalid_1's rmse: 0.0884227\n",
      "[400]\ttraining's rmse: 0.0852045\tvalid_1's rmse: 0.0884009\n",
      "[425]\ttraining's rmse: 0.0851437\tvalid_1's rmse: 0.0883815\n",
      "[450]\ttraining's rmse: 0.0850886\tvalid_1's rmse: 0.0883623\n",
      "[475]\ttraining's rmse: 0.0850373\tvalid_1's rmse: 0.0883451\n",
      "[500]\ttraining's rmse: 0.0849924\tvalid_1's rmse: 0.0883279\n",
      "[525]\ttraining's rmse: 0.084936\tvalid_1's rmse: 0.0883123\n",
      "[550]\ttraining's rmse: 0.0848819\tvalid_1's rmse: 0.0882981\n",
      "[575]\ttraining's rmse: 0.0848325\tvalid_1's rmse: 0.0882836\n",
      "[600]\ttraining's rmse: 0.0847848\tvalid_1's rmse: 0.0882706\n",
      "[625]\ttraining's rmse: 0.0847491\tvalid_1's rmse: 0.0882592\n",
      "[650]\ttraining's rmse: 0.0847036\tvalid_1's rmse: 0.0882464\n",
      "[675]\ttraining's rmse: 0.0846561\tvalid_1's rmse: 0.088235\n",
      "[700]\ttraining's rmse: 0.0846162\tvalid_1's rmse: 0.0882245\n",
      "[725]\ttraining's rmse: 0.0845791\tvalid_1's rmse: 0.0882151\n",
      "[750]\ttraining's rmse: 0.0845442\tvalid_1's rmse: 0.0882056\n",
      "[775]\ttraining's rmse: 0.0845142\tvalid_1's rmse: 0.088197\n",
      "[800]\ttraining's rmse: 0.084476\tvalid_1's rmse: 0.0881879\n",
      "[825]\ttraining's rmse: 0.0844447\tvalid_1's rmse: 0.0881789\n",
      "[850]\ttraining's rmse: 0.0844138\tvalid_1's rmse: 0.0881718\n",
      "[875]\ttraining's rmse: 0.0843856\tvalid_1's rmse: 0.0881653\n",
      "[900]\ttraining's rmse: 0.0843537\tvalid_1's rmse: 0.0881579\n",
      "[925]\ttraining's rmse: 0.0843236\tvalid_1's rmse: 0.0881517\n",
      "[950]\ttraining's rmse: 0.0842985\tvalid_1's rmse: 0.0881456\n",
      "[975]\ttraining's rmse: 0.0842718\tvalid_1's rmse: 0.0881393\n",
      "[1000]\ttraining's rmse: 0.0842471\tvalid_1's rmse: 0.0881341\n",
      "[1025]\ttraining's rmse: 0.0842178\tvalid_1's rmse: 0.0881289\n",
      "[1050]\ttraining's rmse: 0.0841948\tvalid_1's rmse: 0.0881243\n",
      "[1075]\ttraining's rmse: 0.0841729\tvalid_1's rmse: 0.0881207\n",
      "[1100]\ttraining's rmse: 0.0841551\tvalid_1's rmse: 0.088117\n",
      "[1125]\ttraining's rmse: 0.0841355\tvalid_1's rmse: 0.0881134\n",
      "[1150]\ttraining's rmse: 0.0841153\tvalid_1's rmse: 0.0881103\n",
      "[1175]\ttraining's rmse: 0.0840974\tvalid_1's rmse: 0.0881072\n",
      "[1200]\ttraining's rmse: 0.0840815\tvalid_1's rmse: 0.0881046\n",
      "[1225]\ttraining's rmse: 0.084066\tvalid_1's rmse: 0.0881023\n",
      "[1250]\ttraining's rmse: 0.0840499\tvalid_1's rmse: 0.0880994\n",
      "[1275]\ttraining's rmse: 0.0840318\tvalid_1's rmse: 0.0880971\n",
      "[1300]\ttraining's rmse: 0.0840182\tvalid_1's rmse: 0.0880949\n",
      "[1325]\ttraining's rmse: 0.0840033\tvalid_1's rmse: 0.0880926\n",
      "[1350]\ttraining's rmse: 0.0839893\tvalid_1's rmse: 0.0880906\n",
      "[1375]\ttraining's rmse: 0.0839746\tvalid_1's rmse: 0.0880886\n",
      "[1400]\ttraining's rmse: 0.0839626\tvalid_1's rmse: 0.0880867\n",
      "[1425]\ttraining's rmse: 0.0839498\tvalid_1's rmse: 0.0880845\n",
      "[1450]\ttraining's rmse: 0.0839361\tvalid_1's rmse: 0.088083\n",
      "[1475]\ttraining's rmse: 0.0839228\tvalid_1's rmse: 0.0880804\n",
      "[1500]\ttraining's rmse: 0.0839107\tvalid_1's rmse: 0.0880784\n",
      "[1525]\ttraining's rmse: 0.0839007\tvalid_1's rmse: 0.0880766\n",
      "[1550]\ttraining's rmse: 0.0838895\tvalid_1's rmse: 0.0880752\n",
      "[1575]\ttraining's rmse: 0.0838788\tvalid_1's rmse: 0.0880737\n",
      "[1600]\ttraining's rmse: 0.0838717\tvalid_1's rmse: 0.0880729\n",
      "[1625]\ttraining's rmse: 0.0838609\tvalid_1's rmse: 0.0880712\n",
      "[1650]\ttraining's rmse: 0.0838534\tvalid_1's rmse: 0.0880705\n",
      "[1675]\ttraining's rmse: 0.083846\tvalid_1's rmse: 0.0880691\n",
      "[1700]\ttraining's rmse: 0.0838397\tvalid_1's rmse: 0.0880678\n",
      "[1725]\ttraining's rmse: 0.0838326\tvalid_1's rmse: 0.0880663\n",
      "[1750]\ttraining's rmse: 0.0838237\tvalid_1's rmse: 0.0880654\n",
      "[1775]\ttraining's rmse: 0.0838175\tvalid_1's rmse: 0.088065\n",
      "[1800]\ttraining's rmse: 0.083811\tvalid_1's rmse: 0.0880642\n",
      "[1825]\ttraining's rmse: 0.0838036\tvalid_1's rmse: 0.0880629\n",
      "[1850]\ttraining's rmse: 0.0837972\tvalid_1's rmse: 0.0880621\n",
      "[1875]\ttraining's rmse: 0.08379\tvalid_1's rmse: 0.0880616\n",
      "[1900]\ttraining's rmse: 0.083785\tvalid_1's rmse: 0.0880613\n",
      "[1925]\ttraining's rmse: 0.0837808\tvalid_1's rmse: 0.0880609\n",
      "[1950]\ttraining's rmse: 0.0837767\tvalid_1's rmse: 0.0880605\n",
      "[1975]\ttraining's rmse: 0.0837725\tvalid_1's rmse: 0.0880597\n",
      "[2000]\ttraining's rmse: 0.0837673\tvalid_1's rmse: 0.0880591\n",
      "[2025]\ttraining's rmse: 0.0837634\tvalid_1's rmse: 0.0880582\n",
      "[2050]\ttraining's rmse: 0.0837584\tvalid_1's rmse: 0.0880583\n",
      "[2075]\ttraining's rmse: 0.0837546\tvalid_1's rmse: 0.0880578\n",
      "[2100]\ttraining's rmse: 0.0837498\tvalid_1's rmse: 0.0880573\n",
      "[2125]\ttraining's rmse: 0.0837469\tvalid_1's rmse: 0.0880574\n",
      "Early stopping, best iteration is:\n",
      "[2099]\ttraining's rmse: 0.0837499\tvalid_1's rmse: 0.0880573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0889105\tvalid_1's rmse: 0.0842923\n",
      "[50]\ttraining's rmse: 0.0887894\tvalid_1's rmse: 0.0842425\n",
      "[75]\ttraining's rmse: 0.0886639\tvalid_1's rmse: 0.084193\n",
      "[100]\ttraining's rmse: 0.0885532\tvalid_1's rmse: 0.0841517\n",
      "[125]\ttraining's rmse: 0.0884408\tvalid_1's rmse: 0.0841094\n",
      "[150]\ttraining's rmse: 0.0883355\tvalid_1's rmse: 0.0840726\n",
      "[175]\ttraining's rmse: 0.0882475\tvalid_1's rmse: 0.0840407\n",
      "[200]\ttraining's rmse: 0.088154\tvalid_1's rmse: 0.0840087\n",
      "[225]\ttraining's rmse: 0.0880631\tvalid_1's rmse: 0.083977\n",
      "[250]\ttraining's rmse: 0.0879845\tvalid_1's rmse: 0.0839517\n",
      "[275]\ttraining's rmse: 0.0879131\tvalid_1's rmse: 0.0839274\n",
      "[300]\ttraining's rmse: 0.0878408\tvalid_1's rmse: 0.083907\n",
      "[325]\ttraining's rmse: 0.0877684\tvalid_1's rmse: 0.0838837\n",
      "[350]\ttraining's rmse: 0.0876987\tvalid_1's rmse: 0.0838611\n",
      "[375]\ttraining's rmse: 0.0876403\tvalid_1's rmse: 0.0838437\n",
      "[400]\ttraining's rmse: 0.0875801\tvalid_1's rmse: 0.08383\n",
      "[425]\ttraining's rmse: 0.0875216\tvalid_1's rmse: 0.0838142\n",
      "[450]\ttraining's rmse: 0.0874663\tvalid_1's rmse: 0.0837985\n",
      "[475]\ttraining's rmse: 0.087417\tvalid_1's rmse: 0.083789\n",
      "[500]\ttraining's rmse: 0.0873756\tvalid_1's rmse: 0.083776\n",
      "[525]\ttraining's rmse: 0.0873189\tvalid_1's rmse: 0.0837665\n",
      "[550]\ttraining's rmse: 0.0872697\tvalid_1's rmse: 0.0837534\n",
      "[575]\ttraining's rmse: 0.087222\tvalid_1's rmse: 0.0837463\n",
      "[600]\ttraining's rmse: 0.0871755\tvalid_1's rmse: 0.0837409\n",
      "[625]\ttraining's rmse: 0.0871386\tvalid_1's rmse: 0.0837424\n",
      "[650]\ttraining's rmse: 0.0870937\tvalid_1's rmse: 0.0837318\n",
      "[675]\ttraining's rmse: 0.0870491\tvalid_1's rmse: 0.0837453\n",
      "[700]\ttraining's rmse: 0.0870075\tvalid_1's rmse: 0.083736\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's rmse: 0.0870867\tvalid_1's rmse: 0.0837303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0900427\tvalid_1's rmse: 0.0916726\n",
      "[50]\ttraining's rmse: 0.0898529\tvalid_1's rmse: 0.0916194\n",
      "[75]\ttraining's rmse: 0.0896656\tvalid_1's rmse: 0.0915627\n",
      "[100]\ttraining's rmse: 0.0894916\tvalid_1's rmse: 0.0915168\n",
      "[125]\ttraining's rmse: 0.0893233\tvalid_1's rmse: 0.0914695\n",
      "[150]\ttraining's rmse: 0.0891658\tvalid_1's rmse: 0.0914232\n",
      "[175]\ttraining's rmse: 0.0890367\tvalid_1's rmse: 0.0913874\n",
      "[200]\ttraining's rmse: 0.0888969\tvalid_1's rmse: 0.0913489\n",
      "[225]\ttraining's rmse: 0.0887643\tvalid_1's rmse: 0.091313\n",
      "[250]\ttraining's rmse: 0.0886496\tvalid_1's rmse: 0.0912821\n",
      "[275]\ttraining's rmse: 0.088545\tvalid_1's rmse: 0.0912537\n",
      "[300]\ttraining's rmse: 0.0884425\tvalid_1's rmse: 0.0912245\n",
      "[325]\ttraining's rmse: 0.0883427\tvalid_1's rmse: 0.0911977\n",
      "[350]\ttraining's rmse: 0.0882439\tvalid_1's rmse: 0.0911722\n",
      "[375]\ttraining's rmse: 0.0881548\tvalid_1's rmse: 0.0911514\n",
      "[400]\ttraining's rmse: 0.088065\tvalid_1's rmse: 0.0911304\n",
      "[425]\ttraining's rmse: 0.0879829\tvalid_1's rmse: 0.0911083\n",
      "[450]\ttraining's rmse: 0.0879096\tvalid_1's rmse: 0.0910877\n",
      "[475]\ttraining's rmse: 0.0878396\tvalid_1's rmse: 0.0910694\n",
      "[500]\ttraining's rmse: 0.0877811\tvalid_1's rmse: 0.0910542\n",
      "[525]\ttraining's rmse: 0.0877106\tvalid_1's rmse: 0.0910365\n",
      "[550]\ttraining's rmse: 0.0876458\tvalid_1's rmse: 0.0910207\n",
      "[575]\ttraining's rmse: 0.0875849\tvalid_1's rmse: 0.0910075\n",
      "[600]\ttraining's rmse: 0.0875312\tvalid_1's rmse: 0.0909944\n",
      "[625]\ttraining's rmse: 0.087485\tvalid_1's rmse: 0.090981\n",
      "[650]\ttraining's rmse: 0.0874298\tvalid_1's rmse: 0.0909685\n",
      "[675]\ttraining's rmse: 0.0873781\tvalid_1's rmse: 0.0909583\n",
      "[700]\ttraining's rmse: 0.0873304\tvalid_1's rmse: 0.0909462\n",
      "[725]\ttraining's rmse: 0.0872875\tvalid_1's rmse: 0.0909355\n",
      "[750]\ttraining's rmse: 0.0872463\tvalid_1's rmse: 0.0909248\n",
      "[775]\ttraining's rmse: 0.0872119\tvalid_1's rmse: 0.090914\n",
      "[800]\ttraining's rmse: 0.087166\tvalid_1's rmse: 0.0909042\n",
      "[825]\ttraining's rmse: 0.0871306\tvalid_1's rmse: 0.0908964\n",
      "[850]\ttraining's rmse: 0.0870882\tvalid_1's rmse: 0.09089\n",
      "[875]\ttraining's rmse: 0.0870564\tvalid_1's rmse: 0.0908813\n",
      "[900]\ttraining's rmse: 0.0870206\tvalid_1's rmse: 0.0908734\n",
      "[925]\ttraining's rmse: 0.0869895\tvalid_1's rmse: 0.0908661\n",
      "[950]\ttraining's rmse: 0.0869568\tvalid_1's rmse: 0.0908581\n",
      "[975]\ttraining's rmse: 0.0869266\tvalid_1's rmse: 0.0908504\n",
      "[1000]\ttraining's rmse: 0.0869002\tvalid_1's rmse: 0.0908447\n",
      "[1025]\ttraining's rmse: 0.0868743\tvalid_1's rmse: 0.0908375\n",
      "[1050]\ttraining's rmse: 0.0868474\tvalid_1's rmse: 0.0908315\n",
      "[1075]\ttraining's rmse: 0.0868203\tvalid_1's rmse: 0.0908262\n",
      "[1100]\ttraining's rmse: 0.0867989\tvalid_1's rmse: 0.090822\n",
      "[1125]\ttraining's rmse: 0.0867742\tvalid_1's rmse: 0.0908161\n",
      "[1150]\ttraining's rmse: 0.0867508\tvalid_1's rmse: 0.0908108\n",
      "[1175]\ttraining's rmse: 0.0867303\tvalid_1's rmse: 0.0908077\n",
      "[1200]\ttraining's rmse: 0.08671\tvalid_1's rmse: 0.090802\n",
      "[1225]\ttraining's rmse: 0.0866887\tvalid_1's rmse: 0.0907979\n",
      "[1250]\ttraining's rmse: 0.0866701\tvalid_1's rmse: 0.0907937\n",
      "[1275]\ttraining's rmse: 0.0866496\tvalid_1's rmse: 0.0907898\n",
      "[1300]\ttraining's rmse: 0.0866334\tvalid_1's rmse: 0.0907848\n",
      "[1325]\ttraining's rmse: 0.0866163\tvalid_1's rmse: 0.090781\n",
      "[1350]\ttraining's rmse: 0.0865995\tvalid_1's rmse: 0.0907786\n",
      "[1375]\ttraining's rmse: 0.0865831\tvalid_1's rmse: 0.0907752\n",
      "[1400]\ttraining's rmse: 0.0865674\tvalid_1's rmse: 0.0907708\n",
      "[1425]\ttraining's rmse: 0.0865519\tvalid_1's rmse: 0.0907684\n",
      "[1450]\ttraining's rmse: 0.0865346\tvalid_1's rmse: 0.0907642\n",
      "[1475]\ttraining's rmse: 0.0865216\tvalid_1's rmse: 0.090759\n",
      "[1500]\ttraining's rmse: 0.0865128\tvalid_1's rmse: 0.0907561\n",
      "[1525]\ttraining's rmse: 0.0865016\tvalid_1's rmse: 0.0907528\n",
      "[1550]\ttraining's rmse: 0.0864873\tvalid_1's rmse: 0.09075\n",
      "[1575]\ttraining's rmse: 0.0864759\tvalid_1's rmse: 0.0907469\n",
      "[1600]\ttraining's rmse: 0.0864672\tvalid_1's rmse: 0.0907447\n",
      "[1625]\ttraining's rmse: 0.0864584\tvalid_1's rmse: 0.0907415\n",
      "[1650]\ttraining's rmse: 0.0864462\tvalid_1's rmse: 0.0907393\n",
      "[1675]\ttraining's rmse: 0.0864363\tvalid_1's rmse: 0.0907365\n",
      "[1700]\ttraining's rmse: 0.0864295\tvalid_1's rmse: 0.0907345\n",
      "[1725]\ttraining's rmse: 0.0864212\tvalid_1's rmse: 0.0907325\n",
      "[1750]\ttraining's rmse: 0.0864119\tvalid_1's rmse: 0.0907301\n",
      "[1775]\ttraining's rmse: 0.0864043\tvalid_1's rmse: 0.0907287\n",
      "[1800]\ttraining's rmse: 0.0863966\tvalid_1's rmse: 0.0907263\n",
      "[1825]\ttraining's rmse: 0.0863907\tvalid_1's rmse: 0.0907236\n",
      "[1850]\ttraining's rmse: 0.0863845\tvalid_1's rmse: 0.0907217\n",
      "[1875]\ttraining's rmse: 0.0863782\tvalid_1's rmse: 0.0907208\n",
      "[1900]\ttraining's rmse: 0.0863723\tvalid_1's rmse: 0.0907189\n",
      "[1925]\ttraining's rmse: 0.0863653\tvalid_1's rmse: 0.0907179\n",
      "[1950]\ttraining's rmse: 0.0863603\tvalid_1's rmse: 0.0907158\n",
      "[1975]\ttraining's rmse: 0.0863562\tvalid_1's rmse: 0.0907138\n",
      "[2000]\ttraining's rmse: 0.0863504\tvalid_1's rmse: 0.090712\n",
      "[2025]\ttraining's rmse: 0.0863463\tvalid_1's rmse: 0.0907106\n",
      "[2050]\ttraining's rmse: 0.0863411\tvalid_1's rmse: 0.0907091\n",
      "[2075]\ttraining's rmse: 0.0863366\tvalid_1's rmse: 0.0907077\n",
      "[2100]\ttraining's rmse: 0.0863329\tvalid_1's rmse: 0.0907063\n",
      "[2125]\ttraining's rmse: 0.0863278\tvalid_1's rmse: 0.0907049\n",
      "[2150]\ttraining's rmse: 0.0863234\tvalid_1's rmse: 0.0907032\n",
      "[2175]\ttraining's rmse: 0.0863189\tvalid_1's rmse: 0.0907016\n",
      "[2200]\ttraining's rmse: 0.0863145\tvalid_1's rmse: 0.0907015\n",
      "[2225]\ttraining's rmse: 0.0863111\tvalid_1's rmse: 0.0906999\n",
      "[2250]\ttraining's rmse: 0.0863066\tvalid_1's rmse: 0.0906993\n",
      "[2275]\ttraining's rmse: 0.0863033\tvalid_1's rmse: 0.0906995\n",
      "[2300]\ttraining's rmse: 0.0862988\tvalid_1's rmse: 0.0906989\n",
      "[2325]\ttraining's rmse: 0.0862943\tvalid_1's rmse: 0.090698\n",
      "[2350]\ttraining's rmse: 0.0862917\tvalid_1's rmse: 0.0906972\n",
      "[2375]\ttraining's rmse: 0.0862886\tvalid_1's rmse: 0.0906963\n",
      "[2400]\ttraining's rmse: 0.0862858\tvalid_1's rmse: 0.0906952\n",
      "[2425]\ttraining's rmse: 0.0862815\tvalid_1's rmse: 0.0906947\n",
      "[2450]\ttraining's rmse: 0.0862779\tvalid_1's rmse: 0.0906938\n",
      "[2475]\ttraining's rmse: 0.0862747\tvalid_1's rmse: 0.0906934\n",
      "[2500]\ttraining's rmse: 0.0862713\tvalid_1's rmse: 0.090692\n",
      "[2525]\ttraining's rmse: 0.0862693\tvalid_1's rmse: 0.0906918\n",
      "[2550]\ttraining's rmse: 0.0862677\tvalid_1's rmse: 0.0906909\n",
      "[2575]\ttraining's rmse: 0.0862658\tvalid_1's rmse: 0.0906907\n",
      "[2600]\ttraining's rmse: 0.0862635\tvalid_1's rmse: 0.0906901\n",
      "[2625]\ttraining's rmse: 0.0862616\tvalid_1's rmse: 0.0906896\n",
      "[2650]\ttraining's rmse: 0.086259\tvalid_1's rmse: 0.0906879\n",
      "[2675]\ttraining's rmse: 0.086257\tvalid_1's rmse: 0.0906863\n",
      "[2700]\ttraining's rmse: 0.0862559\tvalid_1's rmse: 0.090686\n",
      "[2725]\ttraining's rmse: 0.0862518\tvalid_1's rmse: 0.0906855\n",
      "[2750]\ttraining's rmse: 0.0862491\tvalid_1's rmse: 0.0906849\n",
      "[2775]\ttraining's rmse: 0.0862462\tvalid_1's rmse: 0.0906836\n",
      "[2800]\ttraining's rmse: 0.0862437\tvalid_1's rmse: 0.0906822\n",
      "[2825]\ttraining's rmse: 0.0862417\tvalid_1's rmse: 0.0906817\n",
      "[2850]\ttraining's rmse: 0.0862392\tvalid_1's rmse: 0.0906818\n",
      "[2875]\ttraining's rmse: 0.0862375\tvalid_1's rmse: 0.0906816\n",
      "[2900]\ttraining's rmse: 0.0862351\tvalid_1's rmse: 0.0906807\n",
      "[2925]\ttraining's rmse: 0.0862331\tvalid_1's rmse: 0.0906804\n",
      "[2950]\ttraining's rmse: 0.0862308\tvalid_1's rmse: 0.0906805\n",
      "[2975]\ttraining's rmse: 0.0862293\tvalid_1's rmse: 0.0906806\n",
      "Early stopping, best iteration is:\n",
      "[2926]\ttraining's rmse: 0.086233\tvalid_1's rmse: 0.0906803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0898562\tvalid_1's rmse: 0.0920538\n",
      "[50]\ttraining's rmse: 0.0896888\tvalid_1's rmse: 0.0919981\n",
      "[75]\ttraining's rmse: 0.0895173\tvalid_1's rmse: 0.091944\n",
      "[100]\ttraining's rmse: 0.0893652\tvalid_1's rmse: 0.0918959\n",
      "[125]\ttraining's rmse: 0.0892097\tvalid_1's rmse: 0.0918473\n",
      "[150]\ttraining's rmse: 0.0890669\tvalid_1's rmse: 0.0918011\n",
      "[175]\ttraining's rmse: 0.0889506\tvalid_1's rmse: 0.0917649\n",
      "[200]\ttraining's rmse: 0.0888236\tvalid_1's rmse: 0.0917264\n",
      "[225]\ttraining's rmse: 0.0887028\tvalid_1's rmse: 0.0916903\n",
      "[250]\ttraining's rmse: 0.0885997\tvalid_1's rmse: 0.0916576\n",
      "[275]\ttraining's rmse: 0.0885043\tvalid_1's rmse: 0.0916286\n",
      "[300]\ttraining's rmse: 0.088409\tvalid_1's rmse: 0.0916005\n",
      "[325]\ttraining's rmse: 0.0883127\tvalid_1's rmse: 0.0915735\n",
      "[350]\ttraining's rmse: 0.0882214\tvalid_1's rmse: 0.0915483\n",
      "[375]\ttraining's rmse: 0.0881467\tvalid_1's rmse: 0.0915249\n",
      "[400]\ttraining's rmse: 0.0880654\tvalid_1's rmse: 0.0915025\n",
      "[425]\ttraining's rmse: 0.0879944\tvalid_1's rmse: 0.0914817\n",
      "[450]\ttraining's rmse: 0.0879297\tvalid_1's rmse: 0.0914634\n",
      "[475]\ttraining's rmse: 0.0878671\tvalid_1's rmse: 0.0914446\n",
      "[500]\ttraining's rmse: 0.0878128\tvalid_1's rmse: 0.0914275\n",
      "[525]\ttraining's rmse: 0.0877462\tvalid_1's rmse: 0.0914096\n",
      "[550]\ttraining's rmse: 0.0876863\tvalid_1's rmse: 0.0913948\n",
      "[575]\ttraining's rmse: 0.0876311\tvalid_1's rmse: 0.0913798\n",
      "[600]\ttraining's rmse: 0.0875778\tvalid_1's rmse: 0.0913668\n",
      "[625]\ttraining's rmse: 0.087534\tvalid_1's rmse: 0.0913555\n",
      "[650]\ttraining's rmse: 0.0874829\tvalid_1's rmse: 0.0913426\n",
      "[675]\ttraining's rmse: 0.0874328\tvalid_1's rmse: 0.0913312\n",
      "[700]\ttraining's rmse: 0.0873863\tvalid_1's rmse: 0.0913203\n",
      "[725]\ttraining's rmse: 0.0873467\tvalid_1's rmse: 0.0913108\n",
      "[750]\ttraining's rmse: 0.0873086\tvalid_1's rmse: 0.0913015\n",
      "[775]\ttraining's rmse: 0.0872758\tvalid_1's rmse: 0.0912925\n",
      "[800]\ttraining's rmse: 0.0872327\tvalid_1's rmse: 0.091284\n",
      "[825]\ttraining's rmse: 0.0872014\tvalid_1's rmse: 0.0912767\n",
      "[850]\ttraining's rmse: 0.0871648\tvalid_1's rmse: 0.0912692\n",
      "[875]\ttraining's rmse: 0.0871346\tvalid_1's rmse: 0.0912625\n",
      "[900]\ttraining's rmse: 0.0871012\tvalid_1's rmse: 0.0912553\n",
      "[925]\ttraining's rmse: 0.0870708\tvalid_1's rmse: 0.0912488\n",
      "[950]\ttraining's rmse: 0.0870411\tvalid_1's rmse: 0.0912427\n",
      "[975]\ttraining's rmse: 0.0870124\tvalid_1's rmse: 0.0912378\n",
      "[1000]\ttraining's rmse: 0.086988\tvalid_1's rmse: 0.0912329\n",
      "[1025]\ttraining's rmse: 0.0869587\tvalid_1's rmse: 0.0912274\n",
      "[1050]\ttraining's rmse: 0.0869362\tvalid_1's rmse: 0.0912225\n",
      "[1075]\ttraining's rmse: 0.0869113\tvalid_1's rmse: 0.0912191\n",
      "[1100]\ttraining's rmse: 0.0868921\tvalid_1's rmse: 0.0912153\n",
      "[1125]\ttraining's rmse: 0.0868677\tvalid_1's rmse: 0.0912111\n",
      "[1150]\ttraining's rmse: 0.0868444\tvalid_1's rmse: 0.091208\n",
      "[1175]\ttraining's rmse: 0.0868258\tvalid_1's rmse: 0.0912059\n",
      "[1200]\ttraining's rmse: 0.0868078\tvalid_1's rmse: 0.0912028\n",
      "[1225]\ttraining's rmse: 0.0867897\tvalid_1's rmse: 0.0912004\n",
      "[1250]\ttraining's rmse: 0.0867737\tvalid_1's rmse: 0.0911977\n",
      "[1275]\ttraining's rmse: 0.0867559\tvalid_1's rmse: 0.0911959\n",
      "[1300]\ttraining's rmse: 0.0867408\tvalid_1's rmse: 0.0911932\n",
      "[1325]\ttraining's rmse: 0.0867227\tvalid_1's rmse: 0.0911911\n",
      "[1350]\ttraining's rmse: 0.0867056\tvalid_1's rmse: 0.0911897\n",
      "[1375]\ttraining's rmse: 0.0866865\tvalid_1's rmse: 0.0911875\n",
      "[1400]\ttraining's rmse: 0.0866752\tvalid_1's rmse: 0.0911855\n",
      "[1425]\ttraining's rmse: 0.0866601\tvalid_1's rmse: 0.0911845\n",
      "[1450]\ttraining's rmse: 0.0866478\tvalid_1's rmse: 0.0911832\n",
      "[1475]\ttraining's rmse: 0.0866328\tvalid_1's rmse: 0.0911804\n",
      "[1500]\ttraining's rmse: 0.0866187\tvalid_1's rmse: 0.0911792\n",
      "[1525]\ttraining's rmse: 0.0866067\tvalid_1's rmse: 0.0911777\n",
      "[1550]\ttraining's rmse: 0.0865946\tvalid_1's rmse: 0.0911767\n",
      "[1575]\ttraining's rmse: 0.0865819\tvalid_1's rmse: 0.0911753\n",
      "[1600]\ttraining's rmse: 0.0865712\tvalid_1's rmse: 0.091174\n",
      "[1625]\ttraining's rmse: 0.0865606\tvalid_1's rmse: 0.0911724\n",
      "[1650]\ttraining's rmse: 0.0865506\tvalid_1's rmse: 0.0911721\n",
      "[1675]\ttraining's rmse: 0.086541\tvalid_1's rmse: 0.0911697\n",
      "[1700]\ttraining's rmse: 0.0865319\tvalid_1's rmse: 0.0911685\n",
      "[1725]\ttraining's rmse: 0.0865258\tvalid_1's rmse: 0.0911676\n",
      "[1750]\ttraining's rmse: 0.0865165\tvalid_1's rmse: 0.0911673\n",
      "[1775]\ttraining's rmse: 0.0865063\tvalid_1's rmse: 0.0911665\n",
      "[1800]\ttraining's rmse: 0.0864988\tvalid_1's rmse: 0.0911659\n",
      "[1825]\ttraining's rmse: 0.0864924\tvalid_1's rmse: 0.0911649\n",
      "[1850]\ttraining's rmse: 0.0864845\tvalid_1's rmse: 0.0911644\n",
      "[1875]\ttraining's rmse: 0.0864791\tvalid_1's rmse: 0.0911642\n",
      "[1900]\ttraining's rmse: 0.0864719\tvalid_1's rmse: 0.0911637\n",
      "[1925]\ttraining's rmse: 0.0864664\tvalid_1's rmse: 0.0911633\n",
      "[1950]\ttraining's rmse: 0.0864621\tvalid_1's rmse: 0.0911628\n",
      "[1975]\ttraining's rmse: 0.0864575\tvalid_1's rmse: 0.0911623\n",
      "[2000]\ttraining's rmse: 0.086451\tvalid_1's rmse: 0.0911614\n",
      "[2025]\ttraining's rmse: 0.0864465\tvalid_1's rmse: 0.0911605\n",
      "[2050]\ttraining's rmse: 0.0864426\tvalid_1's rmse: 0.0911603\n",
      "[2075]\ttraining's rmse: 0.0864372\tvalid_1's rmse: 0.0911594\n",
      "[2100]\ttraining's rmse: 0.0864333\tvalid_1's rmse: 0.0911589\n",
      "[2125]\ttraining's rmse: 0.0864291\tvalid_1's rmse: 0.091159\n",
      "[2150]\ttraining's rmse: 0.0864245\tvalid_1's rmse: 0.0911592\n",
      "Early stopping, best iteration is:\n",
      "[2106]\ttraining's rmse: 0.0864323\tvalid_1's rmse: 0.0911588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0917147\tvalid_1's rmse: 0.0883655\n",
      "[50]\ttraining's rmse: 0.0915796\tvalid_1's rmse: 0.0883158\n",
      "[75]\ttraining's rmse: 0.0914376\tvalid_1's rmse: 0.0882658\n",
      "[100]\ttraining's rmse: 0.0913089\tvalid_1's rmse: 0.0882254\n",
      "[125]\ttraining's rmse: 0.0911766\tvalid_1's rmse: 0.0881835\n",
      "[150]\ttraining's rmse: 0.0910548\tvalid_1's rmse: 0.0881457\n",
      "[175]\ttraining's rmse: 0.0909545\tvalid_1's rmse: 0.0881152\n",
      "[200]\ttraining's rmse: 0.0908427\tvalid_1's rmse: 0.0880848\n",
      "[225]\ttraining's rmse: 0.0907357\tvalid_1's rmse: 0.0880544\n",
      "[250]\ttraining's rmse: 0.0906427\tvalid_1's rmse: 0.0880292\n",
      "[275]\ttraining's rmse: 0.0905632\tvalid_1's rmse: 0.0880054\n",
      "[300]\ttraining's rmse: 0.0904818\tvalid_1's rmse: 0.0879839\n",
      "[325]\ttraining's rmse: 0.0903969\tvalid_1's rmse: 0.0879632\n",
      "[350]\ttraining's rmse: 0.0903174\tvalid_1's rmse: 0.0879429\n",
      "[375]\ttraining's rmse: 0.090251\tvalid_1's rmse: 0.0879251\n",
      "[400]\ttraining's rmse: 0.0901759\tvalid_1's rmse: 0.0879129\n",
      "[425]\ttraining's rmse: 0.0901101\tvalid_1's rmse: 0.0878957\n",
      "[450]\ttraining's rmse: 0.0900472\tvalid_1's rmse: 0.087881\n",
      "[475]\ttraining's rmse: 0.0899902\tvalid_1's rmse: 0.0878667\n",
      "[500]\ttraining's rmse: 0.0899419\tvalid_1's rmse: 0.0878549\n",
      "[525]\ttraining's rmse: 0.0898776\tvalid_1's rmse: 0.087842\n",
      "[550]\ttraining's rmse: 0.0898194\tvalid_1's rmse: 0.0878298\n",
      "[575]\ttraining's rmse: 0.0897669\tvalid_1's rmse: 0.0878198\n",
      "[600]\ttraining's rmse: 0.0897155\tvalid_1's rmse: 0.087815\n",
      "[625]\ttraining's rmse: 0.0896729\tvalid_1's rmse: 0.0878069\n",
      "[650]\ttraining's rmse: 0.0896208\tvalid_1's rmse: 0.0878039\n",
      "[675]\ttraining's rmse: 0.0895671\tvalid_1's rmse: 0.0877981\n",
      "[700]\ttraining's rmse: 0.0895209\tvalid_1's rmse: 0.0878027\n",
      "[725]\ttraining's rmse: 0.0894803\tvalid_1's rmse: 0.0877981\n",
      "[750]\ttraining's rmse: 0.0894393\tvalid_1's rmse: 0.0878044\n",
      "[775]\ttraining's rmse: 0.0894074\tvalid_1's rmse: 0.087804\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 0.0894499\tvalid_1's rmse: 0.0877928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0868049\tvalid_1's rmse: 0.0894171\n",
      "[50]\ttraining's rmse: 0.0866642\tvalid_1's rmse: 0.0893605\n",
      "[75]\ttraining's rmse: 0.0865327\tvalid_1's rmse: 0.0893045\n",
      "[100]\ttraining's rmse: 0.0864094\tvalid_1's rmse: 0.089258\n",
      "[125]\ttraining's rmse: 0.0862847\tvalid_1's rmse: 0.0892075\n",
      "[150]\ttraining's rmse: 0.0861706\tvalid_1's rmse: 0.0891605\n",
      "[175]\ttraining's rmse: 0.0860746\tvalid_1's rmse: 0.0891225\n",
      "[200]\ttraining's rmse: 0.085972\tvalid_1's rmse: 0.0890833\n",
      "[225]\ttraining's rmse: 0.0858727\tvalid_1's rmse: 0.0890484\n",
      "[250]\ttraining's rmse: 0.0857866\tvalid_1's rmse: 0.089014\n",
      "[275]\ttraining's rmse: 0.0857065\tvalid_1's rmse: 0.0889815\n",
      "[300]\ttraining's rmse: 0.0856286\tvalid_1's rmse: 0.0889527\n",
      "[325]\ttraining's rmse: 0.0855516\tvalid_1's rmse: 0.0889247\n",
      "[350]\ttraining's rmse: 0.0854771\tvalid_1's rmse: 0.0888973\n",
      "[375]\ttraining's rmse: 0.0854122\tvalid_1's rmse: 0.0888741\n",
      "[400]\ttraining's rmse: 0.0853441\tvalid_1's rmse: 0.0888517\n",
      "[425]\ttraining's rmse: 0.0852849\tvalid_1's rmse: 0.0888303\n",
      "[450]\ttraining's rmse: 0.0852282\tvalid_1's rmse: 0.0888092\n",
      "[475]\ttraining's rmse: 0.0851723\tvalid_1's rmse: 0.0887872\n",
      "[500]\ttraining's rmse: 0.085126\tvalid_1's rmse: 0.0887704\n",
      "[525]\ttraining's rmse: 0.0850691\tvalid_1's rmse: 0.0887532\n",
      "[550]\ttraining's rmse: 0.0850166\tvalid_1's rmse: 0.0887356\n",
      "[575]\ttraining's rmse: 0.0849679\tvalid_1's rmse: 0.0887219\n",
      "[600]\ttraining's rmse: 0.0849205\tvalid_1's rmse: 0.0887073\n",
      "[625]\ttraining's rmse: 0.0848817\tvalid_1's rmse: 0.0886955\n",
      "[650]\ttraining's rmse: 0.0848375\tvalid_1's rmse: 0.0886829\n",
      "[675]\ttraining's rmse: 0.0847915\tvalid_1's rmse: 0.08867\n",
      "[700]\ttraining's rmse: 0.0847525\tvalid_1's rmse: 0.0886567\n",
      "[725]\ttraining's rmse: 0.0847126\tvalid_1's rmse: 0.0886448\n",
      "[750]\ttraining's rmse: 0.0846778\tvalid_1's rmse: 0.0886348\n",
      "[775]\ttraining's rmse: 0.0846487\tvalid_1's rmse: 0.0886256\n",
      "[800]\ttraining's rmse: 0.0846126\tvalid_1's rmse: 0.0886169\n",
      "[825]\ttraining's rmse: 0.0845812\tvalid_1's rmse: 0.0886063\n",
      "[850]\ttraining's rmse: 0.084549\tvalid_1's rmse: 0.088599\n",
      "[875]\ttraining's rmse: 0.0845202\tvalid_1's rmse: 0.0885909\n",
      "[900]\ttraining's rmse: 0.0844914\tvalid_1's rmse: 0.0885829\n",
      "[925]\ttraining's rmse: 0.0844665\tvalid_1's rmse: 0.088575\n",
      "[950]\ttraining's rmse: 0.0844418\tvalid_1's rmse: 0.0885683\n",
      "[975]\ttraining's rmse: 0.0844173\tvalid_1's rmse: 0.0885611\n",
      "[1000]\ttraining's rmse: 0.0843934\tvalid_1's rmse: 0.088555\n",
      "[1025]\ttraining's rmse: 0.0843672\tvalid_1's rmse: 0.0885489\n",
      "[1050]\ttraining's rmse: 0.0843438\tvalid_1's rmse: 0.0885413\n",
      "[1075]\ttraining's rmse: 0.0843236\tvalid_1's rmse: 0.0885366\n",
      "[1100]\ttraining's rmse: 0.0843057\tvalid_1's rmse: 0.0885311\n",
      "[1125]\ttraining's rmse: 0.0842856\tvalid_1's rmse: 0.0885266\n",
      "[1150]\ttraining's rmse: 0.0842653\tvalid_1's rmse: 0.0885204\n",
      "[1175]\ttraining's rmse: 0.0842448\tvalid_1's rmse: 0.0885162\n",
      "[1200]\ttraining's rmse: 0.084228\tvalid_1's rmse: 0.08851\n",
      "[1225]\ttraining's rmse: 0.0842095\tvalid_1's rmse: 0.0885055\n",
      "[1250]\ttraining's rmse: 0.0841943\tvalid_1's rmse: 0.0885014\n",
      "[1275]\ttraining's rmse: 0.0841756\tvalid_1's rmse: 0.0884974\n",
      "[1300]\ttraining's rmse: 0.0841615\tvalid_1's rmse: 0.0884929\n",
      "[1325]\ttraining's rmse: 0.084146\tvalid_1's rmse: 0.0884894\n",
      "[1350]\ttraining's rmse: 0.0841318\tvalid_1's rmse: 0.0884875\n",
      "[1375]\ttraining's rmse: 0.0841201\tvalid_1's rmse: 0.0884851\n",
      "[1400]\ttraining's rmse: 0.0841069\tvalid_1's rmse: 0.088481\n",
      "[1425]\ttraining's rmse: 0.0840954\tvalid_1's rmse: 0.0884781\n",
      "[1450]\ttraining's rmse: 0.0840815\tvalid_1's rmse: 0.0884755\n",
      "[1475]\ttraining's rmse: 0.0840697\tvalid_1's rmse: 0.0884723\n",
      "[1500]\ttraining's rmse: 0.0840589\tvalid_1's rmse: 0.08847\n",
      "[1525]\ttraining's rmse: 0.0840477\tvalid_1's rmse: 0.0884669\n",
      "[1550]\ttraining's rmse: 0.084038\tvalid_1's rmse: 0.0884653\n",
      "[1575]\ttraining's rmse: 0.0840296\tvalid_1's rmse: 0.0884632\n",
      "[1600]\ttraining's rmse: 0.084023\tvalid_1's rmse: 0.0884611\n",
      "[1625]\ttraining's rmse: 0.084013\tvalid_1's rmse: 0.0884577\n",
      "[1650]\ttraining's rmse: 0.0840048\tvalid_1's rmse: 0.088455\n",
      "[1675]\ttraining's rmse: 0.0839976\tvalid_1's rmse: 0.0884522\n",
      "[1700]\ttraining's rmse: 0.0839923\tvalid_1's rmse: 0.0884504\n",
      "[1725]\ttraining's rmse: 0.0839862\tvalid_1's rmse: 0.0884481\n",
      "[1750]\ttraining's rmse: 0.0839801\tvalid_1's rmse: 0.0884463\n",
      "[1775]\ttraining's rmse: 0.083973\tvalid_1's rmse: 0.0884451\n",
      "[1800]\ttraining's rmse: 0.0839668\tvalid_1's rmse: 0.088444\n",
      "[1825]\ttraining's rmse: 0.0839598\tvalid_1's rmse: 0.0884418\n",
      "[1850]\ttraining's rmse: 0.0839538\tvalid_1's rmse: 0.0884384\n",
      "[1875]\ttraining's rmse: 0.0839494\tvalid_1's rmse: 0.0884364\n",
      "[1900]\ttraining's rmse: 0.0839446\tvalid_1's rmse: 0.0884351\n",
      "[1925]\ttraining's rmse: 0.083939\tvalid_1's rmse: 0.0884331\n",
      "[1950]\ttraining's rmse: 0.0839356\tvalid_1's rmse: 0.0884315\n",
      "[1975]\ttraining's rmse: 0.0839302\tvalid_1's rmse: 0.0884308\n",
      "[2000]\ttraining's rmse: 0.083926\tvalid_1's rmse: 0.0884303\n",
      "[2025]\ttraining's rmse: 0.0839219\tvalid_1's rmse: 0.088429\n",
      "[2050]\ttraining's rmse: 0.083918\tvalid_1's rmse: 0.0884272\n",
      "[2075]\ttraining's rmse: 0.0839149\tvalid_1's rmse: 0.0884258\n",
      "[2100]\ttraining's rmse: 0.0839123\tvalid_1's rmse: 0.0884248\n",
      "[2125]\ttraining's rmse: 0.0839075\tvalid_1's rmse: 0.0884242\n",
      "[2150]\ttraining's rmse: 0.0839032\tvalid_1's rmse: 0.0884237\n",
      "[2175]\ttraining's rmse: 0.0838986\tvalid_1's rmse: 0.0884228\n",
      "[2200]\ttraining's rmse: 0.0838956\tvalid_1's rmse: 0.0884221\n",
      "[2225]\ttraining's rmse: 0.0838921\tvalid_1's rmse: 0.0884206\n",
      "[2250]\ttraining's rmse: 0.0838891\tvalid_1's rmse: 0.0884195\n",
      "[2275]\ttraining's rmse: 0.0838859\tvalid_1's rmse: 0.0884186\n",
      "[2300]\ttraining's rmse: 0.083882\tvalid_1's rmse: 0.0884174\n",
      "[2325]\ttraining's rmse: 0.0838789\tvalid_1's rmse: 0.0884168\n",
      "[2350]\ttraining's rmse: 0.0838763\tvalid_1's rmse: 0.088416\n",
      "[2375]\ttraining's rmse: 0.0838732\tvalid_1's rmse: 0.0884155\n",
      "[2400]\ttraining's rmse: 0.0838705\tvalid_1's rmse: 0.0884151\n",
      "[2425]\ttraining's rmse: 0.0838678\tvalid_1's rmse: 0.0884146\n",
      "[2450]\ttraining's rmse: 0.0838649\tvalid_1's rmse: 0.088414\n",
      "[2475]\ttraining's rmse: 0.0838609\tvalid_1's rmse: 0.0884135\n",
      "[2500]\ttraining's rmse: 0.0838586\tvalid_1's rmse: 0.0884136\n",
      "[2525]\ttraining's rmse: 0.0838559\tvalid_1's rmse: 0.0884125\n",
      "[2550]\ttraining's rmse: 0.0838538\tvalid_1's rmse: 0.0884121\n",
      "[2575]\ttraining's rmse: 0.0838527\tvalid_1's rmse: 0.088412\n",
      "[2600]\ttraining's rmse: 0.083851\tvalid_1's rmse: 0.0884124\n",
      "[2625]\ttraining's rmse: 0.0838487\tvalid_1's rmse: 0.0884107\n",
      "[2650]\ttraining's rmse: 0.0838475\tvalid_1's rmse: 0.0884109\n",
      "[2675]\ttraining's rmse: 0.0838456\tvalid_1's rmse: 0.0884105\n",
      "[2700]\ttraining's rmse: 0.0838434\tvalid_1's rmse: 0.0884102\n",
      "[2725]\ttraining's rmse: 0.0838406\tvalid_1's rmse: 0.0884098\n",
      "[2750]\ttraining's rmse: 0.0838384\tvalid_1's rmse: 0.0884092\n",
      "[2775]\ttraining's rmse: 0.0838361\tvalid_1's rmse: 0.0884093\n",
      "Early stopping, best iteration is:\n",
      "[2744]\ttraining's rmse: 0.0838391\tvalid_1's rmse: 0.0884091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0869063\tvalid_1's rmse: 0.0892235\n",
      "[50]\ttraining's rmse: 0.0867785\tvalid_1's rmse: 0.0891668\n",
      "[75]\ttraining's rmse: 0.0866479\tvalid_1's rmse: 0.0891103\n",
      "[100]\ttraining's rmse: 0.0865307\tvalid_1's rmse: 0.0890606\n",
      "[125]\ttraining's rmse: 0.0864098\tvalid_1's rmse: 0.0890123\n",
      "[150]\ttraining's rmse: 0.0862981\tvalid_1's rmse: 0.0889653\n",
      "[175]\ttraining's rmse: 0.0862072\tvalid_1's rmse: 0.0889284\n",
      "[200]\ttraining's rmse: 0.0861083\tvalid_1's rmse: 0.0888906\n",
      "[225]\ttraining's rmse: 0.0860124\tvalid_1's rmse: 0.0888552\n",
      "[250]\ttraining's rmse: 0.0859267\tvalid_1's rmse: 0.0888229\n",
      "[275]\ttraining's rmse: 0.0858497\tvalid_1's rmse: 0.0887943\n",
      "[300]\ttraining's rmse: 0.085775\tvalid_1's rmse: 0.0887656\n",
      "[325]\ttraining's rmse: 0.0856963\tvalid_1's rmse: 0.0887372\n",
      "[350]\ttraining's rmse: 0.0856215\tvalid_1's rmse: 0.0887116\n",
      "[375]\ttraining's rmse: 0.0855626\tvalid_1's rmse: 0.0886897\n",
      "[400]\ttraining's rmse: 0.0854976\tvalid_1's rmse: 0.0886686\n",
      "[425]\ttraining's rmse: 0.0854362\tvalid_1's rmse: 0.0886478\n",
      "[450]\ttraining's rmse: 0.0853796\tvalid_1's rmse: 0.0886289\n",
      "[475]\ttraining's rmse: 0.0853271\tvalid_1's rmse: 0.0886109\n",
      "[500]\ttraining's rmse: 0.0852811\tvalid_1's rmse: 0.0885936\n",
      "[525]\ttraining's rmse: 0.0852222\tvalid_1's rmse: 0.0885765\n",
      "[550]\ttraining's rmse: 0.0851682\tvalid_1's rmse: 0.0885625\n",
      "[575]\ttraining's rmse: 0.0851177\tvalid_1's rmse: 0.0885484\n",
      "[600]\ttraining's rmse: 0.0850694\tvalid_1's rmse: 0.0885355\n",
      "[625]\ttraining's rmse: 0.0850313\tvalid_1's rmse: 0.0885239\n",
      "[650]\ttraining's rmse: 0.0849835\tvalid_1's rmse: 0.088511\n",
      "[675]\ttraining's rmse: 0.0849373\tvalid_1's rmse: 0.0884995\n",
      "[700]\ttraining's rmse: 0.0848965\tvalid_1's rmse: 0.0884888\n",
      "[725]\ttraining's rmse: 0.0848593\tvalid_1's rmse: 0.088479\n",
      "[750]\ttraining's rmse: 0.084825\tvalid_1's rmse: 0.0884695\n",
      "[775]\ttraining's rmse: 0.0847937\tvalid_1's rmse: 0.0884604\n",
      "[800]\ttraining's rmse: 0.0847556\tvalid_1's rmse: 0.0884524\n",
      "[825]\ttraining's rmse: 0.0847256\tvalid_1's rmse: 0.0884442\n",
      "[850]\ttraining's rmse: 0.0846927\tvalid_1's rmse: 0.0884366\n",
      "[875]\ttraining's rmse: 0.0846647\tvalid_1's rmse: 0.0884301\n",
      "[900]\ttraining's rmse: 0.0846314\tvalid_1's rmse: 0.0884228\n",
      "[925]\ttraining's rmse: 0.0846027\tvalid_1's rmse: 0.0884164\n",
      "[950]\ttraining's rmse: 0.0845751\tvalid_1's rmse: 0.0884104\n",
      "[975]\ttraining's rmse: 0.0845467\tvalid_1's rmse: 0.088404\n",
      "[1000]\ttraining's rmse: 0.0845212\tvalid_1's rmse: 0.088399\n",
      "[1025]\ttraining's rmse: 0.0844935\tvalid_1's rmse: 0.0883939\n",
      "[1050]\ttraining's rmse: 0.0844707\tvalid_1's rmse: 0.0883889\n",
      "[1075]\ttraining's rmse: 0.0844496\tvalid_1's rmse: 0.0883855\n",
      "[1100]\ttraining's rmse: 0.0844324\tvalid_1's rmse: 0.0883814\n",
      "[1125]\ttraining's rmse: 0.0844128\tvalid_1's rmse: 0.0883784\n",
      "[1150]\ttraining's rmse: 0.0843917\tvalid_1's rmse: 0.0883746\n",
      "[1175]\ttraining's rmse: 0.0843747\tvalid_1's rmse: 0.0883719\n",
      "[1200]\ttraining's rmse: 0.0843569\tvalid_1's rmse: 0.0883694\n",
      "[1225]\ttraining's rmse: 0.0843399\tvalid_1's rmse: 0.0883666\n",
      "[1250]\ttraining's rmse: 0.0843258\tvalid_1's rmse: 0.0883633\n",
      "[1275]\ttraining's rmse: 0.0843087\tvalid_1's rmse: 0.0883612\n",
      "[1300]\ttraining's rmse: 0.084293\tvalid_1's rmse: 0.0883593\n",
      "[1325]\ttraining's rmse: 0.0842793\tvalid_1's rmse: 0.0883572\n",
      "[1350]\ttraining's rmse: 0.0842643\tvalid_1's rmse: 0.0883555\n",
      "[1375]\ttraining's rmse: 0.0842509\tvalid_1's rmse: 0.088354\n",
      "[1400]\ttraining's rmse: 0.0842404\tvalid_1's rmse: 0.0883525\n",
      "[1425]\ttraining's rmse: 0.0842267\tvalid_1's rmse: 0.0883511\n",
      "[1450]\ttraining's rmse: 0.0842132\tvalid_1's rmse: 0.0883501\n",
      "[1475]\ttraining's rmse: 0.0842032\tvalid_1's rmse: 0.0883485\n",
      "[1500]\ttraining's rmse: 0.0841935\tvalid_1's rmse: 0.088347\n",
      "[1525]\ttraining's rmse: 0.0841826\tvalid_1's rmse: 0.0883462\n",
      "[1550]\ttraining's rmse: 0.0841721\tvalid_1's rmse: 0.088345\n",
      "[1575]\ttraining's rmse: 0.0841628\tvalid_1's rmse: 0.0883441\n",
      "[1600]\ttraining's rmse: 0.084153\tvalid_1's rmse: 0.0883433\n",
      "[1625]\ttraining's rmse: 0.0841435\tvalid_1's rmse: 0.0883415\n",
      "[1650]\ttraining's rmse: 0.0841343\tvalid_1's rmse: 0.0883403\n",
      "[1675]\ttraining's rmse: 0.0841268\tvalid_1's rmse: 0.088339\n",
      "[1700]\ttraining's rmse: 0.0841192\tvalid_1's rmse: 0.0883375\n",
      "[1725]\ttraining's rmse: 0.0841125\tvalid_1's rmse: 0.0883365\n",
      "[1750]\ttraining's rmse: 0.0841018\tvalid_1's rmse: 0.0883353\n",
      "[1775]\ttraining's rmse: 0.0840947\tvalid_1's rmse: 0.088335\n",
      "[1800]\ttraining's rmse: 0.0840871\tvalid_1's rmse: 0.0883338\n",
      "[1825]\ttraining's rmse: 0.0840807\tvalid_1's rmse: 0.0883331\n",
      "[1850]\ttraining's rmse: 0.0840739\tvalid_1's rmse: 0.0883319\n",
      "[1875]\ttraining's rmse: 0.0840671\tvalid_1's rmse: 0.0883313\n",
      "[1900]\ttraining's rmse: 0.0840626\tvalid_1's rmse: 0.088331\n",
      "[1925]\ttraining's rmse: 0.0840581\tvalid_1's rmse: 0.0883305\n",
      "[1950]\ttraining's rmse: 0.0840528\tvalid_1's rmse: 0.0883295\n",
      "[1975]\ttraining's rmse: 0.0840483\tvalid_1's rmse: 0.0883289\n",
      "[2000]\ttraining's rmse: 0.0840448\tvalid_1's rmse: 0.0883284\n",
      "[2025]\ttraining's rmse: 0.0840401\tvalid_1's rmse: 0.0883274\n",
      "[2050]\ttraining's rmse: 0.084035\tvalid_1's rmse: 0.0883268\n",
      "[2075]\ttraining's rmse: 0.0840312\tvalid_1's rmse: 0.0883261\n",
      "[2100]\ttraining's rmse: 0.084027\tvalid_1's rmse: 0.0883258\n",
      "[2125]\ttraining's rmse: 0.0840236\tvalid_1's rmse: 0.0883259\n",
      "[2150]\ttraining's rmse: 0.0840189\tvalid_1's rmse: 0.0883257\n",
      "Early stopping, best iteration is:\n",
      "[2101]\ttraining's rmse: 0.0840268\tvalid_1's rmse: 0.0883257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0891959\tvalid_1's rmse: 0.0845779\n",
      "[50]\ttraining's rmse: 0.0890727\tvalid_1's rmse: 0.0845278\n",
      "[75]\ttraining's rmse: 0.0889497\tvalid_1's rmse: 0.0844789\n",
      "[100]\ttraining's rmse: 0.0888387\tvalid_1's rmse: 0.0844354\n",
      "[125]\ttraining's rmse: 0.0887233\tvalid_1's rmse: 0.0843918\n",
      "[150]\ttraining's rmse: 0.0886179\tvalid_1's rmse: 0.0843537\n",
      "[175]\ttraining's rmse: 0.0885313\tvalid_1's rmse: 0.0843208\n",
      "[200]\ttraining's rmse: 0.0884386\tvalid_1's rmse: 0.0842888\n",
      "[225]\ttraining's rmse: 0.0883474\tvalid_1's rmse: 0.0842577\n",
      "[250]\ttraining's rmse: 0.0882701\tvalid_1's rmse: 0.0842325\n",
      "[275]\ttraining's rmse: 0.0881989\tvalid_1's rmse: 0.084208\n",
      "[300]\ttraining's rmse: 0.0881271\tvalid_1's rmse: 0.0841837\n",
      "[325]\ttraining's rmse: 0.0880547\tvalid_1's rmse: 0.0841618\n",
      "[350]\ttraining's rmse: 0.0879845\tvalid_1's rmse: 0.0841395\n",
      "[375]\ttraining's rmse: 0.087926\tvalid_1's rmse: 0.084122\n",
      "[400]\ttraining's rmse: 0.0878644\tvalid_1's rmse: 0.0841103\n",
      "[425]\ttraining's rmse: 0.087806\tvalid_1's rmse: 0.0840941\n",
      "[450]\ttraining's rmse: 0.0877533\tvalid_1's rmse: 0.0840777\n",
      "[475]\ttraining's rmse: 0.0877039\tvalid_1's rmse: 0.0840677\n",
      "[500]\ttraining's rmse: 0.0876616\tvalid_1's rmse: 0.0840535\n",
      "[525]\ttraining's rmse: 0.087605\tvalid_1's rmse: 0.0840378\n",
      "[550]\ttraining's rmse: 0.0875548\tvalid_1's rmse: 0.0840246\n",
      "[575]\ttraining's rmse: 0.0875081\tvalid_1's rmse: 0.0840176\n",
      "[600]\ttraining's rmse: 0.087461\tvalid_1's rmse: 0.0840114\n",
      "[625]\ttraining's rmse: 0.0874261\tvalid_1's rmse: 0.0840025\n",
      "[650]\ttraining's rmse: 0.0873807\tvalid_1's rmse: 0.0839999\n",
      "[675]\ttraining's rmse: 0.087332\tvalid_1's rmse: 0.0839891\n",
      "[700]\ttraining's rmse: 0.0872919\tvalid_1's rmse: 0.0839865\n",
      "[725]\ttraining's rmse: 0.0872546\tvalid_1's rmse: 0.0839912\n",
      "[750]\ttraining's rmse: 0.0872193\tvalid_1's rmse: 0.0839927\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's rmse: 0.0872919\tvalid_1's rmse: 0.0839865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0907642\tvalid_1's rmse: 0.0925611\n",
      "[50]\ttraining's rmse: 0.0905696\tvalid_1's rmse: 0.0925067\n",
      "[75]\ttraining's rmse: 0.0903793\tvalid_1's rmse: 0.0924539\n",
      "[100]\ttraining's rmse: 0.0902032\tvalid_1's rmse: 0.0924074\n",
      "[125]\ttraining's rmse: 0.0900311\tvalid_1's rmse: 0.0923613\n",
      "[150]\ttraining's rmse: 0.0898722\tvalid_1's rmse: 0.0923187\n",
      "[175]\ttraining's rmse: 0.0897371\tvalid_1's rmse: 0.0922809\n",
      "[200]\ttraining's rmse: 0.0895949\tvalid_1's rmse: 0.092245\n",
      "[225]\ttraining's rmse: 0.0894611\tvalid_1's rmse: 0.0922099\n",
      "[250]\ttraining's rmse: 0.0893462\tvalid_1's rmse: 0.0921773\n",
      "[275]\ttraining's rmse: 0.0892365\tvalid_1's rmse: 0.0921489\n",
      "[300]\ttraining's rmse: 0.0891299\tvalid_1's rmse: 0.0921203\n",
      "[325]\ttraining's rmse: 0.0890279\tvalid_1's rmse: 0.0920929\n",
      "[350]\ttraining's rmse: 0.0889279\tvalid_1's rmse: 0.0920674\n",
      "[375]\ttraining's rmse: 0.0888403\tvalid_1's rmse: 0.0920466\n",
      "[400]\ttraining's rmse: 0.0887498\tvalid_1's rmse: 0.0920251\n",
      "[425]\ttraining's rmse: 0.0886656\tvalid_1's rmse: 0.0920045\n",
      "[450]\ttraining's rmse: 0.088592\tvalid_1's rmse: 0.0919851\n",
      "[475]\ttraining's rmse: 0.0885244\tvalid_1's rmse: 0.0919654\n",
      "[500]\ttraining's rmse: 0.0884664\tvalid_1's rmse: 0.0919484\n",
      "[525]\ttraining's rmse: 0.0883946\tvalid_1's rmse: 0.0919308\n",
      "[550]\ttraining's rmse: 0.0883302\tvalid_1's rmse: 0.0919157\n",
      "[575]\ttraining's rmse: 0.0882716\tvalid_1's rmse: 0.0919015\n",
      "[600]\ttraining's rmse: 0.0882135\tvalid_1's rmse: 0.0918861\n",
      "[625]\ttraining's rmse: 0.0881659\tvalid_1's rmse: 0.0918739\n",
      "[650]\ttraining's rmse: 0.0881108\tvalid_1's rmse: 0.09186\n",
      "[675]\ttraining's rmse: 0.0880589\tvalid_1's rmse: 0.0918473\n",
      "[700]\ttraining's rmse: 0.0880112\tvalid_1's rmse: 0.0918339\n",
      "[725]\ttraining's rmse: 0.0879633\tvalid_1's rmse: 0.091824\n",
      "[750]\ttraining's rmse: 0.0879195\tvalid_1's rmse: 0.0918128\n",
      "[775]\ttraining's rmse: 0.0878831\tvalid_1's rmse: 0.0918038\n",
      "[800]\ttraining's rmse: 0.0878387\tvalid_1's rmse: 0.0917946\n",
      "[825]\ttraining's rmse: 0.0878001\tvalid_1's rmse: 0.0917851\n",
      "[850]\ttraining's rmse: 0.0877611\tvalid_1's rmse: 0.0917785\n",
      "[875]\ttraining's rmse: 0.0877283\tvalid_1's rmse: 0.0917711\n",
      "[900]\ttraining's rmse: 0.0876928\tvalid_1's rmse: 0.091764\n",
      "[925]\ttraining's rmse: 0.0876591\tvalid_1's rmse: 0.0917559\n",
      "[950]\ttraining's rmse: 0.087631\tvalid_1's rmse: 0.0917484\n",
      "[975]\ttraining's rmse: 0.0876011\tvalid_1's rmse: 0.0917408\n",
      "[1000]\ttraining's rmse: 0.0875725\tvalid_1's rmse: 0.091734\n",
      "[1025]\ttraining's rmse: 0.0875433\tvalid_1's rmse: 0.091728\n",
      "[1050]\ttraining's rmse: 0.0875154\tvalid_1's rmse: 0.0917196\n",
      "[1075]\ttraining's rmse: 0.0874851\tvalid_1's rmse: 0.0917135\n",
      "[1100]\ttraining's rmse: 0.0874625\tvalid_1's rmse: 0.0917079\n",
      "[1125]\ttraining's rmse: 0.0874415\tvalid_1's rmse: 0.0917011\n",
      "[1150]\ttraining's rmse: 0.0874166\tvalid_1's rmse: 0.0916953\n",
      "[1175]\ttraining's rmse: 0.0873952\tvalid_1's rmse: 0.0916922\n",
      "[1200]\ttraining's rmse: 0.0873766\tvalid_1's rmse: 0.0916863\n",
      "[1225]\ttraining's rmse: 0.0873566\tvalid_1's rmse: 0.0916809\n",
      "[1250]\ttraining's rmse: 0.0873385\tvalid_1's rmse: 0.0916763\n",
      "[1275]\ttraining's rmse: 0.0873175\tvalid_1's rmse: 0.0916727\n",
      "[1300]\ttraining's rmse: 0.0873016\tvalid_1's rmse: 0.0916677\n",
      "[1325]\ttraining's rmse: 0.0872855\tvalid_1's rmse: 0.0916641\n",
      "[1350]\ttraining's rmse: 0.0872688\tvalid_1's rmse: 0.0916602\n",
      "[1375]\ttraining's rmse: 0.0872526\tvalid_1's rmse: 0.0916553\n",
      "[1400]\ttraining's rmse: 0.0872394\tvalid_1's rmse: 0.0916511\n",
      "[1425]\ttraining's rmse: 0.087224\tvalid_1's rmse: 0.0916479\n",
      "[1450]\ttraining's rmse: 0.0872085\tvalid_1's rmse: 0.0916453\n",
      "[1475]\ttraining's rmse: 0.0871964\tvalid_1's rmse: 0.0916412\n",
      "[1500]\ttraining's rmse: 0.087183\tvalid_1's rmse: 0.0916383\n",
      "[1525]\ttraining's rmse: 0.0871682\tvalid_1's rmse: 0.0916357\n",
      "[1550]\ttraining's rmse: 0.0871577\tvalid_1's rmse: 0.0916326\n",
      "[1575]\ttraining's rmse: 0.0871485\tvalid_1's rmse: 0.0916312\n",
      "[1600]\ttraining's rmse: 0.0871389\tvalid_1's rmse: 0.0916278\n",
      "[1625]\ttraining's rmse: 0.08713\tvalid_1's rmse: 0.0916248\n",
      "[1650]\ttraining's rmse: 0.0871177\tvalid_1's rmse: 0.0916231\n",
      "[1675]\ttraining's rmse: 0.0871097\tvalid_1's rmse: 0.0916201\n",
      "[1700]\ttraining's rmse: 0.0871003\tvalid_1's rmse: 0.0916172\n",
      "[1725]\ttraining's rmse: 0.0870932\tvalid_1's rmse: 0.0916159\n",
      "[1750]\ttraining's rmse: 0.0870833\tvalid_1's rmse: 0.0916139\n",
      "[1775]\ttraining's rmse: 0.087074\tvalid_1's rmse: 0.0916123\n",
      "[1800]\ttraining's rmse: 0.087068\tvalid_1's rmse: 0.0916107\n",
      "[1825]\ttraining's rmse: 0.0870621\tvalid_1's rmse: 0.0916091\n",
      "[1850]\ttraining's rmse: 0.0870554\tvalid_1's rmse: 0.0916073\n",
      "[1875]\ttraining's rmse: 0.0870479\tvalid_1's rmse: 0.0916057\n",
      "[1900]\ttraining's rmse: 0.0870426\tvalid_1's rmse: 0.0916044\n",
      "[1925]\ttraining's rmse: 0.087034\tvalid_1's rmse: 0.0916021\n",
      "[1950]\ttraining's rmse: 0.0870291\tvalid_1's rmse: 0.0916004\n",
      "[1975]\ttraining's rmse: 0.0870238\tvalid_1's rmse: 0.0915993\n",
      "[2000]\ttraining's rmse: 0.0870175\tvalid_1's rmse: 0.0915972\n",
      "[2025]\ttraining's rmse: 0.0870142\tvalid_1's rmse: 0.0915957\n",
      "[2050]\ttraining's rmse: 0.0870098\tvalid_1's rmse: 0.0915937\n",
      "[2075]\ttraining's rmse: 0.0870057\tvalid_1's rmse: 0.0915928\n",
      "[2100]\ttraining's rmse: 0.087001\tvalid_1's rmse: 0.0915919\n",
      "[2125]\ttraining's rmse: 0.0869962\tvalid_1's rmse: 0.0915907\n",
      "[2150]\ttraining's rmse: 0.0869909\tvalid_1's rmse: 0.0915887\n",
      "[2175]\ttraining's rmse: 0.0869877\tvalid_1's rmse: 0.091588\n",
      "[2200]\ttraining's rmse: 0.0869824\tvalid_1's rmse: 0.0915863\n",
      "[2225]\ttraining's rmse: 0.0869782\tvalid_1's rmse: 0.0915845\n",
      "[2250]\ttraining's rmse: 0.0869758\tvalid_1's rmse: 0.0915838\n",
      "[2275]\ttraining's rmse: 0.0869701\tvalid_1's rmse: 0.0915827\n",
      "[2300]\ttraining's rmse: 0.0869662\tvalid_1's rmse: 0.0915813\n",
      "[2325]\ttraining's rmse: 0.0869624\tvalid_1's rmse: 0.0915805\n",
      "[2350]\ttraining's rmse: 0.0869591\tvalid_1's rmse: 0.0915804\n",
      "[2375]\ttraining's rmse: 0.0869556\tvalid_1's rmse: 0.0915801\n",
      "[2400]\ttraining's rmse: 0.0869523\tvalid_1's rmse: 0.0915782\n",
      "[2425]\ttraining's rmse: 0.0869492\tvalid_1's rmse: 0.0915763\n",
      "[2450]\ttraining's rmse: 0.086946\tvalid_1's rmse: 0.0915754\n",
      "[2475]\ttraining's rmse: 0.0869425\tvalid_1's rmse: 0.0915752\n",
      "[2500]\ttraining's rmse: 0.0869401\tvalid_1's rmse: 0.0915745\n",
      "[2525]\ttraining's rmse: 0.086937\tvalid_1's rmse: 0.0915743\n",
      "[2550]\ttraining's rmse: 0.0869334\tvalid_1's rmse: 0.0915739\n",
      "[2575]\ttraining's rmse: 0.0869299\tvalid_1's rmse: 0.0915733\n",
      "[2600]\ttraining's rmse: 0.0869266\tvalid_1's rmse: 0.0915729\n",
      "[2625]\ttraining's rmse: 0.0869242\tvalid_1's rmse: 0.0915715\n",
      "[2650]\ttraining's rmse: 0.0869222\tvalid_1's rmse: 0.0915716\n",
      "[2675]\ttraining's rmse: 0.086919\tvalid_1's rmse: 0.0915706\n",
      "[2700]\ttraining's rmse: 0.0869171\tvalid_1's rmse: 0.0915695\n",
      "[2725]\ttraining's rmse: 0.0869146\tvalid_1's rmse: 0.0915694\n",
      "[2750]\ttraining's rmse: 0.0869124\tvalid_1's rmse: 0.091569\n",
      "[2775]\ttraining's rmse: 0.0869105\tvalid_1's rmse: 0.0915692\n",
      "Early stopping, best iteration is:\n",
      "[2747]\ttraining's rmse: 0.0869126\tvalid_1's rmse: 0.0915688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0908028\tvalid_1's rmse: 0.0925096\n",
      "[50]\ttraining's rmse: 0.0906297\tvalid_1's rmse: 0.0924558\n",
      "[75]\ttraining's rmse: 0.0904514\tvalid_1's rmse: 0.0923998\n",
      "[100]\ttraining's rmse: 0.0902913\tvalid_1's rmse: 0.0923509\n",
      "[125]\ttraining's rmse: 0.09013\tvalid_1's rmse: 0.0923023\n",
      "[150]\ttraining's rmse: 0.0899824\tvalid_1's rmse: 0.0922556\n",
      "[175]\ttraining's rmse: 0.089858\tvalid_1's rmse: 0.0922192\n",
      "[200]\ttraining's rmse: 0.0897288\tvalid_1's rmse: 0.0921805\n",
      "[225]\ttraining's rmse: 0.0896048\tvalid_1's rmse: 0.0921446\n",
      "[250]\ttraining's rmse: 0.089499\tvalid_1's rmse: 0.0921117\n",
      "[275]\ttraining's rmse: 0.0894004\tvalid_1's rmse: 0.0920816\n",
      "[300]\ttraining's rmse: 0.0893044\tvalid_1's rmse: 0.0920544\n",
      "[325]\ttraining's rmse: 0.0892072\tvalid_1's rmse: 0.0920276\n",
      "[350]\ttraining's rmse: 0.0891151\tvalid_1's rmse: 0.0920028\n",
      "[375]\ttraining's rmse: 0.0890401\tvalid_1's rmse: 0.0919806\n",
      "[400]\ttraining's rmse: 0.0889577\tvalid_1's rmse: 0.091959\n",
      "[425]\ttraining's rmse: 0.0888826\tvalid_1's rmse: 0.0919374\n",
      "[450]\ttraining's rmse: 0.0888125\tvalid_1's rmse: 0.0919182\n",
      "[475]\ttraining's rmse: 0.08875\tvalid_1's rmse: 0.0919013\n",
      "[500]\ttraining's rmse: 0.0886958\tvalid_1's rmse: 0.0918852\n",
      "[525]\ttraining's rmse: 0.088627\tvalid_1's rmse: 0.0918671\n",
      "[550]\ttraining's rmse: 0.0885651\tvalid_1's rmse: 0.0918541\n",
      "[575]\ttraining's rmse: 0.0885112\tvalid_1's rmse: 0.0918407\n",
      "[600]\ttraining's rmse: 0.0884587\tvalid_1's rmse: 0.0918278\n",
      "[625]\ttraining's rmse: 0.0884133\tvalid_1's rmse: 0.0918152\n",
      "[650]\ttraining's rmse: 0.0883594\tvalid_1's rmse: 0.091803\n",
      "[675]\ttraining's rmse: 0.0883081\tvalid_1's rmse: 0.0917919\n",
      "[700]\ttraining's rmse: 0.0882619\tvalid_1's rmse: 0.0917803\n",
      "[725]\ttraining's rmse: 0.0882213\tvalid_1's rmse: 0.0917719\n",
      "[750]\ttraining's rmse: 0.0881819\tvalid_1's rmse: 0.0917627\n",
      "[775]\ttraining's rmse: 0.0881471\tvalid_1's rmse: 0.0917539\n",
      "[800]\ttraining's rmse: 0.0881034\tvalid_1's rmse: 0.0917464\n",
      "[825]\ttraining's rmse: 0.0880689\tvalid_1's rmse: 0.0917382\n",
      "[850]\ttraining's rmse: 0.088033\tvalid_1's rmse: 0.0917319\n",
      "[875]\ttraining's rmse: 0.0880032\tvalid_1's rmse: 0.0917265\n",
      "[900]\ttraining's rmse: 0.0879699\tvalid_1's rmse: 0.0917199\n",
      "[925]\ttraining's rmse: 0.0879391\tvalid_1's rmse: 0.0917138\n",
      "[950]\ttraining's rmse: 0.0879089\tvalid_1's rmse: 0.0917074\n",
      "[975]\ttraining's rmse: 0.0878776\tvalid_1's rmse: 0.0917021\n",
      "[1000]\ttraining's rmse: 0.087852\tvalid_1's rmse: 0.0916988\n",
      "[1025]\ttraining's rmse: 0.0878221\tvalid_1's rmse: 0.0916943\n",
      "[1050]\ttraining's rmse: 0.0877966\tvalid_1's rmse: 0.0916899\n",
      "[1075]\ttraining's rmse: 0.0877718\tvalid_1's rmse: 0.0916869\n",
      "[1100]\ttraining's rmse: 0.0877525\tvalid_1's rmse: 0.0916835\n",
      "[1125]\ttraining's rmse: 0.08773\tvalid_1's rmse: 0.0916795\n",
      "[1150]\ttraining's rmse: 0.0877071\tvalid_1's rmse: 0.0916759\n",
      "[1175]\ttraining's rmse: 0.0876894\tvalid_1's rmse: 0.0916736\n",
      "[1200]\ttraining's rmse: 0.0876704\tvalid_1's rmse: 0.0916702\n",
      "[1225]\ttraining's rmse: 0.087651\tvalid_1's rmse: 0.0916673\n",
      "[1250]\ttraining's rmse: 0.0876353\tvalid_1's rmse: 0.0916648\n",
      "[1275]\ttraining's rmse: 0.0876145\tvalid_1's rmse: 0.0916629\n",
      "[1300]\ttraining's rmse: 0.0875986\tvalid_1's rmse: 0.0916604\n",
      "[1325]\ttraining's rmse: 0.0875821\tvalid_1's rmse: 0.0916589\n",
      "[1350]\ttraining's rmse: 0.087567\tvalid_1's rmse: 0.0916578\n",
      "[1375]\ttraining's rmse: 0.087551\tvalid_1's rmse: 0.0916566\n",
      "[1400]\ttraining's rmse: 0.087536\tvalid_1's rmse: 0.0916546\n",
      "[1425]\ttraining's rmse: 0.0875223\tvalid_1's rmse: 0.0916533\n",
      "[1450]\ttraining's rmse: 0.0875083\tvalid_1's rmse: 0.0916526\n",
      "[1475]\ttraining's rmse: 0.0874947\tvalid_1's rmse: 0.091651\n",
      "[1500]\ttraining's rmse: 0.0874817\tvalid_1's rmse: 0.0916498\n",
      "[1525]\ttraining's rmse: 0.08747\tvalid_1's rmse: 0.0916486\n",
      "[1550]\ttraining's rmse: 0.0874591\tvalid_1's rmse: 0.0916482\n",
      "[1575]\ttraining's rmse: 0.0874493\tvalid_1's rmse: 0.0916473\n",
      "[1600]\ttraining's rmse: 0.0874395\tvalid_1's rmse: 0.0916462\n",
      "[1625]\ttraining's rmse: 0.0874287\tvalid_1's rmse: 0.0916452\n",
      "[1650]\ttraining's rmse: 0.0874196\tvalid_1's rmse: 0.0916447\n",
      "[1675]\ttraining's rmse: 0.0874116\tvalid_1's rmse: 0.0916434\n",
      "[1700]\ttraining's rmse: 0.0874039\tvalid_1's rmse: 0.0916419\n",
      "[1725]\ttraining's rmse: 0.0873956\tvalid_1's rmse: 0.0916404\n",
      "[1750]\ttraining's rmse: 0.0873859\tvalid_1's rmse: 0.0916395\n",
      "[1775]\ttraining's rmse: 0.0873785\tvalid_1's rmse: 0.0916398\n",
      "[1800]\ttraining's rmse: 0.0873724\tvalid_1's rmse: 0.091639\n",
      "[1825]\ttraining's rmse: 0.0873649\tvalid_1's rmse: 0.0916381\n",
      "[1850]\ttraining's rmse: 0.0873583\tvalid_1's rmse: 0.0916374\n",
      "[1875]\ttraining's rmse: 0.087351\tvalid_1's rmse: 0.0916365\n",
      "[1900]\ttraining's rmse: 0.0873471\tvalid_1's rmse: 0.0916364\n",
      "[1925]\ttraining's rmse: 0.0873423\tvalid_1's rmse: 0.0916358\n",
      "[1950]\ttraining's rmse: 0.0873376\tvalid_1's rmse: 0.0916351\n",
      "[1975]\ttraining's rmse: 0.0873331\tvalid_1's rmse: 0.0916347\n",
      "[2000]\ttraining's rmse: 0.0873278\tvalid_1's rmse: 0.0916344\n",
      "[2025]\ttraining's rmse: 0.0873223\tvalid_1's rmse: 0.0916336\n",
      "[2050]\ttraining's rmse: 0.0873151\tvalid_1's rmse: 0.0916335\n",
      "[2075]\ttraining's rmse: 0.0873107\tvalid_1's rmse: 0.0916333\n",
      "[2100]\ttraining's rmse: 0.0873071\tvalid_1's rmse: 0.091633\n",
      "[2125]\ttraining's rmse: 0.0873025\tvalid_1's rmse: 0.0916332\n",
      "Early stopping, best iteration is:\n",
      "[2099]\ttraining's rmse: 0.0873071\tvalid_1's rmse: 0.091633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0923879\tvalid_1's rmse: 0.0893737\n",
      "[50]\ttraining's rmse: 0.0922507\tvalid_1's rmse: 0.089325\n",
      "[75]\ttraining's rmse: 0.0921059\tvalid_1's rmse: 0.0892746\n",
      "[100]\ttraining's rmse: 0.0919785\tvalid_1's rmse: 0.0892318\n",
      "[125]\ttraining's rmse: 0.0918434\tvalid_1's rmse: 0.0891877\n",
      "[150]\ttraining's rmse: 0.0917207\tvalid_1's rmse: 0.089148\n",
      "[175]\ttraining's rmse: 0.0916165\tvalid_1's rmse: 0.0891169\n",
      "[200]\ttraining's rmse: 0.0915035\tvalid_1's rmse: 0.0890846\n",
      "[225]\ttraining's rmse: 0.0913963\tvalid_1's rmse: 0.0890526\n",
      "[250]\ttraining's rmse: 0.0913022\tvalid_1's rmse: 0.0890253\n",
      "[275]\ttraining's rmse: 0.0912192\tvalid_1's rmse: 0.0890018\n",
      "[300]\ttraining's rmse: 0.0911371\tvalid_1's rmse: 0.0889778\n",
      "[325]\ttraining's rmse: 0.0910525\tvalid_1's rmse: 0.088957\n",
      "[350]\ttraining's rmse: 0.0909723\tvalid_1's rmse: 0.0889365\n",
      "[375]\ttraining's rmse: 0.0909059\tvalid_1's rmse: 0.0889188\n",
      "[400]\ttraining's rmse: 0.0908326\tvalid_1's rmse: 0.0889022\n",
      "[425]\ttraining's rmse: 0.0907669\tvalid_1's rmse: 0.0888853\n",
      "[450]\ttraining's rmse: 0.0907027\tvalid_1's rmse: 0.0888695\n",
      "[475]\ttraining's rmse: 0.0906448\tvalid_1's rmse: 0.0888559\n",
      "[500]\ttraining's rmse: 0.090596\tvalid_1's rmse: 0.0888485\n",
      "[525]\ttraining's rmse: 0.0905289\tvalid_1's rmse: 0.0888353\n",
      "[550]\ttraining's rmse: 0.0904689\tvalid_1's rmse: 0.0888237\n",
      "[575]\ttraining's rmse: 0.090415\tvalid_1's rmse: 0.0888195\n",
      "[600]\ttraining's rmse: 0.0903622\tvalid_1's rmse: 0.0888132\n",
      "[625]\ttraining's rmse: 0.0903191\tvalid_1's rmse: 0.088804\n",
      "[650]\ttraining's rmse: 0.0902642\tvalid_1's rmse: 0.088801\n",
      "[675]\ttraining's rmse: 0.0902114\tvalid_1's rmse: 0.0887943\n",
      "[700]\ttraining's rmse: 0.0901649\tvalid_1's rmse: 0.0887931\n",
      "[725]\ttraining's rmse: 0.0901228\tvalid_1's rmse: 0.0887946\n",
      "Early stopping, best iteration is:\n",
      "[686]\ttraining's rmse: 0.0901878\tvalid_1's rmse: 0.0887905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0871488\tvalid_1's rmse: 0.0899039\n",
      "[50]\ttraining's rmse: 0.0870114\tvalid_1's rmse: 0.0898465\n",
      "[75]\ttraining's rmse: 0.0868742\tvalid_1's rmse: 0.0897862\n",
      "[100]\ttraining's rmse: 0.0867454\tvalid_1's rmse: 0.0897366\n",
      "[125]\ttraining's rmse: 0.086618\tvalid_1's rmse: 0.0896864\n",
      "[150]\ttraining's rmse: 0.0865025\tvalid_1's rmse: 0.0896403\n",
      "[175]\ttraining's rmse: 0.0864059\tvalid_1's rmse: 0.089601\n",
      "[200]\ttraining's rmse: 0.0863042\tvalid_1's rmse: 0.0895605\n",
      "[225]\ttraining's rmse: 0.0862056\tvalid_1's rmse: 0.089524\n",
      "[250]\ttraining's rmse: 0.086123\tvalid_1's rmse: 0.08949\n",
      "[275]\ttraining's rmse: 0.0860438\tvalid_1's rmse: 0.0894577\n",
      "[300]\ttraining's rmse: 0.0859676\tvalid_1's rmse: 0.0894276\n",
      "[325]\ttraining's rmse: 0.0858865\tvalid_1's rmse: 0.0894003\n",
      "[350]\ttraining's rmse: 0.0858125\tvalid_1's rmse: 0.0893725\n",
      "[375]\ttraining's rmse: 0.0857467\tvalid_1's rmse: 0.0893485\n",
      "[400]\ttraining's rmse: 0.085678\tvalid_1's rmse: 0.0893268\n",
      "[425]\ttraining's rmse: 0.0856178\tvalid_1's rmse: 0.0893054\n",
      "[450]\ttraining's rmse: 0.0855623\tvalid_1's rmse: 0.0892824\n",
      "[475]\ttraining's rmse: 0.0855064\tvalid_1's rmse: 0.0892632\n",
      "[500]\ttraining's rmse: 0.0854584\tvalid_1's rmse: 0.089245\n",
      "[525]\ttraining's rmse: 0.0854037\tvalid_1's rmse: 0.0892277\n",
      "[550]\ttraining's rmse: 0.0853514\tvalid_1's rmse: 0.0892096\n",
      "[575]\ttraining's rmse: 0.0853022\tvalid_1's rmse: 0.0891955\n",
      "[600]\ttraining's rmse: 0.0852548\tvalid_1's rmse: 0.0891809\n",
      "[625]\ttraining's rmse: 0.0852163\tvalid_1's rmse: 0.0891664\n",
      "[650]\ttraining's rmse: 0.0851731\tvalid_1's rmse: 0.0891539\n",
      "[675]\ttraining's rmse: 0.0851289\tvalid_1's rmse: 0.0891397\n",
      "[700]\ttraining's rmse: 0.0850908\tvalid_1's rmse: 0.0891268\n",
      "[725]\ttraining's rmse: 0.0850542\tvalid_1's rmse: 0.0891164\n",
      "[750]\ttraining's rmse: 0.0850168\tvalid_1's rmse: 0.089106\n",
      "[775]\ttraining's rmse: 0.0849875\tvalid_1's rmse: 0.0890936\n",
      "[800]\ttraining's rmse: 0.0849501\tvalid_1's rmse: 0.0890845\n",
      "[825]\ttraining's rmse: 0.0849199\tvalid_1's rmse: 0.0890745\n",
      "[850]\ttraining's rmse: 0.0848862\tvalid_1's rmse: 0.0890666\n",
      "[875]\ttraining's rmse: 0.0848598\tvalid_1's rmse: 0.0890571\n",
      "[900]\ttraining's rmse: 0.0848293\tvalid_1's rmse: 0.0890499\n",
      "[925]\ttraining's rmse: 0.0848014\tvalid_1's rmse: 0.0890421\n",
      "[950]\ttraining's rmse: 0.0847771\tvalid_1's rmse: 0.0890355\n",
      "[975]\ttraining's rmse: 0.084754\tvalid_1's rmse: 0.0890282\n",
      "[1000]\ttraining's rmse: 0.0847303\tvalid_1's rmse: 0.0890218\n",
      "[1025]\ttraining's rmse: 0.0847044\tvalid_1's rmse: 0.0890154\n",
      "[1050]\ttraining's rmse: 0.0846829\tvalid_1's rmse: 0.0890074\n",
      "[1075]\ttraining's rmse: 0.0846602\tvalid_1's rmse: 0.0890024\n",
      "[1100]\ttraining's rmse: 0.0846388\tvalid_1's rmse: 0.0889966\n",
      "[1125]\ttraining's rmse: 0.0846194\tvalid_1's rmse: 0.0889897\n",
      "[1150]\ttraining's rmse: 0.0845992\tvalid_1's rmse: 0.0889852\n",
      "[1175]\ttraining's rmse: 0.0845812\tvalid_1's rmse: 0.0889823\n",
      "[1200]\ttraining's rmse: 0.0845646\tvalid_1's rmse: 0.0889775\n",
      "[1225]\ttraining's rmse: 0.0845481\tvalid_1's rmse: 0.0889739\n",
      "[1250]\ttraining's rmse: 0.084533\tvalid_1's rmse: 0.0889691\n",
      "[1275]\ttraining's rmse: 0.0845151\tvalid_1's rmse: 0.0889652\n",
      "[1300]\ttraining's rmse: 0.084502\tvalid_1's rmse: 0.0889615\n",
      "[1325]\ttraining's rmse: 0.0844886\tvalid_1's rmse: 0.0889585\n",
      "[1350]\ttraining's rmse: 0.0844734\tvalid_1's rmse: 0.0889558\n",
      "[1375]\ttraining's rmse: 0.0844581\tvalid_1's rmse: 0.0889533\n",
      "[1400]\ttraining's rmse: 0.084448\tvalid_1's rmse: 0.0889484\n",
      "[1425]\ttraining's rmse: 0.0844318\tvalid_1's rmse: 0.0889461\n",
      "[1450]\ttraining's rmse: 0.0844161\tvalid_1's rmse: 0.0889428\n",
      "[1475]\ttraining's rmse: 0.0844047\tvalid_1's rmse: 0.0889397\n",
      "[1500]\ttraining's rmse: 0.0843946\tvalid_1's rmse: 0.0889366\n",
      "[1525]\ttraining's rmse: 0.084385\tvalid_1's rmse: 0.0889338\n",
      "[1550]\ttraining's rmse: 0.0843722\tvalid_1's rmse: 0.0889308\n",
      "[1575]\ttraining's rmse: 0.0843624\tvalid_1's rmse: 0.0889282\n",
      "[1600]\ttraining's rmse: 0.0843561\tvalid_1's rmse: 0.0889259\n",
      "[1625]\ttraining's rmse: 0.0843488\tvalid_1's rmse: 0.088922\n",
      "[1650]\ttraining's rmse: 0.0843425\tvalid_1's rmse: 0.0889202\n",
      "[1675]\ttraining's rmse: 0.0843346\tvalid_1's rmse: 0.0889182\n",
      "[1700]\ttraining's rmse: 0.0843277\tvalid_1's rmse: 0.0889157\n",
      "[1725]\ttraining's rmse: 0.0843197\tvalid_1's rmse: 0.0889141\n",
      "[1750]\ttraining's rmse: 0.0843124\tvalid_1's rmse: 0.0889118\n",
      "[1775]\ttraining's rmse: 0.0843054\tvalid_1's rmse: 0.0889099\n",
      "[1800]\ttraining's rmse: 0.0842993\tvalid_1's rmse: 0.0889083\n",
      "[1825]\ttraining's rmse: 0.0842941\tvalid_1's rmse: 0.0889065\n",
      "[1850]\ttraining's rmse: 0.0842904\tvalid_1's rmse: 0.0889051\n",
      "[1875]\ttraining's rmse: 0.084283\tvalid_1's rmse: 0.0889047\n",
      "[1900]\ttraining's rmse: 0.084276\tvalid_1's rmse: 0.0889028\n",
      "[1925]\ttraining's rmse: 0.0842703\tvalid_1's rmse: 0.088901\n",
      "[1950]\ttraining's rmse: 0.0842662\tvalid_1's rmse: 0.0888991\n",
      "[1975]\ttraining's rmse: 0.0842623\tvalid_1's rmse: 0.0888981\n",
      "[2000]\ttraining's rmse: 0.0842571\tvalid_1's rmse: 0.0888975\n",
      "[2025]\ttraining's rmse: 0.0842526\tvalid_1's rmse: 0.0888957\n",
      "[2050]\ttraining's rmse: 0.0842492\tvalid_1's rmse: 0.0888941\n",
      "[2075]\ttraining's rmse: 0.0842456\tvalid_1's rmse: 0.0888932\n",
      "[2100]\ttraining's rmse: 0.0842424\tvalid_1's rmse: 0.0888927\n",
      "[2125]\ttraining's rmse: 0.0842375\tvalid_1's rmse: 0.0888921\n",
      "[2150]\ttraining's rmse: 0.0842337\tvalid_1's rmse: 0.088891\n",
      "[2175]\ttraining's rmse: 0.0842306\tvalid_1's rmse: 0.0888907\n",
      "[2200]\ttraining's rmse: 0.0842279\tvalid_1's rmse: 0.0888904\n",
      "[2225]\ttraining's rmse: 0.0842241\tvalid_1's rmse: 0.088889\n",
      "[2250]\ttraining's rmse: 0.0842197\tvalid_1's rmse: 0.0888882\n",
      "[2275]\ttraining's rmse: 0.0842172\tvalid_1's rmse: 0.0888877\n",
      "[2300]\ttraining's rmse: 0.0842143\tvalid_1's rmse: 0.0888872\n",
      "[2325]\ttraining's rmse: 0.0842113\tvalid_1's rmse: 0.0888863\n",
      "[2350]\ttraining's rmse: 0.0842088\tvalid_1's rmse: 0.088886\n",
      "[2375]\ttraining's rmse: 0.0842068\tvalid_1's rmse: 0.0888855\n",
      "[2400]\ttraining's rmse: 0.084203\tvalid_1's rmse: 0.0888856\n",
      "[2425]\ttraining's rmse: 0.0841998\tvalid_1's rmse: 0.0888856\n",
      "Early stopping, best iteration is:\n",
      "[2383]\ttraining's rmse: 0.0842058\tvalid_1's rmse: 0.0888851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.087368\tvalid_1's rmse: 0.0894777\n",
      "[50]\ttraining's rmse: 0.0872368\tvalid_1's rmse: 0.0894207\n",
      "[75]\ttraining's rmse: 0.0871039\tvalid_1's rmse: 0.0893647\n",
      "[100]\ttraining's rmse: 0.0869859\tvalid_1's rmse: 0.0893155\n",
      "[125]\ttraining's rmse: 0.0868635\tvalid_1's rmse: 0.089267\n",
      "[150]\ttraining's rmse: 0.0867527\tvalid_1's rmse: 0.0892208\n",
      "[175]\ttraining's rmse: 0.0866588\tvalid_1's rmse: 0.0891844\n",
      "[200]\ttraining's rmse: 0.0865565\tvalid_1's rmse: 0.0891459\n",
      "[225]\ttraining's rmse: 0.0864601\tvalid_1's rmse: 0.0891102\n",
      "[250]\ttraining's rmse: 0.086377\tvalid_1's rmse: 0.0890771\n",
      "[275]\ttraining's rmse: 0.0863001\tvalid_1's rmse: 0.0890455\n",
      "[300]\ttraining's rmse: 0.0862236\tvalid_1's rmse: 0.0890172\n",
      "[325]\ttraining's rmse: 0.086142\tvalid_1's rmse: 0.0889892\n",
      "[350]\ttraining's rmse: 0.0860645\tvalid_1's rmse: 0.0889627\n",
      "[375]\ttraining's rmse: 0.0860028\tvalid_1's rmse: 0.0889405\n",
      "[400]\ttraining's rmse: 0.0859378\tvalid_1's rmse: 0.0889198\n",
      "[425]\ttraining's rmse: 0.0858739\tvalid_1's rmse: 0.0888984\n",
      "[450]\ttraining's rmse: 0.0858177\tvalid_1's rmse: 0.0888791\n",
      "[475]\ttraining's rmse: 0.0857602\tvalid_1's rmse: 0.0888597\n",
      "[500]\ttraining's rmse: 0.0857148\tvalid_1's rmse: 0.0888432\n",
      "[525]\ttraining's rmse: 0.0856576\tvalid_1's rmse: 0.0888266\n",
      "[550]\ttraining's rmse: 0.0856037\tvalid_1's rmse: 0.0888111\n",
      "[575]\ttraining's rmse: 0.0855522\tvalid_1's rmse: 0.088797\n",
      "[600]\ttraining's rmse: 0.0855055\tvalid_1's rmse: 0.088784\n",
      "[625]\ttraining's rmse: 0.0854676\tvalid_1's rmse: 0.0887717\n",
      "[650]\ttraining's rmse: 0.0854189\tvalid_1's rmse: 0.0887596\n",
      "[675]\ttraining's rmse: 0.0853704\tvalid_1's rmse: 0.0887471\n",
      "[700]\ttraining's rmse: 0.0853305\tvalid_1's rmse: 0.0887368\n",
      "[725]\ttraining's rmse: 0.0852925\tvalid_1's rmse: 0.0887273\n",
      "[750]\ttraining's rmse: 0.0852543\tvalid_1's rmse: 0.0887169\n",
      "[775]\ttraining's rmse: 0.0852247\tvalid_1's rmse: 0.0887081\n",
      "[800]\ttraining's rmse: 0.0851851\tvalid_1's rmse: 0.0887001\n",
      "[825]\ttraining's rmse: 0.0851532\tvalid_1's rmse: 0.0886926\n",
      "[850]\ttraining's rmse: 0.0851193\tvalid_1's rmse: 0.0886857\n",
      "[875]\ttraining's rmse: 0.0850897\tvalid_1's rmse: 0.0886789\n",
      "[900]\ttraining's rmse: 0.0850577\tvalid_1's rmse: 0.0886713\n",
      "[925]\ttraining's rmse: 0.0850289\tvalid_1's rmse: 0.0886649\n",
      "[950]\ttraining's rmse: 0.0850026\tvalid_1's rmse: 0.0886596\n",
      "[975]\ttraining's rmse: 0.0849767\tvalid_1's rmse: 0.0886546\n",
      "[1000]\ttraining's rmse: 0.0849543\tvalid_1's rmse: 0.088649\n",
      "[1025]\ttraining's rmse: 0.0849268\tvalid_1's rmse: 0.0886437\n",
      "[1050]\ttraining's rmse: 0.0849046\tvalid_1's rmse: 0.0886388\n",
      "[1075]\ttraining's rmse: 0.0848821\tvalid_1's rmse: 0.0886354\n",
      "[1100]\ttraining's rmse: 0.0848648\tvalid_1's rmse: 0.0886323\n",
      "[1125]\ttraining's rmse: 0.084843\tvalid_1's rmse: 0.0886289\n",
      "[1150]\ttraining's rmse: 0.0848226\tvalid_1's rmse: 0.0886252\n",
      "[1175]\ttraining's rmse: 0.0848043\tvalid_1's rmse: 0.0886222\n",
      "[1200]\ttraining's rmse: 0.0847851\tvalid_1's rmse: 0.0886194\n",
      "[1225]\ttraining's rmse: 0.0847671\tvalid_1's rmse: 0.0886168\n",
      "[1250]\ttraining's rmse: 0.0847517\tvalid_1's rmse: 0.088614\n",
      "[1275]\ttraining's rmse: 0.0847322\tvalid_1's rmse: 0.0886109\n",
      "[1300]\ttraining's rmse: 0.0847169\tvalid_1's rmse: 0.0886081\n",
      "[1325]\ttraining's rmse: 0.0847027\tvalid_1's rmse: 0.088606\n",
      "[1350]\ttraining's rmse: 0.0846868\tvalid_1's rmse: 0.0886041\n",
      "[1375]\ttraining's rmse: 0.0846739\tvalid_1's rmse: 0.0886025\n",
      "[1400]\ttraining's rmse: 0.0846605\tvalid_1's rmse: 0.0885998\n",
      "[1425]\ttraining's rmse: 0.0846465\tvalid_1's rmse: 0.0885983\n",
      "[1450]\ttraining's rmse: 0.0846342\tvalid_1's rmse: 0.0885977\n",
      "[1475]\ttraining's rmse: 0.0846227\tvalid_1's rmse: 0.0885957\n",
      "[1500]\ttraining's rmse: 0.0846112\tvalid_1's rmse: 0.0885943\n",
      "[1525]\ttraining's rmse: 0.0846004\tvalid_1's rmse: 0.0885928\n",
      "[1550]\ttraining's rmse: 0.0845904\tvalid_1's rmse: 0.0885917\n",
      "[1575]\ttraining's rmse: 0.0845817\tvalid_1's rmse: 0.0885905\n",
      "[1600]\ttraining's rmse: 0.084573\tvalid_1's rmse: 0.0885902\n",
      "[1625]\ttraining's rmse: 0.0845638\tvalid_1's rmse: 0.0885887\n",
      "[1650]\ttraining's rmse: 0.0845539\tvalid_1's rmse: 0.0885881\n",
      "[1675]\ttraining's rmse: 0.0845457\tvalid_1's rmse: 0.0885871\n",
      "[1700]\ttraining's rmse: 0.084537\tvalid_1's rmse: 0.0885863\n",
      "[1725]\ttraining's rmse: 0.084529\tvalid_1's rmse: 0.0885852\n",
      "[1750]\ttraining's rmse: 0.0845206\tvalid_1's rmse: 0.088585\n",
      "[1775]\ttraining's rmse: 0.0845145\tvalid_1's rmse: 0.0885843\n",
      "[1800]\ttraining's rmse: 0.084507\tvalid_1's rmse: 0.0885839\n",
      "[1825]\ttraining's rmse: 0.0844993\tvalid_1's rmse: 0.088583\n",
      "[1850]\ttraining's rmse: 0.0844922\tvalid_1's rmse: 0.0885815\n",
      "[1875]\ttraining's rmse: 0.0844853\tvalid_1's rmse: 0.0885809\n",
      "[1900]\ttraining's rmse: 0.0844793\tvalid_1's rmse: 0.088581\n",
      "[1925]\ttraining's rmse: 0.084473\tvalid_1's rmse: 0.0885802\n",
      "[1950]\ttraining's rmse: 0.0844682\tvalid_1's rmse: 0.0885792\n",
      "[1975]\ttraining's rmse: 0.0844643\tvalid_1's rmse: 0.0885786\n",
      "[2000]\ttraining's rmse: 0.0844588\tvalid_1's rmse: 0.0885778\n",
      "[2025]\ttraining's rmse: 0.0844546\tvalid_1's rmse: 0.0885776\n",
      "[2050]\ttraining's rmse: 0.0844499\tvalid_1's rmse: 0.0885772\n",
      "[2075]\ttraining's rmse: 0.0844467\tvalid_1's rmse: 0.0885766\n",
      "[2100]\ttraining's rmse: 0.0844417\tvalid_1's rmse: 0.088576\n",
      "[2125]\ttraining's rmse: 0.0844384\tvalid_1's rmse: 0.0885758\n",
      "[2150]\ttraining's rmse: 0.0844344\tvalid_1's rmse: 0.0885759\n",
      "[2175]\ttraining's rmse: 0.0844312\tvalid_1's rmse: 0.0885757\n",
      "[2200]\ttraining's rmse: 0.0844287\tvalid_1's rmse: 0.0885756\n",
      "[2225]\ttraining's rmse: 0.0844261\tvalid_1's rmse: 0.0885751\n",
      "[2250]\ttraining's rmse: 0.0844235\tvalid_1's rmse: 0.088575\n",
      "[2275]\ttraining's rmse: 0.0844203\tvalid_1's rmse: 0.0885746\n",
      "[2300]\ttraining's rmse: 0.084417\tvalid_1's rmse: 0.0885744\n",
      "[2325]\ttraining's rmse: 0.0844118\tvalid_1's rmse: 0.0885742\n",
      "[2350]\ttraining's rmse: 0.084409\tvalid_1's rmse: 0.0885742\n",
      "Early stopping, best iteration is:\n",
      "[2319]\ttraining's rmse: 0.0844132\tvalid_1's rmse: 0.088574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0895641\tvalid_1's rmse: 0.0850203\n",
      "[50]\ttraining's rmse: 0.0894409\tvalid_1's rmse: 0.0849707\n",
      "[75]\ttraining's rmse: 0.0893145\tvalid_1's rmse: 0.0849206\n",
      "[100]\ttraining's rmse: 0.0892024\tvalid_1's rmse: 0.0848781\n",
      "[125]\ttraining's rmse: 0.0890855\tvalid_1's rmse: 0.0848364\n",
      "[150]\ttraining's rmse: 0.0889784\tvalid_1's rmse: 0.0848018\n",
      "[175]\ttraining's rmse: 0.0888902\tvalid_1's rmse: 0.0847705\n",
      "[200]\ttraining's rmse: 0.0887954\tvalid_1's rmse: 0.0847381\n",
      "[225]\ttraining's rmse: 0.0887029\tvalid_1's rmse: 0.0847071\n",
      "[250]\ttraining's rmse: 0.0886234\tvalid_1's rmse: 0.0846808\n",
      "[275]\ttraining's rmse: 0.0885518\tvalid_1's rmse: 0.0846568\n",
      "[300]\ttraining's rmse: 0.0884787\tvalid_1's rmse: 0.084632\n",
      "[325]\ttraining's rmse: 0.0884062\tvalid_1's rmse: 0.08461\n",
      "[350]\ttraining's rmse: 0.0883338\tvalid_1's rmse: 0.0845885\n",
      "[375]\ttraining's rmse: 0.0882769\tvalid_1's rmse: 0.0845708\n",
      "[400]\ttraining's rmse: 0.0882138\tvalid_1's rmse: 0.0845552\n",
      "[425]\ttraining's rmse: 0.0881528\tvalid_1's rmse: 0.0845377\n",
      "[450]\ttraining's rmse: 0.0880955\tvalid_1's rmse: 0.0845209\n",
      "[475]\ttraining's rmse: 0.0880436\tvalid_1's rmse: 0.0845097\n",
      "[500]\ttraining's rmse: 0.0879985\tvalid_1's rmse: 0.0844952\n",
      "[525]\ttraining's rmse: 0.0879431\tvalid_1's rmse: 0.0844844\n",
      "[550]\ttraining's rmse: 0.0878913\tvalid_1's rmse: 0.084471\n",
      "[575]\ttraining's rmse: 0.0878437\tvalid_1's rmse: 0.0844645\n",
      "[600]\ttraining's rmse: 0.0877952\tvalid_1's rmse: 0.0844535\n",
      "[625]\ttraining's rmse: 0.0877599\tvalid_1's rmse: 0.0844488\n",
      "[650]\ttraining's rmse: 0.0877137\tvalid_1's rmse: 0.0844431\n",
      "[675]\ttraining's rmse: 0.0876654\tvalid_1's rmse: 0.0844326\n",
      "[700]\ttraining's rmse: 0.0876244\tvalid_1's rmse: 0.0844411\n",
      "[725]\ttraining's rmse: 0.087585\tvalid_1's rmse: 0.0844562\n",
      "Early stopping, best iteration is:\n",
      "[681]\ttraining's rmse: 0.0876552\tvalid_1's rmse: 0.0844307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0858839\tvalid_1's rmse: 0.0883257\n",
      "[50]\ttraining's rmse: 0.0857528\tvalid_1's rmse: 0.0882735\n",
      "[75]\ttraining's rmse: 0.0856213\tvalid_1's rmse: 0.0882204\n",
      "[100]\ttraining's rmse: 0.0854968\tvalid_1's rmse: 0.0881758\n",
      "[125]\ttraining's rmse: 0.0853733\tvalid_1's rmse: 0.0881299\n",
      "[150]\ttraining's rmse: 0.0852635\tvalid_1's rmse: 0.088086\n",
      "[175]\ttraining's rmse: 0.085173\tvalid_1's rmse: 0.0880502\n",
      "[200]\ttraining's rmse: 0.0850725\tvalid_1's rmse: 0.0880138\n",
      "[225]\ttraining's rmse: 0.0849739\tvalid_1's rmse: 0.0879783\n",
      "[250]\ttraining's rmse: 0.0848901\tvalid_1's rmse: 0.0879466\n",
      "[275]\ttraining's rmse: 0.0848136\tvalid_1's rmse: 0.0879187\n",
      "[300]\ttraining's rmse: 0.0847378\tvalid_1's rmse: 0.0878913\n",
      "[325]\ttraining's rmse: 0.0846619\tvalid_1's rmse: 0.0878639\n",
      "[350]\ttraining's rmse: 0.0845912\tvalid_1's rmse: 0.0878382\n",
      "[375]\ttraining's rmse: 0.0845315\tvalid_1's rmse: 0.0878176\n",
      "[400]\ttraining's rmse: 0.0844638\tvalid_1's rmse: 0.0877963\n",
      "[425]\ttraining's rmse: 0.0844032\tvalid_1's rmse: 0.0877745\n",
      "[450]\ttraining's rmse: 0.0843505\tvalid_1's rmse: 0.0877552\n",
      "[475]\ttraining's rmse: 0.084298\tvalid_1's rmse: 0.087737\n",
      "[500]\ttraining's rmse: 0.0842545\tvalid_1's rmse: 0.0877206\n",
      "[525]\ttraining's rmse: 0.0842004\tvalid_1's rmse: 0.0877039\n",
      "[550]\ttraining's rmse: 0.0841506\tvalid_1's rmse: 0.0876883\n",
      "[575]\ttraining's rmse: 0.0841055\tvalid_1's rmse: 0.0876744\n",
      "[600]\ttraining's rmse: 0.0840609\tvalid_1's rmse: 0.0876602\n",
      "[625]\ttraining's rmse: 0.0840259\tvalid_1's rmse: 0.0876484\n",
      "[650]\ttraining's rmse: 0.0839821\tvalid_1's rmse: 0.087636\n",
      "[675]\ttraining's rmse: 0.0839396\tvalid_1's rmse: 0.0876235\n",
      "[700]\ttraining's rmse: 0.0839026\tvalid_1's rmse: 0.0876109\n",
      "[725]\ttraining's rmse: 0.083865\tvalid_1's rmse: 0.0876009\n",
      "[750]\ttraining's rmse: 0.0838297\tvalid_1's rmse: 0.0875915\n",
      "[775]\ttraining's rmse: 0.0838033\tvalid_1's rmse: 0.0875833\n",
      "[800]\ttraining's rmse: 0.0837686\tvalid_1's rmse: 0.0875739\n",
      "[825]\ttraining's rmse: 0.0837378\tvalid_1's rmse: 0.0875641\n",
      "[850]\ttraining's rmse: 0.0837033\tvalid_1's rmse: 0.0875566\n",
      "[875]\ttraining's rmse: 0.0836764\tvalid_1's rmse: 0.0875496\n",
      "[900]\ttraining's rmse: 0.0836469\tvalid_1's rmse: 0.0875422\n",
      "[925]\ttraining's rmse: 0.0836209\tvalid_1's rmse: 0.0875341\n",
      "[950]\ttraining's rmse: 0.0835964\tvalid_1's rmse: 0.0875267\n",
      "[975]\ttraining's rmse: 0.0835738\tvalid_1's rmse: 0.0875214\n",
      "[1000]\ttraining's rmse: 0.0835497\tvalid_1's rmse: 0.087515\n",
      "[1025]\ttraining's rmse: 0.0835272\tvalid_1's rmse: 0.0875082\n",
      "[1050]\ttraining's rmse: 0.0835069\tvalid_1's rmse: 0.0875023\n",
      "[1075]\ttraining's rmse: 0.0834847\tvalid_1's rmse: 0.0874981\n",
      "[1100]\ttraining's rmse: 0.0834687\tvalid_1's rmse: 0.0874931\n",
      "[1125]\ttraining's rmse: 0.0834511\tvalid_1's rmse: 0.0874873\n",
      "[1150]\ttraining's rmse: 0.0834318\tvalid_1's rmse: 0.0874827\n",
      "[1175]\ttraining's rmse: 0.083416\tvalid_1's rmse: 0.0874796\n",
      "[1200]\ttraining's rmse: 0.0833972\tvalid_1's rmse: 0.0874732\n",
      "[1225]\ttraining's rmse: 0.0833804\tvalid_1's rmse: 0.0874675\n",
      "[1250]\ttraining's rmse: 0.0833663\tvalid_1's rmse: 0.0874639\n",
      "[1275]\ttraining's rmse: 0.0833478\tvalid_1's rmse: 0.0874592\n",
      "[1300]\ttraining's rmse: 0.0833325\tvalid_1's rmse: 0.0874544\n",
      "[1325]\ttraining's rmse: 0.0833181\tvalid_1's rmse: 0.0874513\n",
      "[1350]\ttraining's rmse: 0.0833018\tvalid_1's rmse: 0.0874481\n",
      "[1375]\ttraining's rmse: 0.0832872\tvalid_1's rmse: 0.0874453\n",
      "[1400]\ttraining's rmse: 0.0832765\tvalid_1's rmse: 0.0874419\n",
      "[1425]\ttraining's rmse: 0.0832624\tvalid_1's rmse: 0.0874393\n",
      "[1450]\ttraining's rmse: 0.0832478\tvalid_1's rmse: 0.0874363\n",
      "[1475]\ttraining's rmse: 0.0832394\tvalid_1's rmse: 0.087433\n",
      "[1500]\ttraining's rmse: 0.0832302\tvalid_1's rmse: 0.0874313\n",
      "[1525]\ttraining's rmse: 0.0832207\tvalid_1's rmse: 0.0874277\n",
      "[1550]\ttraining's rmse: 0.0832118\tvalid_1's rmse: 0.0874246\n",
      "[1575]\ttraining's rmse: 0.0832021\tvalid_1's rmse: 0.0874221\n",
      "[1600]\ttraining's rmse: 0.083195\tvalid_1's rmse: 0.087419\n",
      "[1625]\ttraining's rmse: 0.0831877\tvalid_1's rmse: 0.0874141\n",
      "[1650]\ttraining's rmse: 0.0831814\tvalid_1's rmse: 0.0874115\n",
      "[1675]\ttraining's rmse: 0.0831739\tvalid_1's rmse: 0.0874097\n",
      "[1700]\ttraining's rmse: 0.0831661\tvalid_1's rmse: 0.087407\n",
      "[1725]\ttraining's rmse: 0.0831572\tvalid_1's rmse: 0.0874044\n",
      "[1750]\ttraining's rmse: 0.0831489\tvalid_1's rmse: 0.0874021\n",
      "[1775]\ttraining's rmse: 0.0831423\tvalid_1's rmse: 0.0873994\n",
      "[1800]\ttraining's rmse: 0.0831368\tvalid_1's rmse: 0.0873973\n",
      "[1825]\ttraining's rmse: 0.0831302\tvalid_1's rmse: 0.0873958\n",
      "[1850]\ttraining's rmse: 0.0831249\tvalid_1's rmse: 0.0873933\n",
      "[1875]\ttraining's rmse: 0.0831198\tvalid_1's rmse: 0.0873922\n",
      "[1900]\ttraining's rmse: 0.0831158\tvalid_1's rmse: 0.0873912\n",
      "[1925]\ttraining's rmse: 0.0831097\tvalid_1's rmse: 0.0873895\n",
      "[1950]\ttraining's rmse: 0.0831061\tvalid_1's rmse: 0.0873887\n",
      "[1975]\ttraining's rmse: 0.0831028\tvalid_1's rmse: 0.0873879\n",
      "[2000]\ttraining's rmse: 0.0830979\tvalid_1's rmse: 0.0873863\n",
      "[2025]\ttraining's rmse: 0.0830946\tvalid_1's rmse: 0.0873834\n",
      "[2050]\ttraining's rmse: 0.0830912\tvalid_1's rmse: 0.087382\n",
      "[2075]\ttraining's rmse: 0.0830883\tvalid_1's rmse: 0.0873811\n",
      "[2100]\ttraining's rmse: 0.083085\tvalid_1's rmse: 0.0873798\n",
      "[2125]\ttraining's rmse: 0.083082\tvalid_1's rmse: 0.0873783\n",
      "[2150]\ttraining's rmse: 0.0830789\tvalid_1's rmse: 0.0873774\n",
      "[2175]\ttraining's rmse: 0.0830756\tvalid_1's rmse: 0.0873771\n",
      "[2200]\ttraining's rmse: 0.0830735\tvalid_1's rmse: 0.0873757\n",
      "[2225]\ttraining's rmse: 0.0830697\tvalid_1's rmse: 0.087375\n",
      "[2250]\ttraining's rmse: 0.0830663\tvalid_1's rmse: 0.087374\n",
      "[2275]\ttraining's rmse: 0.0830622\tvalid_1's rmse: 0.0873734\n",
      "[2300]\ttraining's rmse: 0.0830591\tvalid_1's rmse: 0.0873719\n",
      "[2325]\ttraining's rmse: 0.0830549\tvalid_1's rmse: 0.0873704\n",
      "[2350]\ttraining's rmse: 0.0830505\tvalid_1's rmse: 0.0873692\n",
      "[2375]\ttraining's rmse: 0.0830479\tvalid_1's rmse: 0.0873683\n",
      "[2400]\ttraining's rmse: 0.0830448\tvalid_1's rmse: 0.0873678\n",
      "[2425]\ttraining's rmse: 0.0830415\tvalid_1's rmse: 0.0873667\n",
      "[2450]\ttraining's rmse: 0.0830392\tvalid_1's rmse: 0.0873664\n",
      "[2475]\ttraining's rmse: 0.0830361\tvalid_1's rmse: 0.0873657\n",
      "[2500]\ttraining's rmse: 0.0830333\tvalid_1's rmse: 0.087365\n",
      "[2525]\ttraining's rmse: 0.0830294\tvalid_1's rmse: 0.087364\n",
      "[2550]\ttraining's rmse: 0.0830276\tvalid_1's rmse: 0.0873638\n",
      "[2575]\ttraining's rmse: 0.0830255\tvalid_1's rmse: 0.087363\n",
      "[2600]\ttraining's rmse: 0.0830229\tvalid_1's rmse: 0.0873624\n",
      "[2625]\ttraining's rmse: 0.0830221\tvalid_1's rmse: 0.0873622\n",
      "[2650]\ttraining's rmse: 0.0830205\tvalid_1's rmse: 0.0873615\n",
      "[2675]\ttraining's rmse: 0.0830183\tvalid_1's rmse: 0.0873604\n",
      "[2700]\ttraining's rmse: 0.0830162\tvalid_1's rmse: 0.0873604\n",
      "[2725]\ttraining's rmse: 0.0830149\tvalid_1's rmse: 0.0873601\n",
      "[2750]\ttraining's rmse: 0.0830132\tvalid_1's rmse: 0.0873591\n",
      "[2775]\ttraining's rmse: 0.0830121\tvalid_1's rmse: 0.0873588\n",
      "[2800]\ttraining's rmse: 0.0830099\tvalid_1's rmse: 0.0873587\n",
      "[2825]\ttraining's rmse: 0.0830083\tvalid_1's rmse: 0.0873587\n",
      "Early stopping, best iteration is:\n",
      "[2784]\ttraining's rmse: 0.0830108\tvalid_1's rmse: 0.0873585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0858697\tvalid_1's rmse: 0.0883646\n",
      "[50]\ttraining's rmse: 0.085747\tvalid_1's rmse: 0.0883107\n",
      "[75]\ttraining's rmse: 0.0856211\tvalid_1's rmse: 0.0882608\n",
      "[100]\ttraining's rmse: 0.0855098\tvalid_1's rmse: 0.0882154\n",
      "[125]\ttraining's rmse: 0.0853924\tvalid_1's rmse: 0.0881702\n",
      "[150]\ttraining's rmse: 0.0852851\tvalid_1's rmse: 0.0881273\n",
      "[175]\ttraining's rmse: 0.0851974\tvalid_1's rmse: 0.0880922\n",
      "[200]\ttraining's rmse: 0.0850983\tvalid_1's rmse: 0.088056\n",
      "[225]\ttraining's rmse: 0.0850047\tvalid_1's rmse: 0.0880221\n",
      "[250]\ttraining's rmse: 0.0849237\tvalid_1's rmse: 0.087991\n",
      "[275]\ttraining's rmse: 0.0848509\tvalid_1's rmse: 0.0879637\n",
      "[300]\ttraining's rmse: 0.0847788\tvalid_1's rmse: 0.0879376\n",
      "[325]\ttraining's rmse: 0.0847041\tvalid_1's rmse: 0.0879115\n",
      "[350]\ttraining's rmse: 0.0846309\tvalid_1's rmse: 0.0878864\n",
      "[375]\ttraining's rmse: 0.0845712\tvalid_1's rmse: 0.0878657\n",
      "[400]\ttraining's rmse: 0.0845053\tvalid_1's rmse: 0.0878456\n",
      "[425]\ttraining's rmse: 0.0844466\tvalid_1's rmse: 0.0878266\n",
      "[450]\ttraining's rmse: 0.0843939\tvalid_1's rmse: 0.087809\n",
      "[475]\ttraining's rmse: 0.0843411\tvalid_1's rmse: 0.0877933\n",
      "[500]\ttraining's rmse: 0.0842978\tvalid_1's rmse: 0.0877767\n",
      "[525]\ttraining's rmse: 0.0842426\tvalid_1's rmse: 0.0877611\n",
      "[550]\ttraining's rmse: 0.0841889\tvalid_1's rmse: 0.0877461\n",
      "[575]\ttraining's rmse: 0.0841442\tvalid_1's rmse: 0.0877325\n",
      "[600]\ttraining's rmse: 0.0841006\tvalid_1's rmse: 0.0877196\n",
      "[625]\ttraining's rmse: 0.0840653\tvalid_1's rmse: 0.0877077\n",
      "[650]\ttraining's rmse: 0.0840212\tvalid_1's rmse: 0.0876957\n",
      "[675]\ttraining's rmse: 0.0839774\tvalid_1's rmse: 0.0876837\n",
      "[700]\ttraining's rmse: 0.0839387\tvalid_1's rmse: 0.0876732\n",
      "[725]\ttraining's rmse: 0.0839037\tvalid_1's rmse: 0.0876634\n",
      "[750]\ttraining's rmse: 0.0838682\tvalid_1's rmse: 0.0876547\n",
      "[775]\ttraining's rmse: 0.0838386\tvalid_1's rmse: 0.0876461\n",
      "[800]\ttraining's rmse: 0.0838003\tvalid_1's rmse: 0.0876374\n",
      "[825]\ttraining's rmse: 0.0837694\tvalid_1's rmse: 0.0876289\n",
      "[850]\ttraining's rmse: 0.0837381\tvalid_1's rmse: 0.0876225\n",
      "[875]\ttraining's rmse: 0.0837113\tvalid_1's rmse: 0.0876158\n",
      "[900]\ttraining's rmse: 0.0836813\tvalid_1's rmse: 0.0876097\n",
      "[925]\ttraining's rmse: 0.0836548\tvalid_1's rmse: 0.0876037\n",
      "[950]\ttraining's rmse: 0.0836279\tvalid_1's rmse: 0.087598\n",
      "[975]\ttraining's rmse: 0.083604\tvalid_1's rmse: 0.0875924\n",
      "[1000]\ttraining's rmse: 0.0835819\tvalid_1's rmse: 0.0875872\n",
      "[1025]\ttraining's rmse: 0.083557\tvalid_1's rmse: 0.0875826\n",
      "[1050]\ttraining's rmse: 0.0835358\tvalid_1's rmse: 0.087578\n",
      "[1075]\ttraining's rmse: 0.083514\tvalid_1's rmse: 0.0875745\n",
      "[1100]\ttraining's rmse: 0.0834951\tvalid_1's rmse: 0.0875712\n",
      "[1125]\ttraining's rmse: 0.0834749\tvalid_1's rmse: 0.0875679\n",
      "[1150]\ttraining's rmse: 0.0834543\tvalid_1's rmse: 0.087564\n",
      "[1175]\ttraining's rmse: 0.0834369\tvalid_1's rmse: 0.0875604\n",
      "[1200]\ttraining's rmse: 0.0834202\tvalid_1's rmse: 0.0875576\n",
      "[1225]\ttraining's rmse: 0.083404\tvalid_1's rmse: 0.0875545\n",
      "[1250]\ttraining's rmse: 0.0833897\tvalid_1's rmse: 0.0875524\n",
      "[1275]\ttraining's rmse: 0.083374\tvalid_1's rmse: 0.0875499\n",
      "[1300]\ttraining's rmse: 0.0833598\tvalid_1's rmse: 0.0875473\n",
      "[1325]\ttraining's rmse: 0.0833461\tvalid_1's rmse: 0.0875457\n",
      "[1350]\ttraining's rmse: 0.0833308\tvalid_1's rmse: 0.0875439\n",
      "[1375]\ttraining's rmse: 0.0833167\tvalid_1's rmse: 0.0875424\n",
      "[1400]\ttraining's rmse: 0.083306\tvalid_1's rmse: 0.0875403\n",
      "[1425]\ttraining's rmse: 0.0832943\tvalid_1's rmse: 0.0875389\n",
      "[1450]\ttraining's rmse: 0.0832833\tvalid_1's rmse: 0.0875378\n",
      "[1475]\ttraining's rmse: 0.083272\tvalid_1's rmse: 0.0875358\n",
      "[1500]\ttraining's rmse: 0.0832622\tvalid_1's rmse: 0.0875343\n",
      "[1525]\ttraining's rmse: 0.0832489\tvalid_1's rmse: 0.0875325\n",
      "[1550]\ttraining's rmse: 0.08324\tvalid_1's rmse: 0.0875315\n",
      "[1575]\ttraining's rmse: 0.083232\tvalid_1's rmse: 0.0875307\n",
      "[1600]\ttraining's rmse: 0.0832241\tvalid_1's rmse: 0.0875304\n",
      "[1625]\ttraining's rmse: 0.0832146\tvalid_1's rmse: 0.0875288\n",
      "[1650]\ttraining's rmse: 0.0832074\tvalid_1's rmse: 0.0875282\n",
      "[1675]\ttraining's rmse: 0.0832005\tvalid_1's rmse: 0.0875267\n",
      "[1700]\ttraining's rmse: 0.0831936\tvalid_1's rmse: 0.0875257\n",
      "[1725]\ttraining's rmse: 0.0831873\tvalid_1's rmse: 0.0875248\n",
      "[1750]\ttraining's rmse: 0.08318\tvalid_1's rmse: 0.0875237\n",
      "[1775]\ttraining's rmse: 0.0831744\tvalid_1's rmse: 0.0875235\n",
      "[1800]\ttraining's rmse: 0.083168\tvalid_1's rmse: 0.0875228\n",
      "[1825]\ttraining's rmse: 0.0831617\tvalid_1's rmse: 0.0875223\n",
      "[1850]\ttraining's rmse: 0.0831554\tvalid_1's rmse: 0.0875215\n",
      "[1875]\ttraining's rmse: 0.0831497\tvalid_1's rmse: 0.0875212\n",
      "[1900]\ttraining's rmse: 0.0831456\tvalid_1's rmse: 0.087521\n",
      "[1925]\ttraining's rmse: 0.0831403\tvalid_1's rmse: 0.0875201\n",
      "[1950]\ttraining's rmse: 0.0831358\tvalid_1's rmse: 0.0875196\n",
      "[1975]\ttraining's rmse: 0.0831317\tvalid_1's rmse: 0.0875192\n",
      "[2000]\ttraining's rmse: 0.0831257\tvalid_1's rmse: 0.0875186\n",
      "[2025]\ttraining's rmse: 0.0831228\tvalid_1's rmse: 0.0875178\n",
      "[2050]\ttraining's rmse: 0.083118\tvalid_1's rmse: 0.0875175\n",
      "[2075]\ttraining's rmse: 0.0831152\tvalid_1's rmse: 0.087517\n",
      "[2100]\ttraining's rmse: 0.0831129\tvalid_1's rmse: 0.0875168\n",
      "[2125]\ttraining's rmse: 0.083109\tvalid_1's rmse: 0.0875165\n",
      "[2150]\ttraining's rmse: 0.0831049\tvalid_1's rmse: 0.0875168\n",
      "Early stopping, best iteration is:\n",
      "[2124]\ttraining's rmse: 0.0831091\tvalid_1's rmse: 0.0875164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0882259\tvalid_1's rmse: 0.0835917\n",
      "[50]\ttraining's rmse: 0.0881147\tvalid_1's rmse: 0.0835432\n",
      "[75]\ttraining's rmse: 0.0879975\tvalid_1's rmse: 0.0834957\n",
      "[100]\ttraining's rmse: 0.0878933\tvalid_1's rmse: 0.0834543\n",
      "[125]\ttraining's rmse: 0.087787\tvalid_1's rmse: 0.0834195\n",
      "[150]\ttraining's rmse: 0.0876882\tvalid_1's rmse: 0.0833815\n",
      "[175]\ttraining's rmse: 0.0876039\tvalid_1's rmse: 0.0833526\n",
      "[200]\ttraining's rmse: 0.0875131\tvalid_1's rmse: 0.083321\n",
      "[225]\ttraining's rmse: 0.087424\tvalid_1's rmse: 0.0832887\n",
      "[250]\ttraining's rmse: 0.087351\tvalid_1's rmse: 0.0832628\n",
      "[275]\ttraining's rmse: 0.0872836\tvalid_1's rmse: 0.0832378\n",
      "[300]\ttraining's rmse: 0.0872137\tvalid_1's rmse: 0.083214\n",
      "[325]\ttraining's rmse: 0.0871465\tvalid_1's rmse: 0.083193\n",
      "[350]\ttraining's rmse: 0.0870791\tvalid_1's rmse: 0.0831702\n",
      "[375]\ttraining's rmse: 0.0870261\tvalid_1's rmse: 0.0831547\n",
      "[400]\ttraining's rmse: 0.0869671\tvalid_1's rmse: 0.0831478\n",
      "[425]\ttraining's rmse: 0.0869124\tvalid_1's rmse: 0.0831306\n",
      "[450]\ttraining's rmse: 0.0868644\tvalid_1's rmse: 0.0831144\n",
      "[475]\ttraining's rmse: 0.0868163\tvalid_1's rmse: 0.0831052\n",
      "[500]\ttraining's rmse: 0.0867766\tvalid_1's rmse: 0.0830921\n",
      "[525]\ttraining's rmse: 0.0867228\tvalid_1's rmse: 0.0830828\n",
      "[550]\ttraining's rmse: 0.086675\tvalid_1's rmse: 0.0830693\n",
      "[575]\ttraining's rmse: 0.0866289\tvalid_1's rmse: 0.0830613\n",
      "[600]\ttraining's rmse: 0.0865851\tvalid_1's rmse: 0.083056\n",
      "[625]\ttraining's rmse: 0.086552\tvalid_1's rmse: 0.0830469\n",
      "[650]\ttraining's rmse: 0.0865071\tvalid_1's rmse: 0.0830477\n",
      "[675]\ttraining's rmse: 0.0864638\tvalid_1's rmse: 0.0830431\n",
      "[700]\ttraining's rmse: 0.0864226\tvalid_1's rmse: 0.0830442\n",
      "[725]\ttraining's rmse: 0.0863883\tvalid_1's rmse: 0.0830423\n",
      "[750]\ttraining's rmse: 0.0863554\tvalid_1's rmse: 0.0830346\n",
      "[775]\ttraining's rmse: 0.0863274\tvalid_1's rmse: 0.0830402\n",
      "[800]\ttraining's rmse: 0.0862922\tvalid_1's rmse: 0.0830335\n",
      "[825]\ttraining's rmse: 0.0862609\tvalid_1's rmse: 0.0830271\n",
      "[850]\ttraining's rmse: 0.0862303\tvalid_1's rmse: 0.0830284\n",
      "[875]\ttraining's rmse: 0.086204\tvalid_1's rmse: 0.0830446\n",
      "Early stopping, best iteration is:\n",
      "[845]\ttraining's rmse: 0.086237\tvalid_1's rmse: 0.0830224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0854706\tvalid_1's rmse: 0.0880649\n",
      "[50]\ttraining's rmse: 0.0853415\tvalid_1's rmse: 0.0880123\n",
      "[75]\ttraining's rmse: 0.0852159\tvalid_1's rmse: 0.0879612\n",
      "[100]\ttraining's rmse: 0.0850985\tvalid_1's rmse: 0.0879165\n",
      "[125]\ttraining's rmse: 0.0849798\tvalid_1's rmse: 0.0878691\n",
      "[150]\ttraining's rmse: 0.084869\tvalid_1's rmse: 0.0878255\n",
      "[175]\ttraining's rmse: 0.0847767\tvalid_1's rmse: 0.0877885\n",
      "[200]\ttraining's rmse: 0.084681\tvalid_1's rmse: 0.0877515\n",
      "[225]\ttraining's rmse: 0.0845845\tvalid_1's rmse: 0.0877159\n",
      "[250]\ttraining's rmse: 0.0845054\tvalid_1's rmse: 0.0876855\n",
      "[275]\ttraining's rmse: 0.0844291\tvalid_1's rmse: 0.0876573\n",
      "[300]\ttraining's rmse: 0.0843539\tvalid_1's rmse: 0.0876285\n",
      "[325]\ttraining's rmse: 0.0842794\tvalid_1's rmse: 0.0876028\n",
      "[350]\ttraining's rmse: 0.0842076\tvalid_1's rmse: 0.087577\n",
      "[375]\ttraining's rmse: 0.0841484\tvalid_1's rmse: 0.0875558\n",
      "[400]\ttraining's rmse: 0.0840879\tvalid_1's rmse: 0.0875351\n",
      "[425]\ttraining's rmse: 0.0840333\tvalid_1's rmse: 0.087514\n",
      "[450]\ttraining's rmse: 0.083982\tvalid_1's rmse: 0.0874951\n",
      "[475]\ttraining's rmse: 0.0839306\tvalid_1's rmse: 0.0874775\n",
      "[500]\ttraining's rmse: 0.0838886\tvalid_1's rmse: 0.0874604\n",
      "[525]\ttraining's rmse: 0.0838328\tvalid_1's rmse: 0.0874432\n",
      "[550]\ttraining's rmse: 0.0837854\tvalid_1's rmse: 0.0874293\n",
      "[575]\ttraining's rmse: 0.0837379\tvalid_1's rmse: 0.0874164\n",
      "[600]\ttraining's rmse: 0.0836953\tvalid_1's rmse: 0.0874024\n",
      "[625]\ttraining's rmse: 0.0836588\tvalid_1's rmse: 0.08739\n",
      "[650]\ttraining's rmse: 0.0836149\tvalid_1's rmse: 0.087378\n",
      "[675]\ttraining's rmse: 0.0835753\tvalid_1's rmse: 0.0873669\n",
      "[700]\ttraining's rmse: 0.0835384\tvalid_1's rmse: 0.0873557\n",
      "[725]\ttraining's rmse: 0.083503\tvalid_1's rmse: 0.0873464\n",
      "[750]\ttraining's rmse: 0.0834702\tvalid_1's rmse: 0.0873369\n",
      "[775]\ttraining's rmse: 0.0834459\tvalid_1's rmse: 0.087328\n",
      "[800]\ttraining's rmse: 0.0834142\tvalid_1's rmse: 0.0873186\n",
      "[825]\ttraining's rmse: 0.0833857\tvalid_1's rmse: 0.0873094\n",
      "[850]\ttraining's rmse: 0.0833526\tvalid_1's rmse: 0.0873021\n",
      "[875]\ttraining's rmse: 0.0833286\tvalid_1's rmse: 0.0872924\n",
      "[900]\ttraining's rmse: 0.0832998\tvalid_1's rmse: 0.0872856\n",
      "[925]\ttraining's rmse: 0.083273\tvalid_1's rmse: 0.087279\n",
      "[950]\ttraining's rmse: 0.0832472\tvalid_1's rmse: 0.0872706\n",
      "[975]\ttraining's rmse: 0.0832232\tvalid_1's rmse: 0.087264\n",
      "[1000]\ttraining's rmse: 0.0831998\tvalid_1's rmse: 0.0872573\n",
      "[1025]\ttraining's rmse: 0.083176\tvalid_1's rmse: 0.0872505\n",
      "[1050]\ttraining's rmse: 0.083155\tvalid_1's rmse: 0.0872432\n",
      "[1075]\ttraining's rmse: 0.0831353\tvalid_1's rmse: 0.0872382\n",
      "[1100]\ttraining's rmse: 0.0831168\tvalid_1's rmse: 0.0872322\n",
      "[1125]\ttraining's rmse: 0.0830964\tvalid_1's rmse: 0.0872263\n",
      "[1150]\ttraining's rmse: 0.083076\tvalid_1's rmse: 0.0872228\n",
      "[1175]\ttraining's rmse: 0.0830569\tvalid_1's rmse: 0.0872196\n",
      "[1200]\ttraining's rmse: 0.0830394\tvalid_1's rmse: 0.0872137\n",
      "[1225]\ttraining's rmse: 0.0830239\tvalid_1's rmse: 0.087209\n",
      "[1250]\ttraining's rmse: 0.08301\tvalid_1's rmse: 0.0872042\n",
      "[1275]\ttraining's rmse: 0.0829951\tvalid_1's rmse: 0.0872002\n",
      "[1300]\ttraining's rmse: 0.0829829\tvalid_1's rmse: 0.0871959\n",
      "[1325]\ttraining's rmse: 0.0829674\tvalid_1's rmse: 0.0871925\n",
      "[1350]\ttraining's rmse: 0.0829549\tvalid_1's rmse: 0.0871894\n",
      "[1375]\ttraining's rmse: 0.0829413\tvalid_1's rmse: 0.0871859\n",
      "[1400]\ttraining's rmse: 0.0829283\tvalid_1's rmse: 0.087182\n",
      "[1425]\ttraining's rmse: 0.082916\tvalid_1's rmse: 0.0871791\n",
      "[1450]\ttraining's rmse: 0.0829045\tvalid_1's rmse: 0.087176\n",
      "[1475]\ttraining's rmse: 0.0828949\tvalid_1's rmse: 0.0871735\n",
      "[1500]\ttraining's rmse: 0.0828861\tvalid_1's rmse: 0.0871711\n",
      "[1525]\ttraining's rmse: 0.0828768\tvalid_1's rmse: 0.0871682\n",
      "[1550]\ttraining's rmse: 0.0828669\tvalid_1's rmse: 0.0871659\n",
      "[1575]\ttraining's rmse: 0.0828588\tvalid_1's rmse: 0.0871632\n",
      "[1600]\ttraining's rmse: 0.0828495\tvalid_1's rmse: 0.0871611\n",
      "[1625]\ttraining's rmse: 0.0828424\tvalid_1's rmse: 0.0871594\n",
      "[1650]\ttraining's rmse: 0.0828345\tvalid_1's rmse: 0.0871576\n",
      "[1675]\ttraining's rmse: 0.0828285\tvalid_1's rmse: 0.0871545\n",
      "[1700]\ttraining's rmse: 0.0828223\tvalid_1's rmse: 0.0871521\n",
      "[1725]\ttraining's rmse: 0.0828147\tvalid_1's rmse: 0.0871495\n",
      "[1750]\ttraining's rmse: 0.0828071\tvalid_1's rmse: 0.0871465\n",
      "[1775]\ttraining's rmse: 0.0828008\tvalid_1's rmse: 0.087144\n",
      "[1800]\ttraining's rmse: 0.0827957\tvalid_1's rmse: 0.0871418\n",
      "[1825]\ttraining's rmse: 0.0827908\tvalid_1's rmse: 0.0871396\n",
      "[1850]\ttraining's rmse: 0.0827858\tvalid_1's rmse: 0.0871371\n",
      "[1875]\ttraining's rmse: 0.0827795\tvalid_1's rmse: 0.0871361\n",
      "[1900]\ttraining's rmse: 0.0827752\tvalid_1's rmse: 0.0871349\n",
      "[1925]\ttraining's rmse: 0.0827708\tvalid_1's rmse: 0.0871346\n",
      "[1950]\ttraining's rmse: 0.0827663\tvalid_1's rmse: 0.0871327\n",
      "[1975]\ttraining's rmse: 0.0827625\tvalid_1's rmse: 0.087132\n",
      "[2000]\ttraining's rmse: 0.0827576\tvalid_1's rmse: 0.0871295\n",
      "[2025]\ttraining's rmse: 0.0827536\tvalid_1's rmse: 0.0871279\n",
      "[2050]\ttraining's rmse: 0.0827491\tvalid_1's rmse: 0.0871268\n",
      "[2075]\ttraining's rmse: 0.082747\tvalid_1's rmse: 0.0871249\n",
      "[2100]\ttraining's rmse: 0.0827434\tvalid_1's rmse: 0.0871238\n",
      "[2125]\ttraining's rmse: 0.0827396\tvalid_1's rmse: 0.0871236\n",
      "[2150]\ttraining's rmse: 0.0827341\tvalid_1's rmse: 0.0871223\n",
      "[2175]\ttraining's rmse: 0.0827308\tvalid_1's rmse: 0.0871209\n",
      "[2200]\ttraining's rmse: 0.0827265\tvalid_1's rmse: 0.0871203\n",
      "[2225]\ttraining's rmse: 0.0827231\tvalid_1's rmse: 0.0871192\n",
      "[2250]\ttraining's rmse: 0.0827205\tvalid_1's rmse: 0.0871179\n",
      "[2275]\ttraining's rmse: 0.0827172\tvalid_1's rmse: 0.0871172\n",
      "[2300]\ttraining's rmse: 0.0827149\tvalid_1's rmse: 0.0871163\n",
      "[2325]\ttraining's rmse: 0.0827112\tvalid_1's rmse: 0.0871146\n",
      "[2350]\ttraining's rmse: 0.0827074\tvalid_1's rmse: 0.0871143\n",
      "[2375]\ttraining's rmse: 0.0827053\tvalid_1's rmse: 0.0871137\n",
      "[2400]\ttraining's rmse: 0.0827021\tvalid_1's rmse: 0.0871138\n",
      "[2425]\ttraining's rmse: 0.0827005\tvalid_1's rmse: 0.0871131\n",
      "[2450]\ttraining's rmse: 0.0826977\tvalid_1's rmse: 0.0871122\n",
      "[2475]\ttraining's rmse: 0.0826944\tvalid_1's rmse: 0.0871118\n",
      "[2500]\ttraining's rmse: 0.082693\tvalid_1's rmse: 0.0871115\n",
      "[2525]\ttraining's rmse: 0.0826905\tvalid_1's rmse: 0.0871104\n",
      "[2550]\ttraining's rmse: 0.0826881\tvalid_1's rmse: 0.0871099\n",
      "[2575]\ttraining's rmse: 0.0826862\tvalid_1's rmse: 0.0871098\n",
      "[2600]\ttraining's rmse: 0.0826841\tvalid_1's rmse: 0.0871091\n",
      "[2625]\ttraining's rmse: 0.0826834\tvalid_1's rmse: 0.0871087\n",
      "[2650]\ttraining's rmse: 0.0826813\tvalid_1's rmse: 0.0871079\n",
      "[2675]\ttraining's rmse: 0.0826787\tvalid_1's rmse: 0.0871064\n",
      "[2700]\ttraining's rmse: 0.0826761\tvalid_1's rmse: 0.0871062\n",
      "[2725]\ttraining's rmse: 0.082674\tvalid_1's rmse: 0.0871056\n",
      "[2750]\ttraining's rmse: 0.0826725\tvalid_1's rmse: 0.0871056\n",
      "[2775]\ttraining's rmse: 0.0826705\tvalid_1's rmse: 0.0871058\n",
      "[2800]\ttraining's rmse: 0.0826693\tvalid_1's rmse: 0.0871049\n",
      "[2825]\ttraining's rmse: 0.0826661\tvalid_1's rmse: 0.0871047\n",
      "[2850]\ttraining's rmse: 0.0826648\tvalid_1's rmse: 0.0871047\n",
      "[2875]\ttraining's rmse: 0.0826637\tvalid_1's rmse: 0.0871044\n",
      "[2900]\ttraining's rmse: 0.0826618\tvalid_1's rmse: 0.0871042\n",
      "[2925]\ttraining's rmse: 0.0826612\tvalid_1's rmse: 0.0871039\n",
      "[2950]\ttraining's rmse: 0.0826605\tvalid_1's rmse: 0.0871034\n",
      "[2975]\ttraining's rmse: 0.0826584\tvalid_1's rmse: 0.0871031\n",
      "[3000]\ttraining's rmse: 0.0826571\tvalid_1's rmse: 0.0871024\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0826571\tvalid_1's rmse: 0.0871024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0854981\tvalid_1's rmse: 0.0880181\n",
      "[50]\ttraining's rmse: 0.0853802\tvalid_1's rmse: 0.0879644\n",
      "[75]\ttraining's rmse: 0.0852576\tvalid_1's rmse: 0.0879133\n",
      "[100]\ttraining's rmse: 0.08515\tvalid_1's rmse: 0.0878674\n",
      "[125]\ttraining's rmse: 0.0850369\tvalid_1's rmse: 0.0878213\n",
      "[150]\ttraining's rmse: 0.0849341\tvalid_1's rmse: 0.0877793\n",
      "[175]\ttraining's rmse: 0.0848476\tvalid_1's rmse: 0.0877448\n",
      "[200]\ttraining's rmse: 0.0847517\tvalid_1's rmse: 0.0877082\n",
      "[225]\ttraining's rmse: 0.0846594\tvalid_1's rmse: 0.0876733\n",
      "[250]\ttraining's rmse: 0.0845813\tvalid_1's rmse: 0.0876437\n",
      "[275]\ttraining's rmse: 0.0845091\tvalid_1's rmse: 0.0876157\n",
      "[300]\ttraining's rmse: 0.084437\tvalid_1's rmse: 0.087589\n",
      "[325]\ttraining's rmse: 0.0843633\tvalid_1's rmse: 0.0875621\n",
      "[350]\ttraining's rmse: 0.084292\tvalid_1's rmse: 0.0875378\n",
      "[375]\ttraining's rmse: 0.084235\tvalid_1's rmse: 0.0875177\n",
      "[400]\ttraining's rmse: 0.084173\tvalid_1's rmse: 0.0874993\n",
      "[425]\ttraining's rmse: 0.0841155\tvalid_1's rmse: 0.0874797\n",
      "[450]\ttraining's rmse: 0.0840653\tvalid_1's rmse: 0.0874625\n",
      "[475]\ttraining's rmse: 0.0840146\tvalid_1's rmse: 0.0874454\n",
      "[500]\ttraining's rmse: 0.0839743\tvalid_1's rmse: 0.0874302\n",
      "[525]\ttraining's rmse: 0.0839185\tvalid_1's rmse: 0.0874129\n",
      "[550]\ttraining's rmse: 0.0838671\tvalid_1's rmse: 0.0873992\n",
      "[575]\ttraining's rmse: 0.0838211\tvalid_1's rmse: 0.087385\n",
      "[600]\ttraining's rmse: 0.0837762\tvalid_1's rmse: 0.0873721\n",
      "[625]\ttraining's rmse: 0.0837412\tvalid_1's rmse: 0.0873607\n",
      "[650]\ttraining's rmse: 0.0836958\tvalid_1's rmse: 0.0873468\n",
      "[675]\ttraining's rmse: 0.0836524\tvalid_1's rmse: 0.0873361\n",
      "[700]\ttraining's rmse: 0.0836141\tvalid_1's rmse: 0.0873253\n",
      "[725]\ttraining's rmse: 0.0835816\tvalid_1's rmse: 0.0873165\n",
      "[750]\ttraining's rmse: 0.0835473\tvalid_1's rmse: 0.0873069\n",
      "[775]\ttraining's rmse: 0.0835218\tvalid_1's rmse: 0.0872991\n",
      "[800]\ttraining's rmse: 0.083487\tvalid_1's rmse: 0.0872916\n",
      "[825]\ttraining's rmse: 0.0834565\tvalid_1's rmse: 0.0872834\n",
      "[850]\ttraining's rmse: 0.0834266\tvalid_1's rmse: 0.0872763\n",
      "[875]\ttraining's rmse: 0.0834001\tvalid_1's rmse: 0.0872695\n",
      "[900]\ttraining's rmse: 0.083372\tvalid_1's rmse: 0.0872626\n",
      "[925]\ttraining's rmse: 0.0833447\tvalid_1's rmse: 0.0872567\n",
      "[950]\ttraining's rmse: 0.0833187\tvalid_1's rmse: 0.0872515\n",
      "[975]\ttraining's rmse: 0.0832944\tvalid_1's rmse: 0.0872464\n",
      "[1000]\ttraining's rmse: 0.0832721\tvalid_1's rmse: 0.0872413\n",
      "[1025]\ttraining's rmse: 0.0832447\tvalid_1's rmse: 0.087236\n",
      "[1050]\ttraining's rmse: 0.0832238\tvalid_1's rmse: 0.0872313\n",
      "[1075]\ttraining's rmse: 0.0832014\tvalid_1's rmse: 0.0872279\n",
      "[1100]\ttraining's rmse: 0.0831845\tvalid_1's rmse: 0.0872243\n",
      "[1125]\ttraining's rmse: 0.0831668\tvalid_1's rmse: 0.0872206\n",
      "[1150]\ttraining's rmse: 0.0831471\tvalid_1's rmse: 0.0872167\n",
      "[1175]\ttraining's rmse: 0.0831316\tvalid_1's rmse: 0.0872138\n",
      "[1200]\ttraining's rmse: 0.0831147\tvalid_1's rmse: 0.0872105\n",
      "[1225]\ttraining's rmse: 0.0830988\tvalid_1's rmse: 0.087208\n",
      "[1250]\ttraining's rmse: 0.0830851\tvalid_1's rmse: 0.087205\n",
      "[1275]\ttraining's rmse: 0.0830704\tvalid_1's rmse: 0.0872031\n",
      "[1300]\ttraining's rmse: 0.0830561\tvalid_1's rmse: 0.0872005\n",
      "[1325]\ttraining's rmse: 0.0830424\tvalid_1's rmse: 0.0871988\n",
      "[1350]\ttraining's rmse: 0.0830282\tvalid_1's rmse: 0.0871976\n",
      "[1375]\ttraining's rmse: 0.083016\tvalid_1's rmse: 0.0871961\n",
      "[1400]\ttraining's rmse: 0.083006\tvalid_1's rmse: 0.087194\n",
      "[1425]\ttraining's rmse: 0.0829936\tvalid_1's rmse: 0.0871929\n",
      "[1450]\ttraining's rmse: 0.0829807\tvalid_1's rmse: 0.0871921\n",
      "[1475]\ttraining's rmse: 0.0829712\tvalid_1's rmse: 0.0871906\n",
      "[1500]\ttraining's rmse: 0.0829631\tvalid_1's rmse: 0.0871897\n",
      "[1525]\ttraining's rmse: 0.0829542\tvalid_1's rmse: 0.0871877\n",
      "[1550]\ttraining's rmse: 0.082946\tvalid_1's rmse: 0.0871864\n",
      "[1575]\ttraining's rmse: 0.0829362\tvalid_1's rmse: 0.087185\n",
      "[1600]\ttraining's rmse: 0.0829278\tvalid_1's rmse: 0.0871846\n",
      "[1625]\ttraining's rmse: 0.0829209\tvalid_1's rmse: 0.0871831\n",
      "[1650]\ttraining's rmse: 0.082913\tvalid_1's rmse: 0.0871821\n",
      "[1675]\ttraining's rmse: 0.0829065\tvalid_1's rmse: 0.0871807\n",
      "[1700]\ttraining's rmse: 0.0829008\tvalid_1's rmse: 0.0871797\n",
      "[1725]\ttraining's rmse: 0.082894\tvalid_1's rmse: 0.0871786\n",
      "[1750]\ttraining's rmse: 0.082886\tvalid_1's rmse: 0.0871781\n",
      "[1775]\ttraining's rmse: 0.08288\tvalid_1's rmse: 0.0871779\n",
      "[1800]\ttraining's rmse: 0.0828735\tvalid_1's rmse: 0.087177\n",
      "[1825]\ttraining's rmse: 0.0828692\tvalid_1's rmse: 0.0871766\n",
      "[1850]\ttraining's rmse: 0.082863\tvalid_1's rmse: 0.0871751\n",
      "[1875]\ttraining's rmse: 0.0828586\tvalid_1's rmse: 0.0871747\n",
      "[1900]\ttraining's rmse: 0.0828532\tvalid_1's rmse: 0.0871744\n",
      "[1925]\ttraining's rmse: 0.082848\tvalid_1's rmse: 0.0871742\n",
      "[1950]\ttraining's rmse: 0.0828445\tvalid_1's rmse: 0.0871735\n",
      "[1975]\ttraining's rmse: 0.0828412\tvalid_1's rmse: 0.0871729\n",
      "[2000]\ttraining's rmse: 0.0828358\tvalid_1's rmse: 0.0871721\n",
      "[2025]\ttraining's rmse: 0.0828315\tvalid_1's rmse: 0.0871714\n",
      "[2050]\ttraining's rmse: 0.0828287\tvalid_1's rmse: 0.0871716\n",
      "[2075]\ttraining's rmse: 0.0828257\tvalid_1's rmse: 0.0871709\n",
      "[2100]\ttraining's rmse: 0.0828221\tvalid_1's rmse: 0.0871705\n",
      "[2125]\ttraining's rmse: 0.0828179\tvalid_1's rmse: 0.0871701\n",
      "[2150]\ttraining's rmse: 0.0828147\tvalid_1's rmse: 0.0871703\n",
      "Early stopping, best iteration is:\n",
      "[2124]\ttraining's rmse: 0.082818\tvalid_1's rmse: 0.08717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0879233\tvalid_1's rmse: 0.0830919\n",
      "[50]\ttraining's rmse: 0.0878108\tvalid_1's rmse: 0.0830413\n",
      "[75]\ttraining's rmse: 0.0876931\tvalid_1's rmse: 0.0829932\n",
      "[100]\ttraining's rmse: 0.0875893\tvalid_1's rmse: 0.0829524\n",
      "[125]\ttraining's rmse: 0.0874837\tvalid_1's rmse: 0.0829126\n",
      "[150]\ttraining's rmse: 0.0873838\tvalid_1's rmse: 0.0828768\n",
      "[175]\ttraining's rmse: 0.0873017\tvalid_1's rmse: 0.0828467\n",
      "[200]\ttraining's rmse: 0.0872107\tvalid_1's rmse: 0.0828149\n",
      "[225]\ttraining's rmse: 0.0871265\tvalid_1's rmse: 0.0827843\n",
      "[250]\ttraining's rmse: 0.0870543\tvalid_1's rmse: 0.0827607\n",
      "[275]\ttraining's rmse: 0.0869886\tvalid_1's rmse: 0.0827372\n",
      "[300]\ttraining's rmse: 0.0869215\tvalid_1's rmse: 0.0827143\n",
      "[325]\ttraining's rmse: 0.0868535\tvalid_1's rmse: 0.0826931\n",
      "[350]\ttraining's rmse: 0.0867866\tvalid_1's rmse: 0.0826706\n",
      "[375]\ttraining's rmse: 0.0867313\tvalid_1's rmse: 0.0826559\n",
      "[400]\ttraining's rmse: 0.0866708\tvalid_1's rmse: 0.0826474\n",
      "[425]\ttraining's rmse: 0.0866155\tvalid_1's rmse: 0.082637\n",
      "[450]\ttraining's rmse: 0.0865652\tvalid_1's rmse: 0.0826213\n",
      "[475]\ttraining's rmse: 0.0865179\tvalid_1's rmse: 0.0826082\n",
      "[500]\ttraining's rmse: 0.0864783\tvalid_1's rmse: 0.0825957\n",
      "[525]\ttraining's rmse: 0.0864227\tvalid_1's rmse: 0.0825809\n",
      "[550]\ttraining's rmse: 0.086373\tvalid_1's rmse: 0.0825719\n",
      "[575]\ttraining's rmse: 0.086327\tvalid_1's rmse: 0.0825658\n",
      "[600]\ttraining's rmse: 0.0862828\tvalid_1's rmse: 0.0825659\n",
      "[625]\ttraining's rmse: 0.0862504\tvalid_1's rmse: 0.0825579\n",
      "[650]\ttraining's rmse: 0.0862063\tvalid_1's rmse: 0.0825543\n",
      "[675]\ttraining's rmse: 0.0861643\tvalid_1's rmse: 0.0825501\n",
      "[700]\ttraining's rmse: 0.0861255\tvalid_1's rmse: 0.0825411\n",
      "[725]\ttraining's rmse: 0.086089\tvalid_1's rmse: 0.0825401\n",
      "[750]\ttraining's rmse: 0.0860562\tvalid_1's rmse: 0.082542\n",
      "[775]\ttraining's rmse: 0.0860273\tvalid_1's rmse: 0.0825425\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0860743\tvalid_1's rmse: 0.0825366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0867912\tvalid_1's rmse: 0.0893411\n",
      "[50]\ttraining's rmse: 0.0866496\tvalid_1's rmse: 0.0892862\n",
      "[75]\ttraining's rmse: 0.0865098\tvalid_1's rmse: 0.0892336\n",
      "[100]\ttraining's rmse: 0.0863816\tvalid_1's rmse: 0.0891875\n",
      "[125]\ttraining's rmse: 0.0862519\tvalid_1's rmse: 0.0891401\n",
      "[150]\ttraining's rmse: 0.0861335\tvalid_1's rmse: 0.0890961\n",
      "[175]\ttraining's rmse: 0.0860367\tvalid_1's rmse: 0.0890605\n",
      "[200]\ttraining's rmse: 0.0859258\tvalid_1's rmse: 0.0890224\n",
      "[225]\ttraining's rmse: 0.0858187\tvalid_1's rmse: 0.088987\n",
      "[250]\ttraining's rmse: 0.085731\tvalid_1's rmse: 0.0889568\n",
      "[275]\ttraining's rmse: 0.0856495\tvalid_1's rmse: 0.0889266\n",
      "[300]\ttraining's rmse: 0.0855717\tvalid_1's rmse: 0.088899\n",
      "[325]\ttraining's rmse: 0.0854923\tvalid_1's rmse: 0.0888716\n",
      "[350]\ttraining's rmse: 0.0854176\tvalid_1's rmse: 0.088847\n",
      "[375]\ttraining's rmse: 0.0853538\tvalid_1's rmse: 0.0888252\n",
      "[400]\ttraining's rmse: 0.0852855\tvalid_1's rmse: 0.0888031\n",
      "[425]\ttraining's rmse: 0.0852243\tvalid_1's rmse: 0.0887805\n",
      "[450]\ttraining's rmse: 0.0851673\tvalid_1's rmse: 0.0887599\n",
      "[475]\ttraining's rmse: 0.0851136\tvalid_1's rmse: 0.0887412\n",
      "[500]\ttraining's rmse: 0.0850671\tvalid_1's rmse: 0.0887244\n",
      "[525]\ttraining's rmse: 0.0850061\tvalid_1's rmse: 0.0887069\n",
      "[550]\ttraining's rmse: 0.0849572\tvalid_1's rmse: 0.0886913\n",
      "[575]\ttraining's rmse: 0.0849083\tvalid_1's rmse: 0.0886775\n",
      "[600]\ttraining's rmse: 0.0848618\tvalid_1's rmse: 0.0886632\n",
      "[625]\ttraining's rmse: 0.0848246\tvalid_1's rmse: 0.0886519\n",
      "[650]\ttraining's rmse: 0.0847795\tvalid_1's rmse: 0.0886389\n",
      "[675]\ttraining's rmse: 0.0847311\tvalid_1's rmse: 0.088628\n",
      "[700]\ttraining's rmse: 0.0846917\tvalid_1's rmse: 0.0886161\n",
      "[725]\ttraining's rmse: 0.0846545\tvalid_1's rmse: 0.0886051\n",
      "[750]\ttraining's rmse: 0.0846195\tvalid_1's rmse: 0.0885945\n",
      "[775]\ttraining's rmse: 0.0845908\tvalid_1's rmse: 0.0885831\n",
      "[800]\ttraining's rmse: 0.0845542\tvalid_1's rmse: 0.0885742\n",
      "[825]\ttraining's rmse: 0.0845227\tvalid_1's rmse: 0.0885647\n",
      "[850]\ttraining's rmse: 0.0844889\tvalid_1's rmse: 0.0885567\n",
      "[875]\ttraining's rmse: 0.0844631\tvalid_1's rmse: 0.0885492\n",
      "[900]\ttraining's rmse: 0.0844336\tvalid_1's rmse: 0.0885418\n",
      "[925]\ttraining's rmse: 0.0844066\tvalid_1's rmse: 0.0885338\n",
      "[950]\ttraining's rmse: 0.0843799\tvalid_1's rmse: 0.0885267\n",
      "[975]\ttraining's rmse: 0.0843573\tvalid_1's rmse: 0.0885203\n",
      "[1000]\ttraining's rmse: 0.0843328\tvalid_1's rmse: 0.0885138\n",
      "[1025]\ttraining's rmse: 0.0843064\tvalid_1's rmse: 0.0885071\n",
      "[1050]\ttraining's rmse: 0.0842844\tvalid_1's rmse: 0.0884995\n",
      "[1075]\ttraining's rmse: 0.0842624\tvalid_1's rmse: 0.0884951\n",
      "[1100]\ttraining's rmse: 0.0842451\tvalid_1's rmse: 0.0884887\n",
      "[1125]\ttraining's rmse: 0.084225\tvalid_1's rmse: 0.088484\n",
      "[1150]\ttraining's rmse: 0.0842049\tvalid_1's rmse: 0.0884799\n",
      "[1175]\ttraining's rmse: 0.0841869\tvalid_1's rmse: 0.0884756\n",
      "[1200]\ttraining's rmse: 0.0841684\tvalid_1's rmse: 0.0884705\n",
      "[1225]\ttraining's rmse: 0.0841482\tvalid_1's rmse: 0.0884652\n",
      "[1250]\ttraining's rmse: 0.0841331\tvalid_1's rmse: 0.0884617\n",
      "[1275]\ttraining's rmse: 0.0841151\tvalid_1's rmse: 0.0884579\n",
      "[1300]\ttraining's rmse: 0.0841008\tvalid_1's rmse: 0.0884527\n",
      "[1325]\ttraining's rmse: 0.0840857\tvalid_1's rmse: 0.0884491\n",
      "[1350]\ttraining's rmse: 0.0840708\tvalid_1's rmse: 0.0884445\n",
      "[1375]\ttraining's rmse: 0.084055\tvalid_1's rmse: 0.088441\n",
      "[1400]\ttraining's rmse: 0.0840442\tvalid_1's rmse: 0.0884363\n",
      "[1425]\ttraining's rmse: 0.0840299\tvalid_1's rmse: 0.088434\n",
      "[1450]\ttraining's rmse: 0.0840188\tvalid_1's rmse: 0.0884312\n",
      "[1475]\ttraining's rmse: 0.0840078\tvalid_1's rmse: 0.0884276\n",
      "[1500]\ttraining's rmse: 0.0839996\tvalid_1's rmse: 0.0884246\n",
      "[1525]\ttraining's rmse: 0.0839922\tvalid_1's rmse: 0.0884219\n",
      "[1550]\ttraining's rmse: 0.0839824\tvalid_1's rmse: 0.08842\n",
      "[1575]\ttraining's rmse: 0.0839741\tvalid_1's rmse: 0.0884173\n",
      "[1600]\ttraining's rmse: 0.0839664\tvalid_1's rmse: 0.0884144\n",
      "[1625]\ttraining's rmse: 0.0839582\tvalid_1's rmse: 0.0884116\n",
      "[1650]\ttraining's rmse: 0.0839492\tvalid_1's rmse: 0.088409\n",
      "[1675]\ttraining's rmse: 0.083943\tvalid_1's rmse: 0.0884064\n",
      "[1700]\ttraining's rmse: 0.0839333\tvalid_1's rmse: 0.088403\n",
      "[1725]\ttraining's rmse: 0.0839258\tvalid_1's rmse: 0.0884016\n",
      "[1750]\ttraining's rmse: 0.0839176\tvalid_1's rmse: 0.0883999\n",
      "[1775]\ttraining's rmse: 0.0839088\tvalid_1's rmse: 0.0883966\n",
      "[1800]\ttraining's rmse: 0.0839005\tvalid_1's rmse: 0.088394\n",
      "[1825]\ttraining's rmse: 0.0838949\tvalid_1's rmse: 0.0883918\n",
      "[1850]\ttraining's rmse: 0.0838884\tvalid_1's rmse: 0.0883895\n",
      "[1875]\ttraining's rmse: 0.0838827\tvalid_1's rmse: 0.0883877\n",
      "[1900]\ttraining's rmse: 0.0838779\tvalid_1's rmse: 0.0883853\n",
      "[1925]\ttraining's rmse: 0.0838728\tvalid_1's rmse: 0.0883843\n",
      "[1950]\ttraining's rmse: 0.0838678\tvalid_1's rmse: 0.0883827\n",
      "[1975]\ttraining's rmse: 0.0838622\tvalid_1's rmse: 0.0883811\n",
      "[2000]\ttraining's rmse: 0.0838571\tvalid_1's rmse: 0.0883793\n",
      "[2025]\ttraining's rmse: 0.0838539\tvalid_1's rmse: 0.0883787\n",
      "[2050]\ttraining's rmse: 0.0838487\tvalid_1's rmse: 0.0883759\n",
      "[2075]\ttraining's rmse: 0.0838453\tvalid_1's rmse: 0.0883746\n",
      "[2100]\ttraining's rmse: 0.083842\tvalid_1's rmse: 0.0883735\n",
      "[2125]\ttraining's rmse: 0.0838391\tvalid_1's rmse: 0.0883726\n",
      "[2150]\ttraining's rmse: 0.0838359\tvalid_1's rmse: 0.0883718\n",
      "[2175]\ttraining's rmse: 0.0838328\tvalid_1's rmse: 0.0883714\n",
      "[2200]\ttraining's rmse: 0.08383\tvalid_1's rmse: 0.088371\n",
      "[2225]\ttraining's rmse: 0.0838263\tvalid_1's rmse: 0.0883698\n",
      "[2250]\ttraining's rmse: 0.0838219\tvalid_1's rmse: 0.0883694\n",
      "[2275]\ttraining's rmse: 0.0838193\tvalid_1's rmse: 0.0883681\n",
      "[2300]\ttraining's rmse: 0.0838158\tvalid_1's rmse: 0.0883673\n",
      "[2325]\ttraining's rmse: 0.0838134\tvalid_1's rmse: 0.0883668\n",
      "[2350]\ttraining's rmse: 0.08381\tvalid_1's rmse: 0.0883654\n",
      "[2375]\ttraining's rmse: 0.0838064\tvalid_1's rmse: 0.0883649\n",
      "[2400]\ttraining's rmse: 0.0838032\tvalid_1's rmse: 0.0883644\n",
      "[2425]\ttraining's rmse: 0.0838014\tvalid_1's rmse: 0.0883633\n",
      "[2450]\ttraining's rmse: 0.0837995\tvalid_1's rmse: 0.0883628\n",
      "[2475]\ttraining's rmse: 0.083796\tvalid_1's rmse: 0.0883624\n",
      "[2500]\ttraining's rmse: 0.0837941\tvalid_1's rmse: 0.0883621\n",
      "[2525]\ttraining's rmse: 0.0837917\tvalid_1's rmse: 0.0883616\n",
      "[2550]\ttraining's rmse: 0.083789\tvalid_1's rmse: 0.0883607\n",
      "[2575]\ttraining's rmse: 0.0837865\tvalid_1's rmse: 0.0883602\n",
      "[2600]\ttraining's rmse: 0.083784\tvalid_1's rmse: 0.0883588\n",
      "[2625]\ttraining's rmse: 0.0837817\tvalid_1's rmse: 0.088358\n",
      "[2650]\ttraining's rmse: 0.0837804\tvalid_1's rmse: 0.0883573\n",
      "[2675]\ttraining's rmse: 0.0837779\tvalid_1's rmse: 0.0883567\n",
      "[2700]\ttraining's rmse: 0.0837762\tvalid_1's rmse: 0.0883564\n",
      "[2725]\ttraining's rmse: 0.083774\tvalid_1's rmse: 0.0883564\n",
      "[2750]\ttraining's rmse: 0.0837719\tvalid_1's rmse: 0.0883553\n",
      "[2775]\ttraining's rmse: 0.0837693\tvalid_1's rmse: 0.0883557\n",
      "[2800]\ttraining's rmse: 0.0837676\tvalid_1's rmse: 0.0883551\n",
      "[2825]\ttraining's rmse: 0.0837657\tvalid_1's rmse: 0.088355\n",
      "[2850]\ttraining's rmse: 0.0837636\tvalid_1's rmse: 0.088355\n",
      "[2875]\ttraining's rmse: 0.0837622\tvalid_1's rmse: 0.0883547\n",
      "[2900]\ttraining's rmse: 0.0837603\tvalid_1's rmse: 0.0883539\n",
      "[2925]\ttraining's rmse: 0.0837582\tvalid_1's rmse: 0.0883535\n",
      "[2950]\ttraining's rmse: 0.0837567\tvalid_1's rmse: 0.0883534\n",
      "[2975]\ttraining's rmse: 0.0837553\tvalid_1's rmse: 0.0883531\n",
      "[3000]\ttraining's rmse: 0.0837537\tvalid_1's rmse: 0.0883517\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0837537\tvalid_1's rmse: 0.0883517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0867812\tvalid_1's rmse: 0.0893879\n",
      "[50]\ttraining's rmse: 0.0866537\tvalid_1's rmse: 0.0893342\n",
      "[75]\ttraining's rmse: 0.0865246\tvalid_1's rmse: 0.0892828\n",
      "[100]\ttraining's rmse: 0.08641\tvalid_1's rmse: 0.0892364\n",
      "[125]\ttraining's rmse: 0.0862907\tvalid_1's rmse: 0.0891887\n",
      "[150]\ttraining's rmse: 0.0861783\tvalid_1's rmse: 0.0891447\n",
      "[175]\ttraining's rmse: 0.0860858\tvalid_1's rmse: 0.0891081\n",
      "[200]\ttraining's rmse: 0.085985\tvalid_1's rmse: 0.0890716\n",
      "[225]\ttraining's rmse: 0.0858892\tvalid_1's rmse: 0.0890366\n",
      "[250]\ttraining's rmse: 0.0858061\tvalid_1's rmse: 0.0890057\n",
      "[275]\ttraining's rmse: 0.0857311\tvalid_1's rmse: 0.0889764\n",
      "[300]\ttraining's rmse: 0.085655\tvalid_1's rmse: 0.0889489\n",
      "[325]\ttraining's rmse: 0.0855797\tvalid_1's rmse: 0.0889236\n",
      "[350]\ttraining's rmse: 0.0855047\tvalid_1's rmse: 0.0888993\n",
      "[375]\ttraining's rmse: 0.0854453\tvalid_1's rmse: 0.0888793\n",
      "[400]\ttraining's rmse: 0.0853779\tvalid_1's rmse: 0.0888585\n",
      "[425]\ttraining's rmse: 0.0853183\tvalid_1's rmse: 0.0888389\n",
      "[450]\ttraining's rmse: 0.085262\tvalid_1's rmse: 0.0888204\n",
      "[475]\ttraining's rmse: 0.0852099\tvalid_1's rmse: 0.088803\n",
      "[500]\ttraining's rmse: 0.0851647\tvalid_1's rmse: 0.0887865\n",
      "[525]\ttraining's rmse: 0.0851069\tvalid_1's rmse: 0.0887708\n",
      "[550]\ttraining's rmse: 0.0850521\tvalid_1's rmse: 0.0887565\n",
      "[575]\ttraining's rmse: 0.0850036\tvalid_1's rmse: 0.0887429\n",
      "[600]\ttraining's rmse: 0.0849559\tvalid_1's rmse: 0.0887291\n",
      "[625]\ttraining's rmse: 0.0849183\tvalid_1's rmse: 0.0887174\n",
      "[650]\ttraining's rmse: 0.0848721\tvalid_1's rmse: 0.0887057\n",
      "[675]\ttraining's rmse: 0.0848267\tvalid_1's rmse: 0.0886941\n",
      "[700]\ttraining's rmse: 0.0847863\tvalid_1's rmse: 0.0886834\n",
      "[725]\ttraining's rmse: 0.0847494\tvalid_1's rmse: 0.0886743\n",
      "[750]\ttraining's rmse: 0.0847154\tvalid_1's rmse: 0.0886653\n",
      "[775]\ttraining's rmse: 0.0846844\tvalid_1's rmse: 0.088657\n",
      "[800]\ttraining's rmse: 0.0846467\tvalid_1's rmse: 0.0886488\n",
      "[825]\ttraining's rmse: 0.084616\tvalid_1's rmse: 0.0886405\n",
      "[850]\ttraining's rmse: 0.0845855\tvalid_1's rmse: 0.088634\n",
      "[875]\ttraining's rmse: 0.0845584\tvalid_1's rmse: 0.0886273\n",
      "[900]\ttraining's rmse: 0.0845285\tvalid_1's rmse: 0.0886206\n",
      "[925]\ttraining's rmse: 0.0845003\tvalid_1's rmse: 0.0886146\n",
      "[950]\ttraining's rmse: 0.0844742\tvalid_1's rmse: 0.08861\n",
      "[975]\ttraining's rmse: 0.0844486\tvalid_1's rmse: 0.0886047\n",
      "[1000]\ttraining's rmse: 0.0844262\tvalid_1's rmse: 0.0885996\n",
      "[1025]\ttraining's rmse: 0.0844009\tvalid_1's rmse: 0.0885956\n",
      "[1050]\ttraining's rmse: 0.0843765\tvalid_1's rmse: 0.0885902\n",
      "[1075]\ttraining's rmse: 0.0843546\tvalid_1's rmse: 0.0885875\n",
      "[1100]\ttraining's rmse: 0.0843369\tvalid_1's rmse: 0.0885843\n",
      "[1125]\ttraining's rmse: 0.0843152\tvalid_1's rmse: 0.0885807\n",
      "[1150]\ttraining's rmse: 0.0842959\tvalid_1's rmse: 0.0885776\n",
      "[1175]\ttraining's rmse: 0.0842793\tvalid_1's rmse: 0.0885751\n",
      "[1200]\ttraining's rmse: 0.0842595\tvalid_1's rmse: 0.0885719\n",
      "[1225]\ttraining's rmse: 0.0842414\tvalid_1's rmse: 0.0885695\n",
      "[1250]\ttraining's rmse: 0.0842277\tvalid_1's rmse: 0.0885672\n",
      "[1275]\ttraining's rmse: 0.0842102\tvalid_1's rmse: 0.0885654\n",
      "[1300]\ttraining's rmse: 0.084199\tvalid_1's rmse: 0.0885633\n",
      "[1325]\ttraining's rmse: 0.0841852\tvalid_1's rmse: 0.0885614\n",
      "[1350]\ttraining's rmse: 0.0841695\tvalid_1's rmse: 0.0885592\n",
      "[1375]\ttraining's rmse: 0.0841556\tvalid_1's rmse: 0.088558\n",
      "[1400]\ttraining's rmse: 0.0841435\tvalid_1's rmse: 0.0885556\n",
      "[1425]\ttraining's rmse: 0.0841299\tvalid_1's rmse: 0.0885543\n",
      "[1450]\ttraining's rmse: 0.0841152\tvalid_1's rmse: 0.0885525\n",
      "[1475]\ttraining's rmse: 0.0841053\tvalid_1's rmse: 0.0885508\n",
      "[1500]\ttraining's rmse: 0.0840963\tvalid_1's rmse: 0.0885497\n",
      "[1525]\ttraining's rmse: 0.084085\tvalid_1's rmse: 0.0885482\n",
      "[1550]\ttraining's rmse: 0.0840742\tvalid_1's rmse: 0.0885474\n",
      "[1575]\ttraining's rmse: 0.0840626\tvalid_1's rmse: 0.0885463\n",
      "[1600]\ttraining's rmse: 0.0840541\tvalid_1's rmse: 0.0885457\n",
      "[1625]\ttraining's rmse: 0.0840446\tvalid_1's rmse: 0.088544\n",
      "[1650]\ttraining's rmse: 0.0840359\tvalid_1's rmse: 0.0885433\n",
      "[1675]\ttraining's rmse: 0.0840287\tvalid_1's rmse: 0.0885424\n",
      "[1700]\ttraining's rmse: 0.0840219\tvalid_1's rmse: 0.0885413\n",
      "[1725]\ttraining's rmse: 0.0840146\tvalid_1's rmse: 0.0885411\n",
      "[1750]\ttraining's rmse: 0.0840087\tvalid_1's rmse: 0.0885402\n",
      "[1775]\ttraining's rmse: 0.0840023\tvalid_1's rmse: 0.0885395\n",
      "[1800]\ttraining's rmse: 0.0839945\tvalid_1's rmse: 0.0885392\n",
      "[1825]\ttraining's rmse: 0.083988\tvalid_1's rmse: 0.0885381\n",
      "[1850]\ttraining's rmse: 0.0839821\tvalid_1's rmse: 0.0885376\n",
      "[1875]\ttraining's rmse: 0.0839771\tvalid_1's rmse: 0.0885376\n",
      "[1900]\ttraining's rmse: 0.0839722\tvalid_1's rmse: 0.0885378\n",
      "Early stopping, best iteration is:\n",
      "[1860]\ttraining's rmse: 0.08398\tvalid_1's rmse: 0.0885372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0892339\tvalid_1's rmse: 0.0843989\n",
      "[50]\ttraining's rmse: 0.0891189\tvalid_1's rmse: 0.0843514\n",
      "[75]\ttraining's rmse: 0.0889936\tvalid_1's rmse: 0.0843029\n",
      "[100]\ttraining's rmse: 0.088884\tvalid_1's rmse: 0.0842605\n",
      "[125]\ttraining's rmse: 0.0887667\tvalid_1's rmse: 0.0842177\n",
      "[150]\ttraining's rmse: 0.0886615\tvalid_1's rmse: 0.0841805\n",
      "[175]\ttraining's rmse: 0.088576\tvalid_1's rmse: 0.0841478\n",
      "[200]\ttraining's rmse: 0.0884787\tvalid_1's rmse: 0.0841161\n",
      "[225]\ttraining's rmse: 0.0883854\tvalid_1's rmse: 0.0840844\n",
      "[250]\ttraining's rmse: 0.0883078\tvalid_1's rmse: 0.0840575\n",
      "[275]\ttraining's rmse: 0.0882366\tvalid_1's rmse: 0.0840323\n",
      "[300]\ttraining's rmse: 0.0881645\tvalid_1's rmse: 0.0840083\n",
      "[325]\ttraining's rmse: 0.088094\tvalid_1's rmse: 0.0839864\n",
      "[350]\ttraining's rmse: 0.0880226\tvalid_1's rmse: 0.0839647\n",
      "[375]\ttraining's rmse: 0.0879661\tvalid_1's rmse: 0.0839535\n",
      "[400]\ttraining's rmse: 0.0879006\tvalid_1's rmse: 0.0839401\n",
      "[425]\ttraining's rmse: 0.087843\tvalid_1's rmse: 0.0839291\n",
      "[450]\ttraining's rmse: 0.0877907\tvalid_1's rmse: 0.0839164\n",
      "[475]\ttraining's rmse: 0.0877382\tvalid_1's rmse: 0.083908\n",
      "[500]\ttraining's rmse: 0.0876964\tvalid_1's rmse: 0.0838985\n",
      "[525]\ttraining's rmse: 0.0876389\tvalid_1's rmse: 0.0838943\n",
      "[550]\ttraining's rmse: 0.087589\tvalid_1's rmse: 0.0838802\n",
      "[575]\ttraining's rmse: 0.0875424\tvalid_1's rmse: 0.0838744\n",
      "[600]\ttraining's rmse: 0.0874955\tvalid_1's rmse: 0.0838778\n",
      "[625]\ttraining's rmse: 0.0874597\tvalid_1's rmse: 0.0838744\n",
      "Early stopping, best iteration is:\n",
      "[578]\ttraining's rmse: 0.0875376\tvalid_1's rmse: 0.0838734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0859312\tvalid_1's rmse: 0.0885338\n",
      "[50]\ttraining's rmse: 0.0858006\tvalid_1's rmse: 0.0884801\n",
      "[75]\ttraining's rmse: 0.085669\tvalid_1's rmse: 0.088425\n",
      "[100]\ttraining's rmse: 0.0855479\tvalid_1's rmse: 0.0883788\n",
      "[125]\ttraining's rmse: 0.0854273\tvalid_1's rmse: 0.0883307\n",
      "[150]\ttraining's rmse: 0.0853166\tvalid_1's rmse: 0.0882866\n",
      "[175]\ttraining's rmse: 0.0852223\tvalid_1's rmse: 0.0882482\n",
      "[200]\ttraining's rmse: 0.0851244\tvalid_1's rmse: 0.0882104\n",
      "[225]\ttraining's rmse: 0.0850283\tvalid_1's rmse: 0.0881743\n",
      "[250]\ttraining's rmse: 0.0849461\tvalid_1's rmse: 0.0881417\n",
      "[275]\ttraining's rmse: 0.0848685\tvalid_1's rmse: 0.0881118\n",
      "[300]\ttraining's rmse: 0.0847942\tvalid_1's rmse: 0.088083\n",
      "[325]\ttraining's rmse: 0.0847209\tvalid_1's rmse: 0.0880572\n",
      "[350]\ttraining's rmse: 0.0846501\tvalid_1's rmse: 0.0880297\n",
      "[375]\ttraining's rmse: 0.0845904\tvalid_1's rmse: 0.0880076\n",
      "[400]\ttraining's rmse: 0.0845248\tvalid_1's rmse: 0.087985\n",
      "[425]\ttraining's rmse: 0.0844654\tvalid_1's rmse: 0.0879655\n",
      "[450]\ttraining's rmse: 0.0844115\tvalid_1's rmse: 0.0879451\n",
      "[475]\ttraining's rmse: 0.0843605\tvalid_1's rmse: 0.0879272\n",
      "[500]\ttraining's rmse: 0.0843169\tvalid_1's rmse: 0.0879104\n",
      "[525]\ttraining's rmse: 0.0842628\tvalid_1's rmse: 0.0878925\n",
      "[550]\ttraining's rmse: 0.0842138\tvalid_1's rmse: 0.0878765\n",
      "[575]\ttraining's rmse: 0.0841665\tvalid_1's rmse: 0.0878619\n",
      "[600]\ttraining's rmse: 0.0841232\tvalid_1's rmse: 0.0878486\n",
      "[625]\ttraining's rmse: 0.0840871\tvalid_1's rmse: 0.0878355\n",
      "[650]\ttraining's rmse: 0.0840436\tvalid_1's rmse: 0.0878227\n",
      "[675]\ttraining's rmse: 0.084002\tvalid_1's rmse: 0.0878101\n",
      "[700]\ttraining's rmse: 0.0839653\tvalid_1's rmse: 0.0877984\n",
      "[725]\ttraining's rmse: 0.0839298\tvalid_1's rmse: 0.0877891\n",
      "[750]\ttraining's rmse: 0.0838951\tvalid_1's rmse: 0.0877793\n",
      "[775]\ttraining's rmse: 0.0838672\tvalid_1's rmse: 0.0877696\n",
      "[800]\ttraining's rmse: 0.0838308\tvalid_1's rmse: 0.0877602\n",
      "[825]\ttraining's rmse: 0.0838015\tvalid_1's rmse: 0.0877495\n",
      "[850]\ttraining's rmse: 0.0837701\tvalid_1's rmse: 0.0877415\n",
      "[875]\ttraining's rmse: 0.0837445\tvalid_1's rmse: 0.087735\n",
      "[900]\ttraining's rmse: 0.0837178\tvalid_1's rmse: 0.0877276\n",
      "[925]\ttraining's rmse: 0.0836909\tvalid_1's rmse: 0.0877188\n",
      "[950]\ttraining's rmse: 0.0836681\tvalid_1's rmse: 0.0877113\n",
      "[975]\ttraining's rmse: 0.0836464\tvalid_1's rmse: 0.0877054\n",
      "[1000]\ttraining's rmse: 0.083626\tvalid_1's rmse: 0.0877003\n",
      "[1025]\ttraining's rmse: 0.0836025\tvalid_1's rmse: 0.0876925\n",
      "[1050]\ttraining's rmse: 0.0835814\tvalid_1's rmse: 0.0876833\n",
      "[1075]\ttraining's rmse: 0.0835606\tvalid_1's rmse: 0.0876779\n",
      "[1100]\ttraining's rmse: 0.0835419\tvalid_1's rmse: 0.0876728\n",
      "[1125]\ttraining's rmse: 0.0835225\tvalid_1's rmse: 0.0876671\n",
      "[1150]\ttraining's rmse: 0.0835041\tvalid_1's rmse: 0.0876632\n",
      "[1175]\ttraining's rmse: 0.0834884\tvalid_1's rmse: 0.0876606\n",
      "[1200]\ttraining's rmse: 0.0834723\tvalid_1's rmse: 0.0876542\n",
      "[1225]\ttraining's rmse: 0.0834574\tvalid_1's rmse: 0.0876497\n",
      "[1250]\ttraining's rmse: 0.0834456\tvalid_1's rmse: 0.0876447\n",
      "[1275]\ttraining's rmse: 0.0834284\tvalid_1's rmse: 0.0876419\n",
      "[1300]\ttraining's rmse: 0.0834163\tvalid_1's rmse: 0.0876375\n",
      "[1325]\ttraining's rmse: 0.0834035\tvalid_1's rmse: 0.0876346\n",
      "[1350]\ttraining's rmse: 0.0833898\tvalid_1's rmse: 0.0876308\n",
      "[1375]\ttraining's rmse: 0.0833774\tvalid_1's rmse: 0.0876272\n",
      "[1400]\ttraining's rmse: 0.0833668\tvalid_1's rmse: 0.0876222\n",
      "[1425]\ttraining's rmse: 0.0833551\tvalid_1's rmse: 0.0876197\n",
      "[1450]\ttraining's rmse: 0.0833414\tvalid_1's rmse: 0.0876171\n",
      "[1475]\ttraining's rmse: 0.0833299\tvalid_1's rmse: 0.0876142\n",
      "[1500]\ttraining's rmse: 0.0833213\tvalid_1's rmse: 0.0876122\n",
      "[1525]\ttraining's rmse: 0.0833095\tvalid_1's rmse: 0.0876091\n",
      "[1550]\ttraining's rmse: 0.0832984\tvalid_1's rmse: 0.0876065\n",
      "[1575]\ttraining's rmse: 0.0832888\tvalid_1's rmse: 0.0876039\n",
      "[1600]\ttraining's rmse: 0.0832809\tvalid_1's rmse: 0.0876023\n",
      "[1625]\ttraining's rmse: 0.0832719\tvalid_1's rmse: 0.0875993\n",
      "[1650]\ttraining's rmse: 0.0832628\tvalid_1's rmse: 0.0875971\n",
      "[1675]\ttraining's rmse: 0.083258\tvalid_1's rmse: 0.0875938\n",
      "[1700]\ttraining's rmse: 0.0832508\tvalid_1's rmse: 0.0875915\n",
      "[1725]\ttraining's rmse: 0.083245\tvalid_1's rmse: 0.0875901\n",
      "[1750]\ttraining's rmse: 0.0832365\tvalid_1's rmse: 0.0875885\n",
      "[1775]\ttraining's rmse: 0.0832307\tvalid_1's rmse: 0.0875866\n",
      "[1800]\ttraining's rmse: 0.083225\tvalid_1's rmse: 0.0875842\n",
      "[1825]\ttraining's rmse: 0.0832199\tvalid_1's rmse: 0.0875829\n",
      "[1850]\ttraining's rmse: 0.0832155\tvalid_1's rmse: 0.0875806\n",
      "[1875]\ttraining's rmse: 0.0832099\tvalid_1's rmse: 0.0875791\n",
      "[1900]\ttraining's rmse: 0.0832051\tvalid_1's rmse: 0.0875785\n",
      "[1925]\ttraining's rmse: 0.0832005\tvalid_1's rmse: 0.0875772\n",
      "[1950]\ttraining's rmse: 0.0831976\tvalid_1's rmse: 0.0875756\n",
      "[1975]\ttraining's rmse: 0.0831947\tvalid_1's rmse: 0.0875739\n",
      "[2000]\ttraining's rmse: 0.0831912\tvalid_1's rmse: 0.0875727\n",
      "[2025]\ttraining's rmse: 0.0831875\tvalid_1's rmse: 0.0875717\n",
      "[2050]\ttraining's rmse: 0.0831823\tvalid_1's rmse: 0.0875703\n",
      "[2075]\ttraining's rmse: 0.0831787\tvalid_1's rmse: 0.0875682\n",
      "[2100]\ttraining's rmse: 0.0831762\tvalid_1's rmse: 0.0875672\n",
      "[2125]\ttraining's rmse: 0.0831728\tvalid_1's rmse: 0.0875665\n",
      "[2150]\ttraining's rmse: 0.0831703\tvalid_1's rmse: 0.0875651\n",
      "[2175]\ttraining's rmse: 0.0831658\tvalid_1's rmse: 0.0875645\n",
      "[2200]\ttraining's rmse: 0.0831619\tvalid_1's rmse: 0.0875639\n",
      "[2225]\ttraining's rmse: 0.0831583\tvalid_1's rmse: 0.0875631\n",
      "[2250]\ttraining's rmse: 0.0831558\tvalid_1's rmse: 0.0875621\n",
      "[2275]\ttraining's rmse: 0.083153\tvalid_1's rmse: 0.0875613\n",
      "[2300]\ttraining's rmse: 0.0831502\tvalid_1's rmse: 0.0875601\n",
      "[2325]\ttraining's rmse: 0.0831471\tvalid_1's rmse: 0.0875591\n",
      "[2350]\ttraining's rmse: 0.0831444\tvalid_1's rmse: 0.087558\n",
      "[2375]\ttraining's rmse: 0.0831418\tvalid_1's rmse: 0.0875578\n",
      "[2400]\ttraining's rmse: 0.08314\tvalid_1's rmse: 0.0875575\n",
      "[2425]\ttraining's rmse: 0.0831375\tvalid_1's rmse: 0.0875567\n",
      "[2450]\ttraining's rmse: 0.0831355\tvalid_1's rmse: 0.0875561\n",
      "[2475]\ttraining's rmse: 0.0831336\tvalid_1's rmse: 0.0875554\n",
      "[2500]\ttraining's rmse: 0.0831313\tvalid_1's rmse: 0.0875557\n",
      "[2525]\ttraining's rmse: 0.0831283\tvalid_1's rmse: 0.0875556\n",
      "Early stopping, best iteration is:\n",
      "[2485]\ttraining's rmse: 0.0831328\tvalid_1's rmse: 0.0875552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0859262\tvalid_1's rmse: 0.0885618\n",
      "[50]\ttraining's rmse: 0.0858056\tvalid_1's rmse: 0.0885075\n",
      "[75]\ttraining's rmse: 0.0856815\tvalid_1's rmse: 0.0884547\n",
      "[100]\ttraining's rmse: 0.0855697\tvalid_1's rmse: 0.088408\n",
      "[125]\ttraining's rmse: 0.0854522\tvalid_1's rmse: 0.0883605\n",
      "[150]\ttraining's rmse: 0.0853432\tvalid_1's rmse: 0.0883153\n",
      "[175]\ttraining's rmse: 0.085258\tvalid_1's rmse: 0.0882803\n",
      "[200]\ttraining's rmse: 0.0851622\tvalid_1's rmse: 0.0882435\n",
      "[225]\ttraining's rmse: 0.0850704\tvalid_1's rmse: 0.0882096\n",
      "[250]\ttraining's rmse: 0.0849909\tvalid_1's rmse: 0.088179\n",
      "[275]\ttraining's rmse: 0.0849188\tvalid_1's rmse: 0.0881504\n",
      "[300]\ttraining's rmse: 0.0848474\tvalid_1's rmse: 0.0881245\n",
      "[325]\ttraining's rmse: 0.0847736\tvalid_1's rmse: 0.0880988\n",
      "[350]\ttraining's rmse: 0.0847004\tvalid_1's rmse: 0.0880735\n",
      "[375]\ttraining's rmse: 0.0846434\tvalid_1's rmse: 0.0880532\n",
      "[400]\ttraining's rmse: 0.0845796\tvalid_1's rmse: 0.0880334\n",
      "[425]\ttraining's rmse: 0.0845222\tvalid_1's rmse: 0.0880142\n",
      "[450]\ttraining's rmse: 0.0844689\tvalid_1's rmse: 0.0879964\n",
      "[475]\ttraining's rmse: 0.0844162\tvalid_1's rmse: 0.0879785\n",
      "[500]\ttraining's rmse: 0.0843756\tvalid_1's rmse: 0.0879625\n",
      "[525]\ttraining's rmse: 0.0843223\tvalid_1's rmse: 0.0879461\n",
      "[550]\ttraining's rmse: 0.084273\tvalid_1's rmse: 0.0879316\n",
      "[575]\ttraining's rmse: 0.0842231\tvalid_1's rmse: 0.087917\n",
      "[600]\ttraining's rmse: 0.0841797\tvalid_1's rmse: 0.0879037\n",
      "[625]\ttraining's rmse: 0.0841445\tvalid_1's rmse: 0.0878916\n",
      "[650]\ttraining's rmse: 0.0840976\tvalid_1's rmse: 0.0878789\n",
      "[675]\ttraining's rmse: 0.0840541\tvalid_1's rmse: 0.0878667\n",
      "[700]\ttraining's rmse: 0.0840164\tvalid_1's rmse: 0.0878564\n",
      "[725]\ttraining's rmse: 0.0839805\tvalid_1's rmse: 0.0878473\n",
      "[750]\ttraining's rmse: 0.0839484\tvalid_1's rmse: 0.0878385\n",
      "[775]\ttraining's rmse: 0.0839194\tvalid_1's rmse: 0.0878303\n",
      "[800]\ttraining's rmse: 0.083881\tvalid_1's rmse: 0.0878226\n",
      "[825]\ttraining's rmse: 0.0838513\tvalid_1's rmse: 0.0878139\n",
      "[850]\ttraining's rmse: 0.0838225\tvalid_1's rmse: 0.0878069\n",
      "[875]\ttraining's rmse: 0.083795\tvalid_1's rmse: 0.0878003\n",
      "[900]\ttraining's rmse: 0.0837673\tvalid_1's rmse: 0.0877936\n",
      "[925]\ttraining's rmse: 0.0837406\tvalid_1's rmse: 0.087788\n",
      "[950]\ttraining's rmse: 0.0837143\tvalid_1's rmse: 0.0877825\n",
      "[975]\ttraining's rmse: 0.0836906\tvalid_1's rmse: 0.0877764\n",
      "[1000]\ttraining's rmse: 0.0836677\tvalid_1's rmse: 0.0877707\n",
      "[1025]\ttraining's rmse: 0.083645\tvalid_1's rmse: 0.0877662\n",
      "[1050]\ttraining's rmse: 0.0836258\tvalid_1's rmse: 0.0877617\n",
      "[1075]\ttraining's rmse: 0.0836044\tvalid_1's rmse: 0.0877587\n",
      "[1100]\ttraining's rmse: 0.083588\tvalid_1's rmse: 0.0877546\n",
      "[1125]\ttraining's rmse: 0.0835674\tvalid_1's rmse: 0.0877505\n",
      "[1150]\ttraining's rmse: 0.0835501\tvalid_1's rmse: 0.0877472\n",
      "[1175]\ttraining's rmse: 0.0835331\tvalid_1's rmse: 0.0877443\n",
      "[1200]\ttraining's rmse: 0.083515\tvalid_1's rmse: 0.0877411\n",
      "[1225]\ttraining's rmse: 0.0834986\tvalid_1's rmse: 0.0877382\n",
      "[1250]\ttraining's rmse: 0.0834851\tvalid_1's rmse: 0.0877355\n",
      "[1275]\ttraining's rmse: 0.0834698\tvalid_1's rmse: 0.0877336\n",
      "[1300]\ttraining's rmse: 0.0834563\tvalid_1's rmse: 0.0877312\n",
      "[1325]\ttraining's rmse: 0.0834421\tvalid_1's rmse: 0.0877293\n",
      "[1350]\ttraining's rmse: 0.0834277\tvalid_1's rmse: 0.0877276\n",
      "[1375]\ttraining's rmse: 0.0834147\tvalid_1's rmse: 0.0877254\n",
      "[1400]\ttraining's rmse: 0.0834029\tvalid_1's rmse: 0.087723\n",
      "[1425]\ttraining's rmse: 0.0833876\tvalid_1's rmse: 0.0877217\n",
      "[1450]\ttraining's rmse: 0.083374\tvalid_1's rmse: 0.0877194\n",
      "[1475]\ttraining's rmse: 0.083365\tvalid_1's rmse: 0.0877179\n",
      "[1500]\ttraining's rmse: 0.083355\tvalid_1's rmse: 0.0877166\n",
      "[1525]\ttraining's rmse: 0.0833466\tvalid_1's rmse: 0.0877153\n",
      "[1550]\ttraining's rmse: 0.0833362\tvalid_1's rmse: 0.087714\n",
      "[1575]\ttraining's rmse: 0.0833283\tvalid_1's rmse: 0.0877126\n",
      "[1600]\ttraining's rmse: 0.0833195\tvalid_1's rmse: 0.0877115\n",
      "[1625]\ttraining's rmse: 0.0833113\tvalid_1's rmse: 0.08771\n",
      "[1650]\ttraining's rmse: 0.0833024\tvalid_1's rmse: 0.0877096\n",
      "[1675]\ttraining's rmse: 0.0832965\tvalid_1's rmse: 0.0877088\n",
      "[1700]\ttraining's rmse: 0.0832907\tvalid_1's rmse: 0.0877077\n",
      "[1725]\ttraining's rmse: 0.0832842\tvalid_1's rmse: 0.0877069\n",
      "[1750]\ttraining's rmse: 0.0832755\tvalid_1's rmse: 0.0877058\n",
      "[1775]\ttraining's rmse: 0.0832704\tvalid_1's rmse: 0.0877048\n",
      "[1800]\ttraining's rmse: 0.0832643\tvalid_1's rmse: 0.0877042\n",
      "[1825]\ttraining's rmse: 0.0832589\tvalid_1's rmse: 0.0877031\n",
      "[1850]\ttraining's rmse: 0.0832541\tvalid_1's rmse: 0.0877023\n",
      "[1875]\ttraining's rmse: 0.0832491\tvalid_1's rmse: 0.0877023\n",
      "[1900]\ttraining's rmse: 0.0832442\tvalid_1's rmse: 0.0877017\n",
      "[1925]\ttraining's rmse: 0.0832392\tvalid_1's rmse: 0.0877017\n",
      "[1950]\ttraining's rmse: 0.0832349\tvalid_1's rmse: 0.0877009\n",
      "[1975]\ttraining's rmse: 0.083231\tvalid_1's rmse: 0.0877002\n",
      "[2000]\ttraining's rmse: 0.0832265\tvalid_1's rmse: 0.0876996\n",
      "[2025]\ttraining's rmse: 0.0832217\tvalid_1's rmse: 0.0876988\n",
      "[2050]\ttraining's rmse: 0.0832174\tvalid_1's rmse: 0.0876984\n",
      "[2075]\ttraining's rmse: 0.0832139\tvalid_1's rmse: 0.0876982\n",
      "[2100]\ttraining's rmse: 0.0832104\tvalid_1's rmse: 0.0876978\n",
      "[2125]\ttraining's rmse: 0.0832068\tvalid_1's rmse: 0.0876972\n",
      "[2150]\ttraining's rmse: 0.0832036\tvalid_1's rmse: 0.0876969\n",
      "[2175]\ttraining's rmse: 0.0832006\tvalid_1's rmse: 0.087697\n",
      "[2200]\ttraining's rmse: 0.0831983\tvalid_1's rmse: 0.0876969\n",
      "Early stopping, best iteration is:\n",
      "[2164]\ttraining's rmse: 0.0832019\tvalid_1's rmse: 0.0876967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0884252\tvalid_1's rmse: 0.0834772\n",
      "[50]\ttraining's rmse: 0.0883111\tvalid_1's rmse: 0.0834286\n",
      "[75]\ttraining's rmse: 0.0881919\tvalid_1's rmse: 0.0833815\n",
      "[100]\ttraining's rmse: 0.0880855\tvalid_1's rmse: 0.0833407\n",
      "[125]\ttraining's rmse: 0.0879745\tvalid_1's rmse: 0.0832995\n",
      "[150]\ttraining's rmse: 0.0878719\tvalid_1's rmse: 0.083263\n",
      "[175]\ttraining's rmse: 0.0877882\tvalid_1's rmse: 0.0832325\n",
      "[200]\ttraining's rmse: 0.0876976\tvalid_1's rmse: 0.0832013\n",
      "[225]\ttraining's rmse: 0.0876109\tvalid_1's rmse: 0.08317\n",
      "[250]\ttraining's rmse: 0.0875389\tvalid_1's rmse: 0.0831448\n",
      "[275]\ttraining's rmse: 0.087471\tvalid_1's rmse: 0.0831204\n",
      "[300]\ttraining's rmse: 0.087402\tvalid_1's rmse: 0.0830962\n",
      "[325]\ttraining's rmse: 0.0873343\tvalid_1's rmse: 0.0830733\n",
      "[350]\ttraining's rmse: 0.0872647\tvalid_1's rmse: 0.083052\n",
      "[375]\ttraining's rmse: 0.0872111\tvalid_1's rmse: 0.0830349\n",
      "[400]\ttraining's rmse: 0.0871513\tvalid_1's rmse: 0.0830208\n",
      "[425]\ttraining's rmse: 0.0870938\tvalid_1's rmse: 0.0830083\n",
      "[450]\ttraining's rmse: 0.0870418\tvalid_1's rmse: 0.0829942\n",
      "[475]\ttraining's rmse: 0.0869929\tvalid_1's rmse: 0.0829809\n",
      "[500]\ttraining's rmse: 0.0869522\tvalid_1's rmse: 0.0829711\n",
      "[525]\ttraining's rmse: 0.0868979\tvalid_1's rmse: 0.082957\n",
      "[550]\ttraining's rmse: 0.0868481\tvalid_1's rmse: 0.0829437\n",
      "[575]\ttraining's rmse: 0.0868014\tvalid_1's rmse: 0.082936\n",
      "[600]\ttraining's rmse: 0.0867583\tvalid_1's rmse: 0.0829272\n",
      "[625]\ttraining's rmse: 0.0867215\tvalid_1's rmse: 0.0829229\n",
      "[650]\ttraining's rmse: 0.0866767\tvalid_1's rmse: 0.0829183\n",
      "[675]\ttraining's rmse: 0.0866312\tvalid_1's rmse: 0.0829109\n",
      "[700]\ttraining's rmse: 0.0865909\tvalid_1's rmse: 0.0829084\n",
      "[725]\ttraining's rmse: 0.0865536\tvalid_1's rmse: 0.0829093\n",
      "[750]\ttraining's rmse: 0.0865195\tvalid_1's rmse: 0.0829072\n",
      "[775]\ttraining's rmse: 0.0864903\tvalid_1's rmse: 0.0829077\n",
      "Early stopping, best iteration is:\n",
      "[746]\ttraining's rmse: 0.0865257\tvalid_1's rmse: 0.0829032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876003\tvalid_1's rmse: 0.0900247\n",
      "[50]\ttraining's rmse: 0.0874565\tvalid_1's rmse: 0.0899718\n",
      "[75]\ttraining's rmse: 0.0873122\tvalid_1's rmse: 0.0899195\n",
      "[100]\ttraining's rmse: 0.087179\tvalid_1's rmse: 0.0898727\n",
      "[125]\ttraining's rmse: 0.0870453\tvalid_1's rmse: 0.0898247\n",
      "[150]\ttraining's rmse: 0.0869212\tvalid_1's rmse: 0.0897807\n",
      "[175]\ttraining's rmse: 0.0868165\tvalid_1's rmse: 0.0897427\n",
      "[200]\ttraining's rmse: 0.0867053\tvalid_1's rmse: 0.0897045\n",
      "[225]\ttraining's rmse: 0.086599\tvalid_1's rmse: 0.0896689\n",
      "[250]\ttraining's rmse: 0.0865073\tvalid_1's rmse: 0.0896377\n",
      "[275]\ttraining's rmse: 0.0864257\tvalid_1's rmse: 0.0896101\n",
      "[300]\ttraining's rmse: 0.0863411\tvalid_1's rmse: 0.0895823\n",
      "[325]\ttraining's rmse: 0.0862554\tvalid_1's rmse: 0.0895552\n",
      "[350]\ttraining's rmse: 0.0861752\tvalid_1's rmse: 0.0895292\n",
      "[375]\ttraining's rmse: 0.0861071\tvalid_1's rmse: 0.0895084\n",
      "[400]\ttraining's rmse: 0.0860347\tvalid_1's rmse: 0.0894867\n",
      "[425]\ttraining's rmse: 0.0859697\tvalid_1's rmse: 0.0894661\n",
      "[450]\ttraining's rmse: 0.0859078\tvalid_1's rmse: 0.0894447\n",
      "[475]\ttraining's rmse: 0.0858507\tvalid_1's rmse: 0.0894243\n",
      "[500]\ttraining's rmse: 0.0858021\tvalid_1's rmse: 0.0894084\n",
      "[525]\ttraining's rmse: 0.085741\tvalid_1's rmse: 0.0893915\n",
      "[550]\ttraining's rmse: 0.0856882\tvalid_1's rmse: 0.0893762\n",
      "[575]\ttraining's rmse: 0.0856406\tvalid_1's rmse: 0.0893623\n",
      "[600]\ttraining's rmse: 0.0855927\tvalid_1's rmse: 0.089349\n",
      "[625]\ttraining's rmse: 0.0855532\tvalid_1's rmse: 0.0893365\n",
      "[650]\ttraining's rmse: 0.0855078\tvalid_1's rmse: 0.0893246\n",
      "[675]\ttraining's rmse: 0.0854607\tvalid_1's rmse: 0.0893129\n",
      "[700]\ttraining's rmse: 0.0854183\tvalid_1's rmse: 0.0893014\n",
      "[725]\ttraining's rmse: 0.0853788\tvalid_1's rmse: 0.0892911\n",
      "[750]\ttraining's rmse: 0.0853399\tvalid_1's rmse: 0.0892808\n",
      "[775]\ttraining's rmse: 0.0853101\tvalid_1's rmse: 0.08927\n",
      "[800]\ttraining's rmse: 0.085271\tvalid_1's rmse: 0.0892605\n",
      "[825]\ttraining's rmse: 0.0852384\tvalid_1's rmse: 0.0892507\n",
      "[850]\ttraining's rmse: 0.0852048\tvalid_1's rmse: 0.0892432\n",
      "[875]\ttraining's rmse: 0.0851772\tvalid_1's rmse: 0.0892349\n",
      "[900]\ttraining's rmse: 0.0851429\tvalid_1's rmse: 0.0892265\n",
      "[925]\ttraining's rmse: 0.0851155\tvalid_1's rmse: 0.0892196\n",
      "[950]\ttraining's rmse: 0.0850889\tvalid_1's rmse: 0.0892122\n",
      "[975]\ttraining's rmse: 0.0850638\tvalid_1's rmse: 0.0892051\n",
      "[1000]\ttraining's rmse: 0.0850387\tvalid_1's rmse: 0.0891995\n",
      "[1025]\ttraining's rmse: 0.0850136\tvalid_1's rmse: 0.0891925\n",
      "[1050]\ttraining's rmse: 0.0849888\tvalid_1's rmse: 0.0891852\n",
      "[1075]\ttraining's rmse: 0.0849645\tvalid_1's rmse: 0.0891804\n",
      "[1100]\ttraining's rmse: 0.0849446\tvalid_1's rmse: 0.089176\n",
      "[1125]\ttraining's rmse: 0.0849267\tvalid_1's rmse: 0.0891709\n",
      "[1150]\ttraining's rmse: 0.0849081\tvalid_1's rmse: 0.089167\n",
      "[1175]\ttraining's rmse: 0.0848886\tvalid_1's rmse: 0.0891624\n",
      "[1200]\ttraining's rmse: 0.0848701\tvalid_1's rmse: 0.0891549\n",
      "[1225]\ttraining's rmse: 0.0848518\tvalid_1's rmse: 0.0891522\n",
      "[1250]\ttraining's rmse: 0.0848362\tvalid_1's rmse: 0.0891469\n",
      "[1275]\ttraining's rmse: 0.0848169\tvalid_1's rmse: 0.0891443\n",
      "[1300]\ttraining's rmse: 0.0848012\tvalid_1's rmse: 0.0891395\n",
      "[1325]\ttraining's rmse: 0.084787\tvalid_1's rmse: 0.0891371\n",
      "[1350]\ttraining's rmse: 0.0847727\tvalid_1's rmse: 0.0891335\n",
      "[1375]\ttraining's rmse: 0.0847591\tvalid_1's rmse: 0.0891303\n",
      "[1400]\ttraining's rmse: 0.0847467\tvalid_1's rmse: 0.0891266\n",
      "[1425]\ttraining's rmse: 0.0847308\tvalid_1's rmse: 0.0891239\n",
      "[1450]\ttraining's rmse: 0.0847144\tvalid_1's rmse: 0.0891209\n",
      "[1475]\ttraining's rmse: 0.0847046\tvalid_1's rmse: 0.0891178\n",
      "[1500]\ttraining's rmse: 0.084695\tvalid_1's rmse: 0.0891147\n",
      "[1525]\ttraining's rmse: 0.0846836\tvalid_1's rmse: 0.0891122\n",
      "[1550]\ttraining's rmse: 0.0846691\tvalid_1's rmse: 0.0891082\n",
      "[1575]\ttraining's rmse: 0.0846589\tvalid_1's rmse: 0.0891052\n",
      "[1600]\ttraining's rmse: 0.0846512\tvalid_1's rmse: 0.0891019\n",
      "[1625]\ttraining's rmse: 0.0846427\tvalid_1's rmse: 0.089099\n",
      "[1650]\ttraining's rmse: 0.0846355\tvalid_1's rmse: 0.0890966\n",
      "[1675]\ttraining's rmse: 0.0846284\tvalid_1's rmse: 0.0890936\n",
      "[1700]\ttraining's rmse: 0.0846233\tvalid_1's rmse: 0.0890913\n",
      "[1725]\ttraining's rmse: 0.084614\tvalid_1's rmse: 0.0890887\n",
      "[1750]\ttraining's rmse: 0.0846054\tvalid_1's rmse: 0.0890873\n",
      "[1775]\ttraining's rmse: 0.0845977\tvalid_1's rmse: 0.0890854\n",
      "[1800]\ttraining's rmse: 0.0845898\tvalid_1's rmse: 0.0890831\n",
      "[1825]\ttraining's rmse: 0.0845816\tvalid_1's rmse: 0.0890811\n",
      "[1850]\ttraining's rmse: 0.0845769\tvalid_1's rmse: 0.0890797\n",
      "[1875]\ttraining's rmse: 0.0845714\tvalid_1's rmse: 0.0890785\n",
      "[1900]\ttraining's rmse: 0.0845676\tvalid_1's rmse: 0.0890778\n",
      "[1925]\ttraining's rmse: 0.0845619\tvalid_1's rmse: 0.0890751\n",
      "[1950]\ttraining's rmse: 0.0845585\tvalid_1's rmse: 0.0890736\n",
      "[1975]\ttraining's rmse: 0.0845543\tvalid_1's rmse: 0.0890702\n",
      "[2000]\ttraining's rmse: 0.0845506\tvalid_1's rmse: 0.0890689\n",
      "[2025]\ttraining's rmse: 0.0845452\tvalid_1's rmse: 0.0890661\n",
      "[2050]\ttraining's rmse: 0.0845413\tvalid_1's rmse: 0.0890644\n",
      "[2075]\ttraining's rmse: 0.084537\tvalid_1's rmse: 0.0890633\n",
      "[2100]\ttraining's rmse: 0.0845324\tvalid_1's rmse: 0.0890621\n",
      "[2125]\ttraining's rmse: 0.0845283\tvalid_1's rmse: 0.089061\n",
      "[2150]\ttraining's rmse: 0.0845245\tvalid_1's rmse: 0.0890604\n",
      "[2175]\ttraining's rmse: 0.0845197\tvalid_1's rmse: 0.0890587\n",
      "[2200]\ttraining's rmse: 0.0845162\tvalid_1's rmse: 0.0890582\n",
      "[2225]\ttraining's rmse: 0.0845135\tvalid_1's rmse: 0.0890574\n",
      "[2250]\ttraining's rmse: 0.0845073\tvalid_1's rmse: 0.0890567\n",
      "[2275]\ttraining's rmse: 0.0845036\tvalid_1's rmse: 0.0890558\n",
      "[2300]\ttraining's rmse: 0.084501\tvalid_1's rmse: 0.0890543\n",
      "[2325]\ttraining's rmse: 0.0844979\tvalid_1's rmse: 0.0890533\n",
      "[2350]\ttraining's rmse: 0.0844951\tvalid_1's rmse: 0.0890527\n",
      "[2375]\ttraining's rmse: 0.0844921\tvalid_1's rmse: 0.0890526\n",
      "[2400]\ttraining's rmse: 0.084489\tvalid_1's rmse: 0.0890512\n",
      "[2425]\ttraining's rmse: 0.0844856\tvalid_1's rmse: 0.0890503\n",
      "[2450]\ttraining's rmse: 0.0844835\tvalid_1's rmse: 0.0890487\n",
      "[2475]\ttraining's rmse: 0.0844809\tvalid_1's rmse: 0.0890477\n",
      "[2500]\ttraining's rmse: 0.0844789\tvalid_1's rmse: 0.0890474\n",
      "[2525]\ttraining's rmse: 0.0844759\tvalid_1's rmse: 0.0890466\n",
      "[2550]\ttraining's rmse: 0.084474\tvalid_1's rmse: 0.0890464\n",
      "[2575]\ttraining's rmse: 0.0844721\tvalid_1's rmse: 0.089045\n",
      "[2600]\ttraining's rmse: 0.0844698\tvalid_1's rmse: 0.0890446\n",
      "[2625]\ttraining's rmse: 0.0844676\tvalid_1's rmse: 0.0890443\n",
      "[2650]\ttraining's rmse: 0.0844649\tvalid_1's rmse: 0.0890432\n",
      "[2675]\ttraining's rmse: 0.0844626\tvalid_1's rmse: 0.0890428\n",
      "[2700]\ttraining's rmse: 0.0844603\tvalid_1's rmse: 0.0890415\n",
      "[2725]\ttraining's rmse: 0.0844584\tvalid_1's rmse: 0.0890417\n",
      "[2750]\ttraining's rmse: 0.0844555\tvalid_1's rmse: 0.0890413\n",
      "[2775]\ttraining's rmse: 0.0844533\tvalid_1's rmse: 0.089041\n",
      "[2800]\ttraining's rmse: 0.0844519\tvalid_1's rmse: 0.0890403\n",
      "[2825]\ttraining's rmse: 0.0844498\tvalid_1's rmse: 0.0890403\n",
      "Early stopping, best iteration is:\n",
      "[2793]\ttraining's rmse: 0.0844521\tvalid_1's rmse: 0.0890402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0875338\tvalid_1's rmse: 0.0901851\n",
      "[50]\ttraining's rmse: 0.0874055\tvalid_1's rmse: 0.0901299\n",
      "[75]\ttraining's rmse: 0.0872699\tvalid_1's rmse: 0.0900747\n",
      "[100]\ttraining's rmse: 0.0871525\tvalid_1's rmse: 0.0900267\n",
      "[125]\ttraining's rmse: 0.0870305\tvalid_1's rmse: 0.0899797\n",
      "[150]\ttraining's rmse: 0.0869189\tvalid_1's rmse: 0.089934\n",
      "[175]\ttraining's rmse: 0.0868257\tvalid_1's rmse: 0.0898984\n",
      "[200]\ttraining's rmse: 0.0867236\tvalid_1's rmse: 0.0898614\n",
      "[225]\ttraining's rmse: 0.0866223\tvalid_1's rmse: 0.0898252\n",
      "[250]\ttraining's rmse: 0.0865363\tvalid_1's rmse: 0.0897935\n",
      "[275]\ttraining's rmse: 0.0864587\tvalid_1's rmse: 0.0897658\n",
      "[300]\ttraining's rmse: 0.0863781\tvalid_1's rmse: 0.0897381\n",
      "[325]\ttraining's rmse: 0.086299\tvalid_1's rmse: 0.0897114\n",
      "[350]\ttraining's rmse: 0.0862235\tvalid_1's rmse: 0.089687\n",
      "[375]\ttraining's rmse: 0.0861612\tvalid_1's rmse: 0.0896646\n",
      "[400]\ttraining's rmse: 0.0860921\tvalid_1's rmse: 0.0896449\n",
      "[425]\ttraining's rmse: 0.08603\tvalid_1's rmse: 0.0896247\n",
      "[450]\ttraining's rmse: 0.085971\tvalid_1's rmse: 0.0896062\n",
      "[475]\ttraining's rmse: 0.0859163\tvalid_1's rmse: 0.0895881\n",
      "[500]\ttraining's rmse: 0.0858698\tvalid_1's rmse: 0.0895715\n",
      "[525]\ttraining's rmse: 0.0858119\tvalid_1's rmse: 0.0895559\n",
      "[550]\ttraining's rmse: 0.0857589\tvalid_1's rmse: 0.0895408\n",
      "[575]\ttraining's rmse: 0.085712\tvalid_1's rmse: 0.089527\n",
      "[600]\ttraining's rmse: 0.0856629\tvalid_1's rmse: 0.0895136\n",
      "[625]\ttraining's rmse: 0.0856252\tvalid_1's rmse: 0.0895015\n",
      "[650]\ttraining's rmse: 0.0855794\tvalid_1's rmse: 0.089489\n",
      "[675]\ttraining's rmse: 0.0855331\tvalid_1's rmse: 0.0894777\n",
      "[700]\ttraining's rmse: 0.0854888\tvalid_1's rmse: 0.0894664\n",
      "[725]\ttraining's rmse: 0.0854512\tvalid_1's rmse: 0.0894572\n",
      "[750]\ttraining's rmse: 0.0854126\tvalid_1's rmse: 0.0894478\n",
      "[775]\ttraining's rmse: 0.0853841\tvalid_1's rmse: 0.089439\n",
      "[800]\ttraining's rmse: 0.0853447\tvalid_1's rmse: 0.0894311\n",
      "[825]\ttraining's rmse: 0.0853117\tvalid_1's rmse: 0.0894226\n",
      "[850]\ttraining's rmse: 0.0852788\tvalid_1's rmse: 0.0894158\n",
      "[875]\ttraining's rmse: 0.0852485\tvalid_1's rmse: 0.0894088\n",
      "[900]\ttraining's rmse: 0.0852179\tvalid_1's rmse: 0.0894011\n",
      "[925]\ttraining's rmse: 0.0851887\tvalid_1's rmse: 0.0893947\n",
      "[950]\ttraining's rmse: 0.0851613\tvalid_1's rmse: 0.0893892\n",
      "[975]\ttraining's rmse: 0.0851357\tvalid_1's rmse: 0.0893844\n",
      "[1000]\ttraining's rmse: 0.0851112\tvalid_1's rmse: 0.0893797\n",
      "[1025]\ttraining's rmse: 0.085086\tvalid_1's rmse: 0.0893755\n",
      "[1050]\ttraining's rmse: 0.0850647\tvalid_1's rmse: 0.0893709\n",
      "[1075]\ttraining's rmse: 0.0850424\tvalid_1's rmse: 0.0893676\n",
      "[1100]\ttraining's rmse: 0.0850243\tvalid_1's rmse: 0.0893641\n",
      "[1125]\ttraining's rmse: 0.0850061\tvalid_1's rmse: 0.0893613\n",
      "[1150]\ttraining's rmse: 0.0849871\tvalid_1's rmse: 0.0893582\n",
      "[1175]\ttraining's rmse: 0.0849689\tvalid_1's rmse: 0.0893554\n",
      "[1200]\ttraining's rmse: 0.08495\tvalid_1's rmse: 0.0893529\n",
      "[1225]\ttraining's rmse: 0.0849321\tvalid_1's rmse: 0.0893505\n",
      "[1250]\ttraining's rmse: 0.0849161\tvalid_1's rmse: 0.0893474\n",
      "[1275]\ttraining's rmse: 0.084896\tvalid_1's rmse: 0.0893447\n",
      "[1300]\ttraining's rmse: 0.0848822\tvalid_1's rmse: 0.0893421\n",
      "[1325]\ttraining's rmse: 0.0848656\tvalid_1's rmse: 0.0893398\n",
      "[1350]\ttraining's rmse: 0.084849\tvalid_1's rmse: 0.0893379\n",
      "[1375]\ttraining's rmse: 0.0848342\tvalid_1's rmse: 0.0893363\n",
      "[1400]\ttraining's rmse: 0.084823\tvalid_1's rmse: 0.0893343\n",
      "[1425]\ttraining's rmse: 0.0848082\tvalid_1's rmse: 0.0893329\n",
      "[1450]\ttraining's rmse: 0.0847931\tvalid_1's rmse: 0.0893316\n",
      "[1475]\ttraining's rmse: 0.0847815\tvalid_1's rmse: 0.0893302\n",
      "[1500]\ttraining's rmse: 0.0847697\tvalid_1's rmse: 0.0893288\n",
      "[1525]\ttraining's rmse: 0.0847589\tvalid_1's rmse: 0.0893276\n",
      "[1550]\ttraining's rmse: 0.0847487\tvalid_1's rmse: 0.0893263\n",
      "[1575]\ttraining's rmse: 0.0847385\tvalid_1's rmse: 0.0893252\n",
      "[1600]\ttraining's rmse: 0.08473\tvalid_1's rmse: 0.0893246\n",
      "[1625]\ttraining's rmse: 0.0847216\tvalid_1's rmse: 0.0893233\n",
      "[1650]\ttraining's rmse: 0.0847133\tvalid_1's rmse: 0.0893224\n",
      "[1675]\ttraining's rmse: 0.084706\tvalid_1's rmse: 0.0893215\n",
      "[1700]\ttraining's rmse: 0.0846991\tvalid_1's rmse: 0.0893205\n",
      "[1725]\ttraining's rmse: 0.0846911\tvalid_1's rmse: 0.0893188\n",
      "[1750]\ttraining's rmse: 0.0846833\tvalid_1's rmse: 0.0893182\n",
      "[1775]\ttraining's rmse: 0.0846772\tvalid_1's rmse: 0.0893178\n",
      "[1800]\ttraining's rmse: 0.084671\tvalid_1's rmse: 0.0893171\n",
      "[1825]\ttraining's rmse: 0.0846625\tvalid_1's rmse: 0.0893164\n",
      "[1850]\ttraining's rmse: 0.0846565\tvalid_1's rmse: 0.0893157\n",
      "[1875]\ttraining's rmse: 0.0846495\tvalid_1's rmse: 0.0893148\n",
      "[1900]\ttraining's rmse: 0.0846449\tvalid_1's rmse: 0.0893146\n",
      "[1925]\ttraining's rmse: 0.0846397\tvalid_1's rmse: 0.089314\n",
      "[1950]\ttraining's rmse: 0.0846353\tvalid_1's rmse: 0.0893137\n",
      "[1975]\ttraining's rmse: 0.0846295\tvalid_1's rmse: 0.0893132\n",
      "[2000]\ttraining's rmse: 0.0846242\tvalid_1's rmse: 0.0893126\n",
      "[2025]\ttraining's rmse: 0.0846206\tvalid_1's rmse: 0.0893122\n",
      "[2050]\ttraining's rmse: 0.0846164\tvalid_1's rmse: 0.0893123\n",
      "[2075]\ttraining's rmse: 0.0846124\tvalid_1's rmse: 0.0893118\n",
      "[2100]\ttraining's rmse: 0.084609\tvalid_1's rmse: 0.0893114\n",
      "[2125]\ttraining's rmse: 0.0846052\tvalid_1's rmse: 0.0893106\n",
      "[2150]\ttraining's rmse: 0.084602\tvalid_1's rmse: 0.0893106\n",
      "[2175]\ttraining's rmse: 0.0845988\tvalid_1's rmse: 0.0893104\n",
      "[2200]\ttraining's rmse: 0.0845963\tvalid_1's rmse: 0.0893102\n",
      "[2225]\ttraining's rmse: 0.0845932\tvalid_1's rmse: 0.0893093\n",
      "[2250]\ttraining's rmse: 0.0845909\tvalid_1's rmse: 0.0893096\n",
      "[2275]\ttraining's rmse: 0.0845879\tvalid_1's rmse: 0.0893096\n",
      "[2300]\ttraining's rmse: 0.084585\tvalid_1's rmse: 0.0893092\n",
      "[2325]\ttraining's rmse: 0.0845813\tvalid_1's rmse: 0.0893094\n",
      "[2350]\ttraining's rmse: 0.0845787\tvalid_1's rmse: 0.0893093\n",
      "[2375]\ttraining's rmse: 0.0845742\tvalid_1's rmse: 0.0893086\n",
      "[2400]\ttraining's rmse: 0.0845711\tvalid_1's rmse: 0.0893088\n",
      "[2425]\ttraining's rmse: 0.0845684\tvalid_1's rmse: 0.0893087\n",
      "Early stopping, best iteration is:\n",
      "[2386]\ttraining's rmse: 0.0845728\tvalid_1's rmse: 0.0893083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0899668\tvalid_1's rmse: 0.085232\n",
      "[50]\ttraining's rmse: 0.0898423\tvalid_1's rmse: 0.0851824\n",
      "[75]\ttraining's rmse: 0.0897102\tvalid_1's rmse: 0.0851328\n",
      "[100]\ttraining's rmse: 0.089595\tvalid_1's rmse: 0.0850917\n",
      "[125]\ttraining's rmse: 0.0894707\tvalid_1's rmse: 0.0850504\n",
      "[150]\ttraining's rmse: 0.0893597\tvalid_1's rmse: 0.0850134\n",
      "[175]\ttraining's rmse: 0.0892672\tvalid_1's rmse: 0.0849813\n",
      "[200]\ttraining's rmse: 0.0891666\tvalid_1's rmse: 0.0849503\n",
      "[225]\ttraining's rmse: 0.089067\tvalid_1's rmse: 0.0849192\n",
      "[250]\ttraining's rmse: 0.0889851\tvalid_1's rmse: 0.0848918\n",
      "[275]\ttraining's rmse: 0.0889083\tvalid_1's rmse: 0.0848656\n",
      "[300]\ttraining's rmse: 0.0888317\tvalid_1's rmse: 0.0848416\n",
      "[325]\ttraining's rmse: 0.0887566\tvalid_1's rmse: 0.084819\n",
      "[350]\ttraining's rmse: 0.0886819\tvalid_1's rmse: 0.0847961\n",
      "[375]\ttraining's rmse: 0.0886227\tvalid_1's rmse: 0.0847796\n",
      "[400]\ttraining's rmse: 0.0885558\tvalid_1's rmse: 0.0847621\n",
      "[425]\ttraining's rmse: 0.0884945\tvalid_1's rmse: 0.0847526\n",
      "[450]\ttraining's rmse: 0.08844\tvalid_1's rmse: 0.0847371\n",
      "[475]\ttraining's rmse: 0.0883878\tvalid_1's rmse: 0.0847228\n",
      "[500]\ttraining's rmse: 0.0883399\tvalid_1's rmse: 0.0847089\n",
      "[525]\ttraining's rmse: 0.0882811\tvalid_1's rmse: 0.0846955\n",
      "[550]\ttraining's rmse: 0.0882256\tvalid_1's rmse: 0.0846825\n",
      "[575]\ttraining's rmse: 0.0881757\tvalid_1's rmse: 0.0846741\n",
      "[600]\ttraining's rmse: 0.0881272\tvalid_1's rmse: 0.0846678\n",
      "[625]\ttraining's rmse: 0.0880896\tvalid_1's rmse: 0.0846638\n",
      "[650]\ttraining's rmse: 0.088045\tvalid_1's rmse: 0.084665\n",
      "[675]\ttraining's rmse: 0.0879964\tvalid_1's rmse: 0.0846612\n",
      "[700]\ttraining's rmse: 0.0879544\tvalid_1's rmse: 0.0846562\n",
      "[725]\ttraining's rmse: 0.0879146\tvalid_1's rmse: 0.0846607\n",
      "[750]\ttraining's rmse: 0.0878761\tvalid_1's rmse: 0.0846595\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.087946\tvalid_1's rmse: 0.0846556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0863505\tvalid_1's rmse: 0.0891432\n",
      "[50]\ttraining's rmse: 0.0862234\tvalid_1's rmse: 0.0890906\n",
      "[75]\ttraining's rmse: 0.0860912\tvalid_1's rmse: 0.0890347\n",
      "[100]\ttraining's rmse: 0.0859712\tvalid_1's rmse: 0.0889892\n",
      "[125]\ttraining's rmse: 0.0858508\tvalid_1's rmse: 0.088943\n",
      "[150]\ttraining's rmse: 0.0857406\tvalid_1's rmse: 0.0888986\n",
      "[175]\ttraining's rmse: 0.0856494\tvalid_1's rmse: 0.0888578\n",
      "[200]\ttraining's rmse: 0.0855516\tvalid_1's rmse: 0.0888207\n",
      "[225]\ttraining's rmse: 0.0854562\tvalid_1's rmse: 0.0887846\n",
      "[250]\ttraining's rmse: 0.0853758\tvalid_1's rmse: 0.0887515\n",
      "[275]\ttraining's rmse: 0.0852999\tvalid_1's rmse: 0.0887208\n",
      "[300]\ttraining's rmse: 0.0852242\tvalid_1's rmse: 0.088693\n",
      "[325]\ttraining's rmse: 0.0851497\tvalid_1's rmse: 0.0886663\n",
      "[350]\ttraining's rmse: 0.085077\tvalid_1's rmse: 0.0886404\n",
      "[375]\ttraining's rmse: 0.0850138\tvalid_1's rmse: 0.0886179\n",
      "[400]\ttraining's rmse: 0.084948\tvalid_1's rmse: 0.0885973\n",
      "[425]\ttraining's rmse: 0.0848878\tvalid_1's rmse: 0.0885758\n",
      "[450]\ttraining's rmse: 0.0848344\tvalid_1's rmse: 0.0885555\n",
      "[475]\ttraining's rmse: 0.0847837\tvalid_1's rmse: 0.0885365\n",
      "[500]\ttraining's rmse: 0.0847407\tvalid_1's rmse: 0.0885193\n",
      "[525]\ttraining's rmse: 0.0846845\tvalid_1's rmse: 0.0885028\n",
      "[550]\ttraining's rmse: 0.0846349\tvalid_1's rmse: 0.0884875\n",
      "[575]\ttraining's rmse: 0.0845893\tvalid_1's rmse: 0.0884737\n",
      "[600]\ttraining's rmse: 0.084542\tvalid_1's rmse: 0.0884592\n",
      "[625]\ttraining's rmse: 0.0845074\tvalid_1's rmse: 0.0884463\n",
      "[650]\ttraining's rmse: 0.0844649\tvalid_1's rmse: 0.0884326\n",
      "[675]\ttraining's rmse: 0.084424\tvalid_1's rmse: 0.0884195\n",
      "[700]\ttraining's rmse: 0.084385\tvalid_1's rmse: 0.0884066\n",
      "[725]\ttraining's rmse: 0.0843486\tvalid_1's rmse: 0.0883952\n",
      "[750]\ttraining's rmse: 0.0843132\tvalid_1's rmse: 0.0883845\n",
      "[775]\ttraining's rmse: 0.0842862\tvalid_1's rmse: 0.088374\n",
      "[800]\ttraining's rmse: 0.0842541\tvalid_1's rmse: 0.0883654\n",
      "[825]\ttraining's rmse: 0.0842243\tvalid_1's rmse: 0.0883555\n",
      "[850]\ttraining's rmse: 0.0841907\tvalid_1's rmse: 0.0883468\n",
      "[875]\ttraining's rmse: 0.0841658\tvalid_1's rmse: 0.0883392\n",
      "[900]\ttraining's rmse: 0.0841335\tvalid_1's rmse: 0.0883317\n",
      "[925]\ttraining's rmse: 0.0841093\tvalid_1's rmse: 0.0883226\n",
      "[950]\ttraining's rmse: 0.0840872\tvalid_1's rmse: 0.0883156\n",
      "[975]\ttraining's rmse: 0.0840642\tvalid_1's rmse: 0.0883087\n",
      "[1000]\ttraining's rmse: 0.0840399\tvalid_1's rmse: 0.0883026\n",
      "[1025]\ttraining's rmse: 0.0840189\tvalid_1's rmse: 0.0882955\n",
      "[1050]\ttraining's rmse: 0.083997\tvalid_1's rmse: 0.0882896\n",
      "[1075]\ttraining's rmse: 0.0839769\tvalid_1's rmse: 0.0882852\n",
      "[1100]\ttraining's rmse: 0.0839593\tvalid_1's rmse: 0.0882811\n",
      "[1125]\ttraining's rmse: 0.0839421\tvalid_1's rmse: 0.0882764\n",
      "[1150]\ttraining's rmse: 0.0839228\tvalid_1's rmse: 0.0882715\n",
      "[1175]\ttraining's rmse: 0.0839058\tvalid_1's rmse: 0.0882677\n",
      "[1200]\ttraining's rmse: 0.0838903\tvalid_1's rmse: 0.0882621\n",
      "[1225]\ttraining's rmse: 0.0838744\tvalid_1's rmse: 0.088257\n",
      "[1250]\ttraining's rmse: 0.0838601\tvalid_1's rmse: 0.0882535\n",
      "[1275]\ttraining's rmse: 0.0838428\tvalid_1's rmse: 0.0882505\n",
      "[1300]\ttraining's rmse: 0.0838274\tvalid_1's rmse: 0.0882462\n",
      "[1325]\ttraining's rmse: 0.0838136\tvalid_1's rmse: 0.0882432\n",
      "[1350]\ttraining's rmse: 0.0837998\tvalid_1's rmse: 0.0882394\n",
      "[1375]\ttraining's rmse: 0.0837872\tvalid_1's rmse: 0.0882355\n",
      "[1400]\ttraining's rmse: 0.0837761\tvalid_1's rmse: 0.0882312\n",
      "[1425]\ttraining's rmse: 0.0837605\tvalid_1's rmse: 0.0882289\n",
      "[1450]\ttraining's rmse: 0.0837471\tvalid_1's rmse: 0.0882269\n",
      "[1475]\ttraining's rmse: 0.0837361\tvalid_1's rmse: 0.088224\n",
      "[1500]\ttraining's rmse: 0.0837261\tvalid_1's rmse: 0.0882212\n",
      "[1525]\ttraining's rmse: 0.0837167\tvalid_1's rmse: 0.0882193\n",
      "[1550]\ttraining's rmse: 0.0837055\tvalid_1's rmse: 0.0882175\n",
      "[1575]\ttraining's rmse: 0.0836958\tvalid_1's rmse: 0.0882146\n",
      "[1600]\ttraining's rmse: 0.0836881\tvalid_1's rmse: 0.0882123\n",
      "[1625]\ttraining's rmse: 0.0836794\tvalid_1's rmse: 0.0882104\n",
      "[1650]\ttraining's rmse: 0.0836708\tvalid_1's rmse: 0.0882074\n",
      "[1675]\ttraining's rmse: 0.0836653\tvalid_1's rmse: 0.0882049\n",
      "[1700]\ttraining's rmse: 0.0836607\tvalid_1's rmse: 0.0882038\n",
      "[1725]\ttraining's rmse: 0.0836552\tvalid_1's rmse: 0.0882024\n",
      "[1750]\ttraining's rmse: 0.0836468\tvalid_1's rmse: 0.0881996\n",
      "[1775]\ttraining's rmse: 0.083639\tvalid_1's rmse: 0.0881979\n",
      "[1800]\ttraining's rmse: 0.0836327\tvalid_1's rmse: 0.0881939\n",
      "[1825]\ttraining's rmse: 0.0836264\tvalid_1's rmse: 0.0881923\n",
      "[1850]\ttraining's rmse: 0.0836212\tvalid_1's rmse: 0.0881899\n",
      "[1875]\ttraining's rmse: 0.083616\tvalid_1's rmse: 0.0881887\n",
      "[1900]\ttraining's rmse: 0.083612\tvalid_1's rmse: 0.0881864\n",
      "[1925]\ttraining's rmse: 0.0836068\tvalid_1's rmse: 0.0881848\n",
      "[1950]\ttraining's rmse: 0.0836035\tvalid_1's rmse: 0.0881828\n",
      "[1975]\ttraining's rmse: 0.0836002\tvalid_1's rmse: 0.0881819\n",
      "[2000]\ttraining's rmse: 0.0835942\tvalid_1's rmse: 0.0881802\n",
      "[2025]\ttraining's rmse: 0.0835905\tvalid_1's rmse: 0.088179\n",
      "[2050]\ttraining's rmse: 0.0835869\tvalid_1's rmse: 0.0881784\n",
      "[2075]\ttraining's rmse: 0.083584\tvalid_1's rmse: 0.088177\n",
      "[2100]\ttraining's rmse: 0.0835816\tvalid_1's rmse: 0.0881763\n",
      "[2125]\ttraining's rmse: 0.0835782\tvalid_1's rmse: 0.0881747\n",
      "[2150]\ttraining's rmse: 0.0835746\tvalid_1's rmse: 0.0881746\n",
      "[2175]\ttraining's rmse: 0.0835721\tvalid_1's rmse: 0.0881743\n",
      "[2200]\ttraining's rmse: 0.0835677\tvalid_1's rmse: 0.0881731\n",
      "[2225]\ttraining's rmse: 0.0835636\tvalid_1's rmse: 0.0881726\n",
      "[2250]\ttraining's rmse: 0.0835609\tvalid_1's rmse: 0.088172\n",
      "[2275]\ttraining's rmse: 0.083558\tvalid_1's rmse: 0.0881721\n",
      "[2300]\ttraining's rmse: 0.0835545\tvalid_1's rmse: 0.0881711\n",
      "[2325]\ttraining's rmse: 0.0835515\tvalid_1's rmse: 0.08817\n",
      "[2350]\ttraining's rmse: 0.083549\tvalid_1's rmse: 0.0881696\n",
      "[2375]\ttraining's rmse: 0.0835473\tvalid_1's rmse: 0.0881694\n",
      "[2400]\ttraining's rmse: 0.083544\tvalid_1's rmse: 0.0881688\n",
      "[2425]\ttraining's rmse: 0.0835416\tvalid_1's rmse: 0.0881672\n",
      "[2450]\ttraining's rmse: 0.0835384\tvalid_1's rmse: 0.0881668\n",
      "[2475]\ttraining's rmse: 0.0835356\tvalid_1's rmse: 0.088166\n",
      "[2500]\ttraining's rmse: 0.0835342\tvalid_1's rmse: 0.0881656\n",
      "[2525]\ttraining's rmse: 0.0835318\tvalid_1's rmse: 0.0881653\n",
      "[2550]\ttraining's rmse: 0.0835291\tvalid_1's rmse: 0.0881641\n",
      "[2575]\ttraining's rmse: 0.0835267\tvalid_1's rmse: 0.0881633\n",
      "[2600]\ttraining's rmse: 0.0835242\tvalid_1's rmse: 0.088163\n",
      "[2625]\ttraining's rmse: 0.0835226\tvalid_1's rmse: 0.0881625\n",
      "[2650]\ttraining's rmse: 0.0835198\tvalid_1's rmse: 0.0881613\n",
      "[2675]\ttraining's rmse: 0.083518\tvalid_1's rmse: 0.0881609\n",
      "[2700]\ttraining's rmse: 0.0835157\tvalid_1's rmse: 0.0881606\n",
      "[2725]\ttraining's rmse: 0.0835128\tvalid_1's rmse: 0.0881606\n",
      "[2750]\ttraining's rmse: 0.0835099\tvalid_1's rmse: 0.0881597\n",
      "[2775]\ttraining's rmse: 0.0835081\tvalid_1's rmse: 0.0881598\n",
      "[2800]\ttraining's rmse: 0.083507\tvalid_1's rmse: 0.0881592\n",
      "[2825]\ttraining's rmse: 0.083504\tvalid_1's rmse: 0.088159\n",
      "[2850]\ttraining's rmse: 0.0835021\tvalid_1's rmse: 0.0881587\n",
      "[2875]\ttraining's rmse: 0.0834993\tvalid_1's rmse: 0.0881588\n",
      "[2900]\ttraining's rmse: 0.0834981\tvalid_1's rmse: 0.0881584\n",
      "[2925]\ttraining's rmse: 0.0834971\tvalid_1's rmse: 0.0881576\n",
      "[2950]\ttraining's rmse: 0.0834949\tvalid_1's rmse: 0.0881578\n",
      "Early stopping, best iteration is:\n",
      "[2918]\ttraining's rmse: 0.0834972\tvalid_1's rmse: 0.0881576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0864367\tvalid_1's rmse: 0.0889831\n",
      "[50]\ttraining's rmse: 0.0863168\tvalid_1's rmse: 0.0889287\n",
      "[75]\ttraining's rmse: 0.0861914\tvalid_1's rmse: 0.0888753\n",
      "[100]\ttraining's rmse: 0.086082\tvalid_1's rmse: 0.0888289\n",
      "[125]\ttraining's rmse: 0.0859665\tvalid_1's rmse: 0.0887831\n",
      "[150]\ttraining's rmse: 0.0858594\tvalid_1's rmse: 0.0887392\n",
      "[175]\ttraining's rmse: 0.0857696\tvalid_1's rmse: 0.0887037\n",
      "[200]\ttraining's rmse: 0.0856715\tvalid_1's rmse: 0.0886662\n",
      "[225]\ttraining's rmse: 0.0855806\tvalid_1's rmse: 0.0886318\n",
      "[250]\ttraining's rmse: 0.0855023\tvalid_1's rmse: 0.0886013\n",
      "[275]\ttraining's rmse: 0.0854292\tvalid_1's rmse: 0.0885741\n",
      "[300]\ttraining's rmse: 0.0853562\tvalid_1's rmse: 0.0885461\n",
      "[325]\ttraining's rmse: 0.0852803\tvalid_1's rmse: 0.0885186\n",
      "[350]\ttraining's rmse: 0.0852092\tvalid_1's rmse: 0.0884942\n",
      "[375]\ttraining's rmse: 0.0851503\tvalid_1's rmse: 0.0884732\n",
      "[400]\ttraining's rmse: 0.0850871\tvalid_1's rmse: 0.0884546\n",
      "[425]\ttraining's rmse: 0.0850275\tvalid_1's rmse: 0.0884346\n",
      "[450]\ttraining's rmse: 0.0849743\tvalid_1's rmse: 0.0884163\n",
      "[475]\ttraining's rmse: 0.0849239\tvalid_1's rmse: 0.0883984\n",
      "[500]\ttraining's rmse: 0.0848817\tvalid_1's rmse: 0.088383\n",
      "[525]\ttraining's rmse: 0.0848242\tvalid_1's rmse: 0.0883659\n",
      "[550]\ttraining's rmse: 0.0847725\tvalid_1's rmse: 0.0883505\n",
      "[575]\ttraining's rmse: 0.0847249\tvalid_1's rmse: 0.0883356\n",
      "[600]\ttraining's rmse: 0.0846797\tvalid_1's rmse: 0.088322\n",
      "[625]\ttraining's rmse: 0.0846441\tvalid_1's rmse: 0.0883104\n",
      "[650]\ttraining's rmse: 0.0845984\tvalid_1's rmse: 0.0882977\n",
      "[675]\ttraining's rmse: 0.0845543\tvalid_1's rmse: 0.0882865\n",
      "[700]\ttraining's rmse: 0.0845147\tvalid_1's rmse: 0.0882767\n",
      "[725]\ttraining's rmse: 0.0844783\tvalid_1's rmse: 0.0882674\n",
      "[750]\ttraining's rmse: 0.0844445\tvalid_1's rmse: 0.088258\n",
      "[775]\ttraining's rmse: 0.0844141\tvalid_1's rmse: 0.0882486\n",
      "[800]\ttraining's rmse: 0.0843757\tvalid_1's rmse: 0.0882403\n",
      "[825]\ttraining's rmse: 0.0843453\tvalid_1's rmse: 0.0882315\n",
      "[850]\ttraining's rmse: 0.0843156\tvalid_1's rmse: 0.0882251\n",
      "[875]\ttraining's rmse: 0.08429\tvalid_1's rmse: 0.0882189\n",
      "[900]\ttraining's rmse: 0.0842616\tvalid_1's rmse: 0.0882123\n",
      "[925]\ttraining's rmse: 0.0842338\tvalid_1's rmse: 0.0882066\n",
      "[950]\ttraining's rmse: 0.0842104\tvalid_1's rmse: 0.0882006\n",
      "[975]\ttraining's rmse: 0.0841861\tvalid_1's rmse: 0.0881949\n",
      "[1000]\ttraining's rmse: 0.0841637\tvalid_1's rmse: 0.0881898\n",
      "[1025]\ttraining's rmse: 0.0841361\tvalid_1's rmse: 0.088185\n",
      "[1050]\ttraining's rmse: 0.0841154\tvalid_1's rmse: 0.0881808\n",
      "[1075]\ttraining's rmse: 0.0840929\tvalid_1's rmse: 0.0881766\n",
      "[1100]\ttraining's rmse: 0.0840763\tvalid_1's rmse: 0.0881733\n",
      "[1125]\ttraining's rmse: 0.0840568\tvalid_1's rmse: 0.0881697\n",
      "[1150]\ttraining's rmse: 0.0840378\tvalid_1's rmse: 0.0881662\n",
      "[1175]\ttraining's rmse: 0.0840213\tvalid_1's rmse: 0.0881634\n",
      "[1200]\ttraining's rmse: 0.0840045\tvalid_1's rmse: 0.0881597\n",
      "[1225]\ttraining's rmse: 0.0839898\tvalid_1's rmse: 0.0881574\n",
      "[1250]\ttraining's rmse: 0.0839761\tvalid_1's rmse: 0.088155\n",
      "[1275]\ttraining's rmse: 0.083958\tvalid_1's rmse: 0.0881525\n",
      "[1300]\ttraining's rmse: 0.0839446\tvalid_1's rmse: 0.0881503\n",
      "[1325]\ttraining's rmse: 0.0839309\tvalid_1's rmse: 0.0881483\n",
      "[1350]\ttraining's rmse: 0.0839169\tvalid_1's rmse: 0.0881466\n",
      "[1375]\ttraining's rmse: 0.0839042\tvalid_1's rmse: 0.088145\n",
      "[1400]\ttraining's rmse: 0.0838932\tvalid_1's rmse: 0.0881427\n",
      "[1425]\ttraining's rmse: 0.0838802\tvalid_1's rmse: 0.0881415\n",
      "[1450]\ttraining's rmse: 0.083866\tvalid_1's rmse: 0.0881398\n",
      "[1475]\ttraining's rmse: 0.0838542\tvalid_1's rmse: 0.088138\n",
      "[1500]\ttraining's rmse: 0.0838445\tvalid_1's rmse: 0.0881364\n",
      "[1525]\ttraining's rmse: 0.0838334\tvalid_1's rmse: 0.0881354\n",
      "[1550]\ttraining's rmse: 0.083825\tvalid_1's rmse: 0.0881341\n",
      "[1575]\ttraining's rmse: 0.083818\tvalid_1's rmse: 0.0881327\n",
      "[1600]\ttraining's rmse: 0.0838112\tvalid_1's rmse: 0.088132\n",
      "[1625]\ttraining's rmse: 0.0838016\tvalid_1's rmse: 0.0881307\n",
      "[1650]\ttraining's rmse: 0.0837918\tvalid_1's rmse: 0.0881295\n",
      "[1675]\ttraining's rmse: 0.0837838\tvalid_1's rmse: 0.0881283\n",
      "[1700]\ttraining's rmse: 0.0837772\tvalid_1's rmse: 0.0881272\n",
      "[1725]\ttraining's rmse: 0.0837698\tvalid_1's rmse: 0.0881262\n",
      "[1750]\ttraining's rmse: 0.0837639\tvalid_1's rmse: 0.0881257\n",
      "[1775]\ttraining's rmse: 0.0837575\tvalid_1's rmse: 0.0881253\n",
      "[1800]\ttraining's rmse: 0.0837494\tvalid_1's rmse: 0.0881244\n",
      "[1825]\ttraining's rmse: 0.0837423\tvalid_1's rmse: 0.0881236\n",
      "[1850]\ttraining's rmse: 0.0837371\tvalid_1's rmse: 0.0881228\n",
      "[1875]\ttraining's rmse: 0.083731\tvalid_1's rmse: 0.0881222\n",
      "[1900]\ttraining's rmse: 0.0837265\tvalid_1's rmse: 0.0881219\n",
      "[1925]\ttraining's rmse: 0.0837225\tvalid_1's rmse: 0.0881216\n",
      "[1950]\ttraining's rmse: 0.0837171\tvalid_1's rmse: 0.0881207\n",
      "[1975]\ttraining's rmse: 0.0837125\tvalid_1's rmse: 0.0881196\n",
      "[2000]\ttraining's rmse: 0.0837068\tvalid_1's rmse: 0.0881188\n",
      "[2025]\ttraining's rmse: 0.0837026\tvalid_1's rmse: 0.0881182\n",
      "[2050]\ttraining's rmse: 0.083698\tvalid_1's rmse: 0.0881179\n",
      "[2075]\ttraining's rmse: 0.0836932\tvalid_1's rmse: 0.0881171\n",
      "[2100]\ttraining's rmse: 0.0836891\tvalid_1's rmse: 0.0881168\n",
      "[2125]\ttraining's rmse: 0.0836868\tvalid_1's rmse: 0.0881169\n",
      "[2150]\ttraining's rmse: 0.083684\tvalid_1's rmse: 0.0881165\n",
      "[2175]\ttraining's rmse: 0.0836797\tvalid_1's rmse: 0.0881166\n",
      "[2200]\ttraining's rmse: 0.0836768\tvalid_1's rmse: 0.0881166\n",
      "[2225]\ttraining's rmse: 0.0836733\tvalid_1's rmse: 0.0881163\n",
      "[2250]\ttraining's rmse: 0.0836705\tvalid_1's rmse: 0.0881159\n",
      "[2275]\ttraining's rmse: 0.0836667\tvalid_1's rmse: 0.0881157\n",
      "[2300]\ttraining's rmse: 0.0836626\tvalid_1's rmse: 0.0881152\n",
      "[2325]\ttraining's rmse: 0.0836603\tvalid_1's rmse: 0.088115\n",
      "[2350]\ttraining's rmse: 0.0836562\tvalid_1's rmse: 0.0881146\n",
      "[2375]\ttraining's rmse: 0.0836527\tvalid_1's rmse: 0.0881142\n",
      "[2400]\ttraining's rmse: 0.0836487\tvalid_1's rmse: 0.0881143\n",
      "[2425]\ttraining's rmse: 0.0836471\tvalid_1's rmse: 0.0881145\n",
      "Early stopping, best iteration is:\n",
      "[2389]\ttraining's rmse: 0.0836514\tvalid_1's rmse: 0.088114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0889391\tvalid_1's rmse: 0.0838905\n",
      "[50]\ttraining's rmse: 0.0888237\tvalid_1's rmse: 0.0838413\n",
      "[75]\ttraining's rmse: 0.0887022\tvalid_1's rmse: 0.0837933\n",
      "[100]\ttraining's rmse: 0.0885944\tvalid_1's rmse: 0.0837517\n",
      "[125]\ttraining's rmse: 0.0884831\tvalid_1's rmse: 0.0837108\n",
      "[150]\ttraining's rmse: 0.088383\tvalid_1's rmse: 0.0836759\n",
      "[175]\ttraining's rmse: 0.0882985\tvalid_1's rmse: 0.0836448\n",
      "[200]\ttraining's rmse: 0.0882064\tvalid_1's rmse: 0.0836145\n",
      "[225]\ttraining's rmse: 0.0881189\tvalid_1's rmse: 0.0835856\n",
      "[250]\ttraining's rmse: 0.0880415\tvalid_1's rmse: 0.0835631\n",
      "[275]\ttraining's rmse: 0.0879722\tvalid_1's rmse: 0.0835389\n",
      "[300]\ttraining's rmse: 0.0879029\tvalid_1's rmse: 0.0835166\n",
      "[325]\ttraining's rmse: 0.0878316\tvalid_1's rmse: 0.0834944\n",
      "[350]\ttraining's rmse: 0.0877602\tvalid_1's rmse: 0.0834737\n",
      "[375]\ttraining's rmse: 0.0877051\tvalid_1's rmse: 0.0834608\n",
      "[400]\ttraining's rmse: 0.0876443\tvalid_1's rmse: 0.0834487\n",
      "[425]\ttraining's rmse: 0.087586\tvalid_1's rmse: 0.0834378\n",
      "[450]\ttraining's rmse: 0.0875329\tvalid_1's rmse: 0.0834237\n",
      "[475]\ttraining's rmse: 0.0874838\tvalid_1's rmse: 0.08341\n",
      "[500]\ttraining's rmse: 0.0874425\tvalid_1's rmse: 0.0833966\n",
      "[525]\ttraining's rmse: 0.0873879\tvalid_1's rmse: 0.0833824\n",
      "[550]\ttraining's rmse: 0.0873386\tvalid_1's rmse: 0.0833701\n",
      "[575]\ttraining's rmse: 0.0872924\tvalid_1's rmse: 0.0833647\n",
      "[600]\ttraining's rmse: 0.0872461\tvalid_1's rmse: 0.083359\n",
      "[625]\ttraining's rmse: 0.0872115\tvalid_1's rmse: 0.0833531\n",
      "[650]\ttraining's rmse: 0.0871672\tvalid_1's rmse: 0.0833437\n",
      "[675]\ttraining's rmse: 0.0871235\tvalid_1's rmse: 0.0833466\n",
      "[700]\ttraining's rmse: 0.0870853\tvalid_1's rmse: 0.0833392\n",
      "[725]\ttraining's rmse: 0.0870496\tvalid_1's rmse: 0.0833366\n",
      "[750]\ttraining's rmse: 0.0870154\tvalid_1's rmse: 0.0833534\n",
      "[775]\ttraining's rmse: 0.0869865\tvalid_1's rmse: 0.0833467\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 0.0870243\tvalid_1's rmse: 0.0833313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0886471\tvalid_1's rmse: 0.0908024\n",
      "[50]\ttraining's rmse: 0.0884991\tvalid_1's rmse: 0.0907484\n",
      "[75]\ttraining's rmse: 0.0883506\tvalid_1's rmse: 0.0906927\n",
      "[100]\ttraining's rmse: 0.0882146\tvalid_1's rmse: 0.090646\n",
      "[125]\ttraining's rmse: 0.0880796\tvalid_1's rmse: 0.0905982\n",
      "[150]\ttraining's rmse: 0.0879517\tvalid_1's rmse: 0.0905527\n",
      "[175]\ttraining's rmse: 0.0878484\tvalid_1's rmse: 0.0905155\n",
      "[200]\ttraining's rmse: 0.087737\tvalid_1's rmse: 0.0904766\n",
      "[225]\ttraining's rmse: 0.0876297\tvalid_1's rmse: 0.09044\n",
      "[250]\ttraining's rmse: 0.0875346\tvalid_1's rmse: 0.0904082\n",
      "[275]\ttraining's rmse: 0.0874502\tvalid_1's rmse: 0.0903791\n",
      "[300]\ttraining's rmse: 0.0873664\tvalid_1's rmse: 0.0903486\n",
      "[325]\ttraining's rmse: 0.0872828\tvalid_1's rmse: 0.0903196\n",
      "[350]\ttraining's rmse: 0.0872009\tvalid_1's rmse: 0.0902927\n",
      "[375]\ttraining's rmse: 0.0871314\tvalid_1's rmse: 0.090271\n",
      "[400]\ttraining's rmse: 0.0870564\tvalid_1's rmse: 0.0902476\n",
      "[425]\ttraining's rmse: 0.0869891\tvalid_1's rmse: 0.0902271\n",
      "[450]\ttraining's rmse: 0.0869279\tvalid_1's rmse: 0.0902078\n",
      "[475]\ttraining's rmse: 0.0868695\tvalid_1's rmse: 0.0901897\n",
      "[500]\ttraining's rmse: 0.0868184\tvalid_1's rmse: 0.090173\n",
      "[525]\ttraining's rmse: 0.0867594\tvalid_1's rmse: 0.0901563\n",
      "[550]\ttraining's rmse: 0.0867055\tvalid_1's rmse: 0.0901399\n",
      "[575]\ttraining's rmse: 0.086652\tvalid_1's rmse: 0.0901257\n",
      "[600]\ttraining's rmse: 0.086602\tvalid_1's rmse: 0.0901115\n",
      "[625]\ttraining's rmse: 0.0865631\tvalid_1's rmse: 0.0900988\n",
      "[650]\ttraining's rmse: 0.0865178\tvalid_1's rmse: 0.0900848\n",
      "[675]\ttraining's rmse: 0.0864679\tvalid_1's rmse: 0.0900722\n",
      "[700]\ttraining's rmse: 0.0864268\tvalid_1's rmse: 0.0900611\n",
      "[725]\ttraining's rmse: 0.0863888\tvalid_1's rmse: 0.0900516\n",
      "[750]\ttraining's rmse: 0.0863528\tvalid_1's rmse: 0.0900404\n",
      "[775]\ttraining's rmse: 0.0863229\tvalid_1's rmse: 0.0900297\n",
      "[800]\ttraining's rmse: 0.0862856\tvalid_1's rmse: 0.0900218\n",
      "[825]\ttraining's rmse: 0.086253\tvalid_1's rmse: 0.0900131\n",
      "[850]\ttraining's rmse: 0.0862159\tvalid_1's rmse: 0.0900047\n",
      "[875]\ttraining's rmse: 0.0861866\tvalid_1's rmse: 0.089996\n",
      "[900]\ttraining's rmse: 0.0861544\tvalid_1's rmse: 0.0899881\n",
      "[925]\ttraining's rmse: 0.0861258\tvalid_1's rmse: 0.0899807\n",
      "[950]\ttraining's rmse: 0.086098\tvalid_1's rmse: 0.0899726\n",
      "[975]\ttraining's rmse: 0.0860733\tvalid_1's rmse: 0.0899667\n",
      "[1000]\ttraining's rmse: 0.0860488\tvalid_1's rmse: 0.0899597\n",
      "[1025]\ttraining's rmse: 0.0860215\tvalid_1's rmse: 0.0899536\n",
      "[1050]\ttraining's rmse: 0.0859963\tvalid_1's rmse: 0.0899474\n",
      "[1075]\ttraining's rmse: 0.0859721\tvalid_1's rmse: 0.089943\n",
      "[1100]\ttraining's rmse: 0.0859493\tvalid_1's rmse: 0.0899361\n",
      "[1125]\ttraining's rmse: 0.0859303\tvalid_1's rmse: 0.0899306\n",
      "[1150]\ttraining's rmse: 0.0859073\tvalid_1's rmse: 0.0899254\n",
      "[1175]\ttraining's rmse: 0.0858895\tvalid_1's rmse: 0.0899214\n",
      "[1200]\ttraining's rmse: 0.0858708\tvalid_1's rmse: 0.0899156\n",
      "[1225]\ttraining's rmse: 0.0858506\tvalid_1's rmse: 0.0899102\n",
      "[1250]\ttraining's rmse: 0.0858361\tvalid_1's rmse: 0.0899053\n",
      "[1275]\ttraining's rmse: 0.0858163\tvalid_1's rmse: 0.0899011\n",
      "[1300]\ttraining's rmse: 0.0858014\tvalid_1's rmse: 0.0898963\n",
      "[1325]\ttraining's rmse: 0.0857865\tvalid_1's rmse: 0.0898926\n",
      "[1350]\ttraining's rmse: 0.0857694\tvalid_1's rmse: 0.0898897\n",
      "[1375]\ttraining's rmse: 0.0857515\tvalid_1's rmse: 0.0898859\n",
      "[1400]\ttraining's rmse: 0.0857371\tvalid_1's rmse: 0.0898816\n",
      "[1425]\ttraining's rmse: 0.0857194\tvalid_1's rmse: 0.0898784\n",
      "[1450]\ttraining's rmse: 0.0857064\tvalid_1's rmse: 0.0898753\n",
      "[1475]\ttraining's rmse: 0.0856964\tvalid_1's rmse: 0.089872\n",
      "[1500]\ttraining's rmse: 0.0856876\tvalid_1's rmse: 0.0898695\n",
      "[1525]\ttraining's rmse: 0.0856763\tvalid_1's rmse: 0.0898656\n",
      "[1550]\ttraining's rmse: 0.0856644\tvalid_1's rmse: 0.0898633\n",
      "[1575]\ttraining's rmse: 0.0856557\tvalid_1's rmse: 0.0898597\n",
      "[1600]\ttraining's rmse: 0.0856469\tvalid_1's rmse: 0.0898589\n",
      "[1625]\ttraining's rmse: 0.0856381\tvalid_1's rmse: 0.0898553\n",
      "[1650]\ttraining's rmse: 0.0856292\tvalid_1's rmse: 0.0898531\n",
      "[1675]\ttraining's rmse: 0.0856211\tvalid_1's rmse: 0.0898498\n",
      "[1700]\ttraining's rmse: 0.085614\tvalid_1's rmse: 0.0898464\n",
      "[1725]\ttraining's rmse: 0.0856062\tvalid_1's rmse: 0.089845\n",
      "[1750]\ttraining's rmse: 0.0855989\tvalid_1's rmse: 0.0898437\n",
      "[1775]\ttraining's rmse: 0.0855915\tvalid_1's rmse: 0.0898429\n",
      "[1800]\ttraining's rmse: 0.0855856\tvalid_1's rmse: 0.0898408\n",
      "[1825]\ttraining's rmse: 0.0855789\tvalid_1's rmse: 0.0898385\n",
      "[1850]\ttraining's rmse: 0.0855745\tvalid_1's rmse: 0.0898358\n",
      "[1875]\ttraining's rmse: 0.0855673\tvalid_1's rmse: 0.0898338\n",
      "[1900]\ttraining's rmse: 0.0855619\tvalid_1's rmse: 0.0898324\n",
      "[1925]\ttraining's rmse: 0.0855552\tvalid_1's rmse: 0.0898311\n",
      "[1950]\ttraining's rmse: 0.0855512\tvalid_1's rmse: 0.089829\n",
      "[1975]\ttraining's rmse: 0.0855461\tvalid_1's rmse: 0.0898266\n",
      "[2000]\ttraining's rmse: 0.0855407\tvalid_1's rmse: 0.0898245\n",
      "[2025]\ttraining's rmse: 0.0855372\tvalid_1's rmse: 0.0898235\n",
      "[2050]\ttraining's rmse: 0.0855313\tvalid_1's rmse: 0.089822\n",
      "[2075]\ttraining's rmse: 0.0855268\tvalid_1's rmse: 0.089821\n",
      "[2100]\ttraining's rmse: 0.0855227\tvalid_1's rmse: 0.0898198\n",
      "[2125]\ttraining's rmse: 0.0855191\tvalid_1's rmse: 0.0898184\n",
      "[2150]\ttraining's rmse: 0.0855156\tvalid_1's rmse: 0.089818\n",
      "[2175]\ttraining's rmse: 0.0855137\tvalid_1's rmse: 0.0898177\n",
      "[2200]\ttraining's rmse: 0.0855102\tvalid_1's rmse: 0.0898171\n",
      "[2225]\ttraining's rmse: 0.0855075\tvalid_1's rmse: 0.0898163\n",
      "[2250]\ttraining's rmse: 0.0855044\tvalid_1's rmse: 0.0898155\n",
      "[2275]\ttraining's rmse: 0.0855009\tvalid_1's rmse: 0.089814\n",
      "[2300]\ttraining's rmse: 0.0854987\tvalid_1's rmse: 0.0898116\n",
      "[2325]\ttraining's rmse: 0.0854957\tvalid_1's rmse: 0.0898104\n",
      "[2350]\ttraining's rmse: 0.0854931\tvalid_1's rmse: 0.0898095\n",
      "[2375]\ttraining's rmse: 0.0854909\tvalid_1's rmse: 0.0898079\n",
      "[2400]\ttraining's rmse: 0.0854867\tvalid_1's rmse: 0.0898076\n",
      "[2425]\ttraining's rmse: 0.0854833\tvalid_1's rmse: 0.0898068\n",
      "[2450]\ttraining's rmse: 0.0854809\tvalid_1's rmse: 0.0898058\n",
      "[2475]\ttraining's rmse: 0.0854785\tvalid_1's rmse: 0.0898054\n",
      "[2500]\ttraining's rmse: 0.0854767\tvalid_1's rmse: 0.0898051\n",
      "[2525]\ttraining's rmse: 0.0854738\tvalid_1's rmse: 0.0898045\n",
      "[2550]\ttraining's rmse: 0.085472\tvalid_1's rmse: 0.0898038\n",
      "[2575]\ttraining's rmse: 0.0854696\tvalid_1's rmse: 0.0898033\n",
      "[2600]\ttraining's rmse: 0.0854665\tvalid_1's rmse: 0.0898025\n",
      "[2625]\ttraining's rmse: 0.0854638\tvalid_1's rmse: 0.0898006\n",
      "[2650]\ttraining's rmse: 0.085461\tvalid_1's rmse: 0.0897997\n",
      "[2675]\ttraining's rmse: 0.0854597\tvalid_1's rmse: 0.0897992\n",
      "[2700]\ttraining's rmse: 0.0854585\tvalid_1's rmse: 0.0897991\n",
      "[2725]\ttraining's rmse: 0.0854564\tvalid_1's rmse: 0.0897984\n",
      "[2750]\ttraining's rmse: 0.0854531\tvalid_1's rmse: 0.0897972\n",
      "[2775]\ttraining's rmse: 0.0854508\tvalid_1's rmse: 0.0897966\n",
      "[2800]\ttraining's rmse: 0.0854491\tvalid_1's rmse: 0.0897953\n",
      "[2825]\ttraining's rmse: 0.085447\tvalid_1's rmse: 0.0897949\n",
      "[2850]\ttraining's rmse: 0.0854459\tvalid_1's rmse: 0.089795\n",
      "Early stopping, best iteration is:\n",
      "[2815]\ttraining's rmse: 0.0854476\tvalid_1's rmse: 0.0897947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0885255\tvalid_1's rmse: 0.0910678\n",
      "[50]\ttraining's rmse: 0.0883957\tvalid_1's rmse: 0.0910132\n",
      "[75]\ttraining's rmse: 0.088259\tvalid_1's rmse: 0.0909578\n",
      "[100]\ttraining's rmse: 0.088137\tvalid_1's rmse: 0.0909094\n",
      "[125]\ttraining's rmse: 0.0880123\tvalid_1's rmse: 0.0908634\n",
      "[150]\ttraining's rmse: 0.0878984\tvalid_1's rmse: 0.0908182\n",
      "[175]\ttraining's rmse: 0.0878024\tvalid_1's rmse: 0.0907811\n",
      "[200]\ttraining's rmse: 0.0876944\tvalid_1's rmse: 0.0907422\n",
      "[225]\ttraining's rmse: 0.087595\tvalid_1's rmse: 0.090708\n",
      "[250]\ttraining's rmse: 0.0875078\tvalid_1's rmse: 0.0906751\n",
      "[275]\ttraining's rmse: 0.0874311\tvalid_1's rmse: 0.0906467\n",
      "[300]\ttraining's rmse: 0.087353\tvalid_1's rmse: 0.0906178\n",
      "[325]\ttraining's rmse: 0.0872731\tvalid_1's rmse: 0.0905903\n",
      "[350]\ttraining's rmse: 0.0871936\tvalid_1's rmse: 0.090566\n",
      "[375]\ttraining's rmse: 0.0871293\tvalid_1's rmse: 0.0905449\n",
      "[400]\ttraining's rmse: 0.0870586\tvalid_1's rmse: 0.0905242\n",
      "[425]\ttraining's rmse: 0.0869963\tvalid_1's rmse: 0.0905052\n",
      "[450]\ttraining's rmse: 0.0869396\tvalid_1's rmse: 0.0904873\n",
      "[475]\ttraining's rmse: 0.0868846\tvalid_1's rmse: 0.0904688\n",
      "[500]\ttraining's rmse: 0.0868412\tvalid_1's rmse: 0.0904528\n",
      "[525]\ttraining's rmse: 0.086783\tvalid_1's rmse: 0.0904356\n",
      "[550]\ttraining's rmse: 0.0867277\tvalid_1's rmse: 0.0904211\n",
      "[575]\ttraining's rmse: 0.0866778\tvalid_1's rmse: 0.0904063\n",
      "[600]\ttraining's rmse: 0.0866291\tvalid_1's rmse: 0.0903929\n",
      "[625]\ttraining's rmse: 0.0865927\tvalid_1's rmse: 0.0903811\n",
      "[650]\ttraining's rmse: 0.0865444\tvalid_1's rmse: 0.0903697\n",
      "[675]\ttraining's rmse: 0.0864966\tvalid_1's rmse: 0.0903573\n",
      "[700]\ttraining's rmse: 0.0864532\tvalid_1's rmse: 0.0903465\n",
      "[725]\ttraining's rmse: 0.086413\tvalid_1's rmse: 0.0903368\n",
      "[750]\ttraining's rmse: 0.0863775\tvalid_1's rmse: 0.0903287\n",
      "[775]\ttraining's rmse: 0.0863466\tvalid_1's rmse: 0.0903193\n",
      "[800]\ttraining's rmse: 0.0863039\tvalid_1's rmse: 0.090311\n",
      "[825]\ttraining's rmse: 0.0862716\tvalid_1's rmse: 0.0903025\n",
      "[850]\ttraining's rmse: 0.0862376\tvalid_1's rmse: 0.090296\n",
      "[875]\ttraining's rmse: 0.0862104\tvalid_1's rmse: 0.0902902\n",
      "[900]\ttraining's rmse: 0.0861787\tvalid_1's rmse: 0.090283\n",
      "[925]\ttraining's rmse: 0.0861474\tvalid_1's rmse: 0.0902771\n",
      "[950]\ttraining's rmse: 0.0861178\tvalid_1's rmse: 0.0902717\n",
      "[975]\ttraining's rmse: 0.086092\tvalid_1's rmse: 0.0902669\n",
      "[1000]\ttraining's rmse: 0.0860661\tvalid_1's rmse: 0.090262\n",
      "[1025]\ttraining's rmse: 0.0860373\tvalid_1's rmse: 0.0902567\n",
      "[1050]\ttraining's rmse: 0.0860152\tvalid_1's rmse: 0.0902517\n",
      "[1075]\ttraining's rmse: 0.085992\tvalid_1's rmse: 0.0902477\n",
      "[1100]\ttraining's rmse: 0.0859721\tvalid_1's rmse: 0.0902434\n",
      "[1125]\ttraining's rmse: 0.0859505\tvalid_1's rmse: 0.090239\n",
      "[1150]\ttraining's rmse: 0.0859299\tvalid_1's rmse: 0.090236\n",
      "[1175]\ttraining's rmse: 0.085911\tvalid_1's rmse: 0.0902342\n",
      "[1200]\ttraining's rmse: 0.0858931\tvalid_1's rmse: 0.090231\n",
      "[1225]\ttraining's rmse: 0.0858743\tvalid_1's rmse: 0.0902284\n",
      "[1250]\ttraining's rmse: 0.0858575\tvalid_1's rmse: 0.0902256\n",
      "[1275]\ttraining's rmse: 0.0858401\tvalid_1's rmse: 0.0902235\n",
      "[1300]\ttraining's rmse: 0.0858239\tvalid_1's rmse: 0.0902211\n",
      "[1325]\ttraining's rmse: 0.0858082\tvalid_1's rmse: 0.0902191\n",
      "[1350]\ttraining's rmse: 0.0857918\tvalid_1's rmse: 0.0902178\n",
      "[1375]\ttraining's rmse: 0.0857763\tvalid_1's rmse: 0.0902163\n",
      "[1400]\ttraining's rmse: 0.0857645\tvalid_1's rmse: 0.0902141\n",
      "[1425]\ttraining's rmse: 0.0857502\tvalid_1's rmse: 0.0902127\n",
      "[1450]\ttraining's rmse: 0.0857348\tvalid_1's rmse: 0.0902118\n",
      "[1475]\ttraining's rmse: 0.0857218\tvalid_1's rmse: 0.0902101\n",
      "[1500]\ttraining's rmse: 0.0857113\tvalid_1's rmse: 0.0902092\n",
      "[1525]\ttraining's rmse: 0.0857016\tvalid_1's rmse: 0.090208\n",
      "[1550]\ttraining's rmse: 0.0856905\tvalid_1's rmse: 0.0902071\n",
      "[1575]\ttraining's rmse: 0.0856807\tvalid_1's rmse: 0.0902061\n",
      "[1600]\ttraining's rmse: 0.0856716\tvalid_1's rmse: 0.0902052\n",
      "[1625]\ttraining's rmse: 0.0856617\tvalid_1's rmse: 0.0902037\n",
      "[1650]\ttraining's rmse: 0.0856512\tvalid_1's rmse: 0.0902028\n",
      "[1675]\ttraining's rmse: 0.085644\tvalid_1's rmse: 0.0902015\n",
      "[1700]\ttraining's rmse: 0.0856379\tvalid_1's rmse: 0.0902009\n",
      "[1725]\ttraining's rmse: 0.0856314\tvalid_1's rmse: 0.0901998\n",
      "[1750]\ttraining's rmse: 0.0856237\tvalid_1's rmse: 0.0901994\n",
      "[1775]\ttraining's rmse: 0.0856133\tvalid_1's rmse: 0.0901984\n",
      "[1800]\ttraining's rmse: 0.0856071\tvalid_1's rmse: 0.0901979\n",
      "[1825]\ttraining's rmse: 0.0856003\tvalid_1's rmse: 0.0901977\n",
      "[1850]\ttraining's rmse: 0.0855926\tvalid_1's rmse: 0.0901968\n",
      "[1875]\ttraining's rmse: 0.0855867\tvalid_1's rmse: 0.0901961\n",
      "[1900]\ttraining's rmse: 0.0855818\tvalid_1's rmse: 0.0901959\n",
      "[1925]\ttraining's rmse: 0.085575\tvalid_1's rmse: 0.0901956\n",
      "[1950]\ttraining's rmse: 0.0855715\tvalid_1's rmse: 0.0901949\n",
      "[1975]\ttraining's rmse: 0.0855657\tvalid_1's rmse: 0.090194\n",
      "[2000]\ttraining's rmse: 0.0855611\tvalid_1's rmse: 0.0901941\n",
      "[2025]\ttraining's rmse: 0.085557\tvalid_1's rmse: 0.0901934\n",
      "[2050]\ttraining's rmse: 0.0855511\tvalid_1's rmse: 0.090193\n",
      "[2075]\ttraining's rmse: 0.0855468\tvalid_1's rmse: 0.0901923\n",
      "[2100]\ttraining's rmse: 0.0855431\tvalid_1's rmse: 0.0901921\n",
      "[2125]\ttraining's rmse: 0.0855396\tvalid_1's rmse: 0.0901923\n",
      "[2150]\ttraining's rmse: 0.0855358\tvalid_1's rmse: 0.0901921\n",
      "[2175]\ttraining's rmse: 0.0855333\tvalid_1's rmse: 0.090192\n",
      "[2200]\ttraining's rmse: 0.08553\tvalid_1's rmse: 0.0901918\n",
      "[2225]\ttraining's rmse: 0.0855273\tvalid_1's rmse: 0.0901916\n",
      "[2250]\ttraining's rmse: 0.0855233\tvalid_1's rmse: 0.0901916\n",
      "[2275]\ttraining's rmse: 0.0855194\tvalid_1's rmse: 0.0901914\n",
      "[2300]\ttraining's rmse: 0.0855167\tvalid_1's rmse: 0.0901914\n",
      "[2325]\ttraining's rmse: 0.0855136\tvalid_1's rmse: 0.0901915\n",
      "Early stopping, best iteration is:\n",
      "[2287]\ttraining's rmse: 0.085518\tvalid_1's rmse: 0.090191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0907958\tvalid_1's rmse: 0.0864548\n",
      "[50]\ttraining's rmse: 0.0906675\tvalid_1's rmse: 0.0864058\n",
      "[75]\ttraining's rmse: 0.0905332\tvalid_1's rmse: 0.0863576\n",
      "[100]\ttraining's rmse: 0.0904144\tvalid_1's rmse: 0.0863169\n",
      "[125]\ttraining's rmse: 0.0902901\tvalid_1's rmse: 0.0862747\n",
      "[150]\ttraining's rmse: 0.0901773\tvalid_1's rmse: 0.0862364\n",
      "[175]\ttraining's rmse: 0.0900809\tvalid_1's rmse: 0.0862038\n",
      "[200]\ttraining's rmse: 0.0899765\tvalid_1's rmse: 0.0861718\n",
      "[225]\ttraining's rmse: 0.0898761\tvalid_1's rmse: 0.0861408\n",
      "[250]\ttraining's rmse: 0.0897906\tvalid_1's rmse: 0.0861125\n",
      "[275]\ttraining's rmse: 0.0897129\tvalid_1's rmse: 0.0860884\n",
      "[300]\ttraining's rmse: 0.0896365\tvalid_1's rmse: 0.0860653\n",
      "[325]\ttraining's rmse: 0.0895581\tvalid_1's rmse: 0.0860428\n",
      "[350]\ttraining's rmse: 0.0894809\tvalid_1's rmse: 0.0860213\n",
      "[375]\ttraining's rmse: 0.0894181\tvalid_1's rmse: 0.0860115\n",
      "[400]\ttraining's rmse: 0.0893518\tvalid_1's rmse: 0.0860005\n",
      "[425]\ttraining's rmse: 0.08929\tvalid_1's rmse: 0.0859838\n",
      "[450]\ttraining's rmse: 0.0892318\tvalid_1's rmse: 0.0859664\n",
      "[475]\ttraining's rmse: 0.0891755\tvalid_1's rmse: 0.0859514\n",
      "[500]\ttraining's rmse: 0.0891301\tvalid_1's rmse: 0.0859427\n",
      "[525]\ttraining's rmse: 0.0890714\tvalid_1's rmse: 0.085935\n",
      "[550]\ttraining's rmse: 0.0890188\tvalid_1's rmse: 0.0859222\n",
      "[575]\ttraining's rmse: 0.0889684\tvalid_1's rmse: 0.0859155\n",
      "[600]\ttraining's rmse: 0.0889194\tvalid_1's rmse: 0.0859067\n",
      "[625]\ttraining's rmse: 0.0888795\tvalid_1's rmse: 0.0859044\n",
      "[650]\ttraining's rmse: 0.0888307\tvalid_1's rmse: 0.0858989\n",
      "[675]\ttraining's rmse: 0.0887828\tvalid_1's rmse: 0.0858931\n",
      "[700]\ttraining's rmse: 0.088741\tvalid_1's rmse: 0.0858848\n",
      "[725]\ttraining's rmse: 0.0886993\tvalid_1's rmse: 0.0858858\n",
      "[750]\ttraining's rmse: 0.0886605\tvalid_1's rmse: 0.0858909\n",
      "[775]\ttraining's rmse: 0.0886284\tvalid_1's rmse: 0.0858938\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0886821\tvalid_1's rmse: 0.085882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0868627\tvalid_1's rmse: 0.0895528\n",
      "[50]\ttraining's rmse: 0.0867263\tvalid_1's rmse: 0.089497\n",
      "[75]\ttraining's rmse: 0.0865907\tvalid_1's rmse: 0.0894415\n",
      "[100]\ttraining's rmse: 0.0864651\tvalid_1's rmse: 0.0893973\n",
      "[125]\ttraining's rmse: 0.0863389\tvalid_1's rmse: 0.0893515\n",
      "[150]\ttraining's rmse: 0.086224\tvalid_1's rmse: 0.0893056\n",
      "[175]\ttraining's rmse: 0.0861268\tvalid_1's rmse: 0.0892656\n",
      "[200]\ttraining's rmse: 0.0860273\tvalid_1's rmse: 0.089229\n",
      "[225]\ttraining's rmse: 0.0859312\tvalid_1's rmse: 0.0891951\n",
      "[250]\ttraining's rmse: 0.0858486\tvalid_1's rmse: 0.0891607\n",
      "[275]\ttraining's rmse: 0.0857687\tvalid_1's rmse: 0.0891329\n",
      "[300]\ttraining's rmse: 0.0856912\tvalid_1's rmse: 0.0891042\n",
      "[325]\ttraining's rmse: 0.0856148\tvalid_1's rmse: 0.0890783\n",
      "[350]\ttraining's rmse: 0.0855446\tvalid_1's rmse: 0.0890521\n",
      "[375]\ttraining's rmse: 0.0854831\tvalid_1's rmse: 0.0890304\n",
      "[400]\ttraining's rmse: 0.0854185\tvalid_1's rmse: 0.089009\n",
      "[425]\ttraining's rmse: 0.0853563\tvalid_1's rmse: 0.088987\n",
      "[450]\ttraining's rmse: 0.0852959\tvalid_1's rmse: 0.088967\n",
      "[475]\ttraining's rmse: 0.0852455\tvalid_1's rmse: 0.08895\n",
      "[500]\ttraining's rmse: 0.0852023\tvalid_1's rmse: 0.0889337\n",
      "[525]\ttraining's rmse: 0.0851502\tvalid_1's rmse: 0.0889178\n",
      "[550]\ttraining's rmse: 0.0850993\tvalid_1's rmse: 0.0889018\n",
      "[575]\ttraining's rmse: 0.0850487\tvalid_1's rmse: 0.0888879\n",
      "[600]\ttraining's rmse: 0.085004\tvalid_1's rmse: 0.0888739\n",
      "[625]\ttraining's rmse: 0.0849669\tvalid_1's rmse: 0.0888623\n",
      "[650]\ttraining's rmse: 0.0849213\tvalid_1's rmse: 0.0888498\n",
      "[675]\ttraining's rmse: 0.084877\tvalid_1's rmse: 0.0888369\n",
      "[700]\ttraining's rmse: 0.0848361\tvalid_1's rmse: 0.0888247\n",
      "[725]\ttraining's rmse: 0.0847972\tvalid_1's rmse: 0.0888143\n",
      "[750]\ttraining's rmse: 0.0847631\tvalid_1's rmse: 0.0888045\n",
      "[775]\ttraining's rmse: 0.0847362\tvalid_1's rmse: 0.0887947\n",
      "[800]\ttraining's rmse: 0.0847036\tvalid_1's rmse: 0.0887859\n",
      "[825]\ttraining's rmse: 0.0846757\tvalid_1's rmse: 0.0887766\n",
      "[850]\ttraining's rmse: 0.0846435\tvalid_1's rmse: 0.0887688\n",
      "[875]\ttraining's rmse: 0.0846185\tvalid_1's rmse: 0.088761\n",
      "[900]\ttraining's rmse: 0.0845887\tvalid_1's rmse: 0.0887519\n",
      "[925]\ttraining's rmse: 0.0845619\tvalid_1's rmse: 0.0887442\n",
      "[950]\ttraining's rmse: 0.0845362\tvalid_1's rmse: 0.0887369\n",
      "[975]\ttraining's rmse: 0.084514\tvalid_1's rmse: 0.0887299\n",
      "[1000]\ttraining's rmse: 0.0844878\tvalid_1's rmse: 0.0887235\n",
      "[1025]\ttraining's rmse: 0.0844642\tvalid_1's rmse: 0.0887186\n",
      "[1050]\ttraining's rmse: 0.0844443\tvalid_1's rmse: 0.0887109\n",
      "[1075]\ttraining's rmse: 0.0844224\tvalid_1's rmse: 0.0887074\n",
      "[1100]\ttraining's rmse: 0.0844043\tvalid_1's rmse: 0.0887018\n",
      "[1125]\ttraining's rmse: 0.0843874\tvalid_1's rmse: 0.0886961\n",
      "[1150]\ttraining's rmse: 0.0843678\tvalid_1's rmse: 0.088692\n",
      "[1175]\ttraining's rmse: 0.084352\tvalid_1's rmse: 0.0886881\n",
      "[1200]\ttraining's rmse: 0.0843331\tvalid_1's rmse: 0.0886832\n",
      "[1225]\ttraining's rmse: 0.0843161\tvalid_1's rmse: 0.0886781\n",
      "[1250]\ttraining's rmse: 0.084302\tvalid_1's rmse: 0.0886739\n",
      "[1275]\ttraining's rmse: 0.0842824\tvalid_1's rmse: 0.0886697\n",
      "[1300]\ttraining's rmse: 0.0842685\tvalid_1's rmse: 0.0886643\n",
      "[1325]\ttraining's rmse: 0.0842529\tvalid_1's rmse: 0.0886603\n",
      "[1350]\ttraining's rmse: 0.0842384\tvalid_1's rmse: 0.0886581\n",
      "[1375]\ttraining's rmse: 0.0842231\tvalid_1's rmse: 0.0886552\n",
      "[1400]\ttraining's rmse: 0.0842122\tvalid_1's rmse: 0.0886519\n",
      "[1425]\ttraining's rmse: 0.0841985\tvalid_1's rmse: 0.0886496\n",
      "[1450]\ttraining's rmse: 0.0841842\tvalid_1's rmse: 0.0886465\n",
      "[1475]\ttraining's rmse: 0.0841745\tvalid_1's rmse: 0.0886418\n",
      "[1500]\ttraining's rmse: 0.084164\tvalid_1's rmse: 0.0886398\n",
      "[1525]\ttraining's rmse: 0.0841529\tvalid_1's rmse: 0.0886382\n",
      "[1550]\ttraining's rmse: 0.0841424\tvalid_1's rmse: 0.0886354\n",
      "[1575]\ttraining's rmse: 0.0841346\tvalid_1's rmse: 0.0886337\n",
      "[1600]\ttraining's rmse: 0.0841256\tvalid_1's rmse: 0.0886308\n",
      "[1625]\ttraining's rmse: 0.0841163\tvalid_1's rmse: 0.088628\n",
      "[1650]\ttraining's rmse: 0.0841074\tvalid_1's rmse: 0.0886257\n",
      "[1675]\ttraining's rmse: 0.0841014\tvalid_1's rmse: 0.0886234\n",
      "[1700]\ttraining's rmse: 0.0840958\tvalid_1's rmse: 0.0886212\n",
      "[1725]\ttraining's rmse: 0.084089\tvalid_1's rmse: 0.0886197\n",
      "[1750]\ttraining's rmse: 0.0840819\tvalid_1's rmse: 0.088617\n",
      "[1775]\ttraining's rmse: 0.0840742\tvalid_1's rmse: 0.088615\n",
      "[1800]\ttraining's rmse: 0.0840677\tvalid_1's rmse: 0.0886113\n",
      "[1825]\ttraining's rmse: 0.0840622\tvalid_1's rmse: 0.08861\n",
      "[1850]\ttraining's rmse: 0.0840571\tvalid_1's rmse: 0.0886085\n",
      "[1875]\ttraining's rmse: 0.0840505\tvalid_1's rmse: 0.0886066\n",
      "[1900]\ttraining's rmse: 0.0840452\tvalid_1's rmse: 0.0886049\n",
      "[1925]\ttraining's rmse: 0.0840389\tvalid_1's rmse: 0.0886036\n",
      "[1950]\ttraining's rmse: 0.0840351\tvalid_1's rmse: 0.088602\n",
      "[1975]\ttraining's rmse: 0.0840301\tvalid_1's rmse: 0.0886008\n",
      "[2000]\ttraining's rmse: 0.0840256\tvalid_1's rmse: 0.0886005\n",
      "[2025]\ttraining's rmse: 0.0840208\tvalid_1's rmse: 0.088599\n",
      "[2050]\ttraining's rmse: 0.0840155\tvalid_1's rmse: 0.0885969\n",
      "[2075]\ttraining's rmse: 0.0840125\tvalid_1's rmse: 0.088596\n",
      "[2100]\ttraining's rmse: 0.084007\tvalid_1's rmse: 0.0885952\n",
      "[2125]\ttraining's rmse: 0.0840038\tvalid_1's rmse: 0.0885945\n",
      "[2150]\ttraining's rmse: 0.0840007\tvalid_1's rmse: 0.0885935\n",
      "[2175]\ttraining's rmse: 0.083998\tvalid_1's rmse: 0.0885924\n",
      "[2200]\ttraining's rmse: 0.0839949\tvalid_1's rmse: 0.0885921\n",
      "[2225]\ttraining's rmse: 0.0839914\tvalid_1's rmse: 0.0885903\n",
      "[2250]\ttraining's rmse: 0.0839887\tvalid_1's rmse: 0.0885898\n",
      "[2275]\ttraining's rmse: 0.0839854\tvalid_1's rmse: 0.088589\n",
      "[2300]\ttraining's rmse: 0.0839823\tvalid_1's rmse: 0.0885881\n",
      "[2325]\ttraining's rmse: 0.0839783\tvalid_1's rmse: 0.0885855\n",
      "[2350]\ttraining's rmse: 0.0839764\tvalid_1's rmse: 0.0885855\n",
      "[2375]\ttraining's rmse: 0.083973\tvalid_1's rmse: 0.0885851\n",
      "[2400]\ttraining's rmse: 0.0839708\tvalid_1's rmse: 0.0885846\n",
      "[2425]\ttraining's rmse: 0.0839671\tvalid_1's rmse: 0.0885839\n",
      "[2450]\ttraining's rmse: 0.0839658\tvalid_1's rmse: 0.0885838\n",
      "[2475]\ttraining's rmse: 0.0839627\tvalid_1's rmse: 0.0885837\n",
      "[2500]\ttraining's rmse: 0.0839593\tvalid_1's rmse: 0.0885836\n",
      "[2525]\ttraining's rmse: 0.0839555\tvalid_1's rmse: 0.0885833\n",
      "[2550]\ttraining's rmse: 0.0839528\tvalid_1's rmse: 0.0885823\n",
      "[2575]\ttraining's rmse: 0.0839499\tvalid_1's rmse: 0.0885814\n",
      "[2600]\ttraining's rmse: 0.0839477\tvalid_1's rmse: 0.0885813\n",
      "[2625]\ttraining's rmse: 0.083946\tvalid_1's rmse: 0.0885807\n",
      "[2650]\ttraining's rmse: 0.0839437\tvalid_1's rmse: 0.08858\n",
      "[2675]\ttraining's rmse: 0.083941\tvalid_1's rmse: 0.0885794\n",
      "[2700]\ttraining's rmse: 0.0839386\tvalid_1's rmse: 0.0885788\n",
      "[2725]\ttraining's rmse: 0.0839373\tvalid_1's rmse: 0.0885787\n",
      "[2750]\ttraining's rmse: 0.0839351\tvalid_1's rmse: 0.0885788\n",
      "[2775]\ttraining's rmse: 0.0839321\tvalid_1's rmse: 0.0885784\n",
      "[2800]\ttraining's rmse: 0.0839299\tvalid_1's rmse: 0.0885778\n",
      "[2825]\ttraining's rmse: 0.0839285\tvalid_1's rmse: 0.088577\n",
      "[2850]\ttraining's rmse: 0.0839277\tvalid_1's rmse: 0.0885771\n",
      "[2875]\ttraining's rmse: 0.0839249\tvalid_1's rmse: 0.0885769\n",
      "[2900]\ttraining's rmse: 0.0839226\tvalid_1's rmse: 0.0885768\n",
      "[2925]\ttraining's rmse: 0.0839207\tvalid_1's rmse: 0.0885761\n",
      "[2950]\ttraining's rmse: 0.0839195\tvalid_1's rmse: 0.0885762\n",
      "[2975]\ttraining's rmse: 0.0839176\tvalid_1's rmse: 0.0885759\n",
      "[3000]\ttraining's rmse: 0.0839155\tvalid_1's rmse: 0.0885754\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0839155\tvalid_1's rmse: 0.0885754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0869711\tvalid_1's rmse: 0.0893457\n",
      "[50]\ttraining's rmse: 0.0868426\tvalid_1's rmse: 0.089289\n",
      "[75]\ttraining's rmse: 0.0867128\tvalid_1's rmse: 0.089235\n",
      "[100]\ttraining's rmse: 0.0865968\tvalid_1's rmse: 0.0891871\n",
      "[125]\ttraining's rmse: 0.086476\tvalid_1's rmse: 0.0891397\n",
      "[150]\ttraining's rmse: 0.0863677\tvalid_1's rmse: 0.0890948\n",
      "[175]\ttraining's rmse: 0.0862764\tvalid_1's rmse: 0.0890578\n",
      "[200]\ttraining's rmse: 0.0861751\tvalid_1's rmse: 0.0890212\n",
      "[225]\ttraining's rmse: 0.0860814\tvalid_1's rmse: 0.0889867\n",
      "[250]\ttraining's rmse: 0.0859991\tvalid_1's rmse: 0.0889571\n",
      "[275]\ttraining's rmse: 0.0859265\tvalid_1's rmse: 0.0889282\n",
      "[300]\ttraining's rmse: 0.0858536\tvalid_1's rmse: 0.0889009\n",
      "[325]\ttraining's rmse: 0.0857781\tvalid_1's rmse: 0.088874\n",
      "[350]\ttraining's rmse: 0.0857056\tvalid_1's rmse: 0.0888497\n",
      "[375]\ttraining's rmse: 0.0856456\tvalid_1's rmse: 0.0888277\n",
      "[400]\ttraining's rmse: 0.0855797\tvalid_1's rmse: 0.0888065\n",
      "[425]\ttraining's rmse: 0.0855186\tvalid_1's rmse: 0.0887865\n",
      "[450]\ttraining's rmse: 0.0854631\tvalid_1's rmse: 0.088768\n",
      "[475]\ttraining's rmse: 0.0854097\tvalid_1's rmse: 0.08875\n",
      "[500]\ttraining's rmse: 0.0853685\tvalid_1's rmse: 0.0887348\n",
      "[525]\ttraining's rmse: 0.0853123\tvalid_1's rmse: 0.0887185\n",
      "[550]\ttraining's rmse: 0.0852608\tvalid_1's rmse: 0.0887033\n",
      "[575]\ttraining's rmse: 0.0852133\tvalid_1's rmse: 0.0886891\n",
      "[600]\ttraining's rmse: 0.0851649\tvalid_1's rmse: 0.0886754\n",
      "[625]\ttraining's rmse: 0.0851287\tvalid_1's rmse: 0.0886641\n",
      "[650]\ttraining's rmse: 0.0850807\tvalid_1's rmse: 0.0886511\n",
      "[675]\ttraining's rmse: 0.0850346\tvalid_1's rmse: 0.0886402\n",
      "[700]\ttraining's rmse: 0.0849961\tvalid_1's rmse: 0.0886292\n",
      "[725]\ttraining's rmse: 0.0849581\tvalid_1's rmse: 0.0886199\n",
      "[750]\ttraining's rmse: 0.084924\tvalid_1's rmse: 0.088611\n",
      "[775]\ttraining's rmse: 0.0848942\tvalid_1's rmse: 0.0886017\n",
      "[800]\ttraining's rmse: 0.084858\tvalid_1's rmse: 0.0885938\n",
      "[825]\ttraining's rmse: 0.0848264\tvalid_1's rmse: 0.0885862\n",
      "[850]\ttraining's rmse: 0.0847961\tvalid_1's rmse: 0.0885798\n",
      "[875]\ttraining's rmse: 0.08477\tvalid_1's rmse: 0.0885735\n",
      "[900]\ttraining's rmse: 0.0847391\tvalid_1's rmse: 0.0885666\n",
      "[925]\ttraining's rmse: 0.0847105\tvalid_1's rmse: 0.0885609\n",
      "[950]\ttraining's rmse: 0.0846844\tvalid_1's rmse: 0.0885551\n",
      "[975]\ttraining's rmse: 0.0846607\tvalid_1's rmse: 0.0885494\n",
      "[1000]\ttraining's rmse: 0.0846381\tvalid_1's rmse: 0.0885439\n",
      "[1025]\ttraining's rmse: 0.0846141\tvalid_1's rmse: 0.0885393\n",
      "[1050]\ttraining's rmse: 0.0845922\tvalid_1's rmse: 0.088534\n",
      "[1075]\ttraining's rmse: 0.0845699\tvalid_1's rmse: 0.0885299\n",
      "[1100]\ttraining's rmse: 0.0845534\tvalid_1's rmse: 0.0885261\n",
      "[1125]\ttraining's rmse: 0.084534\tvalid_1's rmse: 0.0885234\n",
      "[1150]\ttraining's rmse: 0.0845149\tvalid_1's rmse: 0.0885202\n",
      "[1175]\ttraining's rmse: 0.0844995\tvalid_1's rmse: 0.0885175\n",
      "[1200]\ttraining's rmse: 0.0844816\tvalid_1's rmse: 0.0885143\n",
      "[1225]\ttraining's rmse: 0.0844644\tvalid_1's rmse: 0.0885116\n",
      "[1250]\ttraining's rmse: 0.0844508\tvalid_1's rmse: 0.0885096\n",
      "[1275]\ttraining's rmse: 0.0844321\tvalid_1's rmse: 0.0885071\n",
      "[1300]\ttraining's rmse: 0.0844198\tvalid_1's rmse: 0.0885048\n",
      "[1325]\ttraining's rmse: 0.084407\tvalid_1's rmse: 0.0885027\n",
      "[1350]\ttraining's rmse: 0.0843927\tvalid_1's rmse: 0.0885009\n",
      "[1375]\ttraining's rmse: 0.0843783\tvalid_1's rmse: 0.088499\n",
      "[1400]\ttraining's rmse: 0.0843672\tvalid_1's rmse: 0.0884968\n",
      "[1425]\ttraining's rmse: 0.0843555\tvalid_1's rmse: 0.0884953\n",
      "[1450]\ttraining's rmse: 0.0843413\tvalid_1's rmse: 0.0884935\n",
      "[1475]\ttraining's rmse: 0.0843315\tvalid_1's rmse: 0.0884915\n",
      "[1500]\ttraining's rmse: 0.0843228\tvalid_1's rmse: 0.0884896\n",
      "[1525]\ttraining's rmse: 0.0843108\tvalid_1's rmse: 0.0884879\n",
      "[1550]\ttraining's rmse: 0.0842986\tvalid_1's rmse: 0.088487\n",
      "[1575]\ttraining's rmse: 0.0842882\tvalid_1's rmse: 0.0884852\n",
      "[1600]\ttraining's rmse: 0.0842819\tvalid_1's rmse: 0.0884845\n",
      "[1625]\ttraining's rmse: 0.0842731\tvalid_1's rmse: 0.0884828\n",
      "[1650]\ttraining's rmse: 0.0842653\tvalid_1's rmse: 0.0884819\n",
      "[1675]\ttraining's rmse: 0.0842599\tvalid_1's rmse: 0.0884815\n",
      "[1700]\ttraining's rmse: 0.0842534\tvalid_1's rmse: 0.0884803\n",
      "[1725]\ttraining's rmse: 0.0842476\tvalid_1's rmse: 0.0884792\n",
      "[1750]\ttraining's rmse: 0.0842401\tvalid_1's rmse: 0.0884787\n",
      "[1775]\ttraining's rmse: 0.0842324\tvalid_1's rmse: 0.0884786\n",
      "[1800]\ttraining's rmse: 0.0842225\tvalid_1's rmse: 0.0884775\n",
      "[1825]\ttraining's rmse: 0.0842148\tvalid_1's rmse: 0.0884768\n",
      "[1850]\ttraining's rmse: 0.0842075\tvalid_1's rmse: 0.0884756\n",
      "[1875]\ttraining's rmse: 0.0842023\tvalid_1's rmse: 0.0884752\n",
      "[1900]\ttraining's rmse: 0.0841966\tvalid_1's rmse: 0.0884747\n",
      "[1925]\ttraining's rmse: 0.0841916\tvalid_1's rmse: 0.0884746\n",
      "[1950]\ttraining's rmse: 0.0841873\tvalid_1's rmse: 0.0884737\n",
      "[1975]\ttraining's rmse: 0.0841828\tvalid_1's rmse: 0.0884729\n",
      "[2000]\ttraining's rmse: 0.0841769\tvalid_1's rmse: 0.0884722\n",
      "[2025]\ttraining's rmse: 0.084173\tvalid_1's rmse: 0.0884712\n",
      "[2050]\ttraining's rmse: 0.0841684\tvalid_1's rmse: 0.0884712\n",
      "[2075]\ttraining's rmse: 0.0841655\tvalid_1's rmse: 0.0884709\n",
      "[2100]\ttraining's rmse: 0.084162\tvalid_1's rmse: 0.0884701\n",
      "[2125]\ttraining's rmse: 0.0841586\tvalid_1's rmse: 0.08847\n",
      "[2150]\ttraining's rmse: 0.0841558\tvalid_1's rmse: 0.0884695\n",
      "[2175]\ttraining's rmse: 0.0841533\tvalid_1's rmse: 0.0884693\n",
      "[2200]\ttraining's rmse: 0.0841496\tvalid_1's rmse: 0.0884688\n",
      "[2225]\ttraining's rmse: 0.0841451\tvalid_1's rmse: 0.0884685\n",
      "[2250]\ttraining's rmse: 0.0841427\tvalid_1's rmse: 0.0884683\n",
      "[2275]\ttraining's rmse: 0.084139\tvalid_1's rmse: 0.088468\n",
      "[2300]\ttraining's rmse: 0.0841362\tvalid_1's rmse: 0.0884683\n",
      "[2325]\ttraining's rmse: 0.0841331\tvalid_1's rmse: 0.0884681\n",
      "[2350]\ttraining's rmse: 0.0841301\tvalid_1's rmse: 0.0884674\n",
      "[2375]\ttraining's rmse: 0.0841258\tvalid_1's rmse: 0.0884671\n",
      "[2400]\ttraining's rmse: 0.0841218\tvalid_1's rmse: 0.0884667\n",
      "[2425]\ttraining's rmse: 0.0841194\tvalid_1's rmse: 0.0884665\n",
      "[2450]\ttraining's rmse: 0.0841179\tvalid_1's rmse: 0.0884665\n",
      "Early stopping, best iteration is:\n",
      "[2419]\ttraining's rmse: 0.0841204\tvalid_1's rmse: 0.0884663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0893247\tvalid_1's rmse: 0.0845716\n",
      "[50]\ttraining's rmse: 0.0892091\tvalid_1's rmse: 0.0845225\n",
      "[75]\ttraining's rmse: 0.0890865\tvalid_1's rmse: 0.0844767\n",
      "[100]\ttraining's rmse: 0.0889764\tvalid_1's rmse: 0.0844351\n",
      "[125]\ttraining's rmse: 0.0888636\tvalid_1's rmse: 0.0843929\n",
      "[150]\ttraining's rmse: 0.0887628\tvalid_1's rmse: 0.0843582\n",
      "[175]\ttraining's rmse: 0.0886765\tvalid_1's rmse: 0.0843306\n",
      "[200]\ttraining's rmse: 0.088585\tvalid_1's rmse: 0.0842994\n",
      "[225]\ttraining's rmse: 0.0884957\tvalid_1's rmse: 0.0842692\n",
      "[250]\ttraining's rmse: 0.0884181\tvalid_1's rmse: 0.084243\n",
      "[275]\ttraining's rmse: 0.0883471\tvalid_1's rmse: 0.0842181\n",
      "[300]\ttraining's rmse: 0.0882782\tvalid_1's rmse: 0.0841948\n",
      "[325]\ttraining's rmse: 0.0882088\tvalid_1's rmse: 0.0841724\n",
      "[350]\ttraining's rmse: 0.0881405\tvalid_1's rmse: 0.0841518\n",
      "[375]\ttraining's rmse: 0.0880837\tvalid_1's rmse: 0.084133\n",
      "[400]\ttraining's rmse: 0.0880224\tvalid_1's rmse: 0.0841246\n",
      "[425]\ttraining's rmse: 0.0879656\tvalid_1's rmse: 0.0841085\n",
      "[450]\ttraining's rmse: 0.0879142\tvalid_1's rmse: 0.084094\n",
      "[475]\ttraining's rmse: 0.0878644\tvalid_1's rmse: 0.0840806\n",
      "[500]\ttraining's rmse: 0.087823\tvalid_1's rmse: 0.0840674\n",
      "[525]\ttraining's rmse: 0.087767\tvalid_1's rmse: 0.0840561\n",
      "[550]\ttraining's rmse: 0.0877157\tvalid_1's rmse: 0.0840433\n",
      "[575]\ttraining's rmse: 0.0876706\tvalid_1's rmse: 0.0840333\n",
      "[600]\ttraining's rmse: 0.087625\tvalid_1's rmse: 0.0840235\n",
      "[625]\ttraining's rmse: 0.0875885\tvalid_1's rmse: 0.0840184\n",
      "[650]\ttraining's rmse: 0.0875433\tvalid_1's rmse: 0.0840135\n",
      "[675]\ttraining's rmse: 0.0874984\tvalid_1's rmse: 0.084015\n",
      "Early stopping, best iteration is:\n",
      "[643]\ttraining's rmse: 0.0875582\tvalid_1's rmse: 0.0840109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0897481\tvalid_1's rmse: 0.0914792\n",
      "[50]\ttraining's rmse: 0.08956\tvalid_1's rmse: 0.0914253\n",
      "[75]\ttraining's rmse: 0.089374\tvalid_1's rmse: 0.0913709\n",
      "[100]\ttraining's rmse: 0.0892088\tvalid_1's rmse: 0.0913247\n",
      "[125]\ttraining's rmse: 0.0890431\tvalid_1's rmse: 0.0912782\n",
      "[150]\ttraining's rmse: 0.0888917\tvalid_1's rmse: 0.0912351\n",
      "[175]\ttraining's rmse: 0.0887671\tvalid_1's rmse: 0.0911987\n",
      "[200]\ttraining's rmse: 0.0886295\tvalid_1's rmse: 0.09116\n",
      "[225]\ttraining's rmse: 0.0885037\tvalid_1's rmse: 0.0911244\n",
      "[250]\ttraining's rmse: 0.0883914\tvalid_1's rmse: 0.0910919\n",
      "[275]\ttraining's rmse: 0.0882876\tvalid_1's rmse: 0.0910637\n",
      "[300]\ttraining's rmse: 0.0881857\tvalid_1's rmse: 0.0910349\n",
      "[325]\ttraining's rmse: 0.0880845\tvalid_1's rmse: 0.0910075\n",
      "[350]\ttraining's rmse: 0.0879907\tvalid_1's rmse: 0.0909806\n",
      "[375]\ttraining's rmse: 0.0879092\tvalid_1's rmse: 0.0909582\n",
      "[400]\ttraining's rmse: 0.0878236\tvalid_1's rmse: 0.0909351\n",
      "[425]\ttraining's rmse: 0.0877459\tvalid_1's rmse: 0.0909147\n",
      "[450]\ttraining's rmse: 0.0876723\tvalid_1's rmse: 0.0908931\n",
      "[475]\ttraining's rmse: 0.0876075\tvalid_1's rmse: 0.0908741\n",
      "[500]\ttraining's rmse: 0.08755\tvalid_1's rmse: 0.0908582\n",
      "[525]\ttraining's rmse: 0.0874817\tvalid_1's rmse: 0.0908377\n",
      "[550]\ttraining's rmse: 0.0874215\tvalid_1's rmse: 0.090822\n",
      "[575]\ttraining's rmse: 0.0873646\tvalid_1's rmse: 0.0908076\n",
      "[600]\ttraining's rmse: 0.0873072\tvalid_1's rmse: 0.0907931\n",
      "[625]\ttraining's rmse: 0.0872591\tvalid_1's rmse: 0.0907789\n",
      "[650]\ttraining's rmse: 0.0872073\tvalid_1's rmse: 0.0907637\n",
      "[675]\ttraining's rmse: 0.0871559\tvalid_1's rmse: 0.0907515\n",
      "[700]\ttraining's rmse: 0.0871099\tvalid_1's rmse: 0.0907391\n",
      "[725]\ttraining's rmse: 0.0870675\tvalid_1's rmse: 0.090729\n",
      "[750]\ttraining's rmse: 0.0870294\tvalid_1's rmse: 0.0907192\n",
      "[775]\ttraining's rmse: 0.0869959\tvalid_1's rmse: 0.0907093\n",
      "[800]\ttraining's rmse: 0.0869538\tvalid_1's rmse: 0.0906997\n",
      "[825]\ttraining's rmse: 0.086918\tvalid_1's rmse: 0.0906903\n",
      "[850]\ttraining's rmse: 0.0868787\tvalid_1's rmse: 0.0906824\n",
      "[875]\ttraining's rmse: 0.0868474\tvalid_1's rmse: 0.0906739\n",
      "[900]\ttraining's rmse: 0.0868139\tvalid_1's rmse: 0.0906659\n",
      "[925]\ttraining's rmse: 0.0867835\tvalid_1's rmse: 0.0906593\n",
      "[950]\ttraining's rmse: 0.0867546\tvalid_1's rmse: 0.0906518\n",
      "[975]\ttraining's rmse: 0.0867249\tvalid_1's rmse: 0.0906436\n",
      "[1000]\ttraining's rmse: 0.086696\tvalid_1's rmse: 0.0906364\n",
      "[1025]\ttraining's rmse: 0.0866675\tvalid_1's rmse: 0.0906294\n",
      "[1050]\ttraining's rmse: 0.0866414\tvalid_1's rmse: 0.0906219\n",
      "[1075]\ttraining's rmse: 0.086615\tvalid_1's rmse: 0.0906154\n",
      "[1100]\ttraining's rmse: 0.08659\tvalid_1's rmse: 0.0906096\n",
      "[1125]\ttraining's rmse: 0.0865658\tvalid_1's rmse: 0.090604\n",
      "[1150]\ttraining's rmse: 0.0865427\tvalid_1's rmse: 0.0905978\n",
      "[1175]\ttraining's rmse: 0.0865211\tvalid_1's rmse: 0.0905938\n",
      "[1200]\ttraining's rmse: 0.0865041\tvalid_1's rmse: 0.0905882\n",
      "[1225]\ttraining's rmse: 0.0864864\tvalid_1's rmse: 0.0905829\n",
      "[1250]\ttraining's rmse: 0.0864695\tvalid_1's rmse: 0.0905781\n",
      "[1275]\ttraining's rmse: 0.0864502\tvalid_1's rmse: 0.0905735\n",
      "[1300]\ttraining's rmse: 0.0864359\tvalid_1's rmse: 0.0905689\n",
      "[1325]\ttraining's rmse: 0.0864202\tvalid_1's rmse: 0.0905657\n",
      "[1350]\ttraining's rmse: 0.086402\tvalid_1's rmse: 0.0905607\n",
      "[1375]\ttraining's rmse: 0.0863851\tvalid_1's rmse: 0.0905564\n",
      "[1400]\ttraining's rmse: 0.0863721\tvalid_1's rmse: 0.0905527\n",
      "[1425]\ttraining's rmse: 0.0863569\tvalid_1's rmse: 0.0905491\n",
      "[1450]\ttraining's rmse: 0.0863413\tvalid_1's rmse: 0.0905459\n",
      "[1475]\ttraining's rmse: 0.0863284\tvalid_1's rmse: 0.0905423\n",
      "[1500]\ttraining's rmse: 0.0863189\tvalid_1's rmse: 0.0905403\n",
      "[1525]\ttraining's rmse: 0.0863079\tvalid_1's rmse: 0.0905366\n",
      "[1550]\ttraining's rmse: 0.086296\tvalid_1's rmse: 0.0905348\n",
      "[1575]\ttraining's rmse: 0.0862856\tvalid_1's rmse: 0.0905317\n",
      "[1600]\ttraining's rmse: 0.0862774\tvalid_1's rmse: 0.0905297\n",
      "[1625]\ttraining's rmse: 0.0862697\tvalid_1's rmse: 0.0905265\n",
      "[1650]\ttraining's rmse: 0.0862622\tvalid_1's rmse: 0.0905225\n",
      "[1675]\ttraining's rmse: 0.0862527\tvalid_1's rmse: 0.09052\n",
      "[1700]\ttraining's rmse: 0.0862425\tvalid_1's rmse: 0.0905173\n",
      "[1725]\ttraining's rmse: 0.0862345\tvalid_1's rmse: 0.0905159\n",
      "[1750]\ttraining's rmse: 0.0862254\tvalid_1's rmse: 0.0905137\n",
      "[1775]\ttraining's rmse: 0.0862142\tvalid_1's rmse: 0.0905114\n",
      "[1800]\ttraining's rmse: 0.0862069\tvalid_1's rmse: 0.0905087\n",
      "[1825]\ttraining's rmse: 0.0862011\tvalid_1's rmse: 0.0905056\n",
      "[1850]\ttraining's rmse: 0.0861939\tvalid_1's rmse: 0.0905033\n",
      "[1875]\ttraining's rmse: 0.0861873\tvalid_1's rmse: 0.0905024\n",
      "[1900]\ttraining's rmse: 0.086183\tvalid_1's rmse: 0.0905019\n",
      "[1925]\ttraining's rmse: 0.0861771\tvalid_1's rmse: 0.0905006\n",
      "[1950]\ttraining's rmse: 0.0861708\tvalid_1's rmse: 0.0904992\n",
      "[1975]\ttraining's rmse: 0.0861658\tvalid_1's rmse: 0.0904975\n",
      "[2000]\ttraining's rmse: 0.0861603\tvalid_1's rmse: 0.0904964\n",
      "[2025]\ttraining's rmse: 0.0861564\tvalid_1's rmse: 0.0904952\n",
      "[2050]\ttraining's rmse: 0.0861509\tvalid_1's rmse: 0.0904941\n",
      "[2075]\ttraining's rmse: 0.0861463\tvalid_1's rmse: 0.0904926\n",
      "[2100]\ttraining's rmse: 0.0861423\tvalid_1's rmse: 0.0904917\n",
      "[2125]\ttraining's rmse: 0.0861389\tvalid_1's rmse: 0.0904904\n",
      "[2150]\ttraining's rmse: 0.0861361\tvalid_1's rmse: 0.0904898\n",
      "[2175]\ttraining's rmse: 0.0861331\tvalid_1's rmse: 0.0904881\n",
      "[2200]\ttraining's rmse: 0.0861288\tvalid_1's rmse: 0.0904863\n",
      "[2225]\ttraining's rmse: 0.0861258\tvalid_1's rmse: 0.0904849\n",
      "[2250]\ttraining's rmse: 0.0861221\tvalid_1's rmse: 0.0904842\n",
      "[2275]\ttraining's rmse: 0.0861191\tvalid_1's rmse: 0.0904841\n",
      "[2300]\ttraining's rmse: 0.0861156\tvalid_1's rmse: 0.0904832\n",
      "[2325]\ttraining's rmse: 0.0861122\tvalid_1's rmse: 0.0904812\n",
      "[2350]\ttraining's rmse: 0.0861102\tvalid_1's rmse: 0.0904811\n",
      "[2375]\ttraining's rmse: 0.0861073\tvalid_1's rmse: 0.0904795\n",
      "[2400]\ttraining's rmse: 0.0861054\tvalid_1's rmse: 0.0904786\n",
      "[2425]\ttraining's rmse: 0.0861022\tvalid_1's rmse: 0.0904778\n",
      "[2450]\ttraining's rmse: 0.0861\tvalid_1's rmse: 0.090477\n",
      "[2475]\ttraining's rmse: 0.0860955\tvalid_1's rmse: 0.0904762\n",
      "[2500]\ttraining's rmse: 0.0860931\tvalid_1's rmse: 0.0904759\n",
      "[2525]\ttraining's rmse: 0.0860894\tvalid_1's rmse: 0.0904752\n",
      "[2550]\ttraining's rmse: 0.0860873\tvalid_1's rmse: 0.0904751\n",
      "[2575]\ttraining's rmse: 0.0860855\tvalid_1's rmse: 0.0904746\n",
      "[2600]\ttraining's rmse: 0.0860825\tvalid_1's rmse: 0.0904733\n",
      "[2625]\ttraining's rmse: 0.0860803\tvalid_1's rmse: 0.0904723\n",
      "[2650]\ttraining's rmse: 0.0860781\tvalid_1's rmse: 0.0904711\n",
      "[2675]\ttraining's rmse: 0.0860753\tvalid_1's rmse: 0.0904694\n",
      "[2700]\ttraining's rmse: 0.0860736\tvalid_1's rmse: 0.0904686\n",
      "[2725]\ttraining's rmse: 0.0860712\tvalid_1's rmse: 0.0904683\n",
      "[2750]\ttraining's rmse: 0.0860683\tvalid_1's rmse: 0.090468\n",
      "[2775]\ttraining's rmse: 0.0860665\tvalid_1's rmse: 0.090468\n",
      "[2800]\ttraining's rmse: 0.0860637\tvalid_1's rmse: 0.0904678\n",
      "[2825]\ttraining's rmse: 0.0860614\tvalid_1's rmse: 0.0904673\n",
      "[2850]\ttraining's rmse: 0.0860606\tvalid_1's rmse: 0.0904676\n",
      "Early stopping, best iteration is:\n",
      "[2818]\ttraining's rmse: 0.0860616\tvalid_1's rmse: 0.0904671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0896371\tvalid_1's rmse: 0.0917193\n",
      "[50]\ttraining's rmse: 0.0894682\tvalid_1's rmse: 0.0916657\n",
      "[75]\ttraining's rmse: 0.0892964\tvalid_1's rmse: 0.0916112\n",
      "[100]\ttraining's rmse: 0.089144\tvalid_1's rmse: 0.0915634\n",
      "[125]\ttraining's rmse: 0.0889861\tvalid_1's rmse: 0.0915139\n",
      "[150]\ttraining's rmse: 0.0888479\tvalid_1's rmse: 0.0914688\n",
      "[175]\ttraining's rmse: 0.0887284\tvalid_1's rmse: 0.0914332\n",
      "[200]\ttraining's rmse: 0.0885985\tvalid_1's rmse: 0.0913939\n",
      "[225]\ttraining's rmse: 0.0884769\tvalid_1's rmse: 0.0913603\n",
      "[250]\ttraining's rmse: 0.0883725\tvalid_1's rmse: 0.091328\n",
      "[275]\ttraining's rmse: 0.088277\tvalid_1's rmse: 0.0912987\n",
      "[300]\ttraining's rmse: 0.0881805\tvalid_1's rmse: 0.0912702\n",
      "[325]\ttraining's rmse: 0.0880864\tvalid_1's rmse: 0.0912437\n",
      "[350]\ttraining's rmse: 0.0879921\tvalid_1's rmse: 0.0912179\n",
      "[375]\ttraining's rmse: 0.0879176\tvalid_1's rmse: 0.0911963\n",
      "[400]\ttraining's rmse: 0.0878343\tvalid_1's rmse: 0.0911741\n",
      "[425]\ttraining's rmse: 0.0877608\tvalid_1's rmse: 0.0911532\n",
      "[450]\ttraining's rmse: 0.0876971\tvalid_1's rmse: 0.0911358\n",
      "[475]\ttraining's rmse: 0.0876357\tvalid_1's rmse: 0.0911183\n",
      "[500]\ttraining's rmse: 0.0875823\tvalid_1's rmse: 0.0911016\n",
      "[525]\ttraining's rmse: 0.0875161\tvalid_1's rmse: 0.0910845\n",
      "[550]\ttraining's rmse: 0.0874576\tvalid_1's rmse: 0.0910704\n",
      "[575]\ttraining's rmse: 0.0874042\tvalid_1's rmse: 0.0910564\n",
      "[600]\ttraining's rmse: 0.0873504\tvalid_1's rmse: 0.0910436\n",
      "[625]\ttraining's rmse: 0.0873061\tvalid_1's rmse: 0.0910306\n",
      "[650]\ttraining's rmse: 0.0872547\tvalid_1's rmse: 0.0910178\n",
      "[675]\ttraining's rmse: 0.0872052\tvalid_1's rmse: 0.0910057\n",
      "[700]\ttraining's rmse: 0.0871582\tvalid_1's rmse: 0.0909935\n",
      "[725]\ttraining's rmse: 0.0871149\tvalid_1's rmse: 0.0909842\n",
      "[750]\ttraining's rmse: 0.0870768\tvalid_1's rmse: 0.0909748\n",
      "[775]\ttraining's rmse: 0.0870429\tvalid_1's rmse: 0.0909653\n",
      "[800]\ttraining's rmse: 0.0870005\tvalid_1's rmse: 0.0909562\n",
      "[825]\ttraining's rmse: 0.0869661\tvalid_1's rmse: 0.0909477\n",
      "[850]\ttraining's rmse: 0.0869293\tvalid_1's rmse: 0.0909407\n",
      "[875]\ttraining's rmse: 0.0868977\tvalid_1's rmse: 0.0909335\n",
      "[900]\ttraining's rmse: 0.0868636\tvalid_1's rmse: 0.0909258\n",
      "[925]\ttraining's rmse: 0.0868308\tvalid_1's rmse: 0.0909189\n",
      "[950]\ttraining's rmse: 0.0868023\tvalid_1's rmse: 0.0909125\n",
      "[975]\ttraining's rmse: 0.0867753\tvalid_1's rmse: 0.0909063\n",
      "[1000]\ttraining's rmse: 0.0867477\tvalid_1's rmse: 0.0909007\n",
      "[1025]\ttraining's rmse: 0.0867172\tvalid_1's rmse: 0.0908956\n",
      "[1050]\ttraining's rmse: 0.0866948\tvalid_1's rmse: 0.0908913\n",
      "[1075]\ttraining's rmse: 0.0866712\tvalid_1's rmse: 0.0908878\n",
      "[1100]\ttraining's rmse: 0.0866509\tvalid_1's rmse: 0.0908835\n",
      "[1125]\ttraining's rmse: 0.0866275\tvalid_1's rmse: 0.0908794\n",
      "[1150]\ttraining's rmse: 0.0866043\tvalid_1's rmse: 0.0908759\n",
      "[1175]\ttraining's rmse: 0.0865843\tvalid_1's rmse: 0.0908731\n",
      "[1200]\ttraining's rmse: 0.0865643\tvalid_1's rmse: 0.090869\n",
      "[1225]\ttraining's rmse: 0.0865455\tvalid_1's rmse: 0.0908663\n",
      "[1250]\ttraining's rmse: 0.0865294\tvalid_1's rmse: 0.090864\n",
      "[1275]\ttraining's rmse: 0.0865076\tvalid_1's rmse: 0.0908615\n",
      "[1300]\ttraining's rmse: 0.0864926\tvalid_1's rmse: 0.090859\n",
      "[1325]\ttraining's rmse: 0.0864756\tvalid_1's rmse: 0.0908565\n",
      "[1350]\ttraining's rmse: 0.0864598\tvalid_1's rmse: 0.0908549\n",
      "[1375]\ttraining's rmse: 0.086445\tvalid_1's rmse: 0.0908534\n",
      "[1400]\ttraining's rmse: 0.0864311\tvalid_1's rmse: 0.0908508\n",
      "[1425]\ttraining's rmse: 0.0864164\tvalid_1's rmse: 0.0908491\n",
      "[1450]\ttraining's rmse: 0.0864016\tvalid_1's rmse: 0.0908483\n",
      "[1475]\ttraining's rmse: 0.0863896\tvalid_1's rmse: 0.0908465\n",
      "[1500]\ttraining's rmse: 0.0863782\tvalid_1's rmse: 0.0908452\n",
      "[1525]\ttraining's rmse: 0.0863653\tvalid_1's rmse: 0.0908432\n",
      "[1550]\ttraining's rmse: 0.0863523\tvalid_1's rmse: 0.0908421\n",
      "[1575]\ttraining's rmse: 0.0863425\tvalid_1's rmse: 0.0908402\n",
      "[1600]\ttraining's rmse: 0.0863327\tvalid_1's rmse: 0.0908394\n",
      "[1625]\ttraining's rmse: 0.0863232\tvalid_1's rmse: 0.090838\n",
      "[1650]\ttraining's rmse: 0.086314\tvalid_1's rmse: 0.0908371\n",
      "[1675]\ttraining's rmse: 0.086306\tvalid_1's rmse: 0.0908361\n",
      "[1700]\ttraining's rmse: 0.0862971\tvalid_1's rmse: 0.0908348\n",
      "[1725]\ttraining's rmse: 0.0862867\tvalid_1's rmse: 0.0908334\n",
      "[1750]\ttraining's rmse: 0.0862771\tvalid_1's rmse: 0.0908334\n",
      "[1775]\ttraining's rmse: 0.0862707\tvalid_1's rmse: 0.0908335\n",
      "Early stopping, best iteration is:\n",
      "[1738]\ttraining's rmse: 0.0862828\tvalid_1's rmse: 0.090833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0914591\tvalid_1's rmse: 0.0881135\n",
      "[50]\ttraining's rmse: 0.0913292\tvalid_1's rmse: 0.0880649\n",
      "[75]\ttraining's rmse: 0.0911945\tvalid_1's rmse: 0.088017\n",
      "[100]\ttraining's rmse: 0.0910737\tvalid_1's rmse: 0.0879758\n",
      "[125]\ttraining's rmse: 0.090947\tvalid_1's rmse: 0.0879334\n",
      "[150]\ttraining's rmse: 0.0908323\tvalid_1's rmse: 0.0878954\n",
      "[175]\ttraining's rmse: 0.0907354\tvalid_1's rmse: 0.087864\n",
      "[200]\ttraining's rmse: 0.0906287\tvalid_1's rmse: 0.0878328\n",
      "[225]\ttraining's rmse: 0.0905261\tvalid_1's rmse: 0.0878005\n",
      "[250]\ttraining's rmse: 0.0904394\tvalid_1's rmse: 0.087774\n",
      "[275]\ttraining's rmse: 0.0903611\tvalid_1's rmse: 0.0877507\n",
      "[300]\ttraining's rmse: 0.0902834\tvalid_1's rmse: 0.0877285\n",
      "[325]\ttraining's rmse: 0.0902017\tvalid_1's rmse: 0.0877069\n",
      "[350]\ttraining's rmse: 0.0901241\tvalid_1's rmse: 0.0876848\n",
      "[375]\ttraining's rmse: 0.0900595\tvalid_1's rmse: 0.0876725\n",
      "[400]\ttraining's rmse: 0.0899891\tvalid_1's rmse: 0.0876553\n",
      "[425]\ttraining's rmse: 0.0899245\tvalid_1's rmse: 0.0876375\n",
      "[450]\ttraining's rmse: 0.089867\tvalid_1's rmse: 0.0876266\n",
      "[475]\ttraining's rmse: 0.0898111\tvalid_1's rmse: 0.0876129\n",
      "[500]\ttraining's rmse: 0.089765\tvalid_1's rmse: 0.0876059\n",
      "[525]\ttraining's rmse: 0.0897016\tvalid_1's rmse: 0.0875908\n",
      "[550]\ttraining's rmse: 0.0896458\tvalid_1's rmse: 0.0875779\n",
      "[575]\ttraining's rmse: 0.0895935\tvalid_1's rmse: 0.0875678\n",
      "[600]\ttraining's rmse: 0.0895437\tvalid_1's rmse: 0.0875588\n",
      "[625]\ttraining's rmse: 0.0895039\tvalid_1's rmse: 0.0875501\n",
      "[650]\ttraining's rmse: 0.0894517\tvalid_1's rmse: 0.0875471\n",
      "[675]\ttraining's rmse: 0.0894014\tvalid_1's rmse: 0.0875399\n",
      "[700]\ttraining's rmse: 0.0893566\tvalid_1's rmse: 0.0875316\n",
      "[725]\ttraining's rmse: 0.0893153\tvalid_1's rmse: 0.0875366\n",
      "[750]\ttraining's rmse: 0.0892758\tvalid_1's rmse: 0.087534\n",
      "[775]\ttraining's rmse: 0.0892427\tvalid_1's rmse: 0.0875288\n",
      "[800]\ttraining's rmse: 0.0892012\tvalid_1's rmse: 0.0875243\n",
      "[825]\ttraining's rmse: 0.0891653\tvalid_1's rmse: 0.0875252\n",
      "[850]\ttraining's rmse: 0.0891295\tvalid_1's rmse: 0.0875273\n",
      "Early stopping, best iteration is:\n",
      "[803]\ttraining's rmse: 0.0891956\tvalid_1's rmse: 0.0875237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0873395\tvalid_1's rmse: 0.0899653\n",
      "[50]\ttraining's rmse: 0.0872024\tvalid_1's rmse: 0.0899085\n",
      "[75]\ttraining's rmse: 0.0870656\tvalid_1's rmse: 0.0898528\n",
      "[100]\ttraining's rmse: 0.0869382\tvalid_1's rmse: 0.0898046\n",
      "[125]\ttraining's rmse: 0.086813\tvalid_1's rmse: 0.0897567\n",
      "[150]\ttraining's rmse: 0.0866925\tvalid_1's rmse: 0.0897121\n",
      "[175]\ttraining's rmse: 0.0865939\tvalid_1's rmse: 0.0896722\n",
      "[200]\ttraining's rmse: 0.0864877\tvalid_1's rmse: 0.0896359\n",
      "[225]\ttraining's rmse: 0.0863871\tvalid_1's rmse: 0.0895991\n",
      "[250]\ttraining's rmse: 0.0863006\tvalid_1's rmse: 0.0895641\n",
      "[275]\ttraining's rmse: 0.0862212\tvalid_1's rmse: 0.0895344\n",
      "[300]\ttraining's rmse: 0.0861397\tvalid_1's rmse: 0.0895049\n",
      "[325]\ttraining's rmse: 0.0860626\tvalid_1's rmse: 0.0894764\n",
      "[350]\ttraining's rmse: 0.0859882\tvalid_1's rmse: 0.0894508\n",
      "[375]\ttraining's rmse: 0.0859177\tvalid_1's rmse: 0.0894269\n",
      "[400]\ttraining's rmse: 0.0858493\tvalid_1's rmse: 0.0894049\n",
      "[425]\ttraining's rmse: 0.0857863\tvalid_1's rmse: 0.0893832\n",
      "[450]\ttraining's rmse: 0.0857301\tvalid_1's rmse: 0.0893615\n",
      "[475]\ttraining's rmse: 0.0856772\tvalid_1's rmse: 0.0893423\n",
      "[500]\ttraining's rmse: 0.0856335\tvalid_1's rmse: 0.0893237\n",
      "[525]\ttraining's rmse: 0.0855774\tvalid_1's rmse: 0.089306\n",
      "[550]\ttraining's rmse: 0.0855269\tvalid_1's rmse: 0.089291\n",
      "[575]\ttraining's rmse: 0.0854788\tvalid_1's rmse: 0.0892773\n",
      "[600]\ttraining's rmse: 0.0854338\tvalid_1's rmse: 0.0892639\n",
      "[625]\ttraining's rmse: 0.0853971\tvalid_1's rmse: 0.0892503\n",
      "[650]\ttraining's rmse: 0.0853528\tvalid_1's rmse: 0.0892365\n",
      "[675]\ttraining's rmse: 0.085308\tvalid_1's rmse: 0.0892239\n",
      "[700]\ttraining's rmse: 0.0852676\tvalid_1's rmse: 0.0892115\n",
      "[725]\ttraining's rmse: 0.085229\tvalid_1's rmse: 0.0892001\n",
      "[750]\ttraining's rmse: 0.0851925\tvalid_1's rmse: 0.0891895\n",
      "[775]\ttraining's rmse: 0.0851611\tvalid_1's rmse: 0.0891792\n",
      "[800]\ttraining's rmse: 0.085126\tvalid_1's rmse: 0.0891697\n",
      "[825]\ttraining's rmse: 0.0850947\tvalid_1's rmse: 0.0891592\n",
      "[850]\ttraining's rmse: 0.0850643\tvalid_1's rmse: 0.0891524\n",
      "[875]\ttraining's rmse: 0.0850345\tvalid_1's rmse: 0.0891449\n",
      "[900]\ttraining's rmse: 0.0850036\tvalid_1's rmse: 0.0891379\n",
      "[925]\ttraining's rmse: 0.0849757\tvalid_1's rmse: 0.0891291\n",
      "[950]\ttraining's rmse: 0.0849498\tvalid_1's rmse: 0.0891226\n",
      "[975]\ttraining's rmse: 0.0849269\tvalid_1's rmse: 0.0891158\n",
      "[1000]\ttraining's rmse: 0.0849045\tvalid_1's rmse: 0.089109\n",
      "[1025]\ttraining's rmse: 0.084878\tvalid_1's rmse: 0.0891029\n",
      "[1050]\ttraining's rmse: 0.084855\tvalid_1's rmse: 0.0890966\n",
      "[1075]\ttraining's rmse: 0.0848357\tvalid_1's rmse: 0.0890929\n",
      "[1100]\ttraining's rmse: 0.0848179\tvalid_1's rmse: 0.0890879\n",
      "[1125]\ttraining's rmse: 0.0848023\tvalid_1's rmse: 0.0890833\n",
      "[1150]\ttraining's rmse: 0.0847833\tvalid_1's rmse: 0.0890785\n",
      "[1175]\ttraining's rmse: 0.0847665\tvalid_1's rmse: 0.0890752\n",
      "[1200]\ttraining's rmse: 0.0847501\tvalid_1's rmse: 0.0890713\n",
      "[1225]\ttraining's rmse: 0.0847315\tvalid_1's rmse: 0.0890672\n",
      "[1250]\ttraining's rmse: 0.084715\tvalid_1's rmse: 0.0890638\n",
      "[1275]\ttraining's rmse: 0.0846985\tvalid_1's rmse: 0.0890596\n",
      "[1300]\ttraining's rmse: 0.0846842\tvalid_1's rmse: 0.0890538\n",
      "[1325]\ttraining's rmse: 0.0846685\tvalid_1's rmse: 0.0890488\n",
      "[1350]\ttraining's rmse: 0.0846515\tvalid_1's rmse: 0.0890448\n",
      "[1375]\ttraining's rmse: 0.084638\tvalid_1's rmse: 0.0890421\n",
      "[1400]\ttraining's rmse: 0.0846281\tvalid_1's rmse: 0.0890382\n",
      "[1425]\ttraining's rmse: 0.0846137\tvalid_1's rmse: 0.0890362\n",
      "[1450]\ttraining's rmse: 0.0846006\tvalid_1's rmse: 0.0890338\n",
      "[1475]\ttraining's rmse: 0.0845883\tvalid_1's rmse: 0.0890302\n",
      "[1500]\ttraining's rmse: 0.0845776\tvalid_1's rmse: 0.0890275\n",
      "[1525]\ttraining's rmse: 0.0845659\tvalid_1's rmse: 0.0890258\n",
      "[1550]\ttraining's rmse: 0.0845563\tvalid_1's rmse: 0.0890241\n",
      "[1575]\ttraining's rmse: 0.0845467\tvalid_1's rmse: 0.0890219\n",
      "[1600]\ttraining's rmse: 0.0845389\tvalid_1's rmse: 0.0890202\n",
      "[1625]\ttraining's rmse: 0.0845303\tvalid_1's rmse: 0.0890166\n",
      "[1650]\ttraining's rmse: 0.0845238\tvalid_1's rmse: 0.0890151\n",
      "[1675]\ttraining's rmse: 0.0845156\tvalid_1's rmse: 0.0890119\n",
      "[1700]\ttraining's rmse: 0.0845078\tvalid_1's rmse: 0.0890092\n",
      "[1725]\ttraining's rmse: 0.0845012\tvalid_1's rmse: 0.0890074\n",
      "[1750]\ttraining's rmse: 0.0844924\tvalid_1's rmse: 0.0890056\n",
      "[1775]\ttraining's rmse: 0.084486\tvalid_1's rmse: 0.0890039\n",
      "[1800]\ttraining's rmse: 0.0844787\tvalid_1's rmse: 0.089002\n",
      "[1825]\ttraining's rmse: 0.0844725\tvalid_1's rmse: 0.0889999\n",
      "[1850]\ttraining's rmse: 0.0844672\tvalid_1's rmse: 0.0889975\n",
      "[1875]\ttraining's rmse: 0.084462\tvalid_1's rmse: 0.0889959\n",
      "[1900]\ttraining's rmse: 0.0844568\tvalid_1's rmse: 0.0889947\n",
      "[1925]\ttraining's rmse: 0.0844512\tvalid_1's rmse: 0.0889935\n",
      "[1950]\ttraining's rmse: 0.0844468\tvalid_1's rmse: 0.0889916\n",
      "[1975]\ttraining's rmse: 0.084442\tvalid_1's rmse: 0.08899\n",
      "[2000]\ttraining's rmse: 0.0844358\tvalid_1's rmse: 0.0889894\n",
      "[2025]\ttraining's rmse: 0.0844307\tvalid_1's rmse: 0.0889877\n",
      "[2050]\ttraining's rmse: 0.0844243\tvalid_1's rmse: 0.0889864\n",
      "[2075]\ttraining's rmse: 0.0844204\tvalid_1's rmse: 0.0889857\n",
      "[2100]\ttraining's rmse: 0.0844173\tvalid_1's rmse: 0.0889848\n",
      "[2125]\ttraining's rmse: 0.0844137\tvalid_1's rmse: 0.0889843\n",
      "[2150]\ttraining's rmse: 0.0844094\tvalid_1's rmse: 0.088984\n",
      "[2175]\ttraining's rmse: 0.0844054\tvalid_1's rmse: 0.0889832\n",
      "[2200]\ttraining's rmse: 0.0844023\tvalid_1's rmse: 0.0889827\n",
      "[2225]\ttraining's rmse: 0.0843979\tvalid_1's rmse: 0.0889813\n",
      "[2250]\ttraining's rmse: 0.0843936\tvalid_1's rmse: 0.0889809\n",
      "[2275]\ttraining's rmse: 0.0843895\tvalid_1's rmse: 0.0889797\n",
      "[2300]\ttraining's rmse: 0.0843855\tvalid_1's rmse: 0.0889779\n",
      "[2325]\ttraining's rmse: 0.0843808\tvalid_1's rmse: 0.0889774\n",
      "[2350]\ttraining's rmse: 0.0843783\tvalid_1's rmse: 0.0889763\n",
      "[2375]\ttraining's rmse: 0.0843746\tvalid_1's rmse: 0.0889758\n",
      "[2400]\ttraining's rmse: 0.0843721\tvalid_1's rmse: 0.0889751\n",
      "[2425]\ttraining's rmse: 0.0843691\tvalid_1's rmse: 0.088975\n",
      "[2450]\ttraining's rmse: 0.0843651\tvalid_1's rmse: 0.0889744\n",
      "[2475]\ttraining's rmse: 0.0843617\tvalid_1's rmse: 0.0889742\n",
      "[2500]\ttraining's rmse: 0.0843592\tvalid_1's rmse: 0.0889744\n",
      "[2525]\ttraining's rmse: 0.0843566\tvalid_1's rmse: 0.0889742\n",
      "Early stopping, best iteration is:\n",
      "[2481]\ttraining's rmse: 0.0843613\tvalid_1's rmse: 0.0889739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0873883\tvalid_1's rmse: 0.0898836\n",
      "[50]\ttraining's rmse: 0.0872595\tvalid_1's rmse: 0.0898273\n",
      "[75]\ttraining's rmse: 0.087126\tvalid_1's rmse: 0.0897705\n",
      "[100]\ttraining's rmse: 0.0870076\tvalid_1's rmse: 0.089723\n",
      "[125]\ttraining's rmse: 0.0868872\tvalid_1's rmse: 0.0896751\n",
      "[150]\ttraining's rmse: 0.0867762\tvalid_1's rmse: 0.0896276\n",
      "[175]\ttraining's rmse: 0.0866844\tvalid_1's rmse: 0.0895924\n",
      "[200]\ttraining's rmse: 0.0865853\tvalid_1's rmse: 0.0895555\n",
      "[225]\ttraining's rmse: 0.0864893\tvalid_1's rmse: 0.089519\n",
      "[250]\ttraining's rmse: 0.0864066\tvalid_1's rmse: 0.0894857\n",
      "[275]\ttraining's rmse: 0.0863307\tvalid_1's rmse: 0.0894559\n",
      "[300]\ttraining's rmse: 0.0862538\tvalid_1's rmse: 0.0894268\n",
      "[325]\ttraining's rmse: 0.0861766\tvalid_1's rmse: 0.0894008\n",
      "[350]\ttraining's rmse: 0.0861015\tvalid_1's rmse: 0.089376\n",
      "[375]\ttraining's rmse: 0.08604\tvalid_1's rmse: 0.0893547\n",
      "[400]\ttraining's rmse: 0.0859756\tvalid_1's rmse: 0.0893331\n",
      "[425]\ttraining's rmse: 0.0859155\tvalid_1's rmse: 0.089314\n",
      "[450]\ttraining's rmse: 0.0858613\tvalid_1's rmse: 0.0892953\n",
      "[475]\ttraining's rmse: 0.0858087\tvalid_1's rmse: 0.089278\n",
      "[500]\ttraining's rmse: 0.0857638\tvalid_1's rmse: 0.0892619\n",
      "[525]\ttraining's rmse: 0.0857072\tvalid_1's rmse: 0.089246\n",
      "[550]\ttraining's rmse: 0.0856544\tvalid_1's rmse: 0.0892306\n",
      "[575]\ttraining's rmse: 0.0856053\tvalid_1's rmse: 0.0892169\n",
      "[600]\ttraining's rmse: 0.0855584\tvalid_1's rmse: 0.0892039\n",
      "[625]\ttraining's rmse: 0.0855214\tvalid_1's rmse: 0.0891917\n",
      "[650]\ttraining's rmse: 0.0854742\tvalid_1's rmse: 0.08918\n",
      "[675]\ttraining's rmse: 0.0854276\tvalid_1's rmse: 0.0891682\n",
      "[700]\ttraining's rmse: 0.0853875\tvalid_1's rmse: 0.0891576\n",
      "[725]\ttraining's rmse: 0.0853486\tvalid_1's rmse: 0.0891478\n",
      "[750]\ttraining's rmse: 0.0853138\tvalid_1's rmse: 0.0891389\n",
      "[775]\ttraining's rmse: 0.0852851\tvalid_1's rmse: 0.0891301\n",
      "[800]\ttraining's rmse: 0.085247\tvalid_1's rmse: 0.0891215\n",
      "[825]\ttraining's rmse: 0.0852141\tvalid_1's rmse: 0.0891136\n",
      "[850]\ttraining's rmse: 0.0851817\tvalid_1's rmse: 0.0891057\n",
      "[875]\ttraining's rmse: 0.0851531\tvalid_1's rmse: 0.0890998\n",
      "[900]\ttraining's rmse: 0.0851214\tvalid_1's rmse: 0.0890937\n",
      "[925]\ttraining's rmse: 0.0850911\tvalid_1's rmse: 0.0890871\n",
      "[950]\ttraining's rmse: 0.0850637\tvalid_1's rmse: 0.0890815\n",
      "[975]\ttraining's rmse: 0.0850383\tvalid_1's rmse: 0.0890751\n",
      "[1000]\ttraining's rmse: 0.0850124\tvalid_1's rmse: 0.0890698\n",
      "[1025]\ttraining's rmse: 0.0849854\tvalid_1's rmse: 0.0890653\n",
      "[1050]\ttraining's rmse: 0.0849641\tvalid_1's rmse: 0.0890611\n",
      "[1075]\ttraining's rmse: 0.0849425\tvalid_1's rmse: 0.0890571\n",
      "[1100]\ttraining's rmse: 0.0849232\tvalid_1's rmse: 0.089053\n",
      "[1125]\ttraining's rmse: 0.0849034\tvalid_1's rmse: 0.0890497\n",
      "[1150]\ttraining's rmse: 0.084882\tvalid_1's rmse: 0.0890457\n",
      "[1175]\ttraining's rmse: 0.0848657\tvalid_1's rmse: 0.0890424\n",
      "[1200]\ttraining's rmse: 0.0848506\tvalid_1's rmse: 0.0890398\n",
      "[1225]\ttraining's rmse: 0.0848325\tvalid_1's rmse: 0.089037\n",
      "[1250]\ttraining's rmse: 0.0848174\tvalid_1's rmse: 0.0890345\n",
      "[1275]\ttraining's rmse: 0.0848003\tvalid_1's rmse: 0.0890325\n",
      "[1300]\ttraining's rmse: 0.0847867\tvalid_1's rmse: 0.0890301\n",
      "[1325]\ttraining's rmse: 0.0847721\tvalid_1's rmse: 0.0890283\n",
      "[1350]\ttraining's rmse: 0.0847565\tvalid_1's rmse: 0.0890266\n",
      "[1375]\ttraining's rmse: 0.0847424\tvalid_1's rmse: 0.0890246\n",
      "[1400]\ttraining's rmse: 0.0847304\tvalid_1's rmse: 0.0890224\n",
      "[1425]\ttraining's rmse: 0.084717\tvalid_1's rmse: 0.0890205\n",
      "[1450]\ttraining's rmse: 0.0847059\tvalid_1's rmse: 0.0890195\n",
      "[1475]\ttraining's rmse: 0.0846925\tvalid_1's rmse: 0.0890176\n",
      "[1500]\ttraining's rmse: 0.084683\tvalid_1's rmse: 0.0890162\n",
      "[1525]\ttraining's rmse: 0.084671\tvalid_1's rmse: 0.0890145\n",
      "[1550]\ttraining's rmse: 0.0846615\tvalid_1's rmse: 0.0890137\n",
      "[1575]\ttraining's rmse: 0.0846503\tvalid_1's rmse: 0.0890122\n",
      "[1600]\ttraining's rmse: 0.0846427\tvalid_1's rmse: 0.0890121\n",
      "[1625]\ttraining's rmse: 0.0846337\tvalid_1's rmse: 0.089011\n",
      "[1650]\ttraining's rmse: 0.0846248\tvalid_1's rmse: 0.0890101\n",
      "[1675]\ttraining's rmse: 0.0846179\tvalid_1's rmse: 0.0890091\n",
      "[1700]\ttraining's rmse: 0.0846094\tvalid_1's rmse: 0.0890079\n",
      "[1725]\ttraining's rmse: 0.0846038\tvalid_1's rmse: 0.0890071\n",
      "[1750]\ttraining's rmse: 0.084595\tvalid_1's rmse: 0.089006\n",
      "[1775]\ttraining's rmse: 0.0845869\tvalid_1's rmse: 0.0890054\n",
      "[1800]\ttraining's rmse: 0.0845801\tvalid_1's rmse: 0.0890042\n",
      "[1825]\ttraining's rmse: 0.0845719\tvalid_1's rmse: 0.0890034\n",
      "[1850]\ttraining's rmse: 0.084566\tvalid_1's rmse: 0.0890028\n",
      "[1875]\ttraining's rmse: 0.0845603\tvalid_1's rmse: 0.0890032\n",
      "[1900]\ttraining's rmse: 0.0845556\tvalid_1's rmse: 0.0890029\n",
      "Early stopping, best iteration is:\n",
      "[1857]\ttraining's rmse: 0.0845642\tvalid_1's rmse: 0.0890027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0897996\tvalid_1's rmse: 0.084987\n",
      "[50]\ttraining's rmse: 0.0896802\tvalid_1's rmse: 0.0849385\n",
      "[75]\ttraining's rmse: 0.089553\tvalid_1's rmse: 0.0848897\n",
      "[100]\ttraining's rmse: 0.0894413\tvalid_1's rmse: 0.0848466\n",
      "[125]\ttraining's rmse: 0.0893274\tvalid_1's rmse: 0.0848038\n",
      "[150]\ttraining's rmse: 0.089223\tvalid_1's rmse: 0.0847674\n",
      "[175]\ttraining's rmse: 0.089137\tvalid_1's rmse: 0.0847379\n",
      "[200]\ttraining's rmse: 0.0890438\tvalid_1's rmse: 0.0847063\n",
      "[225]\ttraining's rmse: 0.0889507\tvalid_1's rmse: 0.0846747\n",
      "[250]\ttraining's rmse: 0.0888719\tvalid_1's rmse: 0.0846488\n",
      "[275]\ttraining's rmse: 0.0888013\tvalid_1's rmse: 0.084623\n",
      "[300]\ttraining's rmse: 0.088733\tvalid_1's rmse: 0.0846008\n",
      "[325]\ttraining's rmse: 0.0886601\tvalid_1's rmse: 0.0845785\n",
      "[350]\ttraining's rmse: 0.0885887\tvalid_1's rmse: 0.0845571\n",
      "[375]\ttraining's rmse: 0.0885319\tvalid_1's rmse: 0.0845393\n",
      "[400]\ttraining's rmse: 0.0884694\tvalid_1's rmse: 0.0845248\n",
      "[425]\ttraining's rmse: 0.0884098\tvalid_1's rmse: 0.084509\n",
      "[450]\ttraining's rmse: 0.0883538\tvalid_1's rmse: 0.0844951\n",
      "[475]\ttraining's rmse: 0.0883051\tvalid_1's rmse: 0.0844812\n",
      "[500]\ttraining's rmse: 0.0882625\tvalid_1's rmse: 0.0844687\n",
      "[525]\ttraining's rmse: 0.0882047\tvalid_1's rmse: 0.0844543\n",
      "[550]\ttraining's rmse: 0.0881534\tvalid_1's rmse: 0.0844416\n",
      "[575]\ttraining's rmse: 0.0881051\tvalid_1's rmse: 0.0844344\n",
      "[600]\ttraining's rmse: 0.0880587\tvalid_1's rmse: 0.0844295\n",
      "[625]\ttraining's rmse: 0.0880222\tvalid_1's rmse: 0.0844205\n",
      "[650]\ttraining's rmse: 0.0879751\tvalid_1's rmse: 0.0844169\n",
      "[675]\ttraining's rmse: 0.0879263\tvalid_1's rmse: 0.0844107\n",
      "[700]\ttraining's rmse: 0.0878858\tvalid_1's rmse: 0.0844083\n",
      "[725]\ttraining's rmse: 0.0878475\tvalid_1's rmse: 0.0844211\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0878966\tvalid_1's rmse: 0.084405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0903966\tvalid_1's rmse: 0.0920373\n",
      "[50]\ttraining's rmse: 0.0902028\tvalid_1's rmse: 0.091982\n",
      "[75]\ttraining's rmse: 0.090015\tvalid_1's rmse: 0.0919266\n",
      "[100]\ttraining's rmse: 0.0898391\tvalid_1's rmse: 0.0918788\n",
      "[125]\ttraining's rmse: 0.0896724\tvalid_1's rmse: 0.0918302\n",
      "[150]\ttraining's rmse: 0.0895161\tvalid_1's rmse: 0.0917847\n",
      "[175]\ttraining's rmse: 0.0893844\tvalid_1's rmse: 0.0917466\n",
      "[200]\ttraining's rmse: 0.0892406\tvalid_1's rmse: 0.0917068\n",
      "[225]\ttraining's rmse: 0.089109\tvalid_1's rmse: 0.0916709\n",
      "[250]\ttraining's rmse: 0.0889948\tvalid_1's rmse: 0.0916375\n",
      "[275]\ttraining's rmse: 0.0888841\tvalid_1's rmse: 0.0916074\n",
      "[300]\ttraining's rmse: 0.0887824\tvalid_1's rmse: 0.0915777\n",
      "[325]\ttraining's rmse: 0.0886818\tvalid_1's rmse: 0.0915501\n",
      "[350]\ttraining's rmse: 0.0885861\tvalid_1's rmse: 0.0915246\n",
      "[375]\ttraining's rmse: 0.0885021\tvalid_1's rmse: 0.0915014\n",
      "[400]\ttraining's rmse: 0.0884107\tvalid_1's rmse: 0.0914787\n",
      "[425]\ttraining's rmse: 0.0883292\tvalid_1's rmse: 0.0914568\n",
      "[450]\ttraining's rmse: 0.0882581\tvalid_1's rmse: 0.091436\n",
      "[475]\ttraining's rmse: 0.0881908\tvalid_1's rmse: 0.0914164\n",
      "[500]\ttraining's rmse: 0.0881295\tvalid_1's rmse: 0.0913978\n",
      "[525]\ttraining's rmse: 0.0880583\tvalid_1's rmse: 0.0913805\n",
      "[550]\ttraining's rmse: 0.0879912\tvalid_1's rmse: 0.0913654\n",
      "[575]\ttraining's rmse: 0.0879323\tvalid_1's rmse: 0.0913517\n",
      "[600]\ttraining's rmse: 0.0878751\tvalid_1's rmse: 0.0913375\n",
      "[625]\ttraining's rmse: 0.0878273\tvalid_1's rmse: 0.0913246\n",
      "[650]\ttraining's rmse: 0.0877759\tvalid_1's rmse: 0.0913114\n",
      "[675]\ttraining's rmse: 0.0877258\tvalid_1's rmse: 0.0912997\n",
      "[700]\ttraining's rmse: 0.0876782\tvalid_1's rmse: 0.0912881\n",
      "[725]\ttraining's rmse: 0.0876346\tvalid_1's rmse: 0.0912767\n",
      "[750]\ttraining's rmse: 0.0875928\tvalid_1's rmse: 0.0912676\n",
      "[775]\ttraining's rmse: 0.0875586\tvalid_1's rmse: 0.0912574\n",
      "[800]\ttraining's rmse: 0.0875157\tvalid_1's rmse: 0.0912486\n",
      "[825]\ttraining's rmse: 0.0874822\tvalid_1's rmse: 0.0912405\n",
      "[850]\ttraining's rmse: 0.0874443\tvalid_1's rmse: 0.0912328\n",
      "[875]\ttraining's rmse: 0.08741\tvalid_1's rmse: 0.0912248\n",
      "[900]\ttraining's rmse: 0.087375\tvalid_1's rmse: 0.0912158\n",
      "[925]\ttraining's rmse: 0.0873446\tvalid_1's rmse: 0.0912084\n",
      "[950]\ttraining's rmse: 0.0873134\tvalid_1's rmse: 0.0912\n",
      "[975]\ttraining's rmse: 0.0872799\tvalid_1's rmse: 0.0911931\n",
      "[1000]\ttraining's rmse: 0.0872504\tvalid_1's rmse: 0.0911863\n",
      "[1025]\ttraining's rmse: 0.0872248\tvalid_1's rmse: 0.0911793\n",
      "[1050]\ttraining's rmse: 0.0872\tvalid_1's rmse: 0.0911719\n",
      "[1075]\ttraining's rmse: 0.0871735\tvalid_1's rmse: 0.0911675\n",
      "[1100]\ttraining's rmse: 0.0871498\tvalid_1's rmse: 0.091161\n",
      "[1125]\ttraining's rmse: 0.087126\tvalid_1's rmse: 0.0911552\n",
      "[1150]\ttraining's rmse: 0.0870994\tvalid_1's rmse: 0.0911498\n",
      "[1175]\ttraining's rmse: 0.0870815\tvalid_1's rmse: 0.0911456\n",
      "[1200]\ttraining's rmse: 0.0870649\tvalid_1's rmse: 0.0911384\n",
      "[1225]\ttraining's rmse: 0.0870466\tvalid_1's rmse: 0.0911337\n",
      "[1250]\ttraining's rmse: 0.0870322\tvalid_1's rmse: 0.0911305\n",
      "[1275]\ttraining's rmse: 0.0870114\tvalid_1's rmse: 0.0911266\n",
      "[1300]\ttraining's rmse: 0.0869968\tvalid_1's rmse: 0.0911231\n",
      "[1325]\ttraining's rmse: 0.0869806\tvalid_1's rmse: 0.0911194\n",
      "[1350]\ttraining's rmse: 0.086964\tvalid_1's rmse: 0.0911161\n",
      "[1375]\ttraining's rmse: 0.0869453\tvalid_1's rmse: 0.0911125\n",
      "[1400]\ttraining's rmse: 0.0869328\tvalid_1's rmse: 0.0911081\n",
      "[1425]\ttraining's rmse: 0.0869153\tvalid_1's rmse: 0.0911051\n",
      "[1450]\ttraining's rmse: 0.0868995\tvalid_1's rmse: 0.0911023\n",
      "[1475]\ttraining's rmse: 0.0868851\tvalid_1's rmse: 0.0910982\n",
      "[1500]\ttraining's rmse: 0.086872\tvalid_1's rmse: 0.0910946\n",
      "[1525]\ttraining's rmse: 0.0868615\tvalid_1's rmse: 0.0910915\n",
      "[1550]\ttraining's rmse: 0.0868503\tvalid_1's rmse: 0.0910888\n",
      "[1575]\ttraining's rmse: 0.0868406\tvalid_1's rmse: 0.0910867\n",
      "[1600]\ttraining's rmse: 0.0868317\tvalid_1's rmse: 0.0910833\n",
      "[1625]\ttraining's rmse: 0.0868249\tvalid_1's rmse: 0.0910803\n",
      "[1650]\ttraining's rmse: 0.0868153\tvalid_1's rmse: 0.0910774\n",
      "[1675]\ttraining's rmse: 0.0868078\tvalid_1's rmse: 0.0910747\n",
      "[1700]\ttraining's rmse: 0.0867998\tvalid_1's rmse: 0.0910729\n",
      "[1725]\ttraining's rmse: 0.0867936\tvalid_1's rmse: 0.0910719\n",
      "[1750]\ttraining's rmse: 0.0867859\tvalid_1's rmse: 0.0910694\n",
      "[1775]\ttraining's rmse: 0.0867783\tvalid_1's rmse: 0.0910665\n",
      "[1800]\ttraining's rmse: 0.0867707\tvalid_1's rmse: 0.0910651\n",
      "[1825]\ttraining's rmse: 0.0867629\tvalid_1's rmse: 0.0910635\n",
      "[1850]\ttraining's rmse: 0.0867566\tvalid_1's rmse: 0.0910613\n",
      "[1875]\ttraining's rmse: 0.0867509\tvalid_1's rmse: 0.0910604\n",
      "[1900]\ttraining's rmse: 0.0867436\tvalid_1's rmse: 0.0910586\n",
      "[1925]\ttraining's rmse: 0.0867374\tvalid_1's rmse: 0.0910571\n",
      "[1950]\ttraining's rmse: 0.0867331\tvalid_1's rmse: 0.091055\n",
      "[1975]\ttraining's rmse: 0.086728\tvalid_1's rmse: 0.0910529\n",
      "[2000]\ttraining's rmse: 0.086722\tvalid_1's rmse: 0.0910511\n",
      "[2025]\ttraining's rmse: 0.0867161\tvalid_1's rmse: 0.0910498\n",
      "[2050]\ttraining's rmse: 0.0867114\tvalid_1's rmse: 0.0910486\n",
      "[2075]\ttraining's rmse: 0.0867057\tvalid_1's rmse: 0.0910474\n",
      "[2100]\ttraining's rmse: 0.0867012\tvalid_1's rmse: 0.0910463\n",
      "[2125]\ttraining's rmse: 0.0866974\tvalid_1's rmse: 0.0910454\n",
      "[2150]\ttraining's rmse: 0.0866933\tvalid_1's rmse: 0.0910443\n",
      "[2175]\ttraining's rmse: 0.086689\tvalid_1's rmse: 0.0910417\n",
      "[2200]\ttraining's rmse: 0.0866847\tvalid_1's rmse: 0.0910408\n",
      "[2225]\ttraining's rmse: 0.0866806\tvalid_1's rmse: 0.0910392\n",
      "[2250]\ttraining's rmse: 0.0866769\tvalid_1's rmse: 0.0910381\n",
      "[2275]\ttraining's rmse: 0.0866719\tvalid_1's rmse: 0.0910366\n",
      "[2300]\ttraining's rmse: 0.0866685\tvalid_1's rmse: 0.0910344\n",
      "[2325]\ttraining's rmse: 0.0866649\tvalid_1's rmse: 0.0910343\n",
      "[2350]\ttraining's rmse: 0.0866619\tvalid_1's rmse: 0.0910339\n",
      "[2375]\ttraining's rmse: 0.086659\tvalid_1's rmse: 0.0910329\n",
      "[2400]\ttraining's rmse: 0.0866548\tvalid_1's rmse: 0.0910321\n",
      "[2425]\ttraining's rmse: 0.0866527\tvalid_1's rmse: 0.091031\n",
      "[2450]\ttraining's rmse: 0.0866507\tvalid_1's rmse: 0.0910307\n",
      "[2475]\ttraining's rmse: 0.0866475\tvalid_1's rmse: 0.0910299\n",
      "[2500]\ttraining's rmse: 0.0866443\tvalid_1's rmse: 0.0910294\n",
      "[2525]\ttraining's rmse: 0.0866418\tvalid_1's rmse: 0.0910285\n",
      "[2550]\ttraining's rmse: 0.0866382\tvalid_1's rmse: 0.0910282\n",
      "[2575]\ttraining's rmse: 0.0866354\tvalid_1's rmse: 0.0910277\n",
      "[2600]\ttraining's rmse: 0.0866336\tvalid_1's rmse: 0.0910274\n",
      "[2625]\ttraining's rmse: 0.0866316\tvalid_1's rmse: 0.0910264\n",
      "[2650]\ttraining's rmse: 0.0866292\tvalid_1's rmse: 0.0910253\n",
      "[2675]\ttraining's rmse: 0.0866263\tvalid_1's rmse: 0.0910244\n",
      "[2700]\ttraining's rmse: 0.0866239\tvalid_1's rmse: 0.091024\n",
      "[2725]\ttraining's rmse: 0.0866207\tvalid_1's rmse: 0.0910233\n",
      "[2750]\ttraining's rmse: 0.0866175\tvalid_1's rmse: 0.0910223\n",
      "[2775]\ttraining's rmse: 0.0866146\tvalid_1's rmse: 0.091022\n",
      "[2800]\ttraining's rmse: 0.0866131\tvalid_1's rmse: 0.0910222\n",
      "[2825]\ttraining's rmse: 0.0866111\tvalid_1's rmse: 0.091022\n",
      "[2850]\ttraining's rmse: 0.0866093\tvalid_1's rmse: 0.0910218\n",
      "[2875]\ttraining's rmse: 0.0866071\tvalid_1's rmse: 0.0910211\n",
      "[2900]\ttraining's rmse: 0.0866054\tvalid_1's rmse: 0.0910208\n",
      "[2925]\ttraining's rmse: 0.0866039\tvalid_1's rmse: 0.0910205\n",
      "[2950]\ttraining's rmse: 0.0866023\tvalid_1's rmse: 0.09102\n",
      "[2975]\ttraining's rmse: 0.0866003\tvalid_1's rmse: 0.09102\n",
      "[3000]\ttraining's rmse: 0.086598\tvalid_1's rmse: 0.0910196\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.086598\tvalid_1's rmse: 0.0910196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0901824\tvalid_1's rmse: 0.0924796\n",
      "[50]\ttraining's rmse: 0.0900152\tvalid_1's rmse: 0.0924227\n",
      "[75]\ttraining's rmse: 0.0898435\tvalid_1's rmse: 0.0923669\n",
      "[100]\ttraining's rmse: 0.0896904\tvalid_1's rmse: 0.0923183\n",
      "[125]\ttraining's rmse: 0.0895311\tvalid_1's rmse: 0.0922698\n",
      "[150]\ttraining's rmse: 0.0893899\tvalid_1's rmse: 0.0922248\n",
      "[175]\ttraining's rmse: 0.0892665\tvalid_1's rmse: 0.0921879\n",
      "[200]\ttraining's rmse: 0.0891395\tvalid_1's rmse: 0.0921496\n",
      "[225]\ttraining's rmse: 0.0890151\tvalid_1's rmse: 0.0921146\n",
      "[250]\ttraining's rmse: 0.0889097\tvalid_1's rmse: 0.0920824\n",
      "[275]\ttraining's rmse: 0.0888114\tvalid_1's rmse: 0.0920517\n",
      "[300]\ttraining's rmse: 0.088717\tvalid_1's rmse: 0.0920243\n",
      "[325]\ttraining's rmse: 0.08862\tvalid_1's rmse: 0.091996\n",
      "[350]\ttraining's rmse: 0.0885283\tvalid_1's rmse: 0.0919701\n",
      "[375]\ttraining's rmse: 0.0884557\tvalid_1's rmse: 0.0919475\n",
      "[400]\ttraining's rmse: 0.0883745\tvalid_1's rmse: 0.0919263\n",
      "[425]\ttraining's rmse: 0.0883012\tvalid_1's rmse: 0.0919056\n",
      "[450]\ttraining's rmse: 0.0882358\tvalid_1's rmse: 0.0918867\n",
      "[475]\ttraining's rmse: 0.0881732\tvalid_1's rmse: 0.0918691\n",
      "[500]\ttraining's rmse: 0.0881196\tvalid_1's rmse: 0.0918516\n",
      "[525]\ttraining's rmse: 0.0880531\tvalid_1's rmse: 0.0918351\n",
      "[550]\ttraining's rmse: 0.0879927\tvalid_1's rmse: 0.0918208\n",
      "[575]\ttraining's rmse: 0.0879373\tvalid_1's rmse: 0.0918063\n",
      "[600]\ttraining's rmse: 0.087887\tvalid_1's rmse: 0.0917936\n",
      "[625]\ttraining's rmse: 0.0878428\tvalid_1's rmse: 0.0917813\n",
      "[650]\ttraining's rmse: 0.0877906\tvalid_1's rmse: 0.0917688\n",
      "[675]\ttraining's rmse: 0.0877388\tvalid_1's rmse: 0.0917571\n",
      "[700]\ttraining's rmse: 0.0876946\tvalid_1's rmse: 0.0917457\n",
      "[725]\ttraining's rmse: 0.0876538\tvalid_1's rmse: 0.0917348\n",
      "[750]\ttraining's rmse: 0.087614\tvalid_1's rmse: 0.0917252\n",
      "[775]\ttraining's rmse: 0.0875803\tvalid_1's rmse: 0.091716\n",
      "[800]\ttraining's rmse: 0.0875385\tvalid_1's rmse: 0.0917073\n",
      "[825]\ttraining's rmse: 0.0875043\tvalid_1's rmse: 0.0916999\n",
      "[850]\ttraining's rmse: 0.0874685\tvalid_1's rmse: 0.0916922\n",
      "[875]\ttraining's rmse: 0.0874356\tvalid_1's rmse: 0.091686\n",
      "[900]\ttraining's rmse: 0.0874014\tvalid_1's rmse: 0.091678\n",
      "[925]\ttraining's rmse: 0.0873704\tvalid_1's rmse: 0.0916718\n",
      "[950]\ttraining's rmse: 0.087341\tvalid_1's rmse: 0.0916652\n",
      "[975]\ttraining's rmse: 0.0873117\tvalid_1's rmse: 0.0916596\n",
      "[1000]\ttraining's rmse: 0.0872852\tvalid_1's rmse: 0.0916547\n",
      "[1025]\ttraining's rmse: 0.0872556\tvalid_1's rmse: 0.0916503\n",
      "[1050]\ttraining's rmse: 0.087232\tvalid_1's rmse: 0.0916462\n",
      "[1075]\ttraining's rmse: 0.0872057\tvalid_1's rmse: 0.0916425\n",
      "[1100]\ttraining's rmse: 0.0871859\tvalid_1's rmse: 0.0916384\n",
      "[1125]\ttraining's rmse: 0.087164\tvalid_1's rmse: 0.0916344\n",
      "[1150]\ttraining's rmse: 0.0871419\tvalid_1's rmse: 0.0916309\n",
      "[1175]\ttraining's rmse: 0.0871249\tvalid_1's rmse: 0.091629\n",
      "[1200]\ttraining's rmse: 0.0871052\tvalid_1's rmse: 0.0916254\n",
      "[1225]\ttraining's rmse: 0.0870882\tvalid_1's rmse: 0.091623\n",
      "[1250]\ttraining's rmse: 0.0870705\tvalid_1's rmse: 0.0916207\n",
      "[1275]\ttraining's rmse: 0.0870505\tvalid_1's rmse: 0.0916187\n",
      "[1300]\ttraining's rmse: 0.0870345\tvalid_1's rmse: 0.0916165\n",
      "[1325]\ttraining's rmse: 0.0870182\tvalid_1's rmse: 0.0916143\n",
      "[1350]\ttraining's rmse: 0.0870004\tvalid_1's rmse: 0.0916119\n",
      "[1375]\ttraining's rmse: 0.0869837\tvalid_1's rmse: 0.0916104\n",
      "[1400]\ttraining's rmse: 0.0869727\tvalid_1's rmse: 0.0916076\n",
      "[1425]\ttraining's rmse: 0.0869577\tvalid_1's rmse: 0.0916063\n",
      "[1450]\ttraining's rmse: 0.0869441\tvalid_1's rmse: 0.0916053\n",
      "[1475]\ttraining's rmse: 0.086931\tvalid_1's rmse: 0.0916037\n",
      "[1500]\ttraining's rmse: 0.0869203\tvalid_1's rmse: 0.0916015\n",
      "[1525]\ttraining's rmse: 0.0869102\tvalid_1's rmse: 0.0916006\n",
      "[1550]\ttraining's rmse: 0.0868986\tvalid_1's rmse: 0.0915995\n",
      "[1575]\ttraining's rmse: 0.0868884\tvalid_1's rmse: 0.0915985\n",
      "[1600]\ttraining's rmse: 0.0868775\tvalid_1's rmse: 0.0915978\n",
      "[1625]\ttraining's rmse: 0.0868694\tvalid_1's rmse: 0.0915971\n",
      "[1650]\ttraining's rmse: 0.0868587\tvalid_1's rmse: 0.0915963\n",
      "[1675]\ttraining's rmse: 0.0868516\tvalid_1's rmse: 0.0915952\n",
      "[1700]\ttraining's rmse: 0.0868433\tvalid_1's rmse: 0.0915941\n",
      "[1725]\ttraining's rmse: 0.0868364\tvalid_1's rmse: 0.0915929\n",
      "[1750]\ttraining's rmse: 0.0868292\tvalid_1's rmse: 0.0915919\n",
      "[1775]\ttraining's rmse: 0.0868218\tvalid_1's rmse: 0.0915914\n",
      "[1800]\ttraining's rmse: 0.0868132\tvalid_1's rmse: 0.0915907\n",
      "[1825]\ttraining's rmse: 0.0868034\tvalid_1's rmse: 0.0915898\n",
      "[1850]\ttraining's rmse: 0.0867971\tvalid_1's rmse: 0.0915881\n",
      "[1875]\ttraining's rmse: 0.0867919\tvalid_1's rmse: 0.0915879\n",
      "[1900]\ttraining's rmse: 0.0867869\tvalid_1's rmse: 0.0915874\n",
      "[1925]\ttraining's rmse: 0.0867814\tvalid_1's rmse: 0.0915863\n",
      "[1950]\ttraining's rmse: 0.0867763\tvalid_1's rmse: 0.0915856\n",
      "[1975]\ttraining's rmse: 0.0867719\tvalid_1's rmse: 0.0915853\n",
      "[2000]\ttraining's rmse: 0.0867641\tvalid_1's rmse: 0.0915844\n",
      "[2025]\ttraining's rmse: 0.0867596\tvalid_1's rmse: 0.0915837\n",
      "[2050]\ttraining's rmse: 0.086755\tvalid_1's rmse: 0.0915836\n",
      "[2075]\ttraining's rmse: 0.0867498\tvalid_1's rmse: 0.0915827\n",
      "[2100]\ttraining's rmse: 0.0867441\tvalid_1's rmse: 0.0915823\n",
      "[2125]\ttraining's rmse: 0.0867389\tvalid_1's rmse: 0.0915818\n",
      "[2150]\ttraining's rmse: 0.0867346\tvalid_1's rmse: 0.0915813\n",
      "[2175]\ttraining's rmse: 0.0867307\tvalid_1's rmse: 0.091581\n",
      "[2200]\ttraining's rmse: 0.0867267\tvalid_1's rmse: 0.0915805\n",
      "[2225]\ttraining's rmse: 0.0867234\tvalid_1's rmse: 0.0915802\n",
      "[2250]\ttraining's rmse: 0.0867207\tvalid_1's rmse: 0.0915801\n",
      "[2275]\ttraining's rmse: 0.0867173\tvalid_1's rmse: 0.0915798\n",
      "[2300]\ttraining's rmse: 0.0867141\tvalid_1's rmse: 0.0915798\n",
      "[2325]\ttraining's rmse: 0.0867112\tvalid_1's rmse: 0.0915792\n",
      "[2350]\ttraining's rmse: 0.0867083\tvalid_1's rmse: 0.0915789\n",
      "[2375]\ttraining's rmse: 0.0867053\tvalid_1's rmse: 0.0915783\n",
      "[2400]\ttraining's rmse: 0.0867018\tvalid_1's rmse: 0.0915786\n",
      "[2425]\ttraining's rmse: 0.0866992\tvalid_1's rmse: 0.0915789\n",
      "Early stopping, best iteration is:\n",
      "[2384]\ttraining's rmse: 0.0867038\tvalid_1's rmse: 0.0915782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0921111\tvalid_1's rmse: 0.0886547\n",
      "[50]\ttraining's rmse: 0.091975\tvalid_1's rmse: 0.0886056\n",
      "[75]\ttraining's rmse: 0.0918314\tvalid_1's rmse: 0.0885574\n",
      "[100]\ttraining's rmse: 0.0917033\tvalid_1's rmse: 0.088516\n",
      "[125]\ttraining's rmse: 0.0915725\tvalid_1's rmse: 0.0884765\n",
      "[150]\ttraining's rmse: 0.0914483\tvalid_1's rmse: 0.0884375\n",
      "[175]\ttraining's rmse: 0.0913477\tvalid_1's rmse: 0.0884065\n",
      "[200]\ttraining's rmse: 0.0912368\tvalid_1's rmse: 0.088375\n",
      "[225]\ttraining's rmse: 0.0911294\tvalid_1's rmse: 0.0883447\n",
      "[250]\ttraining's rmse: 0.0910412\tvalid_1's rmse: 0.08832\n",
      "[275]\ttraining's rmse: 0.0909574\tvalid_1's rmse: 0.0882963\n",
      "[300]\ttraining's rmse: 0.0908725\tvalid_1's rmse: 0.0882728\n",
      "[325]\ttraining's rmse: 0.09079\tvalid_1's rmse: 0.088253\n",
      "[350]\ttraining's rmse: 0.0907103\tvalid_1's rmse: 0.0882332\n",
      "[375]\ttraining's rmse: 0.0906442\tvalid_1's rmse: 0.0882167\n",
      "[400]\ttraining's rmse: 0.0905699\tvalid_1's rmse: 0.0882053\n",
      "[425]\ttraining's rmse: 0.0905023\tvalid_1's rmse: 0.0881889\n",
      "[450]\ttraining's rmse: 0.0904406\tvalid_1's rmse: 0.0881743\n",
      "[475]\ttraining's rmse: 0.0903815\tvalid_1's rmse: 0.0881618\n",
      "[500]\ttraining's rmse: 0.0903344\tvalid_1's rmse: 0.0881501\n",
      "[525]\ttraining's rmse: 0.0902692\tvalid_1's rmse: 0.0881442\n",
      "[550]\ttraining's rmse: 0.0902098\tvalid_1's rmse: 0.0881322\n",
      "[575]\ttraining's rmse: 0.0901535\tvalid_1's rmse: 0.0881227\n",
      "[600]\ttraining's rmse: 0.0901007\tvalid_1's rmse: 0.0881149\n",
      "[625]\ttraining's rmse: 0.0900605\tvalid_1's rmse: 0.0881065\n",
      "[650]\ttraining's rmse: 0.090006\tvalid_1's rmse: 0.0881025\n",
      "[675]\ttraining's rmse: 0.0899542\tvalid_1's rmse: 0.0881003\n",
      "[700]\ttraining's rmse: 0.0899082\tvalid_1's rmse: 0.0880985\n",
      "[725]\ttraining's rmse: 0.0898649\tvalid_1's rmse: 0.0881053\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0899203\tvalid_1's rmse: 0.0880949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876176\tvalid_1's rmse: 0.0902643\n",
      "[50]\ttraining's rmse: 0.0874803\tvalid_1's rmse: 0.0902077\n",
      "[75]\ttraining's rmse: 0.0873423\tvalid_1's rmse: 0.0901503\n",
      "[100]\ttraining's rmse: 0.087215\tvalid_1's rmse: 0.0901022\n",
      "[125]\ttraining's rmse: 0.0870883\tvalid_1's rmse: 0.0900525\n",
      "[150]\ttraining's rmse: 0.0869712\tvalid_1's rmse: 0.0900055\n",
      "[175]\ttraining's rmse: 0.0868698\tvalid_1's rmse: 0.0899656\n",
      "[200]\ttraining's rmse: 0.0867671\tvalid_1's rmse: 0.0899265\n",
      "[225]\ttraining's rmse: 0.0866663\tvalid_1's rmse: 0.089889\n",
      "[250]\ttraining's rmse: 0.0865809\tvalid_1's rmse: 0.0898543\n",
      "[275]\ttraining's rmse: 0.0864986\tvalid_1's rmse: 0.0898228\n",
      "[300]\ttraining's rmse: 0.0864207\tvalid_1's rmse: 0.0897942\n",
      "[325]\ttraining's rmse: 0.0863425\tvalid_1's rmse: 0.089767\n",
      "[350]\ttraining's rmse: 0.0862674\tvalid_1's rmse: 0.089739\n",
      "[375]\ttraining's rmse: 0.0862023\tvalid_1's rmse: 0.0897164\n",
      "[400]\ttraining's rmse: 0.0861342\tvalid_1's rmse: 0.0896957\n",
      "[425]\ttraining's rmse: 0.0860678\tvalid_1's rmse: 0.089674\n",
      "[450]\ttraining's rmse: 0.0860107\tvalid_1's rmse: 0.0896526\n",
      "[475]\ttraining's rmse: 0.0859594\tvalid_1's rmse: 0.0896331\n",
      "[500]\ttraining's rmse: 0.0859121\tvalid_1's rmse: 0.0896145\n",
      "[525]\ttraining's rmse: 0.0858528\tvalid_1's rmse: 0.0895964\n",
      "[550]\ttraining's rmse: 0.0858001\tvalid_1's rmse: 0.0895812\n",
      "[575]\ttraining's rmse: 0.0857522\tvalid_1's rmse: 0.089567\n",
      "[600]\ttraining's rmse: 0.0857037\tvalid_1's rmse: 0.0895531\n",
      "[625]\ttraining's rmse: 0.0856653\tvalid_1's rmse: 0.0895387\n",
      "[650]\ttraining's rmse: 0.0856207\tvalid_1's rmse: 0.0895262\n",
      "[675]\ttraining's rmse: 0.0855793\tvalid_1's rmse: 0.0895141\n",
      "[700]\ttraining's rmse: 0.0855385\tvalid_1's rmse: 0.0895014\n",
      "[725]\ttraining's rmse: 0.0854995\tvalid_1's rmse: 0.08949\n",
      "[750]\ttraining's rmse: 0.0854645\tvalid_1's rmse: 0.0894787\n",
      "[775]\ttraining's rmse: 0.0854355\tvalid_1's rmse: 0.0894681\n",
      "[800]\ttraining's rmse: 0.0854001\tvalid_1's rmse: 0.0894593\n",
      "[825]\ttraining's rmse: 0.0853722\tvalid_1's rmse: 0.0894504\n",
      "[850]\ttraining's rmse: 0.0853392\tvalid_1's rmse: 0.0894413\n",
      "[875]\ttraining's rmse: 0.0853111\tvalid_1's rmse: 0.0894339\n",
      "[900]\ttraining's rmse: 0.0852832\tvalid_1's rmse: 0.0894264\n",
      "[925]\ttraining's rmse: 0.0852537\tvalid_1's rmse: 0.0894183\n",
      "[950]\ttraining's rmse: 0.0852263\tvalid_1's rmse: 0.089412\n",
      "[975]\ttraining's rmse: 0.0852005\tvalid_1's rmse: 0.0894056\n",
      "[1000]\ttraining's rmse: 0.0851764\tvalid_1's rmse: 0.0893999\n",
      "[1025]\ttraining's rmse: 0.0851511\tvalid_1's rmse: 0.0893937\n",
      "[1050]\ttraining's rmse: 0.0851282\tvalid_1's rmse: 0.0893858\n",
      "[1075]\ttraining's rmse: 0.0851076\tvalid_1's rmse: 0.0893817\n",
      "[1100]\ttraining's rmse: 0.0850905\tvalid_1's rmse: 0.0893764\n",
      "[1125]\ttraining's rmse: 0.0850729\tvalid_1's rmse: 0.089371\n",
      "[1150]\ttraining's rmse: 0.0850545\tvalid_1's rmse: 0.0893673\n",
      "[1175]\ttraining's rmse: 0.0850368\tvalid_1's rmse: 0.0893628\n",
      "[1200]\ttraining's rmse: 0.0850199\tvalid_1's rmse: 0.0893581\n",
      "[1225]\ttraining's rmse: 0.0850043\tvalid_1's rmse: 0.089353\n",
      "[1250]\ttraining's rmse: 0.0849872\tvalid_1's rmse: 0.0893489\n",
      "[1275]\ttraining's rmse: 0.0849694\tvalid_1's rmse: 0.0893449\n",
      "[1300]\ttraining's rmse: 0.0849557\tvalid_1's rmse: 0.0893395\n",
      "[1325]\ttraining's rmse: 0.0849384\tvalid_1's rmse: 0.089336\n",
      "[1350]\ttraining's rmse: 0.0849224\tvalid_1's rmse: 0.089332\n",
      "[1375]\ttraining's rmse: 0.0849085\tvalid_1's rmse: 0.0893299\n",
      "[1400]\ttraining's rmse: 0.0848973\tvalid_1's rmse: 0.0893251\n",
      "[1425]\ttraining's rmse: 0.0848843\tvalid_1's rmse: 0.089323\n",
      "[1450]\ttraining's rmse: 0.0848686\tvalid_1's rmse: 0.0893206\n",
      "[1475]\ttraining's rmse: 0.0848592\tvalid_1's rmse: 0.0893178\n",
      "[1500]\ttraining's rmse: 0.0848463\tvalid_1's rmse: 0.0893146\n",
      "[1525]\ttraining's rmse: 0.0848368\tvalid_1's rmse: 0.0893121\n",
      "[1550]\ttraining's rmse: 0.0848264\tvalid_1's rmse: 0.0893095\n",
      "[1575]\ttraining's rmse: 0.084819\tvalid_1's rmse: 0.0893059\n",
      "[1600]\ttraining's rmse: 0.0848104\tvalid_1's rmse: 0.0893029\n",
      "[1625]\ttraining's rmse: 0.0848012\tvalid_1's rmse: 0.0893\n",
      "[1650]\ttraining's rmse: 0.0847916\tvalid_1's rmse: 0.0892973\n",
      "[1675]\ttraining's rmse: 0.0847856\tvalid_1's rmse: 0.0892949\n",
      "[1700]\ttraining's rmse: 0.0847804\tvalid_1's rmse: 0.0892921\n",
      "[1725]\ttraining's rmse: 0.0847732\tvalid_1's rmse: 0.0892908\n",
      "[1750]\ttraining's rmse: 0.0847649\tvalid_1's rmse: 0.089288\n",
      "[1775]\ttraining's rmse: 0.0847588\tvalid_1's rmse: 0.0892868\n",
      "[1800]\ttraining's rmse: 0.084752\tvalid_1's rmse: 0.0892853\n",
      "[1825]\ttraining's rmse: 0.0847458\tvalid_1's rmse: 0.0892838\n",
      "[1850]\ttraining's rmse: 0.0847396\tvalid_1's rmse: 0.0892817\n",
      "[1875]\ttraining's rmse: 0.0847325\tvalid_1's rmse: 0.0892803\n",
      "[1900]\ttraining's rmse: 0.0847284\tvalid_1's rmse: 0.0892795\n",
      "[1925]\ttraining's rmse: 0.0847251\tvalid_1's rmse: 0.0892789\n",
      "[1950]\ttraining's rmse: 0.0847205\tvalid_1's rmse: 0.0892779\n",
      "[1975]\ttraining's rmse: 0.0847161\tvalid_1's rmse: 0.0892773\n",
      "[2000]\ttraining's rmse: 0.084712\tvalid_1's rmse: 0.0892758\n",
      "[2025]\ttraining's rmse: 0.0847087\tvalid_1's rmse: 0.0892742\n",
      "[2050]\ttraining's rmse: 0.0847037\tvalid_1's rmse: 0.0892735\n",
      "[2075]\ttraining's rmse: 0.0847002\tvalid_1's rmse: 0.0892721\n",
      "[2100]\ttraining's rmse: 0.0846962\tvalid_1's rmse: 0.0892704\n",
      "[2125]\ttraining's rmse: 0.0846936\tvalid_1's rmse: 0.0892693\n",
      "[2150]\ttraining's rmse: 0.0846898\tvalid_1's rmse: 0.0892676\n",
      "[2175]\ttraining's rmse: 0.0846853\tvalid_1's rmse: 0.0892661\n",
      "[2200]\ttraining's rmse: 0.0846821\tvalid_1's rmse: 0.0892651\n",
      "[2225]\ttraining's rmse: 0.0846787\tvalid_1's rmse: 0.089264\n",
      "[2250]\ttraining's rmse: 0.0846759\tvalid_1's rmse: 0.0892635\n",
      "[2275]\ttraining's rmse: 0.0846726\tvalid_1's rmse: 0.0892634\n",
      "[2300]\ttraining's rmse: 0.0846685\tvalid_1's rmse: 0.0892623\n",
      "[2325]\ttraining's rmse: 0.084665\tvalid_1's rmse: 0.0892612\n",
      "[2350]\ttraining's rmse: 0.0846627\tvalid_1's rmse: 0.0892609\n",
      "[2375]\ttraining's rmse: 0.0846587\tvalid_1's rmse: 0.0892595\n",
      "[2400]\ttraining's rmse: 0.0846547\tvalid_1's rmse: 0.0892589\n",
      "[2425]\ttraining's rmse: 0.0846514\tvalid_1's rmse: 0.0892588\n",
      "[2450]\ttraining's rmse: 0.0846496\tvalid_1's rmse: 0.0892579\n",
      "[2475]\ttraining's rmse: 0.0846465\tvalid_1's rmse: 0.0892578\n",
      "[2500]\ttraining's rmse: 0.0846441\tvalid_1's rmse: 0.0892575\n",
      "[2525]\ttraining's rmse: 0.0846421\tvalid_1's rmse: 0.0892566\n",
      "[2550]\ttraining's rmse: 0.0846406\tvalid_1's rmse: 0.0892558\n",
      "[2575]\ttraining's rmse: 0.0846388\tvalid_1's rmse: 0.0892558\n",
      "[2600]\ttraining's rmse: 0.0846368\tvalid_1's rmse: 0.0892553\n",
      "[2625]\ttraining's rmse: 0.084636\tvalid_1's rmse: 0.0892555\n",
      "[2650]\ttraining's rmse: 0.0846334\tvalid_1's rmse: 0.0892553\n",
      "Early stopping, best iteration is:\n",
      "[2605]\ttraining's rmse: 0.0846365\tvalid_1's rmse: 0.0892551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0876787\tvalid_1's rmse: 0.0901527\n",
      "[50]\ttraining's rmse: 0.0875528\tvalid_1's rmse: 0.0900947\n",
      "[75]\ttraining's rmse: 0.0874235\tvalid_1's rmse: 0.0900397\n",
      "[100]\ttraining's rmse: 0.0873041\tvalid_1's rmse: 0.0899888\n",
      "[125]\ttraining's rmse: 0.0871804\tvalid_1's rmse: 0.0899394\n",
      "[150]\ttraining's rmse: 0.0870676\tvalid_1's rmse: 0.0898922\n",
      "[175]\ttraining's rmse: 0.0869764\tvalid_1's rmse: 0.0898563\n",
      "[200]\ttraining's rmse: 0.0868767\tvalid_1's rmse: 0.0898194\n",
      "[225]\ttraining's rmse: 0.0867815\tvalid_1's rmse: 0.0897845\n",
      "[250]\ttraining's rmse: 0.0866982\tvalid_1's rmse: 0.0897524\n",
      "[275]\ttraining's rmse: 0.0866196\tvalid_1's rmse: 0.0897232\n",
      "[300]\ttraining's rmse: 0.0865411\tvalid_1's rmse: 0.0896949\n",
      "[325]\ttraining's rmse: 0.0864622\tvalid_1's rmse: 0.0896682\n",
      "[350]\ttraining's rmse: 0.0863867\tvalid_1's rmse: 0.0896418\n",
      "[375]\ttraining's rmse: 0.0863276\tvalid_1's rmse: 0.0896205\n",
      "[400]\ttraining's rmse: 0.0862617\tvalid_1's rmse: 0.0896002\n",
      "[425]\ttraining's rmse: 0.0861988\tvalid_1's rmse: 0.0895799\n",
      "[450]\ttraining's rmse: 0.0861419\tvalid_1's rmse: 0.0895609\n",
      "[475]\ttraining's rmse: 0.0860876\tvalid_1's rmse: 0.0895434\n",
      "[500]\ttraining's rmse: 0.086043\tvalid_1's rmse: 0.0895271\n",
      "[525]\ttraining's rmse: 0.0859851\tvalid_1's rmse: 0.0895102\n",
      "[550]\ttraining's rmse: 0.0859296\tvalid_1's rmse: 0.089494\n",
      "[575]\ttraining's rmse: 0.0858797\tvalid_1's rmse: 0.0894799\n",
      "[600]\ttraining's rmse: 0.0858332\tvalid_1's rmse: 0.0894661\n",
      "[625]\ttraining's rmse: 0.0857962\tvalid_1's rmse: 0.0894535\n",
      "[650]\ttraining's rmse: 0.0857503\tvalid_1's rmse: 0.0894411\n",
      "[675]\ttraining's rmse: 0.0857034\tvalid_1's rmse: 0.0894292\n",
      "[700]\ttraining's rmse: 0.0856607\tvalid_1's rmse: 0.0894182\n",
      "[725]\ttraining's rmse: 0.0856227\tvalid_1's rmse: 0.0894082\n",
      "[750]\ttraining's rmse: 0.0855882\tvalid_1's rmse: 0.0893996\n",
      "[775]\ttraining's rmse: 0.0855577\tvalid_1's rmse: 0.0893905\n",
      "[800]\ttraining's rmse: 0.0855195\tvalid_1's rmse: 0.0893826\n",
      "[825]\ttraining's rmse: 0.0854884\tvalid_1's rmse: 0.0893747\n",
      "[850]\ttraining's rmse: 0.0854552\tvalid_1's rmse: 0.0893668\n",
      "[875]\ttraining's rmse: 0.0854271\tvalid_1's rmse: 0.0893601\n",
      "[900]\ttraining's rmse: 0.085397\tvalid_1's rmse: 0.0893536\n",
      "[925]\ttraining's rmse: 0.0853679\tvalid_1's rmse: 0.089347\n",
      "[950]\ttraining's rmse: 0.0853413\tvalid_1's rmse: 0.0893412\n",
      "[975]\ttraining's rmse: 0.0853159\tvalid_1's rmse: 0.0893357\n",
      "[1000]\ttraining's rmse: 0.0852916\tvalid_1's rmse: 0.0893293\n",
      "[1025]\ttraining's rmse: 0.0852669\tvalid_1's rmse: 0.0893251\n",
      "[1050]\ttraining's rmse: 0.0852444\tvalid_1's rmse: 0.0893206\n",
      "[1075]\ttraining's rmse: 0.0852234\tvalid_1's rmse: 0.0893173\n",
      "[1100]\ttraining's rmse: 0.0852056\tvalid_1's rmse: 0.0893131\n",
      "[1125]\ttraining's rmse: 0.0851842\tvalid_1's rmse: 0.0893099\n",
      "[1150]\ttraining's rmse: 0.0851633\tvalid_1's rmse: 0.0893068\n",
      "[1175]\ttraining's rmse: 0.0851485\tvalid_1's rmse: 0.0893043\n",
      "[1200]\ttraining's rmse: 0.0851304\tvalid_1's rmse: 0.089301\n",
      "[1225]\ttraining's rmse: 0.0851132\tvalid_1's rmse: 0.0892984\n",
      "[1250]\ttraining's rmse: 0.0850984\tvalid_1's rmse: 0.0892957\n",
      "[1275]\ttraining's rmse: 0.0850792\tvalid_1's rmse: 0.0892941\n",
      "[1300]\ttraining's rmse: 0.0850652\tvalid_1's rmse: 0.0892921\n",
      "[1325]\ttraining's rmse: 0.0850516\tvalid_1's rmse: 0.0892902\n",
      "[1350]\ttraining's rmse: 0.0850363\tvalid_1's rmse: 0.0892882\n",
      "[1375]\ttraining's rmse: 0.0850241\tvalid_1's rmse: 0.0892867\n",
      "[1400]\ttraining's rmse: 0.0850092\tvalid_1's rmse: 0.0892842\n",
      "[1425]\ttraining's rmse: 0.0849936\tvalid_1's rmse: 0.0892821\n",
      "[1450]\ttraining's rmse: 0.0849793\tvalid_1's rmse: 0.0892808\n",
      "[1475]\ttraining's rmse: 0.0849695\tvalid_1's rmse: 0.089279\n",
      "[1500]\ttraining's rmse: 0.0849574\tvalid_1's rmse: 0.0892776\n",
      "[1525]\ttraining's rmse: 0.0849445\tvalid_1's rmse: 0.0892761\n",
      "[1550]\ttraining's rmse: 0.0849348\tvalid_1's rmse: 0.0892753\n",
      "[1575]\ttraining's rmse: 0.0849249\tvalid_1's rmse: 0.0892733\n",
      "[1600]\ttraining's rmse: 0.0849163\tvalid_1's rmse: 0.0892727\n",
      "[1625]\ttraining's rmse: 0.0849071\tvalid_1's rmse: 0.089272\n",
      "[1650]\ttraining's rmse: 0.0848991\tvalid_1's rmse: 0.0892711\n",
      "[1675]\ttraining's rmse: 0.0848911\tvalid_1's rmse: 0.0892699\n",
      "[1700]\ttraining's rmse: 0.0848856\tvalid_1's rmse: 0.0892689\n",
      "[1725]\ttraining's rmse: 0.0848789\tvalid_1's rmse: 0.0892676\n",
      "[1750]\ttraining's rmse: 0.0848702\tvalid_1's rmse: 0.0892666\n",
      "[1775]\ttraining's rmse: 0.084863\tvalid_1's rmse: 0.0892662\n",
      "[1800]\ttraining's rmse: 0.0848559\tvalid_1's rmse: 0.0892653\n",
      "[1825]\ttraining's rmse: 0.0848488\tvalid_1's rmse: 0.0892643\n",
      "[1850]\ttraining's rmse: 0.0848438\tvalid_1's rmse: 0.0892633\n",
      "[1875]\ttraining's rmse: 0.0848378\tvalid_1's rmse: 0.089263\n",
      "[1900]\ttraining's rmse: 0.084832\tvalid_1's rmse: 0.0892628\n",
      "[1925]\ttraining's rmse: 0.0848264\tvalid_1's rmse: 0.0892624\n",
      "[1950]\ttraining's rmse: 0.0848217\tvalid_1's rmse: 0.0892612\n",
      "[1975]\ttraining's rmse: 0.0848172\tvalid_1's rmse: 0.0892608\n",
      "[2000]\ttraining's rmse: 0.0848113\tvalid_1's rmse: 0.0892601\n",
      "[2025]\ttraining's rmse: 0.084807\tvalid_1's rmse: 0.0892599\n",
      "[2050]\ttraining's rmse: 0.0848031\tvalid_1's rmse: 0.0892596\n",
      "[2075]\ttraining's rmse: 0.0847992\tvalid_1's rmse: 0.0892596\n",
      "[2100]\ttraining's rmse: 0.0847949\tvalid_1's rmse: 0.0892591\n",
      "[2125]\ttraining's rmse: 0.0847919\tvalid_1's rmse: 0.0892589\n",
      "[2150]\ttraining's rmse: 0.0847868\tvalid_1's rmse: 0.089259\n",
      "[2175]\ttraining's rmse: 0.0847846\tvalid_1's rmse: 0.0892592\n",
      "Early stopping, best iteration is:\n",
      "[2134]\ttraining's rmse: 0.0847901\tvalid_1's rmse: 0.0892588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0900838\tvalid_1's rmse: 0.0852756\n",
      "[50]\ttraining's rmse: 0.0899634\tvalid_1's rmse: 0.0852251\n",
      "[75]\ttraining's rmse: 0.0898386\tvalid_1's rmse: 0.0851769\n",
      "[100]\ttraining's rmse: 0.0897283\tvalid_1's rmse: 0.0851336\n",
      "[125]\ttraining's rmse: 0.0896107\tvalid_1's rmse: 0.085091\n",
      "[150]\ttraining's rmse: 0.089506\tvalid_1's rmse: 0.0850545\n",
      "[175]\ttraining's rmse: 0.0894185\tvalid_1's rmse: 0.0850231\n",
      "[200]\ttraining's rmse: 0.089323\tvalid_1's rmse: 0.0849912\n",
      "[225]\ttraining's rmse: 0.08923\tvalid_1's rmse: 0.0849604\n",
      "[250]\ttraining's rmse: 0.0891521\tvalid_1's rmse: 0.0849335\n",
      "[275]\ttraining's rmse: 0.0890804\tvalid_1's rmse: 0.0849086\n",
      "[300]\ttraining's rmse: 0.0890062\tvalid_1's rmse: 0.0848861\n",
      "[325]\ttraining's rmse: 0.0889339\tvalid_1's rmse: 0.0848625\n",
      "[350]\ttraining's rmse: 0.0888614\tvalid_1's rmse: 0.0848396\n",
      "[375]\ttraining's rmse: 0.0888027\tvalid_1's rmse: 0.0848221\n",
      "[400]\ttraining's rmse: 0.08874\tvalid_1's rmse: 0.0848143\n",
      "[425]\ttraining's rmse: 0.088681\tvalid_1's rmse: 0.0847983\n",
      "[450]\ttraining's rmse: 0.0886278\tvalid_1's rmse: 0.084785\n",
      "[475]\ttraining's rmse: 0.0885771\tvalid_1's rmse: 0.0847756\n",
      "[500]\ttraining's rmse: 0.0885339\tvalid_1's rmse: 0.0847617\n",
      "[525]\ttraining's rmse: 0.088475\tvalid_1's rmse: 0.0847457\n",
      "[550]\ttraining's rmse: 0.0884234\tvalid_1's rmse: 0.0847339\n",
      "[575]\ttraining's rmse: 0.0883746\tvalid_1's rmse: 0.084722\n",
      "[600]\ttraining's rmse: 0.0883281\tvalid_1's rmse: 0.0847227\n",
      "[625]\ttraining's rmse: 0.0882914\tvalid_1's rmse: 0.0847171\n",
      "[650]\ttraining's rmse: 0.0882461\tvalid_1's rmse: 0.0847121\n",
      "[675]\ttraining's rmse: 0.088199\tvalid_1's rmse: 0.0847084\n",
      "[700]\ttraining's rmse: 0.0881577\tvalid_1's rmse: 0.0846997\n",
      "[725]\ttraining's rmse: 0.0881187\tvalid_1's rmse: 0.0847034\n",
      "[750]\ttraining's rmse: 0.0880838\tvalid_1's rmse: 0.0846957\n",
      "[775]\ttraining's rmse: 0.0880514\tvalid_1's rmse: 0.0846902\n",
      "[800]\ttraining's rmse: 0.0880131\tvalid_1's rmse: 0.0846902\n",
      "[825]\ttraining's rmse: 0.0879796\tvalid_1's rmse: 0.0846908\n",
      "[850]\ttraining's rmse: 0.087948\tvalid_1's rmse: 0.0846901\n",
      "Early stopping, best iteration is:\n",
      "[815]\ttraining's rmse: 0.0879936\tvalid_1's rmse: 0.0846863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.091118\tvalid_1's rmse: 0.0929227\n",
      "[50]\ttraining's rmse: 0.0909257\tvalid_1's rmse: 0.0928671\n",
      "[75]\ttraining's rmse: 0.0907341\tvalid_1's rmse: 0.0928125\n",
      "[100]\ttraining's rmse: 0.0905567\tvalid_1's rmse: 0.0927651\n",
      "[125]\ttraining's rmse: 0.0903868\tvalid_1's rmse: 0.0927165\n",
      "[150]\ttraining's rmse: 0.0902293\tvalid_1's rmse: 0.092673\n",
      "[175]\ttraining's rmse: 0.0900954\tvalid_1's rmse: 0.0926327\n",
      "[200]\ttraining's rmse: 0.0899514\tvalid_1's rmse: 0.0925943\n",
      "[225]\ttraining's rmse: 0.0898205\tvalid_1's rmse: 0.0925606\n",
      "[250]\ttraining's rmse: 0.0897048\tvalid_1's rmse: 0.0925266\n",
      "[275]\ttraining's rmse: 0.0895933\tvalid_1's rmse: 0.0924971\n",
      "[300]\ttraining's rmse: 0.0894864\tvalid_1's rmse: 0.0924693\n",
      "[325]\ttraining's rmse: 0.0893799\tvalid_1's rmse: 0.0924431\n",
      "[350]\ttraining's rmse: 0.089281\tvalid_1's rmse: 0.0924157\n",
      "[375]\ttraining's rmse: 0.0891934\tvalid_1's rmse: 0.0923931\n",
      "[400]\ttraining's rmse: 0.0891046\tvalid_1's rmse: 0.0923712\n",
      "[425]\ttraining's rmse: 0.0890229\tvalid_1's rmse: 0.0923507\n",
      "[450]\ttraining's rmse: 0.0889521\tvalid_1's rmse: 0.0923301\n",
      "[475]\ttraining's rmse: 0.0888814\tvalid_1's rmse: 0.0923096\n",
      "[500]\ttraining's rmse: 0.0888194\tvalid_1's rmse: 0.0922932\n",
      "[525]\ttraining's rmse: 0.0887457\tvalid_1's rmse: 0.0922737\n",
      "[550]\ttraining's rmse: 0.0886842\tvalid_1's rmse: 0.0922582\n",
      "[575]\ttraining's rmse: 0.0886214\tvalid_1's rmse: 0.0922431\n",
      "[600]\ttraining's rmse: 0.0885616\tvalid_1's rmse: 0.0922279\n",
      "[625]\ttraining's rmse: 0.0885146\tvalid_1's rmse: 0.0922155\n",
      "[650]\ttraining's rmse: 0.0884582\tvalid_1's rmse: 0.0922013\n",
      "[675]\ttraining's rmse: 0.0884026\tvalid_1's rmse: 0.0921894\n",
      "[700]\ttraining's rmse: 0.088353\tvalid_1's rmse: 0.0921771\n",
      "[725]\ttraining's rmse: 0.088306\tvalid_1's rmse: 0.0921657\n",
      "[750]\ttraining's rmse: 0.0882628\tvalid_1's rmse: 0.0921545\n",
      "[775]\ttraining's rmse: 0.0882259\tvalid_1's rmse: 0.0921451\n",
      "[800]\ttraining's rmse: 0.0881792\tvalid_1's rmse: 0.0921354\n",
      "[825]\ttraining's rmse: 0.0881412\tvalid_1's rmse: 0.092125\n",
      "[850]\ttraining's rmse: 0.0880986\tvalid_1's rmse: 0.0921178\n",
      "[875]\ttraining's rmse: 0.0880655\tvalid_1's rmse: 0.09211\n",
      "[900]\ttraining's rmse: 0.0880287\tvalid_1's rmse: 0.0921019\n",
      "[925]\ttraining's rmse: 0.0879958\tvalid_1's rmse: 0.0920935\n",
      "[950]\ttraining's rmse: 0.0879652\tvalid_1's rmse: 0.0920864\n",
      "[975]\ttraining's rmse: 0.087934\tvalid_1's rmse: 0.0920806\n",
      "[1000]\ttraining's rmse: 0.0879066\tvalid_1's rmse: 0.0920735\n",
      "[1025]\ttraining's rmse: 0.0878756\tvalid_1's rmse: 0.0920672\n",
      "[1050]\ttraining's rmse: 0.0878498\tvalid_1's rmse: 0.0920595\n",
      "[1075]\ttraining's rmse: 0.0878228\tvalid_1's rmse: 0.0920547\n",
      "[1100]\ttraining's rmse: 0.0877998\tvalid_1's rmse: 0.0920491\n",
      "[1125]\ttraining's rmse: 0.0877783\tvalid_1's rmse: 0.0920422\n",
      "[1150]\ttraining's rmse: 0.0877545\tvalid_1's rmse: 0.092036\n",
      "[1175]\ttraining's rmse: 0.0877343\tvalid_1's rmse: 0.0920322\n",
      "[1200]\ttraining's rmse: 0.0877135\tvalid_1's rmse: 0.0920265\n",
      "[1225]\ttraining's rmse: 0.0876946\tvalid_1's rmse: 0.0920226\n",
      "[1250]\ttraining's rmse: 0.0876756\tvalid_1's rmse: 0.0920181\n",
      "[1275]\ttraining's rmse: 0.0876537\tvalid_1's rmse: 0.0920143\n",
      "[1300]\ttraining's rmse: 0.0876366\tvalid_1's rmse: 0.0920088\n",
      "[1325]\ttraining's rmse: 0.0876197\tvalid_1's rmse: 0.0920042\n",
      "[1350]\ttraining's rmse: 0.0876041\tvalid_1's rmse: 0.0920012\n",
      "[1375]\ttraining's rmse: 0.0875871\tvalid_1's rmse: 0.0919965\n",
      "[1400]\ttraining's rmse: 0.0875735\tvalid_1's rmse: 0.0919924\n",
      "[1425]\ttraining's rmse: 0.087556\tvalid_1's rmse: 0.0919903\n",
      "[1450]\ttraining's rmse: 0.0875437\tvalid_1's rmse: 0.0919862\n",
      "[1475]\ttraining's rmse: 0.0875278\tvalid_1's rmse: 0.0919833\n",
      "[1500]\ttraining's rmse: 0.0875153\tvalid_1's rmse: 0.0919797\n",
      "[1525]\ttraining's rmse: 0.0875053\tvalid_1's rmse: 0.0919775\n",
      "[1550]\ttraining's rmse: 0.0874915\tvalid_1's rmse: 0.0919733\n",
      "[1575]\ttraining's rmse: 0.0874806\tvalid_1's rmse: 0.0919713\n",
      "[1600]\ttraining's rmse: 0.0874727\tvalid_1's rmse: 0.0919697\n",
      "[1625]\ttraining's rmse: 0.087462\tvalid_1's rmse: 0.0919672\n",
      "[1650]\ttraining's rmse: 0.0874539\tvalid_1's rmse: 0.0919646\n",
      "[1675]\ttraining's rmse: 0.0874448\tvalid_1's rmse: 0.0919614\n",
      "[1700]\ttraining's rmse: 0.0874361\tvalid_1's rmse: 0.0919591\n",
      "[1725]\ttraining's rmse: 0.0874288\tvalid_1's rmse: 0.0919559\n",
      "[1750]\ttraining's rmse: 0.0874209\tvalid_1's rmse: 0.0919538\n",
      "[1775]\ttraining's rmse: 0.0874099\tvalid_1's rmse: 0.091952\n",
      "[1800]\ttraining's rmse: 0.0874034\tvalid_1's rmse: 0.0919496\n",
      "[1825]\ttraining's rmse: 0.0873946\tvalid_1's rmse: 0.0919462\n",
      "[1850]\ttraining's rmse: 0.0873893\tvalid_1's rmse: 0.0919448\n",
      "[1875]\ttraining's rmse: 0.0873826\tvalid_1's rmse: 0.0919431\n",
      "[1900]\ttraining's rmse: 0.0873783\tvalid_1's rmse: 0.0919422\n",
      "[1925]\ttraining's rmse: 0.0873727\tvalid_1's rmse: 0.0919409\n",
      "[1950]\ttraining's rmse: 0.0873683\tvalid_1's rmse: 0.0919391\n",
      "[1975]\ttraining's rmse: 0.0873633\tvalid_1's rmse: 0.0919369\n",
      "[2000]\ttraining's rmse: 0.0873579\tvalid_1's rmse: 0.0919358\n",
      "[2025]\ttraining's rmse: 0.0873509\tvalid_1's rmse: 0.0919331\n",
      "[2050]\ttraining's rmse: 0.0873474\tvalid_1's rmse: 0.0919314\n",
      "[2075]\ttraining's rmse: 0.0873435\tvalid_1's rmse: 0.0919305\n",
      "[2100]\ttraining's rmse: 0.0873394\tvalid_1's rmse: 0.0919297\n",
      "[2125]\ttraining's rmse: 0.0873357\tvalid_1's rmse: 0.0919286\n",
      "[2150]\ttraining's rmse: 0.0873318\tvalid_1's rmse: 0.0919274\n",
      "[2175]\ttraining's rmse: 0.0873281\tvalid_1's rmse: 0.091926\n",
      "[2200]\ttraining's rmse: 0.0873241\tvalid_1's rmse: 0.0919251\n",
      "[2225]\ttraining's rmse: 0.08732\tvalid_1's rmse: 0.0919235\n",
      "[2250]\ttraining's rmse: 0.087318\tvalid_1's rmse: 0.0919235\n",
      "[2275]\ttraining's rmse: 0.0873132\tvalid_1's rmse: 0.0919214\n",
      "[2300]\ttraining's rmse: 0.0873094\tvalid_1's rmse: 0.0919205\n",
      "[2325]\ttraining's rmse: 0.0873061\tvalid_1's rmse: 0.0919194\n",
      "[2350]\ttraining's rmse: 0.0873031\tvalid_1's rmse: 0.0919179\n",
      "[2375]\ttraining's rmse: 0.0872993\tvalid_1's rmse: 0.0919171\n",
      "[2400]\ttraining's rmse: 0.0872951\tvalid_1's rmse: 0.0919167\n",
      "[2425]\ttraining's rmse: 0.0872922\tvalid_1's rmse: 0.0919157\n",
      "[2450]\ttraining's rmse: 0.0872897\tvalid_1's rmse: 0.0919151\n",
      "[2475]\ttraining's rmse: 0.0872859\tvalid_1's rmse: 0.0919142\n",
      "[2500]\ttraining's rmse: 0.0872838\tvalid_1's rmse: 0.0919139\n",
      "[2525]\ttraining's rmse: 0.0872797\tvalid_1's rmse: 0.0919122\n",
      "[2550]\ttraining's rmse: 0.0872757\tvalid_1's rmse: 0.0919115\n",
      "[2575]\ttraining's rmse: 0.0872731\tvalid_1's rmse: 0.0919109\n",
      "[2600]\ttraining's rmse: 0.0872713\tvalid_1's rmse: 0.0919102\n",
      "[2625]\ttraining's rmse: 0.0872696\tvalid_1's rmse: 0.091909\n",
      "[2650]\ttraining's rmse: 0.0872664\tvalid_1's rmse: 0.0919082\n",
      "[2675]\ttraining's rmse: 0.0872626\tvalid_1's rmse: 0.0919074\n",
      "[2700]\ttraining's rmse: 0.0872607\tvalid_1's rmse: 0.0919073\n",
      "[2725]\ttraining's rmse: 0.087257\tvalid_1's rmse: 0.0919076\n",
      "Early stopping, best iteration is:\n",
      "[2692]\ttraining's rmse: 0.0872613\tvalid_1's rmse: 0.0919072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0911266\tvalid_1's rmse: 0.0929362\n",
      "[50]\ttraining's rmse: 0.0909526\tvalid_1's rmse: 0.0928812\n",
      "[75]\ttraining's rmse: 0.0907728\tvalid_1's rmse: 0.0928259\n",
      "[100]\ttraining's rmse: 0.0906157\tvalid_1's rmse: 0.0927771\n",
      "[125]\ttraining's rmse: 0.0904551\tvalid_1's rmse: 0.0927283\n",
      "[150]\ttraining's rmse: 0.0903114\tvalid_1's rmse: 0.0926836\n",
      "[175]\ttraining's rmse: 0.090184\tvalid_1's rmse: 0.0926441\n",
      "[200]\ttraining's rmse: 0.0900522\tvalid_1's rmse: 0.0926058\n",
      "[225]\ttraining's rmse: 0.089927\tvalid_1's rmse: 0.0925713\n",
      "[250]\ttraining's rmse: 0.0898171\tvalid_1's rmse: 0.0925385\n",
      "[275]\ttraining's rmse: 0.0897161\tvalid_1's rmse: 0.0925092\n",
      "[300]\ttraining's rmse: 0.0896167\tvalid_1's rmse: 0.092481\n",
      "[325]\ttraining's rmse: 0.0895197\tvalid_1's rmse: 0.0924553\n",
      "[350]\ttraining's rmse: 0.0894261\tvalid_1's rmse: 0.0924317\n",
      "[375]\ttraining's rmse: 0.0893486\tvalid_1's rmse: 0.0924093\n",
      "[400]\ttraining's rmse: 0.0892644\tvalid_1's rmse: 0.092387\n",
      "[425]\ttraining's rmse: 0.0891897\tvalid_1's rmse: 0.0923671\n",
      "[450]\ttraining's rmse: 0.0891213\tvalid_1's rmse: 0.0923486\n",
      "[475]\ttraining's rmse: 0.0890564\tvalid_1's rmse: 0.0923314\n",
      "[500]\ttraining's rmse: 0.0890016\tvalid_1's rmse: 0.0923151\n",
      "[525]\ttraining's rmse: 0.0889354\tvalid_1's rmse: 0.0922993\n",
      "[550]\ttraining's rmse: 0.0888729\tvalid_1's rmse: 0.0922841\n",
      "[575]\ttraining's rmse: 0.0888172\tvalid_1's rmse: 0.0922712\n",
      "[600]\ttraining's rmse: 0.0887642\tvalid_1's rmse: 0.0922577\n",
      "[625]\ttraining's rmse: 0.0887179\tvalid_1's rmse: 0.0922454\n",
      "[650]\ttraining's rmse: 0.0886629\tvalid_1's rmse: 0.0922327\n",
      "[675]\ttraining's rmse: 0.0886121\tvalid_1's rmse: 0.0922215\n",
      "[700]\ttraining's rmse: 0.0885651\tvalid_1's rmse: 0.0922099\n",
      "[725]\ttraining's rmse: 0.0885232\tvalid_1's rmse: 0.0922015\n",
      "[750]\ttraining's rmse: 0.0884821\tvalid_1's rmse: 0.0921927\n",
      "[775]\ttraining's rmse: 0.0884471\tvalid_1's rmse: 0.0921825\n",
      "[800]\ttraining's rmse: 0.0884057\tvalid_1's rmse: 0.0921754\n",
      "[825]\ttraining's rmse: 0.0883702\tvalid_1's rmse: 0.0921678\n",
      "[850]\ttraining's rmse: 0.0883327\tvalid_1's rmse: 0.0921609\n",
      "[875]\ttraining's rmse: 0.0883007\tvalid_1's rmse: 0.0921539\n",
      "[900]\ttraining's rmse: 0.0882655\tvalid_1's rmse: 0.0921474\n",
      "[925]\ttraining's rmse: 0.0882317\tvalid_1's rmse: 0.0921412\n",
      "[950]\ttraining's rmse: 0.0882029\tvalid_1's rmse: 0.0921357\n",
      "[975]\ttraining's rmse: 0.0881728\tvalid_1's rmse: 0.0921298\n",
      "[1000]\ttraining's rmse: 0.0881453\tvalid_1's rmse: 0.092125\n",
      "[1025]\ttraining's rmse: 0.0881132\tvalid_1's rmse: 0.0921196\n",
      "[1050]\ttraining's rmse: 0.0880859\tvalid_1's rmse: 0.0921153\n",
      "[1075]\ttraining's rmse: 0.0880601\tvalid_1's rmse: 0.0921128\n",
      "[1100]\ttraining's rmse: 0.0880394\tvalid_1's rmse: 0.092109\n",
      "[1125]\ttraining's rmse: 0.0880177\tvalid_1's rmse: 0.0921051\n",
      "[1150]\ttraining's rmse: 0.0879974\tvalid_1's rmse: 0.0921023\n",
      "[1175]\ttraining's rmse: 0.0879794\tvalid_1's rmse: 0.0920993\n",
      "[1200]\ttraining's rmse: 0.0879593\tvalid_1's rmse: 0.0920964\n",
      "[1225]\ttraining's rmse: 0.0879415\tvalid_1's rmse: 0.0920946\n",
      "[1250]\ttraining's rmse: 0.0879246\tvalid_1's rmse: 0.0920921\n",
      "[1275]\ttraining's rmse: 0.0879037\tvalid_1's rmse: 0.0920896\n",
      "[1300]\ttraining's rmse: 0.0878861\tvalid_1's rmse: 0.0920865\n",
      "[1325]\ttraining's rmse: 0.0878707\tvalid_1's rmse: 0.0920845\n",
      "[1350]\ttraining's rmse: 0.0878537\tvalid_1's rmse: 0.0920831\n",
      "[1375]\ttraining's rmse: 0.0878369\tvalid_1's rmse: 0.0920818\n",
      "[1400]\ttraining's rmse: 0.0878229\tvalid_1's rmse: 0.0920794\n",
      "[1425]\ttraining's rmse: 0.0878074\tvalid_1's rmse: 0.0920774\n",
      "[1450]\ttraining's rmse: 0.0877926\tvalid_1's rmse: 0.0920764\n",
      "[1475]\ttraining's rmse: 0.0877802\tvalid_1's rmse: 0.0920746\n",
      "[1500]\ttraining's rmse: 0.0877662\tvalid_1's rmse: 0.0920733\n",
      "[1525]\ttraining's rmse: 0.0877553\tvalid_1's rmse: 0.0920726\n",
      "[1550]\ttraining's rmse: 0.0877401\tvalid_1's rmse: 0.0920716\n",
      "[1575]\ttraining's rmse: 0.0877298\tvalid_1's rmse: 0.0920701\n",
      "[1600]\ttraining's rmse: 0.0877208\tvalid_1's rmse: 0.0920696\n",
      "[1625]\ttraining's rmse: 0.087712\tvalid_1's rmse: 0.0920688\n",
      "[1650]\ttraining's rmse: 0.0877014\tvalid_1's rmse: 0.0920678\n",
      "[1675]\ttraining's rmse: 0.0876927\tvalid_1's rmse: 0.0920669\n",
      "[1700]\ttraining's rmse: 0.0876835\tvalid_1's rmse: 0.0920665\n",
      "[1725]\ttraining's rmse: 0.087674\tvalid_1's rmse: 0.0920658\n",
      "[1750]\ttraining's rmse: 0.0876656\tvalid_1's rmse: 0.0920653\n",
      "[1775]\ttraining's rmse: 0.0876573\tvalid_1's rmse: 0.092065\n",
      "[1800]\ttraining's rmse: 0.08765\tvalid_1's rmse: 0.0920649\n",
      "[1825]\ttraining's rmse: 0.0876414\tvalid_1's rmse: 0.0920646\n",
      "[1850]\ttraining's rmse: 0.0876333\tvalid_1's rmse: 0.0920636\n",
      "[1875]\ttraining's rmse: 0.0876261\tvalid_1's rmse: 0.0920634\n",
      "[1900]\ttraining's rmse: 0.0876208\tvalid_1's rmse: 0.0920633\n",
      "[1925]\ttraining's rmse: 0.087613\tvalid_1's rmse: 0.0920624\n",
      "[1950]\ttraining's rmse: 0.0876083\tvalid_1's rmse: 0.0920617\n",
      "[1975]\ttraining's rmse: 0.0876053\tvalid_1's rmse: 0.0920616\n",
      "[2000]\ttraining's rmse: 0.0875986\tvalid_1's rmse: 0.0920607\n",
      "[2025]\ttraining's rmse: 0.087593\tvalid_1's rmse: 0.0920604\n",
      "[2050]\ttraining's rmse: 0.0875867\tvalid_1's rmse: 0.0920598\n",
      "[2075]\ttraining's rmse: 0.0875837\tvalid_1's rmse: 0.0920594\n",
      "[2100]\ttraining's rmse: 0.0875787\tvalid_1's rmse: 0.0920589\n",
      "[2125]\ttraining's rmse: 0.0875739\tvalid_1's rmse: 0.0920587\n",
      "[2150]\ttraining's rmse: 0.0875683\tvalid_1's rmse: 0.0920587\n",
      "[2175]\ttraining's rmse: 0.0875637\tvalid_1's rmse: 0.0920584\n",
      "[2200]\ttraining's rmse: 0.0875603\tvalid_1's rmse: 0.0920583\n",
      "[2225]\ttraining's rmse: 0.087557\tvalid_1's rmse: 0.092058\n",
      "[2250]\ttraining's rmse: 0.0875546\tvalid_1's rmse: 0.0920582\n",
      "[2275]\ttraining's rmse: 0.0875503\tvalid_1's rmse: 0.0920581\n",
      "[2300]\ttraining's rmse: 0.0875463\tvalid_1's rmse: 0.0920576\n",
      "[2325]\ttraining's rmse: 0.087542\tvalid_1's rmse: 0.0920577\n",
      "[2350]\ttraining's rmse: 0.0875383\tvalid_1's rmse: 0.0920568\n",
      "[2375]\ttraining's rmse: 0.087534\tvalid_1's rmse: 0.0920565\n",
      "[2400]\ttraining's rmse: 0.0875309\tvalid_1's rmse: 0.0920563\n",
      "[2425]\ttraining's rmse: 0.0875267\tvalid_1's rmse: 0.0920562\n",
      "[2450]\ttraining's rmse: 0.0875245\tvalid_1's rmse: 0.092056\n",
      "[2475]\ttraining's rmse: 0.0875215\tvalid_1's rmse: 0.0920561\n",
      "Early stopping, best iteration is:\n",
      "[2444]\ttraining's rmse: 0.0875251\tvalid_1's rmse: 0.0920558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0927836\tvalid_1's rmse: 0.0896564\n",
      "[50]\ttraining's rmse: 0.0926494\tvalid_1's rmse: 0.0896056\n",
      "[75]\ttraining's rmse: 0.0925028\tvalid_1's rmse: 0.0895542\n",
      "[100]\ttraining's rmse: 0.0923756\tvalid_1's rmse: 0.0895132\n",
      "[125]\ttraining's rmse: 0.0922413\tvalid_1's rmse: 0.0894705\n",
      "[150]\ttraining's rmse: 0.092117\tvalid_1's rmse: 0.0894314\n",
      "[175]\ttraining's rmse: 0.092013\tvalid_1's rmse: 0.0893989\n",
      "[200]\ttraining's rmse: 0.0919006\tvalid_1's rmse: 0.0893684\n",
      "[225]\ttraining's rmse: 0.0917897\tvalid_1's rmse: 0.0893383\n",
      "[250]\ttraining's rmse: 0.0916971\tvalid_1's rmse: 0.0893128\n",
      "[275]\ttraining's rmse: 0.0916111\tvalid_1's rmse: 0.0892877\n",
      "[300]\ttraining's rmse: 0.0915253\tvalid_1's rmse: 0.0892652\n",
      "[325]\ttraining's rmse: 0.0914398\tvalid_1's rmse: 0.0892436\n",
      "[350]\ttraining's rmse: 0.0913592\tvalid_1's rmse: 0.089224\n",
      "[375]\ttraining's rmse: 0.0912921\tvalid_1's rmse: 0.0892114\n",
      "[400]\ttraining's rmse: 0.0912177\tvalid_1's rmse: 0.0891945\n",
      "[425]\ttraining's rmse: 0.0911479\tvalid_1's rmse: 0.0891794\n",
      "[450]\ttraining's rmse: 0.0910862\tvalid_1's rmse: 0.0891645\n",
      "[475]\ttraining's rmse: 0.0910268\tvalid_1's rmse: 0.0891512\n",
      "[500]\ttraining's rmse: 0.0909797\tvalid_1's rmse: 0.0891397\n",
      "[525]\ttraining's rmse: 0.0909128\tvalid_1's rmse: 0.0891258\n",
      "[550]\ttraining's rmse: 0.0908537\tvalid_1's rmse: 0.089114\n",
      "[575]\ttraining's rmse: 0.0907979\tvalid_1's rmse: 0.0891076\n",
      "[600]\ttraining's rmse: 0.0907463\tvalid_1's rmse: 0.0890992\n",
      "[625]\ttraining's rmse: 0.090704\tvalid_1's rmse: 0.0890962\n",
      "[650]\ttraining's rmse: 0.090651\tvalid_1's rmse: 0.0890958\n",
      "[675]\ttraining's rmse: 0.0905978\tvalid_1's rmse: 0.0890934\n",
      "[700]\ttraining's rmse: 0.0905523\tvalid_1's rmse: 0.089086\n",
      "[725]\ttraining's rmse: 0.0905111\tvalid_1's rmse: 0.0890818\n",
      "[750]\ttraining's rmse: 0.0904707\tvalid_1's rmse: 0.0890813\n",
      "[775]\ttraining's rmse: 0.0904355\tvalid_1's rmse: 0.0890825\n",
      "Early stopping, best iteration is:\n",
      "[749]\ttraining's rmse: 0.0904734\tvalid_1's rmse: 0.0890765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0879579\tvalid_1's rmse: 0.0907483\n",
      "[50]\ttraining's rmse: 0.0878205\tvalid_1's rmse: 0.0906927\n",
      "[75]\ttraining's rmse: 0.0876835\tvalid_1's rmse: 0.0906363\n",
      "[100]\ttraining's rmse: 0.0875623\tvalid_1's rmse: 0.090589\n",
      "[125]\ttraining's rmse: 0.087432\tvalid_1's rmse: 0.0905394\n",
      "[150]\ttraining's rmse: 0.0873132\tvalid_1's rmse: 0.0904909\n",
      "[175]\ttraining's rmse: 0.0872156\tvalid_1's rmse: 0.0904512\n",
      "[200]\ttraining's rmse: 0.0871126\tvalid_1's rmse: 0.0904116\n",
      "[225]\ttraining's rmse: 0.0870127\tvalid_1's rmse: 0.0903745\n",
      "[250]\ttraining's rmse: 0.0869264\tvalid_1's rmse: 0.09034\n",
      "[275]\ttraining's rmse: 0.0868479\tvalid_1's rmse: 0.0903092\n",
      "[300]\ttraining's rmse: 0.0867636\tvalid_1's rmse: 0.0902773\n",
      "[325]\ttraining's rmse: 0.0866853\tvalid_1's rmse: 0.090249\n",
      "[350]\ttraining's rmse: 0.0866092\tvalid_1's rmse: 0.0902213\n",
      "[375]\ttraining's rmse: 0.0865435\tvalid_1's rmse: 0.0901979\n",
      "[400]\ttraining's rmse: 0.0864756\tvalid_1's rmse: 0.0901755\n",
      "[425]\ttraining's rmse: 0.0864129\tvalid_1's rmse: 0.090154\n",
      "[450]\ttraining's rmse: 0.0863587\tvalid_1's rmse: 0.0901317\n",
      "[475]\ttraining's rmse: 0.0863044\tvalid_1's rmse: 0.0901123\n",
      "[500]\ttraining's rmse: 0.0862559\tvalid_1's rmse: 0.0900926\n",
      "[525]\ttraining's rmse: 0.0862002\tvalid_1's rmse: 0.0900747\n",
      "[550]\ttraining's rmse: 0.0861466\tvalid_1's rmse: 0.0900601\n",
      "[575]\ttraining's rmse: 0.0860983\tvalid_1's rmse: 0.0900449\n",
      "[600]\ttraining's rmse: 0.0860509\tvalid_1's rmse: 0.09003\n",
      "[625]\ttraining's rmse: 0.0860124\tvalid_1's rmse: 0.0900163\n",
      "[650]\ttraining's rmse: 0.0859693\tvalid_1's rmse: 0.0900036\n",
      "[675]\ttraining's rmse: 0.0859267\tvalid_1's rmse: 0.0899908\n",
      "[700]\ttraining's rmse: 0.0858895\tvalid_1's rmse: 0.0899787\n",
      "[725]\ttraining's rmse: 0.085851\tvalid_1's rmse: 0.0899682\n",
      "[750]\ttraining's rmse: 0.085816\tvalid_1's rmse: 0.0899579\n",
      "[775]\ttraining's rmse: 0.0857872\tvalid_1's rmse: 0.089947\n",
      "[800]\ttraining's rmse: 0.0857486\tvalid_1's rmse: 0.0899367\n",
      "[825]\ttraining's rmse: 0.0857149\tvalid_1's rmse: 0.0899267\n",
      "[850]\ttraining's rmse: 0.0856836\tvalid_1's rmse: 0.0899192\n",
      "[875]\ttraining's rmse: 0.0856526\tvalid_1's rmse: 0.0899099\n",
      "[900]\ttraining's rmse: 0.0856203\tvalid_1's rmse: 0.0899004\n",
      "[925]\ttraining's rmse: 0.0855915\tvalid_1's rmse: 0.0898944\n",
      "[950]\ttraining's rmse: 0.0855657\tvalid_1's rmse: 0.0898862\n",
      "[975]\ttraining's rmse: 0.0855429\tvalid_1's rmse: 0.0898789\n",
      "[1000]\ttraining's rmse: 0.0855184\tvalid_1's rmse: 0.089872\n",
      "[1025]\ttraining's rmse: 0.0854936\tvalid_1's rmse: 0.0898663\n",
      "[1050]\ttraining's rmse: 0.0854705\tvalid_1's rmse: 0.0898591\n",
      "[1075]\ttraining's rmse: 0.0854485\tvalid_1's rmse: 0.0898549\n",
      "[1100]\ttraining's rmse: 0.0854286\tvalid_1's rmse: 0.0898495\n",
      "[1125]\ttraining's rmse: 0.085408\tvalid_1's rmse: 0.0898438\n",
      "[1150]\ttraining's rmse: 0.0853871\tvalid_1's rmse: 0.0898387\n",
      "[1175]\ttraining's rmse: 0.0853686\tvalid_1's rmse: 0.0898355\n",
      "[1200]\ttraining's rmse: 0.0853536\tvalid_1's rmse: 0.08983\n",
      "[1225]\ttraining's rmse: 0.0853384\tvalid_1's rmse: 0.0898248\n",
      "[1250]\ttraining's rmse: 0.0853216\tvalid_1's rmse: 0.0898211\n",
      "[1275]\ttraining's rmse: 0.0853047\tvalid_1's rmse: 0.0898168\n",
      "[1300]\ttraining's rmse: 0.0852888\tvalid_1's rmse: 0.0898119\n",
      "[1325]\ttraining's rmse: 0.0852754\tvalid_1's rmse: 0.0898089\n",
      "[1350]\ttraining's rmse: 0.0852603\tvalid_1's rmse: 0.089805\n",
      "[1375]\ttraining's rmse: 0.0852459\tvalid_1's rmse: 0.0898009\n",
      "[1400]\ttraining's rmse: 0.0852338\tvalid_1's rmse: 0.0897966\n",
      "[1425]\ttraining's rmse: 0.0852194\tvalid_1's rmse: 0.0897941\n",
      "[1450]\ttraining's rmse: 0.0852054\tvalid_1's rmse: 0.0897903\n",
      "[1475]\ttraining's rmse: 0.0851929\tvalid_1's rmse: 0.0897885\n",
      "[1500]\ttraining's rmse: 0.0851807\tvalid_1's rmse: 0.0897855\n",
      "[1525]\ttraining's rmse: 0.0851702\tvalid_1's rmse: 0.0897839\n",
      "[1550]\ttraining's rmse: 0.0851598\tvalid_1's rmse: 0.0897811\n",
      "[1575]\ttraining's rmse: 0.0851491\tvalid_1's rmse: 0.0897789\n",
      "[1600]\ttraining's rmse: 0.0851396\tvalid_1's rmse: 0.0897757\n",
      "[1625]\ttraining's rmse: 0.0851299\tvalid_1's rmse: 0.0897739\n",
      "[1650]\ttraining's rmse: 0.0851216\tvalid_1's rmse: 0.0897711\n",
      "[1675]\ttraining's rmse: 0.0851158\tvalid_1's rmse: 0.0897689\n",
      "[1700]\ttraining's rmse: 0.0851105\tvalid_1's rmse: 0.0897676\n",
      "[1725]\ttraining's rmse: 0.0851016\tvalid_1's rmse: 0.0897657\n",
      "[1750]\ttraining's rmse: 0.0850938\tvalid_1's rmse: 0.0897632\n",
      "[1775]\ttraining's rmse: 0.0850887\tvalid_1's rmse: 0.0897622\n",
      "[1800]\ttraining's rmse: 0.0850826\tvalid_1's rmse: 0.0897597\n",
      "[1825]\ttraining's rmse: 0.085078\tvalid_1's rmse: 0.0897582\n",
      "[1850]\ttraining's rmse: 0.0850726\tvalid_1's rmse: 0.0897567\n",
      "[1875]\ttraining's rmse: 0.085066\tvalid_1's rmse: 0.0897556\n",
      "[1900]\ttraining's rmse: 0.0850624\tvalid_1's rmse: 0.0897548\n",
      "[1925]\ttraining's rmse: 0.085057\tvalid_1's rmse: 0.0897538\n",
      "[1950]\ttraining's rmse: 0.0850525\tvalid_1's rmse: 0.0897514\n",
      "[1975]\ttraining's rmse: 0.085047\tvalid_1's rmse: 0.0897502\n",
      "[2000]\ttraining's rmse: 0.0850396\tvalid_1's rmse: 0.0897487\n",
      "[2025]\ttraining's rmse: 0.0850345\tvalid_1's rmse: 0.0897479\n",
      "[2050]\ttraining's rmse: 0.0850304\tvalid_1's rmse: 0.0897468\n",
      "[2075]\ttraining's rmse: 0.0850271\tvalid_1's rmse: 0.0897455\n",
      "[2100]\ttraining's rmse: 0.085023\tvalid_1's rmse: 0.0897447\n",
      "[2125]\ttraining's rmse: 0.0850185\tvalid_1's rmse: 0.089743\n",
      "[2150]\ttraining's rmse: 0.0850153\tvalid_1's rmse: 0.0897431\n",
      "[2175]\ttraining's rmse: 0.0850114\tvalid_1's rmse: 0.0897428\n",
      "[2200]\ttraining's rmse: 0.0850076\tvalid_1's rmse: 0.0897416\n",
      "[2225]\ttraining's rmse: 0.0850049\tvalid_1's rmse: 0.0897398\n",
      "[2250]\ttraining's rmse: 0.085\tvalid_1's rmse: 0.0897391\n",
      "[2275]\ttraining's rmse: 0.0849971\tvalid_1's rmse: 0.0897386\n",
      "[2300]\ttraining's rmse: 0.0849928\tvalid_1's rmse: 0.0897375\n",
      "[2325]\ttraining's rmse: 0.0849894\tvalid_1's rmse: 0.089737\n",
      "[2350]\ttraining's rmse: 0.084987\tvalid_1's rmse: 0.0897358\n",
      "[2375]\ttraining's rmse: 0.0849828\tvalid_1's rmse: 0.0897346\n",
      "[2400]\ttraining's rmse: 0.0849795\tvalid_1's rmse: 0.0897343\n",
      "[2425]\ttraining's rmse: 0.0849764\tvalid_1's rmse: 0.0897345\n",
      "Early stopping, best iteration is:\n",
      "[2386]\ttraining's rmse: 0.0849809\tvalid_1's rmse: 0.0897341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0881365\tvalid_1's rmse: 0.0904042\n",
      "[50]\ttraining's rmse: 0.0880059\tvalid_1's rmse: 0.0903458\n",
      "[75]\ttraining's rmse: 0.0878712\tvalid_1's rmse: 0.0902898\n",
      "[100]\ttraining's rmse: 0.0877499\tvalid_1's rmse: 0.0902396\n",
      "[125]\ttraining's rmse: 0.0876292\tvalid_1's rmse: 0.0901909\n",
      "[150]\ttraining's rmse: 0.0875173\tvalid_1's rmse: 0.0901462\n",
      "[175]\ttraining's rmse: 0.0874221\tvalid_1's rmse: 0.0901075\n",
      "[200]\ttraining's rmse: 0.0873213\tvalid_1's rmse: 0.0900694\n",
      "[225]\ttraining's rmse: 0.0872253\tvalid_1's rmse: 0.0900349\n",
      "[250]\ttraining's rmse: 0.0871425\tvalid_1's rmse: 0.0900018\n",
      "[275]\ttraining's rmse: 0.0870629\tvalid_1's rmse: 0.0899721\n",
      "[300]\ttraining's rmse: 0.0869861\tvalid_1's rmse: 0.0899452\n",
      "[325]\ttraining's rmse: 0.0869095\tvalid_1's rmse: 0.0899184\n",
      "[350]\ttraining's rmse: 0.086834\tvalid_1's rmse: 0.0898929\n",
      "[375]\ttraining's rmse: 0.0867717\tvalid_1's rmse: 0.08987\n",
      "[400]\ttraining's rmse: 0.0867031\tvalid_1's rmse: 0.0898485\n",
      "[425]\ttraining's rmse: 0.0866399\tvalid_1's rmse: 0.089828\n",
      "[450]\ttraining's rmse: 0.0865825\tvalid_1's rmse: 0.0898096\n",
      "[475]\ttraining's rmse: 0.0865298\tvalid_1's rmse: 0.0897903\n",
      "[500]\ttraining's rmse: 0.0864835\tvalid_1's rmse: 0.0897736\n",
      "[525]\ttraining's rmse: 0.0864252\tvalid_1's rmse: 0.0897563\n",
      "[550]\ttraining's rmse: 0.0863696\tvalid_1's rmse: 0.0897417\n",
      "[575]\ttraining's rmse: 0.0863208\tvalid_1's rmse: 0.0897273\n",
      "[600]\ttraining's rmse: 0.0862709\tvalid_1's rmse: 0.0897137\n",
      "[625]\ttraining's rmse: 0.0862326\tvalid_1's rmse: 0.0897014\n",
      "[650]\ttraining's rmse: 0.086183\tvalid_1's rmse: 0.0896883\n",
      "[675]\ttraining's rmse: 0.086135\tvalid_1's rmse: 0.0896768\n",
      "[700]\ttraining's rmse: 0.0860943\tvalid_1's rmse: 0.0896655\n",
      "[725]\ttraining's rmse: 0.086054\tvalid_1's rmse: 0.0896556\n",
      "[750]\ttraining's rmse: 0.0860172\tvalid_1's rmse: 0.0896464\n",
      "[775]\ttraining's rmse: 0.0859848\tvalid_1's rmse: 0.0896377\n",
      "[800]\ttraining's rmse: 0.0859428\tvalid_1's rmse: 0.0896289\n",
      "[825]\ttraining's rmse: 0.0859105\tvalid_1's rmse: 0.0896205\n",
      "[850]\ttraining's rmse: 0.0858791\tvalid_1's rmse: 0.0896138\n",
      "[875]\ttraining's rmse: 0.0858501\tvalid_1's rmse: 0.0896071\n",
      "[900]\ttraining's rmse: 0.0858184\tvalid_1's rmse: 0.089601\n",
      "[925]\ttraining's rmse: 0.0857873\tvalid_1's rmse: 0.0895947\n",
      "[950]\ttraining's rmse: 0.0857602\tvalid_1's rmse: 0.0895892\n",
      "[975]\ttraining's rmse: 0.0857347\tvalid_1's rmse: 0.0895836\n",
      "[1000]\ttraining's rmse: 0.0857101\tvalid_1's rmse: 0.0895786\n",
      "[1025]\ttraining's rmse: 0.0856827\tvalid_1's rmse: 0.089574\n",
      "[1050]\ttraining's rmse: 0.0856605\tvalid_1's rmse: 0.0895703\n",
      "[1075]\ttraining's rmse: 0.085638\tvalid_1's rmse: 0.0895663\n",
      "[1100]\ttraining's rmse: 0.085619\tvalid_1's rmse: 0.0895623\n",
      "[1125]\ttraining's rmse: 0.0855993\tvalid_1's rmse: 0.0895589\n",
      "[1150]\ttraining's rmse: 0.0855809\tvalid_1's rmse: 0.0895564\n",
      "[1175]\ttraining's rmse: 0.0855611\tvalid_1's rmse: 0.0895527\n",
      "[1200]\ttraining's rmse: 0.0855434\tvalid_1's rmse: 0.0895494\n",
      "[1225]\ttraining's rmse: 0.085527\tvalid_1's rmse: 0.0895471\n",
      "[1250]\ttraining's rmse: 0.0855131\tvalid_1's rmse: 0.0895443\n",
      "[1275]\ttraining's rmse: 0.0854947\tvalid_1's rmse: 0.0895418\n",
      "[1300]\ttraining's rmse: 0.085481\tvalid_1's rmse: 0.089539\n",
      "[1325]\ttraining's rmse: 0.085467\tvalid_1's rmse: 0.0895366\n",
      "[1350]\ttraining's rmse: 0.0854517\tvalid_1's rmse: 0.0895348\n",
      "[1375]\ttraining's rmse: 0.0854388\tvalid_1's rmse: 0.0895331\n",
      "[1400]\ttraining's rmse: 0.0854273\tvalid_1's rmse: 0.0895307\n",
      "[1425]\ttraining's rmse: 0.0854125\tvalid_1's rmse: 0.0895296\n",
      "[1450]\ttraining's rmse: 0.0853983\tvalid_1's rmse: 0.0895284\n",
      "[1475]\ttraining's rmse: 0.0853875\tvalid_1's rmse: 0.0895266\n",
      "[1500]\ttraining's rmse: 0.0853787\tvalid_1's rmse: 0.0895253\n",
      "[1525]\ttraining's rmse: 0.085366\tvalid_1's rmse: 0.0895247\n",
      "[1550]\ttraining's rmse: 0.0853547\tvalid_1's rmse: 0.089524\n",
      "[1575]\ttraining's rmse: 0.0853436\tvalid_1's rmse: 0.0895228\n",
      "[1600]\ttraining's rmse: 0.0853345\tvalid_1's rmse: 0.089522\n",
      "[1625]\ttraining's rmse: 0.0853236\tvalid_1's rmse: 0.0895212\n",
      "[1650]\ttraining's rmse: 0.0853159\tvalid_1's rmse: 0.0895208\n",
      "[1675]\ttraining's rmse: 0.0853089\tvalid_1's rmse: 0.08952\n",
      "[1700]\ttraining's rmse: 0.0853023\tvalid_1's rmse: 0.089519\n",
      "[1725]\ttraining's rmse: 0.0852939\tvalid_1's rmse: 0.0895182\n",
      "[1750]\ttraining's rmse: 0.0852838\tvalid_1's rmse: 0.0895169\n",
      "[1775]\ttraining's rmse: 0.0852768\tvalid_1's rmse: 0.0895165\n",
      "[1800]\ttraining's rmse: 0.0852694\tvalid_1's rmse: 0.0895162\n",
      "[1825]\ttraining's rmse: 0.0852625\tvalid_1's rmse: 0.0895157\n",
      "[1850]\ttraining's rmse: 0.0852575\tvalid_1's rmse: 0.089515\n",
      "[1875]\ttraining's rmse: 0.0852508\tvalid_1's rmse: 0.0895144\n",
      "[1900]\ttraining's rmse: 0.0852458\tvalid_1's rmse: 0.0895143\n",
      "[1925]\ttraining's rmse: 0.0852414\tvalid_1's rmse: 0.0895139\n",
      "[1950]\ttraining's rmse: 0.0852376\tvalid_1's rmse: 0.0895132\n",
      "[1975]\ttraining's rmse: 0.0852341\tvalid_1's rmse: 0.089513\n",
      "[2000]\ttraining's rmse: 0.0852283\tvalid_1's rmse: 0.0895122\n",
      "[2025]\ttraining's rmse: 0.0852243\tvalid_1's rmse: 0.0895116\n",
      "[2050]\ttraining's rmse: 0.0852205\tvalid_1's rmse: 0.0895115\n",
      "[2075]\ttraining's rmse: 0.0852166\tvalid_1's rmse: 0.0895111\n",
      "[2100]\ttraining's rmse: 0.085213\tvalid_1's rmse: 0.0895111\n",
      "[2125]\ttraining's rmse: 0.08521\tvalid_1's rmse: 0.0895108\n",
      "[2150]\ttraining's rmse: 0.0852053\tvalid_1's rmse: 0.089511\n",
      "[2175]\ttraining's rmse: 0.0852025\tvalid_1's rmse: 0.0895107\n",
      "[2200]\ttraining's rmse: 0.0851996\tvalid_1's rmse: 0.0895102\n",
      "[2225]\ttraining's rmse: 0.085197\tvalid_1's rmse: 0.08951\n",
      "[2250]\ttraining's rmse: 0.0851936\tvalid_1's rmse: 0.0895097\n",
      "[2275]\ttraining's rmse: 0.0851896\tvalid_1's rmse: 0.0895095\n",
      "[2300]\ttraining's rmse: 0.0851849\tvalid_1's rmse: 0.0895097\n",
      "[2325]\ttraining's rmse: 0.0851813\tvalid_1's rmse: 0.0895098\n",
      "Early stopping, best iteration is:\n",
      "[2287]\ttraining's rmse: 0.0851874\tvalid_1's rmse: 0.0895092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0904488\tvalid_1's rmse: 0.0857153\n",
      "[50]\ttraining's rmse: 0.0903235\tvalid_1's rmse: 0.0856657\n",
      "[75]\ttraining's rmse: 0.090199\tvalid_1's rmse: 0.0856173\n",
      "[100]\ttraining's rmse: 0.090086\tvalid_1's rmse: 0.0855751\n",
      "[125]\ttraining's rmse: 0.0899687\tvalid_1's rmse: 0.085537\n",
      "[150]\ttraining's rmse: 0.0898655\tvalid_1's rmse: 0.0854981\n",
      "[175]\ttraining's rmse: 0.0897771\tvalid_1's rmse: 0.0854652\n",
      "[200]\ttraining's rmse: 0.0896837\tvalid_1's rmse: 0.0854323\n",
      "[225]\ttraining's rmse: 0.0895914\tvalid_1's rmse: 0.0854012\n",
      "[250]\ttraining's rmse: 0.089511\tvalid_1's rmse: 0.0853734\n",
      "[275]\ttraining's rmse: 0.0894388\tvalid_1's rmse: 0.0853478\n",
      "[300]\ttraining's rmse: 0.0893652\tvalid_1's rmse: 0.0853235\n",
      "[325]\ttraining's rmse: 0.0892921\tvalid_1's rmse: 0.0852998\n",
      "[350]\ttraining's rmse: 0.0892191\tvalid_1's rmse: 0.0852769\n",
      "[375]\ttraining's rmse: 0.0891575\tvalid_1's rmse: 0.0852579\n",
      "[400]\ttraining's rmse: 0.0890942\tvalid_1's rmse: 0.0852524\n",
      "[425]\ttraining's rmse: 0.0890335\tvalid_1's rmse: 0.0852372\n",
      "[450]\ttraining's rmse: 0.0889772\tvalid_1's rmse: 0.085226\n",
      "[475]\ttraining's rmse: 0.0889258\tvalid_1's rmse: 0.0852167\n",
      "[500]\ttraining's rmse: 0.0888819\tvalid_1's rmse: 0.085205\n",
      "[525]\ttraining's rmse: 0.0888248\tvalid_1's rmse: 0.08519\n",
      "[550]\ttraining's rmse: 0.0887756\tvalid_1's rmse: 0.0851763\n",
      "[575]\ttraining's rmse: 0.0887279\tvalid_1's rmse: 0.0851711\n",
      "[600]\ttraining's rmse: 0.0886815\tvalid_1's rmse: 0.0851671\n",
      "[625]\ttraining's rmse: 0.088644\tvalid_1's rmse: 0.0851581\n",
      "[650]\ttraining's rmse: 0.0885982\tvalid_1's rmse: 0.0851512\n",
      "[675]\ttraining's rmse: 0.0885512\tvalid_1's rmse: 0.0851418\n",
      "[700]\ttraining's rmse: 0.0885086\tvalid_1's rmse: 0.0851439\n",
      "[725]\ttraining's rmse: 0.08847\tvalid_1's rmse: 0.0851362\n",
      "[750]\ttraining's rmse: 0.0884314\tvalid_1's rmse: 0.0851345\n",
      "[775]\ttraining's rmse: 0.0884008\tvalid_1's rmse: 0.0851318\n",
      "[800]\ttraining's rmse: 0.0883609\tvalid_1's rmse: 0.0851333\n",
      "[825]\ttraining's rmse: 0.088327\tvalid_1's rmse: 0.0851362\n",
      "Early stopping, best iteration is:\n",
      "[797]\ttraining's rmse: 0.0883654\tvalid_1's rmse: 0.0851272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0872399\tvalid_1's rmse: 0.0899094\n",
      "[50]\ttraining's rmse: 0.0870995\tvalid_1's rmse: 0.0898532\n",
      "[75]\ttraining's rmse: 0.0869629\tvalid_1's rmse: 0.0897998\n",
      "[100]\ttraining's rmse: 0.0868323\tvalid_1's rmse: 0.0897538\n",
      "[125]\ttraining's rmse: 0.0867007\tvalid_1's rmse: 0.0897057\n",
      "[150]\ttraining's rmse: 0.0865801\tvalid_1's rmse: 0.0896633\n",
      "[175]\ttraining's rmse: 0.0864845\tvalid_1's rmse: 0.0896255\n",
      "[200]\ttraining's rmse: 0.0863747\tvalid_1's rmse: 0.0895877\n",
      "[225]\ttraining's rmse: 0.0862708\tvalid_1's rmse: 0.0895519\n",
      "[250]\ttraining's rmse: 0.0861824\tvalid_1's rmse: 0.0895204\n",
      "[275]\ttraining's rmse: 0.0860991\tvalid_1's rmse: 0.0894906\n",
      "[300]\ttraining's rmse: 0.0860174\tvalid_1's rmse: 0.0894619\n",
      "[325]\ttraining's rmse: 0.0859363\tvalid_1's rmse: 0.0894343\n",
      "[350]\ttraining's rmse: 0.0858572\tvalid_1's rmse: 0.0894094\n",
      "[375]\ttraining's rmse: 0.0857914\tvalid_1's rmse: 0.0893875\n",
      "[400]\ttraining's rmse: 0.0857222\tvalid_1's rmse: 0.0893646\n",
      "[425]\ttraining's rmse: 0.0856612\tvalid_1's rmse: 0.0893451\n",
      "[450]\ttraining's rmse: 0.0856021\tvalid_1's rmse: 0.0893252\n",
      "[475]\ttraining's rmse: 0.085547\tvalid_1's rmse: 0.0893075\n",
      "[500]\ttraining's rmse: 0.0855013\tvalid_1's rmse: 0.0892923\n",
      "[525]\ttraining's rmse: 0.0854439\tvalid_1's rmse: 0.0892756\n",
      "[550]\ttraining's rmse: 0.0853944\tvalid_1's rmse: 0.089259\n",
      "[575]\ttraining's rmse: 0.0853447\tvalid_1's rmse: 0.0892443\n",
      "[600]\ttraining's rmse: 0.0852977\tvalid_1's rmse: 0.0892294\n",
      "[625]\ttraining's rmse: 0.0852591\tvalid_1's rmse: 0.0892174\n",
      "[650]\ttraining's rmse: 0.0852128\tvalid_1's rmse: 0.0892039\n",
      "[675]\ttraining's rmse: 0.0851707\tvalid_1's rmse: 0.0891909\n",
      "[700]\ttraining's rmse: 0.0851305\tvalid_1's rmse: 0.0891798\n",
      "[725]\ttraining's rmse: 0.085093\tvalid_1's rmse: 0.0891684\n",
      "[750]\ttraining's rmse: 0.0850555\tvalid_1's rmse: 0.0891582\n",
      "[775]\ttraining's rmse: 0.0850255\tvalid_1's rmse: 0.0891488\n",
      "[800]\ttraining's rmse: 0.084988\tvalid_1's rmse: 0.0891398\n",
      "[825]\ttraining's rmse: 0.0849559\tvalid_1's rmse: 0.0891313\n",
      "[850]\ttraining's rmse: 0.0849206\tvalid_1's rmse: 0.0891242\n",
      "[875]\ttraining's rmse: 0.0848926\tvalid_1's rmse: 0.0891169\n",
      "[900]\ttraining's rmse: 0.084862\tvalid_1's rmse: 0.0891098\n",
      "[925]\ttraining's rmse: 0.084835\tvalid_1's rmse: 0.0891012\n",
      "[950]\ttraining's rmse: 0.0848123\tvalid_1's rmse: 0.0890955\n",
      "[975]\ttraining's rmse: 0.0847871\tvalid_1's rmse: 0.089089\n",
      "[1000]\ttraining's rmse: 0.0847603\tvalid_1's rmse: 0.0890822\n",
      "[1025]\ttraining's rmse: 0.0847371\tvalid_1's rmse: 0.0890751\n",
      "[1050]\ttraining's rmse: 0.0847145\tvalid_1's rmse: 0.0890683\n",
      "[1075]\ttraining's rmse: 0.0846947\tvalid_1's rmse: 0.089065\n",
      "[1100]\ttraining's rmse: 0.0846758\tvalid_1's rmse: 0.0890597\n",
      "[1125]\ttraining's rmse: 0.0846545\tvalid_1's rmse: 0.0890535\n",
      "[1150]\ttraining's rmse: 0.0846369\tvalid_1's rmse: 0.0890478\n",
      "[1175]\ttraining's rmse: 0.0846189\tvalid_1's rmse: 0.0890439\n",
      "[1200]\ttraining's rmse: 0.0846005\tvalid_1's rmse: 0.0890378\n",
      "[1225]\ttraining's rmse: 0.0845828\tvalid_1's rmse: 0.089033\n",
      "[1250]\ttraining's rmse: 0.0845687\tvalid_1's rmse: 0.0890294\n",
      "[1275]\ttraining's rmse: 0.0845494\tvalid_1's rmse: 0.0890258\n",
      "[1300]\ttraining's rmse: 0.0845378\tvalid_1's rmse: 0.0890215\n",
      "[1325]\ttraining's rmse: 0.0845238\tvalid_1's rmse: 0.0890181\n",
      "[1350]\ttraining's rmse: 0.0845111\tvalid_1's rmse: 0.0890154\n",
      "[1375]\ttraining's rmse: 0.0844965\tvalid_1's rmse: 0.0890125\n",
      "[1400]\ttraining's rmse: 0.0844843\tvalid_1's rmse: 0.0890087\n",
      "[1425]\ttraining's rmse: 0.0844702\tvalid_1's rmse: 0.0890047\n",
      "[1450]\ttraining's rmse: 0.0844581\tvalid_1's rmse: 0.0890021\n",
      "[1475]\ttraining's rmse: 0.0844469\tvalid_1's rmse: 0.0889996\n",
      "[1500]\ttraining's rmse: 0.0844354\tvalid_1's rmse: 0.0889968\n",
      "[1525]\ttraining's rmse: 0.0844253\tvalid_1's rmse: 0.0889937\n",
      "[1550]\ttraining's rmse: 0.0844135\tvalid_1's rmse: 0.0889911\n",
      "[1575]\ttraining's rmse: 0.0844043\tvalid_1's rmse: 0.0889879\n",
      "[1600]\ttraining's rmse: 0.0843979\tvalid_1's rmse: 0.0889856\n",
      "[1625]\ttraining's rmse: 0.0843879\tvalid_1's rmse: 0.0889815\n",
      "[1650]\ttraining's rmse: 0.08438\tvalid_1's rmse: 0.0889787\n",
      "[1675]\ttraining's rmse: 0.0843726\tvalid_1's rmse: 0.0889762\n",
      "[1700]\ttraining's rmse: 0.0843651\tvalid_1's rmse: 0.0889737\n",
      "[1725]\ttraining's rmse: 0.0843587\tvalid_1's rmse: 0.0889713\n",
      "[1750]\ttraining's rmse: 0.0843502\tvalid_1's rmse: 0.0889683\n",
      "[1775]\ttraining's rmse: 0.0843427\tvalid_1's rmse: 0.0889672\n",
      "[1800]\ttraining's rmse: 0.0843362\tvalid_1's rmse: 0.0889648\n",
      "[1825]\ttraining's rmse: 0.0843306\tvalid_1's rmse: 0.0889628\n",
      "[1850]\ttraining's rmse: 0.0843254\tvalid_1's rmse: 0.0889606\n",
      "[1875]\ttraining's rmse: 0.0843183\tvalid_1's rmse: 0.0889589\n",
      "[1900]\ttraining's rmse: 0.0843114\tvalid_1's rmse: 0.0889564\n",
      "[1925]\ttraining's rmse: 0.084308\tvalid_1's rmse: 0.0889555\n",
      "[1950]\ttraining's rmse: 0.0843037\tvalid_1's rmse: 0.0889541\n",
      "[1975]\ttraining's rmse: 0.0842987\tvalid_1's rmse: 0.0889526\n",
      "[2000]\ttraining's rmse: 0.0842933\tvalid_1's rmse: 0.0889503\n",
      "[2025]\ttraining's rmse: 0.0842892\tvalid_1's rmse: 0.088949\n",
      "[2050]\ttraining's rmse: 0.0842847\tvalid_1's rmse: 0.0889482\n",
      "[2075]\ttraining's rmse: 0.0842813\tvalid_1's rmse: 0.0889466\n",
      "[2100]\ttraining's rmse: 0.084278\tvalid_1's rmse: 0.0889457\n",
      "[2125]\ttraining's rmse: 0.0842747\tvalid_1's rmse: 0.0889446\n",
      "[2150]\ttraining's rmse: 0.0842707\tvalid_1's rmse: 0.0889439\n",
      "[2175]\ttraining's rmse: 0.0842679\tvalid_1's rmse: 0.088943\n",
      "[2200]\ttraining's rmse: 0.0842635\tvalid_1's rmse: 0.088942\n",
      "[2225]\ttraining's rmse: 0.0842604\tvalid_1's rmse: 0.088941\n",
      "[2250]\ttraining's rmse: 0.0842568\tvalid_1's rmse: 0.0889396\n",
      "[2275]\ttraining's rmse: 0.0842516\tvalid_1's rmse: 0.088938\n",
      "[2300]\ttraining's rmse: 0.0842468\tvalid_1's rmse: 0.0889373\n",
      "[2325]\ttraining's rmse: 0.0842437\tvalid_1's rmse: 0.0889363\n",
      "[2350]\ttraining's rmse: 0.0842413\tvalid_1's rmse: 0.0889355\n",
      "[2375]\ttraining's rmse: 0.0842367\tvalid_1's rmse: 0.0889345\n",
      "[2400]\ttraining's rmse: 0.0842344\tvalid_1's rmse: 0.0889334\n",
      "[2425]\ttraining's rmse: 0.0842319\tvalid_1's rmse: 0.0889323\n",
      "[2450]\ttraining's rmse: 0.0842303\tvalid_1's rmse: 0.0889317\n",
      "[2475]\ttraining's rmse: 0.0842282\tvalid_1's rmse: 0.0889316\n",
      "[2500]\ttraining's rmse: 0.0842268\tvalid_1's rmse: 0.088931\n",
      "[2525]\ttraining's rmse: 0.0842252\tvalid_1's rmse: 0.088931\n",
      "Early stopping, best iteration is:\n",
      "[2484]\ttraining's rmse: 0.0842276\tvalid_1's rmse: 0.0889307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0872256\tvalid_1's rmse: 0.08995\n",
      "[50]\ttraining's rmse: 0.0870992\tvalid_1's rmse: 0.0898961\n",
      "[75]\ttraining's rmse: 0.0869661\tvalid_1's rmse: 0.0898433\n",
      "[100]\ttraining's rmse: 0.086851\tvalid_1's rmse: 0.0897973\n",
      "[125]\ttraining's rmse: 0.0867285\tvalid_1's rmse: 0.0897499\n",
      "[150]\ttraining's rmse: 0.0866159\tvalid_1's rmse: 0.0897061\n",
      "[175]\ttraining's rmse: 0.0865248\tvalid_1's rmse: 0.0896694\n",
      "[200]\ttraining's rmse: 0.0864219\tvalid_1's rmse: 0.0896336\n",
      "[225]\ttraining's rmse: 0.0863242\tvalid_1's rmse: 0.0895995\n",
      "[250]\ttraining's rmse: 0.0862398\tvalid_1's rmse: 0.089568\n",
      "[275]\ttraining's rmse: 0.086163\tvalid_1's rmse: 0.08954\n",
      "[300]\ttraining's rmse: 0.0860867\tvalid_1's rmse: 0.0895136\n",
      "[325]\ttraining's rmse: 0.0860076\tvalid_1's rmse: 0.0894884\n",
      "[350]\ttraining's rmse: 0.0859334\tvalid_1's rmse: 0.0894647\n",
      "[375]\ttraining's rmse: 0.0858749\tvalid_1's rmse: 0.0894445\n",
      "[400]\ttraining's rmse: 0.0858074\tvalid_1's rmse: 0.0894252\n",
      "[425]\ttraining's rmse: 0.0857454\tvalid_1's rmse: 0.089406\n",
      "[450]\ttraining's rmse: 0.0856905\tvalid_1's rmse: 0.0893895\n",
      "[475]\ttraining's rmse: 0.0856373\tvalid_1's rmse: 0.0893735\n",
      "[500]\ttraining's rmse: 0.085592\tvalid_1's rmse: 0.0893579\n",
      "[525]\ttraining's rmse: 0.0855317\tvalid_1's rmse: 0.0893424\n",
      "[550]\ttraining's rmse: 0.0854794\tvalid_1's rmse: 0.0893271\n",
      "[575]\ttraining's rmse: 0.0854303\tvalid_1's rmse: 0.0893131\n",
      "[600]\ttraining's rmse: 0.085383\tvalid_1's rmse: 0.0892994\n",
      "[625]\ttraining's rmse: 0.0853454\tvalid_1's rmse: 0.0892876\n",
      "[650]\ttraining's rmse: 0.0852978\tvalid_1's rmse: 0.0892752\n",
      "[675]\ttraining's rmse: 0.0852504\tvalid_1's rmse: 0.089264\n",
      "[700]\ttraining's rmse: 0.0852085\tvalid_1's rmse: 0.0892529\n",
      "[725]\ttraining's rmse: 0.0851709\tvalid_1's rmse: 0.0892436\n",
      "[750]\ttraining's rmse: 0.0851355\tvalid_1's rmse: 0.0892348\n",
      "[775]\ttraining's rmse: 0.0851048\tvalid_1's rmse: 0.0892261\n",
      "[800]\ttraining's rmse: 0.0850672\tvalid_1's rmse: 0.0892186\n",
      "[825]\ttraining's rmse: 0.0850333\tvalid_1's rmse: 0.0892099\n",
      "[850]\ttraining's rmse: 0.0849997\tvalid_1's rmse: 0.0892027\n",
      "[875]\ttraining's rmse: 0.0849703\tvalid_1's rmse: 0.0891962\n",
      "[900]\ttraining's rmse: 0.0849387\tvalid_1's rmse: 0.0891898\n",
      "[925]\ttraining's rmse: 0.0849099\tvalid_1's rmse: 0.0891849\n",
      "[950]\ttraining's rmse: 0.0848836\tvalid_1's rmse: 0.0891788\n",
      "[975]\ttraining's rmse: 0.0848592\tvalid_1's rmse: 0.0891742\n",
      "[1000]\ttraining's rmse: 0.0848363\tvalid_1's rmse: 0.0891699\n",
      "[1025]\ttraining's rmse: 0.0848096\tvalid_1's rmse: 0.0891654\n",
      "[1050]\ttraining's rmse: 0.0847862\tvalid_1's rmse: 0.08916\n",
      "[1075]\ttraining's rmse: 0.0847617\tvalid_1's rmse: 0.0891574\n",
      "[1100]\ttraining's rmse: 0.0847428\tvalid_1's rmse: 0.0891535\n",
      "[1125]\ttraining's rmse: 0.0847201\tvalid_1's rmse: 0.0891497\n",
      "[1150]\ttraining's rmse: 0.0847004\tvalid_1's rmse: 0.089147\n",
      "[1175]\ttraining's rmse: 0.084683\tvalid_1's rmse: 0.0891444\n",
      "[1200]\ttraining's rmse: 0.084665\tvalid_1's rmse: 0.0891418\n",
      "[1225]\ttraining's rmse: 0.0846455\tvalid_1's rmse: 0.0891388\n",
      "[1250]\ttraining's rmse: 0.084631\tvalid_1's rmse: 0.0891368\n",
      "[1275]\ttraining's rmse: 0.084612\tvalid_1's rmse: 0.089135\n",
      "[1300]\ttraining's rmse: 0.084597\tvalid_1's rmse: 0.0891329\n",
      "[1325]\ttraining's rmse: 0.084582\tvalid_1's rmse: 0.0891306\n",
      "[1350]\ttraining's rmse: 0.0845659\tvalid_1's rmse: 0.0891289\n",
      "[1375]\ttraining's rmse: 0.0845497\tvalid_1's rmse: 0.0891276\n",
      "[1400]\ttraining's rmse: 0.0845386\tvalid_1's rmse: 0.0891255\n",
      "[1425]\ttraining's rmse: 0.0845243\tvalid_1's rmse: 0.089125\n",
      "[1450]\ttraining's rmse: 0.0845109\tvalid_1's rmse: 0.0891241\n",
      "[1475]\ttraining's rmse: 0.0844975\tvalid_1's rmse: 0.0891231\n",
      "[1500]\ttraining's rmse: 0.084487\tvalid_1's rmse: 0.0891221\n",
      "[1525]\ttraining's rmse: 0.0844752\tvalid_1's rmse: 0.089121\n",
      "[1550]\ttraining's rmse: 0.0844657\tvalid_1's rmse: 0.0891203\n",
      "[1575]\ttraining's rmse: 0.0844562\tvalid_1's rmse: 0.0891196\n",
      "[1600]\ttraining's rmse: 0.0844487\tvalid_1's rmse: 0.0891193\n",
      "[1625]\ttraining's rmse: 0.0844387\tvalid_1's rmse: 0.0891185\n",
      "[1650]\ttraining's rmse: 0.0844301\tvalid_1's rmse: 0.0891181\n",
      "[1675]\ttraining's rmse: 0.0844223\tvalid_1's rmse: 0.0891173\n",
      "[1700]\ttraining's rmse: 0.0844148\tvalid_1's rmse: 0.0891158\n",
      "[1725]\ttraining's rmse: 0.0844088\tvalid_1's rmse: 0.0891153\n",
      "[1750]\ttraining's rmse: 0.0843994\tvalid_1's rmse: 0.0891147\n",
      "[1775]\ttraining's rmse: 0.0843909\tvalid_1's rmse: 0.0891142\n",
      "[1800]\ttraining's rmse: 0.0843838\tvalid_1's rmse: 0.089114\n",
      "[1825]\ttraining's rmse: 0.0843768\tvalid_1's rmse: 0.0891136\n",
      "[1850]\ttraining's rmse: 0.0843711\tvalid_1's rmse: 0.0891127\n",
      "[1875]\ttraining's rmse: 0.0843646\tvalid_1's rmse: 0.0891125\n",
      "[1900]\ttraining's rmse: 0.0843598\tvalid_1's rmse: 0.0891128\n",
      "Early stopping, best iteration is:\n",
      "[1863]\ttraining's rmse: 0.0843689\tvalid_1's rmse: 0.0891124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0898027\tvalid_1's rmse: 0.0847214\n",
      "[50]\ttraining's rmse: 0.0896813\tvalid_1's rmse: 0.0846721\n",
      "[75]\ttraining's rmse: 0.0895524\tvalid_1's rmse: 0.0846227\n",
      "[100]\ttraining's rmse: 0.0894422\tvalid_1's rmse: 0.0845807\n",
      "[125]\ttraining's rmse: 0.0893223\tvalid_1's rmse: 0.0845364\n",
      "[150]\ttraining's rmse: 0.0892154\tvalid_1's rmse: 0.0844985\n",
      "[175]\ttraining's rmse: 0.0891265\tvalid_1's rmse: 0.0844658\n",
      "[200]\ttraining's rmse: 0.0890278\tvalid_1's rmse: 0.0844325\n",
      "[225]\ttraining's rmse: 0.0889328\tvalid_1's rmse: 0.0844006\n",
      "[250]\ttraining's rmse: 0.0888546\tvalid_1's rmse: 0.0843742\n",
      "[275]\ttraining's rmse: 0.0887848\tvalid_1's rmse: 0.0843477\n",
      "[300]\ttraining's rmse: 0.0887142\tvalid_1's rmse: 0.0843233\n",
      "[325]\ttraining's rmse: 0.0886418\tvalid_1's rmse: 0.0843009\n",
      "[350]\ttraining's rmse: 0.0885706\tvalid_1's rmse: 0.0842788\n",
      "[375]\ttraining's rmse: 0.0885128\tvalid_1's rmse: 0.0842627\n",
      "[400]\ttraining's rmse: 0.0884515\tvalid_1's rmse: 0.0842488\n",
      "[425]\ttraining's rmse: 0.0883912\tvalid_1's rmse: 0.0842312\n",
      "[450]\ttraining's rmse: 0.0883366\tvalid_1's rmse: 0.0842163\n",
      "[475]\ttraining's rmse: 0.0882841\tvalid_1's rmse: 0.084202\n",
      "[500]\ttraining's rmse: 0.0882439\tvalid_1's rmse: 0.0841892\n",
      "[525]\ttraining's rmse: 0.0881864\tvalid_1's rmse: 0.0841782\n",
      "[550]\ttraining's rmse: 0.0881353\tvalid_1's rmse: 0.0841649\n",
      "[575]\ttraining's rmse: 0.0880883\tvalid_1's rmse: 0.0841522\n",
      "[600]\ttraining's rmse: 0.0880401\tvalid_1's rmse: 0.0841453\n",
      "[625]\ttraining's rmse: 0.0880051\tvalid_1's rmse: 0.0841379\n",
      "[650]\ttraining's rmse: 0.0879583\tvalid_1's rmse: 0.084132\n",
      "[675]\ttraining's rmse: 0.0879119\tvalid_1's rmse: 0.0841266\n",
      "[700]\ttraining's rmse: 0.0878718\tvalid_1's rmse: 0.0841193\n",
      "[725]\ttraining's rmse: 0.087834\tvalid_1's rmse: 0.0841139\n",
      "[750]\ttraining's rmse: 0.087797\tvalid_1's rmse: 0.0841214\n",
      "[775]\ttraining's rmse: 0.087767\tvalid_1's rmse: 0.0841206\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0878167\tvalid_1's rmse: 0.0841104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0867949\tvalid_1's rmse: 0.0893666\n",
      "[50]\ttraining's rmse: 0.0866621\tvalid_1's rmse: 0.0893123\n",
      "[75]\ttraining's rmse: 0.0865305\tvalid_1's rmse: 0.0892582\n",
      "[100]\ttraining's rmse: 0.086408\tvalid_1's rmse: 0.0892124\n",
      "[125]\ttraining's rmse: 0.0862828\tvalid_1's rmse: 0.0891632\n",
      "[150]\ttraining's rmse: 0.0861678\tvalid_1's rmse: 0.0891164\n",
      "[175]\ttraining's rmse: 0.0860734\tvalid_1's rmse: 0.0890781\n",
      "[200]\ttraining's rmse: 0.0859736\tvalid_1's rmse: 0.0890397\n",
      "[225]\ttraining's rmse: 0.0858767\tvalid_1's rmse: 0.0890033\n",
      "[250]\ttraining's rmse: 0.0857937\tvalid_1's rmse: 0.0889708\n",
      "[275]\ttraining's rmse: 0.0857135\tvalid_1's rmse: 0.0889416\n",
      "[300]\ttraining's rmse: 0.0856384\tvalid_1's rmse: 0.0889123\n",
      "[325]\ttraining's rmse: 0.0855627\tvalid_1's rmse: 0.0888866\n",
      "[350]\ttraining's rmse: 0.0854909\tvalid_1's rmse: 0.0888596\n",
      "[375]\ttraining's rmse: 0.085428\tvalid_1's rmse: 0.0888375\n",
      "[400]\ttraining's rmse: 0.0853598\tvalid_1's rmse: 0.0888147\n",
      "[425]\ttraining's rmse: 0.0852977\tvalid_1's rmse: 0.0887926\n",
      "[450]\ttraining's rmse: 0.0852407\tvalid_1's rmse: 0.0887709\n",
      "[475]\ttraining's rmse: 0.0851884\tvalid_1's rmse: 0.0887516\n",
      "[500]\ttraining's rmse: 0.0851435\tvalid_1's rmse: 0.0887336\n",
      "[525]\ttraining's rmse: 0.0850877\tvalid_1's rmse: 0.0887162\n",
      "[550]\ttraining's rmse: 0.0850355\tvalid_1's rmse: 0.0887006\n",
      "[575]\ttraining's rmse: 0.0849876\tvalid_1's rmse: 0.0886862\n",
      "[600]\ttraining's rmse: 0.0849414\tvalid_1's rmse: 0.0886727\n",
      "[625]\ttraining's rmse: 0.084903\tvalid_1's rmse: 0.0886597\n",
      "[650]\ttraining's rmse: 0.0848574\tvalid_1's rmse: 0.0886476\n",
      "[675]\ttraining's rmse: 0.0848129\tvalid_1's rmse: 0.0886346\n",
      "[700]\ttraining's rmse: 0.0847748\tvalid_1's rmse: 0.0886227\n",
      "[725]\ttraining's rmse: 0.0847367\tvalid_1's rmse: 0.0886117\n",
      "[750]\ttraining's rmse: 0.0847003\tvalid_1's rmse: 0.0886011\n",
      "[775]\ttraining's rmse: 0.0846718\tvalid_1's rmse: 0.0885905\n",
      "[800]\ttraining's rmse: 0.0846356\tvalid_1's rmse: 0.0885813\n",
      "[825]\ttraining's rmse: 0.0846064\tvalid_1's rmse: 0.0885724\n",
      "[850]\ttraining's rmse: 0.0845723\tvalid_1's rmse: 0.0885649\n",
      "[875]\ttraining's rmse: 0.0845445\tvalid_1's rmse: 0.0885573\n",
      "[900]\ttraining's rmse: 0.0845121\tvalid_1's rmse: 0.0885501\n",
      "[925]\ttraining's rmse: 0.0844834\tvalid_1's rmse: 0.0885418\n",
      "[950]\ttraining's rmse: 0.0844576\tvalid_1's rmse: 0.0885344\n",
      "[975]\ttraining's rmse: 0.0844353\tvalid_1's rmse: 0.0885288\n",
      "[1000]\ttraining's rmse: 0.0844109\tvalid_1's rmse: 0.0885223\n",
      "[1025]\ttraining's rmse: 0.0843871\tvalid_1's rmse: 0.0885172\n",
      "[1050]\ttraining's rmse: 0.0843658\tvalid_1's rmse: 0.0885104\n",
      "[1075]\ttraining's rmse: 0.0843467\tvalid_1's rmse: 0.0885053\n",
      "[1100]\ttraining's rmse: 0.0843276\tvalid_1's rmse: 0.0885001\n",
      "[1125]\ttraining's rmse: 0.0843086\tvalid_1's rmse: 0.0884943\n",
      "[1150]\ttraining's rmse: 0.0842898\tvalid_1's rmse: 0.0884898\n",
      "[1175]\ttraining's rmse: 0.0842735\tvalid_1's rmse: 0.0884863\n",
      "[1200]\ttraining's rmse: 0.0842586\tvalid_1's rmse: 0.0884811\n",
      "[1225]\ttraining's rmse: 0.0842426\tvalid_1's rmse: 0.088477\n",
      "[1250]\ttraining's rmse: 0.0842276\tvalid_1's rmse: 0.0884721\n",
      "[1275]\ttraining's rmse: 0.0842076\tvalid_1's rmse: 0.0884678\n",
      "[1300]\ttraining's rmse: 0.0841939\tvalid_1's rmse: 0.0884637\n",
      "[1325]\ttraining's rmse: 0.0841785\tvalid_1's rmse: 0.0884594\n",
      "[1350]\ttraining's rmse: 0.0841648\tvalid_1's rmse: 0.0884549\n",
      "[1375]\ttraining's rmse: 0.0841494\tvalid_1's rmse: 0.0884522\n",
      "[1400]\ttraining's rmse: 0.0841366\tvalid_1's rmse: 0.0884484\n",
      "[1425]\ttraining's rmse: 0.0841197\tvalid_1's rmse: 0.0884463\n",
      "[1450]\ttraining's rmse: 0.0841066\tvalid_1's rmse: 0.088443\n",
      "[1475]\ttraining's rmse: 0.0840959\tvalid_1's rmse: 0.0884397\n",
      "[1500]\ttraining's rmse: 0.0840856\tvalid_1's rmse: 0.0884375\n",
      "[1525]\ttraining's rmse: 0.0840767\tvalid_1's rmse: 0.0884356\n",
      "[1550]\ttraining's rmse: 0.0840652\tvalid_1's rmse: 0.0884321\n",
      "[1575]\ttraining's rmse: 0.0840568\tvalid_1's rmse: 0.0884292\n",
      "[1600]\ttraining's rmse: 0.0840491\tvalid_1's rmse: 0.0884264\n",
      "[1625]\ttraining's rmse: 0.0840404\tvalid_1's rmse: 0.0884236\n",
      "[1650]\ttraining's rmse: 0.084033\tvalid_1's rmse: 0.0884212\n",
      "[1675]\ttraining's rmse: 0.0840257\tvalid_1's rmse: 0.0884183\n",
      "[1700]\ttraining's rmse: 0.0840189\tvalid_1's rmse: 0.0884151\n",
      "[1725]\ttraining's rmse: 0.08401\tvalid_1's rmse: 0.0884129\n",
      "[1750]\ttraining's rmse: 0.0840031\tvalid_1's rmse: 0.0884101\n",
      "[1775]\ttraining's rmse: 0.0839954\tvalid_1's rmse: 0.088408\n",
      "[1800]\ttraining's rmse: 0.0839898\tvalid_1's rmse: 0.0884058\n",
      "[1825]\ttraining's rmse: 0.0839825\tvalid_1's rmse: 0.0884032\n",
      "[1850]\ttraining's rmse: 0.083977\tvalid_1's rmse: 0.0884009\n",
      "[1875]\ttraining's rmse: 0.0839713\tvalid_1's rmse: 0.0883999\n",
      "[1900]\ttraining's rmse: 0.0839671\tvalid_1's rmse: 0.0883985\n",
      "[1925]\ttraining's rmse: 0.0839612\tvalid_1's rmse: 0.0883969\n",
      "[1950]\ttraining's rmse: 0.0839573\tvalid_1's rmse: 0.088396\n",
      "[1975]\ttraining's rmse: 0.083954\tvalid_1's rmse: 0.0883951\n",
      "[2000]\ttraining's rmse: 0.0839476\tvalid_1's rmse: 0.0883932\n",
      "[2025]\ttraining's rmse: 0.083944\tvalid_1's rmse: 0.0883909\n",
      "[2050]\ttraining's rmse: 0.0839398\tvalid_1's rmse: 0.0883901\n",
      "[2075]\ttraining's rmse: 0.0839358\tvalid_1's rmse: 0.0883891\n",
      "[2100]\ttraining's rmse: 0.0839324\tvalid_1's rmse: 0.0883886\n",
      "[2125]\ttraining's rmse: 0.0839284\tvalid_1's rmse: 0.0883874\n",
      "[2150]\ttraining's rmse: 0.0839246\tvalid_1's rmse: 0.0883863\n",
      "[2175]\ttraining's rmse: 0.0839217\tvalid_1's rmse: 0.0883852\n",
      "[2200]\ttraining's rmse: 0.083917\tvalid_1's rmse: 0.088384\n",
      "[2225]\ttraining's rmse: 0.0839136\tvalid_1's rmse: 0.0883827\n",
      "[2250]\ttraining's rmse: 0.083911\tvalid_1's rmse: 0.0883819\n",
      "[2275]\ttraining's rmse: 0.0839094\tvalid_1's rmse: 0.0883818\n",
      "[2300]\ttraining's rmse: 0.0839061\tvalid_1's rmse: 0.0883809\n",
      "[2325]\ttraining's rmse: 0.0839033\tvalid_1's rmse: 0.0883801\n",
      "[2350]\ttraining's rmse: 0.0838986\tvalid_1's rmse: 0.0883791\n",
      "[2375]\ttraining's rmse: 0.0838952\tvalid_1's rmse: 0.0883777\n",
      "[2400]\ttraining's rmse: 0.0838914\tvalid_1's rmse: 0.0883765\n",
      "[2425]\ttraining's rmse: 0.083889\tvalid_1's rmse: 0.088375\n",
      "[2450]\ttraining's rmse: 0.0838864\tvalid_1's rmse: 0.0883741\n",
      "[2475]\ttraining's rmse: 0.0838847\tvalid_1's rmse: 0.0883742\n",
      "[2500]\ttraining's rmse: 0.0838825\tvalid_1's rmse: 0.0883738\n",
      "[2525]\ttraining's rmse: 0.0838808\tvalid_1's rmse: 0.0883729\n",
      "[2550]\ttraining's rmse: 0.0838789\tvalid_1's rmse: 0.0883725\n",
      "[2575]\ttraining's rmse: 0.0838765\tvalid_1's rmse: 0.0883724\n",
      "[2600]\ttraining's rmse: 0.0838731\tvalid_1's rmse: 0.0883717\n",
      "[2625]\ttraining's rmse: 0.0838715\tvalid_1's rmse: 0.0883709\n",
      "[2650]\ttraining's rmse: 0.0838692\tvalid_1's rmse: 0.0883703\n",
      "[2675]\ttraining's rmse: 0.0838668\tvalid_1's rmse: 0.0883702\n",
      "[2700]\ttraining's rmse: 0.0838645\tvalid_1's rmse: 0.08837\n",
      "[2725]\ttraining's rmse: 0.0838619\tvalid_1's rmse: 0.0883696\n",
      "[2750]\ttraining's rmse: 0.0838603\tvalid_1's rmse: 0.0883692\n",
      "[2775]\ttraining's rmse: 0.0838576\tvalid_1's rmse: 0.0883691\n",
      "[2800]\ttraining's rmse: 0.0838561\tvalid_1's rmse: 0.0883688\n",
      "[2825]\ttraining's rmse: 0.0838529\tvalid_1's rmse: 0.0883677\n",
      "[2850]\ttraining's rmse: 0.0838502\tvalid_1's rmse: 0.0883675\n",
      "[2875]\ttraining's rmse: 0.0838481\tvalid_1's rmse: 0.0883665\n",
      "[2900]\ttraining's rmse: 0.0838455\tvalid_1's rmse: 0.0883669\n",
      "Early stopping, best iteration is:\n",
      "[2871]\ttraining's rmse: 0.0838482\tvalid_1's rmse: 0.0883664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0867446\tvalid_1's rmse: 0.08947\n",
      "[50]\ttraining's rmse: 0.0866197\tvalid_1's rmse: 0.0894163\n",
      "[75]\ttraining's rmse: 0.0864913\tvalid_1's rmse: 0.0893643\n",
      "[100]\ttraining's rmse: 0.0863776\tvalid_1's rmse: 0.0893176\n",
      "[125]\ttraining's rmse: 0.0862556\tvalid_1's rmse: 0.0892711\n",
      "[150]\ttraining's rmse: 0.0861439\tvalid_1's rmse: 0.0892271\n",
      "[175]\ttraining's rmse: 0.0860563\tvalid_1's rmse: 0.0891912\n",
      "[200]\ttraining's rmse: 0.0859538\tvalid_1's rmse: 0.0891537\n",
      "[225]\ttraining's rmse: 0.0858585\tvalid_1's rmse: 0.0891191\n",
      "[250]\ttraining's rmse: 0.0857762\tvalid_1's rmse: 0.0890888\n",
      "[275]\ttraining's rmse: 0.0856982\tvalid_1's rmse: 0.0890608\n",
      "[300]\ttraining's rmse: 0.0856219\tvalid_1's rmse: 0.0890346\n",
      "[325]\ttraining's rmse: 0.0855451\tvalid_1's rmse: 0.0890099\n",
      "[350]\ttraining's rmse: 0.0854722\tvalid_1's rmse: 0.0889853\n",
      "[375]\ttraining's rmse: 0.0854091\tvalid_1's rmse: 0.0889638\n",
      "[400]\ttraining's rmse: 0.0853444\tvalid_1's rmse: 0.0889447\n",
      "[425]\ttraining's rmse: 0.0852851\tvalid_1's rmse: 0.0889251\n",
      "[450]\ttraining's rmse: 0.0852283\tvalid_1's rmse: 0.088906\n",
      "[475]\ttraining's rmse: 0.0851747\tvalid_1's rmse: 0.0888899\n",
      "[500]\ttraining's rmse: 0.0851312\tvalid_1's rmse: 0.0888739\n",
      "[525]\ttraining's rmse: 0.0850738\tvalid_1's rmse: 0.0888577\n",
      "[550]\ttraining's rmse: 0.0850204\tvalid_1's rmse: 0.0888427\n",
      "[575]\ttraining's rmse: 0.0849739\tvalid_1's rmse: 0.088829\n",
      "[600]\ttraining's rmse: 0.0849291\tvalid_1's rmse: 0.0888163\n",
      "[625]\ttraining's rmse: 0.0848928\tvalid_1's rmse: 0.088805\n",
      "[650]\ttraining's rmse: 0.0848453\tvalid_1's rmse: 0.088793\n",
      "[675]\ttraining's rmse: 0.0848003\tvalid_1's rmse: 0.0887814\n",
      "[700]\ttraining's rmse: 0.0847598\tvalid_1's rmse: 0.0887697\n",
      "[725]\ttraining's rmse: 0.0847222\tvalid_1's rmse: 0.0887599\n",
      "[750]\ttraining's rmse: 0.084687\tvalid_1's rmse: 0.0887517\n",
      "[775]\ttraining's rmse: 0.0846576\tvalid_1's rmse: 0.0887423\n",
      "[800]\ttraining's rmse: 0.0846172\tvalid_1's rmse: 0.0887347\n",
      "[825]\ttraining's rmse: 0.084584\tvalid_1's rmse: 0.0887259\n",
      "[850]\ttraining's rmse: 0.0845529\tvalid_1's rmse: 0.0887194\n",
      "[875]\ttraining's rmse: 0.0845237\tvalid_1's rmse: 0.0887131\n",
      "[900]\ttraining's rmse: 0.0844927\tvalid_1's rmse: 0.0887061\n",
      "[925]\ttraining's rmse: 0.0844659\tvalid_1's rmse: 0.0887012\n",
      "[950]\ttraining's rmse: 0.084439\tvalid_1's rmse: 0.0886962\n",
      "[975]\ttraining's rmse: 0.0844132\tvalid_1's rmse: 0.0886901\n",
      "[1000]\ttraining's rmse: 0.0843901\tvalid_1's rmse: 0.0886858\n",
      "[1025]\ttraining's rmse: 0.0843662\tvalid_1's rmse: 0.0886813\n",
      "[1050]\ttraining's rmse: 0.0843444\tvalid_1's rmse: 0.0886766\n",
      "[1075]\ttraining's rmse: 0.0843244\tvalid_1's rmse: 0.0886733\n",
      "[1100]\ttraining's rmse: 0.0843047\tvalid_1's rmse: 0.0886693\n",
      "[1125]\ttraining's rmse: 0.084285\tvalid_1's rmse: 0.088666\n",
      "[1150]\ttraining's rmse: 0.0842649\tvalid_1's rmse: 0.0886624\n",
      "[1175]\ttraining's rmse: 0.0842462\tvalid_1's rmse: 0.0886595\n",
      "[1200]\ttraining's rmse: 0.0842305\tvalid_1's rmse: 0.0886574\n",
      "[1225]\ttraining's rmse: 0.0842155\tvalid_1's rmse: 0.088655\n",
      "[1250]\ttraining's rmse: 0.0841983\tvalid_1's rmse: 0.0886534\n",
      "[1275]\ttraining's rmse: 0.0841817\tvalid_1's rmse: 0.0886507\n",
      "[1300]\ttraining's rmse: 0.0841671\tvalid_1's rmse: 0.0886486\n",
      "[1325]\ttraining's rmse: 0.0841549\tvalid_1's rmse: 0.0886468\n",
      "[1350]\ttraining's rmse: 0.0841402\tvalid_1's rmse: 0.0886449\n",
      "[1375]\ttraining's rmse: 0.0841238\tvalid_1's rmse: 0.0886426\n",
      "[1400]\ttraining's rmse: 0.08411\tvalid_1's rmse: 0.0886397\n",
      "[1425]\ttraining's rmse: 0.0840974\tvalid_1's rmse: 0.0886384\n",
      "[1450]\ttraining's rmse: 0.0840843\tvalid_1's rmse: 0.0886372\n",
      "[1475]\ttraining's rmse: 0.0840735\tvalid_1's rmse: 0.0886358\n",
      "[1500]\ttraining's rmse: 0.0840624\tvalid_1's rmse: 0.0886346\n",
      "[1525]\ttraining's rmse: 0.0840516\tvalid_1's rmse: 0.0886335\n",
      "[1550]\ttraining's rmse: 0.0840404\tvalid_1's rmse: 0.0886332\n",
      "[1575]\ttraining's rmse: 0.0840318\tvalid_1's rmse: 0.0886315\n",
      "[1600]\ttraining's rmse: 0.0840243\tvalid_1's rmse: 0.0886311\n",
      "[1625]\ttraining's rmse: 0.0840175\tvalid_1's rmse: 0.0886305\n",
      "[1650]\ttraining's rmse: 0.0840096\tvalid_1's rmse: 0.0886299\n",
      "[1675]\ttraining's rmse: 0.0840039\tvalid_1's rmse: 0.0886289\n",
      "[1700]\ttraining's rmse: 0.0839981\tvalid_1's rmse: 0.0886278\n",
      "[1725]\ttraining's rmse: 0.0839908\tvalid_1's rmse: 0.0886274\n",
      "[1750]\ttraining's rmse: 0.0839825\tvalid_1's rmse: 0.0886265\n",
      "[1775]\ttraining's rmse: 0.0839769\tvalid_1's rmse: 0.0886267\n",
      "[1800]\ttraining's rmse: 0.0839711\tvalid_1's rmse: 0.088626\n",
      "[1825]\ttraining's rmse: 0.0839645\tvalid_1's rmse: 0.0886249\n",
      "[1850]\ttraining's rmse: 0.0839577\tvalid_1's rmse: 0.0886243\n",
      "[1875]\ttraining's rmse: 0.083953\tvalid_1's rmse: 0.0886243\n",
      "[1900]\ttraining's rmse: 0.0839491\tvalid_1's rmse: 0.0886241\n",
      "[1925]\ttraining's rmse: 0.0839421\tvalid_1's rmse: 0.0886237\n",
      "[1950]\ttraining's rmse: 0.0839378\tvalid_1's rmse: 0.0886229\n",
      "[1975]\ttraining's rmse: 0.0839336\tvalid_1's rmse: 0.0886225\n",
      "[2000]\ttraining's rmse: 0.0839283\tvalid_1's rmse: 0.0886219\n",
      "[2025]\ttraining's rmse: 0.0839251\tvalid_1's rmse: 0.0886212\n",
      "[2050]\ttraining's rmse: 0.0839212\tvalid_1's rmse: 0.0886208\n",
      "[2075]\ttraining's rmse: 0.0839182\tvalid_1's rmse: 0.0886202\n",
      "[2100]\ttraining's rmse: 0.0839147\tvalid_1's rmse: 0.08862\n",
      "[2125]\ttraining's rmse: 0.0839115\tvalid_1's rmse: 0.0886195\n",
      "[2150]\ttraining's rmse: 0.083907\tvalid_1's rmse: 0.0886192\n",
      "[2175]\ttraining's rmse: 0.0839049\tvalid_1's rmse: 0.0886193\n",
      "[2200]\ttraining's rmse: 0.0839012\tvalid_1's rmse: 0.088619\n",
      "[2225]\ttraining's rmse: 0.0838975\tvalid_1's rmse: 0.0886188\n",
      "[2250]\ttraining's rmse: 0.083895\tvalid_1's rmse: 0.0886188\n",
      "[2275]\ttraining's rmse: 0.0838912\tvalid_1's rmse: 0.0886187\n",
      "[2300]\ttraining's rmse: 0.0838879\tvalid_1's rmse: 0.0886188\n",
      "[2325]\ttraining's rmse: 0.0838846\tvalid_1's rmse: 0.0886188\n",
      "Early stopping, best iteration is:\n",
      "[2287]\ttraining's rmse: 0.0838898\tvalid_1's rmse: 0.0886185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0892967\tvalid_1's rmse: 0.0842974\n",
      "[50]\ttraining's rmse: 0.0891834\tvalid_1's rmse: 0.0842482\n",
      "[75]\ttraining's rmse: 0.0890613\tvalid_1's rmse: 0.0841996\n",
      "[100]\ttraining's rmse: 0.0889547\tvalid_1's rmse: 0.0841583\n",
      "[125]\ttraining's rmse: 0.0888445\tvalid_1's rmse: 0.0841169\n",
      "[150]\ttraining's rmse: 0.0887434\tvalid_1's rmse: 0.0840788\n",
      "[175]\ttraining's rmse: 0.0886596\tvalid_1's rmse: 0.0840464\n",
      "[200]\ttraining's rmse: 0.088569\tvalid_1's rmse: 0.0840153\n",
      "[225]\ttraining's rmse: 0.0884825\tvalid_1's rmse: 0.0839859\n",
      "[250]\ttraining's rmse: 0.0884079\tvalid_1's rmse: 0.0839594\n",
      "[275]\ttraining's rmse: 0.088339\tvalid_1's rmse: 0.0839333\n",
      "[300]\ttraining's rmse: 0.0882716\tvalid_1's rmse: 0.08391\n",
      "[325]\ttraining's rmse: 0.0882005\tvalid_1's rmse: 0.0838859\n",
      "[350]\ttraining's rmse: 0.0881315\tvalid_1's rmse: 0.0838628\n",
      "[375]\ttraining's rmse: 0.0880736\tvalid_1's rmse: 0.0838436\n",
      "[400]\ttraining's rmse: 0.0880145\tvalid_1's rmse: 0.0838297\n",
      "[425]\ttraining's rmse: 0.0879578\tvalid_1's rmse: 0.0838151\n",
      "[450]\ttraining's rmse: 0.0879076\tvalid_1's rmse: 0.0837975\n",
      "[475]\ttraining's rmse: 0.0878585\tvalid_1's rmse: 0.0837891\n",
      "[500]\ttraining's rmse: 0.0878175\tvalid_1's rmse: 0.083782\n",
      "[525]\ttraining's rmse: 0.0877638\tvalid_1's rmse: 0.0837693\n",
      "[550]\ttraining's rmse: 0.087715\tvalid_1's rmse: 0.0837571\n",
      "[575]\ttraining's rmse: 0.0876675\tvalid_1's rmse: 0.0837458\n",
      "[600]\ttraining's rmse: 0.0876229\tvalid_1's rmse: 0.0837368\n",
      "[625]\ttraining's rmse: 0.0875873\tvalid_1's rmse: 0.0837327\n",
      "[650]\ttraining's rmse: 0.0875418\tvalid_1's rmse: 0.0837257\n",
      "[675]\ttraining's rmse: 0.0874971\tvalid_1's rmse: 0.0837173\n",
      "[700]\ttraining's rmse: 0.0874576\tvalid_1's rmse: 0.0837114\n",
      "[725]\ttraining's rmse: 0.0874194\tvalid_1's rmse: 0.083715\n",
      "[750]\ttraining's rmse: 0.0873844\tvalid_1's rmse: 0.0837202\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's rmse: 0.0874423\tvalid_1's rmse: 0.0837089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0880463\tvalid_1's rmse: 0.090592\n",
      "[50]\ttraining's rmse: 0.0878993\tvalid_1's rmse: 0.090539\n",
      "[75]\ttraining's rmse: 0.0877531\tvalid_1's rmse: 0.0904848\n",
      "[100]\ttraining's rmse: 0.0876162\tvalid_1's rmse: 0.0904388\n",
      "[125]\ttraining's rmse: 0.0874839\tvalid_1's rmse: 0.0903918\n",
      "[150]\ttraining's rmse: 0.0873603\tvalid_1's rmse: 0.0903493\n",
      "[175]\ttraining's rmse: 0.0872583\tvalid_1's rmse: 0.090313\n",
      "[200]\ttraining's rmse: 0.0871477\tvalid_1's rmse: 0.0902756\n",
      "[225]\ttraining's rmse: 0.0870404\tvalid_1's rmse: 0.0902407\n",
      "[250]\ttraining's rmse: 0.0869511\tvalid_1's rmse: 0.0902073\n",
      "[275]\ttraining's rmse: 0.0868679\tvalid_1's rmse: 0.0901793\n",
      "[300]\ttraining's rmse: 0.0867823\tvalid_1's rmse: 0.0901516\n",
      "[325]\ttraining's rmse: 0.0866963\tvalid_1's rmse: 0.090126\n",
      "[350]\ttraining's rmse: 0.0866151\tvalid_1's rmse: 0.0900996\n",
      "[375]\ttraining's rmse: 0.0865453\tvalid_1's rmse: 0.0900796\n",
      "[400]\ttraining's rmse: 0.0864722\tvalid_1's rmse: 0.0900577\n",
      "[425]\ttraining's rmse: 0.0864104\tvalid_1's rmse: 0.0900358\n",
      "[450]\ttraining's rmse: 0.0863497\tvalid_1's rmse: 0.0900163\n",
      "[475]\ttraining's rmse: 0.0862918\tvalid_1's rmse: 0.089999\n",
      "[500]\ttraining's rmse: 0.0862428\tvalid_1's rmse: 0.0899807\n",
      "[525]\ttraining's rmse: 0.0861815\tvalid_1's rmse: 0.0899642\n",
      "[550]\ttraining's rmse: 0.0861292\tvalid_1's rmse: 0.0899473\n",
      "[575]\ttraining's rmse: 0.0860764\tvalid_1's rmse: 0.0899338\n",
      "[600]\ttraining's rmse: 0.0860248\tvalid_1's rmse: 0.08992\n",
      "[625]\ttraining's rmse: 0.0859845\tvalid_1's rmse: 0.0899072\n",
      "[650]\ttraining's rmse: 0.0859371\tvalid_1's rmse: 0.0898943\n",
      "[675]\ttraining's rmse: 0.0858911\tvalid_1's rmse: 0.089882\n",
      "[700]\ttraining's rmse: 0.0858489\tvalid_1's rmse: 0.0898704\n",
      "[725]\ttraining's rmse: 0.0858088\tvalid_1's rmse: 0.0898596\n",
      "[750]\ttraining's rmse: 0.085772\tvalid_1's rmse: 0.0898495\n",
      "[775]\ttraining's rmse: 0.0857412\tvalid_1's rmse: 0.0898383\n",
      "[800]\ttraining's rmse: 0.0857065\tvalid_1's rmse: 0.0898287\n",
      "[825]\ttraining's rmse: 0.0856745\tvalid_1's rmse: 0.0898199\n",
      "[850]\ttraining's rmse: 0.0856377\tvalid_1's rmse: 0.0898115\n",
      "[875]\ttraining's rmse: 0.0856061\tvalid_1's rmse: 0.089802\n",
      "[900]\ttraining's rmse: 0.0855749\tvalid_1's rmse: 0.0897951\n",
      "[925]\ttraining's rmse: 0.0855448\tvalid_1's rmse: 0.0897883\n",
      "[950]\ttraining's rmse: 0.085518\tvalid_1's rmse: 0.0897808\n",
      "[975]\ttraining's rmse: 0.085492\tvalid_1's rmse: 0.0897736\n",
      "[1000]\ttraining's rmse: 0.0854654\tvalid_1's rmse: 0.0897682\n",
      "[1025]\ttraining's rmse: 0.0854405\tvalid_1's rmse: 0.08976\n",
      "[1050]\ttraining's rmse: 0.0854171\tvalid_1's rmse: 0.0897527\n",
      "[1075]\ttraining's rmse: 0.0853943\tvalid_1's rmse: 0.0897487\n",
      "[1100]\ttraining's rmse: 0.0853728\tvalid_1's rmse: 0.0897446\n",
      "[1125]\ttraining's rmse: 0.0853535\tvalid_1's rmse: 0.0897395\n",
      "[1150]\ttraining's rmse: 0.085331\tvalid_1's rmse: 0.0897337\n",
      "[1175]\ttraining's rmse: 0.0853133\tvalid_1's rmse: 0.0897294\n",
      "[1200]\ttraining's rmse: 0.0852946\tvalid_1's rmse: 0.0897242\n",
      "[1225]\ttraining's rmse: 0.0852782\tvalid_1's rmse: 0.0897208\n",
      "[1250]\ttraining's rmse: 0.0852623\tvalid_1's rmse: 0.0897164\n",
      "[1275]\ttraining's rmse: 0.0852407\tvalid_1's rmse: 0.0897133\n",
      "[1300]\ttraining's rmse: 0.0852263\tvalid_1's rmse: 0.0897083\n",
      "[1325]\ttraining's rmse: 0.0852103\tvalid_1's rmse: 0.0897036\n",
      "[1350]\ttraining's rmse: 0.0851961\tvalid_1's rmse: 0.0896996\n",
      "[1375]\ttraining's rmse: 0.0851802\tvalid_1's rmse: 0.0896972\n",
      "[1400]\ttraining's rmse: 0.0851677\tvalid_1's rmse: 0.0896942\n",
      "[1425]\ttraining's rmse: 0.0851521\tvalid_1's rmse: 0.089692\n",
      "[1450]\ttraining's rmse: 0.0851372\tvalid_1's rmse: 0.0896896\n",
      "[1475]\ttraining's rmse: 0.0851258\tvalid_1's rmse: 0.0896868\n",
      "[1500]\ttraining's rmse: 0.0851157\tvalid_1's rmse: 0.0896836\n",
      "[1525]\ttraining's rmse: 0.085103\tvalid_1's rmse: 0.0896805\n",
      "[1550]\ttraining's rmse: 0.0850924\tvalid_1's rmse: 0.0896781\n",
      "[1575]\ttraining's rmse: 0.0850843\tvalid_1's rmse: 0.0896751\n",
      "[1600]\ttraining's rmse: 0.0850743\tvalid_1's rmse: 0.0896705\n",
      "[1625]\ttraining's rmse: 0.085065\tvalid_1's rmse: 0.0896673\n",
      "[1650]\ttraining's rmse: 0.0850561\tvalid_1's rmse: 0.0896642\n",
      "[1675]\ttraining's rmse: 0.0850502\tvalid_1's rmse: 0.0896614\n",
      "[1700]\ttraining's rmse: 0.0850418\tvalid_1's rmse: 0.0896588\n",
      "[1725]\ttraining's rmse: 0.0850345\tvalid_1's rmse: 0.089656\n",
      "[1750]\ttraining's rmse: 0.0850267\tvalid_1's rmse: 0.0896541\n",
      "[1775]\ttraining's rmse: 0.0850196\tvalid_1's rmse: 0.0896522\n",
      "[1800]\ttraining's rmse: 0.0850118\tvalid_1's rmse: 0.08965\n",
      "[1825]\ttraining's rmse: 0.0850052\tvalid_1's rmse: 0.0896472\n",
      "[1850]\ttraining's rmse: 0.0849999\tvalid_1's rmse: 0.0896448\n",
      "[1875]\ttraining's rmse: 0.0849943\tvalid_1's rmse: 0.0896433\n",
      "[1900]\ttraining's rmse: 0.0849894\tvalid_1's rmse: 0.0896416\n",
      "[1925]\ttraining's rmse: 0.0849839\tvalid_1's rmse: 0.0896398\n",
      "[1950]\ttraining's rmse: 0.0849803\tvalid_1's rmse: 0.0896382\n",
      "[1975]\ttraining's rmse: 0.0849763\tvalid_1's rmse: 0.0896363\n",
      "[2000]\ttraining's rmse: 0.0849714\tvalid_1's rmse: 0.0896352\n",
      "[2025]\ttraining's rmse: 0.0849677\tvalid_1's rmse: 0.0896334\n",
      "[2050]\ttraining's rmse: 0.0849631\tvalid_1's rmse: 0.0896318\n",
      "[2075]\ttraining's rmse: 0.0849594\tvalid_1's rmse: 0.0896312\n",
      "[2100]\ttraining's rmse: 0.0849566\tvalid_1's rmse: 0.0896297\n",
      "[2125]\ttraining's rmse: 0.0849512\tvalid_1's rmse: 0.0896283\n",
      "[2150]\ttraining's rmse: 0.0849466\tvalid_1's rmse: 0.0896261\n",
      "[2175]\ttraining's rmse: 0.084943\tvalid_1's rmse: 0.0896255\n",
      "[2200]\ttraining's rmse: 0.0849392\tvalid_1's rmse: 0.0896245\n",
      "[2225]\ttraining's rmse: 0.0849361\tvalid_1's rmse: 0.0896238\n",
      "[2250]\ttraining's rmse: 0.0849304\tvalid_1's rmse: 0.0896227\n",
      "[2275]\ttraining's rmse: 0.0849262\tvalid_1's rmse: 0.089621\n",
      "[2300]\ttraining's rmse: 0.0849231\tvalid_1's rmse: 0.0896202\n",
      "[2325]\ttraining's rmse: 0.0849201\tvalid_1's rmse: 0.0896186\n",
      "[2350]\ttraining's rmse: 0.084917\tvalid_1's rmse: 0.0896182\n",
      "[2375]\ttraining's rmse: 0.0849144\tvalid_1's rmse: 0.0896175\n",
      "[2400]\ttraining's rmse: 0.084912\tvalid_1's rmse: 0.0896173\n",
      "[2425]\ttraining's rmse: 0.0849083\tvalid_1's rmse: 0.0896164\n",
      "[2450]\ttraining's rmse: 0.0849066\tvalid_1's rmse: 0.0896154\n",
      "[2475]\ttraining's rmse: 0.0849039\tvalid_1's rmse: 0.0896152\n",
      "[2500]\ttraining's rmse: 0.0849018\tvalid_1's rmse: 0.0896145\n",
      "[2525]\ttraining's rmse: 0.0848988\tvalid_1's rmse: 0.0896136\n",
      "[2550]\ttraining's rmse: 0.0848967\tvalid_1's rmse: 0.0896129\n",
      "[2575]\ttraining's rmse: 0.0848943\tvalid_1's rmse: 0.0896126\n",
      "[2600]\ttraining's rmse: 0.0848927\tvalid_1's rmse: 0.0896121\n",
      "[2625]\ttraining's rmse: 0.0848907\tvalid_1's rmse: 0.089611\n",
      "[2650]\ttraining's rmse: 0.0848881\tvalid_1's rmse: 0.0896111\n",
      "[2675]\ttraining's rmse: 0.0848857\tvalid_1's rmse: 0.0896104\n",
      "[2700]\ttraining's rmse: 0.0848842\tvalid_1's rmse: 0.0896096\n",
      "[2725]\ttraining's rmse: 0.0848811\tvalid_1's rmse: 0.0896086\n",
      "[2750]\ttraining's rmse: 0.084879\tvalid_1's rmse: 0.0896082\n",
      "[2775]\ttraining's rmse: 0.0848766\tvalid_1's rmse: 0.0896073\n",
      "[2800]\ttraining's rmse: 0.0848752\tvalid_1's rmse: 0.0896067\n",
      "[2825]\ttraining's rmse: 0.0848734\tvalid_1's rmse: 0.0896064\n",
      "[2850]\ttraining's rmse: 0.084871\tvalid_1's rmse: 0.0896051\n",
      "[2875]\ttraining's rmse: 0.0848694\tvalid_1's rmse: 0.0896047\n",
      "[2900]\ttraining's rmse: 0.0848679\tvalid_1's rmse: 0.0896043\n",
      "[2925]\ttraining's rmse: 0.0848668\tvalid_1's rmse: 0.0896039\n",
      "[2950]\ttraining's rmse: 0.0848653\tvalid_1's rmse: 0.0896039\n",
      "[2975]\ttraining's rmse: 0.0848633\tvalid_1's rmse: 0.0896042\n",
      "Early stopping, best iteration is:\n",
      "[2945]\ttraining's rmse: 0.0848655\tvalid_1's rmse: 0.0896038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0879791\tvalid_1's rmse: 0.0907415\n",
      "[50]\ttraining's rmse: 0.087852\tvalid_1's rmse: 0.0906873\n",
      "[75]\ttraining's rmse: 0.0877185\tvalid_1's rmse: 0.0906331\n",
      "[100]\ttraining's rmse: 0.0875976\tvalid_1's rmse: 0.0905863\n",
      "[125]\ttraining's rmse: 0.0874756\tvalid_1's rmse: 0.0905385\n",
      "[150]\ttraining's rmse: 0.0873612\tvalid_1's rmse: 0.0904939\n",
      "[175]\ttraining's rmse: 0.0872663\tvalid_1's rmse: 0.0904571\n",
      "[200]\ttraining's rmse: 0.0871625\tvalid_1's rmse: 0.090419\n",
      "[225]\ttraining's rmse: 0.0870637\tvalid_1's rmse: 0.0903851\n",
      "[250]\ttraining's rmse: 0.0869787\tvalid_1's rmse: 0.0903533\n",
      "[275]\ttraining's rmse: 0.0869014\tvalid_1's rmse: 0.0903255\n",
      "[300]\ttraining's rmse: 0.0868212\tvalid_1's rmse: 0.0902985\n",
      "[325]\ttraining's rmse: 0.0867394\tvalid_1's rmse: 0.0902717\n",
      "[350]\ttraining's rmse: 0.0866602\tvalid_1's rmse: 0.0902455\n",
      "[375]\ttraining's rmse: 0.086597\tvalid_1's rmse: 0.0902247\n",
      "[400]\ttraining's rmse: 0.0865281\tvalid_1's rmse: 0.0902047\n",
      "[425]\ttraining's rmse: 0.0864666\tvalid_1's rmse: 0.0901844\n",
      "[450]\ttraining's rmse: 0.0864075\tvalid_1's rmse: 0.0901648\n",
      "[475]\ttraining's rmse: 0.0863541\tvalid_1's rmse: 0.0901485\n",
      "[500]\ttraining's rmse: 0.0863098\tvalid_1's rmse: 0.0901324\n",
      "[525]\ttraining's rmse: 0.08625\tvalid_1's rmse: 0.0901152\n",
      "[550]\ttraining's rmse: 0.0861952\tvalid_1's rmse: 0.0901006\n",
      "[575]\ttraining's rmse: 0.0861475\tvalid_1's rmse: 0.0900869\n",
      "[600]\ttraining's rmse: 0.0860985\tvalid_1's rmse: 0.090074\n",
      "[625]\ttraining's rmse: 0.0860628\tvalid_1's rmse: 0.0900625\n",
      "[650]\ttraining's rmse: 0.0860145\tvalid_1's rmse: 0.0900504\n",
      "[675]\ttraining's rmse: 0.0859656\tvalid_1's rmse: 0.0900393\n",
      "[700]\ttraining's rmse: 0.0859241\tvalid_1's rmse: 0.0900276\n",
      "[725]\ttraining's rmse: 0.0858858\tvalid_1's rmse: 0.0900184\n",
      "[750]\ttraining's rmse: 0.0858502\tvalid_1's rmse: 0.0900095\n",
      "[775]\ttraining's rmse: 0.0858204\tvalid_1's rmse: 0.0900004\n",
      "[800]\ttraining's rmse: 0.0857791\tvalid_1's rmse: 0.0899931\n",
      "[825]\ttraining's rmse: 0.085746\tvalid_1's rmse: 0.0899855\n",
      "[850]\ttraining's rmse: 0.0857119\tvalid_1's rmse: 0.0899792\n",
      "[875]\ttraining's rmse: 0.0856821\tvalid_1's rmse: 0.0899733\n",
      "[900]\ttraining's rmse: 0.0856497\tvalid_1's rmse: 0.0899663\n",
      "[925]\ttraining's rmse: 0.0856215\tvalid_1's rmse: 0.0899609\n",
      "[950]\ttraining's rmse: 0.085596\tvalid_1's rmse: 0.089956\n",
      "[975]\ttraining's rmse: 0.0855691\tvalid_1's rmse: 0.0899503\n",
      "[1000]\ttraining's rmse: 0.0855451\tvalid_1's rmse: 0.0899461\n",
      "[1025]\ttraining's rmse: 0.085518\tvalid_1's rmse: 0.0899414\n",
      "[1050]\ttraining's rmse: 0.0854951\tvalid_1's rmse: 0.0899368\n",
      "[1075]\ttraining's rmse: 0.0854726\tvalid_1's rmse: 0.0899331\n",
      "[1100]\ttraining's rmse: 0.0854531\tvalid_1's rmse: 0.0899295\n",
      "[1125]\ttraining's rmse: 0.0854313\tvalid_1's rmse: 0.0899252\n",
      "[1150]\ttraining's rmse: 0.0854087\tvalid_1's rmse: 0.089922\n",
      "[1175]\ttraining's rmse: 0.0853898\tvalid_1's rmse: 0.0899198\n",
      "[1200]\ttraining's rmse: 0.0853711\tvalid_1's rmse: 0.0899167\n",
      "[1225]\ttraining's rmse: 0.0853522\tvalid_1's rmse: 0.0899138\n",
      "[1250]\ttraining's rmse: 0.0853367\tvalid_1's rmse: 0.0899112\n",
      "[1275]\ttraining's rmse: 0.0853171\tvalid_1's rmse: 0.0899101\n",
      "[1300]\ttraining's rmse: 0.0853011\tvalid_1's rmse: 0.0899089\n",
      "[1325]\ttraining's rmse: 0.0852858\tvalid_1's rmse: 0.0899071\n",
      "[1350]\ttraining's rmse: 0.0852698\tvalid_1's rmse: 0.0899045\n",
      "[1375]\ttraining's rmse: 0.0852545\tvalid_1's rmse: 0.089903\n",
      "[1400]\ttraining's rmse: 0.0852423\tvalid_1's rmse: 0.0899014\n",
      "[1425]\ttraining's rmse: 0.0852272\tvalid_1's rmse: 0.0899007\n",
      "[1450]\ttraining's rmse: 0.0852146\tvalid_1's rmse: 0.0898996\n",
      "[1475]\ttraining's rmse: 0.0852045\tvalid_1's rmse: 0.0898982\n",
      "[1500]\ttraining's rmse: 0.085194\tvalid_1's rmse: 0.0898973\n",
      "[1525]\ttraining's rmse: 0.0851824\tvalid_1's rmse: 0.0898965\n",
      "[1550]\ttraining's rmse: 0.0851726\tvalid_1's rmse: 0.0898952\n",
      "[1575]\ttraining's rmse: 0.0851625\tvalid_1's rmse: 0.0898939\n",
      "[1600]\ttraining's rmse: 0.0851526\tvalid_1's rmse: 0.089893\n",
      "[1625]\ttraining's rmse: 0.0851448\tvalid_1's rmse: 0.0898922\n",
      "[1650]\ttraining's rmse: 0.0851357\tvalid_1's rmse: 0.0898917\n",
      "[1675]\ttraining's rmse: 0.085128\tvalid_1's rmse: 0.089891\n",
      "[1700]\ttraining's rmse: 0.0851204\tvalid_1's rmse: 0.0898903\n",
      "[1725]\ttraining's rmse: 0.0851119\tvalid_1's rmse: 0.0898896\n",
      "[1750]\ttraining's rmse: 0.0851046\tvalid_1's rmse: 0.089889\n",
      "[1775]\ttraining's rmse: 0.0850968\tvalid_1's rmse: 0.0898887\n",
      "[1800]\ttraining's rmse: 0.0850919\tvalid_1's rmse: 0.0898879\n",
      "[1825]\ttraining's rmse: 0.0850848\tvalid_1's rmse: 0.0898875\n",
      "[1850]\ttraining's rmse: 0.0850783\tvalid_1's rmse: 0.0898872\n",
      "[1875]\ttraining's rmse: 0.0850737\tvalid_1's rmse: 0.0898869\n",
      "[1900]\ttraining's rmse: 0.0850686\tvalid_1's rmse: 0.0898859\n",
      "[1925]\ttraining's rmse: 0.0850643\tvalid_1's rmse: 0.0898859\n",
      "[1950]\ttraining's rmse: 0.0850607\tvalid_1's rmse: 0.0898851\n",
      "[1975]\ttraining's rmse: 0.0850561\tvalid_1's rmse: 0.0898847\n",
      "[2000]\ttraining's rmse: 0.0850509\tvalid_1's rmse: 0.0898843\n",
      "[2025]\ttraining's rmse: 0.0850474\tvalid_1's rmse: 0.0898833\n",
      "[2050]\ttraining's rmse: 0.0850429\tvalid_1's rmse: 0.0898838\n",
      "[2075]\ttraining's rmse: 0.0850395\tvalid_1's rmse: 0.0898829\n",
      "[2100]\ttraining's rmse: 0.0850361\tvalid_1's rmse: 0.0898828\n",
      "[2125]\ttraining's rmse: 0.0850323\tvalid_1's rmse: 0.0898824\n",
      "[2150]\ttraining's rmse: 0.0850278\tvalid_1's rmse: 0.089882\n",
      "[2175]\ttraining's rmse: 0.0850252\tvalid_1's rmse: 0.0898823\n",
      "[2200]\ttraining's rmse: 0.0850223\tvalid_1's rmse: 0.0898825\n",
      "Early stopping, best iteration is:\n",
      "[2162]\ttraining's rmse: 0.0850267\tvalid_1's rmse: 0.089882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0905305\tvalid_1's rmse: 0.0855508\n",
      "[50]\ttraining's rmse: 0.090408\tvalid_1's rmse: 0.085501\n",
      "[75]\ttraining's rmse: 0.0902764\tvalid_1's rmse: 0.0854522\n",
      "[100]\ttraining's rmse: 0.090159\tvalid_1's rmse: 0.0854108\n",
      "[125]\ttraining's rmse: 0.0900381\tvalid_1's rmse: 0.0853679\n",
      "[150]\ttraining's rmse: 0.0899276\tvalid_1's rmse: 0.0853307\n",
      "[175]\ttraining's rmse: 0.0898321\tvalid_1's rmse: 0.0853009\n",
      "[200]\ttraining's rmse: 0.0897312\tvalid_1's rmse: 0.0852686\n",
      "[225]\ttraining's rmse: 0.0896319\tvalid_1's rmse: 0.0852369\n",
      "[250]\ttraining's rmse: 0.0895472\tvalid_1's rmse: 0.0852108\n",
      "[275]\ttraining's rmse: 0.0894724\tvalid_1's rmse: 0.0851852\n",
      "[300]\ttraining's rmse: 0.0893973\tvalid_1's rmse: 0.0851608\n",
      "[325]\ttraining's rmse: 0.0893198\tvalid_1's rmse: 0.0851377\n",
      "[350]\ttraining's rmse: 0.0892435\tvalid_1's rmse: 0.0851156\n",
      "[375]\ttraining's rmse: 0.089184\tvalid_1's rmse: 0.085097\n",
      "[400]\ttraining's rmse: 0.0891176\tvalid_1's rmse: 0.0850794\n",
      "[425]\ttraining's rmse: 0.0890549\tvalid_1's rmse: 0.0850625\n",
      "[450]\ttraining's rmse: 0.0889986\tvalid_1's rmse: 0.0850478\n",
      "[475]\ttraining's rmse: 0.0889466\tvalid_1's rmse: 0.0850337\n",
      "[500]\ttraining's rmse: 0.0889021\tvalid_1's rmse: 0.085022\n",
      "[525]\ttraining's rmse: 0.0888414\tvalid_1's rmse: 0.0850076\n",
      "[550]\ttraining's rmse: 0.0887875\tvalid_1's rmse: 0.0849947\n",
      "[575]\ttraining's rmse: 0.0887363\tvalid_1's rmse: 0.0849835\n",
      "[600]\ttraining's rmse: 0.0886884\tvalid_1's rmse: 0.0849739\n",
      "[625]\ttraining's rmse: 0.0886495\tvalid_1's rmse: 0.0849697\n",
      "[650]\ttraining's rmse: 0.0886029\tvalid_1's rmse: 0.0849688\n",
      "[675]\ttraining's rmse: 0.0885529\tvalid_1's rmse: 0.0849618\n",
      "[700]\ttraining's rmse: 0.0885103\tvalid_1's rmse: 0.0849585\n",
      "[725]\ttraining's rmse: 0.088472\tvalid_1's rmse: 0.0849623\n",
      "[750]\ttraining's rmse: 0.0884359\tvalid_1's rmse: 0.0849662\n",
      "[775]\ttraining's rmse: 0.0884051\tvalid_1's rmse: 0.0849595\n",
      "Early stopping, best iteration is:\n",
      "[746]\ttraining's rmse: 0.0884428\tvalid_1's rmse: 0.0849561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0872043\tvalid_1's rmse: 0.0899717\n",
      "[50]\ttraining's rmse: 0.0870694\tvalid_1's rmse: 0.0899186\n",
      "[75]\ttraining's rmse: 0.0869356\tvalid_1's rmse: 0.0898667\n",
      "[100]\ttraining's rmse: 0.08681\tvalid_1's rmse: 0.0898189\n",
      "[125]\ttraining's rmse: 0.0866881\tvalid_1's rmse: 0.0897712\n",
      "[150]\ttraining's rmse: 0.0865767\tvalid_1's rmse: 0.0897267\n",
      "[175]\ttraining's rmse: 0.0864845\tvalid_1's rmse: 0.0896875\n",
      "[200]\ttraining's rmse: 0.0863845\tvalid_1's rmse: 0.08965\n",
      "[225]\ttraining's rmse: 0.0862847\tvalid_1's rmse: 0.0896138\n",
      "[250]\ttraining's rmse: 0.0862005\tvalid_1's rmse: 0.0895798\n",
      "[275]\ttraining's rmse: 0.0861221\tvalid_1's rmse: 0.0895508\n",
      "[300]\ttraining's rmse: 0.0860445\tvalid_1's rmse: 0.0895248\n",
      "[325]\ttraining's rmse: 0.0859697\tvalid_1's rmse: 0.089497\n",
      "[350]\ttraining's rmse: 0.0858972\tvalid_1's rmse: 0.0894715\n",
      "[375]\ttraining's rmse: 0.0858333\tvalid_1's rmse: 0.0894489\n",
      "[400]\ttraining's rmse: 0.0857667\tvalid_1's rmse: 0.0894266\n",
      "[425]\ttraining's rmse: 0.0857046\tvalid_1's rmse: 0.0894045\n",
      "[450]\ttraining's rmse: 0.0856459\tvalid_1's rmse: 0.0893828\n",
      "[475]\ttraining's rmse: 0.0855942\tvalid_1's rmse: 0.089363\n",
      "[500]\ttraining's rmse: 0.0855479\tvalid_1's rmse: 0.0893451\n",
      "[525]\ttraining's rmse: 0.08549\tvalid_1's rmse: 0.0893272\n",
      "[550]\ttraining's rmse: 0.08544\tvalid_1's rmse: 0.0893111\n",
      "[575]\ttraining's rmse: 0.0853921\tvalid_1's rmse: 0.089297\n",
      "[600]\ttraining's rmse: 0.0853444\tvalid_1's rmse: 0.0892828\n",
      "[625]\ttraining's rmse: 0.0853063\tvalid_1's rmse: 0.0892713\n",
      "[650]\ttraining's rmse: 0.0852645\tvalid_1's rmse: 0.0892583\n",
      "[675]\ttraining's rmse: 0.0852201\tvalid_1's rmse: 0.0892451\n",
      "[700]\ttraining's rmse: 0.0851819\tvalid_1's rmse: 0.089232\n",
      "[725]\ttraining's rmse: 0.0851451\tvalid_1's rmse: 0.0892215\n",
      "[750]\ttraining's rmse: 0.0851097\tvalid_1's rmse: 0.0892118\n",
      "[775]\ttraining's rmse: 0.0850812\tvalid_1's rmse: 0.0892003\n",
      "[800]\ttraining's rmse: 0.0850469\tvalid_1's rmse: 0.0891903\n",
      "[825]\ttraining's rmse: 0.0850181\tvalid_1's rmse: 0.0891817\n",
      "[850]\ttraining's rmse: 0.0849858\tvalid_1's rmse: 0.0891733\n",
      "[875]\ttraining's rmse: 0.0849598\tvalid_1's rmse: 0.0891666\n",
      "[900]\ttraining's rmse: 0.0849314\tvalid_1's rmse: 0.0891598\n",
      "[925]\ttraining's rmse: 0.0849067\tvalid_1's rmse: 0.0891522\n",
      "[950]\ttraining's rmse: 0.0848804\tvalid_1's rmse: 0.089146\n",
      "[975]\ttraining's rmse: 0.0848563\tvalid_1's rmse: 0.0891403\n",
      "[1000]\ttraining's rmse: 0.0848313\tvalid_1's rmse: 0.0891337\n",
      "[1025]\ttraining's rmse: 0.0848054\tvalid_1's rmse: 0.0891283\n",
      "[1050]\ttraining's rmse: 0.0847829\tvalid_1's rmse: 0.0891218\n",
      "[1075]\ttraining's rmse: 0.0847622\tvalid_1's rmse: 0.0891173\n",
      "[1100]\ttraining's rmse: 0.0847436\tvalid_1's rmse: 0.0891108\n",
      "[1125]\ttraining's rmse: 0.084725\tvalid_1's rmse: 0.0891051\n",
      "[1150]\ttraining's rmse: 0.0847047\tvalid_1's rmse: 0.0891009\n",
      "[1175]\ttraining's rmse: 0.0846876\tvalid_1's rmse: 0.0890971\n",
      "[1200]\ttraining's rmse: 0.0846701\tvalid_1's rmse: 0.0890928\n",
      "[1225]\ttraining's rmse: 0.0846529\tvalid_1's rmse: 0.089088\n",
      "[1250]\ttraining's rmse: 0.0846366\tvalid_1's rmse: 0.0890825\n",
      "[1275]\ttraining's rmse: 0.0846203\tvalid_1's rmse: 0.0890793\n",
      "[1300]\ttraining's rmse: 0.0846075\tvalid_1's rmse: 0.089075\n",
      "[1325]\ttraining's rmse: 0.0845899\tvalid_1's rmse: 0.0890706\n",
      "[1350]\ttraining's rmse: 0.0845739\tvalid_1's rmse: 0.0890672\n",
      "[1375]\ttraining's rmse: 0.0845592\tvalid_1's rmse: 0.0890638\n",
      "[1400]\ttraining's rmse: 0.0845481\tvalid_1's rmse: 0.0890606\n",
      "[1425]\ttraining's rmse: 0.0845346\tvalid_1's rmse: 0.0890564\n",
      "[1450]\ttraining's rmse: 0.0845192\tvalid_1's rmse: 0.089053\n",
      "[1475]\ttraining's rmse: 0.084508\tvalid_1's rmse: 0.0890499\n",
      "[1500]\ttraining's rmse: 0.0844984\tvalid_1's rmse: 0.089047\n",
      "[1525]\ttraining's rmse: 0.0844867\tvalid_1's rmse: 0.0890441\n",
      "[1550]\ttraining's rmse: 0.0844778\tvalid_1's rmse: 0.0890421\n",
      "[1575]\ttraining's rmse: 0.0844691\tvalid_1's rmse: 0.0890395\n",
      "[1600]\ttraining's rmse: 0.0844602\tvalid_1's rmse: 0.0890358\n",
      "[1625]\ttraining's rmse: 0.0844529\tvalid_1's rmse: 0.0890329\n",
      "[1650]\ttraining's rmse: 0.0844432\tvalid_1's rmse: 0.0890317\n",
      "[1675]\ttraining's rmse: 0.0844379\tvalid_1's rmse: 0.0890287\n",
      "[1700]\ttraining's rmse: 0.0844316\tvalid_1's rmse: 0.0890267\n",
      "[1725]\ttraining's rmse: 0.0844265\tvalid_1's rmse: 0.0890245\n",
      "[1750]\ttraining's rmse: 0.0844198\tvalid_1's rmse: 0.0890232\n",
      "[1775]\ttraining's rmse: 0.0844134\tvalid_1's rmse: 0.0890213\n",
      "[1800]\ttraining's rmse: 0.0844072\tvalid_1's rmse: 0.0890182\n",
      "[1825]\ttraining's rmse: 0.084402\tvalid_1's rmse: 0.0890162\n",
      "[1850]\ttraining's rmse: 0.0843965\tvalid_1's rmse: 0.0890144\n",
      "[1875]\ttraining's rmse: 0.0843894\tvalid_1's rmse: 0.0890133\n",
      "[1900]\ttraining's rmse: 0.0843851\tvalid_1's rmse: 0.0890113\n",
      "[1925]\ttraining's rmse: 0.0843782\tvalid_1's rmse: 0.0890087\n",
      "[1950]\ttraining's rmse: 0.0843732\tvalid_1's rmse: 0.0890067\n",
      "[1975]\ttraining's rmse: 0.0843673\tvalid_1's rmse: 0.0890041\n",
      "[2000]\ttraining's rmse: 0.0843631\tvalid_1's rmse: 0.0890028\n",
      "[2025]\ttraining's rmse: 0.0843588\tvalid_1's rmse: 0.0890014\n",
      "[2050]\ttraining's rmse: 0.0843533\tvalid_1's rmse: 0.0889997\n",
      "[2075]\ttraining's rmse: 0.08435\tvalid_1's rmse: 0.0889978\n",
      "[2100]\ttraining's rmse: 0.0843459\tvalid_1's rmse: 0.088996\n",
      "[2125]\ttraining's rmse: 0.0843423\tvalid_1's rmse: 0.0889949\n",
      "[2150]\ttraining's rmse: 0.0843373\tvalid_1's rmse: 0.0889937\n",
      "[2175]\ttraining's rmse: 0.0843321\tvalid_1's rmse: 0.0889921\n",
      "[2200]\ttraining's rmse: 0.0843289\tvalid_1's rmse: 0.0889912\n",
      "[2225]\ttraining's rmse: 0.0843261\tvalid_1's rmse: 0.0889908\n",
      "[2250]\ttraining's rmse: 0.0843219\tvalid_1's rmse: 0.0889902\n",
      "[2275]\ttraining's rmse: 0.0843179\tvalid_1's rmse: 0.0889894\n",
      "[2300]\ttraining's rmse: 0.0843146\tvalid_1's rmse: 0.0889872\n",
      "[2325]\ttraining's rmse: 0.0843118\tvalid_1's rmse: 0.0889864\n",
      "[2350]\ttraining's rmse: 0.0843089\tvalid_1's rmse: 0.0889848\n",
      "[2375]\ttraining's rmse: 0.0843049\tvalid_1's rmse: 0.0889835\n",
      "[2400]\ttraining's rmse: 0.0843017\tvalid_1's rmse: 0.0889826\n",
      "[2425]\ttraining's rmse: 0.0842986\tvalid_1's rmse: 0.0889817\n",
      "[2450]\ttraining's rmse: 0.084297\tvalid_1's rmse: 0.0889806\n",
      "[2475]\ttraining's rmse: 0.0842944\tvalid_1's rmse: 0.0889798\n",
      "[2500]\ttraining's rmse: 0.0842923\tvalid_1's rmse: 0.0889795\n",
      "[2525]\ttraining's rmse: 0.0842894\tvalid_1's rmse: 0.0889791\n",
      "[2550]\ttraining's rmse: 0.0842872\tvalid_1's rmse: 0.0889786\n",
      "[2575]\ttraining's rmse: 0.0842852\tvalid_1's rmse: 0.0889782\n",
      "[2600]\ttraining's rmse: 0.0842821\tvalid_1's rmse: 0.0889777\n",
      "[2625]\ttraining's rmse: 0.0842806\tvalid_1's rmse: 0.0889772\n",
      "[2650]\ttraining's rmse: 0.0842785\tvalid_1's rmse: 0.0889761\n",
      "[2675]\ttraining's rmse: 0.0842772\tvalid_1's rmse: 0.0889749\n",
      "[2700]\ttraining's rmse: 0.0842745\tvalid_1's rmse: 0.0889736\n",
      "[2725]\ttraining's rmse: 0.0842733\tvalid_1's rmse: 0.0889739\n",
      "[2750]\ttraining's rmse: 0.0842715\tvalid_1's rmse: 0.0889734\n",
      "[2775]\ttraining's rmse: 0.0842671\tvalid_1's rmse: 0.088973\n",
      "[2800]\ttraining's rmse: 0.0842654\tvalid_1's rmse: 0.0889729\n",
      "[2825]\ttraining's rmse: 0.0842632\tvalid_1's rmse: 0.0889724\n",
      "[2850]\ttraining's rmse: 0.0842609\tvalid_1's rmse: 0.0889717\n",
      "[2875]\ttraining's rmse: 0.0842593\tvalid_1's rmse: 0.0889718\n",
      "[2900]\ttraining's rmse: 0.0842584\tvalid_1's rmse: 0.0889721\n",
      "Early stopping, best iteration is:\n",
      "[2858]\ttraining's rmse: 0.0842602\tvalid_1's rmse: 0.0889717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0872518\tvalid_1's rmse: 0.0898879\n",
      "[50]\ttraining's rmse: 0.0871287\tvalid_1's rmse: 0.0898347\n",
      "[75]\ttraining's rmse: 0.0869987\tvalid_1's rmse: 0.0897826\n",
      "[100]\ttraining's rmse: 0.0868826\tvalid_1's rmse: 0.0897344\n",
      "[125]\ttraining's rmse: 0.086761\tvalid_1's rmse: 0.0896867\n",
      "[150]\ttraining's rmse: 0.0866499\tvalid_1's rmse: 0.0896441\n",
      "[175]\ttraining's rmse: 0.0865591\tvalid_1's rmse: 0.089609\n",
      "[200]\ttraining's rmse: 0.0864572\tvalid_1's rmse: 0.0895739\n",
      "[225]\ttraining's rmse: 0.086357\tvalid_1's rmse: 0.0895388\n",
      "[250]\ttraining's rmse: 0.086276\tvalid_1's rmse: 0.0895087\n",
      "[275]\ttraining's rmse: 0.0861991\tvalid_1's rmse: 0.0894805\n",
      "[300]\ttraining's rmse: 0.0861237\tvalid_1's rmse: 0.0894536\n",
      "[325]\ttraining's rmse: 0.086045\tvalid_1's rmse: 0.0894275\n",
      "[350]\ttraining's rmse: 0.0859718\tvalid_1's rmse: 0.089404\n",
      "[375]\ttraining's rmse: 0.085911\tvalid_1's rmse: 0.0893835\n",
      "[400]\ttraining's rmse: 0.0858444\tvalid_1's rmse: 0.0893629\n",
      "[425]\ttraining's rmse: 0.0857824\tvalid_1's rmse: 0.0893424\n",
      "[450]\ttraining's rmse: 0.085727\tvalid_1's rmse: 0.0893249\n",
      "[475]\ttraining's rmse: 0.0856762\tvalid_1's rmse: 0.0893086\n",
      "[500]\ttraining's rmse: 0.0856317\tvalid_1's rmse: 0.089293\n",
      "[525]\ttraining's rmse: 0.0855735\tvalid_1's rmse: 0.0892769\n",
      "[550]\ttraining's rmse: 0.0855224\tvalid_1's rmse: 0.089262\n",
      "[575]\ttraining's rmse: 0.0854739\tvalid_1's rmse: 0.0892485\n",
      "[600]\ttraining's rmse: 0.0854276\tvalid_1's rmse: 0.0892355\n",
      "[625]\ttraining's rmse: 0.085391\tvalid_1's rmse: 0.0892242\n",
      "[650]\ttraining's rmse: 0.0853447\tvalid_1's rmse: 0.0892119\n",
      "[675]\ttraining's rmse: 0.0852979\tvalid_1's rmse: 0.0892005\n",
      "[700]\ttraining's rmse: 0.0852579\tvalid_1's rmse: 0.0891904\n",
      "[725]\ttraining's rmse: 0.0852215\tvalid_1's rmse: 0.089181\n",
      "[750]\ttraining's rmse: 0.0851865\tvalid_1's rmse: 0.0891729\n",
      "[775]\ttraining's rmse: 0.0851536\tvalid_1's rmse: 0.0891641\n",
      "[800]\ttraining's rmse: 0.0851165\tvalid_1's rmse: 0.089157\n",
      "[825]\ttraining's rmse: 0.0850845\tvalid_1's rmse: 0.0891484\n",
      "[850]\ttraining's rmse: 0.0850517\tvalid_1's rmse: 0.0891419\n",
      "[875]\ttraining's rmse: 0.0850218\tvalid_1's rmse: 0.089135\n",
      "[900]\ttraining's rmse: 0.0849896\tvalid_1's rmse: 0.0891288\n",
      "[925]\ttraining's rmse: 0.0849613\tvalid_1's rmse: 0.0891232\n",
      "[950]\ttraining's rmse: 0.0849332\tvalid_1's rmse: 0.0891177\n",
      "[975]\ttraining's rmse: 0.0849096\tvalid_1's rmse: 0.0891119\n",
      "[1000]\ttraining's rmse: 0.084885\tvalid_1's rmse: 0.0891066\n",
      "[1025]\ttraining's rmse: 0.0848625\tvalid_1's rmse: 0.0891028\n",
      "[1050]\ttraining's rmse: 0.0848373\tvalid_1's rmse: 0.089098\n",
      "[1075]\ttraining's rmse: 0.0848164\tvalid_1's rmse: 0.0890947\n",
      "[1100]\ttraining's rmse: 0.0847997\tvalid_1's rmse: 0.0890907\n",
      "[1125]\ttraining's rmse: 0.0847804\tvalid_1's rmse: 0.0890867\n",
      "[1150]\ttraining's rmse: 0.084761\tvalid_1's rmse: 0.0890839\n",
      "[1175]\ttraining's rmse: 0.084745\tvalid_1's rmse: 0.0890813\n",
      "[1200]\ttraining's rmse: 0.0847277\tvalid_1's rmse: 0.0890782\n",
      "[1225]\ttraining's rmse: 0.084708\tvalid_1's rmse: 0.0890756\n",
      "[1250]\ttraining's rmse: 0.0846948\tvalid_1's rmse: 0.0890731\n",
      "[1275]\ttraining's rmse: 0.084677\tvalid_1's rmse: 0.0890714\n",
      "[1300]\ttraining's rmse: 0.0846619\tvalid_1's rmse: 0.0890683\n",
      "[1325]\ttraining's rmse: 0.084649\tvalid_1's rmse: 0.0890668\n",
      "[1350]\ttraining's rmse: 0.0846366\tvalid_1's rmse: 0.0890655\n",
      "[1375]\ttraining's rmse: 0.0846209\tvalid_1's rmse: 0.0890641\n",
      "[1400]\ttraining's rmse: 0.0846108\tvalid_1's rmse: 0.0890614\n",
      "[1425]\ttraining's rmse: 0.0845971\tvalid_1's rmse: 0.0890599\n",
      "[1450]\ttraining's rmse: 0.0845853\tvalid_1's rmse: 0.0890586\n",
      "[1475]\ttraining's rmse: 0.0845727\tvalid_1's rmse: 0.0890562\n",
      "[1500]\ttraining's rmse: 0.0845636\tvalid_1's rmse: 0.0890547\n",
      "[1525]\ttraining's rmse: 0.0845522\tvalid_1's rmse: 0.0890534\n",
      "[1550]\ttraining's rmse: 0.0845421\tvalid_1's rmse: 0.0890519\n",
      "[1575]\ttraining's rmse: 0.0845323\tvalid_1's rmse: 0.0890509\n",
      "[1600]\ttraining's rmse: 0.0845244\tvalid_1's rmse: 0.0890506\n",
      "[1625]\ttraining's rmse: 0.084516\tvalid_1's rmse: 0.0890495\n",
      "[1650]\ttraining's rmse: 0.0845078\tvalid_1's rmse: 0.089049\n",
      "[1675]\ttraining's rmse: 0.0845018\tvalid_1's rmse: 0.0890482\n",
      "[1700]\ttraining's rmse: 0.0844943\tvalid_1's rmse: 0.0890473\n",
      "[1725]\ttraining's rmse: 0.0844874\tvalid_1's rmse: 0.089047\n",
      "[1750]\ttraining's rmse: 0.084479\tvalid_1's rmse: 0.0890459\n",
      "[1775]\ttraining's rmse: 0.0844728\tvalid_1's rmse: 0.0890454\n",
      "[1800]\ttraining's rmse: 0.0844652\tvalid_1's rmse: 0.0890451\n",
      "[1825]\ttraining's rmse: 0.0844588\tvalid_1's rmse: 0.089044\n",
      "[1850]\ttraining's rmse: 0.0844533\tvalid_1's rmse: 0.0890431\n",
      "[1875]\ttraining's rmse: 0.0844474\tvalid_1's rmse: 0.0890429\n",
      "[1900]\ttraining's rmse: 0.0844412\tvalid_1's rmse: 0.0890421\n",
      "[1925]\ttraining's rmse: 0.0844344\tvalid_1's rmse: 0.0890414\n",
      "[1950]\ttraining's rmse: 0.0844297\tvalid_1's rmse: 0.0890406\n",
      "[1975]\ttraining's rmse: 0.0844253\tvalid_1's rmse: 0.0890398\n",
      "[2000]\ttraining's rmse: 0.0844197\tvalid_1's rmse: 0.0890395\n",
      "[2025]\ttraining's rmse: 0.0844156\tvalid_1's rmse: 0.0890389\n",
      "[2050]\ttraining's rmse: 0.0844109\tvalid_1's rmse: 0.0890387\n",
      "[2075]\ttraining's rmse: 0.0844064\tvalid_1's rmse: 0.0890385\n",
      "[2100]\ttraining's rmse: 0.0844035\tvalid_1's rmse: 0.0890387\n",
      "Early stopping, best iteration is:\n",
      "[2069]\ttraining's rmse: 0.0844074\tvalid_1's rmse: 0.0890383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0898068\tvalid_1's rmse: 0.0847042\n",
      "[50]\ttraining's rmse: 0.0896931\tvalid_1's rmse: 0.0846551\n",
      "[75]\ttraining's rmse: 0.0895728\tvalid_1's rmse: 0.0846069\n",
      "[100]\ttraining's rmse: 0.0894642\tvalid_1's rmse: 0.0845658\n",
      "[125]\ttraining's rmse: 0.0893517\tvalid_1's rmse: 0.0845237\n",
      "[150]\ttraining's rmse: 0.0892519\tvalid_1's rmse: 0.0844865\n",
      "[175]\ttraining's rmse: 0.0891668\tvalid_1's rmse: 0.0844536\n",
      "[200]\ttraining's rmse: 0.0890761\tvalid_1's rmse: 0.0844224\n",
      "[225]\ttraining's rmse: 0.0889886\tvalid_1's rmse: 0.0843892\n",
      "[250]\ttraining's rmse: 0.0889118\tvalid_1's rmse: 0.0843631\n",
      "[275]\ttraining's rmse: 0.0888429\tvalid_1's rmse: 0.0843375\n",
      "[300]\ttraining's rmse: 0.0887726\tvalid_1's rmse: 0.0843138\n",
      "[325]\ttraining's rmse: 0.0887035\tvalid_1's rmse: 0.0842926\n",
      "[350]\ttraining's rmse: 0.0886317\tvalid_1's rmse: 0.0842692\n",
      "[375]\ttraining's rmse: 0.0885754\tvalid_1's rmse: 0.0842556\n",
      "[400]\ttraining's rmse: 0.0885137\tvalid_1's rmse: 0.0842392\n",
      "[425]\ttraining's rmse: 0.0884553\tvalid_1's rmse: 0.0842233\n",
      "[450]\ttraining's rmse: 0.0884024\tvalid_1's rmse: 0.0842061\n",
      "[475]\ttraining's rmse: 0.0883523\tvalid_1's rmse: 0.0841928\n",
      "[500]\ttraining's rmse: 0.0883104\tvalid_1's rmse: 0.0841803\n",
      "[525]\ttraining's rmse: 0.0882532\tvalid_1's rmse: 0.0841653\n",
      "[550]\ttraining's rmse: 0.0882016\tvalid_1's rmse: 0.0841513\n",
      "[575]\ttraining's rmse: 0.0881549\tvalid_1's rmse: 0.0841396\n",
      "[600]\ttraining's rmse: 0.0881083\tvalid_1's rmse: 0.0841309\n",
      "[625]\ttraining's rmse: 0.0880714\tvalid_1's rmse: 0.0841279\n",
      "[650]\ttraining's rmse: 0.0880268\tvalid_1's rmse: 0.0841216\n",
      "[675]\ttraining's rmse: 0.0879812\tvalid_1's rmse: 0.0841113\n",
      "[700]\ttraining's rmse: 0.0879415\tvalid_1's rmse: 0.0841059\n",
      "[725]\ttraining's rmse: 0.0879048\tvalid_1's rmse: 0.0841035\n",
      "[750]\ttraining's rmse: 0.0878688\tvalid_1's rmse: 0.0841028\n",
      "[775]\ttraining's rmse: 0.0878395\tvalid_1's rmse: 0.0840958\n",
      "[800]\ttraining's rmse: 0.0878037\tvalid_1's rmse: 0.0840907\n",
      "[825]\ttraining's rmse: 0.0877707\tvalid_1's rmse: 0.0840923\n",
      "[850]\ttraining's rmse: 0.087739\tvalid_1's rmse: 0.0840865\n",
      "[875]\ttraining's rmse: 0.0877117\tvalid_1's rmse: 0.084084\n",
      "[900]\ttraining's rmse: 0.0876791\tvalid_1's rmse: 0.0840897\n",
      "Early stopping, best iteration is:\n",
      "[872]\ttraining's rmse: 0.0877138\tvalid_1's rmse: 0.0840804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.089082\tvalid_1's rmse: 0.0913671\n",
      "[50]\ttraining's rmse: 0.0889353\tvalid_1's rmse: 0.0913125\n",
      "[75]\ttraining's rmse: 0.0887874\tvalid_1's rmse: 0.0912578\n",
      "[100]\ttraining's rmse: 0.0886485\tvalid_1's rmse: 0.0912092\n",
      "[125]\ttraining's rmse: 0.0885129\tvalid_1's rmse: 0.0911633\n",
      "[150]\ttraining's rmse: 0.0883864\tvalid_1's rmse: 0.0911188\n",
      "[175]\ttraining's rmse: 0.0882783\tvalid_1's rmse: 0.0910816\n",
      "[200]\ttraining's rmse: 0.0881689\tvalid_1's rmse: 0.0910434\n",
      "[225]\ttraining's rmse: 0.0880586\tvalid_1's rmse: 0.0910086\n",
      "[250]\ttraining's rmse: 0.0879687\tvalid_1's rmse: 0.0909752\n",
      "[275]\ttraining's rmse: 0.0878843\tvalid_1's rmse: 0.090945\n",
      "[300]\ttraining's rmse: 0.0877976\tvalid_1's rmse: 0.0909152\n",
      "[325]\ttraining's rmse: 0.0877162\tvalid_1's rmse: 0.0908878\n",
      "[350]\ttraining's rmse: 0.0876342\tvalid_1's rmse: 0.0908611\n",
      "[375]\ttraining's rmse: 0.0875639\tvalid_1's rmse: 0.0908395\n",
      "[400]\ttraining's rmse: 0.0874882\tvalid_1's rmse: 0.090816\n",
      "[425]\ttraining's rmse: 0.0874216\tvalid_1's rmse: 0.0907943\n",
      "[450]\ttraining's rmse: 0.0873603\tvalid_1's rmse: 0.0907754\n",
      "[475]\ttraining's rmse: 0.0872991\tvalid_1's rmse: 0.0907559\n",
      "[500]\ttraining's rmse: 0.0872512\tvalid_1's rmse: 0.090738\n",
      "[525]\ttraining's rmse: 0.0871924\tvalid_1's rmse: 0.0907211\n",
      "[550]\ttraining's rmse: 0.0871375\tvalid_1's rmse: 0.0907039\n",
      "[575]\ttraining's rmse: 0.0870814\tvalid_1's rmse: 0.0906883\n",
      "[600]\ttraining's rmse: 0.0870342\tvalid_1's rmse: 0.0906746\n",
      "[625]\ttraining's rmse: 0.0869931\tvalid_1's rmse: 0.0906612\n",
      "[650]\ttraining's rmse: 0.0869418\tvalid_1's rmse: 0.0906485\n",
      "[675]\ttraining's rmse: 0.0868909\tvalid_1's rmse: 0.0906353\n",
      "[700]\ttraining's rmse: 0.0868488\tvalid_1's rmse: 0.0906234\n",
      "[725]\ttraining's rmse: 0.0868101\tvalid_1's rmse: 0.0906113\n",
      "[750]\ttraining's rmse: 0.0867717\tvalid_1's rmse: 0.0906006\n",
      "[775]\ttraining's rmse: 0.0867411\tvalid_1's rmse: 0.09059\n",
      "[800]\ttraining's rmse: 0.086703\tvalid_1's rmse: 0.0905803\n",
      "[825]\ttraining's rmse: 0.086673\tvalid_1's rmse: 0.090572\n",
      "[850]\ttraining's rmse: 0.0866364\tvalid_1's rmse: 0.0905638\n",
      "[875]\ttraining's rmse: 0.0866067\tvalid_1's rmse: 0.0905556\n",
      "[900]\ttraining's rmse: 0.0865765\tvalid_1's rmse: 0.0905492\n",
      "[925]\ttraining's rmse: 0.0865453\tvalid_1's rmse: 0.0905411\n",
      "[950]\ttraining's rmse: 0.0865182\tvalid_1's rmse: 0.0905339\n",
      "[975]\ttraining's rmse: 0.0864937\tvalid_1's rmse: 0.0905279\n",
      "[1000]\ttraining's rmse: 0.086468\tvalid_1's rmse: 0.0905208\n",
      "[1025]\ttraining's rmse: 0.0864462\tvalid_1's rmse: 0.0905146\n",
      "[1050]\ttraining's rmse: 0.0864233\tvalid_1's rmse: 0.0905084\n",
      "[1075]\ttraining's rmse: 0.0863992\tvalid_1's rmse: 0.0905032\n",
      "[1100]\ttraining's rmse: 0.0863799\tvalid_1's rmse: 0.0904991\n",
      "[1125]\ttraining's rmse: 0.0863615\tvalid_1's rmse: 0.0904931\n",
      "[1150]\ttraining's rmse: 0.0863395\tvalid_1's rmse: 0.0904869\n",
      "[1175]\ttraining's rmse: 0.0863183\tvalid_1's rmse: 0.090483\n",
      "[1200]\ttraining's rmse: 0.0862987\tvalid_1's rmse: 0.0904772\n",
      "[1225]\ttraining's rmse: 0.0862787\tvalid_1's rmse: 0.0904727\n",
      "[1250]\ttraining's rmse: 0.0862638\tvalid_1's rmse: 0.090468\n",
      "[1275]\ttraining's rmse: 0.0862453\tvalid_1's rmse: 0.0904636\n",
      "[1300]\ttraining's rmse: 0.0862295\tvalid_1's rmse: 0.0904578\n",
      "[1325]\ttraining's rmse: 0.0862126\tvalid_1's rmse: 0.0904544\n",
      "[1350]\ttraining's rmse: 0.0861967\tvalid_1's rmse: 0.0904499\n",
      "[1375]\ttraining's rmse: 0.0861807\tvalid_1's rmse: 0.0904456\n",
      "[1400]\ttraining's rmse: 0.086168\tvalid_1's rmse: 0.0904417\n",
      "[1425]\ttraining's rmse: 0.0861522\tvalid_1's rmse: 0.0904388\n",
      "[1450]\ttraining's rmse: 0.08614\tvalid_1's rmse: 0.0904355\n",
      "[1475]\ttraining's rmse: 0.0861297\tvalid_1's rmse: 0.0904319\n",
      "[1500]\ttraining's rmse: 0.0861181\tvalid_1's rmse: 0.0904289\n",
      "[1525]\ttraining's rmse: 0.0861064\tvalid_1's rmse: 0.0904264\n",
      "[1550]\ttraining's rmse: 0.0860954\tvalid_1's rmse: 0.0904225\n",
      "[1575]\ttraining's rmse: 0.0860851\tvalid_1's rmse: 0.0904175\n",
      "[1600]\ttraining's rmse: 0.0860779\tvalid_1's rmse: 0.0904149\n",
      "[1625]\ttraining's rmse: 0.0860692\tvalid_1's rmse: 0.0904122\n",
      "[1650]\ttraining's rmse: 0.0860618\tvalid_1's rmse: 0.0904092\n",
      "[1675]\ttraining's rmse: 0.0860537\tvalid_1's rmse: 0.0904071\n",
      "[1700]\ttraining's rmse: 0.0860475\tvalid_1's rmse: 0.0904043\n",
      "[1725]\ttraining's rmse: 0.0860408\tvalid_1's rmse: 0.0904028\n",
      "[1750]\ttraining's rmse: 0.0860323\tvalid_1's rmse: 0.0904007\n",
      "[1775]\ttraining's rmse: 0.0860256\tvalid_1's rmse: 0.0903984\n",
      "[1800]\ttraining's rmse: 0.08602\tvalid_1's rmse: 0.0903966\n",
      "[1825]\ttraining's rmse: 0.0860132\tvalid_1's rmse: 0.0903937\n",
      "[1850]\ttraining's rmse: 0.0860063\tvalid_1's rmse: 0.0903917\n",
      "[1875]\ttraining's rmse: 0.0859972\tvalid_1's rmse: 0.0903889\n",
      "[1900]\ttraining's rmse: 0.0859921\tvalid_1's rmse: 0.0903871\n",
      "[1925]\ttraining's rmse: 0.0859867\tvalid_1's rmse: 0.0903853\n",
      "[1950]\ttraining's rmse: 0.0859822\tvalid_1's rmse: 0.0903836\n",
      "[1975]\ttraining's rmse: 0.0859776\tvalid_1's rmse: 0.0903825\n",
      "[2000]\ttraining's rmse: 0.0859716\tvalid_1's rmse: 0.0903807\n",
      "[2025]\ttraining's rmse: 0.0859682\tvalid_1's rmse: 0.0903786\n",
      "[2050]\ttraining's rmse: 0.0859632\tvalid_1's rmse: 0.090378\n",
      "[2075]\ttraining's rmse: 0.0859605\tvalid_1's rmse: 0.0903775\n",
      "[2100]\ttraining's rmse: 0.0859564\tvalid_1's rmse: 0.0903763\n",
      "[2125]\ttraining's rmse: 0.0859527\tvalid_1's rmse: 0.0903755\n",
      "[2150]\ttraining's rmse: 0.0859478\tvalid_1's rmse: 0.0903747\n",
      "[2175]\ttraining's rmse: 0.0859431\tvalid_1's rmse: 0.090373\n",
      "[2200]\ttraining's rmse: 0.085941\tvalid_1's rmse: 0.0903724\n",
      "[2225]\ttraining's rmse: 0.0859368\tvalid_1's rmse: 0.090372\n",
      "[2250]\ttraining's rmse: 0.0859337\tvalid_1's rmse: 0.0903715\n",
      "[2275]\ttraining's rmse: 0.0859293\tvalid_1's rmse: 0.0903705\n",
      "[2300]\ttraining's rmse: 0.0859256\tvalid_1's rmse: 0.0903698\n",
      "[2325]\ttraining's rmse: 0.0859229\tvalid_1's rmse: 0.0903684\n",
      "[2350]\ttraining's rmse: 0.0859207\tvalid_1's rmse: 0.090367\n",
      "[2375]\ttraining's rmse: 0.0859174\tvalid_1's rmse: 0.0903666\n",
      "[2400]\ttraining's rmse: 0.0859148\tvalid_1's rmse: 0.0903655\n",
      "[2425]\ttraining's rmse: 0.085912\tvalid_1's rmse: 0.0903647\n",
      "[2450]\ttraining's rmse: 0.0859093\tvalid_1's rmse: 0.0903639\n",
      "[2475]\ttraining's rmse: 0.085906\tvalid_1's rmse: 0.090363\n",
      "[2500]\ttraining's rmse: 0.085903\tvalid_1's rmse: 0.0903618\n",
      "[2525]\ttraining's rmse: 0.0858998\tvalid_1's rmse: 0.0903608\n",
      "[2550]\ttraining's rmse: 0.0858965\tvalid_1's rmse: 0.0903599\n",
      "[2575]\ttraining's rmse: 0.0858941\tvalid_1's rmse: 0.0903591\n",
      "[2600]\ttraining's rmse: 0.0858919\tvalid_1's rmse: 0.0903584\n",
      "[2625]\ttraining's rmse: 0.0858903\tvalid_1's rmse: 0.0903577\n",
      "[2650]\ttraining's rmse: 0.0858881\tvalid_1's rmse: 0.0903572\n",
      "[2675]\ttraining's rmse: 0.0858852\tvalid_1's rmse: 0.0903569\n",
      "[2700]\ttraining's rmse: 0.0858834\tvalid_1's rmse: 0.0903563\n",
      "[2725]\ttraining's rmse: 0.0858814\tvalid_1's rmse: 0.0903556\n",
      "[2750]\ttraining's rmse: 0.0858776\tvalid_1's rmse: 0.0903548\n",
      "[2775]\ttraining's rmse: 0.0858765\tvalid_1's rmse: 0.090355\n",
      "[2800]\ttraining's rmse: 0.0858743\tvalid_1's rmse: 0.0903543\n",
      "[2825]\ttraining's rmse: 0.0858734\tvalid_1's rmse: 0.0903543\n",
      "[2850]\ttraining's rmse: 0.0858705\tvalid_1's rmse: 0.0903536\n",
      "[2875]\ttraining's rmse: 0.0858688\tvalid_1's rmse: 0.0903531\n",
      "[2900]\ttraining's rmse: 0.0858661\tvalid_1's rmse: 0.0903526\n",
      "[2925]\ttraining's rmse: 0.0858652\tvalid_1's rmse: 0.0903524\n",
      "[2950]\ttraining's rmse: 0.0858637\tvalid_1's rmse: 0.0903527\n",
      "Early stopping, best iteration is:\n",
      "[2911]\ttraining's rmse: 0.0858657\tvalid_1's rmse: 0.0903523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0889677\tvalid_1's rmse: 0.091616\n",
      "[50]\ttraining's rmse: 0.0888353\tvalid_1's rmse: 0.0915623\n",
      "[75]\ttraining's rmse: 0.0886972\tvalid_1's rmse: 0.0915075\n",
      "[100]\ttraining's rmse: 0.088574\tvalid_1's rmse: 0.0914589\n",
      "[125]\ttraining's rmse: 0.0884457\tvalid_1's rmse: 0.0914125\n",
      "[150]\ttraining's rmse: 0.0883262\tvalid_1's rmse: 0.0913687\n",
      "[175]\ttraining's rmse: 0.0882296\tvalid_1's rmse: 0.091332\n",
      "[200]\ttraining's rmse: 0.0881239\tvalid_1's rmse: 0.0912932\n",
      "[225]\ttraining's rmse: 0.0880241\tvalid_1's rmse: 0.0912588\n",
      "[250]\ttraining's rmse: 0.0879368\tvalid_1's rmse: 0.091226\n",
      "[275]\ttraining's rmse: 0.0878556\tvalid_1's rmse: 0.0911982\n",
      "[300]\ttraining's rmse: 0.087775\tvalid_1's rmse: 0.0911699\n",
      "[325]\ttraining's rmse: 0.0876944\tvalid_1's rmse: 0.0911439\n",
      "[350]\ttraining's rmse: 0.087614\tvalid_1's rmse: 0.0911189\n",
      "[375]\ttraining's rmse: 0.0875519\tvalid_1's rmse: 0.0910979\n",
      "[400]\ttraining's rmse: 0.0874817\tvalid_1's rmse: 0.0910778\n",
      "[425]\ttraining's rmse: 0.0874173\tvalid_1's rmse: 0.0910576\n",
      "[450]\ttraining's rmse: 0.0873581\tvalid_1's rmse: 0.0910398\n",
      "[475]\ttraining's rmse: 0.0873052\tvalid_1's rmse: 0.0910234\n",
      "[500]\ttraining's rmse: 0.0872579\tvalid_1's rmse: 0.0910071\n",
      "[525]\ttraining's rmse: 0.0871976\tvalid_1's rmse: 0.09099\n",
      "[550]\ttraining's rmse: 0.0871437\tvalid_1's rmse: 0.0909746\n",
      "[575]\ttraining's rmse: 0.0870949\tvalid_1's rmse: 0.0909608\n",
      "[600]\ttraining's rmse: 0.0870466\tvalid_1's rmse: 0.0909486\n",
      "[625]\ttraining's rmse: 0.0870105\tvalid_1's rmse: 0.0909372\n",
      "[650]\ttraining's rmse: 0.0869625\tvalid_1's rmse: 0.0909253\n",
      "[675]\ttraining's rmse: 0.0869148\tvalid_1's rmse: 0.0909148\n",
      "[700]\ttraining's rmse: 0.0868735\tvalid_1's rmse: 0.0909041\n",
      "[725]\ttraining's rmse: 0.0868344\tvalid_1's rmse: 0.0908946\n",
      "[750]\ttraining's rmse: 0.0867992\tvalid_1's rmse: 0.0908857\n",
      "[775]\ttraining's rmse: 0.086769\tvalid_1's rmse: 0.0908775\n",
      "[800]\ttraining's rmse: 0.0867304\tvalid_1's rmse: 0.0908704\n",
      "[825]\ttraining's rmse: 0.0866984\tvalid_1's rmse: 0.0908616\n",
      "[850]\ttraining's rmse: 0.0866659\tvalid_1's rmse: 0.0908559\n",
      "[875]\ttraining's rmse: 0.0866359\tvalid_1's rmse: 0.0908497\n",
      "[900]\ttraining's rmse: 0.0866023\tvalid_1's rmse: 0.0908421\n",
      "[925]\ttraining's rmse: 0.0865719\tvalid_1's rmse: 0.0908369\n",
      "[950]\ttraining's rmse: 0.086541\tvalid_1's rmse: 0.0908311\n",
      "[975]\ttraining's rmse: 0.0865158\tvalid_1's rmse: 0.0908265\n",
      "[1000]\ttraining's rmse: 0.08649\tvalid_1's rmse: 0.0908213\n",
      "[1025]\ttraining's rmse: 0.086462\tvalid_1's rmse: 0.0908175\n",
      "[1050]\ttraining's rmse: 0.0864394\tvalid_1's rmse: 0.0908121\n",
      "[1075]\ttraining's rmse: 0.0864157\tvalid_1's rmse: 0.0908091\n",
      "[1100]\ttraining's rmse: 0.0863969\tvalid_1's rmse: 0.0908054\n",
      "[1125]\ttraining's rmse: 0.0863762\tvalid_1's rmse: 0.0908022\n",
      "[1150]\ttraining's rmse: 0.0863523\tvalid_1's rmse: 0.0907992\n",
      "[1175]\ttraining's rmse: 0.0863338\tvalid_1's rmse: 0.0907968\n",
      "[1200]\ttraining's rmse: 0.0863169\tvalid_1's rmse: 0.0907945\n",
      "[1225]\ttraining's rmse: 0.0863009\tvalid_1's rmse: 0.0907927\n",
      "[1250]\ttraining's rmse: 0.0862836\tvalid_1's rmse: 0.09079\n",
      "[1275]\ttraining's rmse: 0.0862634\tvalid_1's rmse: 0.0907885\n",
      "[1300]\ttraining's rmse: 0.0862469\tvalid_1's rmse: 0.0907859\n",
      "[1325]\ttraining's rmse: 0.0862328\tvalid_1's rmse: 0.0907843\n",
      "[1350]\ttraining's rmse: 0.0862156\tvalid_1's rmse: 0.0907823\n",
      "[1375]\ttraining's rmse: 0.0862004\tvalid_1's rmse: 0.0907814\n",
      "[1400]\ttraining's rmse: 0.0861872\tvalid_1's rmse: 0.0907795\n",
      "[1425]\ttraining's rmse: 0.0861724\tvalid_1's rmse: 0.0907787\n",
      "[1450]\ttraining's rmse: 0.0861588\tvalid_1's rmse: 0.0907774\n",
      "[1475]\ttraining's rmse: 0.0861465\tvalid_1's rmse: 0.0907757\n",
      "[1500]\ttraining's rmse: 0.0861353\tvalid_1's rmse: 0.0907742\n",
      "[1525]\ttraining's rmse: 0.0861225\tvalid_1's rmse: 0.0907734\n",
      "[1550]\ttraining's rmse: 0.0861119\tvalid_1's rmse: 0.0907727\n",
      "[1575]\ttraining's rmse: 0.0861013\tvalid_1's rmse: 0.0907714\n",
      "[1600]\ttraining's rmse: 0.0860945\tvalid_1's rmse: 0.0907712\n",
      "[1625]\ttraining's rmse: 0.0860837\tvalid_1's rmse: 0.0907707\n",
      "[1650]\ttraining's rmse: 0.0860729\tvalid_1's rmse: 0.0907698\n",
      "[1675]\ttraining's rmse: 0.0860658\tvalid_1's rmse: 0.0907689\n",
      "[1700]\ttraining's rmse: 0.0860589\tvalid_1's rmse: 0.0907682\n",
      "[1725]\ttraining's rmse: 0.0860509\tvalid_1's rmse: 0.0907677\n",
      "[1750]\ttraining's rmse: 0.086043\tvalid_1's rmse: 0.0907673\n",
      "[1775]\ttraining's rmse: 0.0860361\tvalid_1's rmse: 0.0907669\n",
      "[1800]\ttraining's rmse: 0.0860289\tvalid_1's rmse: 0.0907669\n",
      "[1825]\ttraining's rmse: 0.0860214\tvalid_1's rmse: 0.0907666\n",
      "[1850]\ttraining's rmse: 0.0860153\tvalid_1's rmse: 0.0907651\n",
      "[1875]\ttraining's rmse: 0.0860083\tvalid_1's rmse: 0.0907646\n",
      "[1900]\ttraining's rmse: 0.0860029\tvalid_1's rmse: 0.0907647\n",
      "[1925]\ttraining's rmse: 0.0859964\tvalid_1's rmse: 0.0907639\n",
      "[1950]\ttraining's rmse: 0.0859924\tvalid_1's rmse: 0.0907635\n",
      "[1975]\ttraining's rmse: 0.085987\tvalid_1's rmse: 0.0907629\n",
      "[2000]\ttraining's rmse: 0.0859816\tvalid_1's rmse: 0.0907621\n",
      "[2025]\ttraining's rmse: 0.0859776\tvalid_1's rmse: 0.0907615\n",
      "[2050]\ttraining's rmse: 0.0859724\tvalid_1's rmse: 0.0907615\n",
      "[2075]\ttraining's rmse: 0.0859677\tvalid_1's rmse: 0.0907611\n",
      "[2100]\ttraining's rmse: 0.085964\tvalid_1's rmse: 0.0907611\n",
      "[2125]\ttraining's rmse: 0.0859597\tvalid_1's rmse: 0.0907607\n",
      "[2150]\ttraining's rmse: 0.0859566\tvalid_1's rmse: 0.0907606\n",
      "[2175]\ttraining's rmse: 0.0859532\tvalid_1's rmse: 0.0907601\n",
      "[2200]\ttraining's rmse: 0.0859485\tvalid_1's rmse: 0.0907596\n",
      "[2225]\ttraining's rmse: 0.0859453\tvalid_1's rmse: 0.0907592\n",
      "[2250]\ttraining's rmse: 0.0859429\tvalid_1's rmse: 0.0907591\n",
      "[2275]\ttraining's rmse: 0.0859389\tvalid_1's rmse: 0.0907586\n",
      "[2300]\ttraining's rmse: 0.0859346\tvalid_1's rmse: 0.0907583\n",
      "[2325]\ttraining's rmse: 0.0859311\tvalid_1's rmse: 0.0907586\n",
      "Early stopping, best iteration is:\n",
      "[2291]\ttraining's rmse: 0.0859362\tvalid_1's rmse: 0.090758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0913517\tvalid_1's rmse: 0.0867714\n",
      "[50]\ttraining's rmse: 0.0912247\tvalid_1's rmse: 0.0867246\n",
      "[75]\ttraining's rmse: 0.0910888\tvalid_1's rmse: 0.0866734\n",
      "[100]\ttraining's rmse: 0.0909689\tvalid_1's rmse: 0.0866316\n",
      "[125]\ttraining's rmse: 0.0908442\tvalid_1's rmse: 0.086589\n",
      "[150]\ttraining's rmse: 0.0907301\tvalid_1's rmse: 0.0865513\n",
      "[175]\ttraining's rmse: 0.0906322\tvalid_1's rmse: 0.0865196\n",
      "[200]\ttraining's rmse: 0.0905271\tvalid_1's rmse: 0.0864884\n",
      "[225]\ttraining's rmse: 0.0904293\tvalid_1's rmse: 0.0864567\n",
      "[250]\ttraining's rmse: 0.0903431\tvalid_1's rmse: 0.0864283\n",
      "[275]\ttraining's rmse: 0.0902651\tvalid_1's rmse: 0.0864032\n",
      "[300]\ttraining's rmse: 0.090188\tvalid_1's rmse: 0.0863808\n",
      "[325]\ttraining's rmse: 0.0901085\tvalid_1's rmse: 0.0863586\n",
      "[350]\ttraining's rmse: 0.0900326\tvalid_1's rmse: 0.0863356\n",
      "[375]\ttraining's rmse: 0.0899693\tvalid_1's rmse: 0.0863175\n",
      "[400]\ttraining's rmse: 0.0898992\tvalid_1's rmse: 0.0862997\n",
      "[425]\ttraining's rmse: 0.0898347\tvalid_1's rmse: 0.0862841\n",
      "[450]\ttraining's rmse: 0.0897766\tvalid_1's rmse: 0.0862712\n",
      "[475]\ttraining's rmse: 0.0897225\tvalid_1's rmse: 0.0862574\n",
      "[500]\ttraining's rmse: 0.0896768\tvalid_1's rmse: 0.0862444\n",
      "[525]\ttraining's rmse: 0.0896146\tvalid_1's rmse: 0.0862308\n",
      "[550]\ttraining's rmse: 0.0895603\tvalid_1's rmse: 0.0862167\n",
      "[575]\ttraining's rmse: 0.0895088\tvalid_1's rmse: 0.0862064\n",
      "[600]\ttraining's rmse: 0.0894575\tvalid_1's rmse: 0.0861958\n",
      "[625]\ttraining's rmse: 0.0894191\tvalid_1's rmse: 0.0861915\n",
      "[650]\ttraining's rmse: 0.0893696\tvalid_1's rmse: 0.0861864\n",
      "[675]\ttraining's rmse: 0.0893191\tvalid_1's rmse: 0.0861835\n",
      "[700]\ttraining's rmse: 0.0892753\tvalid_1's rmse: 0.0861752\n",
      "[725]\ttraining's rmse: 0.0892344\tvalid_1's rmse: 0.0861796\n",
      "[750]\ttraining's rmse: 0.089196\tvalid_1's rmse: 0.0861805\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0892678\tvalid_1's rmse: 0.086174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.087714\tvalid_1's rmse: 0.090377\n",
      "[50]\ttraining's rmse: 0.0875757\tvalid_1's rmse: 0.0903226\n",
      "[75]\ttraining's rmse: 0.0874374\tvalid_1's rmse: 0.0902697\n",
      "[100]\ttraining's rmse: 0.0873079\tvalid_1's rmse: 0.0902237\n",
      "[125]\ttraining's rmse: 0.0871773\tvalid_1's rmse: 0.0901736\n",
      "[150]\ttraining's rmse: 0.0870571\tvalid_1's rmse: 0.0901284\n",
      "[175]\ttraining's rmse: 0.08696\tvalid_1's rmse: 0.0900907\n",
      "[200]\ttraining's rmse: 0.0868588\tvalid_1's rmse: 0.0900529\n",
      "[225]\ttraining's rmse: 0.0867576\tvalid_1's rmse: 0.0900193\n",
      "[250]\ttraining's rmse: 0.0866729\tvalid_1's rmse: 0.0899867\n",
      "[275]\ttraining's rmse: 0.0865932\tvalid_1's rmse: 0.0899567\n",
      "[300]\ttraining's rmse: 0.0865147\tvalid_1's rmse: 0.0899274\n",
      "[325]\ttraining's rmse: 0.086434\tvalid_1's rmse: 0.0898997\n",
      "[350]\ttraining's rmse: 0.0863584\tvalid_1's rmse: 0.089873\n",
      "[375]\ttraining's rmse: 0.08629\tvalid_1's rmse: 0.0898503\n",
      "[400]\ttraining's rmse: 0.0862198\tvalid_1's rmse: 0.0898294\n",
      "[425]\ttraining's rmse: 0.0861569\tvalid_1's rmse: 0.0898079\n",
      "[450]\ttraining's rmse: 0.0860982\tvalid_1's rmse: 0.0897878\n",
      "[475]\ttraining's rmse: 0.0860456\tvalid_1's rmse: 0.0897688\n",
      "[500]\ttraining's rmse: 0.0859969\tvalid_1's rmse: 0.0897517\n",
      "[525]\ttraining's rmse: 0.0859362\tvalid_1's rmse: 0.0897342\n",
      "[550]\ttraining's rmse: 0.0858835\tvalid_1's rmse: 0.0897172\n",
      "[575]\ttraining's rmse: 0.0858322\tvalid_1's rmse: 0.0897026\n",
      "[600]\ttraining's rmse: 0.0857839\tvalid_1's rmse: 0.0896883\n",
      "[625]\ttraining's rmse: 0.0857443\tvalid_1's rmse: 0.0896752\n",
      "[650]\ttraining's rmse: 0.0857002\tvalid_1's rmse: 0.0896619\n",
      "[675]\ttraining's rmse: 0.0856551\tvalid_1's rmse: 0.0896502\n",
      "[700]\ttraining's rmse: 0.0856156\tvalid_1's rmse: 0.0896386\n",
      "[725]\ttraining's rmse: 0.0855793\tvalid_1's rmse: 0.0896283\n",
      "[750]\ttraining's rmse: 0.0855449\tvalid_1's rmse: 0.0896187\n",
      "[775]\ttraining's rmse: 0.0855141\tvalid_1's rmse: 0.0896093\n",
      "[800]\ttraining's rmse: 0.0854756\tvalid_1's rmse: 0.0896\n",
      "[825]\ttraining's rmse: 0.0854455\tvalid_1's rmse: 0.0895904\n",
      "[850]\ttraining's rmse: 0.0854123\tvalid_1's rmse: 0.0895833\n",
      "[875]\ttraining's rmse: 0.0853848\tvalid_1's rmse: 0.0895754\n",
      "[900]\ttraining's rmse: 0.0853507\tvalid_1's rmse: 0.0895669\n",
      "[925]\ttraining's rmse: 0.0853249\tvalid_1's rmse: 0.0895595\n",
      "[950]\ttraining's rmse: 0.0852989\tvalid_1's rmse: 0.0895524\n",
      "[975]\ttraining's rmse: 0.0852736\tvalid_1's rmse: 0.0895458\n",
      "[1000]\ttraining's rmse: 0.0852484\tvalid_1's rmse: 0.089539\n",
      "[1025]\ttraining's rmse: 0.0852223\tvalid_1's rmse: 0.0895317\n",
      "[1050]\ttraining's rmse: 0.0851986\tvalid_1's rmse: 0.0895252\n",
      "[1075]\ttraining's rmse: 0.0851777\tvalid_1's rmse: 0.0895198\n",
      "[1100]\ttraining's rmse: 0.085159\tvalid_1's rmse: 0.0895151\n",
      "[1125]\ttraining's rmse: 0.0851379\tvalid_1's rmse: 0.0895105\n",
      "[1150]\ttraining's rmse: 0.0851173\tvalid_1's rmse: 0.0895061\n",
      "[1175]\ttraining's rmse: 0.0851013\tvalid_1's rmse: 0.0895018\n",
      "[1200]\ttraining's rmse: 0.0850836\tvalid_1's rmse: 0.0894962\n",
      "[1225]\ttraining's rmse: 0.0850659\tvalid_1's rmse: 0.089492\n",
      "[1250]\ttraining's rmse: 0.0850519\tvalid_1's rmse: 0.0894882\n",
      "[1275]\ttraining's rmse: 0.0850322\tvalid_1's rmse: 0.0894844\n",
      "[1300]\ttraining's rmse: 0.0850199\tvalid_1's rmse: 0.0894801\n",
      "[1325]\ttraining's rmse: 0.0850076\tvalid_1's rmse: 0.0894758\n",
      "[1350]\ttraining's rmse: 0.0849916\tvalid_1's rmse: 0.0894736\n",
      "[1375]\ttraining's rmse: 0.084979\tvalid_1's rmse: 0.0894694\n",
      "[1400]\ttraining's rmse: 0.0849662\tvalid_1's rmse: 0.0894654\n",
      "[1425]\ttraining's rmse: 0.0849513\tvalid_1's rmse: 0.0894623\n",
      "[1450]\ttraining's rmse: 0.0849378\tvalid_1's rmse: 0.0894589\n",
      "[1475]\ttraining's rmse: 0.0849265\tvalid_1's rmse: 0.0894555\n",
      "[1500]\ttraining's rmse: 0.0849165\tvalid_1's rmse: 0.0894532\n",
      "[1525]\ttraining's rmse: 0.0849066\tvalid_1's rmse: 0.0894508\n",
      "[1550]\ttraining's rmse: 0.0848956\tvalid_1's rmse: 0.0894487\n",
      "[1575]\ttraining's rmse: 0.0848869\tvalid_1's rmse: 0.0894459\n",
      "[1600]\ttraining's rmse: 0.084876\tvalid_1's rmse: 0.0894425\n",
      "[1625]\ttraining's rmse: 0.0848668\tvalid_1's rmse: 0.0894396\n",
      "[1650]\ttraining's rmse: 0.0848603\tvalid_1's rmse: 0.0894375\n",
      "[1675]\ttraining's rmse: 0.0848519\tvalid_1's rmse: 0.0894348\n",
      "[1700]\ttraining's rmse: 0.0848463\tvalid_1's rmse: 0.0894326\n",
      "[1725]\ttraining's rmse: 0.0848375\tvalid_1's rmse: 0.0894309\n",
      "[1750]\ttraining's rmse: 0.0848282\tvalid_1's rmse: 0.0894281\n",
      "[1775]\ttraining's rmse: 0.0848204\tvalid_1's rmse: 0.0894266\n",
      "[1800]\ttraining's rmse: 0.084813\tvalid_1's rmse: 0.0894239\n",
      "[1825]\ttraining's rmse: 0.0848062\tvalid_1's rmse: 0.0894232\n",
      "[1850]\ttraining's rmse: 0.0848011\tvalid_1's rmse: 0.0894217\n",
      "[1875]\ttraining's rmse: 0.0847949\tvalid_1's rmse: 0.0894206\n",
      "[1900]\ttraining's rmse: 0.0847899\tvalid_1's rmse: 0.089419\n",
      "[1925]\ttraining's rmse: 0.0847857\tvalid_1's rmse: 0.0894182\n",
      "[1950]\ttraining's rmse: 0.0847803\tvalid_1's rmse: 0.0894164\n",
      "[1975]\ttraining's rmse: 0.0847757\tvalid_1's rmse: 0.0894147\n",
      "[2000]\ttraining's rmse: 0.0847715\tvalid_1's rmse: 0.0894136\n",
      "[2025]\ttraining's rmse: 0.0847672\tvalid_1's rmse: 0.0894109\n",
      "[2050]\ttraining's rmse: 0.08476\tvalid_1's rmse: 0.0894102\n",
      "[2075]\ttraining's rmse: 0.084756\tvalid_1's rmse: 0.0894095\n",
      "[2100]\ttraining's rmse: 0.0847529\tvalid_1's rmse: 0.0894087\n",
      "[2125]\ttraining's rmse: 0.0847493\tvalid_1's rmse: 0.089408\n",
      "[2150]\ttraining's rmse: 0.0847444\tvalid_1's rmse: 0.089407\n",
      "[2175]\ttraining's rmse: 0.0847408\tvalid_1's rmse: 0.0894067\n",
      "[2200]\ttraining's rmse: 0.0847375\tvalid_1's rmse: 0.0894052\n",
      "[2225]\ttraining's rmse: 0.0847345\tvalid_1's rmse: 0.0894039\n",
      "[2250]\ttraining's rmse: 0.0847324\tvalid_1's rmse: 0.0894038\n",
      "[2275]\ttraining's rmse: 0.084729\tvalid_1's rmse: 0.0894039\n",
      "[2300]\ttraining's rmse: 0.0847259\tvalid_1's rmse: 0.0894029\n",
      "[2325]\ttraining's rmse: 0.0847228\tvalid_1's rmse: 0.0894022\n",
      "[2350]\ttraining's rmse: 0.0847197\tvalid_1's rmse: 0.0894012\n",
      "[2375]\ttraining's rmse: 0.0847158\tvalid_1's rmse: 0.0894003\n",
      "[2400]\ttraining's rmse: 0.0847128\tvalid_1's rmse: 0.0893994\n",
      "[2425]\ttraining's rmse: 0.0847102\tvalid_1's rmse: 0.0893989\n",
      "[2450]\ttraining's rmse: 0.0847083\tvalid_1's rmse: 0.0893979\n",
      "[2475]\ttraining's rmse: 0.0847055\tvalid_1's rmse: 0.0893974\n",
      "[2500]\ttraining's rmse: 0.0847021\tvalid_1's rmse: 0.0893969\n",
      "[2525]\ttraining's rmse: 0.0846989\tvalid_1's rmse: 0.0893969\n",
      "[2550]\ttraining's rmse: 0.0846968\tvalid_1's rmse: 0.089396\n",
      "[2575]\ttraining's rmse: 0.0846946\tvalid_1's rmse: 0.0893953\n",
      "[2600]\ttraining's rmse: 0.0846905\tvalid_1's rmse: 0.0893943\n",
      "[2625]\ttraining's rmse: 0.0846883\tvalid_1's rmse: 0.0893936\n",
      "[2650]\ttraining's rmse: 0.0846867\tvalid_1's rmse: 0.0893931\n",
      "[2675]\ttraining's rmse: 0.0846822\tvalid_1's rmse: 0.0893913\n",
      "[2700]\ttraining's rmse: 0.0846796\tvalid_1's rmse: 0.0893907\n",
      "[2725]\ttraining's rmse: 0.0846761\tvalid_1's rmse: 0.0893901\n",
      "[2750]\ttraining's rmse: 0.0846741\tvalid_1's rmse: 0.0893888\n",
      "[2775]\ttraining's rmse: 0.0846727\tvalid_1's rmse: 0.0893883\n",
      "[2800]\ttraining's rmse: 0.0846709\tvalid_1's rmse: 0.089388\n",
      "[2825]\ttraining's rmse: 0.0846686\tvalid_1's rmse: 0.0893884\n",
      "[2850]\ttraining's rmse: 0.0846667\tvalid_1's rmse: 0.0893878\n",
      "[2875]\ttraining's rmse: 0.0846634\tvalid_1's rmse: 0.0893868\n",
      "[2900]\ttraining's rmse: 0.0846622\tvalid_1's rmse: 0.0893867\n",
      "[2925]\ttraining's rmse: 0.0846608\tvalid_1's rmse: 0.0893863\n",
      "[2950]\ttraining's rmse: 0.0846599\tvalid_1's rmse: 0.0893861\n",
      "[2975]\ttraining's rmse: 0.0846585\tvalid_1's rmse: 0.0893855\n",
      "[3000]\ttraining's rmse: 0.0846572\tvalid_1's rmse: 0.0893849\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0846572\tvalid_1's rmse: 0.0893849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0877812\tvalid_1's rmse: 0.0902491\n",
      "[50]\ttraining's rmse: 0.0876505\tvalid_1's rmse: 0.0901935\n",
      "[75]\ttraining's rmse: 0.0875176\tvalid_1's rmse: 0.0901395\n",
      "[100]\ttraining's rmse: 0.0873964\tvalid_1's rmse: 0.0900911\n",
      "[125]\ttraining's rmse: 0.0872708\tvalid_1's rmse: 0.0900437\n",
      "[150]\ttraining's rmse: 0.0871574\tvalid_1's rmse: 0.0900007\n",
      "[175]\ttraining's rmse: 0.0870608\tvalid_1's rmse: 0.0899638\n",
      "[200]\ttraining's rmse: 0.0869544\tvalid_1's rmse: 0.0899257\n",
      "[225]\ttraining's rmse: 0.086857\tvalid_1's rmse: 0.0898916\n",
      "[250]\ttraining's rmse: 0.086773\tvalid_1's rmse: 0.0898612\n",
      "[275]\ttraining's rmse: 0.0866949\tvalid_1's rmse: 0.0898316\n",
      "[300]\ttraining's rmse: 0.0866163\tvalid_1's rmse: 0.0898035\n",
      "[325]\ttraining's rmse: 0.0865376\tvalid_1's rmse: 0.0897779\n",
      "[350]\ttraining's rmse: 0.0864608\tvalid_1's rmse: 0.0897535\n",
      "[375]\ttraining's rmse: 0.0864011\tvalid_1's rmse: 0.0897329\n",
      "[400]\ttraining's rmse: 0.0863341\tvalid_1's rmse: 0.0897129\n",
      "[425]\ttraining's rmse: 0.0862734\tvalid_1's rmse: 0.0896935\n",
      "[450]\ttraining's rmse: 0.0862154\tvalid_1's rmse: 0.0896753\n",
      "[475]\ttraining's rmse: 0.0861612\tvalid_1's rmse: 0.0896585\n",
      "[500]\ttraining's rmse: 0.086116\tvalid_1's rmse: 0.0896426\n",
      "[525]\ttraining's rmse: 0.086056\tvalid_1's rmse: 0.089625\n",
      "[550]\ttraining's rmse: 0.0860032\tvalid_1's rmse: 0.0896094\n",
      "[575]\ttraining's rmse: 0.085954\tvalid_1's rmse: 0.0895958\n",
      "[600]\ttraining's rmse: 0.0859043\tvalid_1's rmse: 0.0895817\n",
      "[625]\ttraining's rmse: 0.0858649\tvalid_1's rmse: 0.0895712\n",
      "[650]\ttraining's rmse: 0.0858174\tvalid_1's rmse: 0.089559\n",
      "[675]\ttraining's rmse: 0.0857723\tvalid_1's rmse: 0.0895485\n",
      "[700]\ttraining's rmse: 0.0857308\tvalid_1's rmse: 0.0895382\n",
      "[725]\ttraining's rmse: 0.0856925\tvalid_1's rmse: 0.0895278\n",
      "[750]\ttraining's rmse: 0.0856539\tvalid_1's rmse: 0.0895192\n",
      "[775]\ttraining's rmse: 0.0856234\tvalid_1's rmse: 0.08951\n",
      "[800]\ttraining's rmse: 0.085585\tvalid_1's rmse: 0.0895025\n",
      "[825]\ttraining's rmse: 0.085552\tvalid_1's rmse: 0.0894946\n",
      "[850]\ttraining's rmse: 0.0855194\tvalid_1's rmse: 0.0894877\n",
      "[875]\ttraining's rmse: 0.0854905\tvalid_1's rmse: 0.0894816\n",
      "[900]\ttraining's rmse: 0.0854586\tvalid_1's rmse: 0.089475\n",
      "[925]\ttraining's rmse: 0.0854309\tvalid_1's rmse: 0.0894696\n",
      "[950]\ttraining's rmse: 0.0854034\tvalid_1's rmse: 0.0894636\n",
      "[975]\ttraining's rmse: 0.0853778\tvalid_1's rmse: 0.0894588\n",
      "[1000]\ttraining's rmse: 0.0853543\tvalid_1's rmse: 0.0894542\n",
      "[1025]\ttraining's rmse: 0.0853279\tvalid_1's rmse: 0.0894485\n",
      "[1050]\ttraining's rmse: 0.0853058\tvalid_1's rmse: 0.0894434\n",
      "[1075]\ttraining's rmse: 0.0852834\tvalid_1's rmse: 0.0894394\n",
      "[1100]\ttraining's rmse: 0.0852653\tvalid_1's rmse: 0.0894359\n",
      "[1125]\ttraining's rmse: 0.0852459\tvalid_1's rmse: 0.0894323\n",
      "[1150]\ttraining's rmse: 0.0852267\tvalid_1's rmse: 0.0894293\n",
      "[1175]\ttraining's rmse: 0.0852103\tvalid_1's rmse: 0.0894266\n",
      "[1200]\ttraining's rmse: 0.0851902\tvalid_1's rmse: 0.0894239\n",
      "[1225]\ttraining's rmse: 0.0851731\tvalid_1's rmse: 0.0894212\n",
      "[1250]\ttraining's rmse: 0.0851585\tvalid_1's rmse: 0.0894194\n",
      "[1275]\ttraining's rmse: 0.085142\tvalid_1's rmse: 0.0894174\n",
      "[1300]\ttraining's rmse: 0.0851277\tvalid_1's rmse: 0.089415\n",
      "[1325]\ttraining's rmse: 0.0851136\tvalid_1's rmse: 0.0894132\n",
      "[1350]\ttraining's rmse: 0.0850964\tvalid_1's rmse: 0.089411\n",
      "[1375]\ttraining's rmse: 0.0850814\tvalid_1's rmse: 0.0894097\n",
      "[1400]\ttraining's rmse: 0.0850698\tvalid_1's rmse: 0.0894085\n",
      "[1425]\ttraining's rmse: 0.0850543\tvalid_1's rmse: 0.0894072\n",
      "[1450]\ttraining's rmse: 0.0850409\tvalid_1's rmse: 0.0894065\n",
      "[1475]\ttraining's rmse: 0.0850289\tvalid_1's rmse: 0.0894053\n",
      "[1500]\ttraining's rmse: 0.0850203\tvalid_1's rmse: 0.0894042\n",
      "[1525]\ttraining's rmse: 0.0850098\tvalid_1's rmse: 0.089403\n",
      "[1550]\ttraining's rmse: 0.0850026\tvalid_1's rmse: 0.0894021\n",
      "[1575]\ttraining's rmse: 0.0849933\tvalid_1's rmse: 0.0894011\n",
      "[1600]\ttraining's rmse: 0.0849844\tvalid_1's rmse: 0.0894001\n",
      "[1625]\ttraining's rmse: 0.0849753\tvalid_1's rmse: 0.0893991\n",
      "[1650]\ttraining's rmse: 0.0849627\tvalid_1's rmse: 0.089398\n",
      "[1675]\ttraining's rmse: 0.0849551\tvalid_1's rmse: 0.0893963\n",
      "[1700]\ttraining's rmse: 0.0849478\tvalid_1's rmse: 0.0893954\n",
      "[1725]\ttraining's rmse: 0.0849392\tvalid_1's rmse: 0.0893944\n",
      "[1750]\ttraining's rmse: 0.084931\tvalid_1's rmse: 0.089394\n",
      "[1775]\ttraining's rmse: 0.0849228\tvalid_1's rmse: 0.0893931\n",
      "[1800]\ttraining's rmse: 0.084916\tvalid_1's rmse: 0.0893923\n",
      "[1825]\ttraining's rmse: 0.0849098\tvalid_1's rmse: 0.0893918\n",
      "[1850]\ttraining's rmse: 0.0849037\tvalid_1's rmse: 0.0893912\n",
      "[1875]\ttraining's rmse: 0.0848961\tvalid_1's rmse: 0.0893905\n",
      "[1900]\ttraining's rmse: 0.0848914\tvalid_1's rmse: 0.0893903\n",
      "[1925]\ttraining's rmse: 0.0848849\tvalid_1's rmse: 0.0893898\n",
      "[1950]\ttraining's rmse: 0.0848809\tvalid_1's rmse: 0.0893893\n",
      "[1975]\ttraining's rmse: 0.0848777\tvalid_1's rmse: 0.0893891\n",
      "[2000]\ttraining's rmse: 0.084874\tvalid_1's rmse: 0.0893887\n",
      "[2025]\ttraining's rmse: 0.0848694\tvalid_1's rmse: 0.0893884\n",
      "[2050]\ttraining's rmse: 0.0848653\tvalid_1's rmse: 0.0893886\n",
      "[2075]\ttraining's rmse: 0.084862\tvalid_1's rmse: 0.0893883\n",
      "[2100]\ttraining's rmse: 0.084858\tvalid_1's rmse: 0.0893886\n",
      "Early stopping, best iteration is:\n",
      "[2070]\ttraining's rmse: 0.0848625\tvalid_1's rmse: 0.0893882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0901873\tvalid_1's rmse: 0.085377\n",
      "[50]\ttraining's rmse: 0.0900709\tvalid_1's rmse: 0.0853282\n",
      "[75]\ttraining's rmse: 0.0899487\tvalid_1's rmse: 0.0852803\n",
      "[100]\ttraining's rmse: 0.0898403\tvalid_1's rmse: 0.0852381\n",
      "[125]\ttraining's rmse: 0.0897303\tvalid_1's rmse: 0.0851955\n",
      "[150]\ttraining's rmse: 0.0896273\tvalid_1's rmse: 0.0851568\n",
      "[175]\ttraining's rmse: 0.089542\tvalid_1's rmse: 0.0851256\n",
      "[200]\ttraining's rmse: 0.0894506\tvalid_1's rmse: 0.0850942\n",
      "[225]\ttraining's rmse: 0.0893601\tvalid_1's rmse: 0.0850626\n",
      "[250]\ttraining's rmse: 0.0892839\tvalid_1's rmse: 0.0850364\n",
      "[275]\ttraining's rmse: 0.089214\tvalid_1's rmse: 0.0850105\n",
      "[300]\ttraining's rmse: 0.0891413\tvalid_1's rmse: 0.0849849\n",
      "[325]\ttraining's rmse: 0.0890731\tvalid_1's rmse: 0.0849623\n",
      "[350]\ttraining's rmse: 0.0890003\tvalid_1's rmse: 0.084941\n",
      "[375]\ttraining's rmse: 0.0889446\tvalid_1's rmse: 0.0849247\n",
      "[400]\ttraining's rmse: 0.0888827\tvalid_1's rmse: 0.084912\n",
      "[425]\ttraining's rmse: 0.088826\tvalid_1's rmse: 0.0848999\n",
      "[450]\ttraining's rmse: 0.0887718\tvalid_1's rmse: 0.0848824\n",
      "[475]\ttraining's rmse: 0.0887196\tvalid_1's rmse: 0.0848685\n",
      "[500]\ttraining's rmse: 0.0886778\tvalid_1's rmse: 0.084855\n",
      "[525]\ttraining's rmse: 0.0886226\tvalid_1's rmse: 0.0848449\n",
      "[550]\ttraining's rmse: 0.0885734\tvalid_1's rmse: 0.0848311\n",
      "[575]\ttraining's rmse: 0.0885256\tvalid_1's rmse: 0.0848196\n",
      "[600]\ttraining's rmse: 0.0884767\tvalid_1's rmse: 0.0848094\n",
      "[625]\ttraining's rmse: 0.0884404\tvalid_1's rmse: 0.0847988\n",
      "[650]\ttraining's rmse: 0.088395\tvalid_1's rmse: 0.0847972\n",
      "[675]\ttraining's rmse: 0.088348\tvalid_1's rmse: 0.0847908\n",
      "[700]\ttraining's rmse: 0.0883086\tvalid_1's rmse: 0.0847876\n",
      "[725]\ttraining's rmse: 0.0882713\tvalid_1's rmse: 0.0847803\n",
      "[750]\ttraining's rmse: 0.0882357\tvalid_1's rmse: 0.0847791\n",
      "[775]\ttraining's rmse: 0.0882041\tvalid_1's rmse: 0.0847827\n",
      "Early stopping, best iteration is:\n",
      "[749]\ttraining's rmse: 0.0882375\tvalid_1's rmse: 0.0847757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0901774\tvalid_1's rmse: 0.0920402\n",
      "[50]\ttraining's rmse: 0.0899903\tvalid_1's rmse: 0.0919861\n",
      "[75]\ttraining's rmse: 0.0898068\tvalid_1's rmse: 0.091931\n",
      "[100]\ttraining's rmse: 0.0896334\tvalid_1's rmse: 0.0918831\n",
      "[125]\ttraining's rmse: 0.0894669\tvalid_1's rmse: 0.0918367\n",
      "[150]\ttraining's rmse: 0.0893162\tvalid_1's rmse: 0.0917927\n",
      "[175]\ttraining's rmse: 0.0891882\tvalid_1's rmse: 0.0917547\n",
      "[200]\ttraining's rmse: 0.0890574\tvalid_1's rmse: 0.0917167\n",
      "[225]\ttraining's rmse: 0.0889291\tvalid_1's rmse: 0.0916806\n",
      "[250]\ttraining's rmse: 0.0888215\tvalid_1's rmse: 0.0916497\n",
      "[275]\ttraining's rmse: 0.0887165\tvalid_1's rmse: 0.0916192\n",
      "[300]\ttraining's rmse: 0.0886128\tvalid_1's rmse: 0.0915896\n",
      "[325]\ttraining's rmse: 0.0885121\tvalid_1's rmse: 0.0915609\n",
      "[350]\ttraining's rmse: 0.088415\tvalid_1's rmse: 0.091532\n",
      "[375]\ttraining's rmse: 0.0883336\tvalid_1's rmse: 0.0915104\n",
      "[400]\ttraining's rmse: 0.0882461\tvalid_1's rmse: 0.0914891\n",
      "[425]\ttraining's rmse: 0.0881663\tvalid_1's rmse: 0.0914667\n",
      "[450]\ttraining's rmse: 0.088097\tvalid_1's rmse: 0.0914469\n",
      "[475]\ttraining's rmse: 0.0880315\tvalid_1's rmse: 0.0914264\n",
      "[500]\ttraining's rmse: 0.0879705\tvalid_1's rmse: 0.0914104\n",
      "[525]\ttraining's rmse: 0.0879018\tvalid_1's rmse: 0.0913918\n",
      "[550]\ttraining's rmse: 0.0878396\tvalid_1's rmse: 0.0913763\n",
      "[575]\ttraining's rmse: 0.0877832\tvalid_1's rmse: 0.0913635\n",
      "[600]\ttraining's rmse: 0.0877261\tvalid_1's rmse: 0.0913499\n",
      "[625]\ttraining's rmse: 0.0876794\tvalid_1's rmse: 0.091337\n",
      "[650]\ttraining's rmse: 0.0876279\tvalid_1's rmse: 0.0913224\n",
      "[675]\ttraining's rmse: 0.0875763\tvalid_1's rmse: 0.0913083\n",
      "[700]\ttraining's rmse: 0.0875302\tvalid_1's rmse: 0.0912969\n",
      "[725]\ttraining's rmse: 0.0874859\tvalid_1's rmse: 0.0912859\n",
      "[750]\ttraining's rmse: 0.0874467\tvalid_1's rmse: 0.0912756\n",
      "[775]\ttraining's rmse: 0.0874123\tvalid_1's rmse: 0.0912639\n",
      "[800]\ttraining's rmse: 0.0873689\tvalid_1's rmse: 0.0912538\n",
      "[825]\ttraining's rmse: 0.0873343\tvalid_1's rmse: 0.0912446\n",
      "[850]\ttraining's rmse: 0.0872987\tvalid_1's rmse: 0.0912372\n",
      "[875]\ttraining's rmse: 0.0872678\tvalid_1's rmse: 0.0912284\n",
      "[900]\ttraining's rmse: 0.0872305\tvalid_1's rmse: 0.0912209\n",
      "[925]\ttraining's rmse: 0.0872008\tvalid_1's rmse: 0.0912132\n",
      "[950]\ttraining's rmse: 0.0871705\tvalid_1's rmse: 0.0912062\n",
      "[975]\ttraining's rmse: 0.0871426\tvalid_1's rmse: 0.0911985\n",
      "[1000]\ttraining's rmse: 0.0871129\tvalid_1's rmse: 0.0911915\n",
      "[1025]\ttraining's rmse: 0.0870855\tvalid_1's rmse: 0.0911846\n",
      "[1050]\ttraining's rmse: 0.0870593\tvalid_1's rmse: 0.0911771\n",
      "[1075]\ttraining's rmse: 0.0870354\tvalid_1's rmse: 0.0911722\n",
      "[1100]\ttraining's rmse: 0.0870116\tvalid_1's rmse: 0.0911642\n",
      "[1125]\ttraining's rmse: 0.086989\tvalid_1's rmse: 0.0911588\n",
      "[1150]\ttraining's rmse: 0.0869661\tvalid_1's rmse: 0.0911523\n",
      "[1175]\ttraining's rmse: 0.0869466\tvalid_1's rmse: 0.0911472\n",
      "[1200]\ttraining's rmse: 0.0869275\tvalid_1's rmse: 0.0911425\n",
      "[1225]\ttraining's rmse: 0.0869126\tvalid_1's rmse: 0.0911383\n",
      "[1250]\ttraining's rmse: 0.0868943\tvalid_1's rmse: 0.0911333\n",
      "[1275]\ttraining's rmse: 0.0868733\tvalid_1's rmse: 0.0911302\n",
      "[1300]\ttraining's rmse: 0.0868569\tvalid_1's rmse: 0.0911263\n",
      "[1325]\ttraining's rmse: 0.0868428\tvalid_1's rmse: 0.0911227\n",
      "[1350]\ttraining's rmse: 0.0868266\tvalid_1's rmse: 0.0911181\n",
      "[1375]\ttraining's rmse: 0.0868092\tvalid_1's rmse: 0.0911137\n",
      "[1400]\ttraining's rmse: 0.0867949\tvalid_1's rmse: 0.0911092\n",
      "[1425]\ttraining's rmse: 0.0867777\tvalid_1's rmse: 0.0911052\n",
      "[1450]\ttraining's rmse: 0.0867596\tvalid_1's rmse: 0.0911013\n",
      "[1475]\ttraining's rmse: 0.0867465\tvalid_1's rmse: 0.0910978\n",
      "[1500]\ttraining's rmse: 0.0867374\tvalid_1's rmse: 0.0910941\n",
      "[1525]\ttraining's rmse: 0.0867264\tvalid_1's rmse: 0.0910918\n",
      "[1550]\ttraining's rmse: 0.0867165\tvalid_1's rmse: 0.0910896\n",
      "[1575]\ttraining's rmse: 0.0867054\tvalid_1's rmse: 0.091086\n",
      "[1600]\ttraining's rmse: 0.0866977\tvalid_1's rmse: 0.0910846\n",
      "[1625]\ttraining's rmse: 0.0866875\tvalid_1's rmse: 0.0910813\n",
      "[1650]\ttraining's rmse: 0.0866781\tvalid_1's rmse: 0.0910784\n",
      "[1675]\ttraining's rmse: 0.0866701\tvalid_1's rmse: 0.0910754\n",
      "[1700]\ttraining's rmse: 0.0866623\tvalid_1's rmse: 0.0910728\n",
      "[1725]\ttraining's rmse: 0.0866541\tvalid_1's rmse: 0.0910705\n",
      "[1750]\ttraining's rmse: 0.0866454\tvalid_1's rmse: 0.0910679\n",
      "[1775]\ttraining's rmse: 0.0866363\tvalid_1's rmse: 0.0910654\n",
      "[1800]\ttraining's rmse: 0.0866282\tvalid_1's rmse: 0.0910632\n",
      "[1825]\ttraining's rmse: 0.0866206\tvalid_1's rmse: 0.0910613\n",
      "[1850]\ttraining's rmse: 0.0866137\tvalid_1's rmse: 0.0910579\n",
      "[1875]\ttraining's rmse: 0.0866076\tvalid_1's rmse: 0.0910568\n",
      "[1900]\ttraining's rmse: 0.0866003\tvalid_1's rmse: 0.0910551\n",
      "[1925]\ttraining's rmse: 0.0865949\tvalid_1's rmse: 0.0910534\n",
      "[1950]\ttraining's rmse: 0.0865896\tvalid_1's rmse: 0.0910519\n",
      "[1975]\ttraining's rmse: 0.0865845\tvalid_1's rmse: 0.0910503\n",
      "[2000]\ttraining's rmse: 0.0865789\tvalid_1's rmse: 0.0910483\n",
      "[2025]\ttraining's rmse: 0.0865732\tvalid_1's rmse: 0.0910463\n",
      "[2050]\ttraining's rmse: 0.0865679\tvalid_1's rmse: 0.0910444\n",
      "[2075]\ttraining's rmse: 0.0865642\tvalid_1's rmse: 0.0910435\n",
      "[2100]\ttraining's rmse: 0.0865593\tvalid_1's rmse: 0.0910414\n",
      "[2125]\ttraining's rmse: 0.0865554\tvalid_1's rmse: 0.0910401\n",
      "[2150]\ttraining's rmse: 0.0865505\tvalid_1's rmse: 0.0910394\n",
      "[2175]\ttraining's rmse: 0.0865471\tvalid_1's rmse: 0.0910386\n",
      "[2200]\ttraining's rmse: 0.0865429\tvalid_1's rmse: 0.0910371\n",
      "[2225]\ttraining's rmse: 0.0865383\tvalid_1's rmse: 0.0910361\n",
      "[2250]\ttraining's rmse: 0.0865331\tvalid_1's rmse: 0.0910343\n",
      "[2275]\ttraining's rmse: 0.0865284\tvalid_1's rmse: 0.0910332\n",
      "[2300]\ttraining's rmse: 0.0865247\tvalid_1's rmse: 0.0910324\n",
      "[2325]\ttraining's rmse: 0.0865207\tvalid_1's rmse: 0.0910307\n",
      "[2350]\ttraining's rmse: 0.0865179\tvalid_1's rmse: 0.0910297\n",
      "[2375]\ttraining's rmse: 0.0865149\tvalid_1's rmse: 0.0910284\n",
      "[2400]\ttraining's rmse: 0.0865124\tvalid_1's rmse: 0.0910285\n",
      "[2425]\ttraining's rmse: 0.0865095\tvalid_1's rmse: 0.0910278\n",
      "[2450]\ttraining's rmse: 0.0865077\tvalid_1's rmse: 0.0910269\n",
      "[2475]\ttraining's rmse: 0.086505\tvalid_1's rmse: 0.0910266\n",
      "[2500]\ttraining's rmse: 0.0865014\tvalid_1's rmse: 0.0910254\n",
      "[2525]\ttraining's rmse: 0.0864981\tvalid_1's rmse: 0.091025\n",
      "[2550]\ttraining's rmse: 0.086495\tvalid_1's rmse: 0.0910243\n",
      "[2575]\ttraining's rmse: 0.0864928\tvalid_1's rmse: 0.0910242\n",
      "[2600]\ttraining's rmse: 0.0864898\tvalid_1's rmse: 0.0910229\n",
      "[2625]\ttraining's rmse: 0.0864877\tvalid_1's rmse: 0.0910228\n",
      "[2650]\ttraining's rmse: 0.0864859\tvalid_1's rmse: 0.0910222\n",
      "[2675]\ttraining's rmse: 0.0864837\tvalid_1's rmse: 0.0910211\n",
      "[2700]\ttraining's rmse: 0.0864805\tvalid_1's rmse: 0.0910208\n",
      "[2725]\ttraining's rmse: 0.0864776\tvalid_1's rmse: 0.0910197\n",
      "[2750]\ttraining's rmse: 0.0864746\tvalid_1's rmse: 0.0910185\n",
      "[2775]\ttraining's rmse: 0.0864727\tvalid_1's rmse: 0.0910183\n",
      "[2800]\ttraining's rmse: 0.0864706\tvalid_1's rmse: 0.0910183\n",
      "[2825]\ttraining's rmse: 0.0864685\tvalid_1's rmse: 0.091018\n",
      "[2850]\ttraining's rmse: 0.0864677\tvalid_1's rmse: 0.0910175\n",
      "[2875]\ttraining's rmse: 0.0864657\tvalid_1's rmse: 0.0910175\n",
      "[2900]\ttraining's rmse: 0.0864641\tvalid_1's rmse: 0.0910169\n",
      "[2925]\ttraining's rmse: 0.0864624\tvalid_1's rmse: 0.0910161\n",
      "[2950]\ttraining's rmse: 0.0864604\tvalid_1's rmse: 0.091016\n",
      "[2975]\ttraining's rmse: 0.0864584\tvalid_1's rmse: 0.0910157\n",
      "[3000]\ttraining's rmse: 0.0864566\tvalid_1's rmse: 0.0910155\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\ttraining's rmse: 0.0864566\tvalid_1's rmse: 0.0910155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0900728\tvalid_1's rmse: 0.0922628\n",
      "[50]\ttraining's rmse: 0.0899028\tvalid_1's rmse: 0.0922092\n",
      "[75]\ttraining's rmse: 0.0897293\tvalid_1's rmse: 0.0921529\n",
      "[100]\ttraining's rmse: 0.0895704\tvalid_1's rmse: 0.0921025\n",
      "[125]\ttraining's rmse: 0.0894112\tvalid_1's rmse: 0.0920537\n",
      "[150]\ttraining's rmse: 0.0892667\tvalid_1's rmse: 0.0920077\n",
      "[175]\ttraining's rmse: 0.0891422\tvalid_1's rmse: 0.0919699\n",
      "[200]\ttraining's rmse: 0.0890158\tvalid_1's rmse: 0.0919318\n",
      "[225]\ttraining's rmse: 0.0888917\tvalid_1's rmse: 0.0918963\n",
      "[250]\ttraining's rmse: 0.0887853\tvalid_1's rmse: 0.0918632\n",
      "[275]\ttraining's rmse: 0.0886867\tvalid_1's rmse: 0.091834\n",
      "[300]\ttraining's rmse: 0.0885873\tvalid_1's rmse: 0.0918052\n",
      "[325]\ttraining's rmse: 0.0884923\tvalid_1's rmse: 0.091778\n",
      "[350]\ttraining's rmse: 0.0884012\tvalid_1's rmse: 0.0917528\n",
      "[375]\ttraining's rmse: 0.0883249\tvalid_1's rmse: 0.0917308\n",
      "[400]\ttraining's rmse: 0.088245\tvalid_1's rmse: 0.0917087\n",
      "[425]\ttraining's rmse: 0.0881687\tvalid_1's rmse: 0.0916884\n",
      "[450]\ttraining's rmse: 0.0881\tvalid_1's rmse: 0.0916704\n",
      "[475]\ttraining's rmse: 0.0880368\tvalid_1's rmse: 0.0916531\n",
      "[500]\ttraining's rmse: 0.0879834\tvalid_1's rmse: 0.0916368\n",
      "[525]\ttraining's rmse: 0.0879156\tvalid_1's rmse: 0.0916187\n",
      "[550]\ttraining's rmse: 0.0878564\tvalid_1's rmse: 0.0916049\n",
      "[575]\ttraining's rmse: 0.0878014\tvalid_1's rmse: 0.0915914\n",
      "[600]\ttraining's rmse: 0.0877465\tvalid_1's rmse: 0.0915779\n",
      "[625]\ttraining's rmse: 0.0877021\tvalid_1's rmse: 0.0915661\n",
      "[650]\ttraining's rmse: 0.0876496\tvalid_1's rmse: 0.0915542\n",
      "[675]\ttraining's rmse: 0.0876\tvalid_1's rmse: 0.0915428\n",
      "[700]\ttraining's rmse: 0.0875554\tvalid_1's rmse: 0.0915324\n",
      "[725]\ttraining's rmse: 0.0875143\tvalid_1's rmse: 0.0915232\n",
      "[750]\ttraining's rmse: 0.087476\tvalid_1's rmse: 0.0915138\n",
      "[775]\ttraining's rmse: 0.0874416\tvalid_1's rmse: 0.0915046\n",
      "[800]\ttraining's rmse: 0.0873992\tvalid_1's rmse: 0.0914962\n",
      "[825]\ttraining's rmse: 0.0873648\tvalid_1's rmse: 0.0914885\n",
      "[850]\ttraining's rmse: 0.0873299\tvalid_1's rmse: 0.0914817\n",
      "[875]\ttraining's rmse: 0.087298\tvalid_1's rmse: 0.091475\n",
      "[900]\ttraining's rmse: 0.0872642\tvalid_1's rmse: 0.0914674\n",
      "[925]\ttraining's rmse: 0.0872336\tvalid_1's rmse: 0.0914621\n",
      "[950]\ttraining's rmse: 0.0872048\tvalid_1's rmse: 0.0914558\n",
      "[975]\ttraining's rmse: 0.0871762\tvalid_1's rmse: 0.0914513\n",
      "[1000]\ttraining's rmse: 0.0871481\tvalid_1's rmse: 0.0914459\n",
      "[1025]\ttraining's rmse: 0.0871178\tvalid_1's rmse: 0.0914413\n",
      "[1050]\ttraining's rmse: 0.0870934\tvalid_1's rmse: 0.0914363\n",
      "[1075]\ttraining's rmse: 0.0870666\tvalid_1's rmse: 0.0914326\n",
      "[1100]\ttraining's rmse: 0.0870422\tvalid_1's rmse: 0.0914276\n",
      "[1125]\ttraining's rmse: 0.0870199\tvalid_1's rmse: 0.0914246\n",
      "[1150]\ttraining's rmse: 0.0869981\tvalid_1's rmse: 0.0914214\n",
      "[1175]\ttraining's rmse: 0.0869797\tvalid_1's rmse: 0.0914199\n",
      "[1200]\ttraining's rmse: 0.0869587\tvalid_1's rmse: 0.0914162\n",
      "[1225]\ttraining's rmse: 0.0869389\tvalid_1's rmse: 0.0914133\n",
      "[1250]\ttraining's rmse: 0.0869192\tvalid_1's rmse: 0.0914102\n",
      "[1275]\ttraining's rmse: 0.0868953\tvalid_1's rmse: 0.091408\n",
      "[1300]\ttraining's rmse: 0.0868789\tvalid_1's rmse: 0.0914058\n",
      "[1325]\ttraining's rmse: 0.0868608\tvalid_1's rmse: 0.091404\n",
      "[1350]\ttraining's rmse: 0.0868431\tvalid_1's rmse: 0.0914022\n",
      "[1375]\ttraining's rmse: 0.0868275\tvalid_1's rmse: 0.0914003\n",
      "[1400]\ttraining's rmse: 0.0868131\tvalid_1's rmse: 0.0913987\n",
      "[1425]\ttraining's rmse: 0.086796\tvalid_1's rmse: 0.0913982\n",
      "[1450]\ttraining's rmse: 0.0867794\tvalid_1's rmse: 0.0913968\n",
      "[1475]\ttraining's rmse: 0.0867661\tvalid_1's rmse: 0.0913948\n",
      "[1500]\ttraining's rmse: 0.0867558\tvalid_1's rmse: 0.0913939\n",
      "[1525]\ttraining's rmse: 0.0867431\tvalid_1's rmse: 0.0913933\n",
      "[1550]\ttraining's rmse: 0.0867316\tvalid_1's rmse: 0.0913925\n",
      "[1575]\ttraining's rmse: 0.0867214\tvalid_1's rmse: 0.0913916\n",
      "[1600]\ttraining's rmse: 0.0867131\tvalid_1's rmse: 0.0913906\n",
      "[1625]\ttraining's rmse: 0.0867016\tvalid_1's rmse: 0.0913896\n",
      "[1650]\ttraining's rmse: 0.0866918\tvalid_1's rmse: 0.0913881\n",
      "[1675]\ttraining's rmse: 0.0866835\tvalid_1's rmse: 0.0913875\n",
      "[1700]\ttraining's rmse: 0.0866764\tvalid_1's rmse: 0.0913865\n",
      "[1725]\ttraining's rmse: 0.0866678\tvalid_1's rmse: 0.0913861\n",
      "[1750]\ttraining's rmse: 0.0866564\tvalid_1's rmse: 0.0913854\n",
      "[1775]\ttraining's rmse: 0.0866493\tvalid_1's rmse: 0.091385\n",
      "[1800]\ttraining's rmse: 0.0866416\tvalid_1's rmse: 0.0913848\n",
      "[1825]\ttraining's rmse: 0.0866342\tvalid_1's rmse: 0.091384\n",
      "[1850]\ttraining's rmse: 0.086628\tvalid_1's rmse: 0.0913833\n",
      "[1875]\ttraining's rmse: 0.0866223\tvalid_1's rmse: 0.0913834\n",
      "[1900]\ttraining's rmse: 0.0866165\tvalid_1's rmse: 0.0913829\n",
      "[1925]\ttraining's rmse: 0.0866104\tvalid_1's rmse: 0.0913826\n",
      "[1950]\ttraining's rmse: 0.0866065\tvalid_1's rmse: 0.0913823\n",
      "[1975]\ttraining's rmse: 0.0866009\tvalid_1's rmse: 0.0913817\n",
      "[2000]\ttraining's rmse: 0.0865953\tvalid_1's rmse: 0.0913816\n",
      "[2025]\ttraining's rmse: 0.0865903\tvalid_1's rmse: 0.0913807\n",
      "[2050]\ttraining's rmse: 0.0865856\tvalid_1's rmse: 0.0913804\n",
      "[2075]\ttraining's rmse: 0.0865822\tvalid_1's rmse: 0.0913797\n",
      "[2100]\ttraining's rmse: 0.0865778\tvalid_1's rmse: 0.0913793\n",
      "[2125]\ttraining's rmse: 0.0865743\tvalid_1's rmse: 0.0913794\n",
      "[2150]\ttraining's rmse: 0.0865706\tvalid_1's rmse: 0.0913792\n",
      "[2175]\ttraining's rmse: 0.0865666\tvalid_1's rmse: 0.0913794\n",
      "Early stopping, best iteration is:\n",
      "[2134]\ttraining's rmse: 0.0865729\tvalid_1's rmse: 0.091379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0920099\tvalid_1's rmse: 0.0884215\n",
      "[50]\ttraining's rmse: 0.0918788\tvalid_1's rmse: 0.088371\n",
      "[75]\ttraining's rmse: 0.0917411\tvalid_1's rmse: 0.0883223\n",
      "[100]\ttraining's rmse: 0.0916179\tvalid_1's rmse: 0.0882782\n",
      "[125]\ttraining's rmse: 0.0914888\tvalid_1's rmse: 0.088234\n",
      "[150]\ttraining's rmse: 0.0913723\tvalid_1's rmse: 0.0881967\n",
      "[175]\ttraining's rmse: 0.0912747\tvalid_1's rmse: 0.0881655\n",
      "[200]\ttraining's rmse: 0.0911688\tvalid_1's rmse: 0.088133\n",
      "[225]\ttraining's rmse: 0.0910677\tvalid_1's rmse: 0.0881028\n",
      "[250]\ttraining's rmse: 0.0909777\tvalid_1's rmse: 0.0880761\n",
      "[275]\ttraining's rmse: 0.0908977\tvalid_1's rmse: 0.0880506\n",
      "[300]\ttraining's rmse: 0.0908175\tvalid_1's rmse: 0.0880283\n",
      "[325]\ttraining's rmse: 0.0907359\tvalid_1's rmse: 0.0880058\n",
      "[350]\ttraining's rmse: 0.090658\tvalid_1's rmse: 0.0879832\n",
      "[375]\ttraining's rmse: 0.0905949\tvalid_1's rmse: 0.0879657\n",
      "[400]\ttraining's rmse: 0.090526\tvalid_1's rmse: 0.0879483\n",
      "[425]\ttraining's rmse: 0.0904602\tvalid_1's rmse: 0.0879315\n",
      "[450]\ttraining's rmse: 0.0904013\tvalid_1's rmse: 0.0879189\n",
      "[475]\ttraining's rmse: 0.0903461\tvalid_1's rmse: 0.0879096\n",
      "[500]\ttraining's rmse: 0.0903007\tvalid_1's rmse: 0.0878967\n",
      "[525]\ttraining's rmse: 0.0902378\tvalid_1's rmse: 0.0878862\n",
      "[550]\ttraining's rmse: 0.0901828\tvalid_1's rmse: 0.0878741\n",
      "[575]\ttraining's rmse: 0.0901308\tvalid_1's rmse: 0.0878678\n",
      "[600]\ttraining's rmse: 0.0900794\tvalid_1's rmse: 0.0878584\n",
      "[625]\ttraining's rmse: 0.0900385\tvalid_1's rmse: 0.0878487\n",
      "[650]\ttraining's rmse: 0.089987\tvalid_1's rmse: 0.0878445\n",
      "[675]\ttraining's rmse: 0.0899368\tvalid_1's rmse: 0.0878361\n",
      "[700]\ttraining's rmse: 0.0898923\tvalid_1's rmse: 0.0878385\n",
      "[725]\ttraining's rmse: 0.0898486\tvalid_1's rmse: 0.0878377\n",
      "Early stopping, best iteration is:\n",
      "[692]\ttraining's rmse: 0.0899068\tvalid_1's rmse: 0.0878302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0881871\tvalid_1's rmse: 0.0907857\n",
      "[50]\ttraining's rmse: 0.088045\tvalid_1's rmse: 0.09073\n",
      "[75]\ttraining's rmse: 0.0879074\tvalid_1's rmse: 0.0906738\n",
      "[100]\ttraining's rmse: 0.0877768\tvalid_1's rmse: 0.0906266\n",
      "[125]\ttraining's rmse: 0.087647\tvalid_1's rmse: 0.0905777\n",
      "[150]\ttraining's rmse: 0.0875258\tvalid_1's rmse: 0.0905316\n",
      "[175]\ttraining's rmse: 0.0874281\tvalid_1's rmse: 0.0904949\n",
      "[200]\ttraining's rmse: 0.0873225\tvalid_1's rmse: 0.0904562\n",
      "[225]\ttraining's rmse: 0.0872173\tvalid_1's rmse: 0.0904202\n",
      "[250]\ttraining's rmse: 0.087131\tvalid_1's rmse: 0.0903881\n",
      "[275]\ttraining's rmse: 0.0870492\tvalid_1's rmse: 0.0903584\n",
      "[300]\ttraining's rmse: 0.0869652\tvalid_1's rmse: 0.0903301\n",
      "[325]\ttraining's rmse: 0.0868817\tvalid_1's rmse: 0.0903018\n",
      "[350]\ttraining's rmse: 0.0868058\tvalid_1's rmse: 0.0902745\n",
      "[375]\ttraining's rmse: 0.0867388\tvalid_1's rmse: 0.0902516\n",
      "[400]\ttraining's rmse: 0.0866677\tvalid_1's rmse: 0.0902292\n",
      "[425]\ttraining's rmse: 0.086602\tvalid_1's rmse: 0.0902066\n",
      "[450]\ttraining's rmse: 0.0865453\tvalid_1's rmse: 0.0901869\n",
      "[475]\ttraining's rmse: 0.0864906\tvalid_1's rmse: 0.0901686\n",
      "[500]\ttraining's rmse: 0.0864441\tvalid_1's rmse: 0.0901502\n",
      "[525]\ttraining's rmse: 0.0863837\tvalid_1's rmse: 0.0901332\n",
      "[550]\ttraining's rmse: 0.0863313\tvalid_1's rmse: 0.0901171\n",
      "[575]\ttraining's rmse: 0.0862821\tvalid_1's rmse: 0.090102\n",
      "[600]\ttraining's rmse: 0.086232\tvalid_1's rmse: 0.0900872\n",
      "[625]\ttraining's rmse: 0.0861922\tvalid_1's rmse: 0.0900739\n",
      "[650]\ttraining's rmse: 0.0861449\tvalid_1's rmse: 0.0900609\n",
      "[675]\ttraining's rmse: 0.0860997\tvalid_1's rmse: 0.0900487\n",
      "[700]\ttraining's rmse: 0.0860608\tvalid_1's rmse: 0.0900367\n",
      "[725]\ttraining's rmse: 0.08602\tvalid_1's rmse: 0.0900263\n",
      "[750]\ttraining's rmse: 0.0859852\tvalid_1's rmse: 0.0900169\n",
      "[775]\ttraining's rmse: 0.0859568\tvalid_1's rmse: 0.0900055\n",
      "[800]\ttraining's rmse: 0.0859219\tvalid_1's rmse: 0.0899965\n",
      "[825]\ttraining's rmse: 0.0858916\tvalid_1's rmse: 0.0899868\n",
      "[850]\ttraining's rmse: 0.0858585\tvalid_1's rmse: 0.0899788\n",
      "[875]\ttraining's rmse: 0.0858283\tvalid_1's rmse: 0.0899709\n",
      "[900]\ttraining's rmse: 0.0857976\tvalid_1's rmse: 0.0899637\n",
      "[925]\ttraining's rmse: 0.0857716\tvalid_1's rmse: 0.0899568\n",
      "[950]\ttraining's rmse: 0.085746\tvalid_1's rmse: 0.0899498\n",
      "[975]\ttraining's rmse: 0.0857192\tvalid_1's rmse: 0.0899439\n",
      "[1000]\ttraining's rmse: 0.0856945\tvalid_1's rmse: 0.0899372\n",
      "[1025]\ttraining's rmse: 0.0856682\tvalid_1's rmse: 0.0899313\n",
      "[1050]\ttraining's rmse: 0.085646\tvalid_1's rmse: 0.0899238\n",
      "[1075]\ttraining's rmse: 0.0856226\tvalid_1's rmse: 0.0899185\n",
      "[1100]\ttraining's rmse: 0.0856039\tvalid_1's rmse: 0.0899146\n",
      "[1125]\ttraining's rmse: 0.0855812\tvalid_1's rmse: 0.0899077\n",
      "[1150]\ttraining's rmse: 0.0855602\tvalid_1's rmse: 0.0899024\n",
      "[1175]\ttraining's rmse: 0.0855395\tvalid_1's rmse: 0.0898986\n",
      "[1200]\ttraining's rmse: 0.0855217\tvalid_1's rmse: 0.089892\n",
      "[1225]\ttraining's rmse: 0.0855043\tvalid_1's rmse: 0.0898876\n",
      "[1250]\ttraining's rmse: 0.0854891\tvalid_1's rmse: 0.089884\n",
      "[1275]\ttraining's rmse: 0.0854716\tvalid_1's rmse: 0.0898804\n",
      "[1300]\ttraining's rmse: 0.0854582\tvalid_1's rmse: 0.0898749\n",
      "[1325]\ttraining's rmse: 0.0854434\tvalid_1's rmse: 0.0898708\n",
      "[1350]\ttraining's rmse: 0.0854309\tvalid_1's rmse: 0.0898671\n",
      "[1375]\ttraining's rmse: 0.0854157\tvalid_1's rmse: 0.0898634\n",
      "[1400]\ttraining's rmse: 0.0854017\tvalid_1's rmse: 0.0898594\n",
      "[1425]\ttraining's rmse: 0.085388\tvalid_1's rmse: 0.0898576\n",
      "[1450]\ttraining's rmse: 0.0853716\tvalid_1's rmse: 0.0898541\n",
      "[1475]\ttraining's rmse: 0.0853603\tvalid_1's rmse: 0.0898503\n",
      "[1500]\ttraining's rmse: 0.0853486\tvalid_1's rmse: 0.0898483\n",
      "[1525]\ttraining's rmse: 0.0853386\tvalid_1's rmse: 0.0898453\n",
      "[1550]\ttraining's rmse: 0.0853272\tvalid_1's rmse: 0.0898424\n",
      "[1575]\ttraining's rmse: 0.0853188\tvalid_1's rmse: 0.08984\n",
      "[1600]\ttraining's rmse: 0.0853104\tvalid_1's rmse: 0.0898366\n",
      "[1625]\ttraining's rmse: 0.0853008\tvalid_1's rmse: 0.089833\n",
      "[1650]\ttraining's rmse: 0.0852913\tvalid_1's rmse: 0.0898305\n",
      "[1675]\ttraining's rmse: 0.0852825\tvalid_1's rmse: 0.0898284\n",
      "[1700]\ttraining's rmse: 0.0852755\tvalid_1's rmse: 0.0898257\n",
      "[1725]\ttraining's rmse: 0.0852671\tvalid_1's rmse: 0.0898237\n",
      "[1750]\ttraining's rmse: 0.0852581\tvalid_1's rmse: 0.0898205\n",
      "[1775]\ttraining's rmse: 0.0852508\tvalid_1's rmse: 0.0898176\n",
      "[1800]\ttraining's rmse: 0.0852434\tvalid_1's rmse: 0.0898145\n",
      "[1825]\ttraining's rmse: 0.0852381\tvalid_1's rmse: 0.0898132\n",
      "[1850]\ttraining's rmse: 0.0852322\tvalid_1's rmse: 0.0898113\n",
      "[1875]\ttraining's rmse: 0.0852266\tvalid_1's rmse: 0.0898108\n",
      "[1900]\ttraining's rmse: 0.08522\tvalid_1's rmse: 0.0898093\n",
      "[1925]\ttraining's rmse: 0.0852143\tvalid_1's rmse: 0.0898082\n",
      "[1950]\ttraining's rmse: 0.0852107\tvalid_1's rmse: 0.0898069\n",
      "[1975]\ttraining's rmse: 0.0852054\tvalid_1's rmse: 0.0898045\n",
      "[2000]\ttraining's rmse: 0.0852018\tvalid_1's rmse: 0.0898033\n",
      "[2025]\ttraining's rmse: 0.0851977\tvalid_1's rmse: 0.0898024\n",
      "[2050]\ttraining's rmse: 0.0851933\tvalid_1's rmse: 0.0898015\n",
      "[2075]\ttraining's rmse: 0.0851897\tvalid_1's rmse: 0.0898006\n",
      "[2100]\ttraining's rmse: 0.0851853\tvalid_1's rmse: 0.0897994\n",
      "[2125]\ttraining's rmse: 0.0851824\tvalid_1's rmse: 0.0897989\n",
      "[2150]\ttraining's rmse: 0.085179\tvalid_1's rmse: 0.0897986\n",
      "[2175]\ttraining's rmse: 0.0851759\tvalid_1's rmse: 0.0897982\n",
      "[2200]\ttraining's rmse: 0.0851733\tvalid_1's rmse: 0.0897974\n",
      "[2225]\ttraining's rmse: 0.0851709\tvalid_1's rmse: 0.0897973\n",
      "[2250]\ttraining's rmse: 0.0851674\tvalid_1's rmse: 0.0897961\n",
      "[2275]\ttraining's rmse: 0.0851636\tvalid_1's rmse: 0.0897959\n",
      "[2300]\ttraining's rmse: 0.0851608\tvalid_1's rmse: 0.0897947\n",
      "[2325]\ttraining's rmse: 0.0851576\tvalid_1's rmse: 0.0897936\n",
      "[2350]\ttraining's rmse: 0.0851546\tvalid_1's rmse: 0.0897925\n",
      "[2375]\ttraining's rmse: 0.085152\tvalid_1's rmse: 0.089791\n",
      "[2400]\ttraining's rmse: 0.0851482\tvalid_1's rmse: 0.0897909\n",
      "[2425]\ttraining's rmse: 0.0851448\tvalid_1's rmse: 0.0897897\n",
      "[2450]\ttraining's rmse: 0.0851418\tvalid_1's rmse: 0.089789\n",
      "[2475]\ttraining's rmse: 0.0851393\tvalid_1's rmse: 0.0897887\n",
      "[2500]\ttraining's rmse: 0.0851363\tvalid_1's rmse: 0.0897882\n",
      "[2525]\ttraining's rmse: 0.0851328\tvalid_1's rmse: 0.0897863\n",
      "[2550]\ttraining's rmse: 0.0851302\tvalid_1's rmse: 0.0897856\n",
      "[2575]\ttraining's rmse: 0.0851269\tvalid_1's rmse: 0.0897851\n",
      "[2600]\ttraining's rmse: 0.0851247\tvalid_1's rmse: 0.0897849\n",
      "[2625]\ttraining's rmse: 0.0851233\tvalid_1's rmse: 0.0897844\n",
      "[2650]\ttraining's rmse: 0.0851209\tvalid_1's rmse: 0.089783\n",
      "[2675]\ttraining's rmse: 0.0851186\tvalid_1's rmse: 0.0897824\n",
      "[2700]\ttraining's rmse: 0.0851156\tvalid_1's rmse: 0.0897818\n",
      "[2725]\ttraining's rmse: 0.085114\tvalid_1's rmse: 0.0897816\n",
      "[2750]\ttraining's rmse: 0.0851115\tvalid_1's rmse: 0.0897812\n",
      "[2775]\ttraining's rmse: 0.0851099\tvalid_1's rmse: 0.0897812\n",
      "[2800]\ttraining's rmse: 0.0851078\tvalid_1's rmse: 0.0897807\n",
      "[2825]\ttraining's rmse: 0.0851058\tvalid_1's rmse: 0.0897809\n",
      "[2850]\ttraining's rmse: 0.0851042\tvalid_1's rmse: 0.0897807\n",
      "[2875]\ttraining's rmse: 0.0851009\tvalid_1's rmse: 0.0897801\n",
      "[2900]\ttraining's rmse: 0.0850997\tvalid_1's rmse: 0.0897801\n",
      "[2925]\ttraining's rmse: 0.085098\tvalid_1's rmse: 0.0897793\n",
      "[2950]\ttraining's rmse: 0.0850967\tvalid_1's rmse: 0.0897783\n",
      "[2975]\ttraining's rmse: 0.0850947\tvalid_1's rmse: 0.0897778\n",
      "[3000]\ttraining's rmse: 0.0850931\tvalid_1's rmse: 0.0897774\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0850931\tvalid_1's rmse: 0.0897774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0881934\tvalid_1's rmse: 0.0907819\n",
      "[50]\ttraining's rmse: 0.0880604\tvalid_1's rmse: 0.0907253\n",
      "[75]\ttraining's rmse: 0.0879238\tvalid_1's rmse: 0.0906697\n",
      "[100]\ttraining's rmse: 0.0878018\tvalid_1's rmse: 0.0906205\n",
      "[125]\ttraining's rmse: 0.0876744\tvalid_1's rmse: 0.0905712\n",
      "[150]\ttraining's rmse: 0.0875565\tvalid_1's rmse: 0.0905254\n",
      "[175]\ttraining's rmse: 0.0874589\tvalid_1's rmse: 0.09049\n",
      "[200]\ttraining's rmse: 0.0873527\tvalid_1's rmse: 0.0904516\n",
      "[225]\ttraining's rmse: 0.087254\tvalid_1's rmse: 0.0904166\n",
      "[250]\ttraining's rmse: 0.0871664\tvalid_1's rmse: 0.0903858\n",
      "[275]\ttraining's rmse: 0.0870867\tvalid_1's rmse: 0.0903568\n",
      "[300]\ttraining's rmse: 0.0870057\tvalid_1's rmse: 0.0903292\n",
      "[325]\ttraining's rmse: 0.0869267\tvalid_1's rmse: 0.0903042\n",
      "[350]\ttraining's rmse: 0.0868495\tvalid_1's rmse: 0.0902788\n",
      "[375]\ttraining's rmse: 0.0867864\tvalid_1's rmse: 0.090258\n",
      "[400]\ttraining's rmse: 0.0867177\tvalid_1's rmse: 0.0902365\n",
      "[425]\ttraining's rmse: 0.0866547\tvalid_1's rmse: 0.0902165\n",
      "[450]\ttraining's rmse: 0.0865961\tvalid_1's rmse: 0.0901977\n",
      "[475]\ttraining's rmse: 0.0865433\tvalid_1's rmse: 0.090181\n",
      "[500]\ttraining's rmse: 0.0864952\tvalid_1's rmse: 0.0901646\n",
      "[525]\ttraining's rmse: 0.0864354\tvalid_1's rmse: 0.0901477\n",
      "[550]\ttraining's rmse: 0.0863796\tvalid_1's rmse: 0.090134\n",
      "[575]\ttraining's rmse: 0.086332\tvalid_1's rmse: 0.0901207\n",
      "[600]\ttraining's rmse: 0.0862821\tvalid_1's rmse: 0.0901083\n",
      "[625]\ttraining's rmse: 0.0862439\tvalid_1's rmse: 0.0900958\n",
      "[650]\ttraining's rmse: 0.0861956\tvalid_1's rmse: 0.0900835\n",
      "[675]\ttraining's rmse: 0.0861489\tvalid_1's rmse: 0.0900718\n",
      "[700]\ttraining's rmse: 0.0861055\tvalid_1's rmse: 0.0900611\n",
      "[725]\ttraining's rmse: 0.0860671\tvalid_1's rmse: 0.0900515\n",
      "[750]\ttraining's rmse: 0.0860313\tvalid_1's rmse: 0.0900427\n",
      "[775]\ttraining's rmse: 0.0860012\tvalid_1's rmse: 0.0900335\n",
      "[800]\ttraining's rmse: 0.0859619\tvalid_1's rmse: 0.0900259\n",
      "[825]\ttraining's rmse: 0.0859286\tvalid_1's rmse: 0.0900175\n",
      "[850]\ttraining's rmse: 0.0858965\tvalid_1's rmse: 0.0900113\n",
      "[875]\ttraining's rmse: 0.0858669\tvalid_1's rmse: 0.0900052\n",
      "[900]\ttraining's rmse: 0.0858343\tvalid_1's rmse: 0.0899983\n",
      "[925]\ttraining's rmse: 0.0858038\tvalid_1's rmse: 0.0899932\n",
      "[950]\ttraining's rmse: 0.085775\tvalid_1's rmse: 0.0899876\n",
      "[975]\ttraining's rmse: 0.0857506\tvalid_1's rmse: 0.0899833\n",
      "[1000]\ttraining's rmse: 0.0857276\tvalid_1's rmse: 0.0899781\n",
      "[1025]\ttraining's rmse: 0.085699\tvalid_1's rmse: 0.0899733\n",
      "[1050]\ttraining's rmse: 0.0856781\tvalid_1's rmse: 0.0899693\n",
      "[1075]\ttraining's rmse: 0.0856557\tvalid_1's rmse: 0.0899655\n",
      "[1100]\ttraining's rmse: 0.0856375\tvalid_1's rmse: 0.0899625\n",
      "[1125]\ttraining's rmse: 0.0856179\tvalid_1's rmse: 0.0899597\n",
      "[1150]\ttraining's rmse: 0.0855981\tvalid_1's rmse: 0.089957\n",
      "[1175]\ttraining's rmse: 0.0855828\tvalid_1's rmse: 0.0899547\n",
      "[1200]\ttraining's rmse: 0.0855624\tvalid_1's rmse: 0.0899508\n",
      "[1225]\ttraining's rmse: 0.085547\tvalid_1's rmse: 0.0899488\n",
      "[1250]\ttraining's rmse: 0.0855304\tvalid_1's rmse: 0.0899468\n",
      "[1275]\ttraining's rmse: 0.0855125\tvalid_1's rmse: 0.0899445\n",
      "[1300]\ttraining's rmse: 0.0854988\tvalid_1's rmse: 0.0899427\n",
      "[1325]\ttraining's rmse: 0.0854841\tvalid_1's rmse: 0.0899406\n",
      "[1350]\ttraining's rmse: 0.0854672\tvalid_1's rmse: 0.0899398\n",
      "[1375]\ttraining's rmse: 0.0854542\tvalid_1's rmse: 0.0899384\n",
      "[1400]\ttraining's rmse: 0.0854427\tvalid_1's rmse: 0.0899366\n",
      "[1425]\ttraining's rmse: 0.08543\tvalid_1's rmse: 0.0899348\n",
      "[1450]\ttraining's rmse: 0.0854152\tvalid_1's rmse: 0.089933\n",
      "[1475]\ttraining's rmse: 0.0854032\tvalid_1's rmse: 0.0899316\n",
      "[1500]\ttraining's rmse: 0.0853935\tvalid_1's rmse: 0.0899303\n",
      "[1525]\ttraining's rmse: 0.085383\tvalid_1's rmse: 0.0899297\n",
      "[1550]\ttraining's rmse: 0.085372\tvalid_1's rmse: 0.0899288\n",
      "[1575]\ttraining's rmse: 0.0853618\tvalid_1's rmse: 0.0899275\n",
      "[1600]\ttraining's rmse: 0.0853545\tvalid_1's rmse: 0.0899271\n",
      "[1625]\ttraining's rmse: 0.085344\tvalid_1's rmse: 0.089926\n",
      "[1650]\ttraining's rmse: 0.085335\tvalid_1's rmse: 0.0899254\n",
      "[1675]\ttraining's rmse: 0.0853284\tvalid_1's rmse: 0.0899247\n",
      "[1700]\ttraining's rmse: 0.0853209\tvalid_1's rmse: 0.0899234\n",
      "[1725]\ttraining's rmse: 0.0853129\tvalid_1's rmse: 0.0899225\n",
      "[1750]\ttraining's rmse: 0.0853036\tvalid_1's rmse: 0.0899223\n",
      "[1775]\ttraining's rmse: 0.085297\tvalid_1's rmse: 0.0899214\n",
      "[1800]\ttraining's rmse: 0.0852907\tvalid_1's rmse: 0.089921\n",
      "[1825]\ttraining's rmse: 0.0852836\tvalid_1's rmse: 0.0899199\n",
      "[1850]\ttraining's rmse: 0.0852771\tvalid_1's rmse: 0.0899195\n",
      "[1875]\ttraining's rmse: 0.0852715\tvalid_1's rmse: 0.0899192\n",
      "[1900]\ttraining's rmse: 0.0852666\tvalid_1's rmse: 0.0899187\n",
      "[1925]\ttraining's rmse: 0.0852618\tvalid_1's rmse: 0.0899181\n",
      "[1950]\ttraining's rmse: 0.0852566\tvalid_1's rmse: 0.0899165\n",
      "[1975]\ttraining's rmse: 0.0852534\tvalid_1's rmse: 0.0899165\n",
      "[2000]\ttraining's rmse: 0.0852479\tvalid_1's rmse: 0.0899159\n",
      "[2025]\ttraining's rmse: 0.0852432\tvalid_1's rmse: 0.0899153\n",
      "[2050]\ttraining's rmse: 0.0852379\tvalid_1's rmse: 0.0899153\n",
      "[2075]\ttraining's rmse: 0.0852337\tvalid_1's rmse: 0.089915\n",
      "[2100]\ttraining's rmse: 0.0852294\tvalid_1's rmse: 0.0899145\n",
      "[2125]\ttraining's rmse: 0.0852253\tvalid_1's rmse: 0.0899146\n",
      "[2150]\ttraining's rmse: 0.085221\tvalid_1's rmse: 0.0899146\n",
      "Early stopping, best iteration is:\n",
      "[2106]\ttraining's rmse: 0.0852285\tvalid_1's rmse: 0.0899144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0906592\tvalid_1's rmse: 0.0857918\n",
      "[50]\ttraining's rmse: 0.0905379\tvalid_1's rmse: 0.0857408\n",
      "[75]\ttraining's rmse: 0.0904143\tvalid_1's rmse: 0.0856921\n",
      "[100]\ttraining's rmse: 0.0903021\tvalid_1's rmse: 0.085649\n",
      "[125]\ttraining's rmse: 0.090191\tvalid_1's rmse: 0.0856058\n",
      "[150]\ttraining's rmse: 0.0900877\tvalid_1's rmse: 0.0855674\n",
      "[175]\ttraining's rmse: 0.0900019\tvalid_1's rmse: 0.0855365\n",
      "[200]\ttraining's rmse: 0.089907\tvalid_1's rmse: 0.0855031\n",
      "[225]\ttraining's rmse: 0.0898116\tvalid_1's rmse: 0.0854693\n",
      "[250]\ttraining's rmse: 0.0897334\tvalid_1's rmse: 0.0854462\n",
      "[275]\ttraining's rmse: 0.0896618\tvalid_1's rmse: 0.0854213\n",
      "[300]\ttraining's rmse: 0.0895887\tvalid_1's rmse: 0.0853965\n",
      "[325]\ttraining's rmse: 0.0895166\tvalid_1's rmse: 0.0853757\n",
      "[350]\ttraining's rmse: 0.0894462\tvalid_1's rmse: 0.0853521\n",
      "[375]\ttraining's rmse: 0.0893873\tvalid_1's rmse: 0.0853348\n",
      "[400]\ttraining's rmse: 0.0893224\tvalid_1's rmse: 0.0853203\n",
      "[425]\ttraining's rmse: 0.0892643\tvalid_1's rmse: 0.0853091\n",
      "[450]\ttraining's rmse: 0.089209\tvalid_1's rmse: 0.0852924\n",
      "[475]\ttraining's rmse: 0.0891574\tvalid_1's rmse: 0.0852823\n",
      "[500]\ttraining's rmse: 0.0891133\tvalid_1's rmse: 0.0852712\n",
      "[525]\ttraining's rmse: 0.0890587\tvalid_1's rmse: 0.0852625\n",
      "[550]\ttraining's rmse: 0.0890066\tvalid_1's rmse: 0.0852481\n",
      "[575]\ttraining's rmse: 0.0889619\tvalid_1's rmse: 0.0852386\n",
      "[600]\ttraining's rmse: 0.0889138\tvalid_1's rmse: 0.0852288\n",
      "[625]\ttraining's rmse: 0.088875\tvalid_1's rmse: 0.0852291\n",
      "[650]\ttraining's rmse: 0.0888261\tvalid_1's rmse: 0.0852248\n",
      "[675]\ttraining's rmse: 0.0887786\tvalid_1's rmse: 0.0852154\n",
      "[700]\ttraining's rmse: 0.0887372\tvalid_1's rmse: 0.0852131\n",
      "[725]\ttraining's rmse: 0.0886993\tvalid_1's rmse: 0.0852068\n",
      "[750]\ttraining's rmse: 0.0886649\tvalid_1's rmse: 0.0852032\n",
      "[775]\ttraining's rmse: 0.0886342\tvalid_1's rmse: 0.0852014\n",
      "[800]\ttraining's rmse: 0.0885963\tvalid_1's rmse: 0.085209\n",
      "[825]\ttraining's rmse: 0.0885624\tvalid_1's rmse: 0.0852089\n",
      "Early stopping, best iteration is:\n",
      "[777]\ttraining's rmse: 0.0886322\tvalid_1's rmse: 0.0852008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0908188\tvalid_1's rmse: 0.0925893\n",
      "[50]\ttraining's rmse: 0.0906304\tvalid_1's rmse: 0.0925361\n",
      "[75]\ttraining's rmse: 0.0904428\tvalid_1's rmse: 0.092482\n",
      "[100]\ttraining's rmse: 0.0902689\tvalid_1's rmse: 0.0924315\n",
      "[125]\ttraining's rmse: 0.0900994\tvalid_1's rmse: 0.0923837\n",
      "[150]\ttraining's rmse: 0.0899392\tvalid_1's rmse: 0.0923394\n",
      "[175]\ttraining's rmse: 0.0898093\tvalid_1's rmse: 0.0923022\n",
      "[200]\ttraining's rmse: 0.089668\tvalid_1's rmse: 0.0922625\n",
      "[225]\ttraining's rmse: 0.0895356\tvalid_1's rmse: 0.0922249\n",
      "[250]\ttraining's rmse: 0.0894189\tvalid_1's rmse: 0.0921919\n",
      "[275]\ttraining's rmse: 0.0893176\tvalid_1's rmse: 0.0921629\n",
      "[300]\ttraining's rmse: 0.0892117\tvalid_1's rmse: 0.092134\n",
      "[325]\ttraining's rmse: 0.0891095\tvalid_1's rmse: 0.0921094\n",
      "[350]\ttraining's rmse: 0.0890102\tvalid_1's rmse: 0.0920848\n",
      "[375]\ttraining's rmse: 0.0889258\tvalid_1's rmse: 0.0920625\n",
      "[400]\ttraining's rmse: 0.088839\tvalid_1's rmse: 0.0920403\n",
      "[425]\ttraining's rmse: 0.0887573\tvalid_1's rmse: 0.0920185\n",
      "[450]\ttraining's rmse: 0.0886863\tvalid_1's rmse: 0.0919981\n",
      "[475]\ttraining's rmse: 0.0886166\tvalid_1's rmse: 0.0919801\n",
      "[500]\ttraining's rmse: 0.0885565\tvalid_1's rmse: 0.0919639\n",
      "[525]\ttraining's rmse: 0.0884834\tvalid_1's rmse: 0.0919461\n",
      "[550]\ttraining's rmse: 0.0884198\tvalid_1's rmse: 0.0919291\n",
      "[575]\ttraining's rmse: 0.088359\tvalid_1's rmse: 0.0919141\n",
      "[600]\ttraining's rmse: 0.0883008\tvalid_1's rmse: 0.0918989\n",
      "[625]\ttraining's rmse: 0.0882538\tvalid_1's rmse: 0.0918862\n",
      "[650]\ttraining's rmse: 0.088198\tvalid_1's rmse: 0.0918726\n",
      "[675]\ttraining's rmse: 0.0881442\tvalid_1's rmse: 0.0918586\n",
      "[700]\ttraining's rmse: 0.0880954\tvalid_1's rmse: 0.0918467\n",
      "[725]\ttraining's rmse: 0.0880497\tvalid_1's rmse: 0.0918366\n",
      "[750]\ttraining's rmse: 0.0880097\tvalid_1's rmse: 0.0918266\n",
      "[775]\ttraining's rmse: 0.0879728\tvalid_1's rmse: 0.0918154\n",
      "[800]\ttraining's rmse: 0.0879317\tvalid_1's rmse: 0.0918065\n",
      "[825]\ttraining's rmse: 0.0878962\tvalid_1's rmse: 0.0917987\n",
      "[850]\ttraining's rmse: 0.0878561\tvalid_1's rmse: 0.0917901\n",
      "[875]\ttraining's rmse: 0.0878249\tvalid_1's rmse: 0.0917814\n",
      "[900]\ttraining's rmse: 0.0877878\tvalid_1's rmse: 0.0917731\n",
      "[925]\ttraining's rmse: 0.0877551\tvalid_1's rmse: 0.0917659\n",
      "[950]\ttraining's rmse: 0.0877261\tvalid_1's rmse: 0.0917589\n",
      "[975]\ttraining's rmse: 0.087698\tvalid_1's rmse: 0.0917519\n",
      "[1000]\ttraining's rmse: 0.0876717\tvalid_1's rmse: 0.0917445\n",
      "[1025]\ttraining's rmse: 0.0876448\tvalid_1's rmse: 0.091739\n",
      "[1050]\ttraining's rmse: 0.0876188\tvalid_1's rmse: 0.0917322\n",
      "[1075]\ttraining's rmse: 0.0875919\tvalid_1's rmse: 0.091727\n",
      "[1100]\ttraining's rmse: 0.0875699\tvalid_1's rmse: 0.0917212\n",
      "[1125]\ttraining's rmse: 0.0875484\tvalid_1's rmse: 0.0917156\n",
      "[1150]\ttraining's rmse: 0.0875236\tvalid_1's rmse: 0.0917107\n",
      "[1175]\ttraining's rmse: 0.0875048\tvalid_1's rmse: 0.0917068\n",
      "[1200]\ttraining's rmse: 0.0874866\tvalid_1's rmse: 0.0917005\n",
      "[1225]\ttraining's rmse: 0.0874691\tvalid_1's rmse: 0.0916952\n",
      "[1250]\ttraining's rmse: 0.0874506\tvalid_1's rmse: 0.091691\n",
      "[1275]\ttraining's rmse: 0.0874255\tvalid_1's rmse: 0.0916864\n",
      "[1300]\ttraining's rmse: 0.0874076\tvalid_1's rmse: 0.0916814\n",
      "[1325]\ttraining's rmse: 0.0873932\tvalid_1's rmse: 0.0916777\n",
      "[1350]\ttraining's rmse: 0.0873778\tvalid_1's rmse: 0.0916742\n",
      "[1375]\ttraining's rmse: 0.0873633\tvalid_1's rmse: 0.0916699\n",
      "[1400]\ttraining's rmse: 0.0873505\tvalid_1's rmse: 0.0916663\n",
      "[1425]\ttraining's rmse: 0.0873323\tvalid_1's rmse: 0.0916633\n",
      "[1450]\ttraining's rmse: 0.0873155\tvalid_1's rmse: 0.0916611\n",
      "[1475]\ttraining's rmse: 0.0872995\tvalid_1's rmse: 0.0916582\n",
      "[1500]\ttraining's rmse: 0.0872906\tvalid_1's rmse: 0.091655\n",
      "[1525]\ttraining's rmse: 0.0872772\tvalid_1's rmse: 0.0916517\n",
      "[1550]\ttraining's rmse: 0.087263\tvalid_1's rmse: 0.0916483\n",
      "[1575]\ttraining's rmse: 0.0872533\tvalid_1's rmse: 0.0916455\n",
      "[1600]\ttraining's rmse: 0.0872428\tvalid_1's rmse: 0.0916417\n",
      "[1625]\ttraining's rmse: 0.0872326\tvalid_1's rmse: 0.0916381\n",
      "[1650]\ttraining's rmse: 0.0872218\tvalid_1's rmse: 0.0916356\n",
      "[1675]\ttraining's rmse: 0.087216\tvalid_1's rmse: 0.0916336\n",
      "[1700]\ttraining's rmse: 0.087207\tvalid_1's rmse: 0.091631\n",
      "[1725]\ttraining's rmse: 0.0871997\tvalid_1's rmse: 0.0916281\n",
      "[1750]\ttraining's rmse: 0.0871903\tvalid_1's rmse: 0.0916245\n",
      "[1775]\ttraining's rmse: 0.0871834\tvalid_1's rmse: 0.0916237\n",
      "[1800]\ttraining's rmse: 0.0871739\tvalid_1's rmse: 0.0916224\n",
      "[1825]\ttraining's rmse: 0.0871667\tvalid_1's rmse: 0.0916204\n",
      "[1850]\ttraining's rmse: 0.0871608\tvalid_1's rmse: 0.091618\n",
      "[1875]\ttraining's rmse: 0.087154\tvalid_1's rmse: 0.0916164\n",
      "[1900]\ttraining's rmse: 0.0871471\tvalid_1's rmse: 0.0916149\n",
      "[1925]\ttraining's rmse: 0.087142\tvalid_1's rmse: 0.0916133\n",
      "[1950]\ttraining's rmse: 0.0871381\tvalid_1's rmse: 0.0916126\n",
      "[1975]\ttraining's rmse: 0.0871335\tvalid_1's rmse: 0.0916119\n",
      "[2000]\ttraining's rmse: 0.0871283\tvalid_1's rmse: 0.09161\n",
      "[2025]\ttraining's rmse: 0.0871235\tvalid_1's rmse: 0.0916078\n",
      "[2050]\ttraining's rmse: 0.0871188\tvalid_1's rmse: 0.0916064\n",
      "[2075]\ttraining's rmse: 0.0871146\tvalid_1's rmse: 0.0916048\n",
      "[2100]\ttraining's rmse: 0.0871103\tvalid_1's rmse: 0.0916039\n",
      "[2125]\ttraining's rmse: 0.0871071\tvalid_1's rmse: 0.0916029\n",
      "[2150]\ttraining's rmse: 0.0871023\tvalid_1's rmse: 0.0916018\n",
      "[2175]\ttraining's rmse: 0.0870972\tvalid_1's rmse: 0.0916004\n",
      "[2200]\ttraining's rmse: 0.0870937\tvalid_1's rmse: 0.0915988\n",
      "[2225]\ttraining's rmse: 0.0870899\tvalid_1's rmse: 0.0915973\n",
      "[2250]\ttraining's rmse: 0.0870864\tvalid_1's rmse: 0.0915956\n",
      "[2275]\ttraining's rmse: 0.0870823\tvalid_1's rmse: 0.091595\n",
      "[2300]\ttraining's rmse: 0.0870798\tvalid_1's rmse: 0.0915943\n",
      "[2325]\ttraining's rmse: 0.0870754\tvalid_1's rmse: 0.0915921\n",
      "[2350]\ttraining's rmse: 0.0870703\tvalid_1's rmse: 0.0915898\n",
      "[2375]\ttraining's rmse: 0.0870674\tvalid_1's rmse: 0.0915884\n",
      "[2400]\ttraining's rmse: 0.087063\tvalid_1's rmse: 0.0915881\n",
      "[2425]\ttraining's rmse: 0.0870609\tvalid_1's rmse: 0.0915873\n",
      "[2450]\ttraining's rmse: 0.0870594\tvalid_1's rmse: 0.0915865\n",
      "[2475]\ttraining's rmse: 0.0870552\tvalid_1's rmse: 0.0915857\n",
      "[2500]\ttraining's rmse: 0.0870522\tvalid_1's rmse: 0.0915853\n",
      "[2525]\ttraining's rmse: 0.0870491\tvalid_1's rmse: 0.0915847\n",
      "[2550]\ttraining's rmse: 0.0870465\tvalid_1's rmse: 0.0915842\n",
      "[2575]\ttraining's rmse: 0.0870442\tvalid_1's rmse: 0.0915836\n",
      "[2600]\ttraining's rmse: 0.0870396\tvalid_1's rmse: 0.0915824\n",
      "[2625]\ttraining's rmse: 0.0870364\tvalid_1's rmse: 0.0915805\n",
      "[2650]\ttraining's rmse: 0.0870352\tvalid_1's rmse: 0.0915797\n",
      "[2675]\ttraining's rmse: 0.0870329\tvalid_1's rmse: 0.0915785\n",
      "[2700]\ttraining's rmse: 0.0870311\tvalid_1's rmse: 0.0915785\n",
      "[2725]\ttraining's rmse: 0.0870289\tvalid_1's rmse: 0.0915779\n",
      "[2750]\ttraining's rmse: 0.0870262\tvalid_1's rmse: 0.0915766\n",
      "[2775]\ttraining's rmse: 0.0870233\tvalid_1's rmse: 0.0915763\n",
      "[2800]\ttraining's rmse: 0.0870217\tvalid_1's rmse: 0.091576\n",
      "[2825]\ttraining's rmse: 0.0870182\tvalid_1's rmse: 0.0915758\n",
      "[2850]\ttraining's rmse: 0.0870169\tvalid_1's rmse: 0.0915753\n",
      "[2875]\ttraining's rmse: 0.0870149\tvalid_1's rmse: 0.0915749\n",
      "[2900]\ttraining's rmse: 0.0870126\tvalid_1's rmse: 0.0915741\n",
      "[2925]\ttraining's rmse: 0.0870111\tvalid_1's rmse: 0.091574\n",
      "[2950]\ttraining's rmse: 0.0870101\tvalid_1's rmse: 0.0915737\n",
      "[2975]\ttraining's rmse: 0.087009\tvalid_1's rmse: 0.0915733\n",
      "[3000]\ttraining's rmse: 0.0870058\tvalid_1's rmse: 0.0915726\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0870058\tvalid_1's rmse: 0.0915726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0906175\tvalid_1's rmse: 0.0930237\n",
      "[50]\ttraining's rmse: 0.0904508\tvalid_1's rmse: 0.0929697\n",
      "[75]\ttraining's rmse: 0.0902765\tvalid_1's rmse: 0.0929149\n",
      "[100]\ttraining's rmse: 0.0901206\tvalid_1's rmse: 0.0928657\n",
      "[125]\ttraining's rmse: 0.0899625\tvalid_1's rmse: 0.0928169\n",
      "[150]\ttraining's rmse: 0.0898217\tvalid_1's rmse: 0.0927722\n",
      "[175]\ttraining's rmse: 0.0896991\tvalid_1's rmse: 0.0927356\n",
      "[200]\ttraining's rmse: 0.0895705\tvalid_1's rmse: 0.0926971\n",
      "[225]\ttraining's rmse: 0.089447\tvalid_1's rmse: 0.0926628\n",
      "[250]\ttraining's rmse: 0.0893396\tvalid_1's rmse: 0.0926305\n",
      "[275]\ttraining's rmse: 0.0892416\tvalid_1's rmse: 0.0926022\n",
      "[300]\ttraining's rmse: 0.0891456\tvalid_1's rmse: 0.0925751\n",
      "[325]\ttraining's rmse: 0.0890485\tvalid_1's rmse: 0.0925476\n",
      "[350]\ttraining's rmse: 0.0889572\tvalid_1's rmse: 0.0925229\n",
      "[375]\ttraining's rmse: 0.0888837\tvalid_1's rmse: 0.0925024\n",
      "[400]\ttraining's rmse: 0.0888028\tvalid_1's rmse: 0.0924822\n",
      "[425]\ttraining's rmse: 0.0887303\tvalid_1's rmse: 0.0924613\n",
      "[450]\ttraining's rmse: 0.0886618\tvalid_1's rmse: 0.0924429\n",
      "[475]\ttraining's rmse: 0.0885998\tvalid_1's rmse: 0.0924257\n",
      "[500]\ttraining's rmse: 0.0885438\tvalid_1's rmse: 0.0924078\n",
      "[525]\ttraining's rmse: 0.0884774\tvalid_1's rmse: 0.0923918\n",
      "[550]\ttraining's rmse: 0.0884154\tvalid_1's rmse: 0.092377\n",
      "[575]\ttraining's rmse: 0.0883587\tvalid_1's rmse: 0.0923636\n",
      "[600]\ttraining's rmse: 0.0883052\tvalid_1's rmse: 0.0923505\n",
      "[625]\ttraining's rmse: 0.088263\tvalid_1's rmse: 0.0923384\n",
      "[650]\ttraining's rmse: 0.0882082\tvalid_1's rmse: 0.0923254\n",
      "[675]\ttraining's rmse: 0.0881555\tvalid_1's rmse: 0.0923146\n",
      "[700]\ttraining's rmse: 0.0881097\tvalid_1's rmse: 0.0923038\n",
      "[725]\ttraining's rmse: 0.0880692\tvalid_1's rmse: 0.0922947\n",
      "[750]\ttraining's rmse: 0.0880289\tvalid_1's rmse: 0.0922856\n",
      "[775]\ttraining's rmse: 0.0879969\tvalid_1's rmse: 0.0922771\n",
      "[800]\ttraining's rmse: 0.0879542\tvalid_1's rmse: 0.0922688\n",
      "[825]\ttraining's rmse: 0.0879209\tvalid_1's rmse: 0.0922599\n",
      "[850]\ttraining's rmse: 0.0878872\tvalid_1's rmse: 0.0922537\n",
      "[875]\ttraining's rmse: 0.087857\tvalid_1's rmse: 0.0922471\n",
      "[900]\ttraining's rmse: 0.0878226\tvalid_1's rmse: 0.0922398\n",
      "[925]\ttraining's rmse: 0.0877887\tvalid_1's rmse: 0.0922332\n",
      "[950]\ttraining's rmse: 0.0877603\tvalid_1's rmse: 0.092228\n",
      "[975]\ttraining's rmse: 0.0877299\tvalid_1's rmse: 0.0922223\n",
      "[1000]\ttraining's rmse: 0.0877019\tvalid_1's rmse: 0.0922173\n",
      "[1025]\ttraining's rmse: 0.087671\tvalid_1's rmse: 0.0922126\n",
      "[1050]\ttraining's rmse: 0.0876454\tvalid_1's rmse: 0.0922075\n",
      "[1075]\ttraining's rmse: 0.0876207\tvalid_1's rmse: 0.0922042\n",
      "[1100]\ttraining's rmse: 0.0875999\tvalid_1's rmse: 0.0922005\n",
      "[1125]\ttraining's rmse: 0.0875767\tvalid_1's rmse: 0.0921966\n",
      "[1150]\ttraining's rmse: 0.087556\tvalid_1's rmse: 0.0921938\n",
      "[1175]\ttraining's rmse: 0.0875381\tvalid_1's rmse: 0.0921916\n",
      "[1200]\ttraining's rmse: 0.0875183\tvalid_1's rmse: 0.0921876\n",
      "[1225]\ttraining's rmse: 0.0874996\tvalid_1's rmse: 0.0921858\n",
      "[1250]\ttraining's rmse: 0.0874815\tvalid_1's rmse: 0.0921834\n",
      "[1275]\ttraining's rmse: 0.0874601\tvalid_1's rmse: 0.0921813\n",
      "[1300]\ttraining's rmse: 0.0874432\tvalid_1's rmse: 0.0921778\n",
      "[1325]\ttraining's rmse: 0.0874242\tvalid_1's rmse: 0.0921747\n",
      "[1350]\ttraining's rmse: 0.0874061\tvalid_1's rmse: 0.0921735\n",
      "[1375]\ttraining's rmse: 0.0873893\tvalid_1's rmse: 0.0921716\n",
      "[1400]\ttraining's rmse: 0.0873757\tvalid_1's rmse: 0.0921698\n",
      "[1425]\ttraining's rmse: 0.0873605\tvalid_1's rmse: 0.0921685\n",
      "[1450]\ttraining's rmse: 0.0873459\tvalid_1's rmse: 0.0921673\n",
      "[1475]\ttraining's rmse: 0.0873331\tvalid_1's rmse: 0.0921662\n",
      "[1500]\ttraining's rmse: 0.0873226\tvalid_1's rmse: 0.0921655\n",
      "[1525]\ttraining's rmse: 0.0873088\tvalid_1's rmse: 0.0921643\n",
      "[1550]\ttraining's rmse: 0.0872978\tvalid_1's rmse: 0.0921643\n",
      "[1575]\ttraining's rmse: 0.0872864\tvalid_1's rmse: 0.0921635\n",
      "[1600]\ttraining's rmse: 0.0872753\tvalid_1's rmse: 0.0921629\n",
      "[1625]\ttraining's rmse: 0.0872663\tvalid_1's rmse: 0.0921617\n",
      "[1650]\ttraining's rmse: 0.0872559\tvalid_1's rmse: 0.0921608\n",
      "[1675]\ttraining's rmse: 0.0872467\tvalid_1's rmse: 0.0921589\n",
      "[1700]\ttraining's rmse: 0.0872385\tvalid_1's rmse: 0.0921576\n",
      "[1725]\ttraining's rmse: 0.0872323\tvalid_1's rmse: 0.0921568\n",
      "[1750]\ttraining's rmse: 0.0872213\tvalid_1's rmse: 0.0921562\n",
      "[1775]\ttraining's rmse: 0.0872141\tvalid_1's rmse: 0.0921557\n",
      "[1800]\ttraining's rmse: 0.0872037\tvalid_1's rmse: 0.0921547\n",
      "[1825]\ttraining's rmse: 0.0871961\tvalid_1's rmse: 0.0921543\n",
      "[1850]\ttraining's rmse: 0.0871893\tvalid_1's rmse: 0.0921537\n",
      "[1875]\ttraining's rmse: 0.0871826\tvalid_1's rmse: 0.092154\n",
      "[1900]\ttraining's rmse: 0.0871769\tvalid_1's rmse: 0.0921542\n",
      "Early stopping, best iteration is:\n",
      "[1860]\ttraining's rmse: 0.0871873\tvalid_1's rmse: 0.0921533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0926575\tvalid_1's rmse: 0.088961\n",
      "[50]\ttraining's rmse: 0.092523\tvalid_1's rmse: 0.0889135\n",
      "[75]\ttraining's rmse: 0.0923813\tvalid_1's rmse: 0.0888642\n",
      "[100]\ttraining's rmse: 0.0922519\tvalid_1's rmse: 0.0888222\n",
      "[125]\ttraining's rmse: 0.0921221\tvalid_1's rmse: 0.0887803\n",
      "[150]\ttraining's rmse: 0.092\tvalid_1's rmse: 0.0887418\n",
      "[175]\ttraining's rmse: 0.0918956\tvalid_1's rmse: 0.0887088\n",
      "[200]\ttraining's rmse: 0.091784\tvalid_1's rmse: 0.0886778\n",
      "[225]\ttraining's rmse: 0.091675\tvalid_1's rmse: 0.0886474\n",
      "[250]\ttraining's rmse: 0.0915835\tvalid_1's rmse: 0.0886204\n",
      "[275]\ttraining's rmse: 0.0915013\tvalid_1's rmse: 0.0885963\n",
      "[300]\ttraining's rmse: 0.0914176\tvalid_1's rmse: 0.0885727\n",
      "[325]\ttraining's rmse: 0.0913332\tvalid_1's rmse: 0.0885512\n",
      "[350]\ttraining's rmse: 0.0912517\tvalid_1's rmse: 0.0885302\n",
      "[375]\ttraining's rmse: 0.0911814\tvalid_1's rmse: 0.0885155\n",
      "[400]\ttraining's rmse: 0.09111\tvalid_1's rmse: 0.0885035\n",
      "[425]\ttraining's rmse: 0.0910412\tvalid_1's rmse: 0.0884874\n",
      "[450]\ttraining's rmse: 0.0909785\tvalid_1's rmse: 0.0884759\n",
      "[475]\ttraining's rmse: 0.0909192\tvalid_1's rmse: 0.0884622\n",
      "[500]\ttraining's rmse: 0.0908704\tvalid_1's rmse: 0.0884484\n",
      "[525]\ttraining's rmse: 0.0908045\tvalid_1's rmse: 0.088435\n",
      "[550]\ttraining's rmse: 0.0907467\tvalid_1's rmse: 0.088424\n",
      "[575]\ttraining's rmse: 0.0906942\tvalid_1's rmse: 0.0884194\n",
      "[600]\ttraining's rmse: 0.0906418\tvalid_1's rmse: 0.0884168\n",
      "[625]\ttraining's rmse: 0.0905995\tvalid_1's rmse: 0.0884083\n",
      "[650]\ttraining's rmse: 0.090546\tvalid_1's rmse: 0.0884049\n",
      "[675]\ttraining's rmse: 0.0904925\tvalid_1's rmse: 0.0884021\n",
      "[700]\ttraining's rmse: 0.0904459\tvalid_1's rmse: 0.0883948\n",
      "[725]\ttraining's rmse: 0.090402\tvalid_1's rmse: 0.0883959\n",
      "[750]\ttraining's rmse: 0.0903593\tvalid_1's rmse: 0.0884019\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's rmse: 0.0904111\tvalid_1's rmse: 0.0883908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0884609\tvalid_1's rmse: 0.0910824\n",
      "[50]\ttraining's rmse: 0.0883195\tvalid_1's rmse: 0.0910257\n",
      "[75]\ttraining's rmse: 0.0881801\tvalid_1's rmse: 0.0909685\n",
      "[100]\ttraining's rmse: 0.0880485\tvalid_1's rmse: 0.0909204\n",
      "[125]\ttraining's rmse: 0.0879171\tvalid_1's rmse: 0.0908696\n",
      "[150]\ttraining's rmse: 0.0877948\tvalid_1's rmse: 0.0908243\n",
      "[175]\ttraining's rmse: 0.0876955\tvalid_1's rmse: 0.0907855\n",
      "[200]\ttraining's rmse: 0.0875896\tvalid_1's rmse: 0.090748\n",
      "[225]\ttraining's rmse: 0.0874847\tvalid_1's rmse: 0.0907127\n",
      "[250]\ttraining's rmse: 0.0873992\tvalid_1's rmse: 0.0906799\n",
      "[275]\ttraining's rmse: 0.0873156\tvalid_1's rmse: 0.0906492\n",
      "[300]\ttraining's rmse: 0.0872314\tvalid_1's rmse: 0.0906207\n",
      "[325]\ttraining's rmse: 0.0871513\tvalid_1's rmse: 0.0905955\n",
      "[350]\ttraining's rmse: 0.0870736\tvalid_1's rmse: 0.0905695\n",
      "[375]\ttraining's rmse: 0.0870067\tvalid_1's rmse: 0.0905479\n",
      "[400]\ttraining's rmse: 0.0869365\tvalid_1's rmse: 0.0905257\n",
      "[425]\ttraining's rmse: 0.0868733\tvalid_1's rmse: 0.090502\n",
      "[450]\ttraining's rmse: 0.0868141\tvalid_1's rmse: 0.0904808\n",
      "[475]\ttraining's rmse: 0.0867574\tvalid_1's rmse: 0.0904623\n",
      "[500]\ttraining's rmse: 0.0867114\tvalid_1's rmse: 0.0904448\n",
      "[525]\ttraining's rmse: 0.086654\tvalid_1's rmse: 0.0904269\n",
      "[550]\ttraining's rmse: 0.0866017\tvalid_1's rmse: 0.0904115\n",
      "[575]\ttraining's rmse: 0.0865503\tvalid_1's rmse: 0.0903966\n",
      "[600]\ttraining's rmse: 0.0865005\tvalid_1's rmse: 0.0903818\n",
      "[625]\ttraining's rmse: 0.0864613\tvalid_1's rmse: 0.0903679\n",
      "[650]\ttraining's rmse: 0.0864148\tvalid_1's rmse: 0.0903532\n",
      "[675]\ttraining's rmse: 0.0863664\tvalid_1's rmse: 0.0903401\n",
      "[700]\ttraining's rmse: 0.0863254\tvalid_1's rmse: 0.0903264\n",
      "[725]\ttraining's rmse: 0.0862863\tvalid_1's rmse: 0.0903153\n",
      "[750]\ttraining's rmse: 0.0862517\tvalid_1's rmse: 0.0903059\n",
      "[775]\ttraining's rmse: 0.0862226\tvalid_1's rmse: 0.0902942\n",
      "[800]\ttraining's rmse: 0.086185\tvalid_1's rmse: 0.0902853\n",
      "[825]\ttraining's rmse: 0.0861548\tvalid_1's rmse: 0.0902754\n",
      "[850]\ttraining's rmse: 0.086122\tvalid_1's rmse: 0.0902678\n",
      "[875]\ttraining's rmse: 0.0860942\tvalid_1's rmse: 0.0902584\n",
      "[900]\ttraining's rmse: 0.0860635\tvalid_1's rmse: 0.0902518\n",
      "[925]\ttraining's rmse: 0.0860357\tvalid_1's rmse: 0.0902437\n",
      "[950]\ttraining's rmse: 0.086007\tvalid_1's rmse: 0.0902372\n",
      "[975]\ttraining's rmse: 0.0859834\tvalid_1's rmse: 0.0902292\n",
      "[1000]\ttraining's rmse: 0.0859599\tvalid_1's rmse: 0.0902222\n",
      "[1025]\ttraining's rmse: 0.085933\tvalid_1's rmse: 0.0902163\n",
      "[1050]\ttraining's rmse: 0.0859115\tvalid_1's rmse: 0.0902099\n",
      "[1075]\ttraining's rmse: 0.0858888\tvalid_1's rmse: 0.0902039\n",
      "[1100]\ttraining's rmse: 0.0858687\tvalid_1's rmse: 0.0901975\n",
      "[1125]\ttraining's rmse: 0.0858488\tvalid_1's rmse: 0.0901917\n",
      "[1150]\ttraining's rmse: 0.0858287\tvalid_1's rmse: 0.0901863\n",
      "[1175]\ttraining's rmse: 0.0858105\tvalid_1's rmse: 0.0901829\n",
      "[1200]\ttraining's rmse: 0.085795\tvalid_1's rmse: 0.0901766\n",
      "[1225]\ttraining's rmse: 0.0857784\tvalid_1's rmse: 0.0901718\n",
      "[1250]\ttraining's rmse: 0.0857632\tvalid_1's rmse: 0.0901679\n",
      "[1275]\ttraining's rmse: 0.0857422\tvalid_1's rmse: 0.0901637\n",
      "[1300]\ttraining's rmse: 0.0857287\tvalid_1's rmse: 0.0901587\n",
      "[1325]\ttraining's rmse: 0.085713\tvalid_1's rmse: 0.0901543\n",
      "[1350]\ttraining's rmse: 0.0856975\tvalid_1's rmse: 0.0901514\n",
      "[1375]\ttraining's rmse: 0.085683\tvalid_1's rmse: 0.0901476\n",
      "[1400]\ttraining's rmse: 0.0856703\tvalid_1's rmse: 0.090144\n",
      "[1425]\ttraining's rmse: 0.0856578\tvalid_1's rmse: 0.0901416\n",
      "[1450]\ttraining's rmse: 0.0856445\tvalid_1's rmse: 0.0901397\n",
      "[1475]\ttraining's rmse: 0.0856321\tvalid_1's rmse: 0.0901355\n",
      "[1500]\ttraining's rmse: 0.0856215\tvalid_1's rmse: 0.0901327\n",
      "[1525]\ttraining's rmse: 0.0856079\tvalid_1's rmse: 0.0901297\n",
      "[1550]\ttraining's rmse: 0.0855968\tvalid_1's rmse: 0.0901274\n",
      "[1575]\ttraining's rmse: 0.0855873\tvalid_1's rmse: 0.0901244\n",
      "[1600]\ttraining's rmse: 0.0855781\tvalid_1's rmse: 0.0901213\n",
      "[1625]\ttraining's rmse: 0.0855688\tvalid_1's rmse: 0.0901183\n",
      "[1650]\ttraining's rmse: 0.0855604\tvalid_1's rmse: 0.0901154\n",
      "[1675]\ttraining's rmse: 0.0855547\tvalid_1's rmse: 0.0901135\n",
      "[1700]\ttraining's rmse: 0.0855466\tvalid_1's rmse: 0.0901107\n",
      "[1725]\ttraining's rmse: 0.0855395\tvalid_1's rmse: 0.0901089\n",
      "[1750]\ttraining's rmse: 0.0855302\tvalid_1's rmse: 0.0901064\n",
      "[1775]\ttraining's rmse: 0.0855222\tvalid_1's rmse: 0.0901049\n",
      "[1800]\ttraining's rmse: 0.0855151\tvalid_1's rmse: 0.0901028\n",
      "[1825]\ttraining's rmse: 0.0855091\tvalid_1's rmse: 0.0901016\n",
      "[1850]\ttraining's rmse: 0.0855038\tvalid_1's rmse: 0.0900989\n",
      "[1875]\ttraining's rmse: 0.0854992\tvalid_1's rmse: 0.0900987\n",
      "[1900]\ttraining's rmse: 0.0854939\tvalid_1's rmse: 0.0900968\n",
      "[1925]\ttraining's rmse: 0.0854891\tvalid_1's rmse: 0.0900963\n",
      "[1950]\ttraining's rmse: 0.0854837\tvalid_1's rmse: 0.0900936\n",
      "[1975]\ttraining's rmse: 0.0854792\tvalid_1's rmse: 0.0900917\n",
      "[2000]\ttraining's rmse: 0.0854731\tvalid_1's rmse: 0.090091\n",
      "[2025]\ttraining's rmse: 0.0854694\tvalid_1's rmse: 0.0900886\n",
      "[2050]\ttraining's rmse: 0.0854662\tvalid_1's rmse: 0.090087\n",
      "[2075]\ttraining's rmse: 0.0854629\tvalid_1's rmse: 0.0900856\n",
      "[2100]\ttraining's rmse: 0.085459\tvalid_1's rmse: 0.0900845\n",
      "[2125]\ttraining's rmse: 0.0854556\tvalid_1's rmse: 0.0900839\n",
      "[2150]\ttraining's rmse: 0.0854524\tvalid_1's rmse: 0.0900835\n",
      "[2175]\ttraining's rmse: 0.0854486\tvalid_1's rmse: 0.0900826\n",
      "[2200]\ttraining's rmse: 0.0854456\tvalid_1's rmse: 0.0900816\n",
      "[2225]\ttraining's rmse: 0.0854425\tvalid_1's rmse: 0.0900809\n",
      "[2250]\ttraining's rmse: 0.08544\tvalid_1's rmse: 0.0900799\n",
      "[2275]\ttraining's rmse: 0.085437\tvalid_1's rmse: 0.0900792\n",
      "[2300]\ttraining's rmse: 0.0854332\tvalid_1's rmse: 0.090078\n",
      "[2325]\ttraining's rmse: 0.0854305\tvalid_1's rmse: 0.0900767\n",
      "[2350]\ttraining's rmse: 0.0854271\tvalid_1's rmse: 0.0900749\n",
      "[2375]\ttraining's rmse: 0.0854241\tvalid_1's rmse: 0.0900735\n",
      "[2400]\ttraining's rmse: 0.0854195\tvalid_1's rmse: 0.0900724\n",
      "[2425]\ttraining's rmse: 0.0854148\tvalid_1's rmse: 0.0900714\n",
      "[2450]\ttraining's rmse: 0.0854112\tvalid_1's rmse: 0.0900711\n",
      "[2475]\ttraining's rmse: 0.0854087\tvalid_1's rmse: 0.0900711\n",
      "[2500]\ttraining's rmse: 0.0854065\tvalid_1's rmse: 0.0900708\n",
      "[2525]\ttraining's rmse: 0.0854042\tvalid_1's rmse: 0.0900702\n",
      "[2550]\ttraining's rmse: 0.0854007\tvalid_1's rmse: 0.0900691\n",
      "[2575]\ttraining's rmse: 0.0853971\tvalid_1's rmse: 0.0900673\n",
      "[2600]\ttraining's rmse: 0.0853942\tvalid_1's rmse: 0.0900671\n",
      "[2625]\ttraining's rmse: 0.085392\tvalid_1's rmse: 0.0900665\n",
      "[2650]\ttraining's rmse: 0.0853897\tvalid_1's rmse: 0.0900656\n",
      "[2675]\ttraining's rmse: 0.0853871\tvalid_1's rmse: 0.0900651\n",
      "[2700]\ttraining's rmse: 0.0853849\tvalid_1's rmse: 0.0900648\n",
      "[2725]\ttraining's rmse: 0.0853817\tvalid_1's rmse: 0.0900642\n",
      "[2750]\ttraining's rmse: 0.0853795\tvalid_1's rmse: 0.0900629\n",
      "[2775]\ttraining's rmse: 0.0853786\tvalid_1's rmse: 0.090063\n",
      "[2800]\ttraining's rmse: 0.0853756\tvalid_1's rmse: 0.0900625\n",
      "[2825]\ttraining's rmse: 0.0853739\tvalid_1's rmse: 0.0900622\n",
      "[2850]\ttraining's rmse: 0.0853724\tvalid_1's rmse: 0.0900623\n",
      "[2875]\ttraining's rmse: 0.0853703\tvalid_1's rmse: 0.0900623\n",
      "[2900]\ttraining's rmse: 0.0853674\tvalid_1's rmse: 0.090062\n",
      "[2925]\ttraining's rmse: 0.0853663\tvalid_1's rmse: 0.0900616\n",
      "[2950]\ttraining's rmse: 0.0853645\tvalid_1's rmse: 0.0900618\n",
      "Early stopping, best iteration is:\n",
      "[2917]\ttraining's rmse: 0.0853666\tvalid_1's rmse: 0.0900615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0884839\tvalid_1's rmse: 0.0910485\n",
      "[50]\ttraining's rmse: 0.0883504\tvalid_1's rmse: 0.0909921\n",
      "[75]\ttraining's rmse: 0.0882164\tvalid_1's rmse: 0.0909371\n",
      "[100]\ttraining's rmse: 0.0880938\tvalid_1's rmse: 0.0908886\n",
      "[125]\ttraining's rmse: 0.0879645\tvalid_1's rmse: 0.0908384\n",
      "[150]\ttraining's rmse: 0.0878467\tvalid_1's rmse: 0.0907934\n",
      "[175]\ttraining's rmse: 0.0877494\tvalid_1's rmse: 0.0907568\n",
      "[200]\ttraining's rmse: 0.0876435\tvalid_1's rmse: 0.0907189\n",
      "[225]\ttraining's rmse: 0.0875424\tvalid_1's rmse: 0.0906841\n",
      "[250]\ttraining's rmse: 0.0874564\tvalid_1's rmse: 0.0906521\n",
      "[275]\ttraining's rmse: 0.0873769\tvalid_1's rmse: 0.090622\n",
      "[300]\ttraining's rmse: 0.0872954\tvalid_1's rmse: 0.0905942\n",
      "[325]\ttraining's rmse: 0.0872152\tvalid_1's rmse: 0.0905689\n",
      "[350]\ttraining's rmse: 0.0871392\tvalid_1's rmse: 0.0905451\n",
      "[375]\ttraining's rmse: 0.0870776\tvalid_1's rmse: 0.0905237\n",
      "[400]\ttraining's rmse: 0.087011\tvalid_1's rmse: 0.0905035\n",
      "[425]\ttraining's rmse: 0.0869478\tvalid_1's rmse: 0.0904837\n",
      "[450]\ttraining's rmse: 0.0868874\tvalid_1's rmse: 0.0904641\n",
      "[475]\ttraining's rmse: 0.0868332\tvalid_1's rmse: 0.0904469\n",
      "[500]\ttraining's rmse: 0.0867856\tvalid_1's rmse: 0.09043\n",
      "[525]\ttraining's rmse: 0.0867252\tvalid_1's rmse: 0.0904124\n",
      "[550]\ttraining's rmse: 0.0866704\tvalid_1's rmse: 0.0903974\n",
      "[575]\ttraining's rmse: 0.0866205\tvalid_1's rmse: 0.0903832\n",
      "[600]\ttraining's rmse: 0.0865722\tvalid_1's rmse: 0.0903702\n",
      "[625]\ttraining's rmse: 0.0865337\tvalid_1's rmse: 0.0903586\n",
      "[650]\ttraining's rmse: 0.0864858\tvalid_1's rmse: 0.0903462\n",
      "[675]\ttraining's rmse: 0.0864358\tvalid_1's rmse: 0.0903348\n",
      "[700]\ttraining's rmse: 0.086394\tvalid_1's rmse: 0.0903239\n",
      "[725]\ttraining's rmse: 0.0863563\tvalid_1's rmse: 0.0903146\n",
      "[750]\ttraining's rmse: 0.0863208\tvalid_1's rmse: 0.0903059\n",
      "[775]\ttraining's rmse: 0.0862871\tvalid_1's rmse: 0.0902972\n",
      "[800]\ttraining's rmse: 0.0862481\tvalid_1's rmse: 0.090289\n",
      "[825]\ttraining's rmse: 0.0862144\tvalid_1's rmse: 0.0902809\n",
      "[850]\ttraining's rmse: 0.0861801\tvalid_1's rmse: 0.0902747\n",
      "[875]\ttraining's rmse: 0.0861525\tvalid_1's rmse: 0.090268\n",
      "[900]\ttraining's rmse: 0.0861189\tvalid_1's rmse: 0.0902604\n",
      "[925]\ttraining's rmse: 0.0860884\tvalid_1's rmse: 0.0902546\n",
      "[950]\ttraining's rmse: 0.0860629\tvalid_1's rmse: 0.0902495\n",
      "[975]\ttraining's rmse: 0.0860374\tvalid_1's rmse: 0.0902441\n",
      "[1000]\ttraining's rmse: 0.0860122\tvalid_1's rmse: 0.090239\n",
      "[1025]\ttraining's rmse: 0.0859851\tvalid_1's rmse: 0.0902353\n",
      "[1050]\ttraining's rmse: 0.0859617\tvalid_1's rmse: 0.0902297\n",
      "[1075]\ttraining's rmse: 0.0859405\tvalid_1's rmse: 0.0902258\n",
      "[1100]\ttraining's rmse: 0.0859214\tvalid_1's rmse: 0.090222\n",
      "[1125]\ttraining's rmse: 0.0859015\tvalid_1's rmse: 0.0902188\n",
      "[1150]\ttraining's rmse: 0.0858795\tvalid_1's rmse: 0.0902154\n",
      "[1175]\ttraining's rmse: 0.0858614\tvalid_1's rmse: 0.0902121\n",
      "[1200]\ttraining's rmse: 0.0858434\tvalid_1's rmse: 0.0902095\n",
      "[1225]\ttraining's rmse: 0.085828\tvalid_1's rmse: 0.0902072\n",
      "[1250]\ttraining's rmse: 0.085813\tvalid_1's rmse: 0.090205\n",
      "[1275]\ttraining's rmse: 0.0857941\tvalid_1's rmse: 0.0902026\n",
      "[1300]\ttraining's rmse: 0.0857792\tvalid_1's rmse: 0.0902001\n",
      "[1325]\ttraining's rmse: 0.0857626\tvalid_1's rmse: 0.0901976\n",
      "[1350]\ttraining's rmse: 0.0857453\tvalid_1's rmse: 0.090196\n",
      "[1375]\ttraining's rmse: 0.0857303\tvalid_1's rmse: 0.0901949\n",
      "[1400]\ttraining's rmse: 0.0857192\tvalid_1's rmse: 0.0901935\n",
      "[1425]\ttraining's rmse: 0.0857048\tvalid_1's rmse: 0.0901923\n",
      "[1450]\ttraining's rmse: 0.0856915\tvalid_1's rmse: 0.0901909\n",
      "[1475]\ttraining's rmse: 0.0856812\tvalid_1's rmse: 0.0901897\n",
      "[1500]\ttraining's rmse: 0.0856714\tvalid_1's rmse: 0.0901877\n",
      "[1525]\ttraining's rmse: 0.0856594\tvalid_1's rmse: 0.0901874\n",
      "[1550]\ttraining's rmse: 0.0856503\tvalid_1's rmse: 0.0901862\n",
      "[1575]\ttraining's rmse: 0.0856405\tvalid_1's rmse: 0.0901842\n",
      "[1600]\ttraining's rmse: 0.0856314\tvalid_1's rmse: 0.090184\n",
      "[1625]\ttraining's rmse: 0.0856218\tvalid_1's rmse: 0.0901831\n",
      "[1650]\ttraining's rmse: 0.0856133\tvalid_1's rmse: 0.0901819\n",
      "[1675]\ttraining's rmse: 0.0856059\tvalid_1's rmse: 0.0901809\n",
      "[1700]\ttraining's rmse: 0.0856005\tvalid_1's rmse: 0.0901799\n",
      "[1725]\ttraining's rmse: 0.0855938\tvalid_1's rmse: 0.0901791\n",
      "[1750]\ttraining's rmse: 0.0855858\tvalid_1's rmse: 0.0901782\n",
      "[1775]\ttraining's rmse: 0.0855786\tvalid_1's rmse: 0.0901777\n",
      "[1800]\ttraining's rmse: 0.0855707\tvalid_1's rmse: 0.0901772\n",
      "[1825]\ttraining's rmse: 0.0855628\tvalid_1's rmse: 0.0901761\n",
      "[1850]\ttraining's rmse: 0.0855547\tvalid_1's rmse: 0.0901759\n",
      "[1875]\ttraining's rmse: 0.0855484\tvalid_1's rmse: 0.0901754\n",
      "[1900]\ttraining's rmse: 0.0855429\tvalid_1's rmse: 0.090175\n",
      "[1925]\ttraining's rmse: 0.0855375\tvalid_1's rmse: 0.0901746\n",
      "[1950]\ttraining's rmse: 0.0855332\tvalid_1's rmse: 0.0901744\n",
      "[1975]\ttraining's rmse: 0.0855288\tvalid_1's rmse: 0.0901739\n",
      "[2000]\ttraining's rmse: 0.0855237\tvalid_1's rmse: 0.0901733\n",
      "[2025]\ttraining's rmse: 0.0855185\tvalid_1's rmse: 0.0901728\n",
      "[2050]\ttraining's rmse: 0.0855139\tvalid_1's rmse: 0.0901724\n",
      "[2075]\ttraining's rmse: 0.0855094\tvalid_1's rmse: 0.0901726\n",
      "[2100]\ttraining's rmse: 0.0855059\tvalid_1's rmse: 0.0901721\n",
      "[2125]\ttraining's rmse: 0.0855004\tvalid_1's rmse: 0.0901721\n",
      "[2150]\ttraining's rmse: 0.0854966\tvalid_1's rmse: 0.090172\n",
      "[2175]\ttraining's rmse: 0.0854933\tvalid_1's rmse: 0.0901719\n",
      "[2200]\ttraining's rmse: 0.0854901\tvalid_1's rmse: 0.0901719\n",
      "[2225]\ttraining's rmse: 0.0854882\tvalid_1's rmse: 0.0901719\n",
      "[2250]\ttraining's rmse: 0.0854835\tvalid_1's rmse: 0.0901714\n",
      "[2275]\ttraining's rmse: 0.0854801\tvalid_1's rmse: 0.0901713\n",
      "[2300]\ttraining's rmse: 0.0854762\tvalid_1's rmse: 0.0901714\n",
      "[2325]\ttraining's rmse: 0.0854719\tvalid_1's rmse: 0.0901714\n",
      "[2350]\ttraining's rmse: 0.0854681\tvalid_1's rmse: 0.090171\n",
      "[2375]\ttraining's rmse: 0.085465\tvalid_1's rmse: 0.0901709\n",
      "[2400]\ttraining's rmse: 0.0854622\tvalid_1's rmse: 0.0901709\n",
      "[2425]\ttraining's rmse: 0.085459\tvalid_1's rmse: 0.0901707\n",
      "[2450]\ttraining's rmse: 0.0854563\tvalid_1's rmse: 0.0901705\n",
      "[2475]\ttraining's rmse: 0.0854532\tvalid_1's rmse: 0.0901707\n",
      "[2500]\ttraining's rmse: 0.0854496\tvalid_1's rmse: 0.0901706\n",
      "Early stopping, best iteration is:\n",
      "[2460]\ttraining's rmse: 0.0854544\tvalid_1's rmse: 0.0901703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0909391\tvalid_1's rmse: 0.0860744\n",
      "[50]\ttraining's rmse: 0.0908176\tvalid_1's rmse: 0.0860254\n",
      "[75]\ttraining's rmse: 0.0906969\tvalid_1's rmse: 0.085976\n",
      "[100]\ttraining's rmse: 0.0905828\tvalid_1's rmse: 0.0859336\n",
      "[125]\ttraining's rmse: 0.0904665\tvalid_1's rmse: 0.0858888\n",
      "[150]\ttraining's rmse: 0.090359\tvalid_1's rmse: 0.0858502\n",
      "[175]\ttraining's rmse: 0.0902729\tvalid_1's rmse: 0.0858171\n",
      "[200]\ttraining's rmse: 0.090179\tvalid_1's rmse: 0.0857847\n",
      "[225]\ttraining's rmse: 0.090087\tvalid_1's rmse: 0.0857521\n",
      "[250]\ttraining's rmse: 0.0900074\tvalid_1's rmse: 0.0857246\n",
      "[275]\ttraining's rmse: 0.0899349\tvalid_1's rmse: 0.0856978\n",
      "[300]\ttraining's rmse: 0.0898624\tvalid_1's rmse: 0.0856749\n",
      "[325]\ttraining's rmse: 0.0897909\tvalid_1's rmse: 0.0856528\n",
      "[350]\ttraining's rmse: 0.0897204\tvalid_1's rmse: 0.085629\n",
      "[375]\ttraining's rmse: 0.0896603\tvalid_1's rmse: 0.0856157\n",
      "[400]\ttraining's rmse: 0.0895947\tvalid_1's rmse: 0.0856007\n",
      "[425]\ttraining's rmse: 0.0895344\tvalid_1's rmse: 0.0855881\n",
      "[450]\ttraining's rmse: 0.0894786\tvalid_1's rmse: 0.085573\n",
      "[475]\ttraining's rmse: 0.0894271\tvalid_1's rmse: 0.0855579\n",
      "[500]\ttraining's rmse: 0.0893844\tvalid_1's rmse: 0.0855441\n",
      "[525]\ttraining's rmse: 0.0893251\tvalid_1's rmse: 0.085535\n",
      "[550]\ttraining's rmse: 0.0892747\tvalid_1's rmse: 0.0855225\n",
      "[575]\ttraining's rmse: 0.089225\tvalid_1's rmse: 0.0855195\n",
      "[600]\ttraining's rmse: 0.0891785\tvalid_1's rmse: 0.0855143\n",
      "[625]\ttraining's rmse: 0.08914\tvalid_1's rmse: 0.0855039\n",
      "[650]\ttraining's rmse: 0.0890922\tvalid_1's rmse: 0.0854994\n",
      "[675]\ttraining's rmse: 0.0890439\tvalid_1's rmse: 0.0855046\n",
      "[700]\ttraining's rmse: 0.0890017\tvalid_1's rmse: 0.0855023\n",
      "Early stopping, best iteration is:\n",
      "[656]\ttraining's rmse: 0.0890806\tvalid_1's rmse: 0.0854973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0915424\tvalid_1's rmse: 0.0934764\n",
      "[50]\ttraining's rmse: 0.0913488\tvalid_1's rmse: 0.0934235\n",
      "[75]\ttraining's rmse: 0.0911597\tvalid_1's rmse: 0.0933677\n",
      "[100]\ttraining's rmse: 0.0909794\tvalid_1's rmse: 0.0933213\n",
      "[125]\ttraining's rmse: 0.0908094\tvalid_1's rmse: 0.0932722\n",
      "[150]\ttraining's rmse: 0.0906471\tvalid_1's rmse: 0.0932284\n",
      "[175]\ttraining's rmse: 0.0905099\tvalid_1's rmse: 0.0931907\n",
      "[200]\ttraining's rmse: 0.0903704\tvalid_1's rmse: 0.0931543\n",
      "[225]\ttraining's rmse: 0.0902354\tvalid_1's rmse: 0.0931201\n",
      "[250]\ttraining's rmse: 0.0901197\tvalid_1's rmse: 0.093086\n",
      "[275]\ttraining's rmse: 0.0900122\tvalid_1's rmse: 0.0930561\n",
      "[300]\ttraining's rmse: 0.0899023\tvalid_1's rmse: 0.0930273\n",
      "[325]\ttraining's rmse: 0.0898011\tvalid_1's rmse: 0.0929996\n",
      "[350]\ttraining's rmse: 0.089698\tvalid_1's rmse: 0.0929734\n",
      "[375]\ttraining's rmse: 0.0896112\tvalid_1's rmse: 0.092955\n",
      "[400]\ttraining's rmse: 0.0895162\tvalid_1's rmse: 0.0929319\n",
      "[425]\ttraining's rmse: 0.0894339\tvalid_1's rmse: 0.09291\n",
      "[450]\ttraining's rmse: 0.0893583\tvalid_1's rmse: 0.0928892\n",
      "[475]\ttraining's rmse: 0.0892883\tvalid_1's rmse: 0.0928694\n",
      "[500]\ttraining's rmse: 0.0892248\tvalid_1's rmse: 0.0928511\n",
      "[525]\ttraining's rmse: 0.0891492\tvalid_1's rmse: 0.0928336\n",
      "[550]\ttraining's rmse: 0.0890847\tvalid_1's rmse: 0.0928173\n",
      "[575]\ttraining's rmse: 0.0890235\tvalid_1's rmse: 0.0928041\n",
      "[600]\ttraining's rmse: 0.088963\tvalid_1's rmse: 0.0927884\n",
      "[625]\ttraining's rmse: 0.0889156\tvalid_1's rmse: 0.0927743\n",
      "[650]\ttraining's rmse: 0.0888583\tvalid_1's rmse: 0.09276\n",
      "[675]\ttraining's rmse: 0.0888037\tvalid_1's rmse: 0.0927465\n",
      "[700]\ttraining's rmse: 0.0887562\tvalid_1's rmse: 0.0927359\n",
      "[725]\ttraining's rmse: 0.0887121\tvalid_1's rmse: 0.092725\n",
      "[750]\ttraining's rmse: 0.0886716\tvalid_1's rmse: 0.0927142\n",
      "[775]\ttraining's rmse: 0.0886383\tvalid_1's rmse: 0.0927052\n",
      "[800]\ttraining's rmse: 0.0885904\tvalid_1's rmse: 0.0926953\n",
      "[825]\ttraining's rmse: 0.0885546\tvalid_1's rmse: 0.0926864\n",
      "[850]\ttraining's rmse: 0.088515\tvalid_1's rmse: 0.0926779\n",
      "[875]\ttraining's rmse: 0.0884808\tvalid_1's rmse: 0.0926691\n",
      "[900]\ttraining's rmse: 0.0884413\tvalid_1's rmse: 0.0926615\n",
      "[925]\ttraining's rmse: 0.0884095\tvalid_1's rmse: 0.0926536\n",
      "[950]\ttraining's rmse: 0.0883768\tvalid_1's rmse: 0.0926447\n",
      "[975]\ttraining's rmse: 0.0883479\tvalid_1's rmse: 0.0926377\n",
      "[1000]\ttraining's rmse: 0.0883209\tvalid_1's rmse: 0.0926315\n",
      "[1025]\ttraining's rmse: 0.0882905\tvalid_1's rmse: 0.0926244\n",
      "[1050]\ttraining's rmse: 0.0882641\tvalid_1's rmse: 0.092617\n",
      "[1075]\ttraining's rmse: 0.0882391\tvalid_1's rmse: 0.0926118\n",
      "[1100]\ttraining's rmse: 0.0882146\tvalid_1's rmse: 0.0926065\n",
      "[1125]\ttraining's rmse: 0.0881913\tvalid_1's rmse: 0.0926009\n",
      "[1150]\ttraining's rmse: 0.0881698\tvalid_1's rmse: 0.0925964\n",
      "[1175]\ttraining's rmse: 0.0881507\tvalid_1's rmse: 0.0925917\n",
      "[1200]\ttraining's rmse: 0.0881306\tvalid_1's rmse: 0.092587\n",
      "[1225]\ttraining's rmse: 0.0881109\tvalid_1's rmse: 0.0925815\n",
      "[1250]\ttraining's rmse: 0.0880928\tvalid_1's rmse: 0.0925769\n",
      "[1275]\ttraining's rmse: 0.0880693\tvalid_1's rmse: 0.0925731\n",
      "[1300]\ttraining's rmse: 0.0880527\tvalid_1's rmse: 0.0925685\n",
      "[1325]\ttraining's rmse: 0.0880347\tvalid_1's rmse: 0.0925637\n",
      "[1350]\ttraining's rmse: 0.0880175\tvalid_1's rmse: 0.0925609\n",
      "[1375]\ttraining's rmse: 0.0879992\tvalid_1's rmse: 0.092558\n",
      "[1400]\ttraining's rmse: 0.0879856\tvalid_1's rmse: 0.0925536\n",
      "[1425]\ttraining's rmse: 0.0879684\tvalid_1's rmse: 0.0925498\n",
      "[1450]\ttraining's rmse: 0.0879541\tvalid_1's rmse: 0.092546\n",
      "[1475]\ttraining's rmse: 0.0879409\tvalid_1's rmse: 0.0925428\n",
      "[1500]\ttraining's rmse: 0.0879285\tvalid_1's rmse: 0.0925396\n",
      "[1525]\ttraining's rmse: 0.0879186\tvalid_1's rmse: 0.0925365\n",
      "[1550]\ttraining's rmse: 0.0879059\tvalid_1's rmse: 0.0925334\n",
      "[1575]\ttraining's rmse: 0.0878961\tvalid_1's rmse: 0.0925293\n",
      "[1600]\ttraining's rmse: 0.0878874\tvalid_1's rmse: 0.0925252\n",
      "[1625]\ttraining's rmse: 0.0878751\tvalid_1's rmse: 0.0925208\n",
      "[1650]\ttraining's rmse: 0.0878651\tvalid_1's rmse: 0.0925179\n",
      "[1675]\ttraining's rmse: 0.087857\tvalid_1's rmse: 0.0925164\n",
      "[1700]\ttraining's rmse: 0.0878491\tvalid_1's rmse: 0.092514\n",
      "[1725]\ttraining's rmse: 0.0878398\tvalid_1's rmse: 0.0925128\n",
      "[1750]\ttraining's rmse: 0.0878308\tvalid_1's rmse: 0.0925102\n",
      "[1775]\ttraining's rmse: 0.0878237\tvalid_1's rmse: 0.0925083\n",
      "[1800]\ttraining's rmse: 0.0878126\tvalid_1's rmse: 0.0925063\n",
      "[1825]\ttraining's rmse: 0.087807\tvalid_1's rmse: 0.0925048\n",
      "[1850]\ttraining's rmse: 0.0878007\tvalid_1's rmse: 0.0925027\n",
      "[1875]\ttraining's rmse: 0.087795\tvalid_1's rmse: 0.0925019\n",
      "[1900]\ttraining's rmse: 0.0877894\tvalid_1's rmse: 0.0925007\n",
      "[1925]\ttraining's rmse: 0.0877835\tvalid_1's rmse: 0.0924992\n",
      "[1950]\ttraining's rmse: 0.0877787\tvalid_1's rmse: 0.0924968\n",
      "[1975]\ttraining's rmse: 0.0877741\tvalid_1's rmse: 0.0924951\n",
      "[2000]\ttraining's rmse: 0.0877697\tvalid_1's rmse: 0.0924937\n",
      "[2025]\ttraining's rmse: 0.0877652\tvalid_1's rmse: 0.0924914\n",
      "[2050]\ttraining's rmse: 0.0877613\tvalid_1's rmse: 0.0924898\n",
      "[2075]\ttraining's rmse: 0.0877569\tvalid_1's rmse: 0.0924881\n",
      "[2100]\ttraining's rmse: 0.0877533\tvalid_1's rmse: 0.0924869\n",
      "[2125]\ttraining's rmse: 0.0877491\tvalid_1's rmse: 0.0924854\n",
      "[2150]\ttraining's rmse: 0.0877446\tvalid_1's rmse: 0.0924842\n",
      "[2175]\ttraining's rmse: 0.0877409\tvalid_1's rmse: 0.0924828\n",
      "[2200]\ttraining's rmse: 0.087736\tvalid_1's rmse: 0.0924819\n",
      "[2225]\ttraining's rmse: 0.0877331\tvalid_1's rmse: 0.0924816\n",
      "[2250]\ttraining's rmse: 0.0877289\tvalid_1's rmse: 0.0924808\n",
      "[2275]\ttraining's rmse: 0.0877253\tvalid_1's rmse: 0.0924801\n",
      "[2300]\ttraining's rmse: 0.0877218\tvalid_1's rmse: 0.0924796\n",
      "[2325]\ttraining's rmse: 0.087718\tvalid_1's rmse: 0.0924784\n",
      "[2350]\ttraining's rmse: 0.0877149\tvalid_1's rmse: 0.0924769\n",
      "[2375]\ttraining's rmse: 0.0877112\tvalid_1's rmse: 0.0924758\n",
      "[2400]\ttraining's rmse: 0.0877064\tvalid_1's rmse: 0.0924746\n",
      "[2425]\ttraining's rmse: 0.0877033\tvalid_1's rmse: 0.0924735\n",
      "[2450]\ttraining's rmse: 0.0877008\tvalid_1's rmse: 0.0924728\n",
      "[2475]\ttraining's rmse: 0.0876972\tvalid_1's rmse: 0.0924724\n",
      "[2500]\ttraining's rmse: 0.0876957\tvalid_1's rmse: 0.0924721\n",
      "[2525]\ttraining's rmse: 0.0876923\tvalid_1's rmse: 0.0924714\n",
      "[2550]\ttraining's rmse: 0.0876898\tvalid_1's rmse: 0.0924705\n",
      "[2575]\ttraining's rmse: 0.087688\tvalid_1's rmse: 0.0924703\n",
      "[2600]\ttraining's rmse: 0.0876854\tvalid_1's rmse: 0.0924694\n",
      "[2625]\ttraining's rmse: 0.0876843\tvalid_1's rmse: 0.0924692\n",
      "[2650]\ttraining's rmse: 0.0876825\tvalid_1's rmse: 0.0924685\n",
      "[2675]\ttraining's rmse: 0.087679\tvalid_1's rmse: 0.0924678\n",
      "[2700]\ttraining's rmse: 0.0876771\tvalid_1's rmse: 0.0924669\n",
      "[2725]\ttraining's rmse: 0.0876743\tvalid_1's rmse: 0.0924669\n",
      "[2750]\ttraining's rmse: 0.087671\tvalid_1's rmse: 0.092466\n",
      "[2775]\ttraining's rmse: 0.0876684\tvalid_1's rmse: 0.0924652\n",
      "[2800]\ttraining's rmse: 0.0876664\tvalid_1's rmse: 0.0924651\n",
      "[2825]\ttraining's rmse: 0.0876648\tvalid_1's rmse: 0.092465\n",
      "[2850]\ttraining's rmse: 0.0876627\tvalid_1's rmse: 0.0924647\n",
      "[2875]\ttraining's rmse: 0.0876605\tvalid_1's rmse: 0.0924649\n",
      "[2900]\ttraining's rmse: 0.0876581\tvalid_1's rmse: 0.0924642\n",
      "[2925]\ttraining's rmse: 0.0876572\tvalid_1's rmse: 0.092464\n",
      "[2950]\ttraining's rmse: 0.0876547\tvalid_1's rmse: 0.0924641\n",
      "[2975]\ttraining's rmse: 0.0876532\tvalid_1's rmse: 0.092464\n",
      "[3000]\ttraining's rmse: 0.0876504\tvalid_1's rmse: 0.0924638\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0876504\tvalid_1's rmse: 0.0924638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0915539\tvalid_1's rmse: 0.0934714\n",
      "[50]\ttraining's rmse: 0.0913749\tvalid_1's rmse: 0.0934139\n",
      "[75]\ttraining's rmse: 0.091198\tvalid_1's rmse: 0.0933591\n",
      "[100]\ttraining's rmse: 0.0910393\tvalid_1's rmse: 0.0933097\n",
      "[125]\ttraining's rmse: 0.0908728\tvalid_1's rmse: 0.0932587\n",
      "[150]\ttraining's rmse: 0.0907213\tvalid_1's rmse: 0.0932101\n",
      "[175]\ttraining's rmse: 0.0905958\tvalid_1's rmse: 0.0931731\n",
      "[200]\ttraining's rmse: 0.0904629\tvalid_1's rmse: 0.0931343\n",
      "[225]\ttraining's rmse: 0.0903347\tvalid_1's rmse: 0.0930989\n",
      "[250]\ttraining's rmse: 0.090224\tvalid_1's rmse: 0.0930665\n",
      "[275]\ttraining's rmse: 0.0901195\tvalid_1's rmse: 0.0930381\n",
      "[300]\ttraining's rmse: 0.0900195\tvalid_1's rmse: 0.0930095\n",
      "[325]\ttraining's rmse: 0.0899236\tvalid_1's rmse: 0.0929833\n",
      "[350]\ttraining's rmse: 0.0898275\tvalid_1's rmse: 0.092958\n",
      "[375]\ttraining's rmse: 0.0897519\tvalid_1's rmse: 0.0929374\n",
      "[400]\ttraining's rmse: 0.0896725\tvalid_1's rmse: 0.0929177\n",
      "[425]\ttraining's rmse: 0.0895979\tvalid_1's rmse: 0.092897\n",
      "[450]\ttraining's rmse: 0.0895281\tvalid_1's rmse: 0.092879\n",
      "[475]\ttraining's rmse: 0.0894629\tvalid_1's rmse: 0.092861\n",
      "[500]\ttraining's rmse: 0.0894082\tvalid_1's rmse: 0.0928449\n",
      "[525]\ttraining's rmse: 0.0893378\tvalid_1's rmse: 0.0928283\n",
      "[550]\ttraining's rmse: 0.0892738\tvalid_1's rmse: 0.0928132\n",
      "[575]\ttraining's rmse: 0.0892171\tvalid_1's rmse: 0.0928002\n",
      "[600]\ttraining's rmse: 0.0891613\tvalid_1's rmse: 0.0927874\n",
      "[625]\ttraining's rmse: 0.0891156\tvalid_1's rmse: 0.092775\n",
      "[650]\ttraining's rmse: 0.0890609\tvalid_1's rmse: 0.0927625\n",
      "[675]\ttraining's rmse: 0.0890086\tvalid_1's rmse: 0.0927527\n",
      "[700]\ttraining's rmse: 0.0889624\tvalid_1's rmse: 0.0927426\n",
      "[725]\ttraining's rmse: 0.0889206\tvalid_1's rmse: 0.0927338\n",
      "[750]\ttraining's rmse: 0.0888798\tvalid_1's rmse: 0.092725\n",
      "[775]\ttraining's rmse: 0.0888447\tvalid_1's rmse: 0.092716\n",
      "[800]\ttraining's rmse: 0.0888009\tvalid_1's rmse: 0.0927092\n",
      "[825]\ttraining's rmse: 0.0887652\tvalid_1's rmse: 0.0927023\n",
      "[850]\ttraining's rmse: 0.0887301\tvalid_1's rmse: 0.0926957\n",
      "[875]\ttraining's rmse: 0.0886968\tvalid_1's rmse: 0.0926906\n",
      "[900]\ttraining's rmse: 0.0886616\tvalid_1's rmse: 0.0926831\n",
      "[925]\ttraining's rmse: 0.0886312\tvalid_1's rmse: 0.0926774\n",
      "[950]\ttraining's rmse: 0.0886009\tvalid_1's rmse: 0.0926724\n",
      "[975]\ttraining's rmse: 0.0885717\tvalid_1's rmse: 0.0926668\n",
      "[1000]\ttraining's rmse: 0.0885457\tvalid_1's rmse: 0.0926627\n",
      "[1025]\ttraining's rmse: 0.0885154\tvalid_1's rmse: 0.0926582\n",
      "[1050]\ttraining's rmse: 0.0884912\tvalid_1's rmse: 0.0926549\n",
      "[1075]\ttraining's rmse: 0.0884618\tvalid_1's rmse: 0.0926511\n",
      "[1100]\ttraining's rmse: 0.0884409\tvalid_1's rmse: 0.0926466\n",
      "[1125]\ttraining's rmse: 0.088419\tvalid_1's rmse: 0.0926432\n",
      "[1150]\ttraining's rmse: 0.0883948\tvalid_1's rmse: 0.0926401\n",
      "[1175]\ttraining's rmse: 0.0883724\tvalid_1's rmse: 0.0926381\n",
      "[1200]\ttraining's rmse: 0.0883508\tvalid_1's rmse: 0.092634\n",
      "[1225]\ttraining's rmse: 0.0883293\tvalid_1's rmse: 0.0926319\n",
      "[1250]\ttraining's rmse: 0.0883106\tvalid_1's rmse: 0.0926289\n",
      "[1275]\ttraining's rmse: 0.0882875\tvalid_1's rmse: 0.0926269\n",
      "[1300]\ttraining's rmse: 0.0882712\tvalid_1's rmse: 0.0926249\n",
      "[1325]\ttraining's rmse: 0.088256\tvalid_1's rmse: 0.0926233\n",
      "[1350]\ttraining's rmse: 0.088239\tvalid_1's rmse: 0.0926213\n",
      "[1375]\ttraining's rmse: 0.0882243\tvalid_1's rmse: 0.0926197\n",
      "[1400]\ttraining's rmse: 0.0882101\tvalid_1's rmse: 0.0926178\n",
      "[1425]\ttraining's rmse: 0.0881939\tvalid_1's rmse: 0.0926166\n",
      "[1450]\ttraining's rmse: 0.0881776\tvalid_1's rmse: 0.0926155\n",
      "[1475]\ttraining's rmse: 0.0881656\tvalid_1's rmse: 0.092615\n",
      "[1500]\ttraining's rmse: 0.0881556\tvalid_1's rmse: 0.0926134\n",
      "[1525]\ttraining's rmse: 0.0881413\tvalid_1's rmse: 0.0926122\n",
      "[1550]\ttraining's rmse: 0.0881302\tvalid_1's rmse: 0.0926113\n",
      "[1575]\ttraining's rmse: 0.0881207\tvalid_1's rmse: 0.0926103\n",
      "[1600]\ttraining's rmse: 0.0881097\tvalid_1's rmse: 0.09261\n",
      "[1625]\ttraining's rmse: 0.0880997\tvalid_1's rmse: 0.0926096\n",
      "[1650]\ttraining's rmse: 0.0880887\tvalid_1's rmse: 0.0926097\n",
      "[1675]\ttraining's rmse: 0.0880791\tvalid_1's rmse: 0.0926086\n",
      "[1700]\ttraining's rmse: 0.0880689\tvalid_1's rmse: 0.0926076\n",
      "[1725]\ttraining's rmse: 0.0880608\tvalid_1's rmse: 0.092607\n",
      "[1750]\ttraining's rmse: 0.0880516\tvalid_1's rmse: 0.0926068\n",
      "[1775]\ttraining's rmse: 0.0880447\tvalid_1's rmse: 0.0926067\n",
      "[1800]\ttraining's rmse: 0.0880373\tvalid_1's rmse: 0.0926063\n",
      "[1825]\ttraining's rmse: 0.0880297\tvalid_1's rmse: 0.0926063\n",
      "[1850]\ttraining's rmse: 0.0880238\tvalid_1's rmse: 0.0926056\n",
      "[1875]\ttraining's rmse: 0.0880163\tvalid_1's rmse: 0.0926056\n",
      "[1900]\ttraining's rmse: 0.0880105\tvalid_1's rmse: 0.092606\n",
      "[1925]\ttraining's rmse: 0.0880026\tvalid_1's rmse: 0.0926053\n",
      "[1950]\ttraining's rmse: 0.0879971\tvalid_1's rmse: 0.0926045\n",
      "[1975]\ttraining's rmse: 0.0879915\tvalid_1's rmse: 0.0926044\n",
      "[2000]\ttraining's rmse: 0.0879869\tvalid_1's rmse: 0.0926047\n",
      "[2025]\ttraining's rmse: 0.0879827\tvalid_1's rmse: 0.0926042\n",
      "[2050]\ttraining's rmse: 0.0879785\tvalid_1's rmse: 0.0926044\n",
      "Early stopping, best iteration is:\n",
      "[2009]\ttraining's rmse: 0.0879849\tvalid_1's rmse: 0.092604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0933265\tvalid_1's rmse: 0.0899675\n",
      "[50]\ttraining's rmse: 0.0931898\tvalid_1's rmse: 0.0899164\n",
      "[75]\ttraining's rmse: 0.0930452\tvalid_1's rmse: 0.0898654\n",
      "[100]\ttraining's rmse: 0.0929187\tvalid_1's rmse: 0.0898223\n",
      "[125]\ttraining's rmse: 0.0927859\tvalid_1's rmse: 0.089779\n",
      "[150]\ttraining's rmse: 0.0926628\tvalid_1's rmse: 0.0897406\n",
      "[175]\ttraining's rmse: 0.0925582\tvalid_1's rmse: 0.089708\n",
      "[200]\ttraining's rmse: 0.0924464\tvalid_1's rmse: 0.0896752\n",
      "[225]\ttraining's rmse: 0.0923369\tvalid_1's rmse: 0.0896438\n",
      "[250]\ttraining's rmse: 0.0922448\tvalid_1's rmse: 0.0896157\n",
      "[275]\ttraining's rmse: 0.0921619\tvalid_1's rmse: 0.0895912\n",
      "[300]\ttraining's rmse: 0.0920771\tvalid_1's rmse: 0.0895681\n",
      "[325]\ttraining's rmse: 0.0919901\tvalid_1's rmse: 0.0895443\n",
      "[350]\ttraining's rmse: 0.091907\tvalid_1's rmse: 0.0895217\n",
      "[375]\ttraining's rmse: 0.0918413\tvalid_1's rmse: 0.0895045\n",
      "[400]\ttraining's rmse: 0.0917647\tvalid_1's rmse: 0.0894872\n",
      "[425]\ttraining's rmse: 0.0916968\tvalid_1's rmse: 0.089471\n",
      "[450]\ttraining's rmse: 0.0916312\tvalid_1's rmse: 0.0894564\n",
      "[475]\ttraining's rmse: 0.0915724\tvalid_1's rmse: 0.0894431\n",
      "[500]\ttraining's rmse: 0.0915247\tvalid_1's rmse: 0.0894305\n",
      "[525]\ttraining's rmse: 0.0914578\tvalid_1's rmse: 0.0894163\n",
      "[550]\ttraining's rmse: 0.0913971\tvalid_1's rmse: 0.0894044\n",
      "[575]\ttraining's rmse: 0.091343\tvalid_1's rmse: 0.0893941\n",
      "[600]\ttraining's rmse: 0.0912901\tvalid_1's rmse: 0.0893856\n",
      "[625]\ttraining's rmse: 0.0912461\tvalid_1's rmse: 0.0893772\n",
      "[650]\ttraining's rmse: 0.0911929\tvalid_1's rmse: 0.0893796\n",
      "[675]\ttraining's rmse: 0.0911387\tvalid_1's rmse: 0.0893769\n",
      "[700]\ttraining's rmse: 0.0910925\tvalid_1's rmse: 0.08937\n",
      "[725]\ttraining's rmse: 0.0910501\tvalid_1's rmse: 0.0893753\n",
      "[750]\ttraining's rmse: 0.0910082\tvalid_1's rmse: 0.0893777\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0910841\tvalid_1's rmse: 0.0893695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0888027\tvalid_1's rmse: 0.0915594\n",
      "[50]\ttraining's rmse: 0.0886593\tvalid_1's rmse: 0.0915011\n",
      "[75]\ttraining's rmse: 0.0885154\tvalid_1's rmse: 0.0914444\n",
      "[100]\ttraining's rmse: 0.0883813\tvalid_1's rmse: 0.0913954\n",
      "[125]\ttraining's rmse: 0.0882518\tvalid_1's rmse: 0.0913441\n",
      "[150]\ttraining's rmse: 0.0881344\tvalid_1's rmse: 0.0912977\n",
      "[175]\ttraining's rmse: 0.0880349\tvalid_1's rmse: 0.0912596\n",
      "[200]\ttraining's rmse: 0.0879298\tvalid_1's rmse: 0.0912205\n",
      "[225]\ttraining's rmse: 0.0878279\tvalid_1's rmse: 0.0911846\n",
      "[250]\ttraining's rmse: 0.0877389\tvalid_1's rmse: 0.0911517\n",
      "[275]\ttraining's rmse: 0.0876514\tvalid_1's rmse: 0.0911208\n",
      "[300]\ttraining's rmse: 0.0875709\tvalid_1's rmse: 0.0910908\n",
      "[325]\ttraining's rmse: 0.0874895\tvalid_1's rmse: 0.0910637\n",
      "[350]\ttraining's rmse: 0.0874129\tvalid_1's rmse: 0.0910374\n",
      "[375]\ttraining's rmse: 0.0873459\tvalid_1's rmse: 0.0910139\n",
      "[400]\ttraining's rmse: 0.0872745\tvalid_1's rmse: 0.0909907\n",
      "[425]\ttraining's rmse: 0.0872118\tvalid_1's rmse: 0.0909686\n",
      "[450]\ttraining's rmse: 0.0871542\tvalid_1's rmse: 0.0909473\n",
      "[475]\ttraining's rmse: 0.0870957\tvalid_1's rmse: 0.090926\n",
      "[500]\ttraining's rmse: 0.0870486\tvalid_1's rmse: 0.0909064\n",
      "[525]\ttraining's rmse: 0.0869887\tvalid_1's rmse: 0.0908871\n",
      "[550]\ttraining's rmse: 0.0869318\tvalid_1's rmse: 0.0908724\n",
      "[575]\ttraining's rmse: 0.0868805\tvalid_1's rmse: 0.0908567\n",
      "[600]\ttraining's rmse: 0.0868323\tvalid_1's rmse: 0.0908437\n",
      "[625]\ttraining's rmse: 0.0867927\tvalid_1's rmse: 0.0908302\n",
      "[650]\ttraining's rmse: 0.0867489\tvalid_1's rmse: 0.090817\n",
      "[675]\ttraining's rmse: 0.0867019\tvalid_1's rmse: 0.0908042\n",
      "[700]\ttraining's rmse: 0.086661\tvalid_1's rmse: 0.0907923\n",
      "[725]\ttraining's rmse: 0.0866203\tvalid_1's rmse: 0.0907799\n",
      "[750]\ttraining's rmse: 0.0865852\tvalid_1's rmse: 0.090769\n",
      "[775]\ttraining's rmse: 0.0865539\tvalid_1's rmse: 0.0907592\n",
      "[800]\ttraining's rmse: 0.0865156\tvalid_1's rmse: 0.0907499\n",
      "[825]\ttraining's rmse: 0.0864862\tvalid_1's rmse: 0.0907406\n",
      "[850]\ttraining's rmse: 0.0864507\tvalid_1's rmse: 0.0907329\n",
      "[875]\ttraining's rmse: 0.0864179\tvalid_1's rmse: 0.0907253\n",
      "[900]\ttraining's rmse: 0.0863865\tvalid_1's rmse: 0.0907162\n",
      "[925]\ttraining's rmse: 0.086358\tvalid_1's rmse: 0.0907089\n",
      "[950]\ttraining's rmse: 0.0863317\tvalid_1's rmse: 0.0907009\n",
      "[975]\ttraining's rmse: 0.0863076\tvalid_1's rmse: 0.0906936\n",
      "[1000]\ttraining's rmse: 0.0862844\tvalid_1's rmse: 0.0906881\n",
      "[1025]\ttraining's rmse: 0.0862562\tvalid_1's rmse: 0.0906819\n",
      "[1050]\ttraining's rmse: 0.0862346\tvalid_1's rmse: 0.0906752\n",
      "[1075]\ttraining's rmse: 0.0862134\tvalid_1's rmse: 0.0906706\n",
      "[1100]\ttraining's rmse: 0.0861957\tvalid_1's rmse: 0.0906658\n",
      "[1125]\ttraining's rmse: 0.0861765\tvalid_1's rmse: 0.0906601\n",
      "[1150]\ttraining's rmse: 0.0861561\tvalid_1's rmse: 0.0906548\n",
      "[1175]\ttraining's rmse: 0.0861353\tvalid_1's rmse: 0.0906508\n",
      "[1200]\ttraining's rmse: 0.0861163\tvalid_1's rmse: 0.0906457\n",
      "[1225]\ttraining's rmse: 0.0860994\tvalid_1's rmse: 0.090641\n",
      "[1250]\ttraining's rmse: 0.0860846\tvalid_1's rmse: 0.0906359\n",
      "[1275]\ttraining's rmse: 0.0860659\tvalid_1's rmse: 0.0906323\n",
      "[1300]\ttraining's rmse: 0.0860521\tvalid_1's rmse: 0.0906274\n",
      "[1325]\ttraining's rmse: 0.0860373\tvalid_1's rmse: 0.0906238\n",
      "[1350]\ttraining's rmse: 0.0860212\tvalid_1's rmse: 0.0906179\n",
      "[1375]\ttraining's rmse: 0.0860057\tvalid_1's rmse: 0.0906141\n",
      "[1400]\ttraining's rmse: 0.0859942\tvalid_1's rmse: 0.0906117\n",
      "[1425]\ttraining's rmse: 0.0859801\tvalid_1's rmse: 0.09061\n",
      "[1450]\ttraining's rmse: 0.0859671\tvalid_1's rmse: 0.0906072\n",
      "[1475]\ttraining's rmse: 0.0859568\tvalid_1's rmse: 0.0906031\n",
      "[1500]\ttraining's rmse: 0.0859468\tvalid_1's rmse: 0.0906004\n",
      "[1525]\ttraining's rmse: 0.085935\tvalid_1's rmse: 0.0905978\n",
      "[1550]\ttraining's rmse: 0.0859238\tvalid_1's rmse: 0.0905964\n",
      "[1575]\ttraining's rmse: 0.0859154\tvalid_1's rmse: 0.0905949\n",
      "[1600]\ttraining's rmse: 0.0859074\tvalid_1's rmse: 0.090593\n",
      "[1625]\ttraining's rmse: 0.0858982\tvalid_1's rmse: 0.0905881\n",
      "[1650]\ttraining's rmse: 0.085891\tvalid_1's rmse: 0.0905855\n",
      "[1675]\ttraining's rmse: 0.0858833\tvalid_1's rmse: 0.0905836\n",
      "[1700]\ttraining's rmse: 0.0858746\tvalid_1's rmse: 0.0905818\n",
      "[1725]\ttraining's rmse: 0.0858671\tvalid_1's rmse: 0.0905803\n",
      "[1750]\ttraining's rmse: 0.0858579\tvalid_1's rmse: 0.0905777\n",
      "[1775]\ttraining's rmse: 0.0858518\tvalid_1's rmse: 0.0905754\n",
      "[1800]\ttraining's rmse: 0.0858439\tvalid_1's rmse: 0.0905725\n",
      "[1825]\ttraining's rmse: 0.0858373\tvalid_1's rmse: 0.0905717\n",
      "[1850]\ttraining's rmse: 0.0858319\tvalid_1's rmse: 0.0905694\n",
      "[1875]\ttraining's rmse: 0.0858249\tvalid_1's rmse: 0.0905677\n",
      "[1900]\ttraining's rmse: 0.0858201\tvalid_1's rmse: 0.0905671\n",
      "[1925]\ttraining's rmse: 0.0858156\tvalid_1's rmse: 0.0905659\n",
      "[1950]\ttraining's rmse: 0.0858117\tvalid_1's rmse: 0.0905643\n",
      "[1975]\ttraining's rmse: 0.0858083\tvalid_1's rmse: 0.0905634\n",
      "[2000]\ttraining's rmse: 0.0858032\tvalid_1's rmse: 0.0905624\n",
      "[2025]\ttraining's rmse: 0.0857977\tvalid_1's rmse: 0.0905614\n",
      "[2050]\ttraining's rmse: 0.0857937\tvalid_1's rmse: 0.0905607\n",
      "[2075]\ttraining's rmse: 0.0857891\tvalid_1's rmse: 0.0905595\n",
      "[2100]\ttraining's rmse: 0.0857865\tvalid_1's rmse: 0.0905591\n",
      "[2125]\ttraining's rmse: 0.0857821\tvalid_1's rmse: 0.0905577\n",
      "[2150]\ttraining's rmse: 0.0857778\tvalid_1's rmse: 0.0905573\n",
      "[2175]\ttraining's rmse: 0.0857747\tvalid_1's rmse: 0.0905553\n",
      "[2200]\ttraining's rmse: 0.085771\tvalid_1's rmse: 0.0905549\n",
      "[2225]\ttraining's rmse: 0.0857674\tvalid_1's rmse: 0.0905545\n",
      "[2250]\ttraining's rmse: 0.0857629\tvalid_1's rmse: 0.0905527\n",
      "[2275]\ttraining's rmse: 0.0857593\tvalid_1's rmse: 0.0905519\n",
      "[2300]\ttraining's rmse: 0.0857559\tvalid_1's rmse: 0.0905511\n",
      "[2325]\ttraining's rmse: 0.0857532\tvalid_1's rmse: 0.0905501\n",
      "[2350]\ttraining's rmse: 0.0857495\tvalid_1's rmse: 0.0905488\n",
      "[2375]\ttraining's rmse: 0.0857447\tvalid_1's rmse: 0.0905481\n",
      "[2400]\ttraining's rmse: 0.0857408\tvalid_1's rmse: 0.090548\n",
      "[2425]\ttraining's rmse: 0.0857381\tvalid_1's rmse: 0.0905474\n",
      "[2450]\ttraining's rmse: 0.085736\tvalid_1's rmse: 0.0905471\n",
      "[2475]\ttraining's rmse: 0.0857331\tvalid_1's rmse: 0.0905461\n",
      "[2500]\ttraining's rmse: 0.0857308\tvalid_1's rmse: 0.0905451\n",
      "[2525]\ttraining's rmse: 0.0857268\tvalid_1's rmse: 0.0905443\n",
      "[2550]\ttraining's rmse: 0.0857241\tvalid_1's rmse: 0.090544\n",
      "[2575]\ttraining's rmse: 0.0857214\tvalid_1's rmse: 0.0905433\n",
      "[2600]\ttraining's rmse: 0.0857196\tvalid_1's rmse: 0.0905427\n",
      "[2625]\ttraining's rmse: 0.085718\tvalid_1's rmse: 0.0905418\n",
      "[2650]\ttraining's rmse: 0.0857159\tvalid_1's rmse: 0.0905413\n",
      "[2675]\ttraining's rmse: 0.0857118\tvalid_1's rmse: 0.0905402\n",
      "[2700]\ttraining's rmse: 0.0857094\tvalid_1's rmse: 0.0905395\n",
      "[2725]\ttraining's rmse: 0.085705\tvalid_1's rmse: 0.0905386\n",
      "[2750]\ttraining's rmse: 0.0857037\tvalid_1's rmse: 0.0905385\n",
      "[2775]\ttraining's rmse: 0.0857017\tvalid_1's rmse: 0.0905381\n",
      "[2800]\ttraining's rmse: 0.0856992\tvalid_1's rmse: 0.090538\n",
      "[2825]\ttraining's rmse: 0.0856975\tvalid_1's rmse: 0.0905373\n",
      "[2850]\ttraining's rmse: 0.0856943\tvalid_1's rmse: 0.090537\n",
      "[2875]\ttraining's rmse: 0.0856927\tvalid_1's rmse: 0.0905367\n",
      "[2900]\ttraining's rmse: 0.0856899\tvalid_1's rmse: 0.0905368\n",
      "[2925]\ttraining's rmse: 0.0856882\tvalid_1's rmse: 0.0905357\n",
      "[2950]\ttraining's rmse: 0.0856859\tvalid_1's rmse: 0.0905352\n",
      "[2975]\ttraining's rmse: 0.0856839\tvalid_1's rmse: 0.0905348\n",
      "[3000]\ttraining's rmse: 0.0856806\tvalid_1's rmse: 0.090534\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0856806\tvalid_1's rmse: 0.090534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0889366\tvalid_1's rmse: 0.0912963\n",
      "[50]\ttraining's rmse: 0.0888028\tvalid_1's rmse: 0.0912389\n",
      "[75]\ttraining's rmse: 0.0886645\tvalid_1's rmse: 0.0911843\n",
      "[100]\ttraining's rmse: 0.0885398\tvalid_1's rmse: 0.0911344\n",
      "[125]\ttraining's rmse: 0.0884135\tvalid_1's rmse: 0.0910844\n",
      "[150]\ttraining's rmse: 0.0882955\tvalid_1's rmse: 0.091038\n",
      "[175]\ttraining's rmse: 0.0881953\tvalid_1's rmse: 0.091\n",
      "[200]\ttraining's rmse: 0.0880907\tvalid_1's rmse: 0.0909626\n",
      "[225]\ttraining's rmse: 0.0879897\tvalid_1's rmse: 0.0909274\n",
      "[250]\ttraining's rmse: 0.087902\tvalid_1's rmse: 0.0908958\n",
      "[275]\ttraining's rmse: 0.0878205\tvalid_1's rmse: 0.0908654\n",
      "[300]\ttraining's rmse: 0.0877387\tvalid_1's rmse: 0.0908377\n",
      "[325]\ttraining's rmse: 0.0876577\tvalid_1's rmse: 0.09081\n",
      "[350]\ttraining's rmse: 0.0875813\tvalid_1's rmse: 0.0907862\n",
      "[375]\ttraining's rmse: 0.0875178\tvalid_1's rmse: 0.0907654\n",
      "[400]\ttraining's rmse: 0.0874508\tvalid_1's rmse: 0.0907455\n",
      "[425]\ttraining's rmse: 0.0873851\tvalid_1's rmse: 0.0907253\n",
      "[450]\ttraining's rmse: 0.0873231\tvalid_1's rmse: 0.0907061\n",
      "[475]\ttraining's rmse: 0.0872661\tvalid_1's rmse: 0.0906888\n",
      "[500]\ttraining's rmse: 0.0872192\tvalid_1's rmse: 0.0906716\n",
      "[525]\ttraining's rmse: 0.0871596\tvalid_1's rmse: 0.0906547\n",
      "[550]\ttraining's rmse: 0.0871064\tvalid_1's rmse: 0.0906406\n",
      "[575]\ttraining's rmse: 0.0870532\tvalid_1's rmse: 0.0906265\n",
      "[600]\ttraining's rmse: 0.0870036\tvalid_1's rmse: 0.0906136\n",
      "[625]\ttraining's rmse: 0.0869655\tvalid_1's rmse: 0.0906015\n",
      "[650]\ttraining's rmse: 0.0869146\tvalid_1's rmse: 0.090588\n",
      "[675]\ttraining's rmse: 0.0868646\tvalid_1's rmse: 0.0905756\n",
      "[700]\ttraining's rmse: 0.0868205\tvalid_1's rmse: 0.0905643\n",
      "[725]\ttraining's rmse: 0.0867809\tvalid_1's rmse: 0.0905541\n",
      "[750]\ttraining's rmse: 0.0867436\tvalid_1's rmse: 0.0905449\n",
      "[775]\ttraining's rmse: 0.086709\tvalid_1's rmse: 0.0905356\n",
      "[800]\ttraining's rmse: 0.0866681\tvalid_1's rmse: 0.0905272\n",
      "[825]\ttraining's rmse: 0.0866355\tvalid_1's rmse: 0.0905197\n",
      "[850]\ttraining's rmse: 0.0866028\tvalid_1's rmse: 0.0905131\n",
      "[875]\ttraining's rmse: 0.0865711\tvalid_1's rmse: 0.0905069\n",
      "[900]\ttraining's rmse: 0.0865385\tvalid_1's rmse: 0.0905007\n",
      "[925]\ttraining's rmse: 0.0865063\tvalid_1's rmse: 0.0904947\n",
      "[950]\ttraining's rmse: 0.0864776\tvalid_1's rmse: 0.0904886\n",
      "[975]\ttraining's rmse: 0.0864529\tvalid_1's rmse: 0.0904827\n",
      "[1000]\ttraining's rmse: 0.0864281\tvalid_1's rmse: 0.0904776\n",
      "[1025]\ttraining's rmse: 0.0863986\tvalid_1's rmse: 0.0904729\n",
      "[1050]\ttraining's rmse: 0.0863755\tvalid_1's rmse: 0.0904682\n",
      "[1075]\ttraining's rmse: 0.0863533\tvalid_1's rmse: 0.090465\n",
      "[1100]\ttraining's rmse: 0.0863342\tvalid_1's rmse: 0.0904615\n",
      "[1125]\ttraining's rmse: 0.0863128\tvalid_1's rmse: 0.090458\n",
      "[1150]\ttraining's rmse: 0.0862935\tvalid_1's rmse: 0.0904545\n",
      "[1175]\ttraining's rmse: 0.0862774\tvalid_1's rmse: 0.090452\n",
      "[1200]\ttraining's rmse: 0.0862595\tvalid_1's rmse: 0.0904493\n",
      "[1225]\ttraining's rmse: 0.0862428\tvalid_1's rmse: 0.090447\n",
      "[1250]\ttraining's rmse: 0.0862264\tvalid_1's rmse: 0.0904445\n",
      "[1275]\ttraining's rmse: 0.086206\tvalid_1's rmse: 0.0904421\n",
      "[1300]\ttraining's rmse: 0.0861909\tvalid_1's rmse: 0.0904396\n",
      "[1325]\ttraining's rmse: 0.086175\tvalid_1's rmse: 0.0904379\n",
      "[1350]\ttraining's rmse: 0.0861589\tvalid_1's rmse: 0.090437\n",
      "[1375]\ttraining's rmse: 0.0861461\tvalid_1's rmse: 0.0904354\n",
      "[1400]\ttraining's rmse: 0.0861345\tvalid_1's rmse: 0.090434\n",
      "[1425]\ttraining's rmse: 0.0861217\tvalid_1's rmse: 0.0904331\n",
      "[1450]\ttraining's rmse: 0.0861083\tvalid_1's rmse: 0.090432\n",
      "[1475]\ttraining's rmse: 0.0860983\tvalid_1's rmse: 0.0904306\n",
      "[1500]\ttraining's rmse: 0.0860885\tvalid_1's rmse: 0.0904296\n",
      "[1525]\ttraining's rmse: 0.0860747\tvalid_1's rmse: 0.0904284\n",
      "[1550]\ttraining's rmse: 0.0860634\tvalid_1's rmse: 0.0904278\n",
      "[1575]\ttraining's rmse: 0.0860539\tvalid_1's rmse: 0.0904263\n",
      "[1600]\ttraining's rmse: 0.0860445\tvalid_1's rmse: 0.0904261\n",
      "[1625]\ttraining's rmse: 0.086034\tvalid_1's rmse: 0.090424\n",
      "[1650]\ttraining's rmse: 0.0860268\tvalid_1's rmse: 0.0904234\n",
      "[1675]\ttraining's rmse: 0.0860194\tvalid_1's rmse: 0.0904226\n",
      "[1700]\ttraining's rmse: 0.0860133\tvalid_1's rmse: 0.0904216\n",
      "[1725]\ttraining's rmse: 0.0860074\tvalid_1's rmse: 0.090421\n",
      "[1750]\ttraining's rmse: 0.0859983\tvalid_1's rmse: 0.09042\n",
      "[1775]\ttraining's rmse: 0.08599\tvalid_1's rmse: 0.09042\n",
      "[1800]\ttraining's rmse: 0.0859808\tvalid_1's rmse: 0.0904193\n",
      "[1825]\ttraining's rmse: 0.0859741\tvalid_1's rmse: 0.0904187\n",
      "[1850]\ttraining's rmse: 0.0859695\tvalid_1's rmse: 0.0904184\n",
      "[1875]\ttraining's rmse: 0.0859639\tvalid_1's rmse: 0.0904185\n",
      "[1900]\ttraining's rmse: 0.0859575\tvalid_1's rmse: 0.0904182\n",
      "[1925]\ttraining's rmse: 0.0859509\tvalid_1's rmse: 0.0904173\n",
      "[1950]\ttraining's rmse: 0.0859462\tvalid_1's rmse: 0.0904165\n",
      "[1975]\ttraining's rmse: 0.0859414\tvalid_1's rmse: 0.0904158\n",
      "[2000]\ttraining's rmse: 0.0859355\tvalid_1's rmse: 0.0904154\n",
      "[2025]\ttraining's rmse: 0.0859298\tvalid_1's rmse: 0.0904148\n",
      "[2050]\ttraining's rmse: 0.0859255\tvalid_1's rmse: 0.0904147\n",
      "[2075]\ttraining's rmse: 0.0859205\tvalid_1's rmse: 0.0904141\n",
      "[2100]\ttraining's rmse: 0.0859164\tvalid_1's rmse: 0.0904143\n",
      "Early stopping, best iteration is:\n",
      "[2071]\ttraining's rmse: 0.0859214\tvalid_1's rmse: 0.090414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0913001\tvalid_1's rmse: 0.0865092\n",
      "[50]\ttraining's rmse: 0.0911796\tvalid_1's rmse: 0.0864584\n",
      "[75]\ttraining's rmse: 0.0910539\tvalid_1's rmse: 0.0864082\n",
      "[100]\ttraining's rmse: 0.0909412\tvalid_1's rmse: 0.0863646\n",
      "[125]\ttraining's rmse: 0.0908263\tvalid_1's rmse: 0.086321\n",
      "[150]\ttraining's rmse: 0.0907173\tvalid_1's rmse: 0.0862818\n",
      "[175]\ttraining's rmse: 0.0906271\tvalid_1's rmse: 0.0862486\n",
      "[200]\ttraining's rmse: 0.0905309\tvalid_1's rmse: 0.0862162\n",
      "[225]\ttraining's rmse: 0.0904356\tvalid_1's rmse: 0.086185\n",
      "[250]\ttraining's rmse: 0.0903539\tvalid_1's rmse: 0.0861577\n",
      "[275]\ttraining's rmse: 0.0902801\tvalid_1's rmse: 0.0861308\n",
      "[300]\ttraining's rmse: 0.0902071\tvalid_1's rmse: 0.086105\n",
      "[325]\ttraining's rmse: 0.0901336\tvalid_1's rmse: 0.086082\n",
      "[350]\ttraining's rmse: 0.0900602\tvalid_1's rmse: 0.0860603\n",
      "[375]\ttraining's rmse: 0.090001\tvalid_1's rmse: 0.0860407\n",
      "[400]\ttraining's rmse: 0.089937\tvalid_1's rmse: 0.0860237\n",
      "[425]\ttraining's rmse: 0.0898772\tvalid_1's rmse: 0.0860074\n",
      "[450]\ttraining's rmse: 0.0898212\tvalid_1's rmse: 0.0859895\n",
      "[475]\ttraining's rmse: 0.0897688\tvalid_1's rmse: 0.0859766\n",
      "[500]\ttraining's rmse: 0.089724\tvalid_1's rmse: 0.0859639\n",
      "[525]\ttraining's rmse: 0.0896639\tvalid_1's rmse: 0.0859576\n",
      "[550]\ttraining's rmse: 0.0896115\tvalid_1's rmse: 0.0859439\n",
      "[575]\ttraining's rmse: 0.0895618\tvalid_1's rmse: 0.0859353\n",
      "[600]\ttraining's rmse: 0.0895132\tvalid_1's rmse: 0.0859243\n",
      "[625]\ttraining's rmse: 0.089475\tvalid_1's rmse: 0.0859223\n",
      "[650]\ttraining's rmse: 0.0894258\tvalid_1's rmse: 0.0859143\n",
      "[675]\ttraining's rmse: 0.0893772\tvalid_1's rmse: 0.0859049\n",
      "[700]\ttraining's rmse: 0.0893363\tvalid_1's rmse: 0.0859022\n",
      "[725]\ttraining's rmse: 0.0892984\tvalid_1's rmse: 0.0859042\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0893471\tvalid_1's rmse: 0.0858988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0884988\tvalid_1's rmse: 0.0910452\n",
      "[50]\ttraining's rmse: 0.0883514\tvalid_1's rmse: 0.0909883\n",
      "[75]\ttraining's rmse: 0.0882036\tvalid_1's rmse: 0.0909329\n",
      "[100]\ttraining's rmse: 0.0880708\tvalid_1's rmse: 0.0908844\n",
      "[125]\ttraining's rmse: 0.087937\tvalid_1's rmse: 0.0908366\n",
      "[150]\ttraining's rmse: 0.0878098\tvalid_1's rmse: 0.0907907\n",
      "[175]\ttraining's rmse: 0.0877062\tvalid_1's rmse: 0.0907516\n",
      "[200]\ttraining's rmse: 0.0875929\tvalid_1's rmse: 0.0907128\n",
      "[225]\ttraining's rmse: 0.0874829\tvalid_1's rmse: 0.0906767\n",
      "[250]\ttraining's rmse: 0.0873897\tvalid_1's rmse: 0.0906423\n",
      "[275]\ttraining's rmse: 0.0872993\tvalid_1's rmse: 0.0906109\n",
      "[300]\ttraining's rmse: 0.0872157\tvalid_1's rmse: 0.0905804\n",
      "[325]\ttraining's rmse: 0.0871326\tvalid_1's rmse: 0.0905519\n",
      "[350]\ttraining's rmse: 0.0870511\tvalid_1's rmse: 0.0905262\n",
      "[375]\ttraining's rmse: 0.0869798\tvalid_1's rmse: 0.090505\n",
      "[400]\ttraining's rmse: 0.086904\tvalid_1's rmse: 0.090482\n",
      "[425]\ttraining's rmse: 0.0868363\tvalid_1's rmse: 0.0904612\n",
      "[450]\ttraining's rmse: 0.0867758\tvalid_1's rmse: 0.09044\n",
      "[475]\ttraining's rmse: 0.0867189\tvalid_1's rmse: 0.0904206\n",
      "[500]\ttraining's rmse: 0.086671\tvalid_1's rmse: 0.0904033\n",
      "[525]\ttraining's rmse: 0.0866105\tvalid_1's rmse: 0.0903859\n",
      "[550]\ttraining's rmse: 0.0865539\tvalid_1's rmse: 0.0903696\n",
      "[575]\ttraining's rmse: 0.0865021\tvalid_1's rmse: 0.0903548\n",
      "[600]\ttraining's rmse: 0.0864552\tvalid_1's rmse: 0.090342\n",
      "[625]\ttraining's rmse: 0.0864151\tvalid_1's rmse: 0.0903296\n",
      "[650]\ttraining's rmse: 0.0863697\tvalid_1's rmse: 0.0903178\n",
      "[675]\ttraining's rmse: 0.0863232\tvalid_1's rmse: 0.0903048\n",
      "[700]\ttraining's rmse: 0.0862811\tvalid_1's rmse: 0.0902922\n",
      "[725]\ttraining's rmse: 0.0862439\tvalid_1's rmse: 0.0902825\n",
      "[750]\ttraining's rmse: 0.086203\tvalid_1's rmse: 0.0902722\n",
      "[775]\ttraining's rmse: 0.0861742\tvalid_1's rmse: 0.0902621\n",
      "[800]\ttraining's rmse: 0.0861354\tvalid_1's rmse: 0.0902527\n",
      "[825]\ttraining's rmse: 0.0861011\tvalid_1's rmse: 0.090244\n",
      "[850]\ttraining's rmse: 0.0860665\tvalid_1's rmse: 0.0902366\n",
      "[875]\ttraining's rmse: 0.0860364\tvalid_1's rmse: 0.0902271\n",
      "[900]\ttraining's rmse: 0.0860034\tvalid_1's rmse: 0.0902195\n",
      "[925]\ttraining's rmse: 0.0859723\tvalid_1's rmse: 0.0902108\n",
      "[950]\ttraining's rmse: 0.0859467\tvalid_1's rmse: 0.0902056\n",
      "[975]\ttraining's rmse: 0.0859202\tvalid_1's rmse: 0.0901992\n",
      "[1000]\ttraining's rmse: 0.0858917\tvalid_1's rmse: 0.0901929\n",
      "[1025]\ttraining's rmse: 0.0858642\tvalid_1's rmse: 0.0901858\n",
      "[1050]\ttraining's rmse: 0.0858408\tvalid_1's rmse: 0.0901793\n",
      "[1075]\ttraining's rmse: 0.085817\tvalid_1's rmse: 0.0901747\n",
      "[1100]\ttraining's rmse: 0.0857968\tvalid_1's rmse: 0.0901699\n",
      "[1125]\ttraining's rmse: 0.0857765\tvalid_1's rmse: 0.0901644\n",
      "[1150]\ttraining's rmse: 0.0857535\tvalid_1's rmse: 0.090158\n",
      "[1175]\ttraining's rmse: 0.0857339\tvalid_1's rmse: 0.0901549\n",
      "[1200]\ttraining's rmse: 0.0857165\tvalid_1's rmse: 0.0901483\n",
      "[1225]\ttraining's rmse: 0.0856997\tvalid_1's rmse: 0.0901433\n",
      "[1250]\ttraining's rmse: 0.085684\tvalid_1's rmse: 0.0901394\n",
      "[1275]\ttraining's rmse: 0.0856643\tvalid_1's rmse: 0.0901347\n",
      "[1300]\ttraining's rmse: 0.0856477\tvalid_1's rmse: 0.090129\n",
      "[1325]\ttraining's rmse: 0.0856306\tvalid_1's rmse: 0.0901258\n",
      "[1350]\ttraining's rmse: 0.0856133\tvalid_1's rmse: 0.0901224\n",
      "[1375]\ttraining's rmse: 0.0855978\tvalid_1's rmse: 0.0901195\n",
      "[1400]\ttraining's rmse: 0.085587\tvalid_1's rmse: 0.0901158\n",
      "[1425]\ttraining's rmse: 0.0855713\tvalid_1's rmse: 0.090113\n",
      "[1450]\ttraining's rmse: 0.0855574\tvalid_1's rmse: 0.0901101\n",
      "[1475]\ttraining's rmse: 0.0855457\tvalid_1's rmse: 0.0901064\n",
      "[1500]\ttraining's rmse: 0.085534\tvalid_1's rmse: 0.0901039\n",
      "[1525]\ttraining's rmse: 0.0855248\tvalid_1's rmse: 0.0901018\n",
      "[1550]\ttraining's rmse: 0.0855133\tvalid_1's rmse: 0.0900993\n",
      "[1575]\ttraining's rmse: 0.0855009\tvalid_1's rmse: 0.0900957\n",
      "[1600]\ttraining's rmse: 0.0854924\tvalid_1's rmse: 0.0900935\n",
      "[1625]\ttraining's rmse: 0.0854832\tvalid_1's rmse: 0.0900906\n",
      "[1650]\ttraining's rmse: 0.0854754\tvalid_1's rmse: 0.0900879\n",
      "[1675]\ttraining's rmse: 0.0854677\tvalid_1's rmse: 0.0900848\n",
      "[1700]\ttraining's rmse: 0.0854611\tvalid_1's rmse: 0.0900821\n",
      "[1725]\ttraining's rmse: 0.0854529\tvalid_1's rmse: 0.0900812\n",
      "[1750]\ttraining's rmse: 0.0854451\tvalid_1's rmse: 0.0900794\n",
      "[1775]\ttraining's rmse: 0.0854385\tvalid_1's rmse: 0.0900777\n",
      "[1800]\ttraining's rmse: 0.0854308\tvalid_1's rmse: 0.0900765\n",
      "[1825]\ttraining's rmse: 0.0854253\tvalid_1's rmse: 0.0900743\n",
      "[1850]\ttraining's rmse: 0.0854199\tvalid_1's rmse: 0.0900726\n",
      "[1875]\ttraining's rmse: 0.085414\tvalid_1's rmse: 0.0900714\n",
      "[1900]\ttraining's rmse: 0.085409\tvalid_1's rmse: 0.0900699\n",
      "[1925]\ttraining's rmse: 0.0854023\tvalid_1's rmse: 0.0900684\n",
      "[1950]\ttraining's rmse: 0.0853979\tvalid_1's rmse: 0.0900669\n",
      "[1975]\ttraining's rmse: 0.0853922\tvalid_1's rmse: 0.0900653\n",
      "[2000]\ttraining's rmse: 0.0853873\tvalid_1's rmse: 0.0900647\n",
      "[2025]\ttraining's rmse: 0.0853827\tvalid_1's rmse: 0.0900623\n",
      "[2050]\ttraining's rmse: 0.0853784\tvalid_1's rmse: 0.0900615\n",
      "[2075]\ttraining's rmse: 0.0853745\tvalid_1's rmse: 0.0900606\n",
      "[2100]\ttraining's rmse: 0.0853714\tvalid_1's rmse: 0.0900595\n",
      "[2125]\ttraining's rmse: 0.0853681\tvalid_1's rmse: 0.0900578\n",
      "[2150]\ttraining's rmse: 0.0853631\tvalid_1's rmse: 0.0900562\n",
      "[2175]\ttraining's rmse: 0.0853605\tvalid_1's rmse: 0.090055\n",
      "[2200]\ttraining's rmse: 0.0853574\tvalid_1's rmse: 0.0900541\n",
      "[2225]\ttraining's rmse: 0.0853536\tvalid_1's rmse: 0.0900528\n",
      "[2250]\ttraining's rmse: 0.0853507\tvalid_1's rmse: 0.0900516\n",
      "[2275]\ttraining's rmse: 0.0853476\tvalid_1's rmse: 0.0900509\n",
      "[2300]\ttraining's rmse: 0.0853446\tvalid_1's rmse: 0.0900502\n",
      "[2325]\ttraining's rmse: 0.0853414\tvalid_1's rmse: 0.0900486\n",
      "[2350]\ttraining's rmse: 0.0853375\tvalid_1's rmse: 0.0900479\n",
      "[2375]\ttraining's rmse: 0.0853339\tvalid_1's rmse: 0.0900468\n",
      "[2400]\ttraining's rmse: 0.08533\tvalid_1's rmse: 0.0900465\n",
      "[2425]\ttraining's rmse: 0.0853276\tvalid_1's rmse: 0.0900454\n",
      "[2450]\ttraining's rmse: 0.0853239\tvalid_1's rmse: 0.090045\n",
      "[2475]\ttraining's rmse: 0.0853211\tvalid_1's rmse: 0.0900448\n",
      "[2500]\ttraining's rmse: 0.0853177\tvalid_1's rmse: 0.0900448\n",
      "[2525]\ttraining's rmse: 0.085314\tvalid_1's rmse: 0.0900438\n",
      "[2550]\ttraining's rmse: 0.0853123\tvalid_1's rmse: 0.0900436\n",
      "[2575]\ttraining's rmse: 0.0853099\tvalid_1's rmse: 0.0900432\n",
      "[2600]\ttraining's rmse: 0.0853069\tvalid_1's rmse: 0.0900422\n",
      "[2625]\ttraining's rmse: 0.0853053\tvalid_1's rmse: 0.0900409\n",
      "[2650]\ttraining's rmse: 0.0853025\tvalid_1's rmse: 0.0900398\n",
      "[2675]\ttraining's rmse: 0.0853006\tvalid_1's rmse: 0.0900385\n",
      "[2700]\ttraining's rmse: 0.0852992\tvalid_1's rmse: 0.0900382\n",
      "[2725]\ttraining's rmse: 0.0852981\tvalid_1's rmse: 0.0900383\n",
      "[2750]\ttraining's rmse: 0.0852972\tvalid_1's rmse: 0.0900375\n",
      "[2775]\ttraining's rmse: 0.0852939\tvalid_1's rmse: 0.0900373\n",
      "[2800]\ttraining's rmse: 0.0852919\tvalid_1's rmse: 0.0900359\n",
      "[2825]\ttraining's rmse: 0.0852896\tvalid_1's rmse: 0.0900351\n",
      "[2850]\ttraining's rmse: 0.0852869\tvalid_1's rmse: 0.090034\n",
      "[2875]\ttraining's rmse: 0.0852845\tvalid_1's rmse: 0.0900337\n",
      "[2900]\ttraining's rmse: 0.0852826\tvalid_1's rmse: 0.090033\n",
      "[2925]\ttraining's rmse: 0.085282\tvalid_1's rmse: 0.0900332\n",
      "Early stopping, best iteration is:\n",
      "[2898]\ttraining's rmse: 0.0852826\tvalid_1's rmse: 0.090033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0883922\tvalid_1's rmse: 0.0912698\n",
      "[50]\ttraining's rmse: 0.0882637\tvalid_1's rmse: 0.0912145\n",
      "[75]\ttraining's rmse: 0.088127\tvalid_1's rmse: 0.0911572\n",
      "[100]\ttraining's rmse: 0.0880063\tvalid_1's rmse: 0.0911082\n",
      "[125]\ttraining's rmse: 0.0878812\tvalid_1's rmse: 0.0910586\n",
      "[150]\ttraining's rmse: 0.0877649\tvalid_1's rmse: 0.0910141\n",
      "[175]\ttraining's rmse: 0.0876687\tvalid_1's rmse: 0.0909772\n",
      "[200]\ttraining's rmse: 0.0875638\tvalid_1's rmse: 0.0909403\n",
      "[225]\ttraining's rmse: 0.0874622\tvalid_1's rmse: 0.0909038\n",
      "[250]\ttraining's rmse: 0.0873755\tvalid_1's rmse: 0.0908712\n",
      "[275]\ttraining's rmse: 0.0872947\tvalid_1's rmse: 0.0908417\n",
      "[300]\ttraining's rmse: 0.0872138\tvalid_1's rmse: 0.0908125\n",
      "[325]\ttraining's rmse: 0.0871336\tvalid_1's rmse: 0.0907857\n",
      "[350]\ttraining's rmse: 0.0870552\tvalid_1's rmse: 0.0907611\n",
      "[375]\ttraining's rmse: 0.0869917\tvalid_1's rmse: 0.0907403\n",
      "[400]\ttraining's rmse: 0.0869207\tvalid_1's rmse: 0.0907177\n",
      "[425]\ttraining's rmse: 0.0868569\tvalid_1's rmse: 0.0906976\n",
      "[450]\ttraining's rmse: 0.0867964\tvalid_1's rmse: 0.0906771\n",
      "[475]\ttraining's rmse: 0.0867424\tvalid_1's rmse: 0.0906595\n",
      "[500]\ttraining's rmse: 0.0866967\tvalid_1's rmse: 0.0906424\n",
      "[525]\ttraining's rmse: 0.0866351\tvalid_1's rmse: 0.0906255\n",
      "[550]\ttraining's rmse: 0.0865796\tvalid_1's rmse: 0.0906111\n",
      "[575]\ttraining's rmse: 0.0865291\tvalid_1's rmse: 0.0905967\n",
      "[600]\ttraining's rmse: 0.0864801\tvalid_1's rmse: 0.0905832\n",
      "[625]\ttraining's rmse: 0.0864414\tvalid_1's rmse: 0.0905701\n",
      "[650]\ttraining's rmse: 0.0863923\tvalid_1's rmse: 0.0905575\n",
      "[675]\ttraining's rmse: 0.086346\tvalid_1's rmse: 0.0905461\n",
      "[700]\ttraining's rmse: 0.0863032\tvalid_1's rmse: 0.0905356\n",
      "[725]\ttraining's rmse: 0.0862617\tvalid_1's rmse: 0.0905259\n",
      "[750]\ttraining's rmse: 0.0862251\tvalid_1's rmse: 0.0905167\n",
      "[775]\ttraining's rmse: 0.0861945\tvalid_1's rmse: 0.0905077\n",
      "[800]\ttraining's rmse: 0.0861548\tvalid_1's rmse: 0.0905006\n",
      "[825]\ttraining's rmse: 0.0861215\tvalid_1's rmse: 0.0904923\n",
      "[850]\ttraining's rmse: 0.0860892\tvalid_1's rmse: 0.0904864\n",
      "[875]\ttraining's rmse: 0.0860607\tvalid_1's rmse: 0.09048\n",
      "[900]\ttraining's rmse: 0.0860282\tvalid_1's rmse: 0.0904729\n",
      "[925]\ttraining's rmse: 0.0859975\tvalid_1's rmse: 0.0904671\n",
      "[950]\ttraining's rmse: 0.085969\tvalid_1's rmse: 0.0904616\n",
      "[975]\ttraining's rmse: 0.0859422\tvalid_1's rmse: 0.0904558\n",
      "[1000]\ttraining's rmse: 0.0859177\tvalid_1's rmse: 0.0904521\n",
      "[1025]\ttraining's rmse: 0.0858916\tvalid_1's rmse: 0.0904477\n",
      "[1050]\ttraining's rmse: 0.0858691\tvalid_1's rmse: 0.0904442\n",
      "[1075]\ttraining's rmse: 0.085846\tvalid_1's rmse: 0.0904412\n",
      "[1100]\ttraining's rmse: 0.0858277\tvalid_1's rmse: 0.0904376\n",
      "[1125]\ttraining's rmse: 0.0858069\tvalid_1's rmse: 0.0904342\n",
      "[1150]\ttraining's rmse: 0.0857837\tvalid_1's rmse: 0.0904305\n",
      "[1175]\ttraining's rmse: 0.0857659\tvalid_1's rmse: 0.0904279\n",
      "[1200]\ttraining's rmse: 0.0857468\tvalid_1's rmse: 0.0904252\n",
      "[1225]\ttraining's rmse: 0.0857297\tvalid_1's rmse: 0.0904222\n",
      "[1250]\ttraining's rmse: 0.085713\tvalid_1's rmse: 0.0904205\n",
      "[1275]\ttraining's rmse: 0.0856933\tvalid_1's rmse: 0.0904187\n",
      "[1300]\ttraining's rmse: 0.0856799\tvalid_1's rmse: 0.0904165\n",
      "[1325]\ttraining's rmse: 0.0856641\tvalid_1's rmse: 0.0904147\n",
      "[1350]\ttraining's rmse: 0.0856484\tvalid_1's rmse: 0.0904134\n",
      "[1375]\ttraining's rmse: 0.0856321\tvalid_1's rmse: 0.0904116\n",
      "[1400]\ttraining's rmse: 0.0856192\tvalid_1's rmse: 0.0904094\n",
      "[1425]\ttraining's rmse: 0.0856051\tvalid_1's rmse: 0.090408\n",
      "[1450]\ttraining's rmse: 0.0855914\tvalid_1's rmse: 0.0904068\n",
      "[1475]\ttraining's rmse: 0.0855785\tvalid_1's rmse: 0.0904054\n",
      "[1500]\ttraining's rmse: 0.0855659\tvalid_1's rmse: 0.0904047\n",
      "[1525]\ttraining's rmse: 0.0855558\tvalid_1's rmse: 0.0904036\n",
      "[1550]\ttraining's rmse: 0.0855445\tvalid_1's rmse: 0.090402\n",
      "[1575]\ttraining's rmse: 0.0855346\tvalid_1's rmse: 0.0904004\n",
      "[1600]\ttraining's rmse: 0.0855251\tvalid_1's rmse: 0.0904001\n",
      "[1625]\ttraining's rmse: 0.0855164\tvalid_1's rmse: 0.0903989\n",
      "[1650]\ttraining's rmse: 0.0855059\tvalid_1's rmse: 0.0903977\n",
      "[1675]\ttraining's rmse: 0.0854991\tvalid_1's rmse: 0.0903969\n",
      "[1700]\ttraining's rmse: 0.0854929\tvalid_1's rmse: 0.0903962\n",
      "[1725]\ttraining's rmse: 0.0854858\tvalid_1's rmse: 0.0903955\n",
      "[1750]\ttraining's rmse: 0.0854785\tvalid_1's rmse: 0.0903954\n",
      "[1775]\ttraining's rmse: 0.0854716\tvalid_1's rmse: 0.0903948\n",
      "[1800]\ttraining's rmse: 0.0854643\tvalid_1's rmse: 0.0903938\n",
      "[1825]\ttraining's rmse: 0.0854577\tvalid_1's rmse: 0.0903937\n",
      "[1850]\ttraining's rmse: 0.0854532\tvalid_1's rmse: 0.0903931\n",
      "[1875]\ttraining's rmse: 0.0854486\tvalid_1's rmse: 0.0903926\n",
      "[1900]\ttraining's rmse: 0.0854429\tvalid_1's rmse: 0.0903922\n",
      "[1925]\ttraining's rmse: 0.0854378\tvalid_1's rmse: 0.0903917\n",
      "[1950]\ttraining's rmse: 0.0854343\tvalid_1's rmse: 0.0903915\n",
      "[1975]\ttraining's rmse: 0.0854302\tvalid_1's rmse: 0.0903905\n",
      "[2000]\ttraining's rmse: 0.085424\tvalid_1's rmse: 0.09039\n",
      "[2025]\ttraining's rmse: 0.0854201\tvalid_1's rmse: 0.0903897\n",
      "[2050]\ttraining's rmse: 0.085416\tvalid_1's rmse: 0.0903897\n",
      "[2075]\ttraining's rmse: 0.0854131\tvalid_1's rmse: 0.0903894\n",
      "[2100]\ttraining's rmse: 0.0854088\tvalid_1's rmse: 0.0903891\n",
      "[2125]\ttraining's rmse: 0.0854056\tvalid_1's rmse: 0.0903892\n",
      "[2150]\ttraining's rmse: 0.0854008\tvalid_1's rmse: 0.0903892\n",
      "[2175]\ttraining's rmse: 0.0853973\tvalid_1's rmse: 0.0903889\n",
      "[2200]\ttraining's rmse: 0.0853937\tvalid_1's rmse: 0.0903884\n",
      "[2225]\ttraining's rmse: 0.0853894\tvalid_1's rmse: 0.0903882\n",
      "[2250]\ttraining's rmse: 0.0853849\tvalid_1's rmse: 0.0903881\n",
      "[2275]\ttraining's rmse: 0.0853816\tvalid_1's rmse: 0.090388\n",
      "[2300]\ttraining's rmse: 0.085379\tvalid_1's rmse: 0.0903882\n",
      "Early stopping, best iteration is:\n",
      "[2263]\ttraining's rmse: 0.0853834\tvalid_1's rmse: 0.0903879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0910226\tvalid_1's rmse: 0.0859243\n",
      "[50]\ttraining's rmse: 0.0908962\tvalid_1's rmse: 0.0858759\n",
      "[75]\ttraining's rmse: 0.0907646\tvalid_1's rmse: 0.0858263\n",
      "[100]\ttraining's rmse: 0.0906446\tvalid_1's rmse: 0.085783\n",
      "[125]\ttraining's rmse: 0.0905217\tvalid_1's rmse: 0.0857397\n",
      "[150]\ttraining's rmse: 0.090408\tvalid_1's rmse: 0.0857003\n",
      "[175]\ttraining's rmse: 0.0903111\tvalid_1's rmse: 0.0856669\n",
      "[200]\ttraining's rmse: 0.0902061\tvalid_1's rmse: 0.0856346\n",
      "[225]\ttraining's rmse: 0.090108\tvalid_1's rmse: 0.0856032\n",
      "[250]\ttraining's rmse: 0.0900218\tvalid_1's rmse: 0.0855757\n",
      "[275]\ttraining's rmse: 0.0899461\tvalid_1's rmse: 0.0855507\n",
      "[300]\ttraining's rmse: 0.0898693\tvalid_1's rmse: 0.0855276\n",
      "[325]\ttraining's rmse: 0.0897899\tvalid_1's rmse: 0.0855048\n",
      "[350]\ttraining's rmse: 0.0897129\tvalid_1's rmse: 0.0854834\n",
      "[375]\ttraining's rmse: 0.0896525\tvalid_1's rmse: 0.0854654\n",
      "[400]\ttraining's rmse: 0.0895829\tvalid_1's rmse: 0.0854506\n",
      "[425]\ttraining's rmse: 0.0895192\tvalid_1's rmse: 0.085433\n",
      "[450]\ttraining's rmse: 0.0894637\tvalid_1's rmse: 0.0854197\n",
      "[475]\ttraining's rmse: 0.0894083\tvalid_1's rmse: 0.085406\n",
      "[500]\ttraining's rmse: 0.0893611\tvalid_1's rmse: 0.0853919\n",
      "[525]\ttraining's rmse: 0.0893009\tvalid_1's rmse: 0.0853807\n",
      "[550]\ttraining's rmse: 0.0892463\tvalid_1's rmse: 0.0853713\n",
      "[575]\ttraining's rmse: 0.0891947\tvalid_1's rmse: 0.0853595\n",
      "[600]\ttraining's rmse: 0.0891467\tvalid_1's rmse: 0.0853546\n",
      "[625]\ttraining's rmse: 0.0891075\tvalid_1's rmse: 0.0853507\n",
      "[650]\ttraining's rmse: 0.0890551\tvalid_1's rmse: 0.0853416\n",
      "[675]\ttraining's rmse: 0.0890041\tvalid_1's rmse: 0.085342\n",
      "[700]\ttraining's rmse: 0.088962\tvalid_1's rmse: 0.085332\n",
      "[725]\ttraining's rmse: 0.0889205\tvalid_1's rmse: 0.0853294\n",
      "[750]\ttraining's rmse: 0.0888829\tvalid_1's rmse: 0.0853338\n",
      "[775]\ttraining's rmse: 0.0888514\tvalid_1's rmse: 0.085328\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0889038\tvalid_1's rmse: 0.0853254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0881007\tvalid_1's rmse: 0.0909684\n",
      "[50]\ttraining's rmse: 0.0879609\tvalid_1's rmse: 0.0909125\n",
      "[75]\ttraining's rmse: 0.0878163\tvalid_1's rmse: 0.0908585\n",
      "[100]\ttraining's rmse: 0.0876866\tvalid_1's rmse: 0.0908114\n",
      "[125]\ttraining's rmse: 0.0875522\tvalid_1's rmse: 0.0907615\n",
      "[150]\ttraining's rmse: 0.0874316\tvalid_1's rmse: 0.090718\n",
      "[175]\ttraining's rmse: 0.0873357\tvalid_1's rmse: 0.0906808\n",
      "[200]\ttraining's rmse: 0.0872279\tvalid_1's rmse: 0.0906419\n",
      "[225]\ttraining's rmse: 0.0871215\tvalid_1's rmse: 0.0906062\n",
      "[250]\ttraining's rmse: 0.0870323\tvalid_1's rmse: 0.0905728\n",
      "[275]\ttraining's rmse: 0.0869508\tvalid_1's rmse: 0.090543\n",
      "[300]\ttraining's rmse: 0.0868695\tvalid_1's rmse: 0.0905139\n",
      "[325]\ttraining's rmse: 0.0867891\tvalid_1's rmse: 0.0904861\n",
      "[350]\ttraining's rmse: 0.0867116\tvalid_1's rmse: 0.0904601\n",
      "[375]\ttraining's rmse: 0.0866456\tvalid_1's rmse: 0.0904377\n",
      "[400]\ttraining's rmse: 0.0865728\tvalid_1's rmse: 0.0904148\n",
      "[425]\ttraining's rmse: 0.0865072\tvalid_1's rmse: 0.0903929\n",
      "[450]\ttraining's rmse: 0.0864473\tvalid_1's rmse: 0.0903731\n",
      "[475]\ttraining's rmse: 0.0863945\tvalid_1's rmse: 0.0903542\n",
      "[500]\ttraining's rmse: 0.0863463\tvalid_1's rmse: 0.0903369\n",
      "[525]\ttraining's rmse: 0.0862886\tvalid_1's rmse: 0.0903197\n",
      "[550]\ttraining's rmse: 0.0862336\tvalid_1's rmse: 0.0903031\n",
      "[575]\ttraining's rmse: 0.0861852\tvalid_1's rmse: 0.0902889\n",
      "[600]\ttraining's rmse: 0.0861368\tvalid_1's rmse: 0.0902745\n",
      "[625]\ttraining's rmse: 0.0861005\tvalid_1's rmse: 0.0902623\n",
      "[650]\ttraining's rmse: 0.0860575\tvalid_1's rmse: 0.0902493\n",
      "[675]\ttraining's rmse: 0.0860127\tvalid_1's rmse: 0.0902367\n",
      "[700]\ttraining's rmse: 0.0859733\tvalid_1's rmse: 0.0902244\n",
      "[725]\ttraining's rmse: 0.0859335\tvalid_1's rmse: 0.0902137\n",
      "[750]\ttraining's rmse: 0.085896\tvalid_1's rmse: 0.0902029\n",
      "[775]\ttraining's rmse: 0.0858653\tvalid_1's rmse: 0.0901912\n",
      "[800]\ttraining's rmse: 0.0858285\tvalid_1's rmse: 0.0901815\n",
      "[825]\ttraining's rmse: 0.0857972\tvalid_1's rmse: 0.0901724\n",
      "[850]\ttraining's rmse: 0.085763\tvalid_1's rmse: 0.0901644\n",
      "[875]\ttraining's rmse: 0.0857318\tvalid_1's rmse: 0.0901553\n",
      "[900]\ttraining's rmse: 0.0856998\tvalid_1's rmse: 0.0901466\n",
      "[925]\ttraining's rmse: 0.0856725\tvalid_1's rmse: 0.090138\n",
      "[950]\ttraining's rmse: 0.0856474\tvalid_1's rmse: 0.0901309\n",
      "[975]\ttraining's rmse: 0.0856224\tvalid_1's rmse: 0.0901234\n",
      "[1000]\ttraining's rmse: 0.0855986\tvalid_1's rmse: 0.090117\n",
      "[1025]\ttraining's rmse: 0.0855748\tvalid_1's rmse: 0.0901108\n",
      "[1050]\ttraining's rmse: 0.0855536\tvalid_1's rmse: 0.0901033\n",
      "[1075]\ttraining's rmse: 0.0855317\tvalid_1's rmse: 0.0900986\n",
      "[1100]\ttraining's rmse: 0.0855131\tvalid_1's rmse: 0.0900934\n",
      "[1125]\ttraining's rmse: 0.0854922\tvalid_1's rmse: 0.0900878\n",
      "[1150]\ttraining's rmse: 0.0854693\tvalid_1's rmse: 0.0900817\n",
      "[1175]\ttraining's rmse: 0.085451\tvalid_1's rmse: 0.0900776\n",
      "[1200]\ttraining's rmse: 0.0854329\tvalid_1's rmse: 0.0900721\n",
      "[1225]\ttraining's rmse: 0.0854148\tvalid_1's rmse: 0.0900673\n",
      "[1250]\ttraining's rmse: 0.0853992\tvalid_1's rmse: 0.0900635\n",
      "[1275]\ttraining's rmse: 0.0853807\tvalid_1's rmse: 0.0900592\n",
      "[1300]\ttraining's rmse: 0.0853677\tvalid_1's rmse: 0.090055\n",
      "[1325]\ttraining's rmse: 0.0853538\tvalid_1's rmse: 0.0900514\n",
      "[1350]\ttraining's rmse: 0.0853387\tvalid_1's rmse: 0.0900474\n",
      "[1375]\ttraining's rmse: 0.0853248\tvalid_1's rmse: 0.0900439\n",
      "[1400]\ttraining's rmse: 0.0853141\tvalid_1's rmse: 0.0900402\n",
      "[1425]\ttraining's rmse: 0.0852977\tvalid_1's rmse: 0.090038\n",
      "[1450]\ttraining's rmse: 0.0852824\tvalid_1's rmse: 0.0900353\n",
      "[1475]\ttraining's rmse: 0.0852702\tvalid_1's rmse: 0.0900313\n",
      "[1500]\ttraining's rmse: 0.0852593\tvalid_1's rmse: 0.0900283\n",
      "[1525]\ttraining's rmse: 0.0852486\tvalid_1's rmse: 0.0900256\n",
      "[1550]\ttraining's rmse: 0.0852371\tvalid_1's rmse: 0.0900239\n",
      "[1575]\ttraining's rmse: 0.0852296\tvalid_1's rmse: 0.0900213\n",
      "[1600]\ttraining's rmse: 0.0852206\tvalid_1's rmse: 0.0900203\n",
      "[1625]\ttraining's rmse: 0.0852097\tvalid_1's rmse: 0.0900181\n",
      "[1650]\ttraining's rmse: 0.0851992\tvalid_1's rmse: 0.0900165\n",
      "[1675]\ttraining's rmse: 0.0851918\tvalid_1's rmse: 0.0900137\n",
      "[1700]\ttraining's rmse: 0.0851845\tvalid_1's rmse: 0.0900117\n",
      "[1725]\ttraining's rmse: 0.0851753\tvalid_1's rmse: 0.0900097\n",
      "[1750]\ttraining's rmse: 0.0851667\tvalid_1's rmse: 0.0900081\n",
      "[1775]\ttraining's rmse: 0.0851593\tvalid_1's rmse: 0.0900062\n",
      "[1800]\ttraining's rmse: 0.0851535\tvalid_1's rmse: 0.0900032\n",
      "[1825]\ttraining's rmse: 0.0851474\tvalid_1's rmse: 0.0900024\n",
      "[1850]\ttraining's rmse: 0.0851419\tvalid_1's rmse: 0.0900007\n",
      "[1875]\ttraining's rmse: 0.085136\tvalid_1's rmse: 0.0899992\n",
      "[1900]\ttraining's rmse: 0.0851271\tvalid_1's rmse: 0.0899983\n",
      "[1925]\ttraining's rmse: 0.0851229\tvalid_1's rmse: 0.0899974\n",
      "[1950]\ttraining's rmse: 0.0851181\tvalid_1's rmse: 0.0899951\n",
      "[1975]\ttraining's rmse: 0.0851141\tvalid_1's rmse: 0.0899933\n",
      "[2000]\ttraining's rmse: 0.0851091\tvalid_1's rmse: 0.0899912\n",
      "[2025]\ttraining's rmse: 0.0851045\tvalid_1's rmse: 0.0899896\n",
      "[2050]\ttraining's rmse: 0.0850995\tvalid_1's rmse: 0.0899884\n",
      "[2075]\ttraining's rmse: 0.0850967\tvalid_1's rmse: 0.0899871\n",
      "[2100]\ttraining's rmse: 0.0850937\tvalid_1's rmse: 0.0899862\n",
      "[2125]\ttraining's rmse: 0.0850896\tvalid_1's rmse: 0.089985\n",
      "[2150]\ttraining's rmse: 0.0850847\tvalid_1's rmse: 0.0899834\n",
      "[2175]\ttraining's rmse: 0.0850816\tvalid_1's rmse: 0.0899827\n",
      "[2200]\ttraining's rmse: 0.085079\tvalid_1's rmse: 0.0899817\n",
      "[2225]\ttraining's rmse: 0.0850765\tvalid_1's rmse: 0.0899803\n",
      "[2250]\ttraining's rmse: 0.085073\tvalid_1's rmse: 0.0899799\n",
      "[2275]\ttraining's rmse: 0.0850697\tvalid_1's rmse: 0.0899791\n",
      "[2300]\ttraining's rmse: 0.0850672\tvalid_1's rmse: 0.0899782\n",
      "[2325]\ttraining's rmse: 0.0850641\tvalid_1's rmse: 0.0899767\n",
      "[2350]\ttraining's rmse: 0.0850604\tvalid_1's rmse: 0.0899754\n",
      "[2375]\ttraining's rmse: 0.0850562\tvalid_1's rmse: 0.0899743\n",
      "[2400]\ttraining's rmse: 0.0850544\tvalid_1's rmse: 0.0899738\n",
      "[2425]\ttraining's rmse: 0.0850525\tvalid_1's rmse: 0.0899735\n",
      "[2450]\ttraining's rmse: 0.0850502\tvalid_1's rmse: 0.0899726\n",
      "[2475]\ttraining's rmse: 0.0850471\tvalid_1's rmse: 0.0899727\n",
      "[2500]\ttraining's rmse: 0.0850456\tvalid_1's rmse: 0.0899729\n",
      "[2525]\ttraining's rmse: 0.0850429\tvalid_1's rmse: 0.0899722\n",
      "[2550]\ttraining's rmse: 0.0850404\tvalid_1's rmse: 0.0899721\n",
      "[2575]\ttraining's rmse: 0.0850373\tvalid_1's rmse: 0.0899716\n",
      "[2600]\ttraining's rmse: 0.0850357\tvalid_1's rmse: 0.0899709\n",
      "[2625]\ttraining's rmse: 0.0850328\tvalid_1's rmse: 0.0899698\n",
      "[2650]\ttraining's rmse: 0.0850306\tvalid_1's rmse: 0.0899693\n",
      "[2675]\ttraining's rmse: 0.0850286\tvalid_1's rmse: 0.0899682\n",
      "[2700]\ttraining's rmse: 0.0850251\tvalid_1's rmse: 0.0899668\n",
      "[2725]\ttraining's rmse: 0.0850236\tvalid_1's rmse: 0.0899667\n",
      "[2750]\ttraining's rmse: 0.0850227\tvalid_1's rmse: 0.0899663\n",
      "[2775]\ttraining's rmse: 0.0850204\tvalid_1's rmse: 0.0899658\n",
      "[2800]\ttraining's rmse: 0.0850184\tvalid_1's rmse: 0.0899651\n",
      "[2825]\ttraining's rmse: 0.0850163\tvalid_1's rmse: 0.0899646\n",
      "[2850]\ttraining's rmse: 0.0850149\tvalid_1's rmse: 0.0899644\n",
      "[2875]\ttraining's rmse: 0.0850133\tvalid_1's rmse: 0.0899642\n",
      "[2900]\ttraining's rmse: 0.085012\tvalid_1's rmse: 0.0899632\n",
      "[2925]\ttraining's rmse: 0.0850101\tvalid_1's rmse: 0.0899634\n",
      "[2950]\ttraining's rmse: 0.0850078\tvalid_1's rmse: 0.0899635\n",
      "Early stopping, best iteration is:\n",
      "[2903]\ttraining's rmse: 0.0850117\tvalid_1's rmse: 0.0899631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0881471\tvalid_1's rmse: 0.0908947\n",
      "[50]\ttraining's rmse: 0.0880198\tvalid_1's rmse: 0.0908408\n",
      "[75]\ttraining's rmse: 0.0878878\tvalid_1's rmse: 0.0907875\n",
      "[100]\ttraining's rmse: 0.0877667\tvalid_1's rmse: 0.0907395\n",
      "[125]\ttraining's rmse: 0.0876415\tvalid_1's rmse: 0.0906912\n",
      "[150]\ttraining's rmse: 0.0875252\tvalid_1's rmse: 0.0906466\n",
      "[175]\ttraining's rmse: 0.0874297\tvalid_1's rmse: 0.0906102\n",
      "[200]\ttraining's rmse: 0.0873283\tvalid_1's rmse: 0.090574\n",
      "[225]\ttraining's rmse: 0.0872288\tvalid_1's rmse: 0.0905396\n",
      "[250]\ttraining's rmse: 0.0871437\tvalid_1's rmse: 0.0905082\n",
      "[275]\ttraining's rmse: 0.0870653\tvalid_1's rmse: 0.0904819\n",
      "[300]\ttraining's rmse: 0.086988\tvalid_1's rmse: 0.0904561\n",
      "[325]\ttraining's rmse: 0.0869087\tvalid_1's rmse: 0.09043\n",
      "[350]\ttraining's rmse: 0.0868316\tvalid_1's rmse: 0.0904064\n",
      "[375]\ttraining's rmse: 0.0867694\tvalid_1's rmse: 0.0903867\n",
      "[400]\ttraining's rmse: 0.086701\tvalid_1's rmse: 0.0903667\n",
      "[425]\ttraining's rmse: 0.0866384\tvalid_1's rmse: 0.0903474\n",
      "[450]\ttraining's rmse: 0.0865816\tvalid_1's rmse: 0.0903284\n",
      "[475]\ttraining's rmse: 0.0865291\tvalid_1's rmse: 0.0903127\n",
      "[500]\ttraining's rmse: 0.086483\tvalid_1's rmse: 0.0902959\n",
      "[525]\ttraining's rmse: 0.0864229\tvalid_1's rmse: 0.0902789\n",
      "[550]\ttraining's rmse: 0.0863696\tvalid_1's rmse: 0.0902642\n",
      "[575]\ttraining's rmse: 0.0863199\tvalid_1's rmse: 0.0902498\n",
      "[600]\ttraining's rmse: 0.086274\tvalid_1's rmse: 0.0902374\n",
      "[625]\ttraining's rmse: 0.0862366\tvalid_1's rmse: 0.0902265\n",
      "[650]\ttraining's rmse: 0.0861894\tvalid_1's rmse: 0.0902139\n",
      "[675]\ttraining's rmse: 0.0861423\tvalid_1's rmse: 0.0902038\n",
      "[700]\ttraining's rmse: 0.0861002\tvalid_1's rmse: 0.0901935\n",
      "[725]\ttraining's rmse: 0.0860609\tvalid_1's rmse: 0.0901842\n",
      "[750]\ttraining's rmse: 0.086024\tvalid_1's rmse: 0.090175\n",
      "[775]\ttraining's rmse: 0.0859923\tvalid_1's rmse: 0.0901661\n",
      "[800]\ttraining's rmse: 0.0859539\tvalid_1's rmse: 0.0901596\n",
      "[825]\ttraining's rmse: 0.0859209\tvalid_1's rmse: 0.090152\n",
      "[850]\ttraining's rmse: 0.0858864\tvalid_1's rmse: 0.0901463\n",
      "[875]\ttraining's rmse: 0.0858584\tvalid_1's rmse: 0.0901402\n",
      "[900]\ttraining's rmse: 0.0858265\tvalid_1's rmse: 0.090134\n",
      "[925]\ttraining's rmse: 0.0857969\tvalid_1's rmse: 0.0901279\n",
      "[950]\ttraining's rmse: 0.0857699\tvalid_1's rmse: 0.0901226\n",
      "[975]\ttraining's rmse: 0.0857454\tvalid_1's rmse: 0.0901182\n",
      "[1000]\ttraining's rmse: 0.0857215\tvalid_1's rmse: 0.090113\n",
      "[1025]\ttraining's rmse: 0.0856954\tvalid_1's rmse: 0.0901088\n",
      "[1050]\ttraining's rmse: 0.0856737\tvalid_1's rmse: 0.0901046\n",
      "[1075]\ttraining's rmse: 0.0856515\tvalid_1's rmse: 0.0901021\n",
      "[1100]\ttraining's rmse: 0.0856341\tvalid_1's rmse: 0.0900984\n",
      "[1125]\ttraining's rmse: 0.0856124\tvalid_1's rmse: 0.0900948\n",
      "[1150]\ttraining's rmse: 0.0855915\tvalid_1's rmse: 0.0900922\n",
      "[1175]\ttraining's rmse: 0.0855739\tvalid_1's rmse: 0.0900893\n",
      "[1200]\ttraining's rmse: 0.0855555\tvalid_1's rmse: 0.0900869\n",
      "[1225]\ttraining's rmse: 0.0855382\tvalid_1's rmse: 0.0900846\n",
      "[1250]\ttraining's rmse: 0.0855249\tvalid_1's rmse: 0.0900828\n",
      "[1275]\ttraining's rmse: 0.0855053\tvalid_1's rmse: 0.0900812\n",
      "[1300]\ttraining's rmse: 0.0854911\tvalid_1's rmse: 0.0900792\n",
      "[1325]\ttraining's rmse: 0.085477\tvalid_1's rmse: 0.0900776\n",
      "[1350]\ttraining's rmse: 0.085461\tvalid_1's rmse: 0.0900759\n",
      "[1375]\ttraining's rmse: 0.0854487\tvalid_1's rmse: 0.0900747\n",
      "[1400]\ttraining's rmse: 0.0854372\tvalid_1's rmse: 0.090073\n",
      "[1425]\ttraining's rmse: 0.085425\tvalid_1's rmse: 0.0900722\n",
      "[1450]\ttraining's rmse: 0.0854106\tvalid_1's rmse: 0.0900716\n",
      "[1475]\ttraining's rmse: 0.0854004\tvalid_1's rmse: 0.0900704\n",
      "[1500]\ttraining's rmse: 0.085391\tvalid_1's rmse: 0.0900692\n",
      "[1525]\ttraining's rmse: 0.0853793\tvalid_1's rmse: 0.0900683\n",
      "[1550]\ttraining's rmse: 0.085369\tvalid_1's rmse: 0.0900676\n",
      "[1575]\ttraining's rmse: 0.0853606\tvalid_1's rmse: 0.0900663\n",
      "[1600]\ttraining's rmse: 0.0853533\tvalid_1's rmse: 0.0900658\n",
      "[1625]\ttraining's rmse: 0.0853447\tvalid_1's rmse: 0.0900651\n",
      "[1650]\ttraining's rmse: 0.0853351\tvalid_1's rmse: 0.0900644\n",
      "[1675]\ttraining's rmse: 0.0853281\tvalid_1's rmse: 0.0900629\n",
      "[1700]\ttraining's rmse: 0.0853215\tvalid_1's rmse: 0.0900618\n",
      "[1725]\ttraining's rmse: 0.0853148\tvalid_1's rmse: 0.0900612\n",
      "[1750]\ttraining's rmse: 0.0853057\tvalid_1's rmse: 0.0900609\n",
      "[1775]\ttraining's rmse: 0.0852986\tvalid_1's rmse: 0.0900604\n",
      "[1800]\ttraining's rmse: 0.085292\tvalid_1's rmse: 0.0900601\n",
      "[1825]\ttraining's rmse: 0.085286\tvalid_1's rmse: 0.0900598\n",
      "[1850]\ttraining's rmse: 0.0852804\tvalid_1's rmse: 0.090059\n",
      "[1875]\ttraining's rmse: 0.0852744\tvalid_1's rmse: 0.0900584\n",
      "[1900]\ttraining's rmse: 0.085269\tvalid_1's rmse: 0.0900578\n",
      "[1925]\ttraining's rmse: 0.0852639\tvalid_1's rmse: 0.0900573\n",
      "[1950]\ttraining's rmse: 0.0852563\tvalid_1's rmse: 0.0900563\n",
      "[1975]\ttraining's rmse: 0.0852529\tvalid_1's rmse: 0.0900559\n",
      "[2000]\ttraining's rmse: 0.0852483\tvalid_1's rmse: 0.0900554\n",
      "[2025]\ttraining's rmse: 0.0852449\tvalid_1's rmse: 0.0900552\n",
      "[2050]\ttraining's rmse: 0.0852402\tvalid_1's rmse: 0.0900546\n",
      "[2075]\ttraining's rmse: 0.0852358\tvalid_1's rmse: 0.0900536\n",
      "[2100]\ttraining's rmse: 0.0852323\tvalid_1's rmse: 0.0900532\n",
      "[2125]\ttraining's rmse: 0.085229\tvalid_1's rmse: 0.0900529\n",
      "[2150]\ttraining's rmse: 0.0852243\tvalid_1's rmse: 0.0900531\n",
      "[2175]\ttraining's rmse: 0.0852201\tvalid_1's rmse: 0.0900531\n",
      "[2200]\ttraining's rmse: 0.0852167\tvalid_1's rmse: 0.0900534\n",
      "Early stopping, best iteration is:\n",
      "[2160]\ttraining's rmse: 0.0852227\tvalid_1's rmse: 0.0900528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0907985\tvalid_1's rmse: 0.0855016\n",
      "[50]\ttraining's rmse: 0.0906777\tvalid_1's rmse: 0.0854532\n",
      "[75]\ttraining's rmse: 0.0905494\tvalid_1's rmse: 0.0854038\n",
      "[100]\ttraining's rmse: 0.0904352\tvalid_1's rmse: 0.0853627\n",
      "[125]\ttraining's rmse: 0.090317\tvalid_1's rmse: 0.0853201\n",
      "[150]\ttraining's rmse: 0.0902119\tvalid_1's rmse: 0.0852834\n",
      "[175]\ttraining's rmse: 0.0901201\tvalid_1's rmse: 0.0852567\n",
      "[200]\ttraining's rmse: 0.0900172\tvalid_1's rmse: 0.0852241\n",
      "[225]\ttraining's rmse: 0.0899204\tvalid_1's rmse: 0.0851926\n",
      "[250]\ttraining's rmse: 0.0898413\tvalid_1's rmse: 0.0851658\n",
      "[275]\ttraining's rmse: 0.0897676\tvalid_1's rmse: 0.0851409\n",
      "[300]\ttraining's rmse: 0.0896925\tvalid_1's rmse: 0.0851162\n",
      "[325]\ttraining's rmse: 0.0896181\tvalid_1's rmse: 0.0850931\n",
      "[350]\ttraining's rmse: 0.0895463\tvalid_1's rmse: 0.0850706\n",
      "[375]\ttraining's rmse: 0.0894876\tvalid_1's rmse: 0.0850551\n",
      "[400]\ttraining's rmse: 0.0894226\tvalid_1's rmse: 0.0850414\n",
      "[425]\ttraining's rmse: 0.0893626\tvalid_1's rmse: 0.0850253\n",
      "[450]\ttraining's rmse: 0.0893068\tvalid_1's rmse: 0.0850101\n",
      "[475]\ttraining's rmse: 0.0892529\tvalid_1's rmse: 0.0849952\n",
      "[500]\ttraining's rmse: 0.0892087\tvalid_1's rmse: 0.0849844\n",
      "[525]\ttraining's rmse: 0.0891503\tvalid_1's rmse: 0.0849695\n",
      "[550]\ttraining's rmse: 0.0890967\tvalid_1's rmse: 0.0849557\n",
      "[575]\ttraining's rmse: 0.0890476\tvalid_1's rmse: 0.0849504\n",
      "[600]\ttraining's rmse: 0.0889979\tvalid_1's rmse: 0.0849455\n",
      "[625]\ttraining's rmse: 0.0889581\tvalid_1's rmse: 0.0849353\n",
      "[650]\ttraining's rmse: 0.0889091\tvalid_1's rmse: 0.0849402\n",
      "[675]\ttraining's rmse: 0.0888605\tvalid_1's rmse: 0.0849352\n",
      "[700]\ttraining's rmse: 0.0888182\tvalid_1's rmse: 0.084932\n",
      "[725]\ttraining's rmse: 0.0887794\tvalid_1's rmse: 0.0849368\n",
      "[750]\ttraining's rmse: 0.0887439\tvalid_1's rmse: 0.0849294\n",
      "[775]\ttraining's rmse: 0.0887142\tvalid_1's rmse: 0.0849294\n",
      "[800]\ttraining's rmse: 0.0886744\tvalid_1's rmse: 0.0849234\n",
      "[825]\ttraining's rmse: 0.0886423\tvalid_1's rmse: 0.0849182\n",
      "[850]\ttraining's rmse: 0.0886096\tvalid_1's rmse: 0.0849127\n",
      "[875]\ttraining's rmse: 0.0885794\tvalid_1's rmse: 0.0849216\n",
      "[900]\ttraining's rmse: 0.0885444\tvalid_1's rmse: 0.0849231\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's rmse: 0.0886014\tvalid_1's rmse: 0.0849114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0895322\tvalid_1's rmse: 0.0918154\n",
      "[50]\ttraining's rmse: 0.0893859\tvalid_1's rmse: 0.0917597\n",
      "[75]\ttraining's rmse: 0.0892373\tvalid_1's rmse: 0.091704\n",
      "[100]\ttraining's rmse: 0.0890979\tvalid_1's rmse: 0.0916546\n",
      "[125]\ttraining's rmse: 0.0889629\tvalid_1's rmse: 0.0916044\n",
      "[150]\ttraining's rmse: 0.0888338\tvalid_1's rmse: 0.0915572\n",
      "[175]\ttraining's rmse: 0.0887309\tvalid_1's rmse: 0.0915197\n",
      "[200]\ttraining's rmse: 0.0886182\tvalid_1's rmse: 0.0914801\n",
      "[225]\ttraining's rmse: 0.0885086\tvalid_1's rmse: 0.0914424\n",
      "[250]\ttraining's rmse: 0.0884167\tvalid_1's rmse: 0.0914085\n",
      "[275]\ttraining's rmse: 0.0883275\tvalid_1's rmse: 0.0913761\n",
      "[300]\ttraining's rmse: 0.0882398\tvalid_1's rmse: 0.0913468\n",
      "[325]\ttraining's rmse: 0.0881562\tvalid_1's rmse: 0.0913194\n",
      "[350]\ttraining's rmse: 0.0880747\tvalid_1's rmse: 0.0912924\n",
      "[375]\ttraining's rmse: 0.0880044\tvalid_1's rmse: 0.0912696\n",
      "[400]\ttraining's rmse: 0.0879282\tvalid_1's rmse: 0.0912462\n",
      "[425]\ttraining's rmse: 0.0878586\tvalid_1's rmse: 0.0912246\n",
      "[450]\ttraining's rmse: 0.0877962\tvalid_1's rmse: 0.0912049\n",
      "[475]\ttraining's rmse: 0.0877405\tvalid_1's rmse: 0.0911866\n",
      "[500]\ttraining's rmse: 0.0876892\tvalid_1's rmse: 0.0911707\n",
      "[525]\ttraining's rmse: 0.0876272\tvalid_1's rmse: 0.0911526\n",
      "[550]\ttraining's rmse: 0.087572\tvalid_1's rmse: 0.0911345\n",
      "[575]\ttraining's rmse: 0.0875198\tvalid_1's rmse: 0.0911204\n",
      "[600]\ttraining's rmse: 0.0874672\tvalid_1's rmse: 0.0911069\n",
      "[625]\ttraining's rmse: 0.0874258\tvalid_1's rmse: 0.0910936\n",
      "[650]\ttraining's rmse: 0.0873797\tvalid_1's rmse: 0.0910801\n",
      "[675]\ttraining's rmse: 0.0873319\tvalid_1's rmse: 0.0910664\n",
      "[700]\ttraining's rmse: 0.0872901\tvalid_1's rmse: 0.0910528\n",
      "[725]\ttraining's rmse: 0.0872507\tvalid_1's rmse: 0.0910421\n",
      "[750]\ttraining's rmse: 0.0872131\tvalid_1's rmse: 0.0910319\n",
      "[775]\ttraining's rmse: 0.0871813\tvalid_1's rmse: 0.0910211\n",
      "[800]\ttraining's rmse: 0.0871426\tvalid_1's rmse: 0.0910109\n",
      "[825]\ttraining's rmse: 0.087112\tvalid_1's rmse: 0.0910009\n",
      "[850]\ttraining's rmse: 0.0870756\tvalid_1's rmse: 0.0909914\n",
      "[875]\ttraining's rmse: 0.0870441\tvalid_1's rmse: 0.0909825\n",
      "[900]\ttraining's rmse: 0.0870108\tvalid_1's rmse: 0.0909743\n",
      "[925]\ttraining's rmse: 0.0869814\tvalid_1's rmse: 0.090965\n",
      "[950]\ttraining's rmse: 0.0869549\tvalid_1's rmse: 0.0909581\n",
      "[975]\ttraining's rmse: 0.0869322\tvalid_1's rmse: 0.0909516\n",
      "[1000]\ttraining's rmse: 0.0869068\tvalid_1's rmse: 0.0909449\n",
      "[1025]\ttraining's rmse: 0.0868806\tvalid_1's rmse: 0.0909367\n",
      "[1050]\ttraining's rmse: 0.0868566\tvalid_1's rmse: 0.0909286\n",
      "[1075]\ttraining's rmse: 0.0868329\tvalid_1's rmse: 0.0909237\n",
      "[1100]\ttraining's rmse: 0.0868141\tvalid_1's rmse: 0.0909194\n",
      "[1125]\ttraining's rmse: 0.0867937\tvalid_1's rmse: 0.0909126\n",
      "[1150]\ttraining's rmse: 0.0867719\tvalid_1's rmse: 0.0909061\n",
      "[1175]\ttraining's rmse: 0.0867517\tvalid_1's rmse: 0.0909017\n",
      "[1200]\ttraining's rmse: 0.0867348\tvalid_1's rmse: 0.090897\n",
      "[1225]\ttraining's rmse: 0.0867181\tvalid_1's rmse: 0.0908927\n",
      "[1250]\ttraining's rmse: 0.0867007\tvalid_1's rmse: 0.0908892\n",
      "[1275]\ttraining's rmse: 0.0866814\tvalid_1's rmse: 0.0908855\n",
      "[1300]\ttraining's rmse: 0.086666\tvalid_1's rmse: 0.0908813\n",
      "[1325]\ttraining's rmse: 0.0866502\tvalid_1's rmse: 0.0908779\n",
      "[1350]\ttraining's rmse: 0.0866341\tvalid_1's rmse: 0.0908743\n",
      "[1375]\ttraining's rmse: 0.0866203\tvalid_1's rmse: 0.0908701\n",
      "[1400]\ttraining's rmse: 0.0866102\tvalid_1's rmse: 0.090867\n",
      "[1425]\ttraining's rmse: 0.0865928\tvalid_1's rmse: 0.0908638\n",
      "[1450]\ttraining's rmse: 0.0865767\tvalid_1's rmse: 0.090861\n",
      "[1475]\ttraining's rmse: 0.0865638\tvalid_1's rmse: 0.0908575\n",
      "[1500]\ttraining's rmse: 0.086552\tvalid_1's rmse: 0.090855\n",
      "[1525]\ttraining's rmse: 0.0865398\tvalid_1's rmse: 0.0908517\n",
      "[1550]\ttraining's rmse: 0.0865283\tvalid_1's rmse: 0.0908497\n",
      "[1575]\ttraining's rmse: 0.0865166\tvalid_1's rmse: 0.0908462\n",
      "[1600]\ttraining's rmse: 0.0865062\tvalid_1's rmse: 0.0908425\n",
      "[1625]\ttraining's rmse: 0.0864955\tvalid_1's rmse: 0.0908398\n",
      "[1650]\ttraining's rmse: 0.0864854\tvalid_1's rmse: 0.0908359\n",
      "[1675]\ttraining's rmse: 0.0864779\tvalid_1's rmse: 0.0908323\n",
      "[1700]\ttraining's rmse: 0.0864697\tvalid_1's rmse: 0.0908297\n",
      "[1725]\ttraining's rmse: 0.0864605\tvalid_1's rmse: 0.090828\n",
      "[1750]\ttraining's rmse: 0.0864514\tvalid_1's rmse: 0.0908253\n",
      "[1775]\ttraining's rmse: 0.0864442\tvalid_1's rmse: 0.0908229\n",
      "[1800]\ttraining's rmse: 0.086438\tvalid_1's rmse: 0.0908208\n",
      "[1825]\ttraining's rmse: 0.086431\tvalid_1's rmse: 0.0908192\n",
      "[1850]\ttraining's rmse: 0.0864264\tvalid_1's rmse: 0.0908173\n",
      "[1875]\ttraining's rmse: 0.0864194\tvalid_1's rmse: 0.0908154\n",
      "[1900]\ttraining's rmse: 0.0864133\tvalid_1's rmse: 0.0908138\n",
      "[1925]\ttraining's rmse: 0.0864085\tvalid_1's rmse: 0.0908133\n",
      "[1950]\ttraining's rmse: 0.0864032\tvalid_1's rmse: 0.0908106\n",
      "[1975]\ttraining's rmse: 0.0863987\tvalid_1's rmse: 0.0908093\n",
      "[2000]\ttraining's rmse: 0.0863931\tvalid_1's rmse: 0.0908083\n",
      "[2025]\ttraining's rmse: 0.0863873\tvalid_1's rmse: 0.0908066\n",
      "[2050]\ttraining's rmse: 0.0863826\tvalid_1's rmse: 0.0908052\n",
      "[2075]\ttraining's rmse: 0.0863791\tvalid_1's rmse: 0.0908037\n",
      "[2100]\ttraining's rmse: 0.086375\tvalid_1's rmse: 0.0908024\n",
      "[2125]\ttraining's rmse: 0.0863708\tvalid_1's rmse: 0.0908015\n",
      "[2150]\ttraining's rmse: 0.0863672\tvalid_1's rmse: 0.0908007\n",
      "[2175]\ttraining's rmse: 0.086364\tvalid_1's rmse: 0.0907993\n",
      "[2200]\ttraining's rmse: 0.0863603\tvalid_1's rmse: 0.0907975\n",
      "[2225]\ttraining's rmse: 0.086357\tvalid_1's rmse: 0.0907962\n",
      "[2250]\ttraining's rmse: 0.0863545\tvalid_1's rmse: 0.0907953\n",
      "[2275]\ttraining's rmse: 0.0863511\tvalid_1's rmse: 0.0907935\n",
      "[2300]\ttraining's rmse: 0.0863461\tvalid_1's rmse: 0.0907923\n",
      "[2325]\ttraining's rmse: 0.0863425\tvalid_1's rmse: 0.090791\n",
      "[2350]\ttraining's rmse: 0.0863388\tvalid_1's rmse: 0.09079\n",
      "[2375]\ttraining's rmse: 0.086336\tvalid_1's rmse: 0.0907892\n",
      "[2400]\ttraining's rmse: 0.0863328\tvalid_1's rmse: 0.0907888\n",
      "[2425]\ttraining's rmse: 0.086331\tvalid_1's rmse: 0.0907886\n",
      "[2450]\ttraining's rmse: 0.086328\tvalid_1's rmse: 0.0907877\n",
      "[2475]\ttraining's rmse: 0.086324\tvalid_1's rmse: 0.0907866\n",
      "[2500]\ttraining's rmse: 0.0863208\tvalid_1's rmse: 0.0907858\n",
      "[2525]\ttraining's rmse: 0.086318\tvalid_1's rmse: 0.0907854\n",
      "[2550]\ttraining's rmse: 0.0863151\tvalid_1's rmse: 0.0907849\n",
      "[2575]\ttraining's rmse: 0.0863137\tvalid_1's rmse: 0.0907849\n",
      "[2600]\ttraining's rmse: 0.0863091\tvalid_1's rmse: 0.0907842\n",
      "[2625]\ttraining's rmse: 0.0863074\tvalid_1's rmse: 0.0907834\n",
      "[2650]\ttraining's rmse: 0.0863047\tvalid_1's rmse: 0.090782\n",
      "[2675]\ttraining's rmse: 0.0863026\tvalid_1's rmse: 0.0907811\n",
      "[2700]\ttraining's rmse: 0.0863009\tvalid_1's rmse: 0.0907803\n",
      "[2725]\ttraining's rmse: 0.0862978\tvalid_1's rmse: 0.0907796\n",
      "[2750]\ttraining's rmse: 0.0862962\tvalid_1's rmse: 0.0907782\n",
      "[2775]\ttraining's rmse: 0.086294\tvalid_1's rmse: 0.0907778\n",
      "[2800]\ttraining's rmse: 0.0862917\tvalid_1's rmse: 0.0907773\n",
      "[2825]\ttraining's rmse: 0.0862902\tvalid_1's rmse: 0.0907772\n",
      "[2850]\ttraining's rmse: 0.0862882\tvalid_1's rmse: 0.0907776\n",
      "Early stopping, best iteration is:\n",
      "[2823]\ttraining's rmse: 0.0862903\tvalid_1's rmse: 0.0907771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0893754\tvalid_1's rmse: 0.0921377\n",
      "[50]\ttraining's rmse: 0.0892435\tvalid_1's rmse: 0.0920844\n",
      "[75]\ttraining's rmse: 0.0891034\tvalid_1's rmse: 0.092028\n",
      "[100]\ttraining's rmse: 0.088981\tvalid_1's rmse: 0.091979\n",
      "[125]\ttraining's rmse: 0.0888539\tvalid_1's rmse: 0.0919309\n",
      "[150]\ttraining's rmse: 0.088739\tvalid_1's rmse: 0.0918864\n",
      "[175]\ttraining's rmse: 0.088642\tvalid_1's rmse: 0.0918502\n",
      "[200]\ttraining's rmse: 0.0885329\tvalid_1's rmse: 0.0918127\n",
      "[225]\ttraining's rmse: 0.0884308\tvalid_1's rmse: 0.0917779\n",
      "[250]\ttraining's rmse: 0.0883425\tvalid_1's rmse: 0.0917442\n",
      "[275]\ttraining's rmse: 0.0882603\tvalid_1's rmse: 0.0917147\n",
      "[300]\ttraining's rmse: 0.0881784\tvalid_1's rmse: 0.0916874\n",
      "[325]\ttraining's rmse: 0.0880959\tvalid_1's rmse: 0.0916612\n",
      "[350]\ttraining's rmse: 0.0880187\tvalid_1's rmse: 0.0916374\n",
      "[375]\ttraining's rmse: 0.0879536\tvalid_1's rmse: 0.0916162\n",
      "[400]\ttraining's rmse: 0.0878813\tvalid_1's rmse: 0.0915925\n",
      "[425]\ttraining's rmse: 0.0878186\tvalid_1's rmse: 0.091573\n",
      "[450]\ttraining's rmse: 0.0877571\tvalid_1's rmse: 0.0915536\n",
      "[475]\ttraining's rmse: 0.0877035\tvalid_1's rmse: 0.0915362\n",
      "[500]\ttraining's rmse: 0.0876558\tvalid_1's rmse: 0.09152\n",
      "[525]\ttraining's rmse: 0.0875936\tvalid_1's rmse: 0.0915037\n",
      "[550]\ttraining's rmse: 0.0875368\tvalid_1's rmse: 0.0914885\n",
      "[575]\ttraining's rmse: 0.087484\tvalid_1's rmse: 0.0914741\n",
      "[600]\ttraining's rmse: 0.0874355\tvalid_1's rmse: 0.0914615\n",
      "[625]\ttraining's rmse: 0.0873958\tvalid_1's rmse: 0.0914501\n",
      "[650]\ttraining's rmse: 0.0873457\tvalid_1's rmse: 0.091437\n",
      "[675]\ttraining's rmse: 0.0872957\tvalid_1's rmse: 0.0914263\n",
      "[700]\ttraining's rmse: 0.0872531\tvalid_1's rmse: 0.0914158\n",
      "[725]\ttraining's rmse: 0.0872116\tvalid_1's rmse: 0.091406\n",
      "[750]\ttraining's rmse: 0.0871745\tvalid_1's rmse: 0.0913969\n",
      "[775]\ttraining's rmse: 0.0871428\tvalid_1's rmse: 0.0913881\n",
      "[800]\ttraining's rmse: 0.0871018\tvalid_1's rmse: 0.09138\n",
      "[825]\ttraining's rmse: 0.0870685\tvalid_1's rmse: 0.0913728\n",
      "[850]\ttraining's rmse: 0.0870349\tvalid_1's rmse: 0.091366\n",
      "[875]\ttraining's rmse: 0.0870053\tvalid_1's rmse: 0.0913591\n",
      "[900]\ttraining's rmse: 0.0869731\tvalid_1's rmse: 0.0913521\n",
      "[925]\ttraining's rmse: 0.0869425\tvalid_1's rmse: 0.0913456\n",
      "[950]\ttraining's rmse: 0.0869144\tvalid_1's rmse: 0.0913404\n",
      "[975]\ttraining's rmse: 0.0868897\tvalid_1's rmse: 0.0913351\n",
      "[1000]\ttraining's rmse: 0.0868653\tvalid_1's rmse: 0.0913306\n",
      "[1025]\ttraining's rmse: 0.0868374\tvalid_1's rmse: 0.0913256\n",
      "[1050]\ttraining's rmse: 0.0868122\tvalid_1's rmse: 0.0913207\n",
      "[1075]\ttraining's rmse: 0.0867857\tvalid_1's rmse: 0.0913168\n",
      "[1100]\ttraining's rmse: 0.0867658\tvalid_1's rmse: 0.0913132\n",
      "[1125]\ttraining's rmse: 0.0867436\tvalid_1's rmse: 0.0913098\n",
      "[1150]\ttraining's rmse: 0.086722\tvalid_1's rmse: 0.0913075\n",
      "[1175]\ttraining's rmse: 0.0867018\tvalid_1's rmse: 0.0913051\n",
      "[1200]\ttraining's rmse: 0.0866811\tvalid_1's rmse: 0.0913019\n",
      "[1225]\ttraining's rmse: 0.0866615\tvalid_1's rmse: 0.0912998\n",
      "[1250]\ttraining's rmse: 0.0866462\tvalid_1's rmse: 0.0912982\n",
      "[1275]\ttraining's rmse: 0.0866247\tvalid_1's rmse: 0.0912964\n",
      "[1300]\ttraining's rmse: 0.086609\tvalid_1's rmse: 0.0912944\n",
      "[1325]\ttraining's rmse: 0.0865909\tvalid_1's rmse: 0.0912926\n",
      "[1350]\ttraining's rmse: 0.0865738\tvalid_1's rmse: 0.0912912\n",
      "[1375]\ttraining's rmse: 0.0865577\tvalid_1's rmse: 0.0912898\n",
      "[1400]\ttraining's rmse: 0.0865453\tvalid_1's rmse: 0.0912876\n",
      "[1425]\ttraining's rmse: 0.0865313\tvalid_1's rmse: 0.0912866\n",
      "[1450]\ttraining's rmse: 0.0865183\tvalid_1's rmse: 0.0912858\n",
      "[1475]\ttraining's rmse: 0.0865059\tvalid_1's rmse: 0.0912846\n",
      "[1500]\ttraining's rmse: 0.0864939\tvalid_1's rmse: 0.0912833\n",
      "[1525]\ttraining's rmse: 0.0864812\tvalid_1's rmse: 0.0912817\n",
      "[1550]\ttraining's rmse: 0.0864693\tvalid_1's rmse: 0.091281\n",
      "[1575]\ttraining's rmse: 0.086458\tvalid_1's rmse: 0.0912793\n",
      "[1600]\ttraining's rmse: 0.0864473\tvalid_1's rmse: 0.0912787\n",
      "[1625]\ttraining's rmse: 0.0864361\tvalid_1's rmse: 0.0912768\n",
      "[1650]\ttraining's rmse: 0.0864261\tvalid_1's rmse: 0.091276\n",
      "[1675]\ttraining's rmse: 0.086419\tvalid_1's rmse: 0.0912747\n",
      "[1700]\ttraining's rmse: 0.0864118\tvalid_1's rmse: 0.0912739\n",
      "[1725]\ttraining's rmse: 0.0864032\tvalid_1's rmse: 0.091273\n",
      "[1750]\ttraining's rmse: 0.0863944\tvalid_1's rmse: 0.0912724\n",
      "[1775]\ttraining's rmse: 0.0863874\tvalid_1's rmse: 0.0912723\n",
      "[1800]\ttraining's rmse: 0.0863793\tvalid_1's rmse: 0.0912723\n",
      "[1825]\ttraining's rmse: 0.0863727\tvalid_1's rmse: 0.0912718\n",
      "[1850]\ttraining's rmse: 0.086367\tvalid_1's rmse: 0.0912714\n",
      "[1875]\ttraining's rmse: 0.0863624\tvalid_1's rmse: 0.0912714\n",
      "[1900]\ttraining's rmse: 0.0863557\tvalid_1's rmse: 0.0912712\n",
      "[1925]\ttraining's rmse: 0.0863502\tvalid_1's rmse: 0.0912711\n",
      "[1950]\ttraining's rmse: 0.0863442\tvalid_1's rmse: 0.0912701\n",
      "[1975]\ttraining's rmse: 0.0863399\tvalid_1's rmse: 0.0912699\n",
      "[2000]\ttraining's rmse: 0.0863334\tvalid_1's rmse: 0.0912695\n",
      "[2025]\ttraining's rmse: 0.0863292\tvalid_1's rmse: 0.091269\n",
      "[2050]\ttraining's rmse: 0.0863254\tvalid_1's rmse: 0.0912691\n",
      "[2075]\ttraining's rmse: 0.0863217\tvalid_1's rmse: 0.0912686\n",
      "[2100]\ttraining's rmse: 0.0863171\tvalid_1's rmse: 0.0912683\n",
      "[2125]\ttraining's rmse: 0.0863131\tvalid_1's rmse: 0.0912682\n",
      "[2150]\ttraining's rmse: 0.0863077\tvalid_1's rmse: 0.0912685\n",
      "Early stopping, best iteration is:\n",
      "[2124]\ttraining's rmse: 0.0863131\tvalid_1's rmse: 0.0912682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0918406\tvalid_1's rmse: 0.0871399\n",
      "[50]\ttraining's rmse: 0.0917127\tvalid_1's rmse: 0.0870901\n",
      "[75]\ttraining's rmse: 0.0915759\tvalid_1's rmse: 0.0870397\n",
      "[100]\ttraining's rmse: 0.0914551\tvalid_1's rmse: 0.0869975\n",
      "[125]\ttraining's rmse: 0.0913255\tvalid_1's rmse: 0.0869541\n",
      "[150]\ttraining's rmse: 0.0912085\tvalid_1's rmse: 0.0869135\n",
      "[175]\ttraining's rmse: 0.0911143\tvalid_1's rmse: 0.0868817\n",
      "[200]\ttraining's rmse: 0.0910081\tvalid_1's rmse: 0.0868481\n",
      "[225]\ttraining's rmse: 0.0909044\tvalid_1's rmse: 0.0868155\n",
      "[250]\ttraining's rmse: 0.0908175\tvalid_1's rmse: 0.0867882\n",
      "[275]\ttraining's rmse: 0.0907407\tvalid_1's rmse: 0.0867628\n",
      "[300]\ttraining's rmse: 0.0906616\tvalid_1's rmse: 0.0867407\n",
      "[325]\ttraining's rmse: 0.0905809\tvalid_1's rmse: 0.0867183\n",
      "[350]\ttraining's rmse: 0.0905047\tvalid_1's rmse: 0.0866958\n",
      "[375]\ttraining's rmse: 0.0904409\tvalid_1's rmse: 0.0866771\n",
      "[400]\ttraining's rmse: 0.0903693\tvalid_1's rmse: 0.0866616\n",
      "[425]\ttraining's rmse: 0.0903038\tvalid_1's rmse: 0.0866497\n",
      "[450]\ttraining's rmse: 0.0902464\tvalid_1's rmse: 0.0866336\n",
      "[475]\ttraining's rmse: 0.0901911\tvalid_1's rmse: 0.0866241\n",
      "[500]\ttraining's rmse: 0.0901437\tvalid_1's rmse: 0.0866127\n",
      "[525]\ttraining's rmse: 0.0900822\tvalid_1's rmse: 0.0865982\n",
      "[550]\ttraining's rmse: 0.0900261\tvalid_1's rmse: 0.0865861\n",
      "[575]\ttraining's rmse: 0.0899749\tvalid_1's rmse: 0.0865782\n",
      "[600]\ttraining's rmse: 0.0899235\tvalid_1's rmse: 0.0865696\n",
      "[625]\ttraining's rmse: 0.0898828\tvalid_1's rmse: 0.0865638\n",
      "[650]\ttraining's rmse: 0.0898321\tvalid_1's rmse: 0.0865602\n",
      "[675]\ttraining's rmse: 0.0897798\tvalid_1's rmse: 0.0865567\n",
      "[700]\ttraining's rmse: 0.0897341\tvalid_1's rmse: 0.0865474\n",
      "[725]\ttraining's rmse: 0.0896909\tvalid_1's rmse: 0.0865451\n",
      "[750]\ttraining's rmse: 0.0896537\tvalid_1's rmse: 0.0865419\n",
      "[775]\ttraining's rmse: 0.0896198\tvalid_1's rmse: 0.086549\n",
      "[800]\ttraining's rmse: 0.089578\tvalid_1's rmse: 0.0865442\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's rmse: 0.0896518\tvalid_1's rmse: 0.0865416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.088607\tvalid_1's rmse: 0.0913689\n",
      "[50]\ttraining's rmse: 0.088464\tvalid_1's rmse: 0.0913151\n",
      "[75]\ttraining's rmse: 0.0883158\tvalid_1's rmse: 0.0912607\n",
      "[100]\ttraining's rmse: 0.0881807\tvalid_1's rmse: 0.091214\n",
      "[125]\ttraining's rmse: 0.0880422\tvalid_1's rmse: 0.0911669\n",
      "[150]\ttraining's rmse: 0.0879159\tvalid_1's rmse: 0.0911214\n",
      "[175]\ttraining's rmse: 0.0878134\tvalid_1's rmse: 0.0910835\n",
      "[200]\ttraining's rmse: 0.087704\tvalid_1's rmse: 0.0910464\n",
      "[225]\ttraining's rmse: 0.0875962\tvalid_1's rmse: 0.0910091\n",
      "[250]\ttraining's rmse: 0.087507\tvalid_1's rmse: 0.0909736\n",
      "[275]\ttraining's rmse: 0.0874188\tvalid_1's rmse: 0.0909446\n",
      "[300]\ttraining's rmse: 0.0873328\tvalid_1's rmse: 0.0909155\n",
      "[325]\ttraining's rmse: 0.0872489\tvalid_1's rmse: 0.0908886\n",
      "[350]\ttraining's rmse: 0.0871688\tvalid_1's rmse: 0.090863\n",
      "[375]\ttraining's rmse: 0.0870982\tvalid_1's rmse: 0.0908418\n",
      "[400]\ttraining's rmse: 0.0870277\tvalid_1's rmse: 0.0908204\n",
      "[425]\ttraining's rmse: 0.0869613\tvalid_1's rmse: 0.0907989\n",
      "[450]\ttraining's rmse: 0.0868984\tvalid_1's rmse: 0.0907791\n",
      "[475]\ttraining's rmse: 0.0868429\tvalid_1's rmse: 0.09076\n",
      "[500]\ttraining's rmse: 0.0867959\tvalid_1's rmse: 0.0907424\n",
      "[525]\ttraining's rmse: 0.086734\tvalid_1's rmse: 0.0907247\n",
      "[550]\ttraining's rmse: 0.0866786\tvalid_1's rmse: 0.0907082\n",
      "[575]\ttraining's rmse: 0.0866269\tvalid_1's rmse: 0.0906934\n",
      "[600]\ttraining's rmse: 0.0865774\tvalid_1's rmse: 0.0906797\n",
      "[625]\ttraining's rmse: 0.0865342\tvalid_1's rmse: 0.0906677\n",
      "[650]\ttraining's rmse: 0.086487\tvalid_1's rmse: 0.0906543\n",
      "[675]\ttraining's rmse: 0.0864416\tvalid_1's rmse: 0.0906413\n",
      "[700]\ttraining's rmse: 0.0864\tvalid_1's rmse: 0.090629\n",
      "[725]\ttraining's rmse: 0.0863615\tvalid_1's rmse: 0.0906187\n",
      "[750]\ttraining's rmse: 0.0863225\tvalid_1's rmse: 0.0906083\n",
      "[775]\ttraining's rmse: 0.0862916\tvalid_1's rmse: 0.0905973\n",
      "[800]\ttraining's rmse: 0.0862538\tvalid_1's rmse: 0.0905884\n",
      "[825]\ttraining's rmse: 0.0862186\tvalid_1's rmse: 0.0905793\n",
      "[850]\ttraining's rmse: 0.0861842\tvalid_1's rmse: 0.0905723\n",
      "[875]\ttraining's rmse: 0.0861542\tvalid_1's rmse: 0.0905644\n",
      "[900]\ttraining's rmse: 0.0861206\tvalid_1's rmse: 0.0905559\n",
      "[925]\ttraining's rmse: 0.0860945\tvalid_1's rmse: 0.0905483\n",
      "[950]\ttraining's rmse: 0.0860677\tvalid_1's rmse: 0.0905409\n",
      "[975]\ttraining's rmse: 0.0860437\tvalid_1's rmse: 0.0905329\n",
      "[1000]\ttraining's rmse: 0.086016\tvalid_1's rmse: 0.0905249\n",
      "[1025]\ttraining's rmse: 0.0859895\tvalid_1's rmse: 0.0905193\n",
      "[1050]\ttraining's rmse: 0.0859655\tvalid_1's rmse: 0.0905119\n",
      "[1075]\ttraining's rmse: 0.0859443\tvalid_1's rmse: 0.090508\n",
      "[1100]\ttraining's rmse: 0.0859251\tvalid_1's rmse: 0.0905025\n",
      "[1125]\ttraining's rmse: 0.0859061\tvalid_1's rmse: 0.0904967\n",
      "[1150]\ttraining's rmse: 0.0858846\tvalid_1's rmse: 0.0904914\n",
      "[1175]\ttraining's rmse: 0.0858671\tvalid_1's rmse: 0.0904875\n",
      "[1200]\ttraining's rmse: 0.0858495\tvalid_1's rmse: 0.0904823\n",
      "[1225]\ttraining's rmse: 0.0858325\tvalid_1's rmse: 0.0904775\n",
      "[1250]\ttraining's rmse: 0.0858154\tvalid_1's rmse: 0.0904727\n",
      "[1275]\ttraining's rmse: 0.0857954\tvalid_1's rmse: 0.0904691\n",
      "[1300]\ttraining's rmse: 0.0857794\tvalid_1's rmse: 0.0904642\n",
      "[1325]\ttraining's rmse: 0.0857641\tvalid_1's rmse: 0.090461\n",
      "[1350]\ttraining's rmse: 0.0857491\tvalid_1's rmse: 0.0904578\n",
      "[1375]\ttraining's rmse: 0.0857335\tvalid_1's rmse: 0.0904542\n",
      "[1400]\ttraining's rmse: 0.0857232\tvalid_1's rmse: 0.090451\n",
      "[1425]\ttraining's rmse: 0.0857067\tvalid_1's rmse: 0.0904502\n",
      "[1450]\ttraining's rmse: 0.0856919\tvalid_1's rmse: 0.0904464\n",
      "[1475]\ttraining's rmse: 0.0856817\tvalid_1's rmse: 0.0904435\n",
      "[1500]\ttraining's rmse: 0.0856721\tvalid_1's rmse: 0.0904402\n",
      "[1525]\ttraining's rmse: 0.0856605\tvalid_1's rmse: 0.0904375\n",
      "[1550]\ttraining's rmse: 0.085647\tvalid_1's rmse: 0.090435\n",
      "[1575]\ttraining's rmse: 0.0856353\tvalid_1's rmse: 0.0904332\n",
      "[1600]\ttraining's rmse: 0.0856291\tvalid_1's rmse: 0.0904306\n",
      "[1625]\ttraining's rmse: 0.0856202\tvalid_1's rmse: 0.0904275\n",
      "[1650]\ttraining's rmse: 0.0856116\tvalid_1's rmse: 0.0904233\n",
      "[1675]\ttraining's rmse: 0.0856049\tvalid_1's rmse: 0.0904208\n",
      "[1700]\ttraining's rmse: 0.0855983\tvalid_1's rmse: 0.0904189\n",
      "[1725]\ttraining's rmse: 0.0855918\tvalid_1's rmse: 0.0904177\n",
      "[1750]\ttraining's rmse: 0.0855838\tvalid_1's rmse: 0.0904145\n",
      "[1775]\ttraining's rmse: 0.0855771\tvalid_1's rmse: 0.0904127\n",
      "[1800]\ttraining's rmse: 0.0855704\tvalid_1's rmse: 0.0904097\n",
      "[1825]\ttraining's rmse: 0.0855647\tvalid_1's rmse: 0.0904077\n",
      "[1850]\ttraining's rmse: 0.0855585\tvalid_1's rmse: 0.090405\n",
      "[1875]\ttraining's rmse: 0.0855522\tvalid_1's rmse: 0.0904036\n",
      "[1900]\ttraining's rmse: 0.0855477\tvalid_1's rmse: 0.0904022\n",
      "[1925]\ttraining's rmse: 0.0855426\tvalid_1's rmse: 0.0904006\n",
      "[1950]\ttraining's rmse: 0.0855394\tvalid_1's rmse: 0.0903976\n",
      "[1975]\ttraining's rmse: 0.0855355\tvalid_1's rmse: 0.0903969\n",
      "[2000]\ttraining's rmse: 0.08553\tvalid_1's rmse: 0.0903953\n",
      "[2025]\ttraining's rmse: 0.0855258\tvalid_1's rmse: 0.0903929\n",
      "[2050]\ttraining's rmse: 0.0855217\tvalid_1's rmse: 0.0903924\n",
      "[2075]\ttraining's rmse: 0.0855187\tvalid_1's rmse: 0.0903912\n",
      "[2100]\ttraining's rmse: 0.0855146\tvalid_1's rmse: 0.0903902\n",
      "[2125]\ttraining's rmse: 0.0855109\tvalid_1's rmse: 0.0903889\n",
      "[2150]\ttraining's rmse: 0.0855074\tvalid_1's rmse: 0.0903871\n",
      "[2175]\ttraining's rmse: 0.0855048\tvalid_1's rmse: 0.0903868\n",
      "[2200]\ttraining's rmse: 0.085501\tvalid_1's rmse: 0.0903854\n",
      "[2225]\ttraining's rmse: 0.0854986\tvalid_1's rmse: 0.0903847\n",
      "[2250]\ttraining's rmse: 0.0854942\tvalid_1's rmse: 0.0903837\n",
      "[2275]\ttraining's rmse: 0.0854919\tvalid_1's rmse: 0.0903834\n",
      "[2300]\ttraining's rmse: 0.0854877\tvalid_1's rmse: 0.0903824\n",
      "[2325]\ttraining's rmse: 0.0854842\tvalid_1's rmse: 0.0903808\n",
      "[2350]\ttraining's rmse: 0.0854815\tvalid_1's rmse: 0.0903798\n",
      "[2375]\ttraining's rmse: 0.0854773\tvalid_1's rmse: 0.0903784\n",
      "[2400]\ttraining's rmse: 0.0854733\tvalid_1's rmse: 0.0903776\n",
      "[2425]\ttraining's rmse: 0.085471\tvalid_1's rmse: 0.0903771\n",
      "[2450]\ttraining's rmse: 0.0854682\tvalid_1's rmse: 0.0903762\n",
      "[2475]\ttraining's rmse: 0.0854652\tvalid_1's rmse: 0.0903749\n",
      "[2500]\ttraining's rmse: 0.0854621\tvalid_1's rmse: 0.0903748\n",
      "[2525]\ttraining's rmse: 0.0854578\tvalid_1's rmse: 0.0903743\n",
      "[2550]\ttraining's rmse: 0.0854554\tvalid_1's rmse: 0.0903736\n",
      "[2575]\ttraining's rmse: 0.085453\tvalid_1's rmse: 0.0903731\n",
      "[2600]\ttraining's rmse: 0.0854512\tvalid_1's rmse: 0.0903729\n",
      "[2625]\ttraining's rmse: 0.0854486\tvalid_1's rmse: 0.0903724\n",
      "[2650]\ttraining's rmse: 0.0854462\tvalid_1's rmse: 0.090372\n",
      "[2675]\ttraining's rmse: 0.0854435\tvalid_1's rmse: 0.0903719\n",
      "[2700]\ttraining's rmse: 0.0854423\tvalid_1's rmse: 0.0903707\n",
      "[2725]\ttraining's rmse: 0.0854384\tvalid_1's rmse: 0.0903701\n",
      "[2750]\ttraining's rmse: 0.0854368\tvalid_1's rmse: 0.0903696\n",
      "[2775]\ttraining's rmse: 0.0854338\tvalid_1's rmse: 0.0903693\n",
      "[2800]\ttraining's rmse: 0.0854323\tvalid_1's rmse: 0.0903696\n",
      "[2825]\ttraining's rmse: 0.0854306\tvalid_1's rmse: 0.0903695\n",
      "Early stopping, best iteration is:\n",
      "[2775]\ttraining's rmse: 0.0854338\tvalid_1's rmse: 0.0903693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0886742\tvalid_1's rmse: 0.0912526\n",
      "[50]\ttraining's rmse: 0.0885401\tvalid_1's rmse: 0.0911969\n",
      "[75]\ttraining's rmse: 0.0884026\tvalid_1's rmse: 0.0911425\n",
      "[100]\ttraining's rmse: 0.0882802\tvalid_1's rmse: 0.0910941\n",
      "[125]\ttraining's rmse: 0.0881521\tvalid_1's rmse: 0.0910457\n",
      "[150]\ttraining's rmse: 0.0880296\tvalid_1's rmse: 0.0909993\n",
      "[175]\ttraining's rmse: 0.0879298\tvalid_1's rmse: 0.0909632\n",
      "[200]\ttraining's rmse: 0.0878236\tvalid_1's rmse: 0.0909257\n",
      "[225]\ttraining's rmse: 0.087723\tvalid_1's rmse: 0.090891\n",
      "[250]\ttraining's rmse: 0.0876345\tvalid_1's rmse: 0.0908594\n",
      "[275]\ttraining's rmse: 0.0875554\tvalid_1's rmse: 0.0908315\n",
      "[300]\ttraining's rmse: 0.0874733\tvalid_1's rmse: 0.0908033\n",
      "[325]\ttraining's rmse: 0.0873945\tvalid_1's rmse: 0.0907781\n",
      "[350]\ttraining's rmse: 0.0873188\tvalid_1's rmse: 0.0907541\n",
      "[375]\ttraining's rmse: 0.0872575\tvalid_1's rmse: 0.0907347\n",
      "[400]\ttraining's rmse: 0.0871892\tvalid_1's rmse: 0.0907142\n",
      "[425]\ttraining's rmse: 0.0871254\tvalid_1's rmse: 0.0906956\n",
      "[450]\ttraining's rmse: 0.087065\tvalid_1's rmse: 0.090677\n",
      "[475]\ttraining's rmse: 0.0870096\tvalid_1's rmse: 0.0906598\n",
      "[500]\ttraining's rmse: 0.0869639\tvalid_1's rmse: 0.0906441\n",
      "[525]\ttraining's rmse: 0.0869053\tvalid_1's rmse: 0.0906284\n",
      "[550]\ttraining's rmse: 0.0868507\tvalid_1's rmse: 0.0906141\n",
      "[575]\ttraining's rmse: 0.0868018\tvalid_1's rmse: 0.0906017\n",
      "[600]\ttraining's rmse: 0.0867518\tvalid_1's rmse: 0.090589\n",
      "[625]\ttraining's rmse: 0.0867143\tvalid_1's rmse: 0.0905771\n",
      "[650]\ttraining's rmse: 0.0866679\tvalid_1's rmse: 0.0905645\n",
      "[675]\ttraining's rmse: 0.0866205\tvalid_1's rmse: 0.0905533\n",
      "[700]\ttraining's rmse: 0.0865774\tvalid_1's rmse: 0.0905434\n",
      "[725]\ttraining's rmse: 0.0865377\tvalid_1's rmse: 0.0905341\n",
      "[750]\ttraining's rmse: 0.0865013\tvalid_1's rmse: 0.0905257\n",
      "[775]\ttraining's rmse: 0.0864698\tvalid_1's rmse: 0.0905172\n",
      "[800]\ttraining's rmse: 0.0864299\tvalid_1's rmse: 0.0905101\n",
      "[825]\ttraining's rmse: 0.0863946\tvalid_1's rmse: 0.0905019\n",
      "[850]\ttraining's rmse: 0.0863612\tvalid_1's rmse: 0.0904958\n",
      "[875]\ttraining's rmse: 0.0863331\tvalid_1's rmse: 0.09049\n",
      "[900]\ttraining's rmse: 0.0862998\tvalid_1's rmse: 0.0904833\n",
      "[925]\ttraining's rmse: 0.0862687\tvalid_1's rmse: 0.0904768\n",
      "[950]\ttraining's rmse: 0.0862428\tvalid_1's rmse: 0.0904712\n",
      "[975]\ttraining's rmse: 0.0862154\tvalid_1's rmse: 0.0904655\n",
      "[1000]\ttraining's rmse: 0.0861911\tvalid_1's rmse: 0.0904605\n",
      "[1025]\ttraining's rmse: 0.0861619\tvalid_1's rmse: 0.0904551\n",
      "[1050]\ttraining's rmse: 0.0861391\tvalid_1's rmse: 0.0904502\n",
      "[1075]\ttraining's rmse: 0.0861139\tvalid_1's rmse: 0.0904469\n",
      "[1100]\ttraining's rmse: 0.0860958\tvalid_1's rmse: 0.090443\n",
      "[1125]\ttraining's rmse: 0.0860757\tvalid_1's rmse: 0.0904396\n",
      "[1150]\ttraining's rmse: 0.0860528\tvalid_1's rmse: 0.090436\n",
      "[1175]\ttraining's rmse: 0.0860358\tvalid_1's rmse: 0.0904335\n",
      "[1200]\ttraining's rmse: 0.0860176\tvalid_1's rmse: 0.0904307\n",
      "[1225]\ttraining's rmse: 0.0860001\tvalid_1's rmse: 0.0904284\n",
      "[1250]\ttraining's rmse: 0.085985\tvalid_1's rmse: 0.0904262\n",
      "[1275]\ttraining's rmse: 0.0859667\tvalid_1's rmse: 0.0904245\n",
      "[1300]\ttraining's rmse: 0.0859518\tvalid_1's rmse: 0.0904215\n",
      "[1325]\ttraining's rmse: 0.0859386\tvalid_1's rmse: 0.09042\n",
      "[1350]\ttraining's rmse: 0.085921\tvalid_1's rmse: 0.0904179\n",
      "[1375]\ttraining's rmse: 0.0859062\tvalid_1's rmse: 0.0904172\n",
      "[1400]\ttraining's rmse: 0.0858953\tvalid_1's rmse: 0.0904151\n",
      "[1425]\ttraining's rmse: 0.0858814\tvalid_1's rmse: 0.0904143\n",
      "[1450]\ttraining's rmse: 0.0858692\tvalid_1's rmse: 0.0904132\n",
      "[1475]\ttraining's rmse: 0.0858566\tvalid_1's rmse: 0.0904112\n",
      "[1500]\ttraining's rmse: 0.0858455\tvalid_1's rmse: 0.0904099\n",
      "[1525]\ttraining's rmse: 0.0858339\tvalid_1's rmse: 0.0904081\n",
      "[1550]\ttraining's rmse: 0.0858229\tvalid_1's rmse: 0.0904073\n",
      "[1575]\ttraining's rmse: 0.0858134\tvalid_1's rmse: 0.0904066\n",
      "[1600]\ttraining's rmse: 0.0858052\tvalid_1's rmse: 0.0904067\n",
      "[1625]\ttraining's rmse: 0.0857944\tvalid_1's rmse: 0.0904052\n",
      "[1650]\ttraining's rmse: 0.0857838\tvalid_1's rmse: 0.0904048\n",
      "[1675]\ttraining's rmse: 0.0857783\tvalid_1's rmse: 0.0904037\n",
      "[1700]\ttraining's rmse: 0.0857717\tvalid_1's rmse: 0.0904028\n",
      "[1725]\ttraining's rmse: 0.0857635\tvalid_1's rmse: 0.0904019\n",
      "[1750]\ttraining's rmse: 0.0857566\tvalid_1's rmse: 0.0904017\n",
      "[1775]\ttraining's rmse: 0.0857512\tvalid_1's rmse: 0.0904013\n",
      "[1800]\ttraining's rmse: 0.0857422\tvalid_1's rmse: 0.0904006\n",
      "[1825]\ttraining's rmse: 0.0857354\tvalid_1's rmse: 0.0904003\n",
      "[1850]\ttraining's rmse: 0.0857301\tvalid_1's rmse: 0.0904002\n",
      "[1875]\ttraining's rmse: 0.0857251\tvalid_1's rmse: 0.0903995\n",
      "[1900]\ttraining's rmse: 0.0857214\tvalid_1's rmse: 0.0903993\n",
      "[1925]\ttraining's rmse: 0.0857157\tvalid_1's rmse: 0.090399\n",
      "[1950]\ttraining's rmse: 0.0857103\tvalid_1's rmse: 0.0903981\n",
      "[1975]\ttraining's rmse: 0.0857046\tvalid_1's rmse: 0.0903971\n",
      "[2000]\ttraining's rmse: 0.0856991\tvalid_1's rmse: 0.0903966\n",
      "[2025]\ttraining's rmse: 0.0856935\tvalid_1's rmse: 0.0903963\n",
      "[2050]\ttraining's rmse: 0.0856887\tvalid_1's rmse: 0.0903965\n",
      "Early stopping, best iteration is:\n",
      "[2010]\ttraining's rmse: 0.0856966\tvalid_1's rmse: 0.0903962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0911766\tvalid_1's rmse: 0.0861681\n",
      "[50]\ttraining's rmse: 0.0910554\tvalid_1's rmse: 0.0861197\n",
      "[75]\ttraining's rmse: 0.090925\tvalid_1's rmse: 0.0860685\n",
      "[100]\ttraining's rmse: 0.090811\tvalid_1's rmse: 0.0860278\n",
      "[125]\ttraining's rmse: 0.0906908\tvalid_1's rmse: 0.0859833\n",
      "[150]\ttraining's rmse: 0.0905845\tvalid_1's rmse: 0.0859445\n",
      "[175]\ttraining's rmse: 0.0904933\tvalid_1's rmse: 0.0859174\n",
      "[200]\ttraining's rmse: 0.0903961\tvalid_1's rmse: 0.0858859\n",
      "[225]\ttraining's rmse: 0.0903024\tvalid_1's rmse: 0.0858561\n",
      "[250]\ttraining's rmse: 0.0902209\tvalid_1's rmse: 0.0858285\n",
      "[275]\ttraining's rmse: 0.090149\tvalid_1's rmse: 0.0858029\n",
      "[300]\ttraining's rmse: 0.0900739\tvalid_1's rmse: 0.0857769\n",
      "[325]\ttraining's rmse: 0.0899991\tvalid_1's rmse: 0.0857535\n",
      "[350]\ttraining's rmse: 0.0899236\tvalid_1's rmse: 0.0857304\n",
      "[375]\ttraining's rmse: 0.089862\tvalid_1's rmse: 0.085712\n",
      "[400]\ttraining's rmse: 0.0897971\tvalid_1's rmse: 0.0856959\n",
      "[425]\ttraining's rmse: 0.0897372\tvalid_1's rmse: 0.0856832\n",
      "[450]\ttraining's rmse: 0.0896798\tvalid_1's rmse: 0.0856679\n",
      "[475]\ttraining's rmse: 0.0896282\tvalid_1's rmse: 0.0856543\n",
      "[500]\ttraining's rmse: 0.0895858\tvalid_1's rmse: 0.0856415\n",
      "[525]\ttraining's rmse: 0.0895255\tvalid_1's rmse: 0.0856255\n",
      "[550]\ttraining's rmse: 0.0894729\tvalid_1's rmse: 0.0856126\n",
      "[575]\ttraining's rmse: 0.0894223\tvalid_1's rmse: 0.0856006\n",
      "[600]\ttraining's rmse: 0.0893702\tvalid_1's rmse: 0.0855902\n",
      "[625]\ttraining's rmse: 0.0893314\tvalid_1's rmse: 0.0855842\n",
      "[650]\ttraining's rmse: 0.0892819\tvalid_1's rmse: 0.0855771\n",
      "[675]\ttraining's rmse: 0.0892327\tvalid_1's rmse: 0.0855771\n",
      "[700]\ttraining's rmse: 0.0891895\tvalid_1's rmse: 0.085574\n",
      "[725]\ttraining's rmse: 0.0891514\tvalid_1's rmse: 0.0855726\n",
      "[750]\ttraining's rmse: 0.0891137\tvalid_1's rmse: 0.0855702\n",
      "[775]\ttraining's rmse: 0.0890823\tvalid_1's rmse: 0.0855692\n",
      "[800]\ttraining's rmse: 0.0890439\tvalid_1's rmse: 0.0855627\n",
      "[825]\ttraining's rmse: 0.0890118\tvalid_1's rmse: 0.0855623\n",
      "[850]\ttraining's rmse: 0.088977\tvalid_1's rmse: 0.0855696\n",
      "Early stopping, best iteration is:\n",
      "[823]\ttraining's rmse: 0.0890145\tvalid_1's rmse: 0.0855561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0906179\tvalid_1's rmse: 0.0924853\n",
      "[50]\ttraining's rmse: 0.0904344\tvalid_1's rmse: 0.0924312\n",
      "[75]\ttraining's rmse: 0.0902509\tvalid_1's rmse: 0.092374\n",
      "[100]\ttraining's rmse: 0.0900776\tvalid_1's rmse: 0.0923245\n",
      "[125]\ttraining's rmse: 0.0899089\tvalid_1's rmse: 0.092275\n",
      "[150]\ttraining's rmse: 0.0897573\tvalid_1's rmse: 0.0922287\n",
      "[175]\ttraining's rmse: 0.0896293\tvalid_1's rmse: 0.092189\n",
      "[200]\ttraining's rmse: 0.0894956\tvalid_1's rmse: 0.0921506\n",
      "[225]\ttraining's rmse: 0.0893633\tvalid_1's rmse: 0.0921126\n",
      "[250]\ttraining's rmse: 0.0892489\tvalid_1's rmse: 0.092079\n",
      "[275]\ttraining's rmse: 0.0891449\tvalid_1's rmse: 0.0920486\n",
      "[300]\ttraining's rmse: 0.0890416\tvalid_1's rmse: 0.0920215\n",
      "[325]\ttraining's rmse: 0.0889403\tvalid_1's rmse: 0.0919926\n",
      "[350]\ttraining's rmse: 0.0888456\tvalid_1's rmse: 0.091965\n",
      "[375]\ttraining's rmse: 0.0887605\tvalid_1's rmse: 0.0919406\n",
      "[400]\ttraining's rmse: 0.0886693\tvalid_1's rmse: 0.0919169\n",
      "[425]\ttraining's rmse: 0.0885909\tvalid_1's rmse: 0.0918947\n",
      "[450]\ttraining's rmse: 0.0885157\tvalid_1's rmse: 0.0918723\n",
      "[475]\ttraining's rmse: 0.0884504\tvalid_1's rmse: 0.091853\n",
      "[500]\ttraining's rmse: 0.0883936\tvalid_1's rmse: 0.0918363\n",
      "[525]\ttraining's rmse: 0.0883233\tvalid_1's rmse: 0.0918169\n",
      "[550]\ttraining's rmse: 0.088261\tvalid_1's rmse: 0.0918005\n",
      "[575]\ttraining's rmse: 0.0882013\tvalid_1's rmse: 0.0917869\n",
      "[600]\ttraining's rmse: 0.0881435\tvalid_1's rmse: 0.0917721\n",
      "[625]\ttraining's rmse: 0.0880966\tvalid_1's rmse: 0.0917576\n",
      "[650]\ttraining's rmse: 0.0880426\tvalid_1's rmse: 0.0917433\n",
      "[675]\ttraining's rmse: 0.087991\tvalid_1's rmse: 0.0917289\n",
      "[700]\ttraining's rmse: 0.0879425\tvalid_1's rmse: 0.0917175\n",
      "[725]\ttraining's rmse: 0.0878989\tvalid_1's rmse: 0.0917071\n",
      "[750]\ttraining's rmse: 0.0878566\tvalid_1's rmse: 0.0916981\n",
      "[775]\ttraining's rmse: 0.0878212\tvalid_1's rmse: 0.0916861\n",
      "[800]\ttraining's rmse: 0.0877774\tvalid_1's rmse: 0.091677\n",
      "[825]\ttraining's rmse: 0.0877432\tvalid_1's rmse: 0.0916659\n",
      "[850]\ttraining's rmse: 0.0877067\tvalid_1's rmse: 0.0916583\n",
      "[875]\ttraining's rmse: 0.0876734\tvalid_1's rmse: 0.0916485\n",
      "[900]\ttraining's rmse: 0.087637\tvalid_1's rmse: 0.0916397\n",
      "[925]\ttraining's rmse: 0.0876045\tvalid_1's rmse: 0.0916305\n",
      "[950]\ttraining's rmse: 0.0875722\tvalid_1's rmse: 0.091623\n",
      "[975]\ttraining's rmse: 0.0875439\tvalid_1's rmse: 0.0916165\n",
      "[1000]\ttraining's rmse: 0.0875146\tvalid_1's rmse: 0.0916089\n",
      "[1025]\ttraining's rmse: 0.0874857\tvalid_1's rmse: 0.0916016\n",
      "[1050]\ttraining's rmse: 0.0874596\tvalid_1's rmse: 0.0915948\n",
      "[1075]\ttraining's rmse: 0.0874354\tvalid_1's rmse: 0.0915895\n",
      "[1100]\ttraining's rmse: 0.0874121\tvalid_1's rmse: 0.0915836\n",
      "[1125]\ttraining's rmse: 0.0873896\tvalid_1's rmse: 0.0915781\n",
      "[1150]\ttraining's rmse: 0.0873645\tvalid_1's rmse: 0.0915714\n",
      "[1175]\ttraining's rmse: 0.0873476\tvalid_1's rmse: 0.0915669\n",
      "[1200]\ttraining's rmse: 0.0873276\tvalid_1's rmse: 0.0915619\n",
      "[1225]\ttraining's rmse: 0.0873092\tvalid_1's rmse: 0.0915581\n",
      "[1250]\ttraining's rmse: 0.0872919\tvalid_1's rmse: 0.0915543\n",
      "[1275]\ttraining's rmse: 0.0872716\tvalid_1's rmse: 0.0915489\n",
      "[1300]\ttraining's rmse: 0.0872581\tvalid_1's rmse: 0.0915444\n",
      "[1325]\ttraining's rmse: 0.08724\tvalid_1's rmse: 0.0915392\n",
      "[1350]\ttraining's rmse: 0.0872217\tvalid_1's rmse: 0.0915348\n",
      "[1375]\ttraining's rmse: 0.0872049\tvalid_1's rmse: 0.0915301\n",
      "[1400]\ttraining's rmse: 0.0871914\tvalid_1's rmse: 0.091527\n",
      "[1425]\ttraining's rmse: 0.0871765\tvalid_1's rmse: 0.0915252\n",
      "[1450]\ttraining's rmse: 0.0871641\tvalid_1's rmse: 0.0915205\n",
      "[1475]\ttraining's rmse: 0.0871509\tvalid_1's rmse: 0.0915166\n",
      "[1500]\ttraining's rmse: 0.0871375\tvalid_1's rmse: 0.0915115\n",
      "[1525]\ttraining's rmse: 0.0871245\tvalid_1's rmse: 0.091508\n",
      "[1550]\ttraining's rmse: 0.0871133\tvalid_1's rmse: 0.0915059\n",
      "[1575]\ttraining's rmse: 0.0871043\tvalid_1's rmse: 0.0915025\n",
      "[1600]\ttraining's rmse: 0.0870942\tvalid_1's rmse: 0.0914993\n",
      "[1625]\ttraining's rmse: 0.0870821\tvalid_1's rmse: 0.0914952\n",
      "[1650]\ttraining's rmse: 0.0870729\tvalid_1's rmse: 0.0914928\n",
      "[1675]\ttraining's rmse: 0.0870654\tvalid_1's rmse: 0.0914905\n",
      "[1700]\ttraining's rmse: 0.0870573\tvalid_1's rmse: 0.0914874\n",
      "[1725]\ttraining's rmse: 0.0870496\tvalid_1's rmse: 0.0914857\n",
      "[1750]\ttraining's rmse: 0.0870413\tvalid_1's rmse: 0.0914836\n",
      "[1775]\ttraining's rmse: 0.0870342\tvalid_1's rmse: 0.0914814\n",
      "[1800]\ttraining's rmse: 0.0870265\tvalid_1's rmse: 0.0914782\n",
      "[1825]\ttraining's rmse: 0.0870199\tvalid_1's rmse: 0.0914767\n",
      "[1850]\ttraining's rmse: 0.087014\tvalid_1's rmse: 0.0914751\n",
      "[1875]\ttraining's rmse: 0.0870078\tvalid_1's rmse: 0.0914739\n",
      "[1900]\ttraining's rmse: 0.0870005\tvalid_1's rmse: 0.0914717\n",
      "[1925]\ttraining's rmse: 0.0869966\tvalid_1's rmse: 0.0914701\n",
      "[1950]\ttraining's rmse: 0.0869911\tvalid_1's rmse: 0.0914688\n",
      "[1975]\ttraining's rmse: 0.0869869\tvalid_1's rmse: 0.0914667\n",
      "[2000]\ttraining's rmse: 0.08698\tvalid_1's rmse: 0.0914655\n",
      "[2025]\ttraining's rmse: 0.0869747\tvalid_1's rmse: 0.0914634\n",
      "[2050]\ttraining's rmse: 0.0869699\tvalid_1's rmse: 0.0914623\n",
      "[2075]\ttraining's rmse: 0.0869656\tvalid_1's rmse: 0.0914602\n",
      "[2100]\ttraining's rmse: 0.0869617\tvalid_1's rmse: 0.0914591\n",
      "[2125]\ttraining's rmse: 0.0869582\tvalid_1's rmse: 0.0914575\n",
      "[2150]\ttraining's rmse: 0.0869536\tvalid_1's rmse: 0.0914568\n",
      "[2175]\ttraining's rmse: 0.0869497\tvalid_1's rmse: 0.0914547\n",
      "[2200]\ttraining's rmse: 0.0869452\tvalid_1's rmse: 0.0914539\n",
      "[2225]\ttraining's rmse: 0.0869422\tvalid_1's rmse: 0.0914535\n",
      "[2250]\ttraining's rmse: 0.086938\tvalid_1's rmse: 0.0914515\n",
      "[2275]\ttraining's rmse: 0.0869348\tvalid_1's rmse: 0.0914495\n",
      "[2300]\ttraining's rmse: 0.086932\tvalid_1's rmse: 0.0914488\n",
      "[2325]\ttraining's rmse: 0.0869277\tvalid_1's rmse: 0.0914479\n",
      "[2350]\ttraining's rmse: 0.0869239\tvalid_1's rmse: 0.0914476\n",
      "[2375]\ttraining's rmse: 0.0869205\tvalid_1's rmse: 0.0914471\n",
      "[2400]\ttraining's rmse: 0.086918\tvalid_1's rmse: 0.0914464\n",
      "[2425]\ttraining's rmse: 0.0869144\tvalid_1's rmse: 0.0914461\n",
      "[2450]\ttraining's rmse: 0.0869119\tvalid_1's rmse: 0.0914449\n",
      "[2475]\ttraining's rmse: 0.0869089\tvalid_1's rmse: 0.0914445\n",
      "[2500]\ttraining's rmse: 0.0869053\tvalid_1's rmse: 0.0914441\n",
      "[2525]\ttraining's rmse: 0.086902\tvalid_1's rmse: 0.091443\n",
      "[2550]\ttraining's rmse: 0.0868979\tvalid_1's rmse: 0.0914425\n",
      "[2575]\ttraining's rmse: 0.0868949\tvalid_1's rmse: 0.0914416\n",
      "[2600]\ttraining's rmse: 0.0868927\tvalid_1's rmse: 0.0914414\n",
      "[2625]\ttraining's rmse: 0.0868895\tvalid_1's rmse: 0.0914393\n",
      "[2650]\ttraining's rmse: 0.0868874\tvalid_1's rmse: 0.0914384\n",
      "[2675]\ttraining's rmse: 0.0868849\tvalid_1's rmse: 0.0914376\n",
      "[2700]\ttraining's rmse: 0.0868828\tvalid_1's rmse: 0.0914361\n",
      "[2725]\ttraining's rmse: 0.0868804\tvalid_1's rmse: 0.0914351\n",
      "[2750]\ttraining's rmse: 0.0868775\tvalid_1's rmse: 0.091435\n",
      "[2775]\ttraining's rmse: 0.0868751\tvalid_1's rmse: 0.0914347\n",
      "[2800]\ttraining's rmse: 0.0868735\tvalid_1's rmse: 0.0914345\n",
      "[2825]\ttraining's rmse: 0.0868715\tvalid_1's rmse: 0.0914339\n",
      "[2850]\ttraining's rmse: 0.0868707\tvalid_1's rmse: 0.0914331\n",
      "[2875]\ttraining's rmse: 0.0868685\tvalid_1's rmse: 0.0914329\n",
      "[2900]\ttraining's rmse: 0.0868671\tvalid_1's rmse: 0.0914328\n",
      "[2925]\ttraining's rmse: 0.0868657\tvalid_1's rmse: 0.0914322\n",
      "[2950]\ttraining's rmse: 0.0868648\tvalid_1's rmse: 0.091432\n",
      "[2975]\ttraining's rmse: 0.0868616\tvalid_1's rmse: 0.0914316\n",
      "[3000]\ttraining's rmse: 0.0868601\tvalid_1's rmse: 0.0914317\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0868601\tvalid_1's rmse: 0.0914317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0904758\tvalid_1's rmse: 0.0927788\n",
      "[50]\ttraining's rmse: 0.0903054\tvalid_1's rmse: 0.0927221\n",
      "[75]\ttraining's rmse: 0.0901262\tvalid_1's rmse: 0.0926651\n",
      "[100]\ttraining's rmse: 0.0899709\tvalid_1's rmse: 0.0926164\n",
      "[125]\ttraining's rmse: 0.0898121\tvalid_1's rmse: 0.0925671\n",
      "[150]\ttraining's rmse: 0.0896676\tvalid_1's rmse: 0.0925211\n",
      "[175]\ttraining's rmse: 0.0895438\tvalid_1's rmse: 0.0924836\n",
      "[200]\ttraining's rmse: 0.089415\tvalid_1's rmse: 0.0924439\n",
      "[225]\ttraining's rmse: 0.0892927\tvalid_1's rmse: 0.0924076\n",
      "[250]\ttraining's rmse: 0.0891863\tvalid_1's rmse: 0.0923765\n",
      "[275]\ttraining's rmse: 0.0890864\tvalid_1's rmse: 0.0923459\n",
      "[300]\ttraining's rmse: 0.0889883\tvalid_1's rmse: 0.0923174\n",
      "[325]\ttraining's rmse: 0.0888934\tvalid_1's rmse: 0.0922896\n",
      "[350]\ttraining's rmse: 0.0888002\tvalid_1's rmse: 0.0922633\n",
      "[375]\ttraining's rmse: 0.088726\tvalid_1's rmse: 0.0922426\n",
      "[400]\ttraining's rmse: 0.0886434\tvalid_1's rmse: 0.0922226\n",
      "[425]\ttraining's rmse: 0.0885684\tvalid_1's rmse: 0.0922014\n",
      "[450]\ttraining's rmse: 0.0885009\tvalid_1's rmse: 0.092183\n",
      "[475]\ttraining's rmse: 0.0884374\tvalid_1's rmse: 0.0921651\n",
      "[500]\ttraining's rmse: 0.0883819\tvalid_1's rmse: 0.0921484\n",
      "[525]\ttraining's rmse: 0.0883156\tvalid_1's rmse: 0.0921313\n",
      "[550]\ttraining's rmse: 0.0882551\tvalid_1's rmse: 0.092116\n",
      "[575]\ttraining's rmse: 0.0881986\tvalid_1's rmse: 0.0921032\n",
      "[600]\ttraining's rmse: 0.0881441\tvalid_1's rmse: 0.0920904\n",
      "[625]\ttraining's rmse: 0.0880998\tvalid_1's rmse: 0.0920779\n",
      "[650]\ttraining's rmse: 0.0880465\tvalid_1's rmse: 0.0920637\n",
      "[675]\ttraining's rmse: 0.0879934\tvalid_1's rmse: 0.0920512\n",
      "[700]\ttraining's rmse: 0.0879472\tvalid_1's rmse: 0.0920389\n",
      "[725]\ttraining's rmse: 0.0879047\tvalid_1's rmse: 0.0920292\n",
      "[750]\ttraining's rmse: 0.0878666\tvalid_1's rmse: 0.0920194\n",
      "[775]\ttraining's rmse: 0.087832\tvalid_1's rmse: 0.0920096\n",
      "[800]\ttraining's rmse: 0.0877879\tvalid_1's rmse: 0.0920003\n",
      "[825]\ttraining's rmse: 0.0877515\tvalid_1's rmse: 0.0919919\n",
      "[850]\ttraining's rmse: 0.0877147\tvalid_1's rmse: 0.0919855\n",
      "[875]\ttraining's rmse: 0.0876818\tvalid_1's rmse: 0.0919789\n",
      "[900]\ttraining's rmse: 0.0876468\tvalid_1's rmse: 0.0919719\n",
      "[925]\ttraining's rmse: 0.0876154\tvalid_1's rmse: 0.091966\n",
      "[950]\ttraining's rmse: 0.0875857\tvalid_1's rmse: 0.0919603\n",
      "[975]\ttraining's rmse: 0.0875565\tvalid_1's rmse: 0.0919543\n",
      "[1000]\ttraining's rmse: 0.0875298\tvalid_1's rmse: 0.0919493\n",
      "[1025]\ttraining's rmse: 0.087498\tvalid_1's rmse: 0.0919449\n",
      "[1050]\ttraining's rmse: 0.0874729\tvalid_1's rmse: 0.0919402\n",
      "[1075]\ttraining's rmse: 0.0874454\tvalid_1's rmse: 0.0919365\n",
      "[1100]\ttraining's rmse: 0.0874256\tvalid_1's rmse: 0.0919325\n",
      "[1125]\ttraining's rmse: 0.0874026\tvalid_1's rmse: 0.0919289\n",
      "[1150]\ttraining's rmse: 0.0873781\tvalid_1's rmse: 0.0919257\n",
      "[1175]\ttraining's rmse: 0.0873612\tvalid_1's rmse: 0.0919237\n",
      "[1200]\ttraining's rmse: 0.0873402\tvalid_1's rmse: 0.0919195\n",
      "[1225]\ttraining's rmse: 0.0873201\tvalid_1's rmse: 0.0919171\n",
      "[1250]\ttraining's rmse: 0.0873024\tvalid_1's rmse: 0.091914\n",
      "[1275]\ttraining's rmse: 0.087281\tvalid_1's rmse: 0.0919125\n",
      "[1300]\ttraining's rmse: 0.0872635\tvalid_1's rmse: 0.0919095\n",
      "[1325]\ttraining's rmse: 0.0872462\tvalid_1's rmse: 0.0919074\n",
      "[1350]\ttraining's rmse: 0.0872303\tvalid_1's rmse: 0.0919058\n",
      "[1375]\ttraining's rmse: 0.0872144\tvalid_1's rmse: 0.0919039\n",
      "[1400]\ttraining's rmse: 0.0871996\tvalid_1's rmse: 0.0919011\n",
      "[1425]\ttraining's rmse: 0.0871835\tvalid_1's rmse: 0.0918988\n",
      "[1450]\ttraining's rmse: 0.087168\tvalid_1's rmse: 0.0918976\n",
      "[1475]\ttraining's rmse: 0.0871558\tvalid_1's rmse: 0.0918963\n",
      "[1500]\ttraining's rmse: 0.0871431\tvalid_1's rmse: 0.091895\n",
      "[1525]\ttraining's rmse: 0.0871316\tvalid_1's rmse: 0.0918941\n",
      "[1550]\ttraining's rmse: 0.0871181\tvalid_1's rmse: 0.091893\n",
      "[1575]\ttraining's rmse: 0.0871083\tvalid_1's rmse: 0.0918922\n",
      "[1600]\ttraining's rmse: 0.0870974\tvalid_1's rmse: 0.0918921\n",
      "[1625]\ttraining's rmse: 0.087088\tvalid_1's rmse: 0.0918908\n",
      "[1650]\ttraining's rmse: 0.087078\tvalid_1's rmse: 0.0918902\n",
      "[1675]\ttraining's rmse: 0.0870693\tvalid_1's rmse: 0.0918893\n",
      "[1700]\ttraining's rmse: 0.0870609\tvalid_1's rmse: 0.0918885\n",
      "[1725]\ttraining's rmse: 0.0870535\tvalid_1's rmse: 0.0918878\n",
      "[1750]\ttraining's rmse: 0.0870452\tvalid_1's rmse: 0.0918882\n",
      "[1775]\ttraining's rmse: 0.0870374\tvalid_1's rmse: 0.0918879\n",
      "[1800]\ttraining's rmse: 0.0870282\tvalid_1's rmse: 0.091888\n",
      "[1825]\ttraining's rmse: 0.0870209\tvalid_1's rmse: 0.0918873\n",
      "[1850]\ttraining's rmse: 0.0870151\tvalid_1's rmse: 0.0918862\n",
      "[1875]\ttraining's rmse: 0.087008\tvalid_1's rmse: 0.0918853\n",
      "[1900]\ttraining's rmse: 0.0870021\tvalid_1's rmse: 0.0918847\n",
      "[1925]\ttraining's rmse: 0.0869959\tvalid_1's rmse: 0.0918844\n",
      "[1950]\ttraining's rmse: 0.0869919\tvalid_1's rmse: 0.0918833\n",
      "[1975]\ttraining's rmse: 0.086986\tvalid_1's rmse: 0.0918829\n",
      "[2000]\ttraining's rmse: 0.0869807\tvalid_1's rmse: 0.0918818\n",
      "[2025]\ttraining's rmse: 0.0869761\tvalid_1's rmse: 0.0918813\n",
      "[2050]\ttraining's rmse: 0.0869716\tvalid_1's rmse: 0.0918815\n",
      "[2075]\ttraining's rmse: 0.0869672\tvalid_1's rmse: 0.0918805\n",
      "[2100]\ttraining's rmse: 0.0869628\tvalid_1's rmse: 0.09188\n",
      "[2125]\ttraining's rmse: 0.0869581\tvalid_1's rmse: 0.0918803\n",
      "[2150]\ttraining's rmse: 0.0869529\tvalid_1's rmse: 0.0918802\n",
      "Early stopping, best iteration is:\n",
      "[2121]\ttraining's rmse: 0.0869594\tvalid_1's rmse: 0.0918798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0924924\tvalid_1's rmse: 0.088785\n",
      "[50]\ttraining's rmse: 0.0923612\tvalid_1's rmse: 0.0887366\n",
      "[75]\ttraining's rmse: 0.092224\tvalid_1's rmse: 0.0886883\n",
      "[100]\ttraining's rmse: 0.092099\tvalid_1's rmse: 0.0886447\n",
      "[125]\ttraining's rmse: 0.0919717\tvalid_1's rmse: 0.0886006\n",
      "[150]\ttraining's rmse: 0.0918533\tvalid_1's rmse: 0.0885625\n",
      "[175]\ttraining's rmse: 0.0917549\tvalid_1's rmse: 0.0885294\n",
      "[200]\ttraining's rmse: 0.0916444\tvalid_1's rmse: 0.0884981\n",
      "[225]\ttraining's rmse: 0.0915409\tvalid_1's rmse: 0.0884674\n",
      "[250]\ttraining's rmse: 0.0914525\tvalid_1's rmse: 0.0884422\n",
      "[275]\ttraining's rmse: 0.0913716\tvalid_1's rmse: 0.0884169\n",
      "[300]\ttraining's rmse: 0.0912918\tvalid_1's rmse: 0.0883942\n",
      "[325]\ttraining's rmse: 0.0912088\tvalid_1's rmse: 0.0883716\n",
      "[350]\ttraining's rmse: 0.0911292\tvalid_1's rmse: 0.0883496\n",
      "[375]\ttraining's rmse: 0.0910641\tvalid_1's rmse: 0.0883307\n",
      "[400]\ttraining's rmse: 0.0909925\tvalid_1's rmse: 0.0883132\n",
      "[425]\ttraining's rmse: 0.0909254\tvalid_1's rmse: 0.0882962\n",
      "[450]\ttraining's rmse: 0.090864\tvalid_1's rmse: 0.0882822\n",
      "[475]\ttraining's rmse: 0.0908073\tvalid_1's rmse: 0.0882677\n",
      "[500]\ttraining's rmse: 0.0907585\tvalid_1's rmse: 0.088253\n",
      "[525]\ttraining's rmse: 0.0906934\tvalid_1's rmse: 0.0882407\n",
      "[550]\ttraining's rmse: 0.0906364\tvalid_1's rmse: 0.0882312\n",
      "[575]\ttraining's rmse: 0.0905848\tvalid_1's rmse: 0.0882206\n",
      "[600]\ttraining's rmse: 0.0905334\tvalid_1's rmse: 0.0882162\n",
      "[625]\ttraining's rmse: 0.0904913\tvalid_1's rmse: 0.0882127\n",
      "[650]\ttraining's rmse: 0.0904403\tvalid_1's rmse: 0.0882043\n",
      "[675]\ttraining's rmse: 0.0903888\tvalid_1's rmse: 0.0881959\n",
      "[700]\ttraining's rmse: 0.0903424\tvalid_1's rmse: 0.0881942\n",
      "[725]\ttraining's rmse: 0.0902998\tvalid_1's rmse: 0.0881888\n",
      "[750]\ttraining's rmse: 0.0902588\tvalid_1's rmse: 0.0881953\n",
      "[775]\ttraining's rmse: 0.0902261\tvalid_1's rmse: 0.08819\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0902821\tvalid_1's rmse: 0.0881856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0890752\tvalid_1's rmse: 0.0917751\n",
      "[50]\ttraining's rmse: 0.0889248\tvalid_1's rmse: 0.0917185\n",
      "[75]\ttraining's rmse: 0.0887767\tvalid_1's rmse: 0.0916662\n",
      "[100]\ttraining's rmse: 0.0886399\tvalid_1's rmse: 0.0916177\n",
      "[125]\ttraining's rmse: 0.0884993\tvalid_1's rmse: 0.0915676\n",
      "[150]\ttraining's rmse: 0.0883722\tvalid_1's rmse: 0.091521\n",
      "[175]\ttraining's rmse: 0.0882668\tvalid_1's rmse: 0.0914828\n",
      "[200]\ttraining's rmse: 0.0881519\tvalid_1's rmse: 0.0914448\n",
      "[225]\ttraining's rmse: 0.0880422\tvalid_1's rmse: 0.0914066\n",
      "[250]\ttraining's rmse: 0.0879501\tvalid_1's rmse: 0.0913701\n",
      "[275]\ttraining's rmse: 0.0878617\tvalid_1's rmse: 0.091339\n",
      "[300]\ttraining's rmse: 0.0877747\tvalid_1's rmse: 0.0913112\n",
      "[325]\ttraining's rmse: 0.087688\tvalid_1's rmse: 0.0912837\n",
      "[350]\ttraining's rmse: 0.087608\tvalid_1's rmse: 0.0912584\n",
      "[375]\ttraining's rmse: 0.0875361\tvalid_1's rmse: 0.0912348\n",
      "[400]\ttraining's rmse: 0.0874601\tvalid_1's rmse: 0.0912124\n",
      "[425]\ttraining's rmse: 0.0873922\tvalid_1's rmse: 0.0911906\n",
      "[450]\ttraining's rmse: 0.08733\tvalid_1's rmse: 0.0911676\n",
      "[475]\ttraining's rmse: 0.08727\tvalid_1's rmse: 0.0911485\n",
      "[500]\ttraining's rmse: 0.0872206\tvalid_1's rmse: 0.0911302\n",
      "[525]\ttraining's rmse: 0.0871602\tvalid_1's rmse: 0.0911121\n",
      "[550]\ttraining's rmse: 0.0871022\tvalid_1's rmse: 0.0910955\n",
      "[575]\ttraining's rmse: 0.0870505\tvalid_1's rmse: 0.0910804\n",
      "[600]\ttraining's rmse: 0.0870016\tvalid_1's rmse: 0.0910659\n",
      "[625]\ttraining's rmse: 0.0869614\tvalid_1's rmse: 0.0910529\n",
      "[650]\ttraining's rmse: 0.0869138\tvalid_1's rmse: 0.0910396\n",
      "[675]\ttraining's rmse: 0.0868666\tvalid_1's rmse: 0.0910264\n",
      "[700]\ttraining's rmse: 0.0868241\tvalid_1's rmse: 0.0910144\n",
      "[725]\ttraining's rmse: 0.0867842\tvalid_1's rmse: 0.0910035\n",
      "[750]\ttraining's rmse: 0.0867465\tvalid_1's rmse: 0.0909939\n",
      "[775]\ttraining's rmse: 0.0867145\tvalid_1's rmse: 0.090983\n",
      "[800]\ttraining's rmse: 0.0866749\tvalid_1's rmse: 0.0909724\n",
      "[825]\ttraining's rmse: 0.0866422\tvalid_1's rmse: 0.0909625\n",
      "[850]\ttraining's rmse: 0.0866058\tvalid_1's rmse: 0.0909545\n",
      "[875]\ttraining's rmse: 0.0865766\tvalid_1's rmse: 0.0909463\n",
      "[900]\ttraining's rmse: 0.0865448\tvalid_1's rmse: 0.0909392\n",
      "[925]\ttraining's rmse: 0.0865152\tvalid_1's rmse: 0.0909316\n",
      "[950]\ttraining's rmse: 0.0864876\tvalid_1's rmse: 0.0909249\n",
      "[975]\ttraining's rmse: 0.0864635\tvalid_1's rmse: 0.0909185\n",
      "[1000]\ttraining's rmse: 0.0864368\tvalid_1's rmse: 0.0909122\n",
      "[1025]\ttraining's rmse: 0.08641\tvalid_1's rmse: 0.0909063\n",
      "[1050]\ttraining's rmse: 0.0863841\tvalid_1's rmse: 0.0908982\n",
      "[1075]\ttraining's rmse: 0.0863607\tvalid_1's rmse: 0.090894\n",
      "[1100]\ttraining's rmse: 0.0863415\tvalid_1's rmse: 0.0908881\n",
      "[1125]\ttraining's rmse: 0.0863227\tvalid_1's rmse: 0.0908822\n",
      "[1150]\ttraining's rmse: 0.0863007\tvalid_1's rmse: 0.0908778\n",
      "[1175]\ttraining's rmse: 0.0862824\tvalid_1's rmse: 0.0908743\n",
      "[1200]\ttraining's rmse: 0.0862656\tvalid_1's rmse: 0.0908694\n",
      "[1225]\ttraining's rmse: 0.0862487\tvalid_1's rmse: 0.0908636\n",
      "[1250]\ttraining's rmse: 0.0862324\tvalid_1's rmse: 0.0908592\n",
      "[1275]\ttraining's rmse: 0.0862146\tvalid_1's rmse: 0.0908564\n",
      "[1300]\ttraining's rmse: 0.0861995\tvalid_1's rmse: 0.0908526\n",
      "[1325]\ttraining's rmse: 0.0861841\tvalid_1's rmse: 0.09085\n",
      "[1350]\ttraining's rmse: 0.0861697\tvalid_1's rmse: 0.0908472\n",
      "[1375]\ttraining's rmse: 0.0861536\tvalid_1's rmse: 0.0908435\n",
      "[1400]\ttraining's rmse: 0.0861419\tvalid_1's rmse: 0.0908402\n",
      "[1425]\ttraining's rmse: 0.0861271\tvalid_1's rmse: 0.0908364\n",
      "[1450]\ttraining's rmse: 0.0861127\tvalid_1's rmse: 0.0908328\n",
      "[1475]\ttraining's rmse: 0.0861017\tvalid_1's rmse: 0.0908296\n",
      "[1500]\ttraining's rmse: 0.0860902\tvalid_1's rmse: 0.0908272\n",
      "[1525]\ttraining's rmse: 0.0860785\tvalid_1's rmse: 0.090824\n",
      "[1550]\ttraining's rmse: 0.0860667\tvalid_1's rmse: 0.0908226\n",
      "[1575]\ttraining's rmse: 0.0860585\tvalid_1's rmse: 0.090821\n",
      "[1600]\ttraining's rmse: 0.0860497\tvalid_1's rmse: 0.0908187\n",
      "[1625]\ttraining's rmse: 0.0860414\tvalid_1's rmse: 0.0908143\n",
      "[1650]\ttraining's rmse: 0.0860332\tvalid_1's rmse: 0.090812\n",
      "[1675]\ttraining's rmse: 0.0860253\tvalid_1's rmse: 0.0908103\n",
      "[1700]\ttraining's rmse: 0.0860183\tvalid_1's rmse: 0.0908071\n",
      "[1725]\ttraining's rmse: 0.0860121\tvalid_1's rmse: 0.0908044\n",
      "[1750]\ttraining's rmse: 0.0860038\tvalid_1's rmse: 0.0908013\n",
      "[1775]\ttraining's rmse: 0.0859954\tvalid_1's rmse: 0.0907995\n",
      "[1800]\ttraining's rmse: 0.085988\tvalid_1's rmse: 0.0907971\n",
      "[1825]\ttraining's rmse: 0.0859812\tvalid_1's rmse: 0.0907953\n",
      "[1850]\ttraining's rmse: 0.0859738\tvalid_1's rmse: 0.0907929\n",
      "[1875]\ttraining's rmse: 0.0859672\tvalid_1's rmse: 0.0907912\n",
      "[1900]\ttraining's rmse: 0.0859621\tvalid_1's rmse: 0.09079\n",
      "[1925]\ttraining's rmse: 0.0859562\tvalid_1's rmse: 0.0907881\n",
      "[1950]\ttraining's rmse: 0.0859499\tvalid_1's rmse: 0.090786\n",
      "[1975]\ttraining's rmse: 0.0859448\tvalid_1's rmse: 0.0907843\n",
      "[2000]\ttraining's rmse: 0.0859389\tvalid_1's rmse: 0.0907831\n",
      "[2025]\ttraining's rmse: 0.0859343\tvalid_1's rmse: 0.0907806\n",
      "[2050]\ttraining's rmse: 0.0859298\tvalid_1's rmse: 0.0907792\n",
      "[2075]\ttraining's rmse: 0.0859262\tvalid_1's rmse: 0.0907775\n",
      "[2100]\ttraining's rmse: 0.0859213\tvalid_1's rmse: 0.0907756\n",
      "[2125]\ttraining's rmse: 0.0859181\tvalid_1's rmse: 0.0907741\n",
      "[2150]\ttraining's rmse: 0.085915\tvalid_1's rmse: 0.0907738\n",
      "[2175]\ttraining's rmse: 0.0859099\tvalid_1's rmse: 0.0907722\n",
      "[2200]\ttraining's rmse: 0.0859063\tvalid_1's rmse: 0.0907719\n",
      "[2225]\ttraining's rmse: 0.0859026\tvalid_1's rmse: 0.0907708\n",
      "[2250]\ttraining's rmse: 0.0858991\tvalid_1's rmse: 0.09077\n",
      "[2275]\ttraining's rmse: 0.0858954\tvalid_1's rmse: 0.0907692\n",
      "[2300]\ttraining's rmse: 0.0858915\tvalid_1's rmse: 0.0907677\n",
      "[2325]\ttraining's rmse: 0.0858884\tvalid_1's rmse: 0.0907668\n",
      "[2350]\ttraining's rmse: 0.0858859\tvalid_1's rmse: 0.0907657\n",
      "[2375]\ttraining's rmse: 0.0858827\tvalid_1's rmse: 0.0907649\n",
      "[2400]\ttraining's rmse: 0.0858789\tvalid_1's rmse: 0.0907634\n",
      "[2425]\ttraining's rmse: 0.0858762\tvalid_1's rmse: 0.0907623\n",
      "[2450]\ttraining's rmse: 0.0858735\tvalid_1's rmse: 0.0907621\n",
      "[2475]\ttraining's rmse: 0.0858708\tvalid_1's rmse: 0.0907623\n",
      "[2500]\ttraining's rmse: 0.0858687\tvalid_1's rmse: 0.0907614\n",
      "[2525]\ttraining's rmse: 0.0858664\tvalid_1's rmse: 0.0907613\n",
      "[2550]\ttraining's rmse: 0.0858642\tvalid_1's rmse: 0.0907596\n",
      "[2575]\ttraining's rmse: 0.0858622\tvalid_1's rmse: 0.0907589\n",
      "[2600]\ttraining's rmse: 0.0858608\tvalid_1's rmse: 0.0907585\n",
      "[2625]\ttraining's rmse: 0.0858585\tvalid_1's rmse: 0.0907576\n",
      "[2650]\ttraining's rmse: 0.0858553\tvalid_1's rmse: 0.0907576\n",
      "[2675]\ttraining's rmse: 0.0858512\tvalid_1's rmse: 0.0907558\n",
      "[2700]\ttraining's rmse: 0.0858481\tvalid_1's rmse: 0.090755\n",
      "[2725]\ttraining's rmse: 0.0858459\tvalid_1's rmse: 0.0907549\n",
      "[2750]\ttraining's rmse: 0.0858434\tvalid_1's rmse: 0.0907546\n",
      "[2775]\ttraining's rmse: 0.0858401\tvalid_1's rmse: 0.0907543\n",
      "[2800]\ttraining's rmse: 0.0858381\tvalid_1's rmse: 0.0907539\n",
      "[2825]\ttraining's rmse: 0.0858351\tvalid_1's rmse: 0.0907527\n",
      "[2850]\ttraining's rmse: 0.0858343\tvalid_1's rmse: 0.0907523\n",
      "[2875]\ttraining's rmse: 0.0858323\tvalid_1's rmse: 0.0907526\n",
      "[2900]\ttraining's rmse: 0.0858306\tvalid_1's rmse: 0.0907527\n",
      "Early stopping, best iteration is:\n",
      "[2857]\ttraining's rmse: 0.0858334\tvalid_1's rmse: 0.0907523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0890794\tvalid_1's rmse: 0.0917778\n",
      "[50]\ttraining's rmse: 0.0889453\tvalid_1's rmse: 0.0917216\n",
      "[75]\ttraining's rmse: 0.0888071\tvalid_1's rmse: 0.0916659\n",
      "[100]\ttraining's rmse: 0.0886827\tvalid_1's rmse: 0.0916173\n",
      "[125]\ttraining's rmse: 0.0885505\tvalid_1's rmse: 0.0915683\n",
      "[150]\ttraining's rmse: 0.088431\tvalid_1's rmse: 0.0915223\n",
      "[175]\ttraining's rmse: 0.0883332\tvalid_1's rmse: 0.0914851\n",
      "[200]\ttraining's rmse: 0.0882278\tvalid_1's rmse: 0.0914485\n",
      "[225]\ttraining's rmse: 0.0881252\tvalid_1's rmse: 0.0914134\n",
      "[250]\ttraining's rmse: 0.0880389\tvalid_1's rmse: 0.0913817\n",
      "[275]\ttraining's rmse: 0.0879563\tvalid_1's rmse: 0.0913537\n",
      "[300]\ttraining's rmse: 0.0878751\tvalid_1's rmse: 0.091326\n",
      "[325]\ttraining's rmse: 0.0877933\tvalid_1's rmse: 0.0912983\n",
      "[350]\ttraining's rmse: 0.0877158\tvalid_1's rmse: 0.0912736\n",
      "[375]\ttraining's rmse: 0.0876534\tvalid_1's rmse: 0.0912523\n",
      "[400]\ttraining's rmse: 0.0875823\tvalid_1's rmse: 0.0912305\n",
      "[425]\ttraining's rmse: 0.0875182\tvalid_1's rmse: 0.0912119\n",
      "[450]\ttraining's rmse: 0.0874589\tvalid_1's rmse: 0.0911931\n",
      "[475]\ttraining's rmse: 0.0874019\tvalid_1's rmse: 0.0911764\n",
      "[500]\ttraining's rmse: 0.0873536\tvalid_1's rmse: 0.0911599\n",
      "[525]\ttraining's rmse: 0.0872922\tvalid_1's rmse: 0.091144\n",
      "[550]\ttraining's rmse: 0.0872354\tvalid_1's rmse: 0.0911302\n",
      "[575]\ttraining's rmse: 0.0871838\tvalid_1's rmse: 0.0911172\n",
      "[600]\ttraining's rmse: 0.0871353\tvalid_1's rmse: 0.0911046\n",
      "[625]\ttraining's rmse: 0.0870954\tvalid_1's rmse: 0.0910922\n",
      "[650]\ttraining's rmse: 0.0870466\tvalid_1's rmse: 0.0910797\n",
      "[675]\ttraining's rmse: 0.0869989\tvalid_1's rmse: 0.0910683\n",
      "[700]\ttraining's rmse: 0.0869565\tvalid_1's rmse: 0.0910575\n",
      "[725]\ttraining's rmse: 0.0869164\tvalid_1's rmse: 0.0910473\n",
      "[750]\ttraining's rmse: 0.0868779\tvalid_1's rmse: 0.0910389\n",
      "[775]\ttraining's rmse: 0.0868468\tvalid_1's rmse: 0.0910302\n",
      "[800]\ttraining's rmse: 0.0868067\tvalid_1's rmse: 0.0910228\n",
      "[825]\ttraining's rmse: 0.0867728\tvalid_1's rmse: 0.0910141\n",
      "[850]\ttraining's rmse: 0.08674\tvalid_1's rmse: 0.0910082\n",
      "[875]\ttraining's rmse: 0.0867084\tvalid_1's rmse: 0.0910024\n",
      "[900]\ttraining's rmse: 0.0866731\tvalid_1's rmse: 0.0909955\n",
      "[925]\ttraining's rmse: 0.0866422\tvalid_1's rmse: 0.0909893\n",
      "[950]\ttraining's rmse: 0.0866136\tvalid_1's rmse: 0.0909846\n",
      "[975]\ttraining's rmse: 0.0865893\tvalid_1's rmse: 0.0909796\n",
      "[1000]\ttraining's rmse: 0.0865643\tvalid_1's rmse: 0.0909751\n",
      "[1025]\ttraining's rmse: 0.0865373\tvalid_1's rmse: 0.0909707\n",
      "[1050]\ttraining's rmse: 0.0865142\tvalid_1's rmse: 0.0909663\n",
      "[1075]\ttraining's rmse: 0.0864886\tvalid_1's rmse: 0.0909622\n",
      "[1100]\ttraining's rmse: 0.086468\tvalid_1's rmse: 0.0909585\n",
      "[1125]\ttraining's rmse: 0.0864473\tvalid_1's rmse: 0.0909554\n",
      "[1150]\ttraining's rmse: 0.0864239\tvalid_1's rmse: 0.0909517\n",
      "[1175]\ttraining's rmse: 0.0864067\tvalid_1's rmse: 0.0909492\n",
      "[1200]\ttraining's rmse: 0.0863877\tvalid_1's rmse: 0.0909464\n",
      "[1225]\ttraining's rmse: 0.0863687\tvalid_1's rmse: 0.0909439\n",
      "[1250]\ttraining's rmse: 0.0863537\tvalid_1's rmse: 0.0909418\n",
      "[1275]\ttraining's rmse: 0.0863349\tvalid_1's rmse: 0.0909402\n",
      "[1300]\ttraining's rmse: 0.086319\tvalid_1's rmse: 0.090938\n",
      "[1325]\ttraining's rmse: 0.0863057\tvalid_1's rmse: 0.090936\n",
      "[1350]\ttraining's rmse: 0.086288\tvalid_1's rmse: 0.0909339\n",
      "[1375]\ttraining's rmse: 0.0862739\tvalid_1's rmse: 0.0909328\n",
      "[1400]\ttraining's rmse: 0.0862632\tvalid_1's rmse: 0.0909311\n",
      "[1425]\ttraining's rmse: 0.0862496\tvalid_1's rmse: 0.0909297\n",
      "[1450]\ttraining's rmse: 0.0862349\tvalid_1's rmse: 0.0909288\n",
      "[1475]\ttraining's rmse: 0.0862232\tvalid_1's rmse: 0.0909272\n",
      "[1500]\ttraining's rmse: 0.0862113\tvalid_1's rmse: 0.0909259\n",
      "[1525]\ttraining's rmse: 0.0862028\tvalid_1's rmse: 0.090925\n",
      "[1550]\ttraining's rmse: 0.0861916\tvalid_1's rmse: 0.0909242\n",
      "[1575]\ttraining's rmse: 0.0861826\tvalid_1's rmse: 0.0909233\n",
      "[1600]\ttraining's rmse: 0.0861729\tvalid_1's rmse: 0.0909227\n",
      "[1625]\ttraining's rmse: 0.0861652\tvalid_1's rmse: 0.0909213\n",
      "[1650]\ttraining's rmse: 0.0861563\tvalid_1's rmse: 0.0909208\n",
      "[1675]\ttraining's rmse: 0.0861492\tvalid_1's rmse: 0.09092\n",
      "[1700]\ttraining's rmse: 0.0861424\tvalid_1's rmse: 0.0909187\n",
      "[1725]\ttraining's rmse: 0.0861342\tvalid_1's rmse: 0.090918\n",
      "[1750]\ttraining's rmse: 0.0861268\tvalid_1's rmse: 0.0909171\n",
      "[1775]\ttraining's rmse: 0.0861196\tvalid_1's rmse: 0.0909162\n",
      "[1800]\ttraining's rmse: 0.0861127\tvalid_1's rmse: 0.0909153\n",
      "[1825]\ttraining's rmse: 0.0861058\tvalid_1's rmse: 0.0909147\n",
      "[1850]\ttraining's rmse: 0.0860992\tvalid_1's rmse: 0.0909144\n",
      "[1875]\ttraining's rmse: 0.0860931\tvalid_1's rmse: 0.0909142\n",
      "[1900]\ttraining's rmse: 0.0860878\tvalid_1's rmse: 0.0909137\n",
      "[1925]\ttraining's rmse: 0.0860817\tvalid_1's rmse: 0.0909133\n",
      "[1950]\ttraining's rmse: 0.0860767\tvalid_1's rmse: 0.0909126\n",
      "[1975]\ttraining's rmse: 0.0860732\tvalid_1's rmse: 0.0909124\n",
      "[2000]\ttraining's rmse: 0.0860688\tvalid_1's rmse: 0.0909117\n",
      "[2025]\ttraining's rmse: 0.0860653\tvalid_1's rmse: 0.0909117\n",
      "[2050]\ttraining's rmse: 0.0860605\tvalid_1's rmse: 0.0909116\n",
      "[2075]\ttraining's rmse: 0.0860567\tvalid_1's rmse: 0.0909112\n",
      "[2100]\ttraining's rmse: 0.0860517\tvalid_1's rmse: 0.0909109\n",
      "[2125]\ttraining's rmse: 0.0860486\tvalid_1's rmse: 0.0909108\n",
      "[2150]\ttraining's rmse: 0.0860439\tvalid_1's rmse: 0.0909112\n",
      "Early stopping, best iteration is:\n",
      "[2107]\ttraining's rmse: 0.0860507\tvalid_1's rmse: 0.0909106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0916423\tvalid_1's rmse: 0.0865778\n",
      "[50]\ttraining's rmse: 0.0915181\tvalid_1's rmse: 0.0865285\n",
      "[75]\ttraining's rmse: 0.0913863\tvalid_1's rmse: 0.0864776\n",
      "[100]\ttraining's rmse: 0.0912699\tvalid_1's rmse: 0.0864341\n",
      "[125]\ttraining's rmse: 0.0911489\tvalid_1's rmse: 0.0863937\n",
      "[150]\ttraining's rmse: 0.0910364\tvalid_1's rmse: 0.0863528\n",
      "[175]\ttraining's rmse: 0.0909434\tvalid_1's rmse: 0.0863259\n",
      "[200]\ttraining's rmse: 0.0908417\tvalid_1's rmse: 0.0862925\n",
      "[225]\ttraining's rmse: 0.0907435\tvalid_1's rmse: 0.0862599\n",
      "[250]\ttraining's rmse: 0.0906599\tvalid_1's rmse: 0.086233\n",
      "[275]\ttraining's rmse: 0.0905872\tvalid_1's rmse: 0.0862074\n",
      "[300]\ttraining's rmse: 0.090511\tvalid_1's rmse: 0.0861829\n",
      "[325]\ttraining's rmse: 0.0904349\tvalid_1's rmse: 0.0861623\n",
      "[350]\ttraining's rmse: 0.0903607\tvalid_1's rmse: 0.0861401\n",
      "[375]\ttraining's rmse: 0.0902993\tvalid_1's rmse: 0.0861245\n",
      "[400]\ttraining's rmse: 0.0902325\tvalid_1's rmse: 0.0861099\n",
      "[425]\ttraining's rmse: 0.0901713\tvalid_1's rmse: 0.0860943\n",
      "[450]\ttraining's rmse: 0.0901132\tvalid_1's rmse: 0.0860761\n",
      "[475]\ttraining's rmse: 0.0900595\tvalid_1's rmse: 0.0860674\n",
      "[500]\ttraining's rmse: 0.0900119\tvalid_1's rmse: 0.0860526\n",
      "[525]\ttraining's rmse: 0.0899485\tvalid_1's rmse: 0.0860412\n",
      "[550]\ttraining's rmse: 0.0898936\tvalid_1's rmse: 0.0860269\n",
      "[575]\ttraining's rmse: 0.0898416\tvalid_1's rmse: 0.0860183\n",
      "[600]\ttraining's rmse: 0.0897905\tvalid_1's rmse: 0.0860075\n",
      "[625]\ttraining's rmse: 0.089752\tvalid_1's rmse: 0.0860034\n",
      "[650]\ttraining's rmse: 0.0897033\tvalid_1's rmse: 0.086004\n",
      "[675]\ttraining's rmse: 0.089653\tvalid_1's rmse: 0.0859948\n",
      "[700]\ttraining's rmse: 0.0896083\tvalid_1's rmse: 0.0859854\n",
      "[725]\ttraining's rmse: 0.089568\tvalid_1's rmse: 0.085987\n",
      "[750]\ttraining's rmse: 0.0895292\tvalid_1's rmse: 0.0859883\n",
      "[775]\ttraining's rmse: 0.0894973\tvalid_1's rmse: 0.0859936\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0895496\tvalid_1's rmse: 0.0859831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.091264\tvalid_1's rmse: 0.093036\n",
      "[50]\ttraining's rmse: 0.091073\tvalid_1's rmse: 0.0929801\n",
      "[75]\ttraining's rmse: 0.0908869\tvalid_1's rmse: 0.0929239\n",
      "[100]\ttraining's rmse: 0.0907097\tvalid_1's rmse: 0.0928744\n",
      "[125]\ttraining's rmse: 0.0905376\tvalid_1's rmse: 0.0928255\n",
      "[150]\ttraining's rmse: 0.0903792\tvalid_1's rmse: 0.092779\n",
      "[175]\ttraining's rmse: 0.0902458\tvalid_1's rmse: 0.0927371\n",
      "[200]\ttraining's rmse: 0.0901064\tvalid_1's rmse: 0.0926984\n",
      "[225]\ttraining's rmse: 0.0899704\tvalid_1's rmse: 0.0926585\n",
      "[250]\ttraining's rmse: 0.0898521\tvalid_1's rmse: 0.0926229\n",
      "[275]\ttraining's rmse: 0.0897435\tvalid_1's rmse: 0.092593\n",
      "[300]\ttraining's rmse: 0.0896379\tvalid_1's rmse: 0.0925622\n",
      "[325]\ttraining's rmse: 0.0895304\tvalid_1's rmse: 0.0925338\n",
      "[350]\ttraining's rmse: 0.0894296\tvalid_1's rmse: 0.0925071\n",
      "[375]\ttraining's rmse: 0.0893391\tvalid_1's rmse: 0.0924831\n",
      "[400]\ttraining's rmse: 0.0892474\tvalid_1's rmse: 0.0924598\n",
      "[425]\ttraining's rmse: 0.0891647\tvalid_1's rmse: 0.0924374\n",
      "[450]\ttraining's rmse: 0.0890917\tvalid_1's rmse: 0.0924171\n",
      "[475]\ttraining's rmse: 0.0890207\tvalid_1's rmse: 0.0923964\n",
      "[500]\ttraining's rmse: 0.0889606\tvalid_1's rmse: 0.0923784\n",
      "[525]\ttraining's rmse: 0.0888858\tvalid_1's rmse: 0.092359\n",
      "[550]\ttraining's rmse: 0.0888222\tvalid_1's rmse: 0.0923415\n",
      "[575]\ttraining's rmse: 0.0887624\tvalid_1's rmse: 0.0923266\n",
      "[600]\ttraining's rmse: 0.0887049\tvalid_1's rmse: 0.0923138\n",
      "[625]\ttraining's rmse: 0.0886561\tvalid_1's rmse: 0.0923012\n",
      "[650]\ttraining's rmse: 0.088603\tvalid_1's rmse: 0.0922869\n",
      "[675]\ttraining's rmse: 0.0885478\tvalid_1's rmse: 0.0922728\n",
      "[700]\ttraining's rmse: 0.0885008\tvalid_1's rmse: 0.0922621\n",
      "[725]\ttraining's rmse: 0.0884582\tvalid_1's rmse: 0.0922505\n",
      "[750]\ttraining's rmse: 0.0884186\tvalid_1's rmse: 0.0922392\n",
      "[775]\ttraining's rmse: 0.088383\tvalid_1's rmse: 0.0922285\n",
      "[800]\ttraining's rmse: 0.0883393\tvalid_1's rmse: 0.0922189\n",
      "[825]\ttraining's rmse: 0.0883068\tvalid_1's rmse: 0.0922097\n",
      "[850]\ttraining's rmse: 0.0882694\tvalid_1's rmse: 0.092201\n",
      "[875]\ttraining's rmse: 0.0882365\tvalid_1's rmse: 0.0921937\n",
      "[900]\ttraining's rmse: 0.0881992\tvalid_1's rmse: 0.0921834\n",
      "[925]\ttraining's rmse: 0.0881678\tvalid_1's rmse: 0.0921759\n",
      "[950]\ttraining's rmse: 0.0881378\tvalid_1's rmse: 0.0921695\n",
      "[975]\ttraining's rmse: 0.088108\tvalid_1's rmse: 0.0921618\n",
      "[1000]\ttraining's rmse: 0.0880775\tvalid_1's rmse: 0.0921549\n",
      "[1025]\ttraining's rmse: 0.088046\tvalid_1's rmse: 0.0921466\n",
      "[1050]\ttraining's rmse: 0.0880224\tvalid_1's rmse: 0.0921395\n",
      "[1075]\ttraining's rmse: 0.087998\tvalid_1's rmse: 0.0921345\n",
      "[1100]\ttraining's rmse: 0.0879777\tvalid_1's rmse: 0.092129\n",
      "[1125]\ttraining's rmse: 0.087955\tvalid_1's rmse: 0.0921229\n",
      "[1150]\ttraining's rmse: 0.0879322\tvalid_1's rmse: 0.0921179\n",
      "[1175]\ttraining's rmse: 0.0879113\tvalid_1's rmse: 0.0921129\n",
      "[1200]\ttraining's rmse: 0.0878875\tvalid_1's rmse: 0.0921076\n",
      "[1225]\ttraining's rmse: 0.0878664\tvalid_1's rmse: 0.0921012\n",
      "[1250]\ttraining's rmse: 0.0878483\tvalid_1's rmse: 0.0920971\n",
      "[1275]\ttraining's rmse: 0.0878236\tvalid_1's rmse: 0.0920937\n",
      "[1300]\ttraining's rmse: 0.0878062\tvalid_1's rmse: 0.0920895\n",
      "[1325]\ttraining's rmse: 0.0877876\tvalid_1's rmse: 0.0920867\n",
      "[1350]\ttraining's rmse: 0.0877713\tvalid_1's rmse: 0.0920832\n",
      "[1375]\ttraining's rmse: 0.0877535\tvalid_1's rmse: 0.0920797\n",
      "[1400]\ttraining's rmse: 0.0877355\tvalid_1's rmse: 0.0920755\n",
      "[1425]\ttraining's rmse: 0.0877176\tvalid_1's rmse: 0.0920732\n",
      "[1450]\ttraining's rmse: 0.0876999\tvalid_1's rmse: 0.0920689\n",
      "[1475]\ttraining's rmse: 0.0876889\tvalid_1's rmse: 0.0920651\n",
      "[1500]\ttraining's rmse: 0.0876764\tvalid_1's rmse: 0.0920622\n",
      "[1525]\ttraining's rmse: 0.0876643\tvalid_1's rmse: 0.0920598\n",
      "[1550]\ttraining's rmse: 0.087654\tvalid_1's rmse: 0.0920571\n",
      "[1575]\ttraining's rmse: 0.0876407\tvalid_1's rmse: 0.0920534\n",
      "[1600]\ttraining's rmse: 0.0876324\tvalid_1's rmse: 0.0920513\n",
      "[1625]\ttraining's rmse: 0.0876227\tvalid_1's rmse: 0.092049\n",
      "[1650]\ttraining's rmse: 0.0876111\tvalid_1's rmse: 0.0920475\n",
      "[1675]\ttraining's rmse: 0.0876006\tvalid_1's rmse: 0.0920455\n",
      "[1700]\ttraining's rmse: 0.0875932\tvalid_1's rmse: 0.0920424\n",
      "[1725]\ttraining's rmse: 0.0875814\tvalid_1's rmse: 0.0920409\n",
      "[1750]\ttraining's rmse: 0.0875717\tvalid_1's rmse: 0.0920379\n",
      "[1775]\ttraining's rmse: 0.0875643\tvalid_1's rmse: 0.0920352\n",
      "[1800]\ttraining's rmse: 0.0875566\tvalid_1's rmse: 0.0920323\n",
      "[1825]\ttraining's rmse: 0.0875502\tvalid_1's rmse: 0.0920302\n",
      "[1850]\ttraining's rmse: 0.0875426\tvalid_1's rmse: 0.0920278\n",
      "[1875]\ttraining's rmse: 0.0875359\tvalid_1's rmse: 0.0920269\n",
      "[1900]\ttraining's rmse: 0.0875299\tvalid_1's rmse: 0.0920238\n",
      "[1925]\ttraining's rmse: 0.0875233\tvalid_1's rmse: 0.0920214\n",
      "[1950]\ttraining's rmse: 0.0875179\tvalid_1's rmse: 0.0920194\n",
      "[1975]\ttraining's rmse: 0.0875133\tvalid_1's rmse: 0.0920172\n",
      "[2000]\ttraining's rmse: 0.0875082\tvalid_1's rmse: 0.0920158\n",
      "[2025]\ttraining's rmse: 0.0875036\tvalid_1's rmse: 0.0920125\n",
      "[2050]\ttraining's rmse: 0.0874977\tvalid_1's rmse: 0.0920115\n",
      "[2075]\ttraining's rmse: 0.0874945\tvalid_1's rmse: 0.0920098\n",
      "[2100]\ttraining's rmse: 0.087491\tvalid_1's rmse: 0.0920087\n",
      "[2125]\ttraining's rmse: 0.0874881\tvalid_1's rmse: 0.0920069\n",
      "[2150]\ttraining's rmse: 0.0874835\tvalid_1's rmse: 0.0920066\n",
      "[2175]\ttraining's rmse: 0.0874812\tvalid_1's rmse: 0.0920058\n",
      "[2200]\ttraining's rmse: 0.0874761\tvalid_1's rmse: 0.0920045\n",
      "[2225]\ttraining's rmse: 0.0874726\tvalid_1's rmse: 0.0920039\n",
      "[2250]\ttraining's rmse: 0.08747\tvalid_1's rmse: 0.0920038\n",
      "[2275]\ttraining's rmse: 0.0874646\tvalid_1's rmse: 0.0920028\n",
      "[2300]\ttraining's rmse: 0.087461\tvalid_1's rmse: 0.0920016\n",
      "[2325]\ttraining's rmse: 0.0874568\tvalid_1's rmse: 0.0920009\n",
      "[2350]\ttraining's rmse: 0.0874537\tvalid_1's rmse: 0.0920001\n",
      "[2375]\ttraining's rmse: 0.0874504\tvalid_1's rmse: 0.091999\n",
      "[2400]\ttraining's rmse: 0.0874468\tvalid_1's rmse: 0.0919985\n",
      "[2425]\ttraining's rmse: 0.087444\tvalid_1's rmse: 0.091998\n",
      "[2450]\ttraining's rmse: 0.0874408\tvalid_1's rmse: 0.0919969\n",
      "[2475]\ttraining's rmse: 0.0874368\tvalid_1's rmse: 0.0919969\n",
      "[2500]\ttraining's rmse: 0.0874344\tvalid_1's rmse: 0.0919963\n",
      "[2525]\ttraining's rmse: 0.0874315\tvalid_1's rmse: 0.0919964\n",
      "[2550]\ttraining's rmse: 0.0874277\tvalid_1's rmse: 0.091995\n",
      "[2575]\ttraining's rmse: 0.087426\tvalid_1's rmse: 0.0919942\n",
      "[2600]\ttraining's rmse: 0.0874235\tvalid_1's rmse: 0.0919938\n",
      "[2625]\ttraining's rmse: 0.087422\tvalid_1's rmse: 0.0919926\n",
      "[2650]\ttraining's rmse: 0.0874202\tvalid_1's rmse: 0.0919916\n",
      "[2675]\ttraining's rmse: 0.0874183\tvalid_1's rmse: 0.0919912\n",
      "[2700]\ttraining's rmse: 0.0874162\tvalid_1's rmse: 0.0919899\n",
      "[2725]\ttraining's rmse: 0.0874144\tvalid_1's rmse: 0.0919899\n",
      "[2750]\ttraining's rmse: 0.087412\tvalid_1's rmse: 0.0919893\n",
      "[2775]\ttraining's rmse: 0.0874093\tvalid_1's rmse: 0.091988\n",
      "[2800]\ttraining's rmse: 0.0874077\tvalid_1's rmse: 0.0919877\n",
      "[2825]\ttraining's rmse: 0.0874051\tvalid_1's rmse: 0.0919873\n",
      "[2850]\ttraining's rmse: 0.0874037\tvalid_1's rmse: 0.0919866\n",
      "[2875]\ttraining's rmse: 0.0874004\tvalid_1's rmse: 0.0919857\n",
      "[2900]\ttraining's rmse: 0.0873966\tvalid_1's rmse: 0.0919857\n",
      "[2925]\ttraining's rmse: 0.0873951\tvalid_1's rmse: 0.0919853\n",
      "[2950]\ttraining's rmse: 0.0873937\tvalid_1's rmse: 0.0919854\n",
      "[2975]\ttraining's rmse: 0.0873914\tvalid_1's rmse: 0.0919852\n",
      "[3000]\ttraining's rmse: 0.0873891\tvalid_1's rmse: 0.091985\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\ttraining's rmse: 0.0873891\tvalid_1's rmse: 0.091985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0910188\tvalid_1's rmse: 0.0935365\n",
      "[50]\ttraining's rmse: 0.0908451\tvalid_1's rmse: 0.093479\n",
      "[75]\ttraining's rmse: 0.0906683\tvalid_1's rmse: 0.0934228\n",
      "[100]\ttraining's rmse: 0.0905133\tvalid_1's rmse: 0.0933739\n",
      "[125]\ttraining's rmse: 0.0903548\tvalid_1's rmse: 0.093324\n",
      "[150]\ttraining's rmse: 0.0902122\tvalid_1's rmse: 0.0932783\n",
      "[175]\ttraining's rmse: 0.0900894\tvalid_1's rmse: 0.0932413\n",
      "[200]\ttraining's rmse: 0.0899583\tvalid_1's rmse: 0.0932032\n",
      "[225]\ttraining's rmse: 0.0898333\tvalid_1's rmse: 0.0931665\n",
      "[250]\ttraining's rmse: 0.0897278\tvalid_1's rmse: 0.0931354\n",
      "[275]\ttraining's rmse: 0.0896264\tvalid_1's rmse: 0.0931059\n",
      "[300]\ttraining's rmse: 0.0895312\tvalid_1's rmse: 0.0930788\n",
      "[325]\ttraining's rmse: 0.089434\tvalid_1's rmse: 0.0930507\n",
      "[350]\ttraining's rmse: 0.0893415\tvalid_1's rmse: 0.0930269\n",
      "[375]\ttraining's rmse: 0.0892655\tvalid_1's rmse: 0.0930049\n",
      "[400]\ttraining's rmse: 0.0891833\tvalid_1's rmse: 0.0929831\n",
      "[425]\ttraining's rmse: 0.0891064\tvalid_1's rmse: 0.0929612\n",
      "[450]\ttraining's rmse: 0.0890377\tvalid_1's rmse: 0.0929413\n",
      "[475]\ttraining's rmse: 0.0889762\tvalid_1's rmse: 0.092923\n",
      "[500]\ttraining's rmse: 0.0889213\tvalid_1's rmse: 0.0929057\n",
      "[525]\ttraining's rmse: 0.0888549\tvalid_1's rmse: 0.0928886\n",
      "[550]\ttraining's rmse: 0.0887933\tvalid_1's rmse: 0.0928747\n",
      "[575]\ttraining's rmse: 0.0887343\tvalid_1's rmse: 0.09286\n",
      "[600]\ttraining's rmse: 0.0886802\tvalid_1's rmse: 0.0928458\n",
      "[625]\ttraining's rmse: 0.0886353\tvalid_1's rmse: 0.0928327\n",
      "[650]\ttraining's rmse: 0.0885806\tvalid_1's rmse: 0.0928196\n",
      "[675]\ttraining's rmse: 0.0885305\tvalid_1's rmse: 0.0928088\n",
      "[700]\ttraining's rmse: 0.0884833\tvalid_1's rmse: 0.0927973\n",
      "[725]\ttraining's rmse: 0.0884417\tvalid_1's rmse: 0.0927866\n",
      "[750]\ttraining's rmse: 0.0884011\tvalid_1's rmse: 0.0927762\n",
      "[775]\ttraining's rmse: 0.0883672\tvalid_1's rmse: 0.0927671\n",
      "[800]\ttraining's rmse: 0.0883242\tvalid_1's rmse: 0.0927586\n",
      "[825]\ttraining's rmse: 0.0882899\tvalid_1's rmse: 0.0927501\n",
      "[850]\ttraining's rmse: 0.0882535\tvalid_1's rmse: 0.0927433\n",
      "[875]\ttraining's rmse: 0.0882213\tvalid_1's rmse: 0.0927358\n",
      "[900]\ttraining's rmse: 0.0881852\tvalid_1's rmse: 0.0927282\n",
      "[925]\ttraining's rmse: 0.0881535\tvalid_1's rmse: 0.0927225\n",
      "[950]\ttraining's rmse: 0.088123\tvalid_1's rmse: 0.0927161\n",
      "[975]\ttraining's rmse: 0.0880937\tvalid_1's rmse: 0.0927097\n",
      "[1000]\ttraining's rmse: 0.0880648\tvalid_1's rmse: 0.0927045\n",
      "[1025]\ttraining's rmse: 0.0880358\tvalid_1's rmse: 0.0927002\n",
      "[1050]\ttraining's rmse: 0.0880106\tvalid_1's rmse: 0.0926948\n",
      "[1075]\ttraining's rmse: 0.0879861\tvalid_1's rmse: 0.0926918\n",
      "[1100]\ttraining's rmse: 0.0879648\tvalid_1's rmse: 0.092688\n",
      "[1125]\ttraining's rmse: 0.087941\tvalid_1's rmse: 0.0926849\n",
      "[1150]\ttraining's rmse: 0.0879167\tvalid_1's rmse: 0.0926813\n",
      "[1175]\ttraining's rmse: 0.0878964\tvalid_1's rmse: 0.0926776\n",
      "[1200]\ttraining's rmse: 0.0878751\tvalid_1's rmse: 0.0926736\n",
      "[1225]\ttraining's rmse: 0.0878559\tvalid_1's rmse: 0.0926703\n",
      "[1250]\ttraining's rmse: 0.0878386\tvalid_1's rmse: 0.0926677\n",
      "[1275]\ttraining's rmse: 0.0878163\tvalid_1's rmse: 0.0926657\n",
      "[1300]\ttraining's rmse: 0.0878\tvalid_1's rmse: 0.0926624\n",
      "[1325]\ttraining's rmse: 0.0877853\tvalid_1's rmse: 0.0926606\n",
      "[1350]\ttraining's rmse: 0.087768\tvalid_1's rmse: 0.092659\n",
      "[1375]\ttraining's rmse: 0.0877521\tvalid_1's rmse: 0.0926577\n",
      "[1400]\ttraining's rmse: 0.0877381\tvalid_1's rmse: 0.0926549\n",
      "[1425]\ttraining's rmse: 0.0877214\tvalid_1's rmse: 0.0926533\n",
      "[1450]\ttraining's rmse: 0.0877062\tvalid_1's rmse: 0.0926521\n",
      "[1475]\ttraining's rmse: 0.0876921\tvalid_1's rmse: 0.0926505\n",
      "[1500]\ttraining's rmse: 0.0876813\tvalid_1's rmse: 0.0926491\n",
      "[1525]\ttraining's rmse: 0.0876693\tvalid_1's rmse: 0.0926479\n",
      "[1550]\ttraining's rmse: 0.0876581\tvalid_1's rmse: 0.0926474\n",
      "[1575]\ttraining's rmse: 0.0876467\tvalid_1's rmse: 0.0926469\n",
      "[1600]\ttraining's rmse: 0.0876374\tvalid_1's rmse: 0.0926463\n",
      "[1625]\ttraining's rmse: 0.0876262\tvalid_1's rmse: 0.0926445\n",
      "[1650]\ttraining's rmse: 0.0876172\tvalid_1's rmse: 0.0926439\n",
      "[1675]\ttraining's rmse: 0.0876081\tvalid_1's rmse: 0.0926422\n",
      "[1700]\ttraining's rmse: 0.0875997\tvalid_1's rmse: 0.0926414\n",
      "[1725]\ttraining's rmse: 0.087591\tvalid_1's rmse: 0.0926406\n",
      "[1750]\ttraining's rmse: 0.0875827\tvalid_1's rmse: 0.0926405\n",
      "[1775]\ttraining's rmse: 0.0875746\tvalid_1's rmse: 0.0926396\n",
      "[1800]\ttraining's rmse: 0.0875675\tvalid_1's rmse: 0.0926389\n",
      "[1825]\ttraining's rmse: 0.0875602\tvalid_1's rmse: 0.0926379\n",
      "[1850]\ttraining's rmse: 0.0875535\tvalid_1's rmse: 0.0926372\n",
      "[1875]\ttraining's rmse: 0.0875459\tvalid_1's rmse: 0.0926365\n",
      "[1900]\ttraining's rmse: 0.0875393\tvalid_1's rmse: 0.0926363\n",
      "[1925]\ttraining's rmse: 0.0875337\tvalid_1's rmse: 0.0926358\n",
      "[1950]\ttraining's rmse: 0.0875284\tvalid_1's rmse: 0.0926354\n",
      "[1975]\ttraining's rmse: 0.0875245\tvalid_1's rmse: 0.0926347\n",
      "[2000]\ttraining's rmse: 0.0875206\tvalid_1's rmse: 0.0926343\n",
      "[2025]\ttraining's rmse: 0.0875143\tvalid_1's rmse: 0.0926335\n",
      "[2050]\ttraining's rmse: 0.0875098\tvalid_1's rmse: 0.0926335\n",
      "[2075]\ttraining's rmse: 0.0875058\tvalid_1's rmse: 0.0926329\n",
      "[2100]\ttraining's rmse: 0.0875012\tvalid_1's rmse: 0.0926327\n",
      "[2125]\ttraining's rmse: 0.087497\tvalid_1's rmse: 0.0926324\n",
      "[2150]\ttraining's rmse: 0.0874923\tvalid_1's rmse: 0.092632\n",
      "[2175]\ttraining's rmse: 0.0874877\tvalid_1's rmse: 0.0926321\n",
      "[2200]\ttraining's rmse: 0.0874836\tvalid_1's rmse: 0.092632\n",
      "Early stopping, best iteration is:\n",
      "[2153]\ttraining's rmse: 0.0874914\tvalid_1's rmse: 0.0926318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0931359\tvalid_1's rmse: 0.0893206\n",
      "[50]\ttraining's rmse: 0.0929987\tvalid_1's rmse: 0.0892703\n",
      "[75]\ttraining's rmse: 0.0928565\tvalid_1's rmse: 0.0892205\n",
      "[100]\ttraining's rmse: 0.0927291\tvalid_1's rmse: 0.0891767\n",
      "[125]\ttraining's rmse: 0.0925926\tvalid_1's rmse: 0.0891335\n",
      "[150]\ttraining's rmse: 0.0924678\tvalid_1's rmse: 0.0890947\n",
      "[175]\ttraining's rmse: 0.0923644\tvalid_1's rmse: 0.0890674\n",
      "[200]\ttraining's rmse: 0.0922524\tvalid_1's rmse: 0.0890365\n",
      "[225]\ttraining's rmse: 0.0921423\tvalid_1's rmse: 0.0890049\n",
      "[250]\ttraining's rmse: 0.092048\tvalid_1's rmse: 0.0889783\n",
      "[275]\ttraining's rmse: 0.0919652\tvalid_1's rmse: 0.0889527\n",
      "[300]\ttraining's rmse: 0.0918814\tvalid_1's rmse: 0.0889281\n",
      "[325]\ttraining's rmse: 0.0917982\tvalid_1's rmse: 0.0889069\n",
      "[350]\ttraining's rmse: 0.0917158\tvalid_1's rmse: 0.0888844\n",
      "[375]\ttraining's rmse: 0.0916464\tvalid_1's rmse: 0.0888764\n",
      "[400]\ttraining's rmse: 0.09157\tvalid_1's rmse: 0.0888585\n",
      "[425]\ttraining's rmse: 0.0915001\tvalid_1's rmse: 0.0888452\n",
      "[450]\ttraining's rmse: 0.0914358\tvalid_1's rmse: 0.0888286\n",
      "[475]\ttraining's rmse: 0.091376\tvalid_1's rmse: 0.0888159\n",
      "[500]\ttraining's rmse: 0.0913267\tvalid_1's rmse: 0.0888019\n",
      "[525]\ttraining's rmse: 0.0912596\tvalid_1's rmse: 0.0887893\n",
      "[550]\ttraining's rmse: 0.0912006\tvalid_1's rmse: 0.0887774\n",
      "[575]\ttraining's rmse: 0.0911459\tvalid_1's rmse: 0.0887669\n",
      "[600]\ttraining's rmse: 0.0910939\tvalid_1's rmse: 0.0887581\n",
      "[625]\ttraining's rmse: 0.0910512\tvalid_1's rmse: 0.0887549\n",
      "[650]\ttraining's rmse: 0.0909946\tvalid_1's rmse: 0.0887463\n",
      "[675]\ttraining's rmse: 0.0909435\tvalid_1's rmse: 0.0887395\n",
      "[700]\ttraining's rmse: 0.0908967\tvalid_1's rmse: 0.0887325\n",
      "[725]\ttraining's rmse: 0.090854\tvalid_1's rmse: 0.0887263\n",
      "[750]\ttraining's rmse: 0.090812\tvalid_1's rmse: 0.0887264\n",
      "[775]\ttraining's rmse: 0.0907775\tvalid_1's rmse: 0.0887198\n",
      "[800]\ttraining's rmse: 0.0907309\tvalid_1's rmse: 0.0887161\n",
      "[825]\ttraining's rmse: 0.0906957\tvalid_1's rmse: 0.0887147\n",
      "[850]\ttraining's rmse: 0.0906579\tvalid_1's rmse: 0.0887099\n",
      "[875]\ttraining's rmse: 0.0906245\tvalid_1's rmse: 0.088716\n",
      "[900]\ttraining's rmse: 0.0905876\tvalid_1's rmse: 0.0887123\n",
      "Early stopping, best iteration is:\n",
      "[851]\ttraining's rmse: 0.0906562\tvalid_1's rmse: 0.0887095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.089345\tvalid_1's rmse: 0.0920641\n",
      "[50]\ttraining's rmse: 0.0891954\tvalid_1's rmse: 0.0920059\n",
      "[75]\ttraining's rmse: 0.0890454\tvalid_1's rmse: 0.0919475\n",
      "[100]\ttraining's rmse: 0.0889068\tvalid_1's rmse: 0.0918988\n",
      "[125]\ttraining's rmse: 0.0887694\tvalid_1's rmse: 0.0918488\n",
      "[150]\ttraining's rmse: 0.0886411\tvalid_1's rmse: 0.0918005\n",
      "[175]\ttraining's rmse: 0.0885353\tvalid_1's rmse: 0.0917635\n",
      "[200]\ttraining's rmse: 0.0884237\tvalid_1's rmse: 0.0917226\n",
      "[225]\ttraining's rmse: 0.088316\tvalid_1's rmse: 0.0916851\n",
      "[250]\ttraining's rmse: 0.0882223\tvalid_1's rmse: 0.0916496\n",
      "[275]\ttraining's rmse: 0.0881313\tvalid_1's rmse: 0.091617\n",
      "[300]\ttraining's rmse: 0.088044\tvalid_1's rmse: 0.0915865\n",
      "[325]\ttraining's rmse: 0.0879552\tvalid_1's rmse: 0.0915569\n",
      "[350]\ttraining's rmse: 0.0878735\tvalid_1's rmse: 0.09153\n",
      "[375]\ttraining's rmse: 0.0878024\tvalid_1's rmse: 0.0915071\n",
      "[400]\ttraining's rmse: 0.0877277\tvalid_1's rmse: 0.0914828\n",
      "[425]\ttraining's rmse: 0.0876569\tvalid_1's rmse: 0.0914582\n",
      "[450]\ttraining's rmse: 0.0875976\tvalid_1's rmse: 0.0914367\n",
      "[475]\ttraining's rmse: 0.0875386\tvalid_1's rmse: 0.091418\n",
      "[500]\ttraining's rmse: 0.0874907\tvalid_1's rmse: 0.0913983\n",
      "[525]\ttraining's rmse: 0.0874328\tvalid_1's rmse: 0.0913803\n",
      "[550]\ttraining's rmse: 0.0873784\tvalid_1's rmse: 0.0913639\n",
      "[575]\ttraining's rmse: 0.087326\tvalid_1's rmse: 0.0913509\n",
      "[600]\ttraining's rmse: 0.0872756\tvalid_1's rmse: 0.0913371\n",
      "[625]\ttraining's rmse: 0.087235\tvalid_1's rmse: 0.0913233\n",
      "[650]\ttraining's rmse: 0.0871884\tvalid_1's rmse: 0.0913086\n",
      "[675]\ttraining's rmse: 0.087143\tvalid_1's rmse: 0.0912956\n",
      "[700]\ttraining's rmse: 0.0871023\tvalid_1's rmse: 0.0912834\n",
      "[725]\ttraining's rmse: 0.0870651\tvalid_1's rmse: 0.091273\n",
      "[750]\ttraining's rmse: 0.0870273\tvalid_1's rmse: 0.091262\n",
      "[775]\ttraining's rmse: 0.0869953\tvalid_1's rmse: 0.0912506\n",
      "[800]\ttraining's rmse: 0.086955\tvalid_1's rmse: 0.0912414\n",
      "[825]\ttraining's rmse: 0.0869213\tvalid_1's rmse: 0.0912316\n",
      "[850]\ttraining's rmse: 0.0868869\tvalid_1's rmse: 0.0912241\n",
      "[875]\ttraining's rmse: 0.0868572\tvalid_1's rmse: 0.0912162\n",
      "[900]\ttraining's rmse: 0.086824\tvalid_1's rmse: 0.091207\n",
      "[925]\ttraining's rmse: 0.0867949\tvalid_1's rmse: 0.0911993\n",
      "[950]\ttraining's rmse: 0.0867694\tvalid_1's rmse: 0.0911932\n",
      "[975]\ttraining's rmse: 0.0867456\tvalid_1's rmse: 0.0911868\n",
      "[1000]\ttraining's rmse: 0.0867196\tvalid_1's rmse: 0.091181\n",
      "[1025]\ttraining's rmse: 0.0866948\tvalid_1's rmse: 0.0911734\n",
      "[1050]\ttraining's rmse: 0.0866708\tvalid_1's rmse: 0.0911659\n",
      "[1075]\ttraining's rmse: 0.0866487\tvalid_1's rmse: 0.0911615\n",
      "[1100]\ttraining's rmse: 0.0866283\tvalid_1's rmse: 0.0911559\n",
      "[1125]\ttraining's rmse: 0.0866091\tvalid_1's rmse: 0.0911504\n",
      "[1150]\ttraining's rmse: 0.0865882\tvalid_1's rmse: 0.0911451\n",
      "[1175]\ttraining's rmse: 0.0865693\tvalid_1's rmse: 0.0911409\n",
      "[1200]\ttraining's rmse: 0.0865507\tvalid_1's rmse: 0.091135\n",
      "[1225]\ttraining's rmse: 0.0865309\tvalid_1's rmse: 0.0911302\n",
      "[1250]\ttraining's rmse: 0.0865144\tvalid_1's rmse: 0.0911257\n",
      "[1275]\ttraining's rmse: 0.086492\tvalid_1's rmse: 0.0911226\n",
      "[1300]\ttraining's rmse: 0.086476\tvalid_1's rmse: 0.0911184\n",
      "[1325]\ttraining's rmse: 0.0864622\tvalid_1's rmse: 0.0911154\n",
      "[1350]\ttraining's rmse: 0.0864447\tvalid_1's rmse: 0.0911127\n",
      "[1375]\ttraining's rmse: 0.0864275\tvalid_1's rmse: 0.0911101\n",
      "[1400]\ttraining's rmse: 0.0864138\tvalid_1's rmse: 0.0911056\n",
      "[1425]\ttraining's rmse: 0.0863967\tvalid_1's rmse: 0.0911032\n",
      "[1450]\ttraining's rmse: 0.0863803\tvalid_1's rmse: 0.0911006\n",
      "[1475]\ttraining's rmse: 0.0863675\tvalid_1's rmse: 0.0910976\n",
      "[1500]\ttraining's rmse: 0.0863567\tvalid_1's rmse: 0.0910956\n",
      "[1525]\ttraining's rmse: 0.0863456\tvalid_1's rmse: 0.0910932\n",
      "[1550]\ttraining's rmse: 0.0863327\tvalid_1's rmse: 0.0910902\n",
      "[1575]\ttraining's rmse: 0.0863228\tvalid_1's rmse: 0.0910871\n",
      "[1600]\ttraining's rmse: 0.086313\tvalid_1's rmse: 0.0910841\n",
      "[1625]\ttraining's rmse: 0.0863053\tvalid_1's rmse: 0.0910811\n",
      "[1650]\ttraining's rmse: 0.0862982\tvalid_1's rmse: 0.0910778\n",
      "[1675]\ttraining's rmse: 0.0862912\tvalid_1's rmse: 0.0910753\n",
      "[1700]\ttraining's rmse: 0.0862855\tvalid_1's rmse: 0.0910736\n",
      "[1725]\ttraining's rmse: 0.0862778\tvalid_1's rmse: 0.091072\n",
      "[1750]\ttraining's rmse: 0.0862702\tvalid_1's rmse: 0.0910692\n",
      "[1775]\ttraining's rmse: 0.086263\tvalid_1's rmse: 0.0910677\n",
      "[1800]\ttraining's rmse: 0.0862552\tvalid_1's rmse: 0.0910641\n",
      "[1825]\ttraining's rmse: 0.08625\tvalid_1's rmse: 0.0910632\n",
      "[1850]\ttraining's rmse: 0.0862444\tvalid_1's rmse: 0.0910608\n",
      "[1875]\ttraining's rmse: 0.086238\tvalid_1's rmse: 0.0910591\n",
      "[1900]\ttraining's rmse: 0.086232\tvalid_1's rmse: 0.0910578\n",
      "[1925]\ttraining's rmse: 0.0862251\tvalid_1's rmse: 0.0910563\n",
      "[1950]\ttraining's rmse: 0.0862218\tvalid_1's rmse: 0.0910547\n",
      "[1975]\ttraining's rmse: 0.0862152\tvalid_1's rmse: 0.091053\n",
      "[2000]\ttraining's rmse: 0.0862099\tvalid_1's rmse: 0.0910509\n",
      "[2025]\ttraining's rmse: 0.0862057\tvalid_1's rmse: 0.0910489\n",
      "[2050]\ttraining's rmse: 0.086202\tvalid_1's rmse: 0.0910477\n",
      "[2075]\ttraining's rmse: 0.0861981\tvalid_1's rmse: 0.091046\n",
      "[2100]\ttraining's rmse: 0.086194\tvalid_1's rmse: 0.091044\n",
      "[2125]\ttraining's rmse: 0.0861898\tvalid_1's rmse: 0.0910423\n",
      "[2150]\ttraining's rmse: 0.0861853\tvalid_1's rmse: 0.0910407\n",
      "[2175]\ttraining's rmse: 0.0861821\tvalid_1's rmse: 0.0910404\n",
      "[2200]\ttraining's rmse: 0.0861789\tvalid_1's rmse: 0.0910394\n",
      "[2225]\ttraining's rmse: 0.086176\tvalid_1's rmse: 0.091039\n",
      "[2250]\ttraining's rmse: 0.0861728\tvalid_1's rmse: 0.0910384\n",
      "[2275]\ttraining's rmse: 0.0861666\tvalid_1's rmse: 0.0910365\n",
      "[2300]\ttraining's rmse: 0.0861627\tvalid_1's rmse: 0.0910351\n",
      "[2325]\ttraining's rmse: 0.086159\tvalid_1's rmse: 0.0910339\n",
      "[2350]\ttraining's rmse: 0.0861565\tvalid_1's rmse: 0.0910335\n",
      "[2375]\ttraining's rmse: 0.0861531\tvalid_1's rmse: 0.0910326\n",
      "[2400]\ttraining's rmse: 0.0861489\tvalid_1's rmse: 0.0910318\n",
      "[2425]\ttraining's rmse: 0.0861461\tvalid_1's rmse: 0.0910319\n",
      "[2450]\ttraining's rmse: 0.0861429\tvalid_1's rmse: 0.0910307\n",
      "[2475]\ttraining's rmse: 0.0861401\tvalid_1's rmse: 0.0910304\n",
      "[2500]\ttraining's rmse: 0.0861371\tvalid_1's rmse: 0.0910303\n",
      "[2525]\ttraining's rmse: 0.0861352\tvalid_1's rmse: 0.0910299\n",
      "[2550]\ttraining's rmse: 0.0861327\tvalid_1's rmse: 0.0910301\n",
      "Early stopping, best iteration is:\n",
      "[2522]\ttraining's rmse: 0.0861353\tvalid_1's rmse: 0.0910298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.089366\tvalid_1's rmse: 0.0920437\n",
      "[50]\ttraining's rmse: 0.0892314\tvalid_1's rmse: 0.0919869\n",
      "[75]\ttraining's rmse: 0.0890916\tvalid_1's rmse: 0.0919326\n",
      "[100]\ttraining's rmse: 0.0889626\tvalid_1's rmse: 0.0918836\n",
      "[125]\ttraining's rmse: 0.0888297\tvalid_1's rmse: 0.0918331\n",
      "[150]\ttraining's rmse: 0.0887084\tvalid_1's rmse: 0.0917884\n",
      "[175]\ttraining's rmse: 0.0886076\tvalid_1's rmse: 0.0917507\n",
      "[200]\ttraining's rmse: 0.0885047\tvalid_1's rmse: 0.0917142\n",
      "[225]\ttraining's rmse: 0.0884035\tvalid_1's rmse: 0.09168\n",
      "[250]\ttraining's rmse: 0.0883154\tvalid_1's rmse: 0.0916483\n",
      "[275]\ttraining's rmse: 0.0882337\tvalid_1's rmse: 0.0916191\n",
      "[300]\ttraining's rmse: 0.0881527\tvalid_1's rmse: 0.0915916\n",
      "[325]\ttraining's rmse: 0.0880682\tvalid_1's rmse: 0.0915654\n",
      "[350]\ttraining's rmse: 0.0879883\tvalid_1's rmse: 0.0915401\n",
      "[375]\ttraining's rmse: 0.0879244\tvalid_1's rmse: 0.0915175\n",
      "[400]\ttraining's rmse: 0.0878545\tvalid_1's rmse: 0.0914975\n",
      "[425]\ttraining's rmse: 0.0877867\tvalid_1's rmse: 0.0914775\n",
      "[450]\ttraining's rmse: 0.0877266\tvalid_1's rmse: 0.0914597\n",
      "[475]\ttraining's rmse: 0.0876715\tvalid_1's rmse: 0.0914435\n",
      "[500]\ttraining's rmse: 0.0876232\tvalid_1's rmse: 0.0914284\n",
      "[525]\ttraining's rmse: 0.0875624\tvalid_1's rmse: 0.0914112\n",
      "[550]\ttraining's rmse: 0.0875062\tvalid_1's rmse: 0.0913971\n",
      "[575]\ttraining's rmse: 0.0874527\tvalid_1's rmse: 0.0913824\n",
      "[600]\ttraining's rmse: 0.0874013\tvalid_1's rmse: 0.0913681\n",
      "[625]\ttraining's rmse: 0.0873609\tvalid_1's rmse: 0.0913572\n",
      "[650]\ttraining's rmse: 0.0873102\tvalid_1's rmse: 0.091344\n",
      "[675]\ttraining's rmse: 0.0872622\tvalid_1's rmse: 0.0913329\n",
      "[700]\ttraining's rmse: 0.087217\tvalid_1's rmse: 0.0913223\n",
      "[725]\ttraining's rmse: 0.087175\tvalid_1's rmse: 0.0913128\n",
      "[750]\ttraining's rmse: 0.087139\tvalid_1's rmse: 0.0913037\n",
      "[775]\ttraining's rmse: 0.087107\tvalid_1's rmse: 0.0912943\n",
      "[800]\ttraining's rmse: 0.0870661\tvalid_1's rmse: 0.0912866\n",
      "[825]\ttraining's rmse: 0.0870324\tvalid_1's rmse: 0.091278\n",
      "[850]\ttraining's rmse: 0.086999\tvalid_1's rmse: 0.0912709\n",
      "[875]\ttraining's rmse: 0.0869677\tvalid_1's rmse: 0.0912637\n",
      "[900]\ttraining's rmse: 0.086936\tvalid_1's rmse: 0.0912578\n",
      "[925]\ttraining's rmse: 0.0869043\tvalid_1's rmse: 0.0912525\n",
      "[950]\ttraining's rmse: 0.0868767\tvalid_1's rmse: 0.0912476\n",
      "[975]\ttraining's rmse: 0.0868522\tvalid_1's rmse: 0.0912426\n",
      "[1000]\ttraining's rmse: 0.0868268\tvalid_1's rmse: 0.0912373\n",
      "[1025]\ttraining's rmse: 0.0867993\tvalid_1's rmse: 0.0912327\n",
      "[1050]\ttraining's rmse: 0.0867742\tvalid_1's rmse: 0.0912278\n",
      "[1075]\ttraining's rmse: 0.0867476\tvalid_1's rmse: 0.0912234\n",
      "[1100]\ttraining's rmse: 0.0867272\tvalid_1's rmse: 0.0912194\n",
      "[1125]\ttraining's rmse: 0.086707\tvalid_1's rmse: 0.0912159\n",
      "[1150]\ttraining's rmse: 0.0866846\tvalid_1's rmse: 0.0912122\n",
      "[1175]\ttraining's rmse: 0.0866663\tvalid_1's rmse: 0.09121\n",
      "[1200]\ttraining's rmse: 0.0866469\tvalid_1's rmse: 0.0912071\n",
      "[1225]\ttraining's rmse: 0.086629\tvalid_1's rmse: 0.0912051\n",
      "[1250]\ttraining's rmse: 0.0866138\tvalid_1's rmse: 0.0912037\n",
      "[1275]\ttraining's rmse: 0.0865929\tvalid_1's rmse: 0.0912017\n",
      "[1300]\ttraining's rmse: 0.0865774\tvalid_1's rmse: 0.0911997\n",
      "[1325]\ttraining's rmse: 0.0865617\tvalid_1's rmse: 0.0911978\n",
      "[1350]\ttraining's rmse: 0.0865478\tvalid_1's rmse: 0.0911966\n",
      "[1375]\ttraining's rmse: 0.0865335\tvalid_1's rmse: 0.0911956\n",
      "[1400]\ttraining's rmse: 0.0865214\tvalid_1's rmse: 0.0911938\n",
      "[1425]\ttraining's rmse: 0.0865071\tvalid_1's rmse: 0.0911926\n",
      "[1450]\ttraining's rmse: 0.0864945\tvalid_1's rmse: 0.0911916\n",
      "[1475]\ttraining's rmse: 0.0864818\tvalid_1's rmse: 0.0911891\n",
      "[1500]\ttraining's rmse: 0.0864699\tvalid_1's rmse: 0.0911886\n",
      "[1525]\ttraining's rmse: 0.0864576\tvalid_1's rmse: 0.0911875\n",
      "[1550]\ttraining's rmse: 0.0864467\tvalid_1's rmse: 0.0911864\n",
      "[1575]\ttraining's rmse: 0.0864373\tvalid_1's rmse: 0.0911856\n",
      "[1600]\ttraining's rmse: 0.0864272\tvalid_1's rmse: 0.091185\n",
      "[1625]\ttraining's rmse: 0.0864177\tvalid_1's rmse: 0.0911841\n",
      "[1650]\ttraining's rmse: 0.0864066\tvalid_1's rmse: 0.0911833\n",
      "[1675]\ttraining's rmse: 0.0863997\tvalid_1's rmse: 0.0911828\n",
      "[1700]\ttraining's rmse: 0.0863927\tvalid_1's rmse: 0.091182\n",
      "[1725]\ttraining's rmse: 0.0863847\tvalid_1's rmse: 0.0911811\n",
      "[1750]\ttraining's rmse: 0.0863766\tvalid_1's rmse: 0.0911801\n",
      "[1775]\ttraining's rmse: 0.0863704\tvalid_1's rmse: 0.0911791\n",
      "[1800]\ttraining's rmse: 0.0863633\tvalid_1's rmse: 0.0911787\n",
      "[1825]\ttraining's rmse: 0.0863567\tvalid_1's rmse: 0.0911778\n",
      "[1850]\ttraining's rmse: 0.0863469\tvalid_1's rmse: 0.091177\n",
      "[1875]\ttraining's rmse: 0.0863403\tvalid_1's rmse: 0.0911765\n",
      "[1900]\ttraining's rmse: 0.0863325\tvalid_1's rmse: 0.0911759\n",
      "[1925]\ttraining's rmse: 0.0863274\tvalid_1's rmse: 0.0911756\n",
      "[1950]\ttraining's rmse: 0.086322\tvalid_1's rmse: 0.0911748\n",
      "[1975]\ttraining's rmse: 0.0863186\tvalid_1's rmse: 0.0911742\n",
      "[2000]\ttraining's rmse: 0.0863133\tvalid_1's rmse: 0.0911735\n",
      "[2025]\ttraining's rmse: 0.0863087\tvalid_1's rmse: 0.0911728\n",
      "[2050]\ttraining's rmse: 0.0863042\tvalid_1's rmse: 0.091172\n",
      "[2075]\ttraining's rmse: 0.0863002\tvalid_1's rmse: 0.0911714\n",
      "[2100]\ttraining's rmse: 0.0862961\tvalid_1's rmse: 0.0911708\n",
      "[2125]\ttraining's rmse: 0.0862926\tvalid_1's rmse: 0.0911709\n",
      "[2150]\ttraining's rmse: 0.0862876\tvalid_1's rmse: 0.0911707\n",
      "[2175]\ttraining's rmse: 0.0862824\tvalid_1's rmse: 0.0911704\n",
      "[2200]\ttraining's rmse: 0.0862783\tvalid_1's rmse: 0.0911701\n",
      "[2225]\ttraining's rmse: 0.0862751\tvalid_1's rmse: 0.0911701\n",
      "Early stopping, best iteration is:\n",
      "[2197]\ttraining's rmse: 0.0862786\tvalid_1's rmse: 0.09117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0919222\tvalid_1's rmse: 0.0868561\n",
      "[50]\ttraining's rmse: 0.0917924\tvalid_1's rmse: 0.0868049\n",
      "[75]\ttraining's rmse: 0.0916613\tvalid_1's rmse: 0.0867553\n",
      "[100]\ttraining's rmse: 0.0915457\tvalid_1's rmse: 0.0867124\n",
      "[125]\ttraining's rmse: 0.091426\tvalid_1's rmse: 0.0866676\n",
      "[150]\ttraining's rmse: 0.0913176\tvalid_1's rmse: 0.0866297\n",
      "[175]\ttraining's rmse: 0.0912265\tvalid_1's rmse: 0.0865985\n",
      "[200]\ttraining's rmse: 0.0911259\tvalid_1's rmse: 0.0865661\n",
      "[225]\ttraining's rmse: 0.0910254\tvalid_1's rmse: 0.0865316\n",
      "[250]\ttraining's rmse: 0.0909436\tvalid_1's rmse: 0.0865036\n",
      "[275]\ttraining's rmse: 0.0908678\tvalid_1's rmse: 0.0864778\n",
      "[300]\ttraining's rmse: 0.0907897\tvalid_1's rmse: 0.0864514\n",
      "[325]\ttraining's rmse: 0.0907122\tvalid_1's rmse: 0.086428\n",
      "[350]\ttraining's rmse: 0.0906362\tvalid_1's rmse: 0.0864047\n",
      "[375]\ttraining's rmse: 0.0905728\tvalid_1's rmse: 0.0863853\n",
      "[400]\ttraining's rmse: 0.0905056\tvalid_1's rmse: 0.0863741\n",
      "[425]\ttraining's rmse: 0.0904427\tvalid_1's rmse: 0.086359\n",
      "[450]\ttraining's rmse: 0.0903871\tvalid_1's rmse: 0.0863426\n",
      "[475]\ttraining's rmse: 0.0903319\tvalid_1's rmse: 0.0863273\n",
      "[500]\ttraining's rmse: 0.0902865\tvalid_1's rmse: 0.0863159\n",
      "[525]\ttraining's rmse: 0.0902258\tvalid_1's rmse: 0.0863057\n",
      "[550]\ttraining's rmse: 0.0901715\tvalid_1's rmse: 0.0862966\n",
      "[575]\ttraining's rmse: 0.0901202\tvalid_1's rmse: 0.0862895\n",
      "[600]\ttraining's rmse: 0.0900683\tvalid_1's rmse: 0.0862783\n",
      "[625]\ttraining's rmse: 0.0900281\tvalid_1's rmse: 0.0862682\n",
      "[650]\ttraining's rmse: 0.0899767\tvalid_1's rmse: 0.0862619\n",
      "[675]\ttraining's rmse: 0.0899266\tvalid_1's rmse: 0.0862567\n",
      "[700]\ttraining's rmse: 0.0898837\tvalid_1's rmse: 0.0862459\n",
      "[725]\ttraining's rmse: 0.0898434\tvalid_1's rmse: 0.0862436\n",
      "[750]\ttraining's rmse: 0.0898052\tvalid_1's rmse: 0.0862421\n",
      "[775]\ttraining's rmse: 0.0897746\tvalid_1's rmse: 0.0862417\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0898265\tvalid_1's rmse: 0.0862402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0919778\tvalid_1's rmse: 0.0939144\n",
      "[50]\ttraining's rmse: 0.0917834\tvalid_1's rmse: 0.0938597\n",
      "[75]\ttraining's rmse: 0.0915959\tvalid_1's rmse: 0.0938047\n",
      "[100]\ttraining's rmse: 0.0914181\tvalid_1's rmse: 0.0937546\n",
      "[125]\ttraining's rmse: 0.0912419\tvalid_1's rmse: 0.0937071\n",
      "[150]\ttraining's rmse: 0.0910847\tvalid_1's rmse: 0.0936634\n",
      "[175]\ttraining's rmse: 0.0909479\tvalid_1's rmse: 0.0936239\n",
      "[200]\ttraining's rmse: 0.0908061\tvalid_1's rmse: 0.0935862\n",
      "[225]\ttraining's rmse: 0.0906672\tvalid_1's rmse: 0.0935483\n",
      "[250]\ttraining's rmse: 0.0905483\tvalid_1's rmse: 0.0935127\n",
      "[275]\ttraining's rmse: 0.0904379\tvalid_1's rmse: 0.0934816\n",
      "[300]\ttraining's rmse: 0.0903306\tvalid_1's rmse: 0.0934509\n",
      "[325]\ttraining's rmse: 0.0902261\tvalid_1's rmse: 0.0934228\n",
      "[350]\ttraining's rmse: 0.0901203\tvalid_1's rmse: 0.093396\n",
      "[375]\ttraining's rmse: 0.0900352\tvalid_1's rmse: 0.0933734\n",
      "[400]\ttraining's rmse: 0.0899385\tvalid_1's rmse: 0.093351\n",
      "[425]\ttraining's rmse: 0.0898575\tvalid_1's rmse: 0.0933282\n",
      "[450]\ttraining's rmse: 0.0897839\tvalid_1's rmse: 0.0933079\n",
      "[475]\ttraining's rmse: 0.089716\tvalid_1's rmse: 0.0932882\n",
      "[500]\ttraining's rmse: 0.0896532\tvalid_1's rmse: 0.0932701\n",
      "[525]\ttraining's rmse: 0.0895776\tvalid_1's rmse: 0.0932503\n",
      "[550]\ttraining's rmse: 0.0895145\tvalid_1's rmse: 0.0932357\n",
      "[575]\ttraining's rmse: 0.0894509\tvalid_1's rmse: 0.0932205\n",
      "[600]\ttraining's rmse: 0.0893912\tvalid_1's rmse: 0.0932067\n",
      "[625]\ttraining's rmse: 0.0893403\tvalid_1's rmse: 0.0931935\n",
      "[650]\ttraining's rmse: 0.0892841\tvalid_1's rmse: 0.0931798\n",
      "[675]\ttraining's rmse: 0.0892301\tvalid_1's rmse: 0.0931649\n",
      "[700]\ttraining's rmse: 0.0891799\tvalid_1's rmse: 0.0931505\n",
      "[725]\ttraining's rmse: 0.0891359\tvalid_1's rmse: 0.0931382\n",
      "[750]\ttraining's rmse: 0.0890916\tvalid_1's rmse: 0.0931275\n",
      "[775]\ttraining's rmse: 0.0890568\tvalid_1's rmse: 0.0931165\n",
      "[800]\ttraining's rmse: 0.089009\tvalid_1's rmse: 0.0931062\n",
      "[825]\ttraining's rmse: 0.0889736\tvalid_1's rmse: 0.0930958\n",
      "[850]\ttraining's rmse: 0.0889302\tvalid_1's rmse: 0.0930875\n",
      "[875]\ttraining's rmse: 0.0888951\tvalid_1's rmse: 0.0930792\n",
      "[900]\ttraining's rmse: 0.088857\tvalid_1's rmse: 0.0930713\n",
      "[925]\ttraining's rmse: 0.088824\tvalid_1's rmse: 0.0930634\n",
      "[950]\ttraining's rmse: 0.0887948\tvalid_1's rmse: 0.0930565\n",
      "[975]\ttraining's rmse: 0.0887673\tvalid_1's rmse: 0.09305\n",
      "[1000]\ttraining's rmse: 0.0887382\tvalid_1's rmse: 0.093044\n",
      "[1025]\ttraining's rmse: 0.0887067\tvalid_1's rmse: 0.0930385\n",
      "[1050]\ttraining's rmse: 0.0886821\tvalid_1's rmse: 0.0930309\n",
      "[1075]\ttraining's rmse: 0.0886567\tvalid_1's rmse: 0.0930268\n",
      "[1100]\ttraining's rmse: 0.0886339\tvalid_1's rmse: 0.0930219\n",
      "[1125]\ttraining's rmse: 0.0886102\tvalid_1's rmse: 0.0930162\n",
      "[1150]\ttraining's rmse: 0.0885857\tvalid_1's rmse: 0.0930107\n",
      "[1175]\ttraining's rmse: 0.0885663\tvalid_1's rmse: 0.0930063\n",
      "[1200]\ttraining's rmse: 0.0885441\tvalid_1's rmse: 0.0930008\n",
      "[1225]\ttraining's rmse: 0.0885246\tvalid_1's rmse: 0.0929952\n",
      "[1250]\ttraining's rmse: 0.0885076\tvalid_1's rmse: 0.0929905\n",
      "[1275]\ttraining's rmse: 0.0884865\tvalid_1's rmse: 0.0929867\n",
      "[1300]\ttraining's rmse: 0.088469\tvalid_1's rmse: 0.0929825\n",
      "[1325]\ttraining's rmse: 0.0884499\tvalid_1's rmse: 0.0929779\n",
      "[1350]\ttraining's rmse: 0.0884304\tvalid_1's rmse: 0.092973\n",
      "[1375]\ttraining's rmse: 0.0884123\tvalid_1's rmse: 0.09297\n",
      "[1400]\ttraining's rmse: 0.0883989\tvalid_1's rmse: 0.0929651\n",
      "[1425]\ttraining's rmse: 0.0883804\tvalid_1's rmse: 0.0929615\n",
      "[1450]\ttraining's rmse: 0.0883638\tvalid_1's rmse: 0.0929588\n",
      "[1475]\ttraining's rmse: 0.0883497\tvalid_1's rmse: 0.0929549\n",
      "[1500]\ttraining's rmse: 0.0883386\tvalid_1's rmse: 0.0929519\n",
      "[1525]\ttraining's rmse: 0.0883263\tvalid_1's rmse: 0.0929497\n",
      "[1550]\ttraining's rmse: 0.0883145\tvalid_1's rmse: 0.0929468\n",
      "[1575]\ttraining's rmse: 0.0883039\tvalid_1's rmse: 0.0929444\n",
      "[1600]\ttraining's rmse: 0.0882959\tvalid_1's rmse: 0.0929423\n",
      "[1625]\ttraining's rmse: 0.0882855\tvalid_1's rmse: 0.0929385\n",
      "[1650]\ttraining's rmse: 0.0882752\tvalid_1's rmse: 0.0929345\n",
      "[1675]\ttraining's rmse: 0.0882663\tvalid_1's rmse: 0.0929319\n",
      "[1700]\ttraining's rmse: 0.088259\tvalid_1's rmse: 0.0929303\n",
      "[1725]\ttraining's rmse: 0.0882513\tvalid_1's rmse: 0.0929278\n",
      "[1750]\ttraining's rmse: 0.0882438\tvalid_1's rmse: 0.0929252\n",
      "[1775]\ttraining's rmse: 0.088234\tvalid_1's rmse: 0.0929238\n",
      "[1800]\ttraining's rmse: 0.0882272\tvalid_1's rmse: 0.0929215\n",
      "[1825]\ttraining's rmse: 0.0882201\tvalid_1's rmse: 0.092919\n",
      "[1850]\ttraining's rmse: 0.088212\tvalid_1's rmse: 0.0929176\n",
      "[1875]\ttraining's rmse: 0.0882075\tvalid_1's rmse: 0.0929162\n",
      "[1900]\ttraining's rmse: 0.0882021\tvalid_1's rmse: 0.0929151\n",
      "[1925]\ttraining's rmse: 0.0881966\tvalid_1's rmse: 0.0929136\n",
      "[1950]\ttraining's rmse: 0.0881909\tvalid_1's rmse: 0.092912\n",
      "[1975]\ttraining's rmse: 0.0881841\tvalid_1's rmse: 0.09291\n",
      "[2000]\ttraining's rmse: 0.0881787\tvalid_1's rmse: 0.0929074\n",
      "[2025]\ttraining's rmse: 0.0881733\tvalid_1's rmse: 0.0929058\n",
      "[2050]\ttraining's rmse: 0.0881688\tvalid_1's rmse: 0.0929041\n",
      "[2075]\ttraining's rmse: 0.0881633\tvalid_1's rmse: 0.0929024\n",
      "[2100]\ttraining's rmse: 0.088158\tvalid_1's rmse: 0.0929006\n",
      "[2125]\ttraining's rmse: 0.0881547\tvalid_1's rmse: 0.0929002\n",
      "[2150]\ttraining's rmse: 0.0881502\tvalid_1's rmse: 0.0928994\n",
      "[2175]\ttraining's rmse: 0.0881469\tvalid_1's rmse: 0.092899\n",
      "[2200]\ttraining's rmse: 0.0881442\tvalid_1's rmse: 0.0928985\n",
      "[2225]\ttraining's rmse: 0.0881401\tvalid_1's rmse: 0.0928974\n",
      "[2250]\ttraining's rmse: 0.0881371\tvalid_1's rmse: 0.092897\n",
      "[2275]\ttraining's rmse: 0.0881319\tvalid_1's rmse: 0.0928961\n",
      "[2300]\ttraining's rmse: 0.0881277\tvalid_1's rmse: 0.0928944\n",
      "[2325]\ttraining's rmse: 0.0881228\tvalid_1's rmse: 0.0928924\n",
      "[2350]\ttraining's rmse: 0.0881195\tvalid_1's rmse: 0.092892\n",
      "[2375]\ttraining's rmse: 0.0881153\tvalid_1's rmse: 0.0928911\n",
      "[2400]\ttraining's rmse: 0.0881114\tvalid_1's rmse: 0.0928904\n",
      "[2425]\ttraining's rmse: 0.0881079\tvalid_1's rmse: 0.092889\n",
      "[2450]\ttraining's rmse: 0.0881049\tvalid_1's rmse: 0.0928878\n",
      "[2475]\ttraining's rmse: 0.088102\tvalid_1's rmse: 0.0928878\n",
      "[2500]\ttraining's rmse: 0.0880985\tvalid_1's rmse: 0.0928873\n",
      "[2525]\ttraining's rmse: 0.0880967\tvalid_1's rmse: 0.0928869\n",
      "Early stopping, best iteration is:\n",
      "[2494]\ttraining's rmse: 0.0880993\tvalid_1's rmse: 0.0928869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.091951\tvalid_1's rmse: 0.0939894\n",
      "[50]\ttraining's rmse: 0.091773\tvalid_1's rmse: 0.0939337\n",
      "[75]\ttraining's rmse: 0.0915929\tvalid_1's rmse: 0.0938763\n",
      "[100]\ttraining's rmse: 0.0914312\tvalid_1's rmse: 0.0938279\n",
      "[125]\ttraining's rmse: 0.0912673\tvalid_1's rmse: 0.0937771\n",
      "[150]\ttraining's rmse: 0.0911209\tvalid_1's rmse: 0.0937296\n",
      "[175]\ttraining's rmse: 0.0909948\tvalid_1's rmse: 0.0936918\n",
      "[200]\ttraining's rmse: 0.0908623\tvalid_1's rmse: 0.0936534\n",
      "[225]\ttraining's rmse: 0.0907367\tvalid_1's rmse: 0.0936177\n",
      "[250]\ttraining's rmse: 0.0906257\tvalid_1's rmse: 0.0935845\n",
      "[275]\ttraining's rmse: 0.0905252\tvalid_1's rmse: 0.0935548\n",
      "[300]\ttraining's rmse: 0.0904263\tvalid_1's rmse: 0.0935269\n",
      "[325]\ttraining's rmse: 0.0903289\tvalid_1's rmse: 0.0934996\n",
      "[350]\ttraining's rmse: 0.0902332\tvalid_1's rmse: 0.0934754\n",
      "[375]\ttraining's rmse: 0.0901553\tvalid_1's rmse: 0.0934553\n",
      "[400]\ttraining's rmse: 0.0900704\tvalid_1's rmse: 0.0934322\n",
      "[425]\ttraining's rmse: 0.0899947\tvalid_1's rmse: 0.0934128\n",
      "[450]\ttraining's rmse: 0.0899233\tvalid_1's rmse: 0.0933943\n",
      "[475]\ttraining's rmse: 0.0898587\tvalid_1's rmse: 0.0933758\n",
      "[500]\ttraining's rmse: 0.0898042\tvalid_1's rmse: 0.0933594\n",
      "[525]\ttraining's rmse: 0.0897354\tvalid_1's rmse: 0.0933408\n",
      "[550]\ttraining's rmse: 0.0896692\tvalid_1's rmse: 0.0933268\n",
      "[575]\ttraining's rmse: 0.0896116\tvalid_1's rmse: 0.0933131\n",
      "[600]\ttraining's rmse: 0.0895528\tvalid_1's rmse: 0.0932999\n",
      "[625]\ttraining's rmse: 0.0895076\tvalid_1's rmse: 0.0932879\n",
      "[650]\ttraining's rmse: 0.08945\tvalid_1's rmse: 0.093276\n",
      "[675]\ttraining's rmse: 0.0893976\tvalid_1's rmse: 0.0932645\n",
      "[700]\ttraining's rmse: 0.0893498\tvalid_1's rmse: 0.0932534\n",
      "[725]\ttraining's rmse: 0.0893045\tvalid_1's rmse: 0.0932434\n",
      "[750]\ttraining's rmse: 0.0892635\tvalid_1's rmse: 0.0932335\n",
      "[775]\ttraining's rmse: 0.0892304\tvalid_1's rmse: 0.0932243\n",
      "[800]\ttraining's rmse: 0.0891882\tvalid_1's rmse: 0.0932156\n",
      "[825]\ttraining's rmse: 0.0891511\tvalid_1's rmse: 0.0932078\n",
      "[850]\ttraining's rmse: 0.0891176\tvalid_1's rmse: 0.0932016\n",
      "[875]\ttraining's rmse: 0.0890856\tvalid_1's rmse: 0.0931948\n",
      "[900]\ttraining's rmse: 0.0890501\tvalid_1's rmse: 0.0931873\n",
      "[925]\ttraining's rmse: 0.0890168\tvalid_1's rmse: 0.0931819\n",
      "[950]\ttraining's rmse: 0.0889858\tvalid_1's rmse: 0.093176\n",
      "[975]\ttraining's rmse: 0.088955\tvalid_1's rmse: 0.0931702\n",
      "[1000]\ttraining's rmse: 0.0889275\tvalid_1's rmse: 0.0931652\n",
      "[1025]\ttraining's rmse: 0.0888972\tvalid_1's rmse: 0.0931609\n",
      "[1050]\ttraining's rmse: 0.0888713\tvalid_1's rmse: 0.0931564\n",
      "[1075]\ttraining's rmse: 0.0888457\tvalid_1's rmse: 0.0931529\n",
      "[1100]\ttraining's rmse: 0.0888217\tvalid_1's rmse: 0.0931479\n",
      "[1125]\ttraining's rmse: 0.0887982\tvalid_1's rmse: 0.0931444\n",
      "[1150]\ttraining's rmse: 0.0887758\tvalid_1's rmse: 0.093141\n",
      "[1175]\ttraining's rmse: 0.0887549\tvalid_1's rmse: 0.0931389\n",
      "[1200]\ttraining's rmse: 0.0887348\tvalid_1's rmse: 0.0931358\n",
      "[1225]\ttraining's rmse: 0.0887131\tvalid_1's rmse: 0.0931335\n",
      "[1250]\ttraining's rmse: 0.0886953\tvalid_1's rmse: 0.0931314\n",
      "[1275]\ttraining's rmse: 0.0886774\tvalid_1's rmse: 0.0931297\n",
      "[1300]\ttraining's rmse: 0.088662\tvalid_1's rmse: 0.0931272\n",
      "[1325]\ttraining's rmse: 0.0886445\tvalid_1's rmse: 0.0931254\n",
      "[1350]\ttraining's rmse: 0.0886268\tvalid_1's rmse: 0.093124\n",
      "[1375]\ttraining's rmse: 0.0886088\tvalid_1's rmse: 0.0931226\n",
      "[1400]\ttraining's rmse: 0.0885931\tvalid_1's rmse: 0.0931208\n",
      "[1425]\ttraining's rmse: 0.0885766\tvalid_1's rmse: 0.0931193\n",
      "[1450]\ttraining's rmse: 0.0885611\tvalid_1's rmse: 0.0931191\n",
      "[1475]\ttraining's rmse: 0.0885476\tvalid_1's rmse: 0.0931175\n",
      "[1500]\ttraining's rmse: 0.0885354\tvalid_1's rmse: 0.0931164\n",
      "[1525]\ttraining's rmse: 0.0885216\tvalid_1's rmse: 0.093116\n",
      "[1550]\ttraining's rmse: 0.0885092\tvalid_1's rmse: 0.0931155\n",
      "[1575]\ttraining's rmse: 0.0884988\tvalid_1's rmse: 0.0931149\n",
      "[1600]\ttraining's rmse: 0.0884895\tvalid_1's rmse: 0.0931141\n",
      "[1625]\ttraining's rmse: 0.0884804\tvalid_1's rmse: 0.0931134\n",
      "[1650]\ttraining's rmse: 0.0884719\tvalid_1's rmse: 0.0931128\n",
      "[1675]\ttraining's rmse: 0.0884635\tvalid_1's rmse: 0.0931113\n",
      "[1700]\ttraining's rmse: 0.0884546\tvalid_1's rmse: 0.0931106\n",
      "[1725]\ttraining's rmse: 0.0884466\tvalid_1's rmse: 0.09311\n",
      "[1750]\ttraining's rmse: 0.088437\tvalid_1's rmse: 0.0931095\n",
      "[1775]\ttraining's rmse: 0.0884304\tvalid_1's rmse: 0.0931098\n",
      "[1800]\ttraining's rmse: 0.0884211\tvalid_1's rmse: 0.0931102\n",
      "Early stopping, best iteration is:\n",
      "[1753]\ttraining's rmse: 0.0884366\tvalid_1's rmse: 0.0931094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0938035\tvalid_1's rmse: 0.0903183\n",
      "[50]\ttraining's rmse: 0.0936681\tvalid_1's rmse: 0.0902685\n",
      "[75]\ttraining's rmse: 0.0935202\tvalid_1's rmse: 0.090216\n",
      "[100]\ttraining's rmse: 0.0933894\tvalid_1's rmse: 0.0901706\n",
      "[125]\ttraining's rmse: 0.0932539\tvalid_1's rmse: 0.0901254\n",
      "[150]\ttraining's rmse: 0.0931274\tvalid_1's rmse: 0.0900825\n",
      "[175]\ttraining's rmse: 0.0930234\tvalid_1's rmse: 0.0900508\n",
      "[200]\ttraining's rmse: 0.0929124\tvalid_1's rmse: 0.0900184\n",
      "[225]\ttraining's rmse: 0.0928047\tvalid_1's rmse: 0.089987\n",
      "[250]\ttraining's rmse: 0.0927111\tvalid_1's rmse: 0.0899603\n",
      "[275]\ttraining's rmse: 0.0926271\tvalid_1's rmse: 0.0899341\n",
      "[300]\ttraining's rmse: 0.0925425\tvalid_1's rmse: 0.0899101\n",
      "[325]\ttraining's rmse: 0.0924554\tvalid_1's rmse: 0.0898871\n",
      "[350]\ttraining's rmse: 0.0923704\tvalid_1's rmse: 0.0898653\n",
      "[375]\ttraining's rmse: 0.092301\tvalid_1's rmse: 0.0898475\n",
      "[400]\ttraining's rmse: 0.0922225\tvalid_1's rmse: 0.0898278\n",
      "[425]\ttraining's rmse: 0.0921528\tvalid_1's rmse: 0.089815\n",
      "[450]\ttraining's rmse: 0.0920898\tvalid_1's rmse: 0.0897989\n",
      "[475]\ttraining's rmse: 0.0920295\tvalid_1's rmse: 0.0897861\n",
      "[500]\ttraining's rmse: 0.0919806\tvalid_1's rmse: 0.0897726\n",
      "[525]\ttraining's rmse: 0.0919138\tvalid_1's rmse: 0.0897629\n",
      "[550]\ttraining's rmse: 0.0918554\tvalid_1's rmse: 0.0897517\n",
      "[575]\ttraining's rmse: 0.0917983\tvalid_1's rmse: 0.0897411\n",
      "[600]\ttraining's rmse: 0.0917446\tvalid_1's rmse: 0.0897374\n",
      "[625]\ttraining's rmse: 0.0917007\tvalid_1's rmse: 0.0897338\n",
      "[650]\ttraining's rmse: 0.0916461\tvalid_1's rmse: 0.0897254\n",
      "[675]\ttraining's rmse: 0.0915918\tvalid_1's rmse: 0.0897179\n",
      "[700]\ttraining's rmse: 0.0915448\tvalid_1's rmse: 0.0897096\n",
      "[725]\ttraining's rmse: 0.0914995\tvalid_1's rmse: 0.0897106\n",
      "[750]\ttraining's rmse: 0.091457\tvalid_1's rmse: 0.0897044\n",
      "[775]\ttraining's rmse: 0.0914221\tvalid_1's rmse: 0.0897075\n",
      "[800]\ttraining's rmse: 0.0913762\tvalid_1's rmse: 0.0897032\n",
      "[825]\ttraining's rmse: 0.091339\tvalid_1's rmse: 0.0897105\n",
      "[850]\ttraining's rmse: 0.0912995\tvalid_1's rmse: 0.0897067\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's rmse: 0.0913618\tvalid_1's rmse: 0.0897014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0896795\tvalid_1's rmse: 0.092538\n",
      "[50]\ttraining's rmse: 0.0895301\tvalid_1's rmse: 0.0924783\n",
      "[75]\ttraining's rmse: 0.0893856\tvalid_1's rmse: 0.0924215\n",
      "[100]\ttraining's rmse: 0.0892476\tvalid_1's rmse: 0.0923711\n",
      "[125]\ttraining's rmse: 0.0891078\tvalid_1's rmse: 0.0923212\n",
      "[150]\ttraining's rmse: 0.0889792\tvalid_1's rmse: 0.0922742\n",
      "[175]\ttraining's rmse: 0.0888773\tvalid_1's rmse: 0.0922363\n",
      "[200]\ttraining's rmse: 0.0887635\tvalid_1's rmse: 0.0921971\n",
      "[225]\ttraining's rmse: 0.0886533\tvalid_1's rmse: 0.092159\n",
      "[250]\ttraining's rmse: 0.0885579\tvalid_1's rmse: 0.0921246\n",
      "[275]\ttraining's rmse: 0.0884695\tvalid_1's rmse: 0.0920934\n",
      "[300]\ttraining's rmse: 0.088382\tvalid_1's rmse: 0.0920625\n",
      "[325]\ttraining's rmse: 0.0882972\tvalid_1's rmse: 0.0920353\n",
      "[350]\ttraining's rmse: 0.0882155\tvalid_1's rmse: 0.0920068\n",
      "[375]\ttraining's rmse: 0.0881432\tvalid_1's rmse: 0.091984\n",
      "[400]\ttraining's rmse: 0.0880671\tvalid_1's rmse: 0.0919606\n",
      "[425]\ttraining's rmse: 0.0879967\tvalid_1's rmse: 0.0919368\n",
      "[450]\ttraining's rmse: 0.0879313\tvalid_1's rmse: 0.0919134\n",
      "[475]\ttraining's rmse: 0.0878713\tvalid_1's rmse: 0.091893\n",
      "[500]\ttraining's rmse: 0.0878229\tvalid_1's rmse: 0.0918734\n",
      "[525]\ttraining's rmse: 0.0877605\tvalid_1's rmse: 0.0918543\n",
      "[550]\ttraining's rmse: 0.0877026\tvalid_1's rmse: 0.0918377\n",
      "[575]\ttraining's rmse: 0.0876509\tvalid_1's rmse: 0.0918222\n",
      "[600]\ttraining's rmse: 0.0876036\tvalid_1's rmse: 0.0918081\n",
      "[625]\ttraining's rmse: 0.0875645\tvalid_1's rmse: 0.0917943\n",
      "[650]\ttraining's rmse: 0.0875154\tvalid_1's rmse: 0.0917817\n",
      "[675]\ttraining's rmse: 0.0874704\tvalid_1's rmse: 0.0917681\n",
      "[700]\ttraining's rmse: 0.0874288\tvalid_1's rmse: 0.0917558\n",
      "[725]\ttraining's rmse: 0.0873892\tvalid_1's rmse: 0.0917455\n",
      "[750]\ttraining's rmse: 0.087351\tvalid_1's rmse: 0.0917344\n",
      "[775]\ttraining's rmse: 0.0873201\tvalid_1's rmse: 0.0917232\n",
      "[800]\ttraining's rmse: 0.0872829\tvalid_1's rmse: 0.0917133\n",
      "[825]\ttraining's rmse: 0.0872503\tvalid_1's rmse: 0.0917036\n",
      "[850]\ttraining's rmse: 0.0872145\tvalid_1's rmse: 0.0916961\n",
      "[875]\ttraining's rmse: 0.087186\tvalid_1's rmse: 0.0916884\n",
      "[900]\ttraining's rmse: 0.0871541\tvalid_1's rmse: 0.0916794\n",
      "[925]\ttraining's rmse: 0.0871244\tvalid_1's rmse: 0.0916704\n",
      "[950]\ttraining's rmse: 0.0870975\tvalid_1's rmse: 0.0916619\n",
      "[975]\ttraining's rmse: 0.0870736\tvalid_1's rmse: 0.0916546\n",
      "[1000]\ttraining's rmse: 0.0870481\tvalid_1's rmse: 0.0916488\n",
      "[1025]\ttraining's rmse: 0.0870208\tvalid_1's rmse: 0.0916406\n",
      "[1050]\ttraining's rmse: 0.086997\tvalid_1's rmse: 0.0916336\n",
      "[1075]\ttraining's rmse: 0.0869762\tvalid_1's rmse: 0.0916291\n",
      "[1100]\ttraining's rmse: 0.086956\tvalid_1's rmse: 0.0916242\n",
      "[1125]\ttraining's rmse: 0.0869357\tvalid_1's rmse: 0.0916172\n",
      "[1150]\ttraining's rmse: 0.086914\tvalid_1's rmse: 0.0916111\n",
      "[1175]\ttraining's rmse: 0.0868963\tvalid_1's rmse: 0.0916064\n",
      "[1200]\ttraining's rmse: 0.0868783\tvalid_1's rmse: 0.0916011\n",
      "[1225]\ttraining's rmse: 0.08686\tvalid_1's rmse: 0.091596\n",
      "[1250]\ttraining's rmse: 0.086842\tvalid_1's rmse: 0.0915918\n",
      "[1275]\ttraining's rmse: 0.0868234\tvalid_1's rmse: 0.091588\n",
      "[1300]\ttraining's rmse: 0.0868117\tvalid_1's rmse: 0.0915845\n",
      "[1325]\ttraining's rmse: 0.086799\tvalid_1's rmse: 0.0915813\n",
      "[1350]\ttraining's rmse: 0.086782\tvalid_1's rmse: 0.0915779\n",
      "[1375]\ttraining's rmse: 0.0867652\tvalid_1's rmse: 0.0915748\n",
      "[1400]\ttraining's rmse: 0.0867529\tvalid_1's rmse: 0.091571\n",
      "[1425]\ttraining's rmse: 0.0867391\tvalid_1's rmse: 0.0915689\n",
      "[1450]\ttraining's rmse: 0.0867222\tvalid_1's rmse: 0.0915654\n",
      "[1475]\ttraining's rmse: 0.0867094\tvalid_1's rmse: 0.0915626\n",
      "[1500]\ttraining's rmse: 0.0866955\tvalid_1's rmse: 0.0915605\n",
      "[1525]\ttraining's rmse: 0.0866864\tvalid_1's rmse: 0.0915587\n",
      "[1550]\ttraining's rmse: 0.0866748\tvalid_1's rmse: 0.0915553\n",
      "[1575]\ttraining's rmse: 0.0866672\tvalid_1's rmse: 0.091553\n",
      "[1600]\ttraining's rmse: 0.086658\tvalid_1's rmse: 0.0915502\n",
      "[1625]\ttraining's rmse: 0.0866465\tvalid_1's rmse: 0.0915481\n",
      "[1650]\ttraining's rmse: 0.0866372\tvalid_1's rmse: 0.0915458\n",
      "[1675]\ttraining's rmse: 0.0866305\tvalid_1's rmse: 0.0915432\n",
      "[1700]\ttraining's rmse: 0.0866219\tvalid_1's rmse: 0.0915407\n",
      "[1725]\ttraining's rmse: 0.0866149\tvalid_1's rmse: 0.0915391\n",
      "[1750]\ttraining's rmse: 0.0866051\tvalid_1's rmse: 0.0915365\n",
      "[1775]\ttraining's rmse: 0.0865998\tvalid_1's rmse: 0.0915357\n",
      "[1800]\ttraining's rmse: 0.0865943\tvalid_1's rmse: 0.0915339\n",
      "[1825]\ttraining's rmse: 0.086589\tvalid_1's rmse: 0.0915324\n",
      "[1850]\ttraining's rmse: 0.0865827\tvalid_1's rmse: 0.0915306\n",
      "[1875]\ttraining's rmse: 0.0865781\tvalid_1's rmse: 0.0915301\n",
      "[1900]\ttraining's rmse: 0.086572\tvalid_1's rmse: 0.0915271\n",
      "[1925]\ttraining's rmse: 0.0865664\tvalid_1's rmse: 0.0915258\n",
      "[1950]\ttraining's rmse: 0.0865604\tvalid_1's rmse: 0.091523\n",
      "[1975]\ttraining's rmse: 0.0865561\tvalid_1's rmse: 0.0915198\n",
      "[2000]\ttraining's rmse: 0.0865516\tvalid_1's rmse: 0.091519\n",
      "[2025]\ttraining's rmse: 0.0865465\tvalid_1's rmse: 0.0915164\n",
      "[2050]\ttraining's rmse: 0.0865421\tvalid_1's rmse: 0.0915155\n",
      "[2075]\ttraining's rmse: 0.0865369\tvalid_1's rmse: 0.0915141\n",
      "[2100]\ttraining's rmse: 0.0865333\tvalid_1's rmse: 0.0915131\n",
      "[2125]\ttraining's rmse: 0.0865292\tvalid_1's rmse: 0.091512\n",
      "[2150]\ttraining's rmse: 0.0865251\tvalid_1's rmse: 0.0915111\n",
      "[2175]\ttraining's rmse: 0.0865222\tvalid_1's rmse: 0.0915103\n",
      "[2200]\ttraining's rmse: 0.0865161\tvalid_1's rmse: 0.0915082\n",
      "[2225]\ttraining's rmse: 0.0865122\tvalid_1's rmse: 0.0915062\n",
      "[2250]\ttraining's rmse: 0.0865088\tvalid_1's rmse: 0.0915058\n",
      "[2275]\ttraining's rmse: 0.0865054\tvalid_1's rmse: 0.0915055\n",
      "[2300]\ttraining's rmse: 0.0865019\tvalid_1's rmse: 0.0915051\n",
      "[2325]\ttraining's rmse: 0.0864967\tvalid_1's rmse: 0.0915043\n",
      "[2350]\ttraining's rmse: 0.0864936\tvalid_1's rmse: 0.0915036\n",
      "[2375]\ttraining's rmse: 0.0864893\tvalid_1's rmse: 0.0915024\n",
      "[2400]\ttraining's rmse: 0.0864843\tvalid_1's rmse: 0.0915013\n",
      "[2425]\ttraining's rmse: 0.0864821\tvalid_1's rmse: 0.0915009\n",
      "[2450]\ttraining's rmse: 0.0864787\tvalid_1's rmse: 0.0915002\n",
      "[2475]\ttraining's rmse: 0.0864754\tvalid_1's rmse: 0.0915003\n",
      "[2500]\ttraining's rmse: 0.0864724\tvalid_1's rmse: 0.0914997\n",
      "[2525]\ttraining's rmse: 0.0864691\tvalid_1's rmse: 0.0914985\n",
      "[2550]\ttraining's rmse: 0.0864664\tvalid_1's rmse: 0.0914978\n",
      "[2575]\ttraining's rmse: 0.0864632\tvalid_1's rmse: 0.0914974\n",
      "[2600]\ttraining's rmse: 0.0864603\tvalid_1's rmse: 0.0914967\n",
      "[2625]\ttraining's rmse: 0.0864581\tvalid_1's rmse: 0.0914956\n",
      "[2650]\ttraining's rmse: 0.086456\tvalid_1's rmse: 0.0914945\n",
      "[2675]\ttraining's rmse: 0.086454\tvalid_1's rmse: 0.0914934\n",
      "[2700]\ttraining's rmse: 0.0864517\tvalid_1's rmse: 0.0914932\n",
      "[2725]\ttraining's rmse: 0.086449\tvalid_1's rmse: 0.091493\n",
      "[2750]\ttraining's rmse: 0.086447\tvalid_1's rmse: 0.091492\n",
      "[2775]\ttraining's rmse: 0.0864443\tvalid_1's rmse: 0.0914919\n",
      "[2800]\ttraining's rmse: 0.0864428\tvalid_1's rmse: 0.0914914\n",
      "[2825]\ttraining's rmse: 0.0864403\tvalid_1's rmse: 0.0914907\n",
      "[2850]\ttraining's rmse: 0.0864381\tvalid_1's rmse: 0.0914906\n",
      "[2875]\ttraining's rmse: 0.0864365\tvalid_1's rmse: 0.0914904\n",
      "[2900]\ttraining's rmse: 0.0864347\tvalid_1's rmse: 0.09149\n",
      "[2925]\ttraining's rmse: 0.0864335\tvalid_1's rmse: 0.0914901\n",
      "[2950]\ttraining's rmse: 0.0864303\tvalid_1's rmse: 0.09149\n",
      "[2975]\ttraining's rmse: 0.0864287\tvalid_1's rmse: 0.0914893\n",
      "[3000]\ttraining's rmse: 0.0864276\tvalid_1's rmse: 0.0914884\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0864276\tvalid_1's rmse: 0.0914884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0898185\tvalid_1's rmse: 0.092289\n",
      "[50]\ttraining's rmse: 0.0896786\tvalid_1's rmse: 0.0922313\n",
      "[75]\ttraining's rmse: 0.089536\tvalid_1's rmse: 0.0921738\n",
      "[100]\ttraining's rmse: 0.0894104\tvalid_1's rmse: 0.0921231\n",
      "[125]\ttraining's rmse: 0.0892754\tvalid_1's rmse: 0.092072\n",
      "[150]\ttraining's rmse: 0.0891533\tvalid_1's rmse: 0.0920262\n",
      "[175]\ttraining's rmse: 0.0890517\tvalid_1's rmse: 0.091989\n",
      "[200]\ttraining's rmse: 0.088942\tvalid_1's rmse: 0.091951\n",
      "[225]\ttraining's rmse: 0.0888402\tvalid_1's rmse: 0.0919169\n",
      "[250]\ttraining's rmse: 0.0887491\tvalid_1's rmse: 0.0918844\n",
      "[275]\ttraining's rmse: 0.0886635\tvalid_1's rmse: 0.0918547\n",
      "[300]\ttraining's rmse: 0.0885796\tvalid_1's rmse: 0.0918273\n",
      "[325]\ttraining's rmse: 0.0884965\tvalid_1's rmse: 0.091801\n",
      "[350]\ttraining's rmse: 0.0884189\tvalid_1's rmse: 0.0917775\n",
      "[375]\ttraining's rmse: 0.0883567\tvalid_1's rmse: 0.0917562\n",
      "[400]\ttraining's rmse: 0.0882846\tvalid_1's rmse: 0.0917355\n",
      "[425]\ttraining's rmse: 0.0882182\tvalid_1's rmse: 0.0917153\n",
      "[450]\ttraining's rmse: 0.0881562\tvalid_1's rmse: 0.0916959\n",
      "[475]\ttraining's rmse: 0.0881001\tvalid_1's rmse: 0.0916781\n",
      "[500]\ttraining's rmse: 0.0880521\tvalid_1's rmse: 0.091661\n",
      "[525]\ttraining's rmse: 0.0879885\tvalid_1's rmse: 0.0916433\n",
      "[550]\ttraining's rmse: 0.0879319\tvalid_1's rmse: 0.0916304\n",
      "[575]\ttraining's rmse: 0.0878784\tvalid_1's rmse: 0.0916157\n",
      "[600]\ttraining's rmse: 0.0878243\tvalid_1's rmse: 0.0916038\n",
      "[625]\ttraining's rmse: 0.0877827\tvalid_1's rmse: 0.0915919\n",
      "[650]\ttraining's rmse: 0.0877331\tvalid_1's rmse: 0.0915798\n",
      "[675]\ttraining's rmse: 0.0876844\tvalid_1's rmse: 0.0915694\n",
      "[700]\ttraining's rmse: 0.0876395\tvalid_1's rmse: 0.0915593\n",
      "[725]\ttraining's rmse: 0.0875979\tvalid_1's rmse: 0.0915499\n",
      "[750]\ttraining's rmse: 0.0875592\tvalid_1's rmse: 0.09154\n",
      "[775]\ttraining's rmse: 0.0875255\tvalid_1's rmse: 0.0915311\n",
      "[800]\ttraining's rmse: 0.0874836\tvalid_1's rmse: 0.0915232\n",
      "[825]\ttraining's rmse: 0.0874476\tvalid_1's rmse: 0.0915144\n",
      "[850]\ttraining's rmse: 0.0874147\tvalid_1's rmse: 0.0915081\n",
      "[875]\ttraining's rmse: 0.0873832\tvalid_1's rmse: 0.091501\n",
      "[900]\ttraining's rmse: 0.0873497\tvalid_1's rmse: 0.0914954\n",
      "[925]\ttraining's rmse: 0.0873186\tvalid_1's rmse: 0.0914902\n",
      "[950]\ttraining's rmse: 0.0872899\tvalid_1's rmse: 0.0914845\n",
      "[975]\ttraining's rmse: 0.0872639\tvalid_1's rmse: 0.0914794\n",
      "[1000]\ttraining's rmse: 0.0872397\tvalid_1's rmse: 0.0914749\n",
      "[1025]\ttraining's rmse: 0.0872103\tvalid_1's rmse: 0.0914703\n",
      "[1050]\ttraining's rmse: 0.0871852\tvalid_1's rmse: 0.0914656\n",
      "[1075]\ttraining's rmse: 0.0871588\tvalid_1's rmse: 0.0914616\n",
      "[1100]\ttraining's rmse: 0.0871374\tvalid_1's rmse: 0.0914581\n",
      "[1125]\ttraining's rmse: 0.0871151\tvalid_1's rmse: 0.0914546\n",
      "[1150]\ttraining's rmse: 0.0870918\tvalid_1's rmse: 0.091451\n",
      "[1175]\ttraining's rmse: 0.0870735\tvalid_1's rmse: 0.0914488\n",
      "[1200]\ttraining's rmse: 0.0870544\tvalid_1's rmse: 0.0914458\n",
      "[1225]\ttraining's rmse: 0.087037\tvalid_1's rmse: 0.0914439\n",
      "[1250]\ttraining's rmse: 0.0870204\tvalid_1's rmse: 0.0914409\n",
      "[1275]\ttraining's rmse: 0.0869984\tvalid_1's rmse: 0.0914381\n",
      "[1300]\ttraining's rmse: 0.0869832\tvalid_1's rmse: 0.0914365\n",
      "[1325]\ttraining's rmse: 0.0869693\tvalid_1's rmse: 0.091435\n",
      "[1350]\ttraining's rmse: 0.086953\tvalid_1's rmse: 0.0914336\n",
      "[1375]\ttraining's rmse: 0.0869358\tvalid_1's rmse: 0.0914318\n",
      "[1400]\ttraining's rmse: 0.0869224\tvalid_1's rmse: 0.0914295\n",
      "[1425]\ttraining's rmse: 0.0869086\tvalid_1's rmse: 0.0914284\n",
      "[1450]\ttraining's rmse: 0.0868969\tvalid_1's rmse: 0.0914271\n",
      "[1475]\ttraining's rmse: 0.0868848\tvalid_1's rmse: 0.0914257\n",
      "[1500]\ttraining's rmse: 0.0868714\tvalid_1's rmse: 0.0914242\n",
      "[1525]\ttraining's rmse: 0.0868609\tvalid_1's rmse: 0.0914235\n",
      "[1550]\ttraining's rmse: 0.08685\tvalid_1's rmse: 0.0914229\n",
      "[1575]\ttraining's rmse: 0.086839\tvalid_1's rmse: 0.0914218\n",
      "[1600]\ttraining's rmse: 0.086831\tvalid_1's rmse: 0.0914216\n",
      "[1625]\ttraining's rmse: 0.0868202\tvalid_1's rmse: 0.0914207\n",
      "[1650]\ttraining's rmse: 0.0868119\tvalid_1's rmse: 0.0914207\n",
      "[1675]\ttraining's rmse: 0.0868061\tvalid_1's rmse: 0.0914198\n",
      "[1700]\ttraining's rmse: 0.0867987\tvalid_1's rmse: 0.0914189\n",
      "[1725]\ttraining's rmse: 0.0867903\tvalid_1's rmse: 0.0914178\n",
      "[1750]\ttraining's rmse: 0.0867822\tvalid_1's rmse: 0.0914174\n",
      "[1775]\ttraining's rmse: 0.086775\tvalid_1's rmse: 0.0914176\n",
      "[1800]\ttraining's rmse: 0.0867682\tvalid_1's rmse: 0.0914173\n",
      "[1825]\ttraining's rmse: 0.0867618\tvalid_1's rmse: 0.0914175\n",
      "[1850]\ttraining's rmse: 0.0867552\tvalid_1's rmse: 0.0914166\n",
      "[1875]\ttraining's rmse: 0.0867497\tvalid_1's rmse: 0.0914161\n",
      "[1900]\ttraining's rmse: 0.0867441\tvalid_1's rmse: 0.0914166\n",
      "[1925]\ttraining's rmse: 0.0867391\tvalid_1's rmse: 0.0914167\n",
      "Early stopping, best iteration is:\n",
      "[1876]\ttraining's rmse: 0.0867496\tvalid_1's rmse: 0.0914161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0922784\tvalid_1's rmse: 0.08729\n",
      "[50]\ttraining's rmse: 0.0921474\tvalid_1's rmse: 0.0872377\n",
      "[75]\ttraining's rmse: 0.092017\tvalid_1's rmse: 0.0871864\n",
      "[100]\ttraining's rmse: 0.0919008\tvalid_1's rmse: 0.0871443\n",
      "[125]\ttraining's rmse: 0.0917794\tvalid_1's rmse: 0.0870996\n",
      "[150]\ttraining's rmse: 0.0916674\tvalid_1's rmse: 0.0870611\n",
      "[175]\ttraining's rmse: 0.0915734\tvalid_1's rmse: 0.0870296\n",
      "[200]\ttraining's rmse: 0.0914708\tvalid_1's rmse: 0.0869993\n",
      "[225]\ttraining's rmse: 0.0913755\tvalid_1's rmse: 0.0869665\n",
      "[250]\ttraining's rmse: 0.0912894\tvalid_1's rmse: 0.0869386\n",
      "[275]\ttraining's rmse: 0.0912133\tvalid_1's rmse: 0.0869125\n",
      "[300]\ttraining's rmse: 0.0911342\tvalid_1's rmse: 0.0868882\n",
      "[325]\ttraining's rmse: 0.0910552\tvalid_1's rmse: 0.0868638\n",
      "[350]\ttraining's rmse: 0.090978\tvalid_1's rmse: 0.0868416\n",
      "[375]\ttraining's rmse: 0.0909144\tvalid_1's rmse: 0.0868226\n",
      "[400]\ttraining's rmse: 0.0908474\tvalid_1's rmse: 0.0868139\n",
      "[425]\ttraining's rmse: 0.0907822\tvalid_1's rmse: 0.0868013\n",
      "[450]\ttraining's rmse: 0.0907219\tvalid_1's rmse: 0.0867884\n",
      "[475]\ttraining's rmse: 0.0906684\tvalid_1's rmse: 0.0867801\n",
      "[500]\ttraining's rmse: 0.090623\tvalid_1's rmse: 0.0867654\n",
      "[525]\ttraining's rmse: 0.0905594\tvalid_1's rmse: 0.0867563\n",
      "[550]\ttraining's rmse: 0.0905021\tvalid_1's rmse: 0.086748\n",
      "[575]\ttraining's rmse: 0.0904497\tvalid_1's rmse: 0.0867349\n",
      "[600]\ttraining's rmse: 0.0903986\tvalid_1's rmse: 0.0867303\n",
      "[625]\ttraining's rmse: 0.0903593\tvalid_1's rmse: 0.08672\n",
      "[650]\ttraining's rmse: 0.0903083\tvalid_1's rmse: 0.0867133\n",
      "[675]\ttraining's rmse: 0.09026\tvalid_1's rmse: 0.0867041\n",
      "[700]\ttraining's rmse: 0.0902158\tvalid_1's rmse: 0.0867008\n",
      "[725]\ttraining's rmse: 0.0901731\tvalid_1's rmse: 0.0867031\n",
      "[750]\ttraining's rmse: 0.0901352\tvalid_1's rmse: 0.0867137\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's rmse: 0.0901815\tvalid_1's rmse: 0.0866992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0899348\tvalid_1's rmse: 0.0924084\n",
      "[50]\ttraining's rmse: 0.0897866\tvalid_1's rmse: 0.0923538\n",
      "[75]\ttraining's rmse: 0.0896361\tvalid_1's rmse: 0.0922969\n",
      "[100]\ttraining's rmse: 0.0894944\tvalid_1's rmse: 0.0922506\n",
      "[125]\ttraining's rmse: 0.0893583\tvalid_1's rmse: 0.0922025\n",
      "[150]\ttraining's rmse: 0.0892347\tvalid_1's rmse: 0.092158\n",
      "[175]\ttraining's rmse: 0.0891285\tvalid_1's rmse: 0.0921191\n",
      "[200]\ttraining's rmse: 0.0890151\tvalid_1's rmse: 0.0920815\n",
      "[225]\ttraining's rmse: 0.0889063\tvalid_1's rmse: 0.0920465\n",
      "[250]\ttraining's rmse: 0.0888158\tvalid_1's rmse: 0.092012\n",
      "[275]\ttraining's rmse: 0.0887294\tvalid_1's rmse: 0.091981\n",
      "[300]\ttraining's rmse: 0.0886432\tvalid_1's rmse: 0.0919501\n",
      "[325]\ttraining's rmse: 0.0885562\tvalid_1's rmse: 0.091923\n",
      "[350]\ttraining's rmse: 0.0884763\tvalid_1's rmse: 0.0918986\n",
      "[375]\ttraining's rmse: 0.0884075\tvalid_1's rmse: 0.0918748\n",
      "[400]\ttraining's rmse: 0.0883338\tvalid_1's rmse: 0.0918539\n",
      "[425]\ttraining's rmse: 0.0882636\tvalid_1's rmse: 0.0918309\n",
      "[450]\ttraining's rmse: 0.088199\tvalid_1's rmse: 0.0918111\n",
      "[475]\ttraining's rmse: 0.08814\tvalid_1's rmse: 0.091791\n",
      "[500]\ttraining's rmse: 0.0880879\tvalid_1's rmse: 0.0917717\n",
      "[525]\ttraining's rmse: 0.0880207\tvalid_1's rmse: 0.0917534\n",
      "[550]\ttraining's rmse: 0.0879672\tvalid_1's rmse: 0.0917366\n",
      "[575]\ttraining's rmse: 0.0879108\tvalid_1's rmse: 0.0917201\n",
      "[600]\ttraining's rmse: 0.0878637\tvalid_1's rmse: 0.0917047\n",
      "[625]\ttraining's rmse: 0.0878212\tvalid_1's rmse: 0.0916921\n",
      "[650]\ttraining's rmse: 0.0877729\tvalid_1's rmse: 0.0916786\n",
      "[675]\ttraining's rmse: 0.0877261\tvalid_1's rmse: 0.0916664\n",
      "[700]\ttraining's rmse: 0.0876854\tvalid_1's rmse: 0.0916541\n",
      "[725]\ttraining's rmse: 0.0876459\tvalid_1's rmse: 0.0916434\n",
      "[750]\ttraining's rmse: 0.0876051\tvalid_1's rmse: 0.0916342\n",
      "[775]\ttraining's rmse: 0.0875747\tvalid_1's rmse: 0.0916223\n",
      "[800]\ttraining's rmse: 0.0875369\tvalid_1's rmse: 0.0916125\n",
      "[825]\ttraining's rmse: 0.087505\tvalid_1's rmse: 0.0916033\n",
      "[850]\ttraining's rmse: 0.0874699\tvalid_1's rmse: 0.0915945\n",
      "[875]\ttraining's rmse: 0.0874407\tvalid_1's rmse: 0.0915864\n",
      "[900]\ttraining's rmse: 0.0874083\tvalid_1's rmse: 0.0915788\n",
      "[925]\ttraining's rmse: 0.0873776\tvalid_1's rmse: 0.0915708\n",
      "[950]\ttraining's rmse: 0.0873487\tvalid_1's rmse: 0.0915634\n",
      "[975]\ttraining's rmse: 0.0873233\tvalid_1's rmse: 0.0915547\n",
      "[1000]\ttraining's rmse: 0.0872979\tvalid_1's rmse: 0.091548\n",
      "[1025]\ttraining's rmse: 0.0872707\tvalid_1's rmse: 0.0915397\n",
      "[1050]\ttraining's rmse: 0.0872487\tvalid_1's rmse: 0.0915334\n",
      "[1075]\ttraining's rmse: 0.0872275\tvalid_1's rmse: 0.0915294\n",
      "[1100]\ttraining's rmse: 0.0872057\tvalid_1's rmse: 0.0915244\n",
      "[1125]\ttraining's rmse: 0.0871845\tvalid_1's rmse: 0.091519\n",
      "[1150]\ttraining's rmse: 0.0871617\tvalid_1's rmse: 0.0915134\n",
      "[1175]\ttraining's rmse: 0.087142\tvalid_1's rmse: 0.0915086\n",
      "[1200]\ttraining's rmse: 0.0871249\tvalid_1's rmse: 0.091504\n",
      "[1225]\ttraining's rmse: 0.0871065\tvalid_1's rmse: 0.0914998\n",
      "[1250]\ttraining's rmse: 0.0870898\tvalid_1's rmse: 0.0914964\n",
      "[1275]\ttraining's rmse: 0.0870686\tvalid_1's rmse: 0.0914918\n",
      "[1300]\ttraining's rmse: 0.0870551\tvalid_1's rmse: 0.0914876\n",
      "[1325]\ttraining's rmse: 0.0870378\tvalid_1's rmse: 0.0914837\n",
      "[1350]\ttraining's rmse: 0.0870223\tvalid_1's rmse: 0.0914801\n",
      "[1375]\ttraining's rmse: 0.0870056\tvalid_1's rmse: 0.0914769\n",
      "[1400]\ttraining's rmse: 0.0869926\tvalid_1's rmse: 0.0914729\n",
      "[1425]\ttraining's rmse: 0.0869754\tvalid_1's rmse: 0.0914707\n",
      "[1450]\ttraining's rmse: 0.0869594\tvalid_1's rmse: 0.0914681\n",
      "[1475]\ttraining's rmse: 0.0869464\tvalid_1's rmse: 0.0914653\n",
      "[1500]\ttraining's rmse: 0.0869359\tvalid_1's rmse: 0.0914621\n",
      "[1525]\ttraining's rmse: 0.0869268\tvalid_1's rmse: 0.0914594\n",
      "[1550]\ttraining's rmse: 0.0869144\tvalid_1's rmse: 0.0914574\n",
      "[1575]\ttraining's rmse: 0.0869049\tvalid_1's rmse: 0.0914548\n",
      "[1600]\ttraining's rmse: 0.0868971\tvalid_1's rmse: 0.0914519\n",
      "[1625]\ttraining's rmse: 0.0868863\tvalid_1's rmse: 0.0914498\n",
      "[1650]\ttraining's rmse: 0.0868775\tvalid_1's rmse: 0.0914475\n",
      "[1675]\ttraining's rmse: 0.08687\tvalid_1's rmse: 0.0914454\n",
      "[1700]\ttraining's rmse: 0.0868621\tvalid_1's rmse: 0.0914422\n",
      "[1725]\ttraining's rmse: 0.0868523\tvalid_1's rmse: 0.0914405\n",
      "[1750]\ttraining's rmse: 0.0868444\tvalid_1's rmse: 0.0914374\n",
      "[1775]\ttraining's rmse: 0.0868368\tvalid_1's rmse: 0.0914357\n",
      "[1800]\ttraining's rmse: 0.0868301\tvalid_1's rmse: 0.0914341\n",
      "[1825]\ttraining's rmse: 0.0868229\tvalid_1's rmse: 0.0914326\n",
      "[1850]\ttraining's rmse: 0.0868179\tvalid_1's rmse: 0.0914314\n",
      "[1875]\ttraining's rmse: 0.0868096\tvalid_1's rmse: 0.0914291\n",
      "[1900]\ttraining's rmse: 0.0868038\tvalid_1's rmse: 0.0914266\n",
      "[1925]\ttraining's rmse: 0.0867985\tvalid_1's rmse: 0.0914256\n",
      "[1950]\ttraining's rmse: 0.0867941\tvalid_1's rmse: 0.0914241\n",
      "[1975]\ttraining's rmse: 0.0867895\tvalid_1's rmse: 0.0914221\n",
      "[2000]\ttraining's rmse: 0.0867842\tvalid_1's rmse: 0.0914201\n",
      "[2025]\ttraining's rmse: 0.0867787\tvalid_1's rmse: 0.0914182\n",
      "[2050]\ttraining's rmse: 0.0867729\tvalid_1's rmse: 0.0914171\n",
      "[2075]\ttraining's rmse: 0.0867686\tvalid_1's rmse: 0.0914157\n",
      "[2100]\ttraining's rmse: 0.0867655\tvalid_1's rmse: 0.0914144\n",
      "[2125]\ttraining's rmse: 0.0867617\tvalid_1's rmse: 0.0914136\n",
      "[2150]\ttraining's rmse: 0.086758\tvalid_1's rmse: 0.0914134\n",
      "[2175]\ttraining's rmse: 0.0867526\tvalid_1's rmse: 0.0914121\n",
      "[2200]\ttraining's rmse: 0.0867496\tvalid_1's rmse: 0.091411\n",
      "[2225]\ttraining's rmse: 0.0867458\tvalid_1's rmse: 0.0914106\n",
      "[2250]\ttraining's rmse: 0.0867428\tvalid_1's rmse: 0.0914097\n",
      "[2275]\ttraining's rmse: 0.0867393\tvalid_1's rmse: 0.0914091\n",
      "[2300]\ttraining's rmse: 0.0867352\tvalid_1's rmse: 0.0914074\n",
      "[2325]\ttraining's rmse: 0.0867314\tvalid_1's rmse: 0.0914056\n",
      "[2350]\ttraining's rmse: 0.0867286\tvalid_1's rmse: 0.0914047\n",
      "[2375]\ttraining's rmse: 0.0867261\tvalid_1's rmse: 0.0914042\n",
      "[2400]\ttraining's rmse: 0.0867233\tvalid_1's rmse: 0.0914036\n",
      "[2425]\ttraining's rmse: 0.08672\tvalid_1's rmse: 0.0914032\n",
      "[2450]\ttraining's rmse: 0.0867168\tvalid_1's rmse: 0.0914029\n",
      "[2475]\ttraining's rmse: 0.0867139\tvalid_1's rmse: 0.091402\n",
      "[2500]\ttraining's rmse: 0.0867108\tvalid_1's rmse: 0.0914017\n",
      "[2525]\ttraining's rmse: 0.0867091\tvalid_1's rmse: 0.0914017\n",
      "[2550]\ttraining's rmse: 0.086706\tvalid_1's rmse: 0.0914014\n",
      "[2575]\ttraining's rmse: 0.0867037\tvalid_1's rmse: 0.0914014\n",
      "[2600]\ttraining's rmse: 0.086701\tvalid_1's rmse: 0.0914001\n",
      "[2625]\ttraining's rmse: 0.0866992\tvalid_1's rmse: 0.0913997\n",
      "[2650]\ttraining's rmse: 0.086696\tvalid_1's rmse: 0.0913988\n",
      "[2675]\ttraining's rmse: 0.0866943\tvalid_1's rmse: 0.0913988\n",
      "[2700]\ttraining's rmse: 0.0866914\tvalid_1's rmse: 0.0913982\n",
      "[2725]\ttraining's rmse: 0.086689\tvalid_1's rmse: 0.091398\n",
      "[2750]\ttraining's rmse: 0.0866873\tvalid_1's rmse: 0.0913975\n",
      "[2775]\ttraining's rmse: 0.0866839\tvalid_1's rmse: 0.0913973\n",
      "[2800]\ttraining's rmse: 0.0866817\tvalid_1's rmse: 0.0913972\n",
      "[2825]\ttraining's rmse: 0.0866787\tvalid_1's rmse: 0.0913971\n",
      "[2850]\ttraining's rmse: 0.0866765\tvalid_1's rmse: 0.0913968\n",
      "[2875]\ttraining's rmse: 0.0866739\tvalid_1's rmse: 0.0913956\n",
      "[2900]\ttraining's rmse: 0.0866723\tvalid_1's rmse: 0.0913955\n",
      "[2925]\ttraining's rmse: 0.0866714\tvalid_1's rmse: 0.0913956\n",
      "[2950]\ttraining's rmse: 0.0866698\tvalid_1's rmse: 0.0913942\n",
      "[2975]\ttraining's rmse: 0.0866684\tvalid_1's rmse: 0.0913941\n",
      "[3000]\ttraining's rmse: 0.0866661\tvalid_1's rmse: 0.0913935\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0866661\tvalid_1's rmse: 0.0913935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0898698\tvalid_1's rmse: 0.0925434\n",
      "[50]\ttraining's rmse: 0.0897388\tvalid_1's rmse: 0.0924892\n",
      "[75]\ttraining's rmse: 0.0895983\tvalid_1's rmse: 0.0924348\n",
      "[100]\ttraining's rmse: 0.0894734\tvalid_1's rmse: 0.0923859\n",
      "[125]\ttraining's rmse: 0.0893435\tvalid_1's rmse: 0.0923383\n",
      "[150]\ttraining's rmse: 0.0892247\tvalid_1's rmse: 0.0922936\n",
      "[175]\ttraining's rmse: 0.0891241\tvalid_1's rmse: 0.0922568\n",
      "[200]\ttraining's rmse: 0.0890136\tvalid_1's rmse: 0.0922196\n",
      "[225]\ttraining's rmse: 0.0889099\tvalid_1's rmse: 0.0921835\n",
      "[250]\ttraining's rmse: 0.0888208\tvalid_1's rmse: 0.0921504\n",
      "[275]\ttraining's rmse: 0.0887398\tvalid_1's rmse: 0.0921225\n",
      "[300]\ttraining's rmse: 0.0886577\tvalid_1's rmse: 0.0920959\n",
      "[325]\ttraining's rmse: 0.0885741\tvalid_1's rmse: 0.0920693\n",
      "[350]\ttraining's rmse: 0.088495\tvalid_1's rmse: 0.0920443\n",
      "[375]\ttraining's rmse: 0.0884298\tvalid_1's rmse: 0.0920229\n",
      "[400]\ttraining's rmse: 0.0883583\tvalid_1's rmse: 0.0920018\n",
      "[425]\ttraining's rmse: 0.0882931\tvalid_1's rmse: 0.0919817\n",
      "[450]\ttraining's rmse: 0.0882352\tvalid_1's rmse: 0.0919629\n",
      "[475]\ttraining's rmse: 0.0881782\tvalid_1's rmse: 0.0919458\n",
      "[500]\ttraining's rmse: 0.0881308\tvalid_1's rmse: 0.0919295\n",
      "[525]\ttraining's rmse: 0.0880707\tvalid_1's rmse: 0.0919132\n",
      "[550]\ttraining's rmse: 0.0880152\tvalid_1's rmse: 0.0918988\n",
      "[575]\ttraining's rmse: 0.0879649\tvalid_1's rmse: 0.0918854\n",
      "[600]\ttraining's rmse: 0.0879148\tvalid_1's rmse: 0.0918729\n",
      "[625]\ttraining's rmse: 0.0878756\tvalid_1's rmse: 0.0918613\n",
      "[650]\ttraining's rmse: 0.0878272\tvalid_1's rmse: 0.0918501\n",
      "[675]\ttraining's rmse: 0.0877777\tvalid_1's rmse: 0.091839\n",
      "[700]\ttraining's rmse: 0.0877324\tvalid_1's rmse: 0.0918296\n",
      "[725]\ttraining's rmse: 0.0876929\tvalid_1's rmse: 0.091821\n",
      "[750]\ttraining's rmse: 0.0876577\tvalid_1's rmse: 0.0918131\n",
      "[775]\ttraining's rmse: 0.0876259\tvalid_1's rmse: 0.0918051\n",
      "[800]\ttraining's rmse: 0.0875858\tvalid_1's rmse: 0.0917982\n",
      "[825]\ttraining's rmse: 0.0875531\tvalid_1's rmse: 0.0917897\n",
      "[850]\ttraining's rmse: 0.0875215\tvalid_1's rmse: 0.0917842\n",
      "[875]\ttraining's rmse: 0.0874899\tvalid_1's rmse: 0.0917778\n",
      "[900]\ttraining's rmse: 0.0874581\tvalid_1's rmse: 0.0917712\n",
      "[925]\ttraining's rmse: 0.0874278\tvalid_1's rmse: 0.0917671\n",
      "[950]\ttraining's rmse: 0.0873987\tvalid_1's rmse: 0.0917617\n",
      "[975]\ttraining's rmse: 0.0873729\tvalid_1's rmse: 0.0917564\n",
      "[1000]\ttraining's rmse: 0.087346\tvalid_1's rmse: 0.0917518\n",
      "[1025]\ttraining's rmse: 0.087318\tvalid_1's rmse: 0.091748\n",
      "[1050]\ttraining's rmse: 0.087294\tvalid_1's rmse: 0.0917436\n",
      "[1075]\ttraining's rmse: 0.0872712\tvalid_1's rmse: 0.0917408\n",
      "[1100]\ttraining's rmse: 0.0872518\tvalid_1's rmse: 0.0917369\n",
      "[1125]\ttraining's rmse: 0.0872289\tvalid_1's rmse: 0.0917339\n",
      "[1150]\ttraining's rmse: 0.0872053\tvalid_1's rmse: 0.0917307\n",
      "[1175]\ttraining's rmse: 0.0871867\tvalid_1's rmse: 0.0917285\n",
      "[1200]\ttraining's rmse: 0.0871677\tvalid_1's rmse: 0.0917262\n",
      "[1225]\ttraining's rmse: 0.0871485\tvalid_1's rmse: 0.0917236\n",
      "[1250]\ttraining's rmse: 0.0871328\tvalid_1's rmse: 0.0917219\n",
      "[1275]\ttraining's rmse: 0.087113\tvalid_1's rmse: 0.0917206\n",
      "[1300]\ttraining's rmse: 0.0870982\tvalid_1's rmse: 0.0917183\n",
      "[1325]\ttraining's rmse: 0.0870831\tvalid_1's rmse: 0.0917167\n",
      "[1350]\ttraining's rmse: 0.0870665\tvalid_1's rmse: 0.0917152\n",
      "[1375]\ttraining's rmse: 0.0870507\tvalid_1's rmse: 0.0917138\n",
      "[1400]\ttraining's rmse: 0.0870369\tvalid_1's rmse: 0.0917117\n",
      "[1425]\ttraining's rmse: 0.0870213\tvalid_1's rmse: 0.0917105\n",
      "[1450]\ttraining's rmse: 0.0870066\tvalid_1's rmse: 0.0917092\n",
      "[1475]\ttraining's rmse: 0.0869937\tvalid_1's rmse: 0.091708\n",
      "[1500]\ttraining's rmse: 0.0869821\tvalid_1's rmse: 0.0917072\n",
      "[1525]\ttraining's rmse: 0.0869716\tvalid_1's rmse: 0.0917061\n",
      "[1550]\ttraining's rmse: 0.0869592\tvalid_1's rmse: 0.0917053\n",
      "[1575]\ttraining's rmse: 0.0869481\tvalid_1's rmse: 0.0917039\n",
      "[1600]\ttraining's rmse: 0.0869394\tvalid_1's rmse: 0.0917034\n",
      "[1625]\ttraining's rmse: 0.0869294\tvalid_1's rmse: 0.0917028\n",
      "[1650]\ttraining's rmse: 0.0869195\tvalid_1's rmse: 0.0917018\n",
      "[1675]\ttraining's rmse: 0.0869111\tvalid_1's rmse: 0.0917008\n",
      "[1700]\ttraining's rmse: 0.0869017\tvalid_1's rmse: 0.0917007\n",
      "[1725]\ttraining's rmse: 0.0868921\tvalid_1's rmse: 0.0916997\n",
      "[1750]\ttraining's rmse: 0.0868852\tvalid_1's rmse: 0.0916993\n",
      "[1775]\ttraining's rmse: 0.0868787\tvalid_1's rmse: 0.0916991\n",
      "[1800]\ttraining's rmse: 0.0868715\tvalid_1's rmse: 0.0916992\n",
      "Early stopping, best iteration is:\n",
      "[1763]\ttraining's rmse: 0.0868824\tvalid_1's rmse: 0.0916987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0923323\tvalid_1's rmse: 0.0875342\n",
      "[50]\ttraining's rmse: 0.0922005\tvalid_1's rmse: 0.0874839\n",
      "[75]\ttraining's rmse: 0.0920652\tvalid_1's rmse: 0.0874341\n",
      "[100]\ttraining's rmse: 0.0919392\tvalid_1's rmse: 0.0873924\n",
      "[125]\ttraining's rmse: 0.0918107\tvalid_1's rmse: 0.0873485\n",
      "[150]\ttraining's rmse: 0.0916907\tvalid_1's rmse: 0.0873085\n",
      "[175]\ttraining's rmse: 0.0915921\tvalid_1's rmse: 0.0872774\n",
      "[200]\ttraining's rmse: 0.0914834\tvalid_1's rmse: 0.0872434\n",
      "[225]\ttraining's rmse: 0.0913822\tvalid_1's rmse: 0.0872112\n",
      "[250]\ttraining's rmse: 0.0912939\tvalid_1's rmse: 0.0871842\n",
      "[275]\ttraining's rmse: 0.0912173\tvalid_1's rmse: 0.0871589\n",
      "[300]\ttraining's rmse: 0.0911366\tvalid_1's rmse: 0.0871351\n",
      "[325]\ttraining's rmse: 0.0910559\tvalid_1's rmse: 0.0871121\n",
      "[350]\ttraining's rmse: 0.090975\tvalid_1's rmse: 0.0870888\n",
      "[375]\ttraining's rmse: 0.090911\tvalid_1's rmse: 0.0870705\n",
      "[400]\ttraining's rmse: 0.0908413\tvalid_1's rmse: 0.0870563\n",
      "[425]\ttraining's rmse: 0.090778\tvalid_1's rmse: 0.0870443\n",
      "[450]\ttraining's rmse: 0.090719\tvalid_1's rmse: 0.0870299\n",
      "[475]\ttraining's rmse: 0.0906631\tvalid_1's rmse: 0.0870154\n",
      "[500]\ttraining's rmse: 0.0906163\tvalid_1's rmse: 0.0870013\n",
      "[525]\ttraining's rmse: 0.0905557\tvalid_1's rmse: 0.086993\n",
      "[550]\ttraining's rmse: 0.0904978\tvalid_1's rmse: 0.0869801\n",
      "[575]\ttraining's rmse: 0.0904467\tvalid_1's rmse: 0.0869693\n",
      "[600]\ttraining's rmse: 0.0903957\tvalid_1's rmse: 0.0869621\n",
      "[625]\ttraining's rmse: 0.0903544\tvalid_1's rmse: 0.0869578\n",
      "[650]\ttraining's rmse: 0.0903027\tvalid_1's rmse: 0.0869515\n",
      "[675]\ttraining's rmse: 0.0902531\tvalid_1's rmse: 0.0869435\n",
      "[700]\ttraining's rmse: 0.0902095\tvalid_1's rmse: 0.0869401\n",
      "[725]\ttraining's rmse: 0.0901692\tvalid_1's rmse: 0.0869393\n",
      "[750]\ttraining's rmse: 0.090129\tvalid_1's rmse: 0.0869487\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's rmse: 0.0901774\tvalid_1's rmse: 0.0869351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0893992\tvalid_1's rmse: 0.0920355\n",
      "[50]\ttraining's rmse: 0.089246\tvalid_1's rmse: 0.0919788\n",
      "[75]\ttraining's rmse: 0.0890922\tvalid_1's rmse: 0.0919237\n",
      "[100]\ttraining's rmse: 0.0889521\tvalid_1's rmse: 0.0918762\n",
      "[125]\ttraining's rmse: 0.0888136\tvalid_1's rmse: 0.0918285\n",
      "[150]\ttraining's rmse: 0.0886876\tvalid_1's rmse: 0.0917856\n",
      "[175]\ttraining's rmse: 0.08858\tvalid_1's rmse: 0.0917471\n",
      "[200]\ttraining's rmse: 0.0884681\tvalid_1's rmse: 0.0917098\n",
      "[225]\ttraining's rmse: 0.0883542\tvalid_1's rmse: 0.0916732\n",
      "[250]\ttraining's rmse: 0.0882578\tvalid_1's rmse: 0.0916402\n",
      "[275]\ttraining's rmse: 0.0881676\tvalid_1's rmse: 0.0916109\n",
      "[300]\ttraining's rmse: 0.0880814\tvalid_1's rmse: 0.091581\n",
      "[325]\ttraining's rmse: 0.0879964\tvalid_1's rmse: 0.0915546\n",
      "[350]\ttraining's rmse: 0.0879134\tvalid_1's rmse: 0.0915298\n",
      "[375]\ttraining's rmse: 0.0878424\tvalid_1's rmse: 0.0915089\n",
      "[400]\ttraining's rmse: 0.0877697\tvalid_1's rmse: 0.0914871\n",
      "[425]\ttraining's rmse: 0.0876995\tvalid_1's rmse: 0.0914666\n",
      "[450]\ttraining's rmse: 0.0876376\tvalid_1's rmse: 0.0914466\n",
      "[475]\ttraining's rmse: 0.0875779\tvalid_1's rmse: 0.0914276\n",
      "[500]\ttraining's rmse: 0.0875292\tvalid_1's rmse: 0.091411\n",
      "[525]\ttraining's rmse: 0.0874667\tvalid_1's rmse: 0.0913932\n",
      "[550]\ttraining's rmse: 0.0874121\tvalid_1's rmse: 0.091377\n",
      "[575]\ttraining's rmse: 0.0873558\tvalid_1's rmse: 0.0913642\n",
      "[600]\ttraining's rmse: 0.0873054\tvalid_1's rmse: 0.0913513\n",
      "[625]\ttraining's rmse: 0.0872626\tvalid_1's rmse: 0.0913377\n",
      "[650]\ttraining's rmse: 0.0872143\tvalid_1's rmse: 0.0913249\n",
      "[675]\ttraining's rmse: 0.0871677\tvalid_1's rmse: 0.0913146\n",
      "[700]\ttraining's rmse: 0.087126\tvalid_1's rmse: 0.0913032\n",
      "[725]\ttraining's rmse: 0.0870839\tvalid_1's rmse: 0.0912912\n",
      "[750]\ttraining's rmse: 0.0870454\tvalid_1's rmse: 0.0912817\n",
      "[775]\ttraining's rmse: 0.0870135\tvalid_1's rmse: 0.0912713\n",
      "[800]\ttraining's rmse: 0.0869747\tvalid_1's rmse: 0.0912623\n",
      "[825]\ttraining's rmse: 0.0869397\tvalid_1's rmse: 0.0912535\n",
      "[850]\ttraining's rmse: 0.0869025\tvalid_1's rmse: 0.0912468\n",
      "[875]\ttraining's rmse: 0.0868735\tvalid_1's rmse: 0.0912401\n",
      "[900]\ttraining's rmse: 0.0868422\tvalid_1's rmse: 0.0912337\n",
      "[925]\ttraining's rmse: 0.0868103\tvalid_1's rmse: 0.0912238\n",
      "[950]\ttraining's rmse: 0.086784\tvalid_1's rmse: 0.0912169\n",
      "[975]\ttraining's rmse: 0.0867572\tvalid_1's rmse: 0.0912116\n",
      "[1000]\ttraining's rmse: 0.0867308\tvalid_1's rmse: 0.0912065\n",
      "[1025]\ttraining's rmse: 0.086705\tvalid_1's rmse: 0.0911992\n",
      "[1050]\ttraining's rmse: 0.0866801\tvalid_1's rmse: 0.0911925\n",
      "[1075]\ttraining's rmse: 0.0866563\tvalid_1's rmse: 0.0911857\n",
      "[1100]\ttraining's rmse: 0.0866359\tvalid_1's rmse: 0.0911802\n",
      "[1125]\ttraining's rmse: 0.0866144\tvalid_1's rmse: 0.0911758\n",
      "[1150]\ttraining's rmse: 0.0865941\tvalid_1's rmse: 0.0911716\n",
      "[1175]\ttraining's rmse: 0.0865736\tvalid_1's rmse: 0.0911674\n",
      "[1200]\ttraining's rmse: 0.086555\tvalid_1's rmse: 0.0911625\n",
      "[1225]\ttraining's rmse: 0.0865391\tvalid_1's rmse: 0.091159\n",
      "[1250]\ttraining's rmse: 0.0865238\tvalid_1's rmse: 0.0911543\n",
      "[1275]\ttraining's rmse: 0.0865066\tvalid_1's rmse: 0.0911524\n",
      "[1300]\ttraining's rmse: 0.0864913\tvalid_1's rmse: 0.0911468\n",
      "[1325]\ttraining's rmse: 0.0864775\tvalid_1's rmse: 0.0911442\n",
      "[1350]\ttraining's rmse: 0.0864622\tvalid_1's rmse: 0.0911419\n",
      "[1375]\ttraining's rmse: 0.0864472\tvalid_1's rmse: 0.0911388\n",
      "[1400]\ttraining's rmse: 0.0864349\tvalid_1's rmse: 0.0911341\n",
      "[1425]\ttraining's rmse: 0.0864193\tvalid_1's rmse: 0.0911301\n",
      "[1450]\ttraining's rmse: 0.0864057\tvalid_1's rmse: 0.0911275\n",
      "[1475]\ttraining's rmse: 0.0863937\tvalid_1's rmse: 0.091124\n",
      "[1500]\ttraining's rmse: 0.0863835\tvalid_1's rmse: 0.0911208\n",
      "[1525]\ttraining's rmse: 0.0863725\tvalid_1's rmse: 0.0911185\n",
      "[1550]\ttraining's rmse: 0.0863619\tvalid_1's rmse: 0.0911158\n",
      "[1575]\ttraining's rmse: 0.0863523\tvalid_1's rmse: 0.0911125\n",
      "[1600]\ttraining's rmse: 0.0863417\tvalid_1's rmse: 0.0911098\n",
      "[1625]\ttraining's rmse: 0.0863279\tvalid_1's rmse: 0.0911065\n",
      "[1650]\ttraining's rmse: 0.086319\tvalid_1's rmse: 0.0911035\n",
      "[1675]\ttraining's rmse: 0.0863115\tvalid_1's rmse: 0.0911006\n",
      "[1700]\ttraining's rmse: 0.0863021\tvalid_1's rmse: 0.0910981\n",
      "[1725]\ttraining's rmse: 0.0862936\tvalid_1's rmse: 0.0910956\n",
      "[1750]\ttraining's rmse: 0.0862861\tvalid_1's rmse: 0.0910933\n",
      "[1775]\ttraining's rmse: 0.0862782\tvalid_1's rmse: 0.0910916\n",
      "[1800]\ttraining's rmse: 0.0862718\tvalid_1's rmse: 0.0910887\n",
      "[1825]\ttraining's rmse: 0.0862661\tvalid_1's rmse: 0.0910875\n",
      "[1850]\ttraining's rmse: 0.0862584\tvalid_1's rmse: 0.0910852\n",
      "[1875]\ttraining's rmse: 0.0862507\tvalid_1's rmse: 0.0910831\n",
      "[1900]\ttraining's rmse: 0.0862447\tvalid_1's rmse: 0.0910818\n",
      "[1925]\ttraining's rmse: 0.0862359\tvalid_1's rmse: 0.0910797\n",
      "[1950]\ttraining's rmse: 0.0862313\tvalid_1's rmse: 0.0910784\n",
      "[1975]\ttraining's rmse: 0.0862257\tvalid_1's rmse: 0.0910768\n",
      "[2000]\ttraining's rmse: 0.0862216\tvalid_1's rmse: 0.0910764\n",
      "[2025]\ttraining's rmse: 0.0862163\tvalid_1's rmse: 0.0910735\n",
      "[2050]\ttraining's rmse: 0.0862101\tvalid_1's rmse: 0.0910721\n",
      "[2075]\ttraining's rmse: 0.086206\tvalid_1's rmse: 0.0910711\n",
      "[2100]\ttraining's rmse: 0.0862034\tvalid_1's rmse: 0.0910699\n",
      "[2125]\ttraining's rmse: 0.0861988\tvalid_1's rmse: 0.0910688\n",
      "[2150]\ttraining's rmse: 0.0861951\tvalid_1's rmse: 0.091068\n",
      "[2175]\ttraining's rmse: 0.0861892\tvalid_1's rmse: 0.0910676\n",
      "[2200]\ttraining's rmse: 0.0861849\tvalid_1's rmse: 0.0910659\n",
      "[2225]\ttraining's rmse: 0.0861817\tvalid_1's rmse: 0.0910653\n",
      "[2250]\ttraining's rmse: 0.0861783\tvalid_1's rmse: 0.0910637\n",
      "[2275]\ttraining's rmse: 0.0861736\tvalid_1's rmse: 0.0910632\n",
      "[2300]\ttraining's rmse: 0.0861705\tvalid_1's rmse: 0.0910618\n",
      "[2325]\ttraining's rmse: 0.0861671\tvalid_1's rmse: 0.0910616\n",
      "[2350]\ttraining's rmse: 0.0861637\tvalid_1's rmse: 0.0910605\n",
      "[2375]\ttraining's rmse: 0.0861601\tvalid_1's rmse: 0.0910595\n",
      "[2400]\ttraining's rmse: 0.0861569\tvalid_1's rmse: 0.0910593\n",
      "[2425]\ttraining's rmse: 0.0861546\tvalid_1's rmse: 0.0910587\n",
      "[2450]\ttraining's rmse: 0.0861514\tvalid_1's rmse: 0.0910577\n",
      "[2475]\ttraining's rmse: 0.0861493\tvalid_1's rmse: 0.0910579\n",
      "[2500]\ttraining's rmse: 0.0861454\tvalid_1's rmse: 0.0910573\n",
      "[2525]\ttraining's rmse: 0.0861415\tvalid_1's rmse: 0.0910571\n",
      "[2550]\ttraining's rmse: 0.0861398\tvalid_1's rmse: 0.0910564\n",
      "[2575]\ttraining's rmse: 0.0861381\tvalid_1's rmse: 0.0910561\n",
      "[2600]\ttraining's rmse: 0.0861352\tvalid_1's rmse: 0.0910553\n",
      "[2625]\ttraining's rmse: 0.0861336\tvalid_1's rmse: 0.0910548\n",
      "[2650]\ttraining's rmse: 0.086132\tvalid_1's rmse: 0.0910542\n",
      "[2675]\ttraining's rmse: 0.0861297\tvalid_1's rmse: 0.0910533\n",
      "[2700]\ttraining's rmse: 0.0861276\tvalid_1's rmse: 0.0910522\n",
      "[2725]\ttraining's rmse: 0.0861261\tvalid_1's rmse: 0.0910519\n",
      "[2750]\ttraining's rmse: 0.0861244\tvalid_1's rmse: 0.0910504\n",
      "[2775]\ttraining's rmse: 0.0861223\tvalid_1's rmse: 0.0910505\n",
      "[2800]\ttraining's rmse: 0.0861207\tvalid_1's rmse: 0.0910508\n",
      "[2825]\ttraining's rmse: 0.0861169\tvalid_1's rmse: 0.0910505\n",
      "[2850]\ttraining's rmse: 0.0861148\tvalid_1's rmse: 0.0910508\n",
      "Early stopping, best iteration is:\n",
      "[2817]\ttraining's rmse: 0.0861181\tvalid_1's rmse: 0.0910503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0894105\tvalid_1's rmse: 0.0920335\n",
      "[50]\ttraining's rmse: 0.0892787\tvalid_1's rmse: 0.0919767\n",
      "[75]\ttraining's rmse: 0.0891378\tvalid_1's rmse: 0.0919233\n",
      "[100]\ttraining's rmse: 0.0890133\tvalid_1's rmse: 0.091873\n",
      "[125]\ttraining's rmse: 0.0888833\tvalid_1's rmse: 0.0918239\n",
      "[150]\ttraining's rmse: 0.0887617\tvalid_1's rmse: 0.0917775\n",
      "[175]\ttraining's rmse: 0.0886636\tvalid_1's rmse: 0.0917409\n",
      "[200]\ttraining's rmse: 0.0885553\tvalid_1's rmse: 0.0917041\n",
      "[225]\ttraining's rmse: 0.0884532\tvalid_1's rmse: 0.0916682\n",
      "[250]\ttraining's rmse: 0.0883641\tvalid_1's rmse: 0.0916374\n",
      "[275]\ttraining's rmse: 0.088283\tvalid_1's rmse: 0.0916084\n",
      "[300]\ttraining's rmse: 0.0882012\tvalid_1's rmse: 0.0915808\n",
      "[325]\ttraining's rmse: 0.08812\tvalid_1's rmse: 0.0915535\n",
      "[350]\ttraining's rmse: 0.0880381\tvalid_1's rmse: 0.0915295\n",
      "[375]\ttraining's rmse: 0.0879751\tvalid_1's rmse: 0.0915093\n",
      "[400]\ttraining's rmse: 0.0879034\tvalid_1's rmse: 0.0914886\n",
      "[425]\ttraining's rmse: 0.0878379\tvalid_1's rmse: 0.0914678\n",
      "[450]\ttraining's rmse: 0.0877798\tvalid_1's rmse: 0.0914494\n",
      "[475]\ttraining's rmse: 0.0877224\tvalid_1's rmse: 0.0914309\n",
      "[500]\ttraining's rmse: 0.0876739\tvalid_1's rmse: 0.0914154\n",
      "[525]\ttraining's rmse: 0.0876109\tvalid_1's rmse: 0.0913981\n",
      "[550]\ttraining's rmse: 0.0875555\tvalid_1's rmse: 0.0913841\n",
      "[575]\ttraining's rmse: 0.0875016\tvalid_1's rmse: 0.0913708\n",
      "[600]\ttraining's rmse: 0.0874509\tvalid_1's rmse: 0.0913582\n",
      "[625]\ttraining's rmse: 0.0874116\tvalid_1's rmse: 0.0913467\n",
      "[650]\ttraining's rmse: 0.0873638\tvalid_1's rmse: 0.091334\n",
      "[675]\ttraining's rmse: 0.0873128\tvalid_1's rmse: 0.0913227\n",
      "[700]\ttraining's rmse: 0.0872691\tvalid_1's rmse: 0.0913124\n",
      "[725]\ttraining's rmse: 0.0872277\tvalid_1's rmse: 0.0913024\n",
      "[750]\ttraining's rmse: 0.087189\tvalid_1's rmse: 0.0912936\n",
      "[775]\ttraining's rmse: 0.0871576\tvalid_1's rmse: 0.0912853\n",
      "[800]\ttraining's rmse: 0.0871183\tvalid_1's rmse: 0.0912784\n",
      "[825]\ttraining's rmse: 0.0870854\tvalid_1's rmse: 0.0912706\n",
      "[850]\ttraining's rmse: 0.0870526\tvalid_1's rmse: 0.0912648\n",
      "[875]\ttraining's rmse: 0.0870237\tvalid_1's rmse: 0.0912591\n",
      "[900]\ttraining's rmse: 0.0869901\tvalid_1's rmse: 0.0912523\n",
      "[925]\ttraining's rmse: 0.0869589\tvalid_1's rmse: 0.0912469\n",
      "[950]\ttraining's rmse: 0.0869304\tvalid_1's rmse: 0.0912423\n",
      "[975]\ttraining's rmse: 0.0869054\tvalid_1's rmse: 0.0912378\n",
      "[1000]\ttraining's rmse: 0.0868798\tvalid_1's rmse: 0.0912329\n",
      "[1025]\ttraining's rmse: 0.0868525\tvalid_1's rmse: 0.0912276\n",
      "[1050]\ttraining's rmse: 0.0868276\tvalid_1's rmse: 0.0912231\n",
      "[1075]\ttraining's rmse: 0.0868023\tvalid_1's rmse: 0.0912195\n",
      "[1100]\ttraining's rmse: 0.0867839\tvalid_1's rmse: 0.0912155\n",
      "[1125]\ttraining's rmse: 0.0867645\tvalid_1's rmse: 0.0912126\n",
      "[1150]\ttraining's rmse: 0.086743\tvalid_1's rmse: 0.091209\n",
      "[1175]\ttraining's rmse: 0.0867259\tvalid_1's rmse: 0.0912059\n",
      "[1200]\ttraining's rmse: 0.086707\tvalid_1's rmse: 0.0912029\n",
      "[1225]\ttraining's rmse: 0.0866893\tvalid_1's rmse: 0.0912004\n",
      "[1250]\ttraining's rmse: 0.08667\tvalid_1's rmse: 0.0911979\n",
      "[1275]\ttraining's rmse: 0.0866483\tvalid_1's rmse: 0.0911958\n",
      "[1300]\ttraining's rmse: 0.0866348\tvalid_1's rmse: 0.0911941\n",
      "[1325]\ttraining's rmse: 0.0866218\tvalid_1's rmse: 0.091193\n",
      "[1350]\ttraining's rmse: 0.0866061\tvalid_1's rmse: 0.0911914\n",
      "[1375]\ttraining's rmse: 0.0865909\tvalid_1's rmse: 0.0911895\n",
      "[1400]\ttraining's rmse: 0.0865771\tvalid_1's rmse: 0.0911877\n",
      "[1425]\ttraining's rmse: 0.0865603\tvalid_1's rmse: 0.0911865\n",
      "[1450]\ttraining's rmse: 0.0865465\tvalid_1's rmse: 0.0911856\n",
      "[1475]\ttraining's rmse: 0.0865335\tvalid_1's rmse: 0.0911838\n",
      "[1500]\ttraining's rmse: 0.0865239\tvalid_1's rmse: 0.091183\n",
      "[1525]\ttraining's rmse: 0.0865116\tvalid_1's rmse: 0.0911819\n",
      "[1550]\ttraining's rmse: 0.0865003\tvalid_1's rmse: 0.0911811\n",
      "[1575]\ttraining's rmse: 0.0864887\tvalid_1's rmse: 0.0911798\n",
      "[1600]\ttraining's rmse: 0.0864781\tvalid_1's rmse: 0.0911794\n",
      "[1625]\ttraining's rmse: 0.0864688\tvalid_1's rmse: 0.0911786\n",
      "[1650]\ttraining's rmse: 0.08646\tvalid_1's rmse: 0.091178\n",
      "[1675]\ttraining's rmse: 0.0864534\tvalid_1's rmse: 0.0911772\n",
      "[1700]\ttraining's rmse: 0.0864464\tvalid_1's rmse: 0.0911761\n",
      "[1725]\ttraining's rmse: 0.0864373\tvalid_1's rmse: 0.0911753\n",
      "[1750]\ttraining's rmse: 0.0864284\tvalid_1's rmse: 0.0911742\n",
      "[1775]\ttraining's rmse: 0.086422\tvalid_1's rmse: 0.0911737\n",
      "[1800]\ttraining's rmse: 0.0864138\tvalid_1's rmse: 0.0911732\n",
      "[1825]\ttraining's rmse: 0.0864074\tvalid_1's rmse: 0.0911725\n",
      "[1850]\ttraining's rmse: 0.0864\tvalid_1's rmse: 0.0911716\n",
      "[1875]\ttraining's rmse: 0.0863927\tvalid_1's rmse: 0.0911711\n",
      "[1900]\ttraining's rmse: 0.0863868\tvalid_1's rmse: 0.0911705\n",
      "[1925]\ttraining's rmse: 0.0863822\tvalid_1's rmse: 0.0911703\n",
      "[1950]\ttraining's rmse: 0.0863768\tvalid_1's rmse: 0.0911696\n",
      "[1975]\ttraining's rmse: 0.0863722\tvalid_1's rmse: 0.091169\n",
      "[2000]\ttraining's rmse: 0.0863648\tvalid_1's rmse: 0.0911682\n",
      "[2025]\ttraining's rmse: 0.0863597\tvalid_1's rmse: 0.0911672\n",
      "[2050]\ttraining's rmse: 0.086355\tvalid_1's rmse: 0.091167\n",
      "[2075]\ttraining's rmse: 0.086352\tvalid_1's rmse: 0.0911665\n",
      "[2100]\ttraining's rmse: 0.0863475\tvalid_1's rmse: 0.0911661\n",
      "[2125]\ttraining's rmse: 0.0863442\tvalid_1's rmse: 0.0911659\n",
      "[2150]\ttraining's rmse: 0.0863393\tvalid_1's rmse: 0.0911663\n",
      "Early stopping, best iteration is:\n",
      "[2124]\ttraining's rmse: 0.0863443\tvalid_1's rmse: 0.0911658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.091896\tvalid_1's rmse: 0.0869858\n",
      "[50]\ttraining's rmse: 0.091766\tvalid_1's rmse: 0.0869416\n",
      "[75]\ttraining's rmse: 0.0916319\tvalid_1's rmse: 0.0868929\n",
      "[100]\ttraining's rmse: 0.0915095\tvalid_1's rmse: 0.0868496\n",
      "[125]\ttraining's rmse: 0.0913839\tvalid_1's rmse: 0.0868059\n",
      "[150]\ttraining's rmse: 0.0912671\tvalid_1's rmse: 0.0867665\n",
      "[175]\ttraining's rmse: 0.0911731\tvalid_1's rmse: 0.0867346\n",
      "[200]\ttraining's rmse: 0.0910694\tvalid_1's rmse: 0.0867023\n",
      "[225]\ttraining's rmse: 0.0909691\tvalid_1's rmse: 0.0866708\n",
      "[250]\ttraining's rmse: 0.0908812\tvalid_1's rmse: 0.0866438\n",
      "[275]\ttraining's rmse: 0.0908031\tvalid_1's rmse: 0.086617\n",
      "[300]\ttraining's rmse: 0.0907237\tvalid_1's rmse: 0.0865925\n",
      "[325]\ttraining's rmse: 0.0906419\tvalid_1's rmse: 0.0865698\n",
      "[350]\ttraining's rmse: 0.0905646\tvalid_1's rmse: 0.0865488\n",
      "[375]\ttraining's rmse: 0.0905033\tvalid_1's rmse: 0.0865316\n",
      "[400]\ttraining's rmse: 0.0904338\tvalid_1's rmse: 0.0865174\n",
      "[425]\ttraining's rmse: 0.0903703\tvalid_1's rmse: 0.0865099\n",
      "[450]\ttraining's rmse: 0.0903117\tvalid_1's rmse: 0.0864978\n",
      "[475]\ttraining's rmse: 0.0902555\tvalid_1's rmse: 0.0864831\n",
      "[500]\ttraining's rmse: 0.090208\tvalid_1's rmse: 0.0864741\n",
      "[525]\ttraining's rmse: 0.0901459\tvalid_1's rmse: 0.0864653\n",
      "[550]\ttraining's rmse: 0.0900904\tvalid_1's rmse: 0.0864522\n",
      "[575]\ttraining's rmse: 0.0900397\tvalid_1's rmse: 0.0864439\n",
      "[600]\ttraining's rmse: 0.0899868\tvalid_1's rmse: 0.0864376\n",
      "[625]\ttraining's rmse: 0.0899453\tvalid_1's rmse: 0.0864318\n",
      "[650]\ttraining's rmse: 0.0898954\tvalid_1's rmse: 0.0864264\n",
      "[675]\ttraining's rmse: 0.0898469\tvalid_1's rmse: 0.0864179\n",
      "[700]\ttraining's rmse: 0.0898046\tvalid_1's rmse: 0.0864092\n",
      "[725]\ttraining's rmse: 0.0897631\tvalid_1's rmse: 0.086409\n",
      "[750]\ttraining's rmse: 0.0897249\tvalid_1's rmse: 0.0864019\n",
      "[775]\ttraining's rmse: 0.0896921\tvalid_1's rmse: 0.0863962\n",
      "[800]\ttraining's rmse: 0.0896525\tvalid_1's rmse: 0.0863912\n",
      "[825]\ttraining's rmse: 0.0896176\tvalid_1's rmse: 0.0863993\n",
      "[850]\ttraining's rmse: 0.0895809\tvalid_1's rmse: 0.0863935\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's rmse: 0.089639\tvalid_1's rmse: 0.0863892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.091021\tvalid_1's rmse: 0.093069\n",
      "[50]\ttraining's rmse: 0.0908329\tvalid_1's rmse: 0.0930133\n",
      "[75]\ttraining's rmse: 0.09065\tvalid_1's rmse: 0.0929558\n",
      "[100]\ttraining's rmse: 0.0904794\tvalid_1's rmse: 0.0929076\n",
      "[125]\ttraining's rmse: 0.0903104\tvalid_1's rmse: 0.0928591\n",
      "[150]\ttraining's rmse: 0.0901582\tvalid_1's rmse: 0.0928125\n",
      "[175]\ttraining's rmse: 0.0900277\tvalid_1's rmse: 0.0927734\n",
      "[200]\ttraining's rmse: 0.0898916\tvalid_1's rmse: 0.0927354\n",
      "[225]\ttraining's rmse: 0.0897612\tvalid_1's rmse: 0.0927003\n",
      "[250]\ttraining's rmse: 0.0896508\tvalid_1's rmse: 0.0926672\n",
      "[275]\ttraining's rmse: 0.0895449\tvalid_1's rmse: 0.0926367\n",
      "[300]\ttraining's rmse: 0.0894428\tvalid_1's rmse: 0.0926068\n",
      "[325]\ttraining's rmse: 0.0893421\tvalid_1's rmse: 0.0925781\n",
      "[350]\ttraining's rmse: 0.0892448\tvalid_1's rmse: 0.092551\n",
      "[375]\ttraining's rmse: 0.089159\tvalid_1's rmse: 0.092529\n",
      "[400]\ttraining's rmse: 0.0890706\tvalid_1's rmse: 0.092508\n",
      "[425]\ttraining's rmse: 0.0889898\tvalid_1's rmse: 0.0924877\n",
      "[450]\ttraining's rmse: 0.0889204\tvalid_1's rmse: 0.0924664\n",
      "[475]\ttraining's rmse: 0.0888527\tvalid_1's rmse: 0.0924478\n",
      "[500]\ttraining's rmse: 0.0887915\tvalid_1's rmse: 0.0924312\n",
      "[525]\ttraining's rmse: 0.0887203\tvalid_1's rmse: 0.0924132\n",
      "[550]\ttraining's rmse: 0.0886586\tvalid_1's rmse: 0.0923978\n",
      "[575]\ttraining's rmse: 0.0885977\tvalid_1's rmse: 0.0923846\n",
      "[600]\ttraining's rmse: 0.0885409\tvalid_1's rmse: 0.0923712\n",
      "[625]\ttraining's rmse: 0.0884938\tvalid_1's rmse: 0.0923584\n",
      "[650]\ttraining's rmse: 0.0884403\tvalid_1's rmse: 0.0923443\n",
      "[675]\ttraining's rmse: 0.0883891\tvalid_1's rmse: 0.0923311\n",
      "[700]\ttraining's rmse: 0.0883441\tvalid_1's rmse: 0.0923204\n",
      "[725]\ttraining's rmse: 0.088301\tvalid_1's rmse: 0.0923097\n",
      "[750]\ttraining's rmse: 0.0882576\tvalid_1's rmse: 0.0922989\n",
      "[775]\ttraining's rmse: 0.0882241\tvalid_1's rmse: 0.0922882\n",
      "[800]\ttraining's rmse: 0.0881807\tvalid_1's rmse: 0.0922796\n",
      "[825]\ttraining's rmse: 0.0881467\tvalid_1's rmse: 0.0922723\n",
      "[850]\ttraining's rmse: 0.0881083\tvalid_1's rmse: 0.0922654\n",
      "[875]\ttraining's rmse: 0.0880774\tvalid_1's rmse: 0.0922587\n",
      "[900]\ttraining's rmse: 0.0880433\tvalid_1's rmse: 0.0922502\n",
      "[925]\ttraining's rmse: 0.088013\tvalid_1's rmse: 0.0922433\n",
      "[950]\ttraining's rmse: 0.0879823\tvalid_1's rmse: 0.0922356\n",
      "[975]\ttraining's rmse: 0.0879535\tvalid_1's rmse: 0.092229\n",
      "[1000]\ttraining's rmse: 0.0879236\tvalid_1's rmse: 0.0922221\n",
      "[1025]\ttraining's rmse: 0.0878935\tvalid_1's rmse: 0.0922149\n",
      "[1050]\ttraining's rmse: 0.087869\tvalid_1's rmse: 0.0922069\n",
      "[1075]\ttraining's rmse: 0.0878458\tvalid_1's rmse: 0.0922015\n",
      "[1100]\ttraining's rmse: 0.0878225\tvalid_1's rmse: 0.0921963\n",
      "[1125]\ttraining's rmse: 0.0878002\tvalid_1's rmse: 0.0921905\n",
      "[1150]\ttraining's rmse: 0.0877776\tvalid_1's rmse: 0.0921851\n",
      "[1175]\ttraining's rmse: 0.0877579\tvalid_1's rmse: 0.0921806\n",
      "[1200]\ttraining's rmse: 0.0877394\tvalid_1's rmse: 0.0921758\n",
      "[1225]\ttraining's rmse: 0.0877204\tvalid_1's rmse: 0.0921703\n",
      "[1250]\ttraining's rmse: 0.0877024\tvalid_1's rmse: 0.0921653\n",
      "[1275]\ttraining's rmse: 0.0876829\tvalid_1's rmse: 0.0921604\n",
      "[1300]\ttraining's rmse: 0.0876674\tvalid_1's rmse: 0.0921554\n",
      "[1325]\ttraining's rmse: 0.0876508\tvalid_1's rmse: 0.0921517\n",
      "[1350]\ttraining's rmse: 0.0876314\tvalid_1's rmse: 0.0921463\n",
      "[1375]\ttraining's rmse: 0.0876153\tvalid_1's rmse: 0.0921418\n",
      "[1400]\ttraining's rmse: 0.0876018\tvalid_1's rmse: 0.0921367\n",
      "[1425]\ttraining's rmse: 0.0875836\tvalid_1's rmse: 0.0921339\n",
      "[1450]\ttraining's rmse: 0.0875667\tvalid_1's rmse: 0.0921304\n",
      "[1475]\ttraining's rmse: 0.0875556\tvalid_1's rmse: 0.092127\n",
      "[1500]\ttraining's rmse: 0.0875432\tvalid_1's rmse: 0.0921232\n",
      "[1525]\ttraining's rmse: 0.0875313\tvalid_1's rmse: 0.0921213\n",
      "[1550]\ttraining's rmse: 0.0875193\tvalid_1's rmse: 0.0921186\n",
      "[1575]\ttraining's rmse: 0.0875073\tvalid_1's rmse: 0.0921141\n",
      "[1600]\ttraining's rmse: 0.0874974\tvalid_1's rmse: 0.0921114\n",
      "[1625]\ttraining's rmse: 0.087486\tvalid_1's rmse: 0.0921084\n",
      "[1650]\ttraining's rmse: 0.0874774\tvalid_1's rmse: 0.0921058\n",
      "[1675]\ttraining's rmse: 0.0874698\tvalid_1's rmse: 0.0921038\n",
      "[1700]\ttraining's rmse: 0.0874601\tvalid_1's rmse: 0.0921015\n",
      "[1725]\ttraining's rmse: 0.0874534\tvalid_1's rmse: 0.0920988\n",
      "[1750]\ttraining's rmse: 0.0874462\tvalid_1's rmse: 0.0920955\n",
      "[1775]\ttraining's rmse: 0.0874391\tvalid_1's rmse: 0.0920939\n",
      "[1800]\ttraining's rmse: 0.0874317\tvalid_1's rmse: 0.0920917\n",
      "[1825]\ttraining's rmse: 0.0874242\tvalid_1's rmse: 0.0920913\n",
      "[1850]\ttraining's rmse: 0.0874181\tvalid_1's rmse: 0.0920898\n",
      "[1875]\ttraining's rmse: 0.0874095\tvalid_1's rmse: 0.0920871\n",
      "[1900]\ttraining's rmse: 0.087403\tvalid_1's rmse: 0.0920851\n",
      "[1925]\ttraining's rmse: 0.0873987\tvalid_1's rmse: 0.092084\n",
      "[1950]\ttraining's rmse: 0.0873925\tvalid_1's rmse: 0.0920819\n",
      "[1975]\ttraining's rmse: 0.0873876\tvalid_1's rmse: 0.0920806\n",
      "[2000]\ttraining's rmse: 0.0873822\tvalid_1's rmse: 0.0920789\n",
      "[2025]\ttraining's rmse: 0.0873771\tvalid_1's rmse: 0.0920773\n",
      "[2050]\ttraining's rmse: 0.0873713\tvalid_1's rmse: 0.0920761\n",
      "[2075]\ttraining's rmse: 0.0873671\tvalid_1's rmse: 0.0920745\n",
      "[2100]\ttraining's rmse: 0.0873634\tvalid_1's rmse: 0.0920738\n",
      "[2125]\ttraining's rmse: 0.08736\tvalid_1's rmse: 0.0920731\n",
      "[2150]\ttraining's rmse: 0.0873561\tvalid_1's rmse: 0.0920718\n",
      "[2175]\ttraining's rmse: 0.0873517\tvalid_1's rmse: 0.0920697\n",
      "[2200]\ttraining's rmse: 0.087348\tvalid_1's rmse: 0.0920682\n",
      "[2225]\ttraining's rmse: 0.0873434\tvalid_1's rmse: 0.0920668\n",
      "[2250]\ttraining's rmse: 0.0873408\tvalid_1's rmse: 0.0920655\n",
      "[2275]\ttraining's rmse: 0.0873373\tvalid_1's rmse: 0.0920646\n",
      "[2300]\ttraining's rmse: 0.0873322\tvalid_1's rmse: 0.0920614\n",
      "[2325]\ttraining's rmse: 0.0873293\tvalid_1's rmse: 0.0920609\n",
      "[2350]\ttraining's rmse: 0.0873265\tvalid_1's rmse: 0.0920605\n",
      "[2375]\ttraining's rmse: 0.0873239\tvalid_1's rmse: 0.0920598\n",
      "[2400]\ttraining's rmse: 0.0873208\tvalid_1's rmse: 0.0920592\n",
      "[2425]\ttraining's rmse: 0.0873178\tvalid_1's rmse: 0.0920579\n",
      "[2450]\ttraining's rmse: 0.0873146\tvalid_1's rmse: 0.0920573\n",
      "[2475]\ttraining's rmse: 0.0873093\tvalid_1's rmse: 0.0920573\n",
      "[2500]\ttraining's rmse: 0.0873064\tvalid_1's rmse: 0.0920573\n",
      "[2525]\ttraining's rmse: 0.0873039\tvalid_1's rmse: 0.0920567\n",
      "[2550]\ttraining's rmse: 0.0872997\tvalid_1's rmse: 0.0920561\n",
      "[2575]\ttraining's rmse: 0.0872972\tvalid_1's rmse: 0.0920552\n",
      "[2600]\ttraining's rmse: 0.0872941\tvalid_1's rmse: 0.0920542\n",
      "[2625]\ttraining's rmse: 0.0872928\tvalid_1's rmse: 0.0920537\n",
      "[2650]\ttraining's rmse: 0.0872912\tvalid_1's rmse: 0.0920534\n",
      "[2675]\ttraining's rmse: 0.0872876\tvalid_1's rmse: 0.0920526\n",
      "[2700]\ttraining's rmse: 0.0872849\tvalid_1's rmse: 0.0920518\n",
      "[2725]\ttraining's rmse: 0.0872823\tvalid_1's rmse: 0.0920511\n",
      "[2750]\ttraining's rmse: 0.0872797\tvalid_1's rmse: 0.0920503\n",
      "[2775]\ttraining's rmse: 0.0872783\tvalid_1's rmse: 0.0920504\n",
      "[2800]\ttraining's rmse: 0.0872757\tvalid_1's rmse: 0.0920496\n",
      "[2825]\ttraining's rmse: 0.0872734\tvalid_1's rmse: 0.0920487\n",
      "[2850]\ttraining's rmse: 0.087271\tvalid_1's rmse: 0.0920484\n",
      "[2875]\ttraining's rmse: 0.0872692\tvalid_1's rmse: 0.0920479\n",
      "[2900]\ttraining's rmse: 0.0872677\tvalid_1's rmse: 0.0920474\n",
      "[2925]\ttraining's rmse: 0.0872667\tvalid_1's rmse: 0.0920474\n",
      "[2950]\ttraining's rmse: 0.0872643\tvalid_1's rmse: 0.0920471\n",
      "[2975]\ttraining's rmse: 0.0872627\tvalid_1's rmse: 0.0920462\n",
      "[3000]\ttraining's rmse: 0.0872608\tvalid_1's rmse: 0.0920454\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0872608\tvalid_1's rmse: 0.0920454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0909631\tvalid_1's rmse: 0.0931849\n",
      "[50]\ttraining's rmse: 0.0907901\tvalid_1's rmse: 0.093129\n",
      "[75]\ttraining's rmse: 0.0906171\tvalid_1's rmse: 0.0930744\n",
      "[100]\ttraining's rmse: 0.0904592\tvalid_1's rmse: 0.0930244\n",
      "[125]\ttraining's rmse: 0.0902996\tvalid_1's rmse: 0.0929762\n",
      "[150]\ttraining's rmse: 0.0901575\tvalid_1's rmse: 0.0929311\n",
      "[175]\ttraining's rmse: 0.0900345\tvalid_1's rmse: 0.0928944\n",
      "[200]\ttraining's rmse: 0.089905\tvalid_1's rmse: 0.0928581\n",
      "[225]\ttraining's rmse: 0.0897836\tvalid_1's rmse: 0.0928237\n",
      "[250]\ttraining's rmse: 0.0896774\tvalid_1's rmse: 0.0927898\n",
      "[275]\ttraining's rmse: 0.0895765\tvalid_1's rmse: 0.0927607\n",
      "[300]\ttraining's rmse: 0.0894783\tvalid_1's rmse: 0.0927327\n",
      "[325]\ttraining's rmse: 0.089381\tvalid_1's rmse: 0.0927051\n",
      "[350]\ttraining's rmse: 0.0892871\tvalid_1's rmse: 0.0926814\n",
      "[375]\ttraining's rmse: 0.0892105\tvalid_1's rmse: 0.0926606\n",
      "[400]\ttraining's rmse: 0.0891293\tvalid_1's rmse: 0.092639\n",
      "[425]\ttraining's rmse: 0.0890521\tvalid_1's rmse: 0.0926184\n",
      "[450]\ttraining's rmse: 0.0889814\tvalid_1's rmse: 0.0925996\n",
      "[475]\ttraining's rmse: 0.0889195\tvalid_1's rmse: 0.0925827\n",
      "[500]\ttraining's rmse: 0.0888649\tvalid_1's rmse: 0.0925656\n",
      "[525]\ttraining's rmse: 0.0887971\tvalid_1's rmse: 0.0925489\n",
      "[550]\ttraining's rmse: 0.0887339\tvalid_1's rmse: 0.0925343\n",
      "[575]\ttraining's rmse: 0.0886757\tvalid_1's rmse: 0.0925194\n",
      "[600]\ttraining's rmse: 0.0886226\tvalid_1's rmse: 0.0925066\n",
      "[625]\ttraining's rmse: 0.08858\tvalid_1's rmse: 0.0924958\n",
      "[650]\ttraining's rmse: 0.0885269\tvalid_1's rmse: 0.0924825\n",
      "[675]\ttraining's rmse: 0.0884743\tvalid_1's rmse: 0.0924713\n",
      "[700]\ttraining's rmse: 0.0884264\tvalid_1's rmse: 0.0924599\n",
      "[725]\ttraining's rmse: 0.0883821\tvalid_1's rmse: 0.092451\n",
      "[750]\ttraining's rmse: 0.0883431\tvalid_1's rmse: 0.0924424\n",
      "[775]\ttraining's rmse: 0.0883066\tvalid_1's rmse: 0.0924335\n",
      "[800]\ttraining's rmse: 0.0882649\tvalid_1's rmse: 0.0924252\n",
      "[825]\ttraining's rmse: 0.0882309\tvalid_1's rmse: 0.092418\n",
      "[850]\ttraining's rmse: 0.0881964\tvalid_1's rmse: 0.0924119\n",
      "[875]\ttraining's rmse: 0.0881652\tvalid_1's rmse: 0.0924062\n",
      "[900]\ttraining's rmse: 0.0881317\tvalid_1's rmse: 0.0923995\n",
      "[925]\ttraining's rmse: 0.0880984\tvalid_1's rmse: 0.0923945\n",
      "[950]\ttraining's rmse: 0.0880683\tvalid_1's rmse: 0.0923887\n",
      "[975]\ttraining's rmse: 0.0880393\tvalid_1's rmse: 0.0923835\n",
      "[1000]\ttraining's rmse: 0.0880123\tvalid_1's rmse: 0.0923781\n",
      "[1025]\ttraining's rmse: 0.0879808\tvalid_1's rmse: 0.0923726\n",
      "[1050]\ttraining's rmse: 0.0879545\tvalid_1's rmse: 0.0923682\n",
      "[1075]\ttraining's rmse: 0.0879286\tvalid_1's rmse: 0.0923653\n",
      "[1100]\ttraining's rmse: 0.0879066\tvalid_1's rmse: 0.0923605\n",
      "[1125]\ttraining's rmse: 0.0878832\tvalid_1's rmse: 0.0923567\n",
      "[1150]\ttraining's rmse: 0.0878605\tvalid_1's rmse: 0.092353\n",
      "[1175]\ttraining's rmse: 0.0878404\tvalid_1's rmse: 0.0923503\n",
      "[1200]\ttraining's rmse: 0.0878199\tvalid_1's rmse: 0.0923472\n",
      "[1225]\ttraining's rmse: 0.0877994\tvalid_1's rmse: 0.0923452\n",
      "[1250]\ttraining's rmse: 0.0877813\tvalid_1's rmse: 0.0923427\n",
      "[1275]\ttraining's rmse: 0.0877622\tvalid_1's rmse: 0.0923417\n",
      "[1300]\ttraining's rmse: 0.0877462\tvalid_1's rmse: 0.0923396\n",
      "[1325]\ttraining's rmse: 0.0877283\tvalid_1's rmse: 0.0923371\n",
      "[1350]\ttraining's rmse: 0.0877108\tvalid_1's rmse: 0.092335\n",
      "[1375]\ttraining's rmse: 0.0876933\tvalid_1's rmse: 0.0923337\n",
      "[1400]\ttraining's rmse: 0.0876779\tvalid_1's rmse: 0.0923313\n",
      "[1425]\ttraining's rmse: 0.0876629\tvalid_1's rmse: 0.0923303\n",
      "[1450]\ttraining's rmse: 0.0876474\tvalid_1's rmse: 0.0923287\n",
      "[1475]\ttraining's rmse: 0.0876342\tvalid_1's rmse: 0.092327\n",
      "[1500]\ttraining's rmse: 0.0876222\tvalid_1's rmse: 0.0923259\n",
      "[1525]\ttraining's rmse: 0.0876109\tvalid_1's rmse: 0.0923254\n",
      "[1550]\ttraining's rmse: 0.0875953\tvalid_1's rmse: 0.0923237\n",
      "[1575]\ttraining's rmse: 0.0875845\tvalid_1's rmse: 0.0923229\n",
      "[1600]\ttraining's rmse: 0.0875766\tvalid_1's rmse: 0.0923223\n",
      "[1625]\ttraining's rmse: 0.0875664\tvalid_1's rmse: 0.0923211\n",
      "[1650]\ttraining's rmse: 0.0875583\tvalid_1's rmse: 0.092321\n",
      "[1675]\ttraining's rmse: 0.0875507\tvalid_1's rmse: 0.0923202\n",
      "[1700]\ttraining's rmse: 0.0875416\tvalid_1's rmse: 0.0923197\n",
      "[1725]\ttraining's rmse: 0.0875332\tvalid_1's rmse: 0.0923189\n",
      "[1750]\ttraining's rmse: 0.0875247\tvalid_1's rmse: 0.092319\n",
      "[1775]\ttraining's rmse: 0.0875175\tvalid_1's rmse: 0.0923189\n",
      "Early stopping, best iteration is:\n",
      "[1731]\ttraining's rmse: 0.0875313\tvalid_1's rmse: 0.0923185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0929819\tvalid_1's rmse: 0.0891747\n",
      "[50]\ttraining's rmse: 0.0928492\tvalid_1's rmse: 0.0891267\n",
      "[75]\ttraining's rmse: 0.0927087\tvalid_1's rmse: 0.0890782\n",
      "[100]\ttraining's rmse: 0.0925798\tvalid_1's rmse: 0.0890357\n",
      "[125]\ttraining's rmse: 0.0924519\tvalid_1's rmse: 0.0889936\n",
      "[150]\ttraining's rmse: 0.0923311\tvalid_1's rmse: 0.0889532\n",
      "[175]\ttraining's rmse: 0.0922298\tvalid_1's rmse: 0.0889211\n",
      "[200]\ttraining's rmse: 0.0921205\tvalid_1's rmse: 0.088889\n",
      "[225]\ttraining's rmse: 0.0920163\tvalid_1's rmse: 0.088857\n",
      "[250]\ttraining's rmse: 0.0919273\tvalid_1's rmse: 0.0888312\n",
      "[275]\ttraining's rmse: 0.0918462\tvalid_1's rmse: 0.0888071\n",
      "[300]\ttraining's rmse: 0.0917657\tvalid_1's rmse: 0.0887839\n",
      "[325]\ttraining's rmse: 0.091684\tvalid_1's rmse: 0.0887619\n",
      "[350]\ttraining's rmse: 0.0916031\tvalid_1's rmse: 0.0887383\n",
      "[375]\ttraining's rmse: 0.0915358\tvalid_1's rmse: 0.0887248\n",
      "[400]\ttraining's rmse: 0.0914638\tvalid_1's rmse: 0.0887111\n",
      "[425]\ttraining's rmse: 0.0913957\tvalid_1's rmse: 0.088695\n",
      "[450]\ttraining's rmse: 0.0913344\tvalid_1's rmse: 0.0886788\n",
      "[475]\ttraining's rmse: 0.0912756\tvalid_1's rmse: 0.0886682\n",
      "[500]\ttraining's rmse: 0.0912304\tvalid_1's rmse: 0.0886545\n",
      "[525]\ttraining's rmse: 0.0911644\tvalid_1's rmse: 0.0886408\n",
      "[550]\ttraining's rmse: 0.0911058\tvalid_1's rmse: 0.0886279\n",
      "[575]\ttraining's rmse: 0.0910542\tvalid_1's rmse: 0.0886218\n",
      "[600]\ttraining's rmse: 0.091002\tvalid_1's rmse: 0.088613\n",
      "[625]\ttraining's rmse: 0.0909609\tvalid_1's rmse: 0.0886043\n",
      "[650]\ttraining's rmse: 0.0909095\tvalid_1's rmse: 0.088599\n",
      "[675]\ttraining's rmse: 0.0908592\tvalid_1's rmse: 0.0885955\n",
      "[700]\ttraining's rmse: 0.0908147\tvalid_1's rmse: 0.0885865\n",
      "[725]\ttraining's rmse: 0.0907714\tvalid_1's rmse: 0.0885928\n",
      "[750]\ttraining's rmse: 0.0907307\tvalid_1's rmse: 0.088598\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0908063\tvalid_1's rmse: 0.0885855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0898617\tvalid_1's rmse: 0.0924397\n",
      "[50]\ttraining's rmse: 0.0897056\tvalid_1's rmse: 0.0923848\n",
      "[75]\ttraining's rmse: 0.0895511\tvalid_1's rmse: 0.0923307\n",
      "[100]\ttraining's rmse: 0.0894108\tvalid_1's rmse: 0.0922821\n",
      "[125]\ttraining's rmse: 0.0892688\tvalid_1's rmse: 0.0922348\n",
      "[150]\ttraining's rmse: 0.0891384\tvalid_1's rmse: 0.0921888\n",
      "[175]\ttraining's rmse: 0.0890275\tvalid_1's rmse: 0.0921504\n",
      "[200]\ttraining's rmse: 0.0889124\tvalid_1's rmse: 0.0921127\n",
      "[225]\ttraining's rmse: 0.088799\tvalid_1's rmse: 0.0920767\n",
      "[250]\ttraining's rmse: 0.0887037\tvalid_1's rmse: 0.0920414\n",
      "[275]\ttraining's rmse: 0.088612\tvalid_1's rmse: 0.0920092\n",
      "[300]\ttraining's rmse: 0.0885237\tvalid_1's rmse: 0.0919809\n",
      "[325]\ttraining's rmse: 0.0884339\tvalid_1's rmse: 0.0919542\n",
      "[350]\ttraining's rmse: 0.0883503\tvalid_1's rmse: 0.091929\n",
      "[375]\ttraining's rmse: 0.0882775\tvalid_1's rmse: 0.0919054\n",
      "[400]\ttraining's rmse: 0.0882016\tvalid_1's rmse: 0.0918836\n",
      "[425]\ttraining's rmse: 0.0881321\tvalid_1's rmse: 0.0918613\n",
      "[450]\ttraining's rmse: 0.0880694\tvalid_1's rmse: 0.0918419\n",
      "[475]\ttraining's rmse: 0.0880096\tvalid_1's rmse: 0.0918225\n",
      "[500]\ttraining's rmse: 0.0879571\tvalid_1's rmse: 0.0918031\n",
      "[525]\ttraining's rmse: 0.0878938\tvalid_1's rmse: 0.0917845\n",
      "[550]\ttraining's rmse: 0.087836\tvalid_1's rmse: 0.0917686\n",
      "[575]\ttraining's rmse: 0.0877794\tvalid_1's rmse: 0.0917531\n",
      "[600]\ttraining's rmse: 0.0877272\tvalid_1's rmse: 0.0917399\n",
      "[625]\ttraining's rmse: 0.0876836\tvalid_1's rmse: 0.0917262\n",
      "[650]\ttraining's rmse: 0.087631\tvalid_1's rmse: 0.0917137\n",
      "[675]\ttraining's rmse: 0.0875819\tvalid_1's rmse: 0.0917013\n",
      "[700]\ttraining's rmse: 0.0875373\tvalid_1's rmse: 0.0916898\n",
      "[725]\ttraining's rmse: 0.0874982\tvalid_1's rmse: 0.0916784\n",
      "[750]\ttraining's rmse: 0.0874579\tvalid_1's rmse: 0.0916694\n",
      "[775]\ttraining's rmse: 0.0874255\tvalid_1's rmse: 0.0916572\n",
      "[800]\ttraining's rmse: 0.0873863\tvalid_1's rmse: 0.0916487\n",
      "[825]\ttraining's rmse: 0.0873521\tvalid_1's rmse: 0.0916391\n",
      "[850]\ttraining's rmse: 0.0873158\tvalid_1's rmse: 0.0916309\n",
      "[875]\ttraining's rmse: 0.0872862\tvalid_1's rmse: 0.0916247\n",
      "[900]\ttraining's rmse: 0.0872506\tvalid_1's rmse: 0.0916174\n",
      "[925]\ttraining's rmse: 0.0872216\tvalid_1's rmse: 0.0916105\n",
      "[950]\ttraining's rmse: 0.0871939\tvalid_1's rmse: 0.0916044\n",
      "[975]\ttraining's rmse: 0.0871669\tvalid_1's rmse: 0.0915974\n",
      "[1000]\ttraining's rmse: 0.0871392\tvalid_1's rmse: 0.0915927\n",
      "[1025]\ttraining's rmse: 0.0871151\tvalid_1's rmse: 0.0915868\n",
      "[1050]\ttraining's rmse: 0.0870906\tvalid_1's rmse: 0.0915795\n",
      "[1075]\ttraining's rmse: 0.0870673\tvalid_1's rmse: 0.0915745\n",
      "[1100]\ttraining's rmse: 0.0870465\tvalid_1's rmse: 0.091569\n",
      "[1125]\ttraining's rmse: 0.0870258\tvalid_1's rmse: 0.0915641\n",
      "[1150]\ttraining's rmse: 0.0870062\tvalid_1's rmse: 0.0915593\n",
      "[1175]\ttraining's rmse: 0.0869872\tvalid_1's rmse: 0.0915564\n",
      "[1200]\ttraining's rmse: 0.0869672\tvalid_1's rmse: 0.0915495\n",
      "[1225]\ttraining's rmse: 0.0869476\tvalid_1's rmse: 0.0915448\n",
      "[1250]\ttraining's rmse: 0.0869345\tvalid_1's rmse: 0.0915404\n",
      "[1275]\ttraining's rmse: 0.0869167\tvalid_1's rmse: 0.091536\n",
      "[1300]\ttraining's rmse: 0.0869007\tvalid_1's rmse: 0.0915329\n",
      "[1325]\ttraining's rmse: 0.0868843\tvalid_1's rmse: 0.0915292\n",
      "[1350]\ttraining's rmse: 0.0868692\tvalid_1's rmse: 0.0915261\n",
      "[1375]\ttraining's rmse: 0.0868527\tvalid_1's rmse: 0.0915233\n",
      "[1400]\ttraining's rmse: 0.0868396\tvalid_1's rmse: 0.0915197\n",
      "[1425]\ttraining's rmse: 0.0868261\tvalid_1's rmse: 0.0915164\n",
      "[1450]\ttraining's rmse: 0.0868136\tvalid_1's rmse: 0.0915116\n",
      "[1475]\ttraining's rmse: 0.086801\tvalid_1's rmse: 0.0915079\n",
      "[1500]\ttraining's rmse: 0.0867889\tvalid_1's rmse: 0.0915054\n",
      "[1525]\ttraining's rmse: 0.0867779\tvalid_1's rmse: 0.091502\n",
      "[1550]\ttraining's rmse: 0.0867645\tvalid_1's rmse: 0.0914997\n",
      "[1575]\ttraining's rmse: 0.0867544\tvalid_1's rmse: 0.091497\n",
      "[1600]\ttraining's rmse: 0.0867444\tvalid_1's rmse: 0.0914949\n",
      "[1625]\ttraining's rmse: 0.0867339\tvalid_1's rmse: 0.0914923\n",
      "[1650]\ttraining's rmse: 0.086724\tvalid_1's rmse: 0.0914902\n",
      "[1675]\ttraining's rmse: 0.0867155\tvalid_1's rmse: 0.091487\n",
      "[1700]\ttraining's rmse: 0.0867079\tvalid_1's rmse: 0.0914855\n",
      "[1725]\ttraining's rmse: 0.086701\tvalid_1's rmse: 0.091484\n",
      "[1750]\ttraining's rmse: 0.0866923\tvalid_1's rmse: 0.0914821\n",
      "[1775]\ttraining's rmse: 0.0866828\tvalid_1's rmse: 0.0914812\n",
      "[1800]\ttraining's rmse: 0.0866764\tvalid_1's rmse: 0.091478\n",
      "[1825]\ttraining's rmse: 0.0866705\tvalid_1's rmse: 0.091476\n",
      "[1850]\ttraining's rmse: 0.0866651\tvalid_1's rmse: 0.0914748\n",
      "[1875]\ttraining's rmse: 0.0866566\tvalid_1's rmse: 0.091474\n",
      "[1900]\ttraining's rmse: 0.0866501\tvalid_1's rmse: 0.0914719\n",
      "[1925]\ttraining's rmse: 0.0866441\tvalid_1's rmse: 0.091469\n",
      "[1950]\ttraining's rmse: 0.0866402\tvalid_1's rmse: 0.0914677\n",
      "[1975]\ttraining's rmse: 0.0866352\tvalid_1's rmse: 0.091466\n",
      "[2000]\ttraining's rmse: 0.0866283\tvalid_1's rmse: 0.0914654\n",
      "[2025]\ttraining's rmse: 0.0866235\tvalid_1's rmse: 0.0914643\n",
      "[2050]\ttraining's rmse: 0.0866186\tvalid_1's rmse: 0.0914624\n",
      "[2075]\ttraining's rmse: 0.0866147\tvalid_1's rmse: 0.0914608\n",
      "[2100]\ttraining's rmse: 0.0866111\tvalid_1's rmse: 0.0914599\n",
      "[2125]\ttraining's rmse: 0.0866067\tvalid_1's rmse: 0.0914591\n",
      "[2150]\ttraining's rmse: 0.086601\tvalid_1's rmse: 0.091458\n",
      "[2175]\ttraining's rmse: 0.0865976\tvalid_1's rmse: 0.0914577\n",
      "[2200]\ttraining's rmse: 0.0865946\tvalid_1's rmse: 0.0914562\n",
      "[2225]\ttraining's rmse: 0.086591\tvalid_1's rmse: 0.0914549\n",
      "[2250]\ttraining's rmse: 0.0865883\tvalid_1's rmse: 0.0914543\n",
      "[2275]\ttraining's rmse: 0.086584\tvalid_1's rmse: 0.0914527\n",
      "[2300]\ttraining's rmse: 0.0865808\tvalid_1's rmse: 0.0914516\n",
      "[2325]\ttraining's rmse: 0.086577\tvalid_1's rmse: 0.091451\n",
      "[2350]\ttraining's rmse: 0.0865721\tvalid_1's rmse: 0.0914495\n",
      "[2375]\ttraining's rmse: 0.0865692\tvalid_1's rmse: 0.0914481\n",
      "[2400]\ttraining's rmse: 0.0865657\tvalid_1's rmse: 0.0914478\n",
      "[2425]\ttraining's rmse: 0.086562\tvalid_1's rmse: 0.0914475\n",
      "[2450]\ttraining's rmse: 0.0865603\tvalid_1's rmse: 0.0914463\n",
      "[2475]\ttraining's rmse: 0.0865563\tvalid_1's rmse: 0.0914468\n",
      "Early stopping, best iteration is:\n",
      "[2442]\ttraining's rmse: 0.0865608\tvalid_1's rmse: 0.0914462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0898146\tvalid_1's rmse: 0.0925572\n",
      "[50]\ttraining's rmse: 0.089681\tvalid_1's rmse: 0.092499\n",
      "[75]\ttraining's rmse: 0.0895398\tvalid_1's rmse: 0.0924438\n",
      "[100]\ttraining's rmse: 0.0894139\tvalid_1's rmse: 0.0923943\n",
      "[125]\ttraining's rmse: 0.0892818\tvalid_1's rmse: 0.0923455\n",
      "[150]\ttraining's rmse: 0.089162\tvalid_1's rmse: 0.0922997\n",
      "[175]\ttraining's rmse: 0.0890627\tvalid_1's rmse: 0.0922616\n",
      "[200]\ttraining's rmse: 0.0889547\tvalid_1's rmse: 0.0922251\n",
      "[225]\ttraining's rmse: 0.0888511\tvalid_1's rmse: 0.0921894\n",
      "[250]\ttraining's rmse: 0.0887592\tvalid_1's rmse: 0.092155\n",
      "[275]\ttraining's rmse: 0.0886792\tvalid_1's rmse: 0.0921257\n",
      "[300]\ttraining's rmse: 0.0885945\tvalid_1's rmse: 0.0920977\n",
      "[325]\ttraining's rmse: 0.0885111\tvalid_1's rmse: 0.0920706\n",
      "[350]\ttraining's rmse: 0.0884311\tvalid_1's rmse: 0.0920458\n",
      "[375]\ttraining's rmse: 0.0883677\tvalid_1's rmse: 0.0920253\n",
      "[400]\ttraining's rmse: 0.0882952\tvalid_1's rmse: 0.0920047\n",
      "[425]\ttraining's rmse: 0.0882291\tvalid_1's rmse: 0.091984\n",
      "[450]\ttraining's rmse: 0.0881686\tvalid_1's rmse: 0.0919649\n",
      "[475]\ttraining's rmse: 0.0881121\tvalid_1's rmse: 0.0919478\n",
      "[500]\ttraining's rmse: 0.0880634\tvalid_1's rmse: 0.0919315\n",
      "[525]\ttraining's rmse: 0.0880005\tvalid_1's rmse: 0.091914\n",
      "[550]\ttraining's rmse: 0.0879426\tvalid_1's rmse: 0.0918997\n",
      "[575]\ttraining's rmse: 0.0878894\tvalid_1's rmse: 0.0918853\n",
      "[600]\ttraining's rmse: 0.0878385\tvalid_1's rmse: 0.0918728\n",
      "[625]\ttraining's rmse: 0.0877972\tvalid_1's rmse: 0.0918602\n",
      "[650]\ttraining's rmse: 0.0877457\tvalid_1's rmse: 0.0918471\n",
      "[675]\ttraining's rmse: 0.0876978\tvalid_1's rmse: 0.0918362\n",
      "[700]\ttraining's rmse: 0.0876527\tvalid_1's rmse: 0.0918258\n",
      "[725]\ttraining's rmse: 0.0876104\tvalid_1's rmse: 0.0918162\n",
      "[750]\ttraining's rmse: 0.0875714\tvalid_1's rmse: 0.0918078\n",
      "[775]\ttraining's rmse: 0.087539\tvalid_1's rmse: 0.0917987\n",
      "[800]\ttraining's rmse: 0.0874971\tvalid_1's rmse: 0.0917902\n",
      "[825]\ttraining's rmse: 0.0874629\tvalid_1's rmse: 0.0917824\n",
      "[850]\ttraining's rmse: 0.0874304\tvalid_1's rmse: 0.0917766\n",
      "[875]\ttraining's rmse: 0.0873987\tvalid_1's rmse: 0.0917696\n",
      "[900]\ttraining's rmse: 0.0873652\tvalid_1's rmse: 0.091763\n",
      "[925]\ttraining's rmse: 0.0873327\tvalid_1's rmse: 0.0917566\n",
      "[950]\ttraining's rmse: 0.0873041\tvalid_1's rmse: 0.0917515\n",
      "[975]\ttraining's rmse: 0.0872766\tvalid_1's rmse: 0.0917455\n",
      "[1000]\ttraining's rmse: 0.087251\tvalid_1's rmse: 0.0917409\n",
      "[1025]\ttraining's rmse: 0.087222\tvalid_1's rmse: 0.0917366\n",
      "[1050]\ttraining's rmse: 0.0871964\tvalid_1's rmse: 0.0917322\n",
      "[1075]\ttraining's rmse: 0.0871734\tvalid_1's rmse: 0.0917292\n",
      "[1100]\ttraining's rmse: 0.0871522\tvalid_1's rmse: 0.0917246\n",
      "[1125]\ttraining's rmse: 0.0871302\tvalid_1's rmse: 0.0917207\n",
      "[1150]\ttraining's rmse: 0.0871055\tvalid_1's rmse: 0.0917177\n",
      "[1175]\ttraining's rmse: 0.0870873\tvalid_1's rmse: 0.0917155\n",
      "[1200]\ttraining's rmse: 0.0870684\tvalid_1's rmse: 0.0917119\n",
      "[1225]\ttraining's rmse: 0.0870505\tvalid_1's rmse: 0.0917094\n",
      "[1250]\ttraining's rmse: 0.087037\tvalid_1's rmse: 0.0917079\n",
      "[1275]\ttraining's rmse: 0.0870169\tvalid_1's rmse: 0.091706\n",
      "[1300]\ttraining's rmse: 0.086999\tvalid_1's rmse: 0.091703\n",
      "[1325]\ttraining's rmse: 0.0869838\tvalid_1's rmse: 0.091701\n",
      "[1350]\ttraining's rmse: 0.0869658\tvalid_1's rmse: 0.091699\n",
      "[1375]\ttraining's rmse: 0.0869514\tvalid_1's rmse: 0.0916977\n",
      "[1400]\ttraining's rmse: 0.0869379\tvalid_1's rmse: 0.0916959\n",
      "[1425]\ttraining's rmse: 0.0869212\tvalid_1's rmse: 0.0916946\n",
      "[1450]\ttraining's rmse: 0.0869097\tvalid_1's rmse: 0.0916938\n",
      "[1475]\ttraining's rmse: 0.0868978\tvalid_1's rmse: 0.0916923\n",
      "[1500]\ttraining's rmse: 0.0868842\tvalid_1's rmse: 0.0916913\n",
      "[1525]\ttraining's rmse: 0.0868747\tvalid_1's rmse: 0.0916906\n",
      "[1550]\ttraining's rmse: 0.0868629\tvalid_1's rmse: 0.0916898\n",
      "[1575]\ttraining's rmse: 0.0868536\tvalid_1's rmse: 0.0916886\n",
      "[1600]\ttraining's rmse: 0.0868438\tvalid_1's rmse: 0.0916879\n",
      "[1625]\ttraining's rmse: 0.086835\tvalid_1's rmse: 0.0916862\n",
      "[1650]\ttraining's rmse: 0.0868255\tvalid_1's rmse: 0.0916856\n",
      "[1675]\ttraining's rmse: 0.086818\tvalid_1's rmse: 0.0916844\n",
      "[1700]\ttraining's rmse: 0.0868111\tvalid_1's rmse: 0.0916835\n",
      "[1725]\ttraining's rmse: 0.0868054\tvalid_1's rmse: 0.0916826\n",
      "[1750]\ttraining's rmse: 0.0867971\tvalid_1's rmse: 0.0916825\n",
      "[1775]\ttraining's rmse: 0.086791\tvalid_1's rmse: 0.0916822\n",
      "[1800]\ttraining's rmse: 0.0867845\tvalid_1's rmse: 0.0916812\n",
      "[1825]\ttraining's rmse: 0.0867773\tvalid_1's rmse: 0.0916806\n",
      "[1850]\ttraining's rmse: 0.086771\tvalid_1's rmse: 0.0916802\n",
      "[1875]\ttraining's rmse: 0.0867649\tvalid_1's rmse: 0.0916796\n",
      "[1900]\ttraining's rmse: 0.0867589\tvalid_1's rmse: 0.0916793\n",
      "[1925]\ttraining's rmse: 0.0867509\tvalid_1's rmse: 0.0916788\n",
      "[1950]\ttraining's rmse: 0.0867456\tvalid_1's rmse: 0.0916781\n",
      "[1975]\ttraining's rmse: 0.0867397\tvalid_1's rmse: 0.0916776\n",
      "[2000]\ttraining's rmse: 0.0867337\tvalid_1's rmse: 0.0916765\n",
      "[2025]\ttraining's rmse: 0.0867292\tvalid_1's rmse: 0.0916758\n",
      "[2050]\ttraining's rmse: 0.0867247\tvalid_1's rmse: 0.0916754\n",
      "[2075]\ttraining's rmse: 0.0867211\tvalid_1's rmse: 0.0916752\n",
      "[2100]\ttraining's rmse: 0.0867176\tvalid_1's rmse: 0.0916754\n",
      "Early stopping, best iteration is:\n",
      "[2067]\ttraining's rmse: 0.086722\tvalid_1's rmse: 0.091675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0923592\tvalid_1's rmse: 0.0873928\n",
      "[50]\ttraining's rmse: 0.0922288\tvalid_1's rmse: 0.0873416\n",
      "[75]\ttraining's rmse: 0.0920918\tvalid_1's rmse: 0.0872922\n",
      "[100]\ttraining's rmse: 0.0919669\tvalid_1's rmse: 0.0872483\n",
      "[125]\ttraining's rmse: 0.0918374\tvalid_1's rmse: 0.0872047\n",
      "[150]\ttraining's rmse: 0.0917207\tvalid_1's rmse: 0.087165\n",
      "[175]\ttraining's rmse: 0.0916246\tvalid_1's rmse: 0.0871333\n",
      "[200]\ttraining's rmse: 0.0915181\tvalid_1's rmse: 0.0871008\n",
      "[225]\ttraining's rmse: 0.0914165\tvalid_1's rmse: 0.0870687\n",
      "[250]\ttraining's rmse: 0.0913278\tvalid_1's rmse: 0.0870408\n",
      "[275]\ttraining's rmse: 0.0912505\tvalid_1's rmse: 0.0870149\n",
      "[300]\ttraining's rmse: 0.0911695\tvalid_1's rmse: 0.0869908\n",
      "[325]\ttraining's rmse: 0.0910869\tvalid_1's rmse: 0.086969\n",
      "[350]\ttraining's rmse: 0.0910083\tvalid_1's rmse: 0.0869497\n",
      "[375]\ttraining's rmse: 0.0909432\tvalid_1's rmse: 0.0869363\n",
      "[400]\ttraining's rmse: 0.0908731\tvalid_1's rmse: 0.0869229\n",
      "[425]\ttraining's rmse: 0.0908073\tvalid_1's rmse: 0.0869083\n",
      "[450]\ttraining's rmse: 0.0907471\tvalid_1's rmse: 0.0868949\n",
      "[475]\ttraining's rmse: 0.0906888\tvalid_1's rmse: 0.0868802\n",
      "[500]\ttraining's rmse: 0.0906415\tvalid_1's rmse: 0.0868691\n",
      "[525]\ttraining's rmse: 0.0905755\tvalid_1's rmse: 0.0868556\n",
      "[550]\ttraining's rmse: 0.0905209\tvalid_1's rmse: 0.0868473\n",
      "[575]\ttraining's rmse: 0.0904672\tvalid_1's rmse: 0.0868351\n",
      "[600]\ttraining's rmse: 0.0904171\tvalid_1's rmse: 0.0868254\n",
      "[625]\ttraining's rmse: 0.0903773\tvalid_1's rmse: 0.0868207\n",
      "[650]\ttraining's rmse: 0.0903269\tvalid_1's rmse: 0.0868248\n",
      "[675]\ttraining's rmse: 0.090275\tvalid_1's rmse: 0.0868253\n",
      "Early stopping, best iteration is:\n",
      "[643]\ttraining's rmse: 0.0903422\tvalid_1's rmse: 0.086818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0916587\tvalid_1's rmse: 0.0936143\n",
      "[50]\ttraining's rmse: 0.0914656\tvalid_1's rmse: 0.0935586\n",
      "[75]\ttraining's rmse: 0.0912813\tvalid_1's rmse: 0.0935036\n",
      "[100]\ttraining's rmse: 0.0911073\tvalid_1's rmse: 0.0934544\n",
      "[125]\ttraining's rmse: 0.0909367\tvalid_1's rmse: 0.0934086\n",
      "[150]\ttraining's rmse: 0.0907776\tvalid_1's rmse: 0.0933637\n",
      "[175]\ttraining's rmse: 0.0906437\tvalid_1's rmse: 0.0933234\n",
      "[200]\ttraining's rmse: 0.0905027\tvalid_1's rmse: 0.0932835\n",
      "[225]\ttraining's rmse: 0.0903699\tvalid_1's rmse: 0.0932453\n",
      "[250]\ttraining's rmse: 0.0902578\tvalid_1's rmse: 0.0932126\n",
      "[275]\ttraining's rmse: 0.0901483\tvalid_1's rmse: 0.0931829\n",
      "[300]\ttraining's rmse: 0.0900402\tvalid_1's rmse: 0.0931542\n",
      "[325]\ttraining's rmse: 0.0899374\tvalid_1's rmse: 0.093126\n",
      "[350]\ttraining's rmse: 0.0898372\tvalid_1's rmse: 0.0930996\n",
      "[375]\ttraining's rmse: 0.0897521\tvalid_1's rmse: 0.0930749\n",
      "[400]\ttraining's rmse: 0.0896563\tvalid_1's rmse: 0.0930524\n",
      "[425]\ttraining's rmse: 0.0895777\tvalid_1's rmse: 0.0930308\n",
      "[450]\ttraining's rmse: 0.0895037\tvalid_1's rmse: 0.0930114\n",
      "[475]\ttraining's rmse: 0.089436\tvalid_1's rmse: 0.0929902\n",
      "[500]\ttraining's rmse: 0.089375\tvalid_1's rmse: 0.0929729\n",
      "[525]\ttraining's rmse: 0.0893035\tvalid_1's rmse: 0.0929554\n",
      "[550]\ttraining's rmse: 0.0892394\tvalid_1's rmse: 0.0929384\n",
      "[575]\ttraining's rmse: 0.0891776\tvalid_1's rmse: 0.092924\n",
      "[600]\ttraining's rmse: 0.0891204\tvalid_1's rmse: 0.0929098\n",
      "[625]\ttraining's rmse: 0.0890711\tvalid_1's rmse: 0.0928952\n",
      "[650]\ttraining's rmse: 0.0890146\tvalid_1's rmse: 0.092881\n",
      "[675]\ttraining's rmse: 0.0889608\tvalid_1's rmse: 0.0928672\n",
      "[700]\ttraining's rmse: 0.0889109\tvalid_1's rmse: 0.0928557\n",
      "[725]\ttraining's rmse: 0.088865\tvalid_1's rmse: 0.0928456\n",
      "[750]\ttraining's rmse: 0.0888218\tvalid_1's rmse: 0.0928349\n",
      "[775]\ttraining's rmse: 0.0887887\tvalid_1's rmse: 0.0928256\n",
      "[800]\ttraining's rmse: 0.0887476\tvalid_1's rmse: 0.0928159\n",
      "[825]\ttraining's rmse: 0.0887119\tvalid_1's rmse: 0.0928062\n",
      "[850]\ttraining's rmse: 0.088677\tvalid_1's rmse: 0.0927981\n",
      "[875]\ttraining's rmse: 0.0886452\tvalid_1's rmse: 0.0927897\n",
      "[900]\ttraining's rmse: 0.0886082\tvalid_1's rmse: 0.0927816\n",
      "[925]\ttraining's rmse: 0.0885777\tvalid_1's rmse: 0.0927741\n",
      "[950]\ttraining's rmse: 0.0885437\tvalid_1's rmse: 0.0927654\n",
      "[975]\ttraining's rmse: 0.0885134\tvalid_1's rmse: 0.0927586\n",
      "[1000]\ttraining's rmse: 0.0884866\tvalid_1's rmse: 0.0927505\n",
      "[1025]\ttraining's rmse: 0.0884548\tvalid_1's rmse: 0.0927416\n",
      "[1050]\ttraining's rmse: 0.0884291\tvalid_1's rmse: 0.0927354\n",
      "[1075]\ttraining's rmse: 0.0884053\tvalid_1's rmse: 0.0927295\n",
      "[1100]\ttraining's rmse: 0.0883823\tvalid_1's rmse: 0.0927236\n",
      "[1125]\ttraining's rmse: 0.0883604\tvalid_1's rmse: 0.0927174\n",
      "[1150]\ttraining's rmse: 0.0883387\tvalid_1's rmse: 0.0927118\n",
      "[1175]\ttraining's rmse: 0.0883182\tvalid_1's rmse: 0.0927078\n",
      "[1200]\ttraining's rmse: 0.088299\tvalid_1's rmse: 0.092703\n",
      "[1225]\ttraining's rmse: 0.0882803\tvalid_1's rmse: 0.0926974\n",
      "[1250]\ttraining's rmse: 0.0882623\tvalid_1's rmse: 0.0926927\n",
      "[1275]\ttraining's rmse: 0.0882411\tvalid_1's rmse: 0.0926893\n",
      "[1300]\ttraining's rmse: 0.0882271\tvalid_1's rmse: 0.0926861\n",
      "[1325]\ttraining's rmse: 0.0882108\tvalid_1's rmse: 0.0926836\n",
      "[1350]\ttraining's rmse: 0.0881959\tvalid_1's rmse: 0.0926803\n",
      "[1375]\ttraining's rmse: 0.0881791\tvalid_1's rmse: 0.0926764\n",
      "[1400]\ttraining's rmse: 0.0881633\tvalid_1's rmse: 0.092672\n",
      "[1425]\ttraining's rmse: 0.0881438\tvalid_1's rmse: 0.0926686\n",
      "[1450]\ttraining's rmse: 0.088128\tvalid_1's rmse: 0.092665\n",
      "[1475]\ttraining's rmse: 0.0881162\tvalid_1's rmse: 0.0926612\n",
      "[1500]\ttraining's rmse: 0.0881036\tvalid_1's rmse: 0.0926589\n",
      "[1525]\ttraining's rmse: 0.0880913\tvalid_1's rmse: 0.0926559\n",
      "[1550]\ttraining's rmse: 0.0880806\tvalid_1's rmse: 0.0926551\n",
      "[1575]\ttraining's rmse: 0.0880693\tvalid_1's rmse: 0.0926516\n",
      "[1600]\ttraining's rmse: 0.0880601\tvalid_1's rmse: 0.0926489\n",
      "[1625]\ttraining's rmse: 0.0880482\tvalid_1's rmse: 0.092645\n",
      "[1650]\ttraining's rmse: 0.0880413\tvalid_1's rmse: 0.0926435\n",
      "[1675]\ttraining's rmse: 0.0880339\tvalid_1's rmse: 0.092642\n",
      "[1700]\ttraining's rmse: 0.0880272\tvalid_1's rmse: 0.09264\n",
      "[1725]\ttraining's rmse: 0.0880201\tvalid_1's rmse: 0.0926374\n",
      "[1750]\ttraining's rmse: 0.0880121\tvalid_1's rmse: 0.0926346\n",
      "[1775]\ttraining's rmse: 0.088002\tvalid_1's rmse: 0.092633\n",
      "[1800]\ttraining's rmse: 0.0879933\tvalid_1's rmse: 0.0926317\n",
      "[1825]\ttraining's rmse: 0.0879858\tvalid_1's rmse: 0.0926304\n",
      "[1850]\ttraining's rmse: 0.0879801\tvalid_1's rmse: 0.0926279\n",
      "[1875]\ttraining's rmse: 0.0879714\tvalid_1's rmse: 0.092626\n",
      "[1900]\ttraining's rmse: 0.0879639\tvalid_1's rmse: 0.0926247\n",
      "[1925]\ttraining's rmse: 0.0879565\tvalid_1's rmse: 0.0926218\n",
      "[1950]\ttraining's rmse: 0.087952\tvalid_1's rmse: 0.0926196\n",
      "[1975]\ttraining's rmse: 0.0879478\tvalid_1's rmse: 0.0926171\n",
      "[2000]\ttraining's rmse: 0.0879399\tvalid_1's rmse: 0.0926156\n",
      "[2025]\ttraining's rmse: 0.0879347\tvalid_1's rmse: 0.092614\n",
      "[2050]\ttraining's rmse: 0.0879298\tvalid_1's rmse: 0.0926118\n",
      "[2075]\ttraining's rmse: 0.0879245\tvalid_1's rmse: 0.0926103\n",
      "[2100]\ttraining's rmse: 0.0879211\tvalid_1's rmse: 0.09261\n",
      "[2125]\ttraining's rmse: 0.0879175\tvalid_1's rmse: 0.0926092\n",
      "[2150]\ttraining's rmse: 0.087912\tvalid_1's rmse: 0.0926082\n",
      "[2175]\ttraining's rmse: 0.0879086\tvalid_1's rmse: 0.0926075\n",
      "[2200]\ttraining's rmse: 0.0879031\tvalid_1's rmse: 0.0926058\n",
      "[2225]\ttraining's rmse: 0.087899\tvalid_1's rmse: 0.0926046\n",
      "[2250]\ttraining's rmse: 0.087896\tvalid_1's rmse: 0.0926039\n",
      "[2275]\ttraining's rmse: 0.0878918\tvalid_1's rmse: 0.0926035\n",
      "[2300]\ttraining's rmse: 0.0878878\tvalid_1's rmse: 0.0926015\n",
      "[2325]\ttraining's rmse: 0.0878821\tvalid_1's rmse: 0.0925993\n",
      "[2350]\ttraining's rmse: 0.0878803\tvalid_1's rmse: 0.0925984\n",
      "[2375]\ttraining's rmse: 0.0878776\tvalid_1's rmse: 0.0925976\n",
      "[2400]\ttraining's rmse: 0.0878744\tvalid_1's rmse: 0.092597\n",
      "[2425]\ttraining's rmse: 0.0878716\tvalid_1's rmse: 0.0925968\n",
      "[2450]\ttraining's rmse: 0.0878695\tvalid_1's rmse: 0.0925962\n",
      "[2475]\ttraining's rmse: 0.0878668\tvalid_1's rmse: 0.0925964\n",
      "[2500]\ttraining's rmse: 0.0878646\tvalid_1's rmse: 0.0925953\n",
      "[2525]\ttraining's rmse: 0.0878626\tvalid_1's rmse: 0.0925947\n",
      "[2550]\ttraining's rmse: 0.0878595\tvalid_1's rmse: 0.0925947\n",
      "[2575]\ttraining's rmse: 0.0878576\tvalid_1's rmse: 0.0925944\n",
      "[2600]\ttraining's rmse: 0.087855\tvalid_1's rmse: 0.0925938\n",
      "[2625]\ttraining's rmse: 0.0878524\tvalid_1's rmse: 0.092593\n",
      "[2650]\ttraining's rmse: 0.0878497\tvalid_1's rmse: 0.0925921\n",
      "[2675]\ttraining's rmse: 0.0878478\tvalid_1's rmse: 0.0925914\n",
      "[2700]\ttraining's rmse: 0.0878458\tvalid_1's rmse: 0.0925908\n",
      "[2725]\ttraining's rmse: 0.0878428\tvalid_1's rmse: 0.0925901\n",
      "[2750]\ttraining's rmse: 0.0878404\tvalid_1's rmse: 0.0925895\n",
      "[2775]\ttraining's rmse: 0.0878382\tvalid_1's rmse: 0.0925887\n",
      "[2800]\ttraining's rmse: 0.0878362\tvalid_1's rmse: 0.0925885\n",
      "[2825]\ttraining's rmse: 0.0878338\tvalid_1's rmse: 0.0925873\n",
      "[2850]\ttraining's rmse: 0.087832\tvalid_1's rmse: 0.0925873\n",
      "[2875]\ttraining's rmse: 0.0878296\tvalid_1's rmse: 0.0925874\n",
      "Early stopping, best iteration is:\n",
      "[2830]\ttraining's rmse: 0.0878335\tvalid_1's rmse: 0.092587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0914991\tvalid_1's rmse: 0.0939428\n",
      "[50]\ttraining's rmse: 0.0913233\tvalid_1's rmse: 0.0938858\n",
      "[75]\ttraining's rmse: 0.0911507\tvalid_1's rmse: 0.093831\n",
      "[100]\ttraining's rmse: 0.0909924\tvalid_1's rmse: 0.0937835\n",
      "[125]\ttraining's rmse: 0.0908321\tvalid_1's rmse: 0.0937342\n",
      "[150]\ttraining's rmse: 0.0906869\tvalid_1's rmse: 0.0936899\n",
      "[175]\ttraining's rmse: 0.0905598\tvalid_1's rmse: 0.0936524\n",
      "[200]\ttraining's rmse: 0.09043\tvalid_1's rmse: 0.0936156\n",
      "[225]\ttraining's rmse: 0.0903071\tvalid_1's rmse: 0.0935819\n",
      "[250]\ttraining's rmse: 0.0902013\tvalid_1's rmse: 0.0935505\n",
      "[275]\ttraining's rmse: 0.0901008\tvalid_1's rmse: 0.0935222\n",
      "[300]\ttraining's rmse: 0.0900044\tvalid_1's rmse: 0.0934945\n",
      "[325]\ttraining's rmse: 0.0899073\tvalid_1's rmse: 0.0934673\n",
      "[350]\ttraining's rmse: 0.0898151\tvalid_1's rmse: 0.0934423\n",
      "[375]\ttraining's rmse: 0.0897382\tvalid_1's rmse: 0.0934224\n",
      "[400]\ttraining's rmse: 0.0896567\tvalid_1's rmse: 0.0934007\n",
      "[425]\ttraining's rmse: 0.0895829\tvalid_1's rmse: 0.0933811\n",
      "[450]\ttraining's rmse: 0.089515\tvalid_1's rmse: 0.0933619\n",
      "[475]\ttraining's rmse: 0.0894511\tvalid_1's rmse: 0.0933441\n",
      "[500]\ttraining's rmse: 0.0893967\tvalid_1's rmse: 0.0933273\n",
      "[525]\ttraining's rmse: 0.0893279\tvalid_1's rmse: 0.0933102\n",
      "[550]\ttraining's rmse: 0.0892666\tvalid_1's rmse: 0.0932963\n",
      "[575]\ttraining's rmse: 0.0892078\tvalid_1's rmse: 0.0932816\n",
      "[600]\ttraining's rmse: 0.0891521\tvalid_1's rmse: 0.0932688\n",
      "[625]\ttraining's rmse: 0.0891074\tvalid_1's rmse: 0.093257\n",
      "[650]\ttraining's rmse: 0.089054\tvalid_1's rmse: 0.0932436\n",
      "[675]\ttraining's rmse: 0.0890009\tvalid_1's rmse: 0.0932326\n",
      "[700]\ttraining's rmse: 0.0889545\tvalid_1's rmse: 0.0932216\n",
      "[725]\ttraining's rmse: 0.0889109\tvalid_1's rmse: 0.093212\n",
      "[750]\ttraining's rmse: 0.0888684\tvalid_1's rmse: 0.0932028\n",
      "[775]\ttraining's rmse: 0.0888335\tvalid_1's rmse: 0.0931928\n",
      "[800]\ttraining's rmse: 0.0887913\tvalid_1's rmse: 0.0931848\n",
      "[825]\ttraining's rmse: 0.0887557\tvalid_1's rmse: 0.0931778\n",
      "[850]\ttraining's rmse: 0.0887198\tvalid_1's rmse: 0.0931711\n",
      "[875]\ttraining's rmse: 0.0886892\tvalid_1's rmse: 0.0931647\n",
      "[900]\ttraining's rmse: 0.0886522\tvalid_1's rmse: 0.0931577\n",
      "[925]\ttraining's rmse: 0.0886215\tvalid_1's rmse: 0.0931516\n",
      "[950]\ttraining's rmse: 0.0885908\tvalid_1's rmse: 0.0931455\n",
      "[975]\ttraining's rmse: 0.088561\tvalid_1's rmse: 0.0931395\n",
      "[1000]\ttraining's rmse: 0.0885337\tvalid_1's rmse: 0.0931346\n",
      "[1025]\ttraining's rmse: 0.0885019\tvalid_1's rmse: 0.0931303\n",
      "[1050]\ttraining's rmse: 0.0884768\tvalid_1's rmse: 0.0931259\n",
      "[1075]\ttraining's rmse: 0.0884518\tvalid_1's rmse: 0.0931218\n",
      "[1100]\ttraining's rmse: 0.0884293\tvalid_1's rmse: 0.0931175\n",
      "[1125]\ttraining's rmse: 0.0884058\tvalid_1's rmse: 0.0931139\n",
      "[1150]\ttraining's rmse: 0.088384\tvalid_1's rmse: 0.0931101\n",
      "[1175]\ttraining's rmse: 0.088363\tvalid_1's rmse: 0.0931074\n",
      "[1200]\ttraining's rmse: 0.0883428\tvalid_1's rmse: 0.0931037\n",
      "[1225]\ttraining's rmse: 0.0883238\tvalid_1's rmse: 0.0931015\n",
      "[1250]\ttraining's rmse: 0.0883056\tvalid_1's rmse: 0.0930989\n",
      "[1275]\ttraining's rmse: 0.0882856\tvalid_1's rmse: 0.093097\n",
      "[1300]\ttraining's rmse: 0.0882715\tvalid_1's rmse: 0.0930943\n",
      "[1325]\ttraining's rmse: 0.0882553\tvalid_1's rmse: 0.0930932\n",
      "[1350]\ttraining's rmse: 0.0882386\tvalid_1's rmse: 0.0930911\n",
      "[1375]\ttraining's rmse: 0.0882205\tvalid_1's rmse: 0.0930892\n",
      "[1400]\ttraining's rmse: 0.0882065\tvalid_1's rmse: 0.0930872\n",
      "[1425]\ttraining's rmse: 0.0881922\tvalid_1's rmse: 0.0930847\n",
      "[1450]\ttraining's rmse: 0.0881743\tvalid_1's rmse: 0.093083\n",
      "[1475]\ttraining's rmse: 0.0881607\tvalid_1's rmse: 0.0930813\n",
      "[1500]\ttraining's rmse: 0.0881481\tvalid_1's rmse: 0.09308\n",
      "[1525]\ttraining's rmse: 0.088136\tvalid_1's rmse: 0.093079\n",
      "[1550]\ttraining's rmse: 0.0881229\tvalid_1's rmse: 0.0930781\n",
      "[1575]\ttraining's rmse: 0.0881123\tvalid_1's rmse: 0.0930769\n",
      "[1600]\ttraining's rmse: 0.0881026\tvalid_1's rmse: 0.0930763\n",
      "[1625]\ttraining's rmse: 0.0880927\tvalid_1's rmse: 0.0930748\n",
      "[1650]\ttraining's rmse: 0.088084\tvalid_1's rmse: 0.093074\n",
      "[1675]\ttraining's rmse: 0.0880769\tvalid_1's rmse: 0.0930727\n",
      "[1700]\ttraining's rmse: 0.0880678\tvalid_1's rmse: 0.0930715\n",
      "[1725]\ttraining's rmse: 0.0880576\tvalid_1's rmse: 0.0930705\n",
      "[1750]\ttraining's rmse: 0.0880475\tvalid_1's rmse: 0.0930697\n",
      "[1775]\ttraining's rmse: 0.088039\tvalid_1's rmse: 0.0930692\n",
      "[1800]\ttraining's rmse: 0.0880315\tvalid_1's rmse: 0.0930688\n",
      "[1825]\ttraining's rmse: 0.0880215\tvalid_1's rmse: 0.0930688\n",
      "[1850]\ttraining's rmse: 0.0880131\tvalid_1's rmse: 0.0930676\n",
      "[1875]\ttraining's rmse: 0.0880054\tvalid_1's rmse: 0.0930673\n",
      "[1900]\ttraining's rmse: 0.0879981\tvalid_1's rmse: 0.0930672\n",
      "[1925]\ttraining's rmse: 0.0879934\tvalid_1's rmse: 0.0930675\n",
      "[1950]\ttraining's rmse: 0.0879881\tvalid_1's rmse: 0.0930673\n",
      "Early stopping, best iteration is:\n",
      "[1901]\ttraining's rmse: 0.0879977\tvalid_1's rmse: 0.093067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0936243\tvalid_1's rmse: 0.0897048\n",
      "[50]\ttraining's rmse: 0.0934882\tvalid_1's rmse: 0.0896575\n",
      "[75]\ttraining's rmse: 0.0933422\tvalid_1's rmse: 0.0896084\n",
      "[100]\ttraining's rmse: 0.0932108\tvalid_1's rmse: 0.089565\n",
      "[125]\ttraining's rmse: 0.0930743\tvalid_1's rmse: 0.0895186\n",
      "[150]\ttraining's rmse: 0.0929475\tvalid_1's rmse: 0.0894798\n",
      "[175]\ttraining's rmse: 0.0928437\tvalid_1's rmse: 0.0894496\n",
      "[200]\ttraining's rmse: 0.0927312\tvalid_1's rmse: 0.0894155\n",
      "[225]\ttraining's rmse: 0.0926214\tvalid_1's rmse: 0.0893827\n",
      "[250]\ttraining's rmse: 0.0925271\tvalid_1's rmse: 0.0893576\n",
      "[275]\ttraining's rmse: 0.0924449\tvalid_1's rmse: 0.089333\n",
      "[300]\ttraining's rmse: 0.0923583\tvalid_1's rmse: 0.0893084\n",
      "[325]\ttraining's rmse: 0.0922721\tvalid_1's rmse: 0.0892876\n",
      "[350]\ttraining's rmse: 0.0921868\tvalid_1's rmse: 0.0892663\n",
      "[375]\ttraining's rmse: 0.0921148\tvalid_1's rmse: 0.0892515\n",
      "[400]\ttraining's rmse: 0.0920378\tvalid_1's rmse: 0.0892335\n",
      "[425]\ttraining's rmse: 0.0919682\tvalid_1's rmse: 0.0892211\n",
      "[450]\ttraining's rmse: 0.0919026\tvalid_1's rmse: 0.089205\n",
      "[475]\ttraining's rmse: 0.091842\tvalid_1's rmse: 0.0891927\n",
      "[500]\ttraining's rmse: 0.0917931\tvalid_1's rmse: 0.0891804\n",
      "[525]\ttraining's rmse: 0.0917268\tvalid_1's rmse: 0.0891723\n",
      "[550]\ttraining's rmse: 0.0916694\tvalid_1's rmse: 0.0891609\n",
      "[575]\ttraining's rmse: 0.091614\tvalid_1's rmse: 0.0891507\n",
      "[600]\ttraining's rmse: 0.0915603\tvalid_1's rmse: 0.0891434\n",
      "[625]\ttraining's rmse: 0.0915162\tvalid_1's rmse: 0.0891339\n",
      "[650]\ttraining's rmse: 0.0914622\tvalid_1's rmse: 0.0891302\n",
      "[675]\ttraining's rmse: 0.0914077\tvalid_1's rmse: 0.0891271\n",
      "[700]\ttraining's rmse: 0.0913614\tvalid_1's rmse: 0.0891201\n",
      "[725]\ttraining's rmse: 0.0913183\tvalid_1's rmse: 0.0891209\n",
      "[750]\ttraining's rmse: 0.0912786\tvalid_1's rmse: 0.0891263\n",
      "[775]\ttraining's rmse: 0.0912424\tvalid_1's rmse: 0.0891205\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0912998\tvalid_1's rmse: 0.0891182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0901343\tvalid_1's rmse: 0.0927294\n",
      "[50]\ttraining's rmse: 0.0899798\tvalid_1's rmse: 0.0926719\n",
      "[75]\ttraining's rmse: 0.0898248\tvalid_1's rmse: 0.0926174\n",
      "[100]\ttraining's rmse: 0.0896789\tvalid_1's rmse: 0.0925692\n",
      "[125]\ttraining's rmse: 0.0895366\tvalid_1's rmse: 0.0925193\n",
      "[150]\ttraining's rmse: 0.0894052\tvalid_1's rmse: 0.0924733\n",
      "[175]\ttraining's rmse: 0.0892944\tvalid_1's rmse: 0.0924344\n",
      "[200]\ttraining's rmse: 0.0891786\tvalid_1's rmse: 0.0923956\n",
      "[225]\ttraining's rmse: 0.0890667\tvalid_1's rmse: 0.0923592\n",
      "[250]\ttraining's rmse: 0.0889708\tvalid_1's rmse: 0.0923235\n",
      "[275]\ttraining's rmse: 0.0888795\tvalid_1's rmse: 0.0922923\n",
      "[300]\ttraining's rmse: 0.0887875\tvalid_1's rmse: 0.0922629\n",
      "[325]\ttraining's rmse: 0.0886984\tvalid_1's rmse: 0.0922362\n",
      "[350]\ttraining's rmse: 0.0886128\tvalid_1's rmse: 0.0922071\n",
      "[375]\ttraining's rmse: 0.0885379\tvalid_1's rmse: 0.0921837\n",
      "[400]\ttraining's rmse: 0.0884587\tvalid_1's rmse: 0.092162\n",
      "[425]\ttraining's rmse: 0.0883888\tvalid_1's rmse: 0.0921399\n",
      "[450]\ttraining's rmse: 0.0883251\tvalid_1's rmse: 0.0921174\n",
      "[475]\ttraining's rmse: 0.0882641\tvalid_1's rmse: 0.0920979\n",
      "[500]\ttraining's rmse: 0.088212\tvalid_1's rmse: 0.0920792\n",
      "[525]\ttraining's rmse: 0.0881484\tvalid_1's rmse: 0.0920627\n",
      "[550]\ttraining's rmse: 0.0880929\tvalid_1's rmse: 0.0920479\n",
      "[575]\ttraining's rmse: 0.0880391\tvalid_1's rmse: 0.0920338\n",
      "[600]\ttraining's rmse: 0.087987\tvalid_1's rmse: 0.0920197\n",
      "[625]\ttraining's rmse: 0.0879431\tvalid_1's rmse: 0.0920081\n",
      "[650]\ttraining's rmse: 0.0878911\tvalid_1's rmse: 0.0919939\n",
      "[675]\ttraining's rmse: 0.0878448\tvalid_1's rmse: 0.0919834\n",
      "[700]\ttraining's rmse: 0.0877997\tvalid_1's rmse: 0.0919697\n",
      "[725]\ttraining's rmse: 0.0877576\tvalid_1's rmse: 0.0919609\n",
      "[750]\ttraining's rmse: 0.0877198\tvalid_1's rmse: 0.0919512\n",
      "[775]\ttraining's rmse: 0.0876887\tvalid_1's rmse: 0.0919399\n",
      "[800]\ttraining's rmse: 0.0876481\tvalid_1's rmse: 0.0919303\n",
      "[825]\ttraining's rmse: 0.0876128\tvalid_1's rmse: 0.0919214\n",
      "[850]\ttraining's rmse: 0.0875791\tvalid_1's rmse: 0.0919148\n",
      "[875]\ttraining's rmse: 0.0875489\tvalid_1's rmse: 0.0919073\n",
      "[900]\ttraining's rmse: 0.087515\tvalid_1's rmse: 0.0918994\n",
      "[925]\ttraining's rmse: 0.0874853\tvalid_1's rmse: 0.0918909\n",
      "[950]\ttraining's rmse: 0.0874564\tvalid_1's rmse: 0.091884\n",
      "[975]\ttraining's rmse: 0.0874294\tvalid_1's rmse: 0.0918776\n",
      "[1000]\ttraining's rmse: 0.0874019\tvalid_1's rmse: 0.0918717\n",
      "[1025]\ttraining's rmse: 0.0873791\tvalid_1's rmse: 0.0918649\n",
      "[1050]\ttraining's rmse: 0.0873553\tvalid_1's rmse: 0.0918587\n",
      "[1075]\ttraining's rmse: 0.0873322\tvalid_1's rmse: 0.0918549\n",
      "[1100]\ttraining's rmse: 0.087311\tvalid_1's rmse: 0.0918486\n",
      "[1125]\ttraining's rmse: 0.0872902\tvalid_1's rmse: 0.0918419\n",
      "[1150]\ttraining's rmse: 0.0872668\tvalid_1's rmse: 0.0918367\n",
      "[1175]\ttraining's rmse: 0.0872453\tvalid_1's rmse: 0.091832\n",
      "[1200]\ttraining's rmse: 0.0872256\tvalid_1's rmse: 0.0918263\n",
      "[1225]\ttraining's rmse: 0.0872066\tvalid_1's rmse: 0.0918212\n",
      "[1250]\ttraining's rmse: 0.087189\tvalid_1's rmse: 0.0918175\n",
      "[1275]\ttraining's rmse: 0.087169\tvalid_1's rmse: 0.0918127\n",
      "[1300]\ttraining's rmse: 0.0871547\tvalid_1's rmse: 0.0918091\n",
      "[1325]\ttraining's rmse: 0.0871388\tvalid_1's rmse: 0.0918047\n",
      "[1350]\ttraining's rmse: 0.0871231\tvalid_1's rmse: 0.0918015\n",
      "[1375]\ttraining's rmse: 0.0871095\tvalid_1's rmse: 0.0917983\n",
      "[1400]\ttraining's rmse: 0.0870979\tvalid_1's rmse: 0.0917946\n",
      "[1425]\ttraining's rmse: 0.0870816\tvalid_1's rmse: 0.0917915\n",
      "[1450]\ttraining's rmse: 0.0870665\tvalid_1's rmse: 0.0917892\n",
      "[1475]\ttraining's rmse: 0.0870525\tvalid_1's rmse: 0.0917846\n",
      "[1500]\ttraining's rmse: 0.0870423\tvalid_1's rmse: 0.0917809\n",
      "[1525]\ttraining's rmse: 0.0870311\tvalid_1's rmse: 0.0917772\n",
      "[1550]\ttraining's rmse: 0.0870204\tvalid_1's rmse: 0.0917751\n",
      "[1575]\ttraining's rmse: 0.0870103\tvalid_1's rmse: 0.0917716\n",
      "[1600]\ttraining's rmse: 0.0869981\tvalid_1's rmse: 0.0917682\n",
      "[1625]\ttraining's rmse: 0.0869882\tvalid_1's rmse: 0.0917662\n",
      "[1650]\ttraining's rmse: 0.0869778\tvalid_1's rmse: 0.091764\n",
      "[1675]\ttraining's rmse: 0.0869713\tvalid_1's rmse: 0.0917622\n",
      "[1700]\ttraining's rmse: 0.0869628\tvalid_1's rmse: 0.0917597\n",
      "[1725]\ttraining's rmse: 0.0869548\tvalid_1's rmse: 0.0917576\n",
      "[1750]\ttraining's rmse: 0.0869464\tvalid_1's rmse: 0.0917556\n",
      "[1775]\ttraining's rmse: 0.0869379\tvalid_1's rmse: 0.0917532\n",
      "[1800]\ttraining's rmse: 0.0869299\tvalid_1's rmse: 0.0917506\n",
      "[1825]\ttraining's rmse: 0.0869241\tvalid_1's rmse: 0.0917487\n",
      "[1850]\ttraining's rmse: 0.0869173\tvalid_1's rmse: 0.0917456\n",
      "[1875]\ttraining's rmse: 0.0869107\tvalid_1's rmse: 0.0917446\n",
      "[1900]\ttraining's rmse: 0.0869057\tvalid_1's rmse: 0.0917432\n",
      "[1925]\ttraining's rmse: 0.0868999\tvalid_1's rmse: 0.0917412\n",
      "[1950]\ttraining's rmse: 0.0868951\tvalid_1's rmse: 0.0917388\n",
      "[1975]\ttraining's rmse: 0.0868911\tvalid_1's rmse: 0.0917376\n",
      "[2000]\ttraining's rmse: 0.0868849\tvalid_1's rmse: 0.0917366\n",
      "[2025]\ttraining's rmse: 0.0868799\tvalid_1's rmse: 0.0917352\n",
      "[2050]\ttraining's rmse: 0.0868766\tvalid_1's rmse: 0.0917335\n",
      "[2075]\ttraining's rmse: 0.0868728\tvalid_1's rmse: 0.0917317\n",
      "[2100]\ttraining's rmse: 0.0868685\tvalid_1's rmse: 0.09173\n",
      "[2125]\ttraining's rmse: 0.0868648\tvalid_1's rmse: 0.0917293\n",
      "[2150]\ttraining's rmse: 0.0868606\tvalid_1's rmse: 0.0917286\n",
      "[2175]\ttraining's rmse: 0.0868571\tvalid_1's rmse: 0.0917272\n",
      "[2200]\ttraining's rmse: 0.0868536\tvalid_1's rmse: 0.0917266\n",
      "[2225]\ttraining's rmse: 0.0868494\tvalid_1's rmse: 0.0917252\n",
      "[2250]\ttraining's rmse: 0.0868461\tvalid_1's rmse: 0.0917245\n",
      "[2275]\ttraining's rmse: 0.0868421\tvalid_1's rmse: 0.0917231\n",
      "[2300]\ttraining's rmse: 0.0868393\tvalid_1's rmse: 0.0917226\n",
      "[2325]\ttraining's rmse: 0.0868354\tvalid_1's rmse: 0.0917206\n",
      "[2350]\ttraining's rmse: 0.0868324\tvalid_1's rmse: 0.0917198\n",
      "[2375]\ttraining's rmse: 0.0868291\tvalid_1's rmse: 0.0917194\n",
      "[2400]\ttraining's rmse: 0.0868243\tvalid_1's rmse: 0.0917182\n",
      "[2425]\ttraining's rmse: 0.0868213\tvalid_1's rmse: 0.0917174\n",
      "[2450]\ttraining's rmse: 0.0868184\tvalid_1's rmse: 0.0917169\n",
      "[2475]\ttraining's rmse: 0.0868156\tvalid_1's rmse: 0.0917166\n",
      "[2500]\ttraining's rmse: 0.0868115\tvalid_1's rmse: 0.0917165\n",
      "[2525]\ttraining's rmse: 0.0868087\tvalid_1's rmse: 0.0917157\n",
      "[2550]\ttraining's rmse: 0.0868061\tvalid_1's rmse: 0.0917154\n",
      "[2575]\ttraining's rmse: 0.0868049\tvalid_1's rmse: 0.0917155\n",
      "[2600]\ttraining's rmse: 0.0868024\tvalid_1's rmse: 0.0917149\n",
      "[2625]\ttraining's rmse: 0.0868009\tvalid_1's rmse: 0.0917146\n",
      "[2650]\ttraining's rmse: 0.0867976\tvalid_1's rmse: 0.0917142\n",
      "[2675]\ttraining's rmse: 0.0867952\tvalid_1's rmse: 0.0917129\n",
      "[2700]\ttraining's rmse: 0.0867925\tvalid_1's rmse: 0.0917119\n",
      "[2725]\ttraining's rmse: 0.0867902\tvalid_1's rmse: 0.0917122\n",
      "[2750]\ttraining's rmse: 0.0867885\tvalid_1's rmse: 0.0917123\n",
      "Early stopping, best iteration is:\n",
      "[2714]\ttraining's rmse: 0.0867918\tvalid_1's rmse: 0.0917119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.090096\tvalid_1's rmse: 0.0928179\n",
      "[50]\ttraining's rmse: 0.0899581\tvalid_1's rmse: 0.0927609\n",
      "[75]\ttraining's rmse: 0.0898161\tvalid_1's rmse: 0.0927054\n",
      "[100]\ttraining's rmse: 0.0896914\tvalid_1's rmse: 0.0926564\n",
      "[125]\ttraining's rmse: 0.0895628\tvalid_1's rmse: 0.0926078\n",
      "[150]\ttraining's rmse: 0.089444\tvalid_1's rmse: 0.0925628\n",
      "[175]\ttraining's rmse: 0.0893408\tvalid_1's rmse: 0.0925237\n",
      "[200]\ttraining's rmse: 0.0892336\tvalid_1's rmse: 0.0924859\n",
      "[225]\ttraining's rmse: 0.0891316\tvalid_1's rmse: 0.0924504\n",
      "[250]\ttraining's rmse: 0.0890435\tvalid_1's rmse: 0.0924182\n",
      "[275]\ttraining's rmse: 0.0889619\tvalid_1's rmse: 0.0923889\n",
      "[300]\ttraining's rmse: 0.0888785\tvalid_1's rmse: 0.0923616\n",
      "[325]\ttraining's rmse: 0.0887934\tvalid_1's rmse: 0.0923341\n",
      "[350]\ttraining's rmse: 0.088714\tvalid_1's rmse: 0.0923087\n",
      "[375]\ttraining's rmse: 0.088649\tvalid_1's rmse: 0.0922874\n",
      "[400]\ttraining's rmse: 0.0885755\tvalid_1's rmse: 0.092266\n",
      "[425]\ttraining's rmse: 0.0885088\tvalid_1's rmse: 0.0922461\n",
      "[450]\ttraining's rmse: 0.0884468\tvalid_1's rmse: 0.0922271\n",
      "[475]\ttraining's rmse: 0.0883883\tvalid_1's rmse: 0.0922087\n",
      "[500]\ttraining's rmse: 0.0883402\tvalid_1's rmse: 0.092192\n",
      "[525]\ttraining's rmse: 0.0882777\tvalid_1's rmse: 0.0921756\n",
      "[550]\ttraining's rmse: 0.0882201\tvalid_1's rmse: 0.0921616\n",
      "[575]\ttraining's rmse: 0.088166\tvalid_1's rmse: 0.0921465\n",
      "[600]\ttraining's rmse: 0.0881151\tvalid_1's rmse: 0.0921328\n",
      "[625]\ttraining's rmse: 0.0880734\tvalid_1's rmse: 0.0921203\n",
      "[650]\ttraining's rmse: 0.0880226\tvalid_1's rmse: 0.092107\n",
      "[675]\ttraining's rmse: 0.0879707\tvalid_1's rmse: 0.0920953\n",
      "[700]\ttraining's rmse: 0.0879253\tvalid_1's rmse: 0.0920844\n",
      "[725]\ttraining's rmse: 0.0878844\tvalid_1's rmse: 0.0920747\n",
      "[750]\ttraining's rmse: 0.0878431\tvalid_1's rmse: 0.0920655\n",
      "[775]\ttraining's rmse: 0.0878087\tvalid_1's rmse: 0.0920557\n",
      "[800]\ttraining's rmse: 0.0877652\tvalid_1's rmse: 0.0920475\n",
      "[825]\ttraining's rmse: 0.0877305\tvalid_1's rmse: 0.0920394\n",
      "[850]\ttraining's rmse: 0.0876957\tvalid_1's rmse: 0.0920334\n",
      "[875]\ttraining's rmse: 0.0876651\tvalid_1's rmse: 0.0920279\n",
      "[900]\ttraining's rmse: 0.0876314\tvalid_1's rmse: 0.0920208\n",
      "[925]\ttraining's rmse: 0.0876005\tvalid_1's rmse: 0.0920149\n",
      "[950]\ttraining's rmse: 0.0875702\tvalid_1's rmse: 0.0920091\n",
      "[975]\ttraining's rmse: 0.0875424\tvalid_1's rmse: 0.0920039\n",
      "[1000]\ttraining's rmse: 0.0875176\tvalid_1's rmse: 0.0919995\n",
      "[1025]\ttraining's rmse: 0.0874883\tvalid_1's rmse: 0.0919952\n",
      "[1050]\ttraining's rmse: 0.0874633\tvalid_1's rmse: 0.0919901\n",
      "[1075]\ttraining's rmse: 0.0874382\tvalid_1's rmse: 0.0919871\n",
      "[1100]\ttraining's rmse: 0.0874178\tvalid_1's rmse: 0.0919832\n",
      "[1125]\ttraining's rmse: 0.0873972\tvalid_1's rmse: 0.0919805\n",
      "[1150]\ttraining's rmse: 0.0873765\tvalid_1's rmse: 0.0919765\n",
      "[1175]\ttraining's rmse: 0.0873577\tvalid_1's rmse: 0.0919743\n",
      "[1200]\ttraining's rmse: 0.0873395\tvalid_1's rmse: 0.0919714\n",
      "[1225]\ttraining's rmse: 0.0873226\tvalid_1's rmse: 0.0919691\n",
      "[1250]\ttraining's rmse: 0.0873066\tvalid_1's rmse: 0.0919663\n",
      "[1275]\ttraining's rmse: 0.0872906\tvalid_1's rmse: 0.0919649\n",
      "[1300]\ttraining's rmse: 0.0872737\tvalid_1's rmse: 0.0919629\n",
      "[1325]\ttraining's rmse: 0.0872571\tvalid_1's rmse: 0.0919607\n",
      "[1350]\ttraining's rmse: 0.0872401\tvalid_1's rmse: 0.0919591\n",
      "[1375]\ttraining's rmse: 0.0872244\tvalid_1's rmse: 0.0919574\n",
      "[1400]\ttraining's rmse: 0.0872115\tvalid_1's rmse: 0.0919557\n",
      "[1425]\ttraining's rmse: 0.0871974\tvalid_1's rmse: 0.0919545\n",
      "[1450]\ttraining's rmse: 0.0871792\tvalid_1's rmse: 0.0919527\n",
      "[1475]\ttraining's rmse: 0.087166\tvalid_1's rmse: 0.0919504\n",
      "[1500]\ttraining's rmse: 0.0871545\tvalid_1's rmse: 0.0919493\n",
      "[1525]\ttraining's rmse: 0.0871418\tvalid_1's rmse: 0.0919483\n",
      "[1550]\ttraining's rmse: 0.0871307\tvalid_1's rmse: 0.0919477\n",
      "[1575]\ttraining's rmse: 0.0871195\tvalid_1's rmse: 0.091946\n",
      "[1600]\ttraining's rmse: 0.0871086\tvalid_1's rmse: 0.0919454\n",
      "[1625]\ttraining's rmse: 0.0870977\tvalid_1's rmse: 0.0919445\n",
      "[1650]\ttraining's rmse: 0.0870885\tvalid_1's rmse: 0.0919438\n",
      "[1675]\ttraining's rmse: 0.0870807\tvalid_1's rmse: 0.0919424\n",
      "[1700]\ttraining's rmse: 0.0870717\tvalid_1's rmse: 0.0919414\n",
      "[1725]\ttraining's rmse: 0.087065\tvalid_1's rmse: 0.0919399\n",
      "[1750]\ttraining's rmse: 0.0870547\tvalid_1's rmse: 0.0919395\n",
      "[1775]\ttraining's rmse: 0.087047\tvalid_1's rmse: 0.0919388\n",
      "[1800]\ttraining's rmse: 0.0870402\tvalid_1's rmse: 0.0919385\n",
      "[1825]\ttraining's rmse: 0.0870332\tvalid_1's rmse: 0.091938\n",
      "[1850]\ttraining's rmse: 0.0870252\tvalid_1's rmse: 0.091937\n",
      "[1875]\ttraining's rmse: 0.087018\tvalid_1's rmse: 0.0919371\n",
      "[1900]\ttraining's rmse: 0.0870128\tvalid_1's rmse: 0.0919373\n",
      "Early stopping, best iteration is:\n",
      "[1854]\ttraining's rmse: 0.0870244\tvalid_1's rmse: 0.0919369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0926346\tvalid_1's rmse: 0.0876694\n",
      "[50]\ttraining's rmse: 0.0925012\tvalid_1's rmse: 0.087626\n",
      "[75]\ttraining's rmse: 0.0923655\tvalid_1's rmse: 0.087575\n",
      "[100]\ttraining's rmse: 0.0922425\tvalid_1's rmse: 0.0875321\n",
      "[125]\ttraining's rmse: 0.0921134\tvalid_1's rmse: 0.0874892\n",
      "[150]\ttraining's rmse: 0.0919974\tvalid_1's rmse: 0.0874516\n",
      "[175]\ttraining's rmse: 0.0919011\tvalid_1's rmse: 0.0874221\n",
      "[200]\ttraining's rmse: 0.0917956\tvalid_1's rmse: 0.0873907\n",
      "[225]\ttraining's rmse: 0.0916907\tvalid_1's rmse: 0.087357\n",
      "[250]\ttraining's rmse: 0.0916033\tvalid_1's rmse: 0.0873312\n",
      "[275]\ttraining's rmse: 0.0915235\tvalid_1's rmse: 0.087305\n",
      "[300]\ttraining's rmse: 0.0914433\tvalid_1's rmse: 0.0872795\n",
      "[325]\ttraining's rmse: 0.091363\tvalid_1's rmse: 0.0872549\n",
      "[350]\ttraining's rmse: 0.0912841\tvalid_1's rmse: 0.0872311\n",
      "[375]\ttraining's rmse: 0.0912181\tvalid_1's rmse: 0.0872132\n",
      "[400]\ttraining's rmse: 0.0911452\tvalid_1's rmse: 0.0871984\n",
      "[425]\ttraining's rmse: 0.091079\tvalid_1's rmse: 0.0871886\n",
      "[450]\ttraining's rmse: 0.091019\tvalid_1's rmse: 0.087175\n",
      "[475]\ttraining's rmse: 0.0909616\tvalid_1's rmse: 0.08716\n",
      "[500]\ttraining's rmse: 0.0909127\tvalid_1's rmse: 0.0871449\n",
      "[525]\ttraining's rmse: 0.0908497\tvalid_1's rmse: 0.087136\n",
      "[550]\ttraining's rmse: 0.0907934\tvalid_1's rmse: 0.0871223\n",
      "[575]\ttraining's rmse: 0.0907405\tvalid_1's rmse: 0.0871089\n",
      "[600]\ttraining's rmse: 0.090688\tvalid_1's rmse: 0.0871041\n",
      "[625]\ttraining's rmse: 0.090647\tvalid_1's rmse: 0.0870997\n",
      "[650]\ttraining's rmse: 0.0905945\tvalid_1's rmse: 0.0870956\n",
      "[675]\ttraining's rmse: 0.0905445\tvalid_1's rmse: 0.0870932\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttraining's rmse: 0.0905974\tvalid_1's rmse: 0.08709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0923731\tvalid_1's rmse: 0.0944896\n",
      "[50]\ttraining's rmse: 0.0921756\tvalid_1's rmse: 0.0944354\n",
      "[75]\ttraining's rmse: 0.0919814\tvalid_1's rmse: 0.0943791\n",
      "[100]\ttraining's rmse: 0.0918058\tvalid_1's rmse: 0.0943323\n",
      "[125]\ttraining's rmse: 0.0916283\tvalid_1's rmse: 0.0942848\n",
      "[150]\ttraining's rmse: 0.0914669\tvalid_1's rmse: 0.0942404\n",
      "[175]\ttraining's rmse: 0.0913322\tvalid_1's rmse: 0.0942034\n",
      "[200]\ttraining's rmse: 0.0911944\tvalid_1's rmse: 0.0941676\n",
      "[225]\ttraining's rmse: 0.0910568\tvalid_1's rmse: 0.0941297\n",
      "[250]\ttraining's rmse: 0.0909381\tvalid_1's rmse: 0.0940954\n",
      "[275]\ttraining's rmse: 0.0908264\tvalid_1's rmse: 0.0940653\n",
      "[300]\ttraining's rmse: 0.0907153\tvalid_1's rmse: 0.0940354\n",
      "[325]\ttraining's rmse: 0.0906103\tvalid_1's rmse: 0.0940074\n",
      "[350]\ttraining's rmse: 0.090511\tvalid_1's rmse: 0.0939814\n",
      "[375]\ttraining's rmse: 0.0904236\tvalid_1's rmse: 0.0939613\n",
      "[400]\ttraining's rmse: 0.0903298\tvalid_1's rmse: 0.0939383\n",
      "[425]\ttraining's rmse: 0.0902468\tvalid_1's rmse: 0.0939174\n",
      "[450]\ttraining's rmse: 0.0901739\tvalid_1's rmse: 0.0938967\n",
      "[475]\ttraining's rmse: 0.0901046\tvalid_1's rmse: 0.0938771\n",
      "[500]\ttraining's rmse: 0.0900389\tvalid_1's rmse: 0.093858\n",
      "[525]\ttraining's rmse: 0.0899644\tvalid_1's rmse: 0.0938401\n",
      "[550]\ttraining's rmse: 0.0899015\tvalid_1's rmse: 0.0938253\n",
      "[575]\ttraining's rmse: 0.089836\tvalid_1's rmse: 0.0938108\n",
      "[600]\ttraining's rmse: 0.0897769\tvalid_1's rmse: 0.0937952\n",
      "[625]\ttraining's rmse: 0.0897286\tvalid_1's rmse: 0.093782\n",
      "[650]\ttraining's rmse: 0.089675\tvalid_1's rmse: 0.0937689\n",
      "[675]\ttraining's rmse: 0.0896219\tvalid_1's rmse: 0.0937553\n",
      "[700]\ttraining's rmse: 0.0895716\tvalid_1's rmse: 0.0937431\n",
      "[725]\ttraining's rmse: 0.0895233\tvalid_1's rmse: 0.0937334\n",
      "[750]\ttraining's rmse: 0.0894787\tvalid_1's rmse: 0.093723\n",
      "[775]\ttraining's rmse: 0.089442\tvalid_1's rmse: 0.093712\n",
      "[800]\ttraining's rmse: 0.0893992\tvalid_1's rmse: 0.0937015\n",
      "[825]\ttraining's rmse: 0.0893635\tvalid_1's rmse: 0.0936921\n",
      "[850]\ttraining's rmse: 0.0893251\tvalid_1's rmse: 0.0936842\n",
      "[875]\ttraining's rmse: 0.0892928\tvalid_1's rmse: 0.093676\n",
      "[900]\ttraining's rmse: 0.0892566\tvalid_1's rmse: 0.0936676\n",
      "[925]\ttraining's rmse: 0.0892232\tvalid_1's rmse: 0.09366\n",
      "[950]\ttraining's rmse: 0.0891934\tvalid_1's rmse: 0.0936542\n",
      "[975]\ttraining's rmse: 0.0891663\tvalid_1's rmse: 0.0936476\n",
      "[1000]\ttraining's rmse: 0.0891357\tvalid_1's rmse: 0.0936427\n",
      "[1025]\ttraining's rmse: 0.0891053\tvalid_1's rmse: 0.0936354\n",
      "[1050]\ttraining's rmse: 0.0890793\tvalid_1's rmse: 0.0936297\n",
      "[1075]\ttraining's rmse: 0.0890562\tvalid_1's rmse: 0.0936254\n",
      "[1100]\ttraining's rmse: 0.0890309\tvalid_1's rmse: 0.0936208\n",
      "[1125]\ttraining's rmse: 0.0890062\tvalid_1's rmse: 0.0936152\n",
      "[1150]\ttraining's rmse: 0.0889824\tvalid_1's rmse: 0.0936095\n",
      "[1175]\ttraining's rmse: 0.0889614\tvalid_1's rmse: 0.0936054\n",
      "[1200]\ttraining's rmse: 0.0889412\tvalid_1's rmse: 0.0935996\n",
      "[1225]\ttraining's rmse: 0.0889225\tvalid_1's rmse: 0.0935944\n",
      "[1250]\ttraining's rmse: 0.0889055\tvalid_1's rmse: 0.0935895\n",
      "[1275]\ttraining's rmse: 0.0888842\tvalid_1's rmse: 0.0935863\n",
      "[1300]\ttraining's rmse: 0.0888716\tvalid_1's rmse: 0.0935829\n",
      "[1325]\ttraining's rmse: 0.0888557\tvalid_1's rmse: 0.093579\n",
      "[1350]\ttraining's rmse: 0.0888398\tvalid_1's rmse: 0.0935776\n",
      "[1375]\ttraining's rmse: 0.0888257\tvalid_1's rmse: 0.0935745\n",
      "[1400]\ttraining's rmse: 0.0888121\tvalid_1's rmse: 0.0935718\n",
      "[1425]\ttraining's rmse: 0.0887971\tvalid_1's rmse: 0.0935689\n",
      "[1450]\ttraining's rmse: 0.0887817\tvalid_1's rmse: 0.0935661\n",
      "[1475]\ttraining's rmse: 0.0887695\tvalid_1's rmse: 0.0935627\n",
      "[1500]\ttraining's rmse: 0.0887554\tvalid_1's rmse: 0.0935591\n",
      "[1525]\ttraining's rmse: 0.0887407\tvalid_1's rmse: 0.0935543\n",
      "[1550]\ttraining's rmse: 0.0887281\tvalid_1's rmse: 0.0935533\n",
      "[1575]\ttraining's rmse: 0.0887169\tvalid_1's rmse: 0.0935501\n",
      "[1600]\ttraining's rmse: 0.0887076\tvalid_1's rmse: 0.0935479\n",
      "[1625]\ttraining's rmse: 0.0886962\tvalid_1's rmse: 0.093545\n",
      "[1650]\ttraining's rmse: 0.0886869\tvalid_1's rmse: 0.0935419\n",
      "[1675]\ttraining's rmse: 0.0886785\tvalid_1's rmse: 0.0935395\n",
      "[1700]\ttraining's rmse: 0.0886697\tvalid_1's rmse: 0.0935373\n",
      "[1725]\ttraining's rmse: 0.0886611\tvalid_1's rmse: 0.0935351\n",
      "[1750]\ttraining's rmse: 0.0886526\tvalid_1's rmse: 0.0935333\n",
      "[1775]\ttraining's rmse: 0.0886453\tvalid_1's rmse: 0.093532\n",
      "[1800]\ttraining's rmse: 0.0886377\tvalid_1's rmse: 0.0935303\n",
      "[1825]\ttraining's rmse: 0.0886291\tvalid_1's rmse: 0.0935284\n",
      "[1850]\ttraining's rmse: 0.0886226\tvalid_1's rmse: 0.0935265\n",
      "[1875]\ttraining's rmse: 0.088616\tvalid_1's rmse: 0.0935253\n",
      "[1900]\ttraining's rmse: 0.0886099\tvalid_1's rmse: 0.0935241\n",
      "[1925]\ttraining's rmse: 0.0886035\tvalid_1's rmse: 0.0935232\n",
      "[1950]\ttraining's rmse: 0.0885979\tvalid_1's rmse: 0.0935216\n",
      "[1975]\ttraining's rmse: 0.0885914\tvalid_1's rmse: 0.0935191\n",
      "[2000]\ttraining's rmse: 0.0885838\tvalid_1's rmse: 0.093518\n",
      "[2025]\ttraining's rmse: 0.0885797\tvalid_1's rmse: 0.0935169\n",
      "[2050]\ttraining's rmse: 0.088574\tvalid_1's rmse: 0.0935158\n",
      "[2075]\ttraining's rmse: 0.0885694\tvalid_1's rmse: 0.0935143\n",
      "[2100]\ttraining's rmse: 0.0885648\tvalid_1's rmse: 0.0935133\n",
      "[2125]\ttraining's rmse: 0.0885615\tvalid_1's rmse: 0.0935126\n",
      "[2150]\ttraining's rmse: 0.0885552\tvalid_1's rmse: 0.0935105\n",
      "[2175]\ttraining's rmse: 0.0885515\tvalid_1's rmse: 0.0935095\n",
      "[2200]\ttraining's rmse: 0.0885475\tvalid_1's rmse: 0.0935083\n",
      "[2225]\ttraining's rmse: 0.0885421\tvalid_1's rmse: 0.0935076\n",
      "[2250]\ttraining's rmse: 0.0885382\tvalid_1's rmse: 0.0935069\n",
      "[2275]\ttraining's rmse: 0.088532\tvalid_1's rmse: 0.0935063\n",
      "[2300]\ttraining's rmse: 0.0885272\tvalid_1's rmse: 0.093504\n",
      "[2325]\ttraining's rmse: 0.0885232\tvalid_1's rmse: 0.0935036\n",
      "[2350]\ttraining's rmse: 0.0885199\tvalid_1's rmse: 0.0935025\n",
      "[2375]\ttraining's rmse: 0.0885165\tvalid_1's rmse: 0.0935018\n",
      "[2400]\ttraining's rmse: 0.0885126\tvalid_1's rmse: 0.0935014\n",
      "[2425]\ttraining's rmse: 0.088509\tvalid_1's rmse: 0.0935014\n",
      "[2450]\ttraining's rmse: 0.0885064\tvalid_1's rmse: 0.0935003\n",
      "[2475]\ttraining's rmse: 0.0885037\tvalid_1's rmse: 0.0935002\n",
      "[2500]\ttraining's rmse: 0.0885013\tvalid_1's rmse: 0.0934996\n",
      "[2525]\ttraining's rmse: 0.088498\tvalid_1's rmse: 0.0934993\n",
      "[2550]\ttraining's rmse: 0.0884947\tvalid_1's rmse: 0.0934989\n",
      "[2575]\ttraining's rmse: 0.088491\tvalid_1's rmse: 0.0934978\n",
      "[2600]\ttraining's rmse: 0.0884883\tvalid_1's rmse: 0.0934977\n",
      "[2625]\ttraining's rmse: 0.088486\tvalid_1's rmse: 0.0934969\n",
      "[2650]\ttraining's rmse: 0.0884843\tvalid_1's rmse: 0.0934965\n",
      "[2675]\ttraining's rmse: 0.0884819\tvalid_1's rmse: 0.093496\n",
      "[2700]\ttraining's rmse: 0.08848\tvalid_1's rmse: 0.0934949\n",
      "[2725]\ttraining's rmse: 0.0884772\tvalid_1's rmse: 0.0934943\n",
      "[2750]\ttraining's rmse: 0.0884746\tvalid_1's rmse: 0.0934933\n",
      "[2775]\ttraining's rmse: 0.0884726\tvalid_1's rmse: 0.0934933\n",
      "[2800]\ttraining's rmse: 0.0884705\tvalid_1's rmse: 0.093492\n",
      "[2825]\ttraining's rmse: 0.0884684\tvalid_1's rmse: 0.0934911\n",
      "[2850]\ttraining's rmse: 0.0884667\tvalid_1's rmse: 0.0934905\n",
      "[2875]\ttraining's rmse: 0.0884645\tvalid_1's rmse: 0.0934904\n",
      "[2900]\ttraining's rmse: 0.0884632\tvalid_1's rmse: 0.0934901\n",
      "[2925]\ttraining's rmse: 0.0884616\tvalid_1's rmse: 0.0934892\n",
      "[2950]\ttraining's rmse: 0.0884594\tvalid_1's rmse: 0.0934893\n",
      "[2975]\ttraining's rmse: 0.0884577\tvalid_1's rmse: 0.0934888\n",
      "[3000]\ttraining's rmse: 0.0884554\tvalid_1's rmse: 0.0934882\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0884554\tvalid_1's rmse: 0.0934882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0924293\tvalid_1's rmse: 0.0943853\n",
      "[50]\ttraining's rmse: 0.0922521\tvalid_1's rmse: 0.0943284\n",
      "[75]\ttraining's rmse: 0.0920711\tvalid_1's rmse: 0.0942711\n",
      "[100]\ttraining's rmse: 0.0919096\tvalid_1's rmse: 0.0942223\n",
      "[125]\ttraining's rmse: 0.0917427\tvalid_1's rmse: 0.0941726\n",
      "[150]\ttraining's rmse: 0.0915953\tvalid_1's rmse: 0.0941269\n",
      "[175]\ttraining's rmse: 0.0914691\tvalid_1's rmse: 0.0940899\n",
      "[200]\ttraining's rmse: 0.0913344\tvalid_1's rmse: 0.0940527\n",
      "[225]\ttraining's rmse: 0.0912084\tvalid_1's rmse: 0.094018\n",
      "[250]\ttraining's rmse: 0.0910983\tvalid_1's rmse: 0.0939847\n",
      "[275]\ttraining's rmse: 0.0909945\tvalid_1's rmse: 0.093956\n",
      "[300]\ttraining's rmse: 0.0908933\tvalid_1's rmse: 0.0939285\n",
      "[325]\ttraining's rmse: 0.0907921\tvalid_1's rmse: 0.093902\n",
      "[350]\ttraining's rmse: 0.0906966\tvalid_1's rmse: 0.0938773\n",
      "[375]\ttraining's rmse: 0.0906202\tvalid_1's rmse: 0.093856\n",
      "[400]\ttraining's rmse: 0.0905362\tvalid_1's rmse: 0.0938356\n",
      "[425]\ttraining's rmse: 0.0904597\tvalid_1's rmse: 0.0938163\n",
      "[450]\ttraining's rmse: 0.0903865\tvalid_1's rmse: 0.0937984\n",
      "[475]\ttraining's rmse: 0.0903228\tvalid_1's rmse: 0.0937807\n",
      "[500]\ttraining's rmse: 0.0902642\tvalid_1's rmse: 0.0937631\n",
      "[525]\ttraining's rmse: 0.0901937\tvalid_1's rmse: 0.0937454\n",
      "[550]\ttraining's rmse: 0.0901289\tvalid_1's rmse: 0.0937299\n",
      "[575]\ttraining's rmse: 0.0900714\tvalid_1's rmse: 0.093716\n",
      "[600]\ttraining's rmse: 0.0900149\tvalid_1's rmse: 0.0937038\n",
      "[625]\ttraining's rmse: 0.0899642\tvalid_1's rmse: 0.0936917\n",
      "[650]\ttraining's rmse: 0.0899088\tvalid_1's rmse: 0.0936793\n",
      "[675]\ttraining's rmse: 0.0898563\tvalid_1's rmse: 0.093668\n",
      "[700]\ttraining's rmse: 0.089809\tvalid_1's rmse: 0.0936574\n",
      "[725]\ttraining's rmse: 0.0897631\tvalid_1's rmse: 0.0936481\n",
      "[750]\ttraining's rmse: 0.0897221\tvalid_1's rmse: 0.0936389\n",
      "[775]\ttraining's rmse: 0.0896865\tvalid_1's rmse: 0.0936304\n",
      "[800]\ttraining's rmse: 0.0896426\tvalid_1's rmse: 0.0936231\n",
      "[825]\ttraining's rmse: 0.0896069\tvalid_1's rmse: 0.0936159\n",
      "[850]\ttraining's rmse: 0.0895726\tvalid_1's rmse: 0.09361\n",
      "[875]\ttraining's rmse: 0.0895405\tvalid_1's rmse: 0.0936052\n",
      "[900]\ttraining's rmse: 0.0895043\tvalid_1's rmse: 0.0935993\n",
      "[925]\ttraining's rmse: 0.0894717\tvalid_1's rmse: 0.0935942\n",
      "[950]\ttraining's rmse: 0.0894381\tvalid_1's rmse: 0.093589\n",
      "[975]\ttraining's rmse: 0.0894091\tvalid_1's rmse: 0.0935838\n",
      "[1000]\ttraining's rmse: 0.0893822\tvalid_1's rmse: 0.0935795\n",
      "[1025]\ttraining's rmse: 0.0893525\tvalid_1's rmse: 0.0935753\n",
      "[1050]\ttraining's rmse: 0.0893269\tvalid_1's rmse: 0.0935718\n",
      "[1075]\ttraining's rmse: 0.0893003\tvalid_1's rmse: 0.093569\n",
      "[1100]\ttraining's rmse: 0.089279\tvalid_1's rmse: 0.0935654\n",
      "[1125]\ttraining's rmse: 0.0892559\tvalid_1's rmse: 0.0935612\n",
      "[1150]\ttraining's rmse: 0.0892336\tvalid_1's rmse: 0.093558\n",
      "[1175]\ttraining's rmse: 0.089212\tvalid_1's rmse: 0.0935559\n",
      "[1200]\ttraining's rmse: 0.0891942\tvalid_1's rmse: 0.0935536\n",
      "[1225]\ttraining's rmse: 0.0891729\tvalid_1's rmse: 0.0935516\n",
      "[1250]\ttraining's rmse: 0.0891528\tvalid_1's rmse: 0.0935492\n",
      "[1275]\ttraining's rmse: 0.089132\tvalid_1's rmse: 0.0935481\n",
      "[1300]\ttraining's rmse: 0.0891149\tvalid_1's rmse: 0.0935462\n",
      "[1325]\ttraining's rmse: 0.0890994\tvalid_1's rmse: 0.0935439\n",
      "[1350]\ttraining's rmse: 0.0890799\tvalid_1's rmse: 0.0935428\n",
      "[1375]\ttraining's rmse: 0.0890638\tvalid_1's rmse: 0.0935414\n",
      "[1400]\ttraining's rmse: 0.0890496\tvalid_1's rmse: 0.0935396\n",
      "[1425]\ttraining's rmse: 0.0890331\tvalid_1's rmse: 0.0935382\n",
      "[1450]\ttraining's rmse: 0.089018\tvalid_1's rmse: 0.0935379\n",
      "[1475]\ttraining's rmse: 0.0890048\tvalid_1's rmse: 0.0935363\n",
      "[1500]\ttraining's rmse: 0.0889936\tvalid_1's rmse: 0.0935359\n",
      "[1525]\ttraining's rmse: 0.0889787\tvalid_1's rmse: 0.0935347\n",
      "[1550]\ttraining's rmse: 0.088965\tvalid_1's rmse: 0.0935334\n",
      "[1575]\ttraining's rmse: 0.0889535\tvalid_1's rmse: 0.0935328\n",
      "[1600]\ttraining's rmse: 0.0889442\tvalid_1's rmse: 0.0935318\n",
      "[1625]\ttraining's rmse: 0.0889325\tvalid_1's rmse: 0.0935301\n",
      "[1650]\ttraining's rmse: 0.0889212\tvalid_1's rmse: 0.0935293\n",
      "[1675]\ttraining's rmse: 0.0889137\tvalid_1's rmse: 0.0935284\n",
      "[1700]\ttraining's rmse: 0.0889038\tvalid_1's rmse: 0.093528\n",
      "[1725]\ttraining's rmse: 0.088895\tvalid_1's rmse: 0.0935269\n",
      "[1750]\ttraining's rmse: 0.0888838\tvalid_1's rmse: 0.0935262\n",
      "[1775]\ttraining's rmse: 0.0888771\tvalid_1's rmse: 0.0935261\n",
      "[1800]\ttraining's rmse: 0.0888673\tvalid_1's rmse: 0.0935249\n",
      "[1825]\ttraining's rmse: 0.08886\tvalid_1's rmse: 0.0935246\n",
      "[1850]\ttraining's rmse: 0.0888514\tvalid_1's rmse: 0.0935247\n",
      "[1875]\ttraining's rmse: 0.0888469\tvalid_1's rmse: 0.0935245\n",
      "[1900]\ttraining's rmse: 0.0888416\tvalid_1's rmse: 0.0935246\n",
      "Early stopping, best iteration is:\n",
      "[1864]\ttraining's rmse: 0.0888484\tvalid_1's rmse: 0.0935242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0942852\tvalid_1's rmse: 0.0907051\n",
      "[50]\ttraining's rmse: 0.0941449\tvalid_1's rmse: 0.0906541\n",
      "[75]\ttraining's rmse: 0.0939984\tvalid_1's rmse: 0.0906032\n",
      "[100]\ttraining's rmse: 0.0938681\tvalid_1's rmse: 0.0905606\n",
      "[125]\ttraining's rmse: 0.0937302\tvalid_1's rmse: 0.0905174\n",
      "[150]\ttraining's rmse: 0.0936044\tvalid_1's rmse: 0.0904785\n",
      "[175]\ttraining's rmse: 0.0934963\tvalid_1's rmse: 0.0904451\n",
      "[200]\ttraining's rmse: 0.093382\tvalid_1's rmse: 0.0904129\n",
      "[225]\ttraining's rmse: 0.0932711\tvalid_1's rmse: 0.0903802\n",
      "[250]\ttraining's rmse: 0.0931761\tvalid_1's rmse: 0.0903539\n",
      "[275]\ttraining's rmse: 0.0930887\tvalid_1's rmse: 0.090329\n",
      "[300]\ttraining's rmse: 0.0930029\tvalid_1's rmse: 0.090307\n",
      "[325]\ttraining's rmse: 0.0929183\tvalid_1's rmse: 0.0902851\n",
      "[350]\ttraining's rmse: 0.0928343\tvalid_1's rmse: 0.0902618\n",
      "[375]\ttraining's rmse: 0.092763\tvalid_1's rmse: 0.0902436\n",
      "[400]\ttraining's rmse: 0.0926863\tvalid_1's rmse: 0.0902266\n",
      "[425]\ttraining's rmse: 0.0926172\tvalid_1's rmse: 0.0902117\n",
      "[450]\ttraining's rmse: 0.0925499\tvalid_1's rmse: 0.0901994\n",
      "[475]\ttraining's rmse: 0.0924906\tvalid_1's rmse: 0.0901857\n",
      "[500]\ttraining's rmse: 0.09244\tvalid_1's rmse: 0.0901726\n",
      "[525]\ttraining's rmse: 0.092372\tvalid_1's rmse: 0.0901612\n",
      "[550]\ttraining's rmse: 0.0923121\tvalid_1's rmse: 0.090151\n",
      "[575]\ttraining's rmse: 0.0922562\tvalid_1's rmse: 0.090142\n",
      "[600]\ttraining's rmse: 0.0922012\tvalid_1's rmse: 0.090139\n",
      "[625]\ttraining's rmse: 0.092155\tvalid_1's rmse: 0.0901294\n",
      "[650]\ttraining's rmse: 0.0920983\tvalid_1's rmse: 0.0901232\n",
      "[675]\ttraining's rmse: 0.0920422\tvalid_1's rmse: 0.0901264\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttraining's rmse: 0.0921009\tvalid_1's rmse: 0.0901204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0904673\tvalid_1's rmse: 0.0931984\n",
      "[50]\ttraining's rmse: 0.0903122\tvalid_1's rmse: 0.0931384\n",
      "[75]\ttraining's rmse: 0.0901566\tvalid_1's rmse: 0.0930827\n",
      "[100]\ttraining's rmse: 0.0900099\tvalid_1's rmse: 0.0930338\n",
      "[125]\ttraining's rmse: 0.0898636\tvalid_1's rmse: 0.092982\n",
      "[150]\ttraining's rmse: 0.0897334\tvalid_1's rmse: 0.0929357\n",
      "[175]\ttraining's rmse: 0.0896254\tvalid_1's rmse: 0.092897\n",
      "[200]\ttraining's rmse: 0.0895087\tvalid_1's rmse: 0.0928589\n",
      "[225]\ttraining's rmse: 0.0893925\tvalid_1's rmse: 0.0928221\n",
      "[250]\ttraining's rmse: 0.0892966\tvalid_1's rmse: 0.0927887\n",
      "[275]\ttraining's rmse: 0.0892072\tvalid_1's rmse: 0.0927588\n",
      "[300]\ttraining's rmse: 0.0891162\tvalid_1's rmse: 0.0927286\n",
      "[325]\ttraining's rmse: 0.0890243\tvalid_1's rmse: 0.0926999\n",
      "[350]\ttraining's rmse: 0.0889385\tvalid_1's rmse: 0.0926731\n",
      "[375]\ttraining's rmse: 0.0888616\tvalid_1's rmse: 0.0926484\n",
      "[400]\ttraining's rmse: 0.0887815\tvalid_1's rmse: 0.0926269\n",
      "[425]\ttraining's rmse: 0.0887129\tvalid_1's rmse: 0.0926038\n",
      "[450]\ttraining's rmse: 0.0886508\tvalid_1's rmse: 0.0925823\n",
      "[475]\ttraining's rmse: 0.0885873\tvalid_1's rmse: 0.0925625\n",
      "[500]\ttraining's rmse: 0.0885336\tvalid_1's rmse: 0.0925452\n",
      "[525]\ttraining's rmse: 0.0884716\tvalid_1's rmse: 0.0925276\n",
      "[550]\ttraining's rmse: 0.0884163\tvalid_1's rmse: 0.0925107\n",
      "[575]\ttraining's rmse: 0.0883594\tvalid_1's rmse: 0.0924949\n",
      "[600]\ttraining's rmse: 0.0883059\tvalid_1's rmse: 0.0924805\n",
      "[625]\ttraining's rmse: 0.0882638\tvalid_1's rmse: 0.092466\n",
      "[650]\ttraining's rmse: 0.0882142\tvalid_1's rmse: 0.0924531\n",
      "[675]\ttraining's rmse: 0.0881654\tvalid_1's rmse: 0.0924395\n",
      "[700]\ttraining's rmse: 0.0881233\tvalid_1's rmse: 0.0924263\n",
      "[725]\ttraining's rmse: 0.0880811\tvalid_1's rmse: 0.0924154\n",
      "[750]\ttraining's rmse: 0.0880413\tvalid_1's rmse: 0.0924047\n",
      "[775]\ttraining's rmse: 0.0880115\tvalid_1's rmse: 0.0923935\n",
      "[800]\ttraining's rmse: 0.0879725\tvalid_1's rmse: 0.0923843\n",
      "[825]\ttraining's rmse: 0.0879396\tvalid_1's rmse: 0.0923749\n",
      "[850]\ttraining's rmse: 0.0879065\tvalid_1's rmse: 0.0923668\n",
      "[875]\ttraining's rmse: 0.0878767\tvalid_1's rmse: 0.0923585\n",
      "[900]\ttraining's rmse: 0.0878429\tvalid_1's rmse: 0.0923532\n",
      "[925]\ttraining's rmse: 0.0878137\tvalid_1's rmse: 0.0923444\n",
      "[950]\ttraining's rmse: 0.0877831\tvalid_1's rmse: 0.0923375\n",
      "[975]\ttraining's rmse: 0.0877562\tvalid_1's rmse: 0.0923315\n",
      "[1000]\ttraining's rmse: 0.0877279\tvalid_1's rmse: 0.0923252\n",
      "[1025]\ttraining's rmse: 0.087701\tvalid_1's rmse: 0.0923197\n",
      "[1050]\ttraining's rmse: 0.0876766\tvalid_1's rmse: 0.0923117\n",
      "[1075]\ttraining's rmse: 0.0876537\tvalid_1's rmse: 0.0923065\n",
      "[1100]\ttraining's rmse: 0.087634\tvalid_1's rmse: 0.0923007\n",
      "[1125]\ttraining's rmse: 0.0876135\tvalid_1's rmse: 0.0922956\n",
      "[1150]\ttraining's rmse: 0.0875931\tvalid_1's rmse: 0.0922903\n",
      "[1175]\ttraining's rmse: 0.0875707\tvalid_1's rmse: 0.0922865\n",
      "[1200]\ttraining's rmse: 0.0875545\tvalid_1's rmse: 0.0922813\n",
      "[1225]\ttraining's rmse: 0.0875363\tvalid_1's rmse: 0.0922766\n",
      "[1250]\ttraining's rmse: 0.0875186\tvalid_1's rmse: 0.0922719\n",
      "[1275]\ttraining's rmse: 0.0874989\tvalid_1's rmse: 0.0922675\n",
      "[1300]\ttraining's rmse: 0.0874827\tvalid_1's rmse: 0.0922633\n",
      "[1325]\ttraining's rmse: 0.0874664\tvalid_1's rmse: 0.0922597\n",
      "[1350]\ttraining's rmse: 0.0874507\tvalid_1's rmse: 0.0922566\n",
      "[1375]\ttraining's rmse: 0.087437\tvalid_1's rmse: 0.0922537\n",
      "[1400]\ttraining's rmse: 0.0874201\tvalid_1's rmse: 0.0922499\n",
      "[1425]\ttraining's rmse: 0.087405\tvalid_1's rmse: 0.0922472\n",
      "[1450]\ttraining's rmse: 0.0873896\tvalid_1's rmse: 0.0922439\n",
      "[1475]\ttraining's rmse: 0.0873766\tvalid_1's rmse: 0.0922401\n",
      "[1500]\ttraining's rmse: 0.087364\tvalid_1's rmse: 0.0922373\n",
      "[1525]\ttraining's rmse: 0.0873512\tvalid_1's rmse: 0.0922349\n",
      "[1550]\ttraining's rmse: 0.0873381\tvalid_1's rmse: 0.0922331\n",
      "[1575]\ttraining's rmse: 0.0873298\tvalid_1's rmse: 0.0922307\n",
      "[1600]\ttraining's rmse: 0.0873205\tvalid_1's rmse: 0.0922287\n",
      "[1625]\ttraining's rmse: 0.0873116\tvalid_1's rmse: 0.0922262\n",
      "[1650]\ttraining's rmse: 0.0873008\tvalid_1's rmse: 0.0922231\n",
      "[1675]\ttraining's rmse: 0.0872938\tvalid_1's rmse: 0.0922215\n",
      "[1700]\ttraining's rmse: 0.0872857\tvalid_1's rmse: 0.0922185\n",
      "[1725]\ttraining's rmse: 0.0872798\tvalid_1's rmse: 0.0922169\n",
      "[1750]\ttraining's rmse: 0.0872733\tvalid_1's rmse: 0.0922144\n",
      "[1775]\ttraining's rmse: 0.0872668\tvalid_1's rmse: 0.0922135\n",
      "[1800]\ttraining's rmse: 0.0872594\tvalid_1's rmse: 0.0922109\n",
      "[1825]\ttraining's rmse: 0.0872537\tvalid_1's rmse: 0.0922094\n",
      "[1850]\ttraining's rmse: 0.0872479\tvalid_1's rmse: 0.0922072\n",
      "[1875]\ttraining's rmse: 0.0872401\tvalid_1's rmse: 0.0922055\n",
      "[1900]\ttraining's rmse: 0.0872354\tvalid_1's rmse: 0.0922041\n",
      "[1925]\ttraining's rmse: 0.0872301\tvalid_1's rmse: 0.0922022\n",
      "[1950]\ttraining's rmse: 0.0872255\tvalid_1's rmse: 0.0921998\n",
      "[1975]\ttraining's rmse: 0.0872208\tvalid_1's rmse: 0.0921975\n",
      "[2000]\ttraining's rmse: 0.0872158\tvalid_1's rmse: 0.0921959\n",
      "[2025]\ttraining's rmse: 0.0872106\tvalid_1's rmse: 0.0921944\n",
      "[2050]\ttraining's rmse: 0.0872064\tvalid_1's rmse: 0.0921932\n",
      "[2075]\ttraining's rmse: 0.0872025\tvalid_1's rmse: 0.0921917\n",
      "[2100]\ttraining's rmse: 0.0871991\tvalid_1's rmse: 0.0921908\n",
      "[2125]\ttraining's rmse: 0.0871954\tvalid_1's rmse: 0.0921902\n",
      "[2150]\ttraining's rmse: 0.0871906\tvalid_1's rmse: 0.0921896\n",
      "[2175]\ttraining's rmse: 0.087187\tvalid_1's rmse: 0.092189\n",
      "[2200]\ttraining's rmse: 0.087184\tvalid_1's rmse: 0.0921889\n",
      "[2225]\ttraining's rmse: 0.0871795\tvalid_1's rmse: 0.0921881\n",
      "[2250]\ttraining's rmse: 0.0871748\tvalid_1's rmse: 0.0921869\n",
      "[2275]\ttraining's rmse: 0.0871701\tvalid_1's rmse: 0.0921861\n",
      "[2300]\ttraining's rmse: 0.0871654\tvalid_1's rmse: 0.0921859\n",
      "[2325]\ttraining's rmse: 0.0871621\tvalid_1's rmse: 0.0921848\n",
      "[2350]\ttraining's rmse: 0.0871593\tvalid_1's rmse: 0.0921839\n",
      "[2375]\ttraining's rmse: 0.0871543\tvalid_1's rmse: 0.092183\n",
      "[2400]\ttraining's rmse: 0.0871508\tvalid_1's rmse: 0.0921825\n",
      "[2425]\ttraining's rmse: 0.0871482\tvalid_1's rmse: 0.0921823\n",
      "[2450]\ttraining's rmse: 0.0871448\tvalid_1's rmse: 0.0921811\n",
      "[2475]\ttraining's rmse: 0.087141\tvalid_1's rmse: 0.0921804\n",
      "[2500]\ttraining's rmse: 0.0871375\tvalid_1's rmse: 0.0921797\n",
      "[2525]\ttraining's rmse: 0.0871339\tvalid_1's rmse: 0.0921794\n",
      "[2550]\ttraining's rmse: 0.087131\tvalid_1's rmse: 0.0921793\n",
      "[2575]\ttraining's rmse: 0.0871287\tvalid_1's rmse: 0.0921788\n",
      "[2600]\ttraining's rmse: 0.0871257\tvalid_1's rmse: 0.0921781\n",
      "[2625]\ttraining's rmse: 0.0871234\tvalid_1's rmse: 0.0921773\n",
      "[2650]\ttraining's rmse: 0.0871201\tvalid_1's rmse: 0.0921766\n",
      "[2675]\ttraining's rmse: 0.0871169\tvalid_1's rmse: 0.0921753\n",
      "[2700]\ttraining's rmse: 0.0871147\tvalid_1's rmse: 0.0921744\n",
      "[2725]\ttraining's rmse: 0.0871123\tvalid_1's rmse: 0.0921738\n",
      "[2750]\ttraining's rmse: 0.0871103\tvalid_1's rmse: 0.0921734\n",
      "[2775]\ttraining's rmse: 0.0871076\tvalid_1's rmse: 0.0921727\n",
      "[2800]\ttraining's rmse: 0.0871062\tvalid_1's rmse: 0.0921722\n",
      "[2825]\ttraining's rmse: 0.0871041\tvalid_1's rmse: 0.092172\n",
      "[2850]\ttraining's rmse: 0.0871019\tvalid_1's rmse: 0.0921721\n",
      "[2875]\ttraining's rmse: 0.0871006\tvalid_1's rmse: 0.0921717\n",
      "[2900]\ttraining's rmse: 0.0870991\tvalid_1's rmse: 0.0921712\n",
      "[2925]\ttraining's rmse: 0.0870974\tvalid_1's rmse: 0.0921704\n",
      "[2950]\ttraining's rmse: 0.0870955\tvalid_1's rmse: 0.0921701\n",
      "[2975]\ttraining's rmse: 0.0870937\tvalid_1's rmse: 0.0921698\n",
      "[3000]\ttraining's rmse: 0.0870913\tvalid_1's rmse: 0.0921696\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0870913\tvalid_1's rmse: 0.0921696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0905431\tvalid_1's rmse: 0.0930617\n",
      "[50]\ttraining's rmse: 0.0904029\tvalid_1's rmse: 0.0930044\n",
      "[75]\ttraining's rmse: 0.0902589\tvalid_1's rmse: 0.0929488\n",
      "[100]\ttraining's rmse: 0.0901296\tvalid_1's rmse: 0.0928988\n",
      "[125]\ttraining's rmse: 0.0899972\tvalid_1's rmse: 0.0928487\n",
      "[150]\ttraining's rmse: 0.0898765\tvalid_1's rmse: 0.0928024\n",
      "[175]\ttraining's rmse: 0.0897764\tvalid_1's rmse: 0.0927647\n",
      "[200]\ttraining's rmse: 0.0896675\tvalid_1's rmse: 0.0927273\n",
      "[225]\ttraining's rmse: 0.0895645\tvalid_1's rmse: 0.092691\n",
      "[250]\ttraining's rmse: 0.0894739\tvalid_1's rmse: 0.0926586\n",
      "[275]\ttraining's rmse: 0.0893906\tvalid_1's rmse: 0.0926295\n",
      "[300]\ttraining's rmse: 0.0893053\tvalid_1's rmse: 0.0926016\n",
      "[325]\ttraining's rmse: 0.0892216\tvalid_1's rmse: 0.0925735\n",
      "[350]\ttraining's rmse: 0.0891435\tvalid_1's rmse: 0.092548\n",
      "[375]\ttraining's rmse: 0.0890773\tvalid_1's rmse: 0.0925263\n",
      "[400]\ttraining's rmse: 0.0890052\tvalid_1's rmse: 0.0925053\n",
      "[425]\ttraining's rmse: 0.088937\tvalid_1's rmse: 0.0924853\n",
      "[450]\ttraining's rmse: 0.0888746\tvalid_1's rmse: 0.0924662\n",
      "[475]\ttraining's rmse: 0.088816\tvalid_1's rmse: 0.0924487\n",
      "[500]\ttraining's rmse: 0.088766\tvalid_1's rmse: 0.0924319\n",
      "[525]\ttraining's rmse: 0.0887028\tvalid_1's rmse: 0.0924162\n",
      "[550]\ttraining's rmse: 0.0886439\tvalid_1's rmse: 0.0924015\n",
      "[575]\ttraining's rmse: 0.0885897\tvalid_1's rmse: 0.0923865\n",
      "[600]\ttraining's rmse: 0.0885379\tvalid_1's rmse: 0.0923731\n",
      "[625]\ttraining's rmse: 0.0884979\tvalid_1's rmse: 0.0923615\n",
      "[650]\ttraining's rmse: 0.0884461\tvalid_1's rmse: 0.0923481\n",
      "[675]\ttraining's rmse: 0.0883939\tvalid_1's rmse: 0.0923363\n",
      "[700]\ttraining's rmse: 0.0883501\tvalid_1's rmse: 0.0923253\n",
      "[725]\ttraining's rmse: 0.0883061\tvalid_1's rmse: 0.0923154\n",
      "[750]\ttraining's rmse: 0.0882658\tvalid_1's rmse: 0.0923054\n",
      "[775]\ttraining's rmse: 0.0882329\tvalid_1's rmse: 0.0922966\n",
      "[800]\ttraining's rmse: 0.0881898\tvalid_1's rmse: 0.0922886\n",
      "[825]\ttraining's rmse: 0.0881537\tvalid_1's rmse: 0.0922804\n",
      "[850]\ttraining's rmse: 0.0881174\tvalid_1's rmse: 0.092275\n",
      "[875]\ttraining's rmse: 0.088088\tvalid_1's rmse: 0.0922681\n",
      "[900]\ttraining's rmse: 0.0880567\tvalid_1's rmse: 0.0922619\n",
      "[925]\ttraining's rmse: 0.0880254\tvalid_1's rmse: 0.0922565\n",
      "[950]\ttraining's rmse: 0.0879955\tvalid_1's rmse: 0.09225\n",
      "[975]\ttraining's rmse: 0.087969\tvalid_1's rmse: 0.092245\n",
      "[1000]\ttraining's rmse: 0.0879428\tvalid_1's rmse: 0.0922396\n",
      "[1025]\ttraining's rmse: 0.0879126\tvalid_1's rmse: 0.0922348\n",
      "[1050]\ttraining's rmse: 0.0878893\tvalid_1's rmse: 0.0922304\n",
      "[1075]\ttraining's rmse: 0.0878612\tvalid_1's rmse: 0.0922274\n",
      "[1100]\ttraining's rmse: 0.0878406\tvalid_1's rmse: 0.0922244\n",
      "[1125]\ttraining's rmse: 0.0878175\tvalid_1's rmse: 0.09222\n",
      "[1150]\ttraining's rmse: 0.0877948\tvalid_1's rmse: 0.0922166\n",
      "[1175]\ttraining's rmse: 0.0877762\tvalid_1's rmse: 0.092214\n",
      "[1200]\ttraining's rmse: 0.0877572\tvalid_1's rmse: 0.0922112\n",
      "[1225]\ttraining's rmse: 0.0877376\tvalid_1's rmse: 0.0922086\n",
      "[1250]\ttraining's rmse: 0.0877206\tvalid_1's rmse: 0.0922069\n",
      "[1275]\ttraining's rmse: 0.087702\tvalid_1's rmse: 0.0922046\n",
      "[1300]\ttraining's rmse: 0.0876879\tvalid_1's rmse: 0.0922023\n",
      "[1325]\ttraining's rmse: 0.0876716\tvalid_1's rmse: 0.0922002\n",
      "[1350]\ttraining's rmse: 0.0876532\tvalid_1's rmse: 0.0921976\n",
      "[1375]\ttraining's rmse: 0.0876389\tvalid_1's rmse: 0.0921968\n",
      "[1400]\ttraining's rmse: 0.0876257\tvalid_1's rmse: 0.0921947\n",
      "[1425]\ttraining's rmse: 0.0876114\tvalid_1's rmse: 0.0921933\n",
      "[1450]\ttraining's rmse: 0.0875983\tvalid_1's rmse: 0.0921926\n",
      "[1475]\ttraining's rmse: 0.0875841\tvalid_1's rmse: 0.0921904\n",
      "[1500]\ttraining's rmse: 0.0875699\tvalid_1's rmse: 0.0921887\n",
      "[1525]\ttraining's rmse: 0.0875554\tvalid_1's rmse: 0.0921874\n",
      "[1550]\ttraining's rmse: 0.0875448\tvalid_1's rmse: 0.0921868\n",
      "[1575]\ttraining's rmse: 0.0875334\tvalid_1's rmse: 0.0921856\n",
      "[1600]\ttraining's rmse: 0.0875241\tvalid_1's rmse: 0.0921847\n",
      "[1625]\ttraining's rmse: 0.0875154\tvalid_1's rmse: 0.092184\n",
      "[1650]\ttraining's rmse: 0.0875051\tvalid_1's rmse: 0.0921833\n",
      "[1675]\ttraining's rmse: 0.0874982\tvalid_1's rmse: 0.0921818\n",
      "[1700]\ttraining's rmse: 0.0874907\tvalid_1's rmse: 0.0921805\n",
      "[1725]\ttraining's rmse: 0.0874823\tvalid_1's rmse: 0.0921796\n",
      "[1750]\ttraining's rmse: 0.0874742\tvalid_1's rmse: 0.0921792\n",
      "[1775]\ttraining's rmse: 0.0874663\tvalid_1's rmse: 0.0921787\n",
      "[1800]\ttraining's rmse: 0.0874574\tvalid_1's rmse: 0.092178\n",
      "[1825]\ttraining's rmse: 0.0874497\tvalid_1's rmse: 0.0921769\n",
      "[1850]\ttraining's rmse: 0.0874445\tvalid_1's rmse: 0.0921761\n",
      "[1875]\ttraining's rmse: 0.0874388\tvalid_1's rmse: 0.0921758\n",
      "[1900]\ttraining's rmse: 0.0874319\tvalid_1's rmse: 0.0921758\n",
      "[1925]\ttraining's rmse: 0.0874255\tvalid_1's rmse: 0.0921753\n",
      "[1950]\ttraining's rmse: 0.0874207\tvalid_1's rmse: 0.0921749\n",
      "[1975]\ttraining's rmse: 0.0874157\tvalid_1's rmse: 0.0921743\n",
      "[2000]\ttraining's rmse: 0.0874115\tvalid_1's rmse: 0.0921741\n",
      "[2025]\ttraining's rmse: 0.0874055\tvalid_1's rmse: 0.092174\n",
      "[2050]\ttraining's rmse: 0.0874018\tvalid_1's rmse: 0.0921737\n",
      "[2075]\ttraining's rmse: 0.087398\tvalid_1's rmse: 0.0921734\n",
      "[2100]\ttraining's rmse: 0.0873928\tvalid_1's rmse: 0.0921728\n",
      "[2125]\ttraining's rmse: 0.0873894\tvalid_1's rmse: 0.0921726\n",
      "[2150]\ttraining's rmse: 0.0873853\tvalid_1's rmse: 0.0921727\n",
      "Early stopping, best iteration is:\n",
      "[2122]\ttraining's rmse: 0.0873899\tvalid_1's rmse: 0.0921725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0929916\tvalid_1's rmse: 0.0880976\n",
      "[50]\ttraining's rmse: 0.092856\tvalid_1's rmse: 0.0880448\n",
      "[75]\ttraining's rmse: 0.0927219\tvalid_1's rmse: 0.0879941\n",
      "[100]\ttraining's rmse: 0.0925968\tvalid_1's rmse: 0.0879504\n",
      "[125]\ttraining's rmse: 0.0924678\tvalid_1's rmse: 0.0879056\n",
      "[150]\ttraining's rmse: 0.092346\tvalid_1's rmse: 0.0878682\n",
      "[175]\ttraining's rmse: 0.0922479\tvalid_1's rmse: 0.0878362\n",
      "[200]\ttraining's rmse: 0.0921407\tvalid_1's rmse: 0.087805\n",
      "[225]\ttraining's rmse: 0.0920369\tvalid_1's rmse: 0.087774\n",
      "[250]\ttraining's rmse: 0.0919439\tvalid_1's rmse: 0.0877445\n",
      "[275]\ttraining's rmse: 0.0918621\tvalid_1's rmse: 0.0877189\n",
      "[300]\ttraining's rmse: 0.0917788\tvalid_1's rmse: 0.0876969\n",
      "[325]\ttraining's rmse: 0.0916947\tvalid_1's rmse: 0.0876729\n",
      "[350]\ttraining's rmse: 0.0916155\tvalid_1's rmse: 0.0876504\n",
      "[375]\ttraining's rmse: 0.0915476\tvalid_1's rmse: 0.0876328\n",
      "[400]\ttraining's rmse: 0.0914769\tvalid_1's rmse: 0.087614\n",
      "[425]\ttraining's rmse: 0.0914111\tvalid_1's rmse: 0.087604\n",
      "[450]\ttraining's rmse: 0.0913481\tvalid_1's rmse: 0.0875928\n",
      "[475]\ttraining's rmse: 0.0912907\tvalid_1's rmse: 0.0875779\n",
      "[500]\ttraining's rmse: 0.0912406\tvalid_1's rmse: 0.0875716\n",
      "[525]\ttraining's rmse: 0.0911763\tvalid_1's rmse: 0.0875587\n",
      "[550]\ttraining's rmse: 0.0911176\tvalid_1's rmse: 0.0875458\n",
      "[575]\ttraining's rmse: 0.0910663\tvalid_1's rmse: 0.0875351\n",
      "[600]\ttraining's rmse: 0.0910121\tvalid_1's rmse: 0.0875241\n",
      "[625]\ttraining's rmse: 0.0909711\tvalid_1's rmse: 0.087516\n",
      "[650]\ttraining's rmse: 0.0909176\tvalid_1's rmse: 0.0875066\n",
      "[675]\ttraining's rmse: 0.0908648\tvalid_1's rmse: 0.0875006\n",
      "[700]\ttraining's rmse: 0.09082\tvalid_1's rmse: 0.0874915\n",
      "[725]\ttraining's rmse: 0.0907778\tvalid_1's rmse: 0.0875039\n",
      "[750]\ttraining's rmse: 0.090738\tvalid_1's rmse: 0.0875207\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0908126\tvalid_1's rmse: 0.087491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0915036\tvalid_1's rmse: 0.0934599\n",
      "[50]\ttraining's rmse: 0.0913124\tvalid_1's rmse: 0.093405\n",
      "[75]\ttraining's rmse: 0.0911232\tvalid_1's rmse: 0.0933488\n",
      "[100]\ttraining's rmse: 0.0909488\tvalid_1's rmse: 0.0933003\n",
      "[125]\ttraining's rmse: 0.0907763\tvalid_1's rmse: 0.0932533\n",
      "[150]\ttraining's rmse: 0.090617\tvalid_1's rmse: 0.0932061\n",
      "[175]\ttraining's rmse: 0.0904839\tvalid_1's rmse: 0.0931676\n",
      "[200]\ttraining's rmse: 0.0903448\tvalid_1's rmse: 0.0931309\n",
      "[225]\ttraining's rmse: 0.0902099\tvalid_1's rmse: 0.0930936\n",
      "[250]\ttraining's rmse: 0.0900932\tvalid_1's rmse: 0.0930603\n",
      "[275]\ttraining's rmse: 0.0899876\tvalid_1's rmse: 0.0930309\n",
      "[300]\ttraining's rmse: 0.0898833\tvalid_1's rmse: 0.0930016\n",
      "[325]\ttraining's rmse: 0.0897816\tvalid_1's rmse: 0.0929735\n",
      "[350]\ttraining's rmse: 0.0896842\tvalid_1's rmse: 0.0929469\n",
      "[375]\ttraining's rmse: 0.0895981\tvalid_1's rmse: 0.0929237\n",
      "[400]\ttraining's rmse: 0.0895069\tvalid_1's rmse: 0.0929017\n",
      "[425]\ttraining's rmse: 0.0894253\tvalid_1's rmse: 0.0928798\n",
      "[450]\ttraining's rmse: 0.0893513\tvalid_1's rmse: 0.0928593\n",
      "[475]\ttraining's rmse: 0.0892828\tvalid_1's rmse: 0.092841\n",
      "[500]\ttraining's rmse: 0.0892224\tvalid_1's rmse: 0.0928244\n",
      "[525]\ttraining's rmse: 0.0891507\tvalid_1's rmse: 0.0928055\n",
      "[550]\ttraining's rmse: 0.0890852\tvalid_1's rmse: 0.0927892\n",
      "[575]\ttraining's rmse: 0.0890246\tvalid_1's rmse: 0.0927773\n",
      "[600]\ttraining's rmse: 0.0889656\tvalid_1's rmse: 0.092762\n",
      "[625]\ttraining's rmse: 0.0889173\tvalid_1's rmse: 0.0927496\n",
      "[650]\ttraining's rmse: 0.088861\tvalid_1's rmse: 0.0927352\n",
      "[675]\ttraining's rmse: 0.0888072\tvalid_1's rmse: 0.0927233\n",
      "[700]\ttraining's rmse: 0.0887604\tvalid_1's rmse: 0.0927115\n",
      "[725]\ttraining's rmse: 0.0887189\tvalid_1's rmse: 0.0927007\n",
      "[750]\ttraining's rmse: 0.0886765\tvalid_1's rmse: 0.0926915\n",
      "[775]\ttraining's rmse: 0.0886449\tvalid_1's rmse: 0.0926792\n",
      "[800]\ttraining's rmse: 0.0886034\tvalid_1's rmse: 0.0926707\n",
      "[825]\ttraining's rmse: 0.0885689\tvalid_1's rmse: 0.0926602\n",
      "[850]\ttraining's rmse: 0.0885302\tvalid_1's rmse: 0.0926522\n",
      "[875]\ttraining's rmse: 0.0885\tvalid_1's rmse: 0.0926434\n",
      "[900]\ttraining's rmse: 0.0884612\tvalid_1's rmse: 0.0926332\n",
      "[925]\ttraining's rmse: 0.0884279\tvalid_1's rmse: 0.0926254\n",
      "[950]\ttraining's rmse: 0.0883973\tvalid_1's rmse: 0.0926173\n",
      "[975]\ttraining's rmse: 0.0883695\tvalid_1's rmse: 0.0926111\n",
      "[1000]\ttraining's rmse: 0.0883378\tvalid_1's rmse: 0.0926054\n",
      "[1025]\ttraining's rmse: 0.0883058\tvalid_1's rmse: 0.0925994\n",
      "[1050]\ttraining's rmse: 0.0882806\tvalid_1's rmse: 0.092591\n",
      "[1075]\ttraining's rmse: 0.0882544\tvalid_1's rmse: 0.0925859\n",
      "[1100]\ttraining's rmse: 0.0882326\tvalid_1's rmse: 0.0925801\n",
      "[1125]\ttraining's rmse: 0.0882072\tvalid_1's rmse: 0.0925738\n",
      "[1150]\ttraining's rmse: 0.0881849\tvalid_1's rmse: 0.0925681\n",
      "[1175]\ttraining's rmse: 0.0881663\tvalid_1's rmse: 0.0925643\n",
      "[1200]\ttraining's rmse: 0.0881471\tvalid_1's rmse: 0.0925586\n",
      "[1225]\ttraining's rmse: 0.0881291\tvalid_1's rmse: 0.0925542\n",
      "[1250]\ttraining's rmse: 0.0881099\tvalid_1's rmse: 0.0925495\n",
      "[1275]\ttraining's rmse: 0.0880891\tvalid_1's rmse: 0.092546\n",
      "[1300]\ttraining's rmse: 0.0880727\tvalid_1's rmse: 0.092541\n",
      "[1325]\ttraining's rmse: 0.0880575\tvalid_1's rmse: 0.092538\n",
      "[1350]\ttraining's rmse: 0.0880421\tvalid_1's rmse: 0.0925352\n",
      "[1375]\ttraining's rmse: 0.088024\tvalid_1's rmse: 0.0925307\n",
      "[1400]\ttraining's rmse: 0.0880104\tvalid_1's rmse: 0.092526\n",
      "[1425]\ttraining's rmse: 0.0879915\tvalid_1's rmse: 0.0925226\n",
      "[1450]\ttraining's rmse: 0.0879758\tvalid_1's rmse: 0.0925204\n",
      "[1475]\ttraining's rmse: 0.0879609\tvalid_1's rmse: 0.0925165\n",
      "[1500]\ttraining's rmse: 0.087949\tvalid_1's rmse: 0.0925141\n",
      "[1525]\ttraining's rmse: 0.0879348\tvalid_1's rmse: 0.092511\n",
      "[1550]\ttraining's rmse: 0.0879211\tvalid_1's rmse: 0.0925101\n",
      "[1575]\ttraining's rmse: 0.0879105\tvalid_1's rmse: 0.0925068\n",
      "[1600]\ttraining's rmse: 0.0879016\tvalid_1's rmse: 0.0925044\n",
      "[1625]\ttraining's rmse: 0.0878921\tvalid_1's rmse: 0.0925008\n",
      "[1650]\ttraining's rmse: 0.0878816\tvalid_1's rmse: 0.0924975\n",
      "[1675]\ttraining's rmse: 0.0878735\tvalid_1's rmse: 0.0924942\n",
      "[1700]\ttraining's rmse: 0.0878656\tvalid_1's rmse: 0.0924918\n",
      "[1725]\ttraining's rmse: 0.0878581\tvalid_1's rmse: 0.0924891\n",
      "[1750]\ttraining's rmse: 0.0878481\tvalid_1's rmse: 0.0924873\n",
      "[1775]\ttraining's rmse: 0.0878369\tvalid_1's rmse: 0.0924851\n",
      "[1800]\ttraining's rmse: 0.0878295\tvalid_1's rmse: 0.092483\n",
      "[1825]\ttraining's rmse: 0.0878208\tvalid_1's rmse: 0.0924813\n",
      "[1850]\ttraining's rmse: 0.0878153\tvalid_1's rmse: 0.0924799\n",
      "[1875]\ttraining's rmse: 0.0878077\tvalid_1's rmse: 0.0924792\n",
      "[1900]\ttraining's rmse: 0.0878015\tvalid_1's rmse: 0.092478\n",
      "[1925]\ttraining's rmse: 0.0877942\tvalid_1's rmse: 0.0924768\n",
      "[1950]\ttraining's rmse: 0.0877889\tvalid_1's rmse: 0.092475\n",
      "[1975]\ttraining's rmse: 0.0877832\tvalid_1's rmse: 0.0924735\n",
      "[2000]\ttraining's rmse: 0.0877765\tvalid_1's rmse: 0.0924724\n",
      "[2025]\ttraining's rmse: 0.0877713\tvalid_1's rmse: 0.092471\n",
      "[2050]\ttraining's rmse: 0.0877667\tvalid_1's rmse: 0.0924678\n",
      "[2075]\ttraining's rmse: 0.0877618\tvalid_1's rmse: 0.0924653\n",
      "[2100]\ttraining's rmse: 0.0877558\tvalid_1's rmse: 0.0924644\n",
      "[2125]\ttraining's rmse: 0.0877514\tvalid_1's rmse: 0.0924634\n",
      "[2150]\ttraining's rmse: 0.0877447\tvalid_1's rmse: 0.0924624\n",
      "[2175]\ttraining's rmse: 0.0877407\tvalid_1's rmse: 0.0924605\n",
      "[2200]\ttraining's rmse: 0.0877363\tvalid_1's rmse: 0.0924589\n",
      "[2225]\ttraining's rmse: 0.0877325\tvalid_1's rmse: 0.0924589\n",
      "[2250]\ttraining's rmse: 0.0877284\tvalid_1's rmse: 0.0924574\n",
      "[2275]\ttraining's rmse: 0.0877246\tvalid_1's rmse: 0.0924573\n",
      "[2300]\ttraining's rmse: 0.0877206\tvalid_1's rmse: 0.0924559\n",
      "[2325]\ttraining's rmse: 0.0877168\tvalid_1's rmse: 0.0924544\n",
      "[2350]\ttraining's rmse: 0.0877142\tvalid_1's rmse: 0.0924542\n",
      "[2375]\ttraining's rmse: 0.0877099\tvalid_1's rmse: 0.0924536\n",
      "[2400]\ttraining's rmse: 0.0877061\tvalid_1's rmse: 0.0924526\n",
      "[2425]\ttraining's rmse: 0.0877037\tvalid_1's rmse: 0.0924525\n",
      "[2450]\ttraining's rmse: 0.0877014\tvalid_1's rmse: 0.0924513\n",
      "[2475]\ttraining's rmse: 0.0876969\tvalid_1's rmse: 0.0924503\n",
      "[2500]\ttraining's rmse: 0.087694\tvalid_1's rmse: 0.0924492\n",
      "[2525]\ttraining's rmse: 0.0876915\tvalid_1's rmse: 0.0924483\n",
      "[2550]\ttraining's rmse: 0.0876879\tvalid_1's rmse: 0.0924482\n",
      "[2575]\ttraining's rmse: 0.0876851\tvalid_1's rmse: 0.092448\n",
      "[2600]\ttraining's rmse: 0.0876829\tvalid_1's rmse: 0.0924475\n",
      "[2625]\ttraining's rmse: 0.0876804\tvalid_1's rmse: 0.0924469\n",
      "[2650]\ttraining's rmse: 0.0876782\tvalid_1's rmse: 0.0924462\n",
      "[2675]\ttraining's rmse: 0.0876762\tvalid_1's rmse: 0.0924455\n",
      "[2700]\ttraining's rmse: 0.0876742\tvalid_1's rmse: 0.0924448\n",
      "[2725]\ttraining's rmse: 0.0876721\tvalid_1's rmse: 0.0924446\n",
      "[2750]\ttraining's rmse: 0.0876691\tvalid_1's rmse: 0.0924435\n",
      "[2775]\ttraining's rmse: 0.0876674\tvalid_1's rmse: 0.0924437\n",
      "[2800]\ttraining's rmse: 0.0876659\tvalid_1's rmse: 0.0924435\n",
      "[2825]\ttraining's rmse: 0.0876637\tvalid_1's rmse: 0.0924439\n",
      "[2850]\ttraining's rmse: 0.0876626\tvalid_1's rmse: 0.092444\n",
      "Early stopping, best iteration is:\n",
      "[2809]\ttraining's rmse: 0.0876655\tvalid_1's rmse: 0.0924434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.091468\tvalid_1's rmse: 0.0935369\n",
      "[50]\ttraining's rmse: 0.0912947\tvalid_1's rmse: 0.0934819\n",
      "[75]\ttraining's rmse: 0.0911155\tvalid_1's rmse: 0.0934259\n",
      "[100]\ttraining's rmse: 0.0909564\tvalid_1's rmse: 0.0933765\n",
      "[125]\ttraining's rmse: 0.0907912\tvalid_1's rmse: 0.0933263\n",
      "[150]\ttraining's rmse: 0.0906437\tvalid_1's rmse: 0.0932798\n",
      "[175]\ttraining's rmse: 0.0905158\tvalid_1's rmse: 0.0932417\n",
      "[200]\ttraining's rmse: 0.09038\tvalid_1's rmse: 0.0932033\n",
      "[225]\ttraining's rmse: 0.0902578\tvalid_1's rmse: 0.0931688\n",
      "[250]\ttraining's rmse: 0.090149\tvalid_1's rmse: 0.0931375\n",
      "[275]\ttraining's rmse: 0.0900478\tvalid_1's rmse: 0.0931082\n",
      "[300]\ttraining's rmse: 0.08995\tvalid_1's rmse: 0.0930815\n",
      "[325]\ttraining's rmse: 0.0898538\tvalid_1's rmse: 0.0930555\n",
      "[350]\ttraining's rmse: 0.0897606\tvalid_1's rmse: 0.0930311\n",
      "[375]\ttraining's rmse: 0.0896847\tvalid_1's rmse: 0.0930109\n",
      "[400]\ttraining's rmse: 0.0896024\tvalid_1's rmse: 0.0929896\n",
      "[425]\ttraining's rmse: 0.089528\tvalid_1's rmse: 0.0929697\n",
      "[450]\ttraining's rmse: 0.0894584\tvalid_1's rmse: 0.0929522\n",
      "[475]\ttraining's rmse: 0.0893917\tvalid_1's rmse: 0.0929335\n",
      "[500]\ttraining's rmse: 0.0893353\tvalid_1's rmse: 0.0929172\n",
      "[525]\ttraining's rmse: 0.0892681\tvalid_1's rmse: 0.0929004\n",
      "[550]\ttraining's rmse: 0.0892049\tvalid_1's rmse: 0.0928861\n",
      "[575]\ttraining's rmse: 0.0891474\tvalid_1's rmse: 0.0928722\n",
      "[600]\ttraining's rmse: 0.0890929\tvalid_1's rmse: 0.0928588\n",
      "[625]\ttraining's rmse: 0.0890475\tvalid_1's rmse: 0.0928467\n",
      "[650]\ttraining's rmse: 0.0889926\tvalid_1's rmse: 0.0928352\n",
      "[675]\ttraining's rmse: 0.0889391\tvalid_1's rmse: 0.0928235\n",
      "[700]\ttraining's rmse: 0.0888932\tvalid_1's rmse: 0.0928123\n",
      "[725]\ttraining's rmse: 0.088851\tvalid_1's rmse: 0.0928034\n",
      "[750]\ttraining's rmse: 0.0888084\tvalid_1's rmse: 0.0927941\n",
      "[775]\ttraining's rmse: 0.0887725\tvalid_1's rmse: 0.0927852\n",
      "[800]\ttraining's rmse: 0.0887265\tvalid_1's rmse: 0.0927768\n",
      "[825]\ttraining's rmse: 0.0886909\tvalid_1's rmse: 0.0927685\n",
      "[850]\ttraining's rmse: 0.0886517\tvalid_1's rmse: 0.0927609\n",
      "[875]\ttraining's rmse: 0.0886206\tvalid_1's rmse: 0.0927547\n",
      "[900]\ttraining's rmse: 0.0885856\tvalid_1's rmse: 0.0927479\n",
      "[925]\ttraining's rmse: 0.0885501\tvalid_1's rmse: 0.0927423\n",
      "[950]\ttraining's rmse: 0.0885204\tvalid_1's rmse: 0.0927374\n",
      "[975]\ttraining's rmse: 0.0884907\tvalid_1's rmse: 0.0927318\n",
      "[1000]\ttraining's rmse: 0.088461\tvalid_1's rmse: 0.0927266\n",
      "[1025]\ttraining's rmse: 0.0884296\tvalid_1's rmse: 0.0927223\n",
      "[1050]\ttraining's rmse: 0.0884044\tvalid_1's rmse: 0.0927176\n",
      "[1075]\ttraining's rmse: 0.0883798\tvalid_1's rmse: 0.0927143\n",
      "[1100]\ttraining's rmse: 0.0883588\tvalid_1's rmse: 0.0927098\n",
      "[1125]\ttraining's rmse: 0.0883357\tvalid_1's rmse: 0.0927065\n",
      "[1150]\ttraining's rmse: 0.0883126\tvalid_1's rmse: 0.0927039\n",
      "[1175]\ttraining's rmse: 0.0882911\tvalid_1's rmse: 0.0927012\n",
      "[1200]\ttraining's rmse: 0.0882686\tvalid_1's rmse: 0.0926974\n",
      "[1225]\ttraining's rmse: 0.0882503\tvalid_1's rmse: 0.0926952\n",
      "[1250]\ttraining's rmse: 0.0882322\tvalid_1's rmse: 0.0926935\n",
      "[1275]\ttraining's rmse: 0.0882116\tvalid_1's rmse: 0.0926915\n",
      "[1300]\ttraining's rmse: 0.0881942\tvalid_1's rmse: 0.0926886\n",
      "[1325]\ttraining's rmse: 0.0881789\tvalid_1's rmse: 0.0926865\n",
      "[1350]\ttraining's rmse: 0.0881595\tvalid_1's rmse: 0.0926839\n",
      "[1375]\ttraining's rmse: 0.0881423\tvalid_1's rmse: 0.0926814\n",
      "[1400]\ttraining's rmse: 0.0881294\tvalid_1's rmse: 0.0926794\n",
      "[1425]\ttraining's rmse: 0.0881135\tvalid_1's rmse: 0.0926776\n",
      "[1450]\ttraining's rmse: 0.088097\tvalid_1's rmse: 0.0926758\n",
      "[1475]\ttraining's rmse: 0.0880848\tvalid_1's rmse: 0.0926737\n",
      "[1500]\ttraining's rmse: 0.0880734\tvalid_1's rmse: 0.0926723\n",
      "[1525]\ttraining's rmse: 0.0880592\tvalid_1's rmse: 0.0926718\n",
      "[1550]\ttraining's rmse: 0.0880473\tvalid_1's rmse: 0.0926714\n",
      "[1575]\ttraining's rmse: 0.0880372\tvalid_1's rmse: 0.0926707\n",
      "[1600]\ttraining's rmse: 0.0880279\tvalid_1's rmse: 0.0926697\n",
      "[1625]\ttraining's rmse: 0.0880176\tvalid_1's rmse: 0.0926683\n",
      "[1650]\ttraining's rmse: 0.0880071\tvalid_1's rmse: 0.0926674\n",
      "[1675]\ttraining's rmse: 0.0879997\tvalid_1's rmse: 0.0926667\n",
      "[1700]\ttraining's rmse: 0.0879919\tvalid_1's rmse: 0.0926655\n",
      "[1725]\ttraining's rmse: 0.0879833\tvalid_1's rmse: 0.0926646\n",
      "[1750]\ttraining's rmse: 0.0879737\tvalid_1's rmse: 0.0926638\n",
      "[1775]\ttraining's rmse: 0.0879647\tvalid_1's rmse: 0.0926632\n",
      "[1800]\ttraining's rmse: 0.0879583\tvalid_1's rmse: 0.0926624\n",
      "[1825]\ttraining's rmse: 0.0879503\tvalid_1's rmse: 0.0926621\n",
      "[1850]\ttraining's rmse: 0.0879429\tvalid_1's rmse: 0.0926612\n",
      "[1875]\ttraining's rmse: 0.0879361\tvalid_1's rmse: 0.0926609\n",
      "[1900]\ttraining's rmse: 0.08793\tvalid_1's rmse: 0.0926607\n",
      "[1925]\ttraining's rmse: 0.0879238\tvalid_1's rmse: 0.0926601\n",
      "[1950]\ttraining's rmse: 0.087919\tvalid_1's rmse: 0.0926589\n",
      "[1975]\ttraining's rmse: 0.0879136\tvalid_1's rmse: 0.0926582\n",
      "[2000]\ttraining's rmse: 0.0879071\tvalid_1's rmse: 0.0926577\n",
      "[2025]\ttraining's rmse: 0.0879032\tvalid_1's rmse: 0.0926573\n",
      "[2050]\ttraining's rmse: 0.0878978\tvalid_1's rmse: 0.0926575\n",
      "[2075]\ttraining's rmse: 0.0878928\tvalid_1's rmse: 0.0926571\n",
      "[2100]\ttraining's rmse: 0.0878893\tvalid_1's rmse: 0.0926568\n",
      "[2125]\ttraining's rmse: 0.0878849\tvalid_1's rmse: 0.0926564\n",
      "[2150]\ttraining's rmse: 0.0878802\tvalid_1's rmse: 0.0926566\n",
      "[2175]\ttraining's rmse: 0.0878766\tvalid_1's rmse: 0.0926564\n",
      "[2200]\ttraining's rmse: 0.0878737\tvalid_1's rmse: 0.0926563\n",
      "[2225]\ttraining's rmse: 0.0878701\tvalid_1's rmse: 0.0926563\n",
      "[2250]\ttraining's rmse: 0.0878666\tvalid_1's rmse: 0.0926562\n",
      "[2275]\ttraining's rmse: 0.087863\tvalid_1's rmse: 0.092656\n",
      "[2300]\ttraining's rmse: 0.0878581\tvalid_1's rmse: 0.0926557\n",
      "[2325]\ttraining's rmse: 0.0878546\tvalid_1's rmse: 0.0926554\n",
      "[2350]\ttraining's rmse: 0.0878516\tvalid_1's rmse: 0.0926553\n",
      "[2375]\ttraining's rmse: 0.0878477\tvalid_1's rmse: 0.0926552\n",
      "[2400]\ttraining's rmse: 0.0878447\tvalid_1's rmse: 0.0926556\n",
      "Early stopping, best iteration is:\n",
      "[2366]\ttraining's rmse: 0.0878487\tvalid_1's rmse: 0.092655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0933518\tvalid_1's rmse: 0.0898135\n",
      "[50]\ttraining's rmse: 0.093219\tvalid_1's rmse: 0.0897645\n",
      "[75]\ttraining's rmse: 0.0930783\tvalid_1's rmse: 0.0897153\n",
      "[100]\ttraining's rmse: 0.0929499\tvalid_1's rmse: 0.0896725\n",
      "[125]\ttraining's rmse: 0.0928216\tvalid_1's rmse: 0.0896313\n",
      "[150]\ttraining's rmse: 0.0926997\tvalid_1's rmse: 0.0895925\n",
      "[175]\ttraining's rmse: 0.0925977\tvalid_1's rmse: 0.0895625\n",
      "[200]\ttraining's rmse: 0.0924886\tvalid_1's rmse: 0.0895277\n",
      "[225]\ttraining's rmse: 0.0923838\tvalid_1's rmse: 0.0894967\n",
      "[250]\ttraining's rmse: 0.0922932\tvalid_1's rmse: 0.0894716\n",
      "[275]\ttraining's rmse: 0.0922117\tvalid_1's rmse: 0.0894456\n",
      "[300]\ttraining's rmse: 0.0921319\tvalid_1's rmse: 0.089423\n",
      "[325]\ttraining's rmse: 0.0920466\tvalid_1's rmse: 0.0893997\n",
      "[350]\ttraining's rmse: 0.0919675\tvalid_1's rmse: 0.0893772\n",
      "[375]\ttraining's rmse: 0.0919025\tvalid_1's rmse: 0.0893604\n",
      "[400]\ttraining's rmse: 0.0918321\tvalid_1's rmse: 0.0893474\n",
      "[425]\ttraining's rmse: 0.0917664\tvalid_1's rmse: 0.0893342\n",
      "[450]\ttraining's rmse: 0.091703\tvalid_1's rmse: 0.0893164\n",
      "[475]\ttraining's rmse: 0.091644\tvalid_1's rmse: 0.0893021\n",
      "[500]\ttraining's rmse: 0.0915944\tvalid_1's rmse: 0.0892877\n",
      "[525]\ttraining's rmse: 0.0915304\tvalid_1's rmse: 0.0892745\n",
      "[550]\ttraining's rmse: 0.091474\tvalid_1's rmse: 0.089261\n",
      "[575]\ttraining's rmse: 0.0914183\tvalid_1's rmse: 0.0892508\n",
      "[600]\ttraining's rmse: 0.0913644\tvalid_1's rmse: 0.0892401\n",
      "[625]\ttraining's rmse: 0.0913207\tvalid_1's rmse: 0.0892317\n",
      "[650]\ttraining's rmse: 0.0912669\tvalid_1's rmse: 0.0892273\n",
      "[675]\ttraining's rmse: 0.0912146\tvalid_1's rmse: 0.0892297\n",
      "[700]\ttraining's rmse: 0.091168\tvalid_1's rmse: 0.0892249\n",
      "[725]\ttraining's rmse: 0.0911241\tvalid_1's rmse: 0.0892196\n",
      "[750]\ttraining's rmse: 0.0910848\tvalid_1's rmse: 0.0892217\n",
      "[775]\ttraining's rmse: 0.0910495\tvalid_1's rmse: 0.0892227\n",
      "Early stopping, best iteration is:\n",
      "[738]\ttraining's rmse: 0.0911037\tvalid_1's rmse: 0.0892154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0908836\tvalid_1's rmse: 0.0932019\n",
      "[50]\ttraining's rmse: 0.0907256\tvalid_1's rmse: 0.0931467\n",
      "[75]\ttraining's rmse: 0.0905667\tvalid_1's rmse: 0.09309\n",
      "[100]\ttraining's rmse: 0.0904209\tvalid_1's rmse: 0.0930398\n",
      "[125]\ttraining's rmse: 0.0902785\tvalid_1's rmse: 0.0929893\n",
      "[150]\ttraining's rmse: 0.0901473\tvalid_1's rmse: 0.0929431\n",
      "[175]\ttraining's rmse: 0.0900367\tvalid_1's rmse: 0.0929046\n",
      "[200]\ttraining's rmse: 0.0899198\tvalid_1's rmse: 0.0928662\n",
      "[225]\ttraining's rmse: 0.0898079\tvalid_1's rmse: 0.0928285\n",
      "[250]\ttraining's rmse: 0.0897101\tvalid_1's rmse: 0.0927953\n",
      "[275]\ttraining's rmse: 0.0896196\tvalid_1's rmse: 0.0927667\n",
      "[300]\ttraining's rmse: 0.0895277\tvalid_1's rmse: 0.0927368\n",
      "[325]\ttraining's rmse: 0.0894384\tvalid_1's rmse: 0.0927091\n",
      "[350]\ttraining's rmse: 0.0893509\tvalid_1's rmse: 0.0926812\n",
      "[375]\ttraining's rmse: 0.089277\tvalid_1's rmse: 0.0926573\n",
      "[400]\ttraining's rmse: 0.0891962\tvalid_1's rmse: 0.0926351\n",
      "[425]\ttraining's rmse: 0.0891258\tvalid_1's rmse: 0.0926137\n",
      "[450]\ttraining's rmse: 0.0890616\tvalid_1's rmse: 0.0925913\n",
      "[475]\ttraining's rmse: 0.0890049\tvalid_1's rmse: 0.0925726\n",
      "[500]\ttraining's rmse: 0.0889521\tvalid_1's rmse: 0.0925533\n",
      "[525]\ttraining's rmse: 0.0888863\tvalid_1's rmse: 0.0925356\n",
      "[550]\ttraining's rmse: 0.0888281\tvalid_1's rmse: 0.0925185\n",
      "[575]\ttraining's rmse: 0.0887742\tvalid_1's rmse: 0.0925045\n",
      "[600]\ttraining's rmse: 0.0887224\tvalid_1's rmse: 0.0924912\n",
      "[625]\ttraining's rmse: 0.088678\tvalid_1's rmse: 0.0924788\n",
      "[650]\ttraining's rmse: 0.0886288\tvalid_1's rmse: 0.0924643\n",
      "[675]\ttraining's rmse: 0.0885813\tvalid_1's rmse: 0.0924512\n",
      "[700]\ttraining's rmse: 0.0885399\tvalid_1's rmse: 0.0924391\n",
      "[725]\ttraining's rmse: 0.0884989\tvalid_1's rmse: 0.0924285\n",
      "[750]\ttraining's rmse: 0.0884548\tvalid_1's rmse: 0.0924189\n",
      "[775]\ttraining's rmse: 0.0884226\tvalid_1's rmse: 0.0924084\n",
      "[800]\ttraining's rmse: 0.0883847\tvalid_1's rmse: 0.0924006\n",
      "[825]\ttraining's rmse: 0.0883504\tvalid_1's rmse: 0.0923906\n",
      "[850]\ttraining's rmse: 0.0883148\tvalid_1's rmse: 0.0923834\n",
      "[875]\ttraining's rmse: 0.0882847\tvalid_1's rmse: 0.0923758\n",
      "[900]\ttraining's rmse: 0.0882503\tvalid_1's rmse: 0.0923685\n",
      "[925]\ttraining's rmse: 0.0882198\tvalid_1's rmse: 0.0923609\n",
      "[950]\ttraining's rmse: 0.0881906\tvalid_1's rmse: 0.0923536\n",
      "[975]\ttraining's rmse: 0.0881649\tvalid_1's rmse: 0.0923465\n",
      "[1000]\ttraining's rmse: 0.0881407\tvalid_1's rmse: 0.0923398\n",
      "[1025]\ttraining's rmse: 0.0881128\tvalid_1's rmse: 0.0923341\n",
      "[1050]\ttraining's rmse: 0.0880903\tvalid_1's rmse: 0.0923271\n",
      "[1075]\ttraining's rmse: 0.0880655\tvalid_1's rmse: 0.092322\n",
      "[1100]\ttraining's rmse: 0.0880436\tvalid_1's rmse: 0.0923173\n",
      "[1125]\ttraining's rmse: 0.0880209\tvalid_1's rmse: 0.0923102\n",
      "[1150]\ttraining's rmse: 0.0879964\tvalid_1's rmse: 0.0923053\n",
      "[1175]\ttraining's rmse: 0.087975\tvalid_1's rmse: 0.0923023\n",
      "[1200]\ttraining's rmse: 0.0879573\tvalid_1's rmse: 0.0922973\n",
      "[1225]\ttraining's rmse: 0.0879378\tvalid_1's rmse: 0.0922933\n",
      "[1250]\ttraining's rmse: 0.0879202\tvalid_1's rmse: 0.0922877\n",
      "[1275]\ttraining's rmse: 0.0879013\tvalid_1's rmse: 0.0922839\n",
      "[1300]\ttraining's rmse: 0.0878849\tvalid_1's rmse: 0.0922781\n",
      "[1325]\ttraining's rmse: 0.0878705\tvalid_1's rmse: 0.0922741\n",
      "[1350]\ttraining's rmse: 0.0878537\tvalid_1's rmse: 0.0922703\n",
      "[1375]\ttraining's rmse: 0.0878382\tvalid_1's rmse: 0.0922675\n",
      "[1400]\ttraining's rmse: 0.0878247\tvalid_1's rmse: 0.0922631\n",
      "[1425]\ttraining's rmse: 0.0878074\tvalid_1's rmse: 0.0922605\n",
      "[1450]\ttraining's rmse: 0.0877918\tvalid_1's rmse: 0.0922579\n",
      "[1475]\ttraining's rmse: 0.0877793\tvalid_1's rmse: 0.092254\n",
      "[1500]\ttraining's rmse: 0.0877667\tvalid_1's rmse: 0.0922496\n",
      "[1525]\ttraining's rmse: 0.0877545\tvalid_1's rmse: 0.0922462\n",
      "[1550]\ttraining's rmse: 0.0877435\tvalid_1's rmse: 0.0922429\n",
      "[1575]\ttraining's rmse: 0.0877339\tvalid_1's rmse: 0.0922411\n",
      "[1600]\ttraining's rmse: 0.0877244\tvalid_1's rmse: 0.0922381\n",
      "[1625]\ttraining's rmse: 0.0877147\tvalid_1's rmse: 0.0922353\n",
      "[1650]\ttraining's rmse: 0.0877028\tvalid_1's rmse: 0.0922326\n",
      "[1675]\ttraining's rmse: 0.0876943\tvalid_1's rmse: 0.0922295\n",
      "[1700]\ttraining's rmse: 0.0876883\tvalid_1's rmse: 0.092228\n",
      "[1725]\ttraining's rmse: 0.087681\tvalid_1's rmse: 0.0922259\n",
      "[1750]\ttraining's rmse: 0.0876704\tvalid_1's rmse: 0.0922231\n",
      "[1775]\ttraining's rmse: 0.0876622\tvalid_1's rmse: 0.0922218\n",
      "[1800]\ttraining's rmse: 0.0876552\tvalid_1's rmse: 0.0922205\n",
      "[1825]\ttraining's rmse: 0.0876487\tvalid_1's rmse: 0.0922175\n",
      "[1850]\ttraining's rmse: 0.0876406\tvalid_1's rmse: 0.0922149\n",
      "[1875]\ttraining's rmse: 0.0876337\tvalid_1's rmse: 0.0922133\n",
      "[1900]\ttraining's rmse: 0.0876281\tvalid_1's rmse: 0.0922111\n",
      "[1925]\ttraining's rmse: 0.0876228\tvalid_1's rmse: 0.0922097\n",
      "[1950]\ttraining's rmse: 0.0876179\tvalid_1's rmse: 0.0922076\n",
      "[1975]\ttraining's rmse: 0.0876126\tvalid_1's rmse: 0.0922065\n",
      "[2000]\ttraining's rmse: 0.0876075\tvalid_1's rmse: 0.0922052\n",
      "[2025]\ttraining's rmse: 0.0876044\tvalid_1's rmse: 0.0922045\n",
      "[2050]\ttraining's rmse: 0.0875992\tvalid_1's rmse: 0.0922017\n",
      "[2075]\ttraining's rmse: 0.0875942\tvalid_1's rmse: 0.0921995\n",
      "[2100]\ttraining's rmse: 0.0875906\tvalid_1's rmse: 0.0921981\n",
      "[2125]\ttraining's rmse: 0.0875849\tvalid_1's rmse: 0.0921976\n",
      "[2150]\ttraining's rmse: 0.0875811\tvalid_1's rmse: 0.0921965\n",
      "[2175]\ttraining's rmse: 0.0875779\tvalid_1's rmse: 0.0921953\n",
      "[2200]\ttraining's rmse: 0.0875727\tvalid_1's rmse: 0.0921939\n",
      "[2225]\ttraining's rmse: 0.0875687\tvalid_1's rmse: 0.0921925\n",
      "[2250]\ttraining's rmse: 0.0875663\tvalid_1's rmse: 0.0921905\n",
      "[2275]\ttraining's rmse: 0.0875625\tvalid_1's rmse: 0.0921905\n",
      "[2300]\ttraining's rmse: 0.0875591\tvalid_1's rmse: 0.0921894\n",
      "[2325]\ttraining's rmse: 0.0875542\tvalid_1's rmse: 0.0921887\n",
      "[2350]\ttraining's rmse: 0.0875513\tvalid_1's rmse: 0.0921877\n",
      "[2375]\ttraining's rmse: 0.087547\tvalid_1's rmse: 0.0921864\n",
      "[2400]\ttraining's rmse: 0.0875427\tvalid_1's rmse: 0.0921855\n",
      "[2425]\ttraining's rmse: 0.0875398\tvalid_1's rmse: 0.0921853\n",
      "[2450]\ttraining's rmse: 0.0875367\tvalid_1's rmse: 0.092185\n",
      "[2475]\ttraining's rmse: 0.0875347\tvalid_1's rmse: 0.0921847\n",
      "[2500]\ttraining's rmse: 0.0875325\tvalid_1's rmse: 0.092184\n",
      "[2525]\ttraining's rmse: 0.0875301\tvalid_1's rmse: 0.0921833\n",
      "[2550]\ttraining's rmse: 0.0875257\tvalid_1's rmse: 0.0921824\n",
      "[2575]\ttraining's rmse: 0.0875227\tvalid_1's rmse: 0.0921816\n",
      "[2600]\ttraining's rmse: 0.0875205\tvalid_1's rmse: 0.0921811\n",
      "[2625]\ttraining's rmse: 0.0875176\tvalid_1's rmse: 0.09218\n",
      "[2650]\ttraining's rmse: 0.0875152\tvalid_1's rmse: 0.0921791\n",
      "[2675]\ttraining's rmse: 0.0875137\tvalid_1's rmse: 0.092179\n",
      "[2700]\ttraining's rmse: 0.08751\tvalid_1's rmse: 0.0921778\n",
      "[2725]\ttraining's rmse: 0.0875087\tvalid_1's rmse: 0.0921778\n",
      "[2750]\ttraining's rmse: 0.0875061\tvalid_1's rmse: 0.0921771\n",
      "[2775]\ttraining's rmse: 0.0875043\tvalid_1's rmse: 0.0921773\n",
      "[2800]\ttraining's rmse: 0.0875027\tvalid_1's rmse: 0.0921766\n",
      "[2825]\ttraining's rmse: 0.0875008\tvalid_1's rmse: 0.0921761\n",
      "[2850]\ttraining's rmse: 0.0874985\tvalid_1's rmse: 0.092176\n",
      "[2875]\ttraining's rmse: 0.0874958\tvalid_1's rmse: 0.0921755\n",
      "[2900]\ttraining's rmse: 0.0874947\tvalid_1's rmse: 0.0921754\n",
      "[2925]\ttraining's rmse: 0.0874922\tvalid_1's rmse: 0.0921747\n",
      "[2950]\ttraining's rmse: 0.0874902\tvalid_1's rmse: 0.0921749\n",
      "[2975]\ttraining's rmse: 0.0874887\tvalid_1's rmse: 0.0921749\n",
      "Early stopping, best iteration is:\n",
      "[2936]\ttraining's rmse: 0.0874915\tvalid_1's rmse: 0.0921745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0907814\tvalid_1's rmse: 0.0934135\n",
      "[50]\ttraining's rmse: 0.0906421\tvalid_1's rmse: 0.0933576\n",
      "[75]\ttraining's rmse: 0.0904949\tvalid_1's rmse: 0.0933002\n",
      "[100]\ttraining's rmse: 0.090368\tvalid_1's rmse: 0.0932508\n",
      "[125]\ttraining's rmse: 0.0902367\tvalid_1's rmse: 0.0932021\n",
      "[150]\ttraining's rmse: 0.0901135\tvalid_1's rmse: 0.0931579\n",
      "[175]\ttraining's rmse: 0.0900075\tvalid_1's rmse: 0.0931199\n",
      "[200]\ttraining's rmse: 0.0898972\tvalid_1's rmse: 0.0930836\n",
      "[225]\ttraining's rmse: 0.089794\tvalid_1's rmse: 0.0930503\n",
      "[250]\ttraining's rmse: 0.0897033\tvalid_1's rmse: 0.0930181\n",
      "[275]\ttraining's rmse: 0.0896195\tvalid_1's rmse: 0.0929879\n",
      "[300]\ttraining's rmse: 0.0895378\tvalid_1's rmse: 0.092961\n",
      "[325]\ttraining's rmse: 0.0894529\tvalid_1's rmse: 0.092935\n",
      "[350]\ttraining's rmse: 0.0893696\tvalid_1's rmse: 0.0929109\n",
      "[375]\ttraining's rmse: 0.0893028\tvalid_1's rmse: 0.0928903\n",
      "[400]\ttraining's rmse: 0.0892302\tvalid_1's rmse: 0.0928695\n",
      "[425]\ttraining's rmse: 0.089164\tvalid_1's rmse: 0.0928497\n",
      "[450]\ttraining's rmse: 0.089102\tvalid_1's rmse: 0.0928315\n",
      "[475]\ttraining's rmse: 0.0890452\tvalid_1's rmse: 0.0928144\n",
      "[500]\ttraining's rmse: 0.0889964\tvalid_1's rmse: 0.0927976\n",
      "[525]\ttraining's rmse: 0.0889321\tvalid_1's rmse: 0.0927801\n",
      "[550]\ttraining's rmse: 0.0888749\tvalid_1's rmse: 0.0927654\n",
      "[575]\ttraining's rmse: 0.088822\tvalid_1's rmse: 0.0927523\n",
      "[600]\ttraining's rmse: 0.088767\tvalid_1's rmse: 0.0927393\n",
      "[625]\ttraining's rmse: 0.0887282\tvalid_1's rmse: 0.0927275\n",
      "[650]\ttraining's rmse: 0.0886786\tvalid_1's rmse: 0.0927156\n",
      "[675]\ttraining's rmse: 0.0886296\tvalid_1's rmse: 0.0927042\n",
      "[700]\ttraining's rmse: 0.0885856\tvalid_1's rmse: 0.0926935\n",
      "[725]\ttraining's rmse: 0.0885443\tvalid_1's rmse: 0.0926838\n",
      "[750]\ttraining's rmse: 0.0885061\tvalid_1's rmse: 0.0926751\n",
      "[775]\ttraining's rmse: 0.0884726\tvalid_1's rmse: 0.0926666\n",
      "[800]\ttraining's rmse: 0.0884321\tvalid_1's rmse: 0.0926588\n",
      "[825]\ttraining's rmse: 0.0883972\tvalid_1's rmse: 0.0926517\n",
      "[850]\ttraining's rmse: 0.088362\tvalid_1's rmse: 0.0926461\n",
      "[875]\ttraining's rmse: 0.0883302\tvalid_1's rmse: 0.0926399\n",
      "[900]\ttraining's rmse: 0.0882977\tvalid_1's rmse: 0.0926347\n",
      "[925]\ttraining's rmse: 0.088266\tvalid_1's rmse: 0.0926286\n",
      "[950]\ttraining's rmse: 0.0882374\tvalid_1's rmse: 0.0926231\n",
      "[975]\ttraining's rmse: 0.0882092\tvalid_1's rmse: 0.0926182\n",
      "[1000]\ttraining's rmse: 0.0881843\tvalid_1's rmse: 0.0926139\n",
      "[1025]\ttraining's rmse: 0.0881542\tvalid_1's rmse: 0.0926096\n",
      "[1050]\ttraining's rmse: 0.0881322\tvalid_1's rmse: 0.0926052\n",
      "[1075]\ttraining's rmse: 0.088107\tvalid_1's rmse: 0.0926022\n",
      "[1100]\ttraining's rmse: 0.0880845\tvalid_1's rmse: 0.0925977\n",
      "[1125]\ttraining's rmse: 0.0880628\tvalid_1's rmse: 0.0925938\n",
      "[1150]\ttraining's rmse: 0.0880399\tvalid_1's rmse: 0.0925906\n",
      "[1175]\ttraining's rmse: 0.0880181\tvalid_1's rmse: 0.0925877\n",
      "[1200]\ttraining's rmse: 0.0880011\tvalid_1's rmse: 0.0925847\n",
      "[1225]\ttraining's rmse: 0.0879833\tvalid_1's rmse: 0.0925819\n",
      "[1250]\ttraining's rmse: 0.087966\tvalid_1's rmse: 0.09258\n",
      "[1275]\ttraining's rmse: 0.0879458\tvalid_1's rmse: 0.0925775\n",
      "[1300]\ttraining's rmse: 0.0879305\tvalid_1's rmse: 0.0925749\n",
      "[1325]\ttraining's rmse: 0.0879145\tvalid_1's rmse: 0.092573\n",
      "[1350]\ttraining's rmse: 0.0878976\tvalid_1's rmse: 0.0925713\n",
      "[1375]\ttraining's rmse: 0.0878808\tvalid_1's rmse: 0.0925694\n",
      "[1400]\ttraining's rmse: 0.0878679\tvalid_1's rmse: 0.0925673\n",
      "[1425]\ttraining's rmse: 0.0878513\tvalid_1's rmse: 0.0925656\n",
      "[1450]\ttraining's rmse: 0.0878371\tvalid_1's rmse: 0.0925643\n",
      "[1475]\ttraining's rmse: 0.0878235\tvalid_1's rmse: 0.092563\n",
      "[1500]\ttraining's rmse: 0.0878119\tvalid_1's rmse: 0.0925622\n",
      "[1525]\ttraining's rmse: 0.0877985\tvalid_1's rmse: 0.0925612\n",
      "[1550]\ttraining's rmse: 0.0877864\tvalid_1's rmse: 0.0925597\n",
      "[1575]\ttraining's rmse: 0.0877757\tvalid_1's rmse: 0.0925591\n",
      "[1600]\ttraining's rmse: 0.0877665\tvalid_1's rmse: 0.0925589\n",
      "[1625]\ttraining's rmse: 0.0877582\tvalid_1's rmse: 0.092558\n",
      "[1650]\ttraining's rmse: 0.0877496\tvalid_1's rmse: 0.0925574\n",
      "[1675]\ttraining's rmse: 0.0877407\tvalid_1's rmse: 0.0925562\n",
      "[1700]\ttraining's rmse: 0.0877322\tvalid_1's rmse: 0.0925551\n",
      "[1725]\ttraining's rmse: 0.087725\tvalid_1's rmse: 0.0925546\n",
      "[1750]\ttraining's rmse: 0.0877144\tvalid_1's rmse: 0.0925545\n",
      "[1775]\ttraining's rmse: 0.0877073\tvalid_1's rmse: 0.0925544\n",
      "[1800]\ttraining's rmse: 0.0876985\tvalid_1's rmse: 0.0925539\n",
      "[1825]\ttraining's rmse: 0.0876885\tvalid_1's rmse: 0.092554\n",
      "[1850]\ttraining's rmse: 0.087682\tvalid_1's rmse: 0.0925531\n",
      "[1875]\ttraining's rmse: 0.0876757\tvalid_1's rmse: 0.092553\n",
      "[1900]\ttraining's rmse: 0.0876701\tvalid_1's rmse: 0.0925529\n",
      "Early stopping, best iteration is:\n",
      "[1860]\ttraining's rmse: 0.0876803\tvalid_1's rmse: 0.0925526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0931612\tvalid_1's rmse: 0.0885875\n",
      "[50]\ttraining's rmse: 0.0930292\tvalid_1's rmse: 0.0885377\n",
      "[75]\ttraining's rmse: 0.0928912\tvalid_1's rmse: 0.0884877\n",
      "[100]\ttraining's rmse: 0.0927663\tvalid_1's rmse: 0.088445\n",
      "[125]\ttraining's rmse: 0.0926348\tvalid_1's rmse: 0.0884006\n",
      "[150]\ttraining's rmse: 0.0925151\tvalid_1's rmse: 0.0883607\n",
      "[175]\ttraining's rmse: 0.0924138\tvalid_1's rmse: 0.0883277\n",
      "[200]\ttraining's rmse: 0.092306\tvalid_1's rmse: 0.0882937\n",
      "[225]\ttraining's rmse: 0.0922037\tvalid_1's rmse: 0.0882611\n",
      "[250]\ttraining's rmse: 0.0921142\tvalid_1's rmse: 0.0882346\n",
      "[275]\ttraining's rmse: 0.092037\tvalid_1's rmse: 0.0882096\n",
      "[300]\ttraining's rmse: 0.0919573\tvalid_1's rmse: 0.0881863\n",
      "[325]\ttraining's rmse: 0.0918746\tvalid_1's rmse: 0.0881611\n",
      "[350]\ttraining's rmse: 0.0917948\tvalid_1's rmse: 0.0881391\n",
      "[375]\ttraining's rmse: 0.0917258\tvalid_1's rmse: 0.0881216\n",
      "[400]\ttraining's rmse: 0.0916531\tvalid_1's rmse: 0.0881067\n",
      "[425]\ttraining's rmse: 0.0915859\tvalid_1's rmse: 0.0880932\n",
      "[450]\ttraining's rmse: 0.091525\tvalid_1's rmse: 0.0880813\n",
      "[475]\ttraining's rmse: 0.0914673\tvalid_1's rmse: 0.0880675\n",
      "[500]\ttraining's rmse: 0.0914182\tvalid_1's rmse: 0.0880543\n",
      "[525]\ttraining's rmse: 0.0913532\tvalid_1's rmse: 0.0880493\n",
      "[550]\ttraining's rmse: 0.0912949\tvalid_1's rmse: 0.0880364\n",
      "[575]\ttraining's rmse: 0.0912391\tvalid_1's rmse: 0.0880258\n",
      "[600]\ttraining's rmse: 0.0911841\tvalid_1's rmse: 0.0880179\n",
      "[625]\ttraining's rmse: 0.0911434\tvalid_1's rmse: 0.0880093\n",
      "[650]\ttraining's rmse: 0.0910925\tvalid_1's rmse: 0.0880045\n",
      "[675]\ttraining's rmse: 0.09104\tvalid_1's rmse: 0.0879956\n",
      "[700]\ttraining's rmse: 0.090996\tvalid_1's rmse: 0.0879865\n",
      "[725]\ttraining's rmse: 0.0909537\tvalid_1's rmse: 0.0879842\n",
      "[750]\ttraining's rmse: 0.0909139\tvalid_1's rmse: 0.0879967\n",
      "[775]\ttraining's rmse: 0.0908789\tvalid_1's rmse: 0.0879899\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.0909357\tvalid_1's rmse: 0.0879807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0921367\tvalid_1's rmse: 0.0940044\n",
      "[50]\ttraining's rmse: 0.0919433\tvalid_1's rmse: 0.0939502\n",
      "[75]\ttraining's rmse: 0.0917494\tvalid_1's rmse: 0.0938935\n",
      "[100]\ttraining's rmse: 0.0915706\tvalid_1's rmse: 0.0938439\n",
      "[125]\ttraining's rmse: 0.0913936\tvalid_1's rmse: 0.0937949\n",
      "[150]\ttraining's rmse: 0.0912332\tvalid_1's rmse: 0.0937516\n",
      "[175]\ttraining's rmse: 0.0910964\tvalid_1's rmse: 0.0937135\n",
      "[200]\ttraining's rmse: 0.0909554\tvalid_1's rmse: 0.0936767\n",
      "[225]\ttraining's rmse: 0.0908221\tvalid_1's rmse: 0.093642\n",
      "[250]\ttraining's rmse: 0.0907049\tvalid_1's rmse: 0.0936099\n",
      "[275]\ttraining's rmse: 0.0905911\tvalid_1's rmse: 0.0935793\n",
      "[300]\ttraining's rmse: 0.0904802\tvalid_1's rmse: 0.0935489\n",
      "[325]\ttraining's rmse: 0.0903778\tvalid_1's rmse: 0.0935215\n",
      "[350]\ttraining's rmse: 0.0902745\tvalid_1's rmse: 0.0934962\n",
      "[375]\ttraining's rmse: 0.0901858\tvalid_1's rmse: 0.0934722\n",
      "[400]\ttraining's rmse: 0.090095\tvalid_1's rmse: 0.0934508\n",
      "[425]\ttraining's rmse: 0.0900103\tvalid_1's rmse: 0.0934299\n",
      "[450]\ttraining's rmse: 0.0899329\tvalid_1's rmse: 0.0934094\n",
      "[475]\ttraining's rmse: 0.0898612\tvalid_1's rmse: 0.0933891\n",
      "[500]\ttraining's rmse: 0.0897972\tvalid_1's rmse: 0.0933716\n",
      "[525]\ttraining's rmse: 0.0897236\tvalid_1's rmse: 0.0933513\n",
      "[550]\ttraining's rmse: 0.0896578\tvalid_1's rmse: 0.0933354\n",
      "[575]\ttraining's rmse: 0.089593\tvalid_1's rmse: 0.0933199\n",
      "[600]\ttraining's rmse: 0.0895301\tvalid_1's rmse: 0.0933056\n",
      "[625]\ttraining's rmse: 0.0894827\tvalid_1's rmse: 0.093291\n",
      "[650]\ttraining's rmse: 0.0894274\tvalid_1's rmse: 0.0932772\n",
      "[675]\ttraining's rmse: 0.0893705\tvalid_1's rmse: 0.0932652\n",
      "[700]\ttraining's rmse: 0.089323\tvalid_1's rmse: 0.0932535\n",
      "[725]\ttraining's rmse: 0.0892791\tvalid_1's rmse: 0.093242\n",
      "[750]\ttraining's rmse: 0.0892371\tvalid_1's rmse: 0.0932327\n",
      "[775]\ttraining's rmse: 0.0891999\tvalid_1's rmse: 0.0932238\n",
      "[800]\ttraining's rmse: 0.0891561\tvalid_1's rmse: 0.0932148\n",
      "[825]\ttraining's rmse: 0.0891169\tvalid_1's rmse: 0.0932056\n",
      "[850]\ttraining's rmse: 0.0890786\tvalid_1's rmse: 0.0931971\n",
      "[875]\ttraining's rmse: 0.0890463\tvalid_1's rmse: 0.0931887\n",
      "[900]\ttraining's rmse: 0.0890057\tvalid_1's rmse: 0.0931795\n",
      "[925]\ttraining's rmse: 0.0889723\tvalid_1's rmse: 0.0931726\n",
      "[950]\ttraining's rmse: 0.0889382\tvalid_1's rmse: 0.0931623\n",
      "[975]\ttraining's rmse: 0.0889087\tvalid_1's rmse: 0.093155\n",
      "[1000]\ttraining's rmse: 0.0888783\tvalid_1's rmse: 0.0931489\n",
      "[1025]\ttraining's rmse: 0.0888477\tvalid_1's rmse: 0.0931433\n",
      "[1050]\ttraining's rmse: 0.0888188\tvalid_1's rmse: 0.0931372\n",
      "[1075]\ttraining's rmse: 0.0887942\tvalid_1's rmse: 0.0931331\n",
      "[1100]\ttraining's rmse: 0.0887729\tvalid_1's rmse: 0.0931279\n",
      "[1125]\ttraining's rmse: 0.0887494\tvalid_1's rmse: 0.0931214\n",
      "[1150]\ttraining's rmse: 0.0887253\tvalid_1's rmse: 0.0931151\n",
      "[1175]\ttraining's rmse: 0.0887053\tvalid_1's rmse: 0.0931119\n",
      "[1200]\ttraining's rmse: 0.0886858\tvalid_1's rmse: 0.0931057\n",
      "[1225]\ttraining's rmse: 0.0886671\tvalid_1's rmse: 0.0931008\n",
      "[1250]\ttraining's rmse: 0.0886489\tvalid_1's rmse: 0.0930978\n",
      "[1275]\ttraining's rmse: 0.0886295\tvalid_1's rmse: 0.0930942\n",
      "[1300]\ttraining's rmse: 0.0886127\tvalid_1's rmse: 0.0930898\n",
      "[1325]\ttraining's rmse: 0.0885944\tvalid_1's rmse: 0.0930864\n",
      "[1350]\ttraining's rmse: 0.0885795\tvalid_1's rmse: 0.0930822\n",
      "[1375]\ttraining's rmse: 0.0885624\tvalid_1's rmse: 0.0930784\n",
      "[1400]\ttraining's rmse: 0.0885467\tvalid_1's rmse: 0.0930744\n",
      "[1425]\ttraining's rmse: 0.0885324\tvalid_1's rmse: 0.0930709\n",
      "[1450]\ttraining's rmse: 0.0885165\tvalid_1's rmse: 0.0930686\n",
      "[1475]\ttraining's rmse: 0.0885052\tvalid_1's rmse: 0.0930656\n",
      "[1500]\ttraining's rmse: 0.0884916\tvalid_1's rmse: 0.0930624\n",
      "[1525]\ttraining's rmse: 0.0884775\tvalid_1's rmse: 0.0930599\n",
      "[1550]\ttraining's rmse: 0.088463\tvalid_1's rmse: 0.0930591\n",
      "[1575]\ttraining's rmse: 0.0884532\tvalid_1's rmse: 0.0930558\n",
      "[1600]\ttraining's rmse: 0.0884418\tvalid_1's rmse: 0.0930526\n",
      "[1625]\ttraining's rmse: 0.0884319\tvalid_1's rmse: 0.0930503\n",
      "[1650]\ttraining's rmse: 0.0884217\tvalid_1's rmse: 0.0930478\n",
      "[1675]\ttraining's rmse: 0.0884137\tvalid_1's rmse: 0.0930449\n",
      "[1700]\ttraining's rmse: 0.0884023\tvalid_1's rmse: 0.0930419\n",
      "[1725]\ttraining's rmse: 0.0883932\tvalid_1's rmse: 0.0930401\n",
      "[1750]\ttraining's rmse: 0.0883828\tvalid_1's rmse: 0.0930366\n",
      "[1775]\ttraining's rmse: 0.088372\tvalid_1's rmse: 0.0930347\n",
      "[1800]\ttraining's rmse: 0.0883644\tvalid_1's rmse: 0.0930339\n",
      "[1825]\ttraining's rmse: 0.088358\tvalid_1's rmse: 0.0930332\n",
      "[1850]\ttraining's rmse: 0.0883525\tvalid_1's rmse: 0.0930307\n",
      "[1875]\ttraining's rmse: 0.0883458\tvalid_1's rmse: 0.0930292\n",
      "[1900]\ttraining's rmse: 0.0883384\tvalid_1's rmse: 0.0930275\n",
      "[1925]\ttraining's rmse: 0.0883326\tvalid_1's rmse: 0.0930255\n",
      "[1950]\ttraining's rmse: 0.0883293\tvalid_1's rmse: 0.0930234\n",
      "[1975]\ttraining's rmse: 0.0883251\tvalid_1's rmse: 0.0930213\n",
      "[2000]\ttraining's rmse: 0.0883197\tvalid_1's rmse: 0.0930201\n",
      "[2025]\ttraining's rmse: 0.0883155\tvalid_1's rmse: 0.0930187\n",
      "[2050]\ttraining's rmse: 0.0883103\tvalid_1's rmse: 0.0930162\n",
      "[2075]\ttraining's rmse: 0.0883052\tvalid_1's rmse: 0.0930156\n",
      "[2100]\ttraining's rmse: 0.0883009\tvalid_1's rmse: 0.0930151\n",
      "[2125]\ttraining's rmse: 0.0882961\tvalid_1's rmse: 0.0930136\n",
      "[2150]\ttraining's rmse: 0.0882904\tvalid_1's rmse: 0.0930128\n",
      "[2175]\ttraining's rmse: 0.0882838\tvalid_1's rmse: 0.0930119\n",
      "[2200]\ttraining's rmse: 0.0882792\tvalid_1's rmse: 0.0930105\n",
      "[2225]\ttraining's rmse: 0.0882749\tvalid_1's rmse: 0.0930099\n",
      "[2250]\ttraining's rmse: 0.0882717\tvalid_1's rmse: 0.0930089\n",
      "[2275]\ttraining's rmse: 0.0882687\tvalid_1's rmse: 0.0930079\n",
      "[2300]\ttraining's rmse: 0.0882643\tvalid_1's rmse: 0.0930071\n",
      "[2325]\ttraining's rmse: 0.0882601\tvalid_1's rmse: 0.0930067\n",
      "[2350]\ttraining's rmse: 0.0882569\tvalid_1's rmse: 0.0930061\n",
      "[2375]\ttraining's rmse: 0.0882532\tvalid_1's rmse: 0.0930049\n",
      "[2400]\ttraining's rmse: 0.0882504\tvalid_1's rmse: 0.0930045\n",
      "[2425]\ttraining's rmse: 0.0882467\tvalid_1's rmse: 0.0930036\n",
      "[2450]\ttraining's rmse: 0.0882429\tvalid_1's rmse: 0.0930028\n",
      "[2475]\ttraining's rmse: 0.0882398\tvalid_1's rmse: 0.0930027\n",
      "[2500]\ttraining's rmse: 0.0882365\tvalid_1's rmse: 0.0930014\n",
      "[2525]\ttraining's rmse: 0.088233\tvalid_1's rmse: 0.0930009\n",
      "[2550]\ttraining's rmse: 0.0882294\tvalid_1's rmse: 0.0930003\n",
      "[2575]\ttraining's rmse: 0.0882275\tvalid_1's rmse: 0.0930003\n",
      "[2600]\ttraining's rmse: 0.0882238\tvalid_1's rmse: 0.0929995\n",
      "[2625]\ttraining's rmse: 0.0882221\tvalid_1's rmse: 0.0929983\n",
      "[2650]\ttraining's rmse: 0.0882203\tvalid_1's rmse: 0.0929972\n",
      "[2675]\ttraining's rmse: 0.0882176\tvalid_1's rmse: 0.0929965\n",
      "[2700]\ttraining's rmse: 0.0882147\tvalid_1's rmse: 0.0929962\n",
      "[2725]\ttraining's rmse: 0.0882116\tvalid_1's rmse: 0.0929952\n",
      "[2750]\ttraining's rmse: 0.0882098\tvalid_1's rmse: 0.0929948\n",
      "[2775]\ttraining's rmse: 0.0882075\tvalid_1's rmse: 0.0929937\n",
      "[2800]\ttraining's rmse: 0.0882061\tvalid_1's rmse: 0.0929941\n",
      "[2825]\ttraining's rmse: 0.0882029\tvalid_1's rmse: 0.0929938\n",
      "[2850]\ttraining's rmse: 0.0881996\tvalid_1's rmse: 0.0929931\n",
      "[2875]\ttraining's rmse: 0.0881968\tvalid_1's rmse: 0.0929931\n",
      "[2900]\ttraining's rmse: 0.0881957\tvalid_1's rmse: 0.0929926\n",
      "[2925]\ttraining's rmse: 0.0881938\tvalid_1's rmse: 0.0929925\n",
      "[2950]\ttraining's rmse: 0.0881921\tvalid_1's rmse: 0.092992\n",
      "[2975]\ttraining's rmse: 0.0881904\tvalid_1's rmse: 0.0929914\n",
      "[3000]\ttraining's rmse: 0.0881888\tvalid_1's rmse: 0.0929913\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0881888\tvalid_1's rmse: 0.0929913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0920082\tvalid_1's rmse: 0.0942812\n",
      "[50]\ttraining's rmse: 0.0918334\tvalid_1's rmse: 0.0942261\n",
      "[75]\ttraining's rmse: 0.0916537\tvalid_1's rmse: 0.0941729\n",
      "[100]\ttraining's rmse: 0.0914953\tvalid_1's rmse: 0.0941232\n",
      "[125]\ttraining's rmse: 0.0913325\tvalid_1's rmse: 0.0940729\n",
      "[150]\ttraining's rmse: 0.0911848\tvalid_1's rmse: 0.0940271\n",
      "[175]\ttraining's rmse: 0.091056\tvalid_1's rmse: 0.0939906\n",
      "[200]\ttraining's rmse: 0.0909245\tvalid_1's rmse: 0.093953\n",
      "[225]\ttraining's rmse: 0.0908028\tvalid_1's rmse: 0.0939172\n",
      "[250]\ttraining's rmse: 0.0906939\tvalid_1's rmse: 0.0938842\n",
      "[275]\ttraining's rmse: 0.0905926\tvalid_1's rmse: 0.0938552\n",
      "[300]\ttraining's rmse: 0.0904969\tvalid_1's rmse: 0.0938283\n",
      "[325]\ttraining's rmse: 0.0903977\tvalid_1's rmse: 0.0938017\n",
      "[350]\ttraining's rmse: 0.0903074\tvalid_1's rmse: 0.0937776\n",
      "[375]\ttraining's rmse: 0.0902297\tvalid_1's rmse: 0.0937562\n",
      "[400]\ttraining's rmse: 0.0901472\tvalid_1's rmse: 0.0937349\n",
      "[425]\ttraining's rmse: 0.0900708\tvalid_1's rmse: 0.0937148\n",
      "[450]\ttraining's rmse: 0.0900003\tvalid_1's rmse: 0.0936948\n",
      "[475]\ttraining's rmse: 0.0899374\tvalid_1's rmse: 0.0936773\n",
      "[500]\ttraining's rmse: 0.0898815\tvalid_1's rmse: 0.0936607\n",
      "[525]\ttraining's rmse: 0.0898121\tvalid_1's rmse: 0.0936446\n",
      "[550]\ttraining's rmse: 0.0897485\tvalid_1's rmse: 0.0936296\n",
      "[575]\ttraining's rmse: 0.0896907\tvalid_1's rmse: 0.0936144\n",
      "[600]\ttraining's rmse: 0.0896337\tvalid_1's rmse: 0.093602\n",
      "[625]\ttraining's rmse: 0.0895875\tvalid_1's rmse: 0.0935896\n",
      "[650]\ttraining's rmse: 0.0895331\tvalid_1's rmse: 0.0935776\n",
      "[675]\ttraining's rmse: 0.0894811\tvalid_1's rmse: 0.0935669\n",
      "[700]\ttraining's rmse: 0.0894331\tvalid_1's rmse: 0.0935559\n",
      "[725]\ttraining's rmse: 0.0893899\tvalid_1's rmse: 0.0935466\n",
      "[750]\ttraining's rmse: 0.0893476\tvalid_1's rmse: 0.0935374\n",
      "[775]\ttraining's rmse: 0.0893129\tvalid_1's rmse: 0.0935284\n",
      "[800]\ttraining's rmse: 0.0892679\tvalid_1's rmse: 0.0935206\n",
      "[825]\ttraining's rmse: 0.0892315\tvalid_1's rmse: 0.093512\n",
      "[850]\ttraining's rmse: 0.0891972\tvalid_1's rmse: 0.0935054\n",
      "[875]\ttraining's rmse: 0.0891633\tvalid_1's rmse: 0.0934989\n",
      "[900]\ttraining's rmse: 0.0891278\tvalid_1's rmse: 0.0934917\n",
      "[925]\ttraining's rmse: 0.0890921\tvalid_1's rmse: 0.093485\n",
      "[950]\ttraining's rmse: 0.0890599\tvalid_1's rmse: 0.0934782\n",
      "[975]\ttraining's rmse: 0.0890324\tvalid_1's rmse: 0.0934725\n",
      "[1000]\ttraining's rmse: 0.0890061\tvalid_1's rmse: 0.0934667\n",
      "[1025]\ttraining's rmse: 0.0889761\tvalid_1's rmse: 0.0934617\n",
      "[1050]\ttraining's rmse: 0.0889499\tvalid_1's rmse: 0.0934572\n",
      "[1075]\ttraining's rmse: 0.0889221\tvalid_1's rmse: 0.0934533\n",
      "[1100]\ttraining's rmse: 0.0889021\tvalid_1's rmse: 0.0934489\n",
      "[1125]\ttraining's rmse: 0.0888763\tvalid_1's rmse: 0.0934447\n",
      "[1150]\ttraining's rmse: 0.088852\tvalid_1's rmse: 0.0934411\n",
      "[1175]\ttraining's rmse: 0.0888334\tvalid_1's rmse: 0.0934387\n",
      "[1200]\ttraining's rmse: 0.0888138\tvalid_1's rmse: 0.0934353\n",
      "[1225]\ttraining's rmse: 0.088793\tvalid_1's rmse: 0.0934331\n",
      "[1250]\ttraining's rmse: 0.0887732\tvalid_1's rmse: 0.093431\n",
      "[1275]\ttraining's rmse: 0.0887513\tvalid_1's rmse: 0.0934293\n",
      "[1300]\ttraining's rmse: 0.0887354\tvalid_1's rmse: 0.093427\n",
      "[1325]\ttraining's rmse: 0.0887172\tvalid_1's rmse: 0.0934252\n",
      "[1350]\ttraining's rmse: 0.0887013\tvalid_1's rmse: 0.0934238\n",
      "[1375]\ttraining's rmse: 0.0886843\tvalid_1's rmse: 0.0934215\n",
      "[1400]\ttraining's rmse: 0.0886717\tvalid_1's rmse: 0.0934197\n",
      "[1425]\ttraining's rmse: 0.0886542\tvalid_1's rmse: 0.093418\n",
      "[1450]\ttraining's rmse: 0.0886378\tvalid_1's rmse: 0.0934167\n",
      "[1475]\ttraining's rmse: 0.0886247\tvalid_1's rmse: 0.093414\n",
      "[1500]\ttraining's rmse: 0.0886136\tvalid_1's rmse: 0.0934127\n",
      "[1525]\ttraining's rmse: 0.0886008\tvalid_1's rmse: 0.0934119\n",
      "[1550]\ttraining's rmse: 0.088586\tvalid_1's rmse: 0.0934109\n",
      "[1575]\ttraining's rmse: 0.0885734\tvalid_1's rmse: 0.0934094\n",
      "[1600]\ttraining's rmse: 0.0885631\tvalid_1's rmse: 0.0934085\n",
      "[1625]\ttraining's rmse: 0.0885514\tvalid_1's rmse: 0.0934075\n",
      "[1650]\ttraining's rmse: 0.0885425\tvalid_1's rmse: 0.0934072\n",
      "[1675]\ttraining's rmse: 0.0885353\tvalid_1's rmse: 0.0934059\n",
      "[1700]\ttraining's rmse: 0.088526\tvalid_1's rmse: 0.0934048\n",
      "[1725]\ttraining's rmse: 0.0885142\tvalid_1's rmse: 0.0934031\n",
      "[1750]\ttraining's rmse: 0.0885057\tvalid_1's rmse: 0.0934022\n",
      "[1775]\ttraining's rmse: 0.0884969\tvalid_1's rmse: 0.093401\n",
      "[1800]\ttraining's rmse: 0.0884879\tvalid_1's rmse: 0.0934002\n",
      "[1825]\ttraining's rmse: 0.0884804\tvalid_1's rmse: 0.0933998\n",
      "[1850]\ttraining's rmse: 0.0884728\tvalid_1's rmse: 0.0933989\n",
      "[1875]\ttraining's rmse: 0.0884659\tvalid_1's rmse: 0.0933984\n",
      "[1900]\ttraining's rmse: 0.0884587\tvalid_1's rmse: 0.0933979\n",
      "[1925]\ttraining's rmse: 0.0884524\tvalid_1's rmse: 0.0933978\n",
      "[1950]\ttraining's rmse: 0.0884474\tvalid_1's rmse: 0.0933973\n",
      "[1975]\ttraining's rmse: 0.0884411\tvalid_1's rmse: 0.0933966\n",
      "[2000]\ttraining's rmse: 0.0884351\tvalid_1's rmse: 0.0933955\n",
      "[2025]\ttraining's rmse: 0.0884299\tvalid_1's rmse: 0.0933949\n",
      "[2050]\ttraining's rmse: 0.088425\tvalid_1's rmse: 0.0933947\n",
      "[2075]\ttraining's rmse: 0.0884209\tvalid_1's rmse: 0.093394\n",
      "[2100]\ttraining's rmse: 0.0884148\tvalid_1's rmse: 0.0933938\n",
      "[2125]\ttraining's rmse: 0.0884116\tvalid_1's rmse: 0.0933935\n",
      "[2150]\ttraining's rmse: 0.0884073\tvalid_1's rmse: 0.0933933\n",
      "[2175]\ttraining's rmse: 0.0884044\tvalid_1's rmse: 0.0933933\n",
      "[2200]\ttraining's rmse: 0.0883993\tvalid_1's rmse: 0.093393\n",
      "[2225]\ttraining's rmse: 0.0883947\tvalid_1's rmse: 0.0933926\n",
      "[2250]\ttraining's rmse: 0.0883907\tvalid_1's rmse: 0.0933929\n",
      "Early stopping, best iteration is:\n",
      "[2211]\ttraining's rmse: 0.088397\tvalid_1's rmse: 0.0933926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0939952\tvalid_1's rmse: 0.0903463\n",
      "[50]\ttraining's rmse: 0.0938566\tvalid_1's rmse: 0.0902982\n",
      "[75]\ttraining's rmse: 0.0937094\tvalid_1's rmse: 0.0902494\n",
      "[100]\ttraining's rmse: 0.0935769\tvalid_1's rmse: 0.0902035\n",
      "[125]\ttraining's rmse: 0.093441\tvalid_1's rmse: 0.090159\n",
      "[150]\ttraining's rmse: 0.0933136\tvalid_1's rmse: 0.0901174\n",
      "[175]\ttraining's rmse: 0.0932097\tvalid_1's rmse: 0.0900854\n",
      "[200]\ttraining's rmse: 0.0930965\tvalid_1's rmse: 0.0900543\n",
      "[225]\ttraining's rmse: 0.0929863\tvalid_1's rmse: 0.0900252\n",
      "[250]\ttraining's rmse: 0.0928911\tvalid_1's rmse: 0.0899988\n",
      "[275]\ttraining's rmse: 0.0928059\tvalid_1's rmse: 0.0899732\n",
      "[300]\ttraining's rmse: 0.0927198\tvalid_1's rmse: 0.0899504\n",
      "[325]\ttraining's rmse: 0.0926331\tvalid_1's rmse: 0.0899285\n",
      "[350]\ttraining's rmse: 0.0925501\tvalid_1's rmse: 0.0899063\n",
      "[375]\ttraining's rmse: 0.0924795\tvalid_1's rmse: 0.0898894\n",
      "[400]\ttraining's rmse: 0.092404\tvalid_1's rmse: 0.0898706\n",
      "[425]\ttraining's rmse: 0.0923337\tvalid_1's rmse: 0.0898555\n",
      "[450]\ttraining's rmse: 0.0922702\tvalid_1's rmse: 0.0898418\n",
      "[475]\ttraining's rmse: 0.0922086\tvalid_1's rmse: 0.0898288\n",
      "[500]\ttraining's rmse: 0.0921606\tvalid_1's rmse: 0.0898153\n",
      "[525]\ttraining's rmse: 0.0920941\tvalid_1's rmse: 0.0898018\n",
      "[550]\ttraining's rmse: 0.0920351\tvalid_1's rmse: 0.0897891\n",
      "[575]\ttraining's rmse: 0.0919794\tvalid_1's rmse: 0.0897809\n",
      "[600]\ttraining's rmse: 0.0919222\tvalid_1's rmse: 0.0897729\n",
      "[625]\ttraining's rmse: 0.0918779\tvalid_1's rmse: 0.0897646\n",
      "[650]\ttraining's rmse: 0.0918238\tvalid_1's rmse: 0.0897599\n",
      "[675]\ttraining's rmse: 0.0917678\tvalid_1's rmse: 0.0897536\n",
      "[700]\ttraining's rmse: 0.0917213\tvalid_1's rmse: 0.0897471\n",
      "[725]\ttraining's rmse: 0.0916769\tvalid_1's rmse: 0.0897467\n",
      "[750]\ttraining's rmse: 0.0916341\tvalid_1's rmse: 0.0897424\n",
      "[775]\ttraining's rmse: 0.0915987\tvalid_1's rmse: 0.0897479\n",
      "[800]\ttraining's rmse: 0.0915548\tvalid_1's rmse: 0.0897428\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's rmse: 0.091632\tvalid_1's rmse: 0.0897423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0911458\tvalid_1's rmse: 0.0934884\n",
      "[50]\ttraining's rmse: 0.0909907\tvalid_1's rmse: 0.0934308\n",
      "[75]\ttraining's rmse: 0.0908365\tvalid_1's rmse: 0.0933718\n",
      "[100]\ttraining's rmse: 0.0906922\tvalid_1's rmse: 0.0933231\n",
      "[125]\ttraining's rmse: 0.0905486\tvalid_1's rmse: 0.093273\n",
      "[150]\ttraining's rmse: 0.0904135\tvalid_1's rmse: 0.0932254\n",
      "[175]\ttraining's rmse: 0.0903032\tvalid_1's rmse: 0.0931861\n",
      "[200]\ttraining's rmse: 0.0901863\tvalid_1's rmse: 0.093149\n",
      "[225]\ttraining's rmse: 0.0900715\tvalid_1's rmse: 0.0931114\n",
      "[250]\ttraining's rmse: 0.0899746\tvalid_1's rmse: 0.093076\n",
      "[275]\ttraining's rmse: 0.0898866\tvalid_1's rmse: 0.0930454\n",
      "[300]\ttraining's rmse: 0.0897914\tvalid_1's rmse: 0.0930148\n",
      "[325]\ttraining's rmse: 0.0897021\tvalid_1's rmse: 0.0929872\n",
      "[350]\ttraining's rmse: 0.0896155\tvalid_1's rmse: 0.0929603\n",
      "[375]\ttraining's rmse: 0.0895388\tvalid_1's rmse: 0.0929375\n",
      "[400]\ttraining's rmse: 0.0894627\tvalid_1's rmse: 0.0929143\n",
      "[425]\ttraining's rmse: 0.0893892\tvalid_1's rmse: 0.0928919\n",
      "[450]\ttraining's rmse: 0.0893252\tvalid_1's rmse: 0.0928693\n",
      "[475]\ttraining's rmse: 0.0892647\tvalid_1's rmse: 0.0928498\n",
      "[500]\ttraining's rmse: 0.0892122\tvalid_1's rmse: 0.0928314\n",
      "[525]\ttraining's rmse: 0.089151\tvalid_1's rmse: 0.0928136\n",
      "[550]\ttraining's rmse: 0.0890929\tvalid_1's rmse: 0.0927973\n",
      "[575]\ttraining's rmse: 0.0890383\tvalid_1's rmse: 0.0927834\n",
      "[600]\ttraining's rmse: 0.0889867\tvalid_1's rmse: 0.0927677\n",
      "[625]\ttraining's rmse: 0.0889419\tvalid_1's rmse: 0.092755\n",
      "[650]\ttraining's rmse: 0.088892\tvalid_1's rmse: 0.0927437\n",
      "[675]\ttraining's rmse: 0.0888416\tvalid_1's rmse: 0.0927315\n",
      "[700]\ttraining's rmse: 0.0887994\tvalid_1's rmse: 0.0927203\n",
      "[725]\ttraining's rmse: 0.0887578\tvalid_1's rmse: 0.0927084\n",
      "[750]\ttraining's rmse: 0.0887157\tvalid_1's rmse: 0.0926976\n",
      "[775]\ttraining's rmse: 0.0886854\tvalid_1's rmse: 0.0926862\n",
      "[800]\ttraining's rmse: 0.0886462\tvalid_1's rmse: 0.0926781\n",
      "[825]\ttraining's rmse: 0.0886094\tvalid_1's rmse: 0.092668\n",
      "[850]\ttraining's rmse: 0.0885738\tvalid_1's rmse: 0.0926591\n",
      "[875]\ttraining's rmse: 0.0885429\tvalid_1's rmse: 0.0926502\n",
      "[900]\ttraining's rmse: 0.088509\tvalid_1's rmse: 0.0926406\n",
      "[925]\ttraining's rmse: 0.0884799\tvalid_1's rmse: 0.092634\n",
      "[950]\ttraining's rmse: 0.0884518\tvalid_1's rmse: 0.0926256\n",
      "[975]\ttraining's rmse: 0.0884242\tvalid_1's rmse: 0.0926185\n",
      "[1000]\ttraining's rmse: 0.0883969\tvalid_1's rmse: 0.0926122\n",
      "[1025]\ttraining's rmse: 0.088368\tvalid_1's rmse: 0.0926052\n",
      "[1050]\ttraining's rmse: 0.0883435\tvalid_1's rmse: 0.092598\n",
      "[1075]\ttraining's rmse: 0.0883169\tvalid_1's rmse: 0.092594\n",
      "[1100]\ttraining's rmse: 0.0882952\tvalid_1's rmse: 0.0925888\n",
      "[1125]\ttraining's rmse: 0.0882732\tvalid_1's rmse: 0.0925832\n",
      "[1150]\ttraining's rmse: 0.0882509\tvalid_1's rmse: 0.0925782\n",
      "[1175]\ttraining's rmse: 0.0882304\tvalid_1's rmse: 0.0925743\n",
      "[1200]\ttraining's rmse: 0.0882122\tvalid_1's rmse: 0.0925684\n",
      "[1225]\ttraining's rmse: 0.0881929\tvalid_1's rmse: 0.0925648\n",
      "[1250]\ttraining's rmse: 0.0881754\tvalid_1's rmse: 0.0925612\n",
      "[1275]\ttraining's rmse: 0.0881556\tvalid_1's rmse: 0.0925581\n",
      "[1300]\ttraining's rmse: 0.088139\tvalid_1's rmse: 0.0925531\n",
      "[1325]\ttraining's rmse: 0.0881244\tvalid_1's rmse: 0.0925508\n",
      "[1350]\ttraining's rmse: 0.0881098\tvalid_1's rmse: 0.0925462\n",
      "[1375]\ttraining's rmse: 0.0880941\tvalid_1's rmse: 0.0925426\n",
      "[1400]\ttraining's rmse: 0.088081\tvalid_1's rmse: 0.0925392\n",
      "[1425]\ttraining's rmse: 0.0880649\tvalid_1's rmse: 0.0925362\n",
      "[1450]\ttraining's rmse: 0.0880502\tvalid_1's rmse: 0.0925337\n",
      "[1475]\ttraining's rmse: 0.088039\tvalid_1's rmse: 0.0925314\n",
      "[1500]\ttraining's rmse: 0.0880261\tvalid_1's rmse: 0.0925271\n",
      "[1525]\ttraining's rmse: 0.0880145\tvalid_1's rmse: 0.092524\n",
      "[1550]\ttraining's rmse: 0.088\tvalid_1's rmse: 0.0925216\n",
      "[1575]\ttraining's rmse: 0.0879904\tvalid_1's rmse: 0.0925196\n",
      "[1600]\ttraining's rmse: 0.0879818\tvalid_1's rmse: 0.0925174\n",
      "[1625]\ttraining's rmse: 0.0879738\tvalid_1's rmse: 0.0925139\n",
      "[1650]\ttraining's rmse: 0.087964\tvalid_1's rmse: 0.0925125\n",
      "[1675]\ttraining's rmse: 0.0879564\tvalid_1's rmse: 0.0925096\n",
      "[1700]\ttraining's rmse: 0.0879474\tvalid_1's rmse: 0.0925064\n",
      "[1725]\ttraining's rmse: 0.087939\tvalid_1's rmse: 0.0925038\n",
      "[1750]\ttraining's rmse: 0.0879303\tvalid_1's rmse: 0.0925022\n",
      "[1775]\ttraining's rmse: 0.0879224\tvalid_1's rmse: 0.0925005\n",
      "[1800]\ttraining's rmse: 0.0879138\tvalid_1's rmse: 0.0924976\n",
      "[1825]\ttraining's rmse: 0.0879067\tvalid_1's rmse: 0.092495\n",
      "[1850]\ttraining's rmse: 0.0879001\tvalid_1's rmse: 0.0924932\n",
      "[1875]\ttraining's rmse: 0.087894\tvalid_1's rmse: 0.0924918\n",
      "[1900]\ttraining's rmse: 0.0878887\tvalid_1's rmse: 0.0924902\n",
      "[1925]\ttraining's rmse: 0.0878835\tvalid_1's rmse: 0.0924884\n",
      "[1950]\ttraining's rmse: 0.0878775\tvalid_1's rmse: 0.0924861\n",
      "[1975]\ttraining's rmse: 0.0878733\tvalid_1's rmse: 0.0924849\n",
      "[2000]\ttraining's rmse: 0.0878692\tvalid_1's rmse: 0.0924838\n",
      "[2025]\ttraining's rmse: 0.0878645\tvalid_1's rmse: 0.0924814\n",
      "[2050]\ttraining's rmse: 0.0878599\tvalid_1's rmse: 0.0924796\n",
      "[2075]\ttraining's rmse: 0.0878567\tvalid_1's rmse: 0.0924782\n",
      "[2100]\ttraining's rmse: 0.0878524\tvalid_1's rmse: 0.0924775\n",
      "[2125]\ttraining's rmse: 0.087849\tvalid_1's rmse: 0.0924767\n",
      "[2150]\ttraining's rmse: 0.0878446\tvalid_1's rmse: 0.0924752\n",
      "[2175]\ttraining's rmse: 0.0878402\tvalid_1's rmse: 0.0924745\n",
      "[2200]\ttraining's rmse: 0.087837\tvalid_1's rmse: 0.0924727\n",
      "[2225]\ttraining's rmse: 0.0878336\tvalid_1's rmse: 0.092472\n",
      "[2250]\ttraining's rmse: 0.0878309\tvalid_1's rmse: 0.0924709\n",
      "[2275]\ttraining's rmse: 0.0878279\tvalid_1's rmse: 0.092471\n",
      "[2300]\ttraining's rmse: 0.0878238\tvalid_1's rmse: 0.0924705\n",
      "[2325]\ttraining's rmse: 0.0878182\tvalid_1's rmse: 0.0924693\n",
      "[2350]\ttraining's rmse: 0.0878157\tvalid_1's rmse: 0.092469\n",
      "[2375]\ttraining's rmse: 0.087813\tvalid_1's rmse: 0.092468\n",
      "[2400]\ttraining's rmse: 0.0878082\tvalid_1's rmse: 0.0924674\n",
      "[2425]\ttraining's rmse: 0.0878052\tvalid_1's rmse: 0.0924663\n",
      "[2450]\ttraining's rmse: 0.0878034\tvalid_1's rmse: 0.0924658\n",
      "[2475]\ttraining's rmse: 0.0878003\tvalid_1's rmse: 0.0924656\n",
      "[2500]\ttraining's rmse: 0.0877957\tvalid_1's rmse: 0.0924646\n",
      "[2525]\ttraining's rmse: 0.087793\tvalid_1's rmse: 0.0924642\n",
      "[2550]\ttraining's rmse: 0.087789\tvalid_1's rmse: 0.0924639\n",
      "[2575]\ttraining's rmse: 0.087787\tvalid_1's rmse: 0.0924634\n",
      "[2600]\ttraining's rmse: 0.0877838\tvalid_1's rmse: 0.0924631\n",
      "[2625]\ttraining's rmse: 0.0877824\tvalid_1's rmse: 0.0924616\n",
      "[2650]\ttraining's rmse: 0.0877795\tvalid_1's rmse: 0.0924606\n",
      "[2675]\ttraining's rmse: 0.0877772\tvalid_1's rmse: 0.0924602\n",
      "[2700]\ttraining's rmse: 0.0877752\tvalid_1's rmse: 0.0924593\n",
      "[2725]\ttraining's rmse: 0.0877728\tvalid_1's rmse: 0.0924586\n",
      "[2750]\ttraining's rmse: 0.087771\tvalid_1's rmse: 0.0924581\n",
      "[2775]\ttraining's rmse: 0.0877684\tvalid_1's rmse: 0.0924581\n",
      "[2800]\ttraining's rmse: 0.0877657\tvalid_1's rmse: 0.0924576\n",
      "[2825]\ttraining's rmse: 0.087764\tvalid_1's rmse: 0.092458\n",
      "[2850]\ttraining's rmse: 0.0877622\tvalid_1's rmse: 0.0924579\n",
      "Early stopping, best iteration is:\n",
      "[2807]\ttraining's rmse: 0.0877655\tvalid_1's rmse: 0.0924573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0910645\tvalid_1's rmse: 0.0936755\n",
      "[50]\ttraining's rmse: 0.0909279\tvalid_1's rmse: 0.0936193\n",
      "[75]\ttraining's rmse: 0.0907802\tvalid_1's rmse: 0.0935643\n",
      "[100]\ttraining's rmse: 0.0906522\tvalid_1's rmse: 0.0935156\n",
      "[125]\ttraining's rmse: 0.0905185\tvalid_1's rmse: 0.0934663\n",
      "[150]\ttraining's rmse: 0.0903943\tvalid_1's rmse: 0.0934193\n",
      "[175]\ttraining's rmse: 0.0902938\tvalid_1's rmse: 0.0933817\n",
      "[200]\ttraining's rmse: 0.0901888\tvalid_1's rmse: 0.0933455\n",
      "[225]\ttraining's rmse: 0.0900825\tvalid_1's rmse: 0.0933096\n",
      "[250]\ttraining's rmse: 0.0899906\tvalid_1's rmse: 0.0932766\n",
      "[275]\ttraining's rmse: 0.0899033\tvalid_1's rmse: 0.0932471\n",
      "[300]\ttraining's rmse: 0.0898196\tvalid_1's rmse: 0.0932186\n",
      "[325]\ttraining's rmse: 0.0897363\tvalid_1's rmse: 0.0931932\n",
      "[350]\ttraining's rmse: 0.0896579\tvalid_1's rmse: 0.093169\n",
      "[375]\ttraining's rmse: 0.0895898\tvalid_1's rmse: 0.0931461\n",
      "[400]\ttraining's rmse: 0.0895164\tvalid_1's rmse: 0.0931255\n",
      "[425]\ttraining's rmse: 0.0894482\tvalid_1's rmse: 0.093104\n",
      "[450]\ttraining's rmse: 0.0893863\tvalid_1's rmse: 0.0930849\n",
      "[475]\ttraining's rmse: 0.089327\tvalid_1's rmse: 0.0930674\n",
      "[500]\ttraining's rmse: 0.0892777\tvalid_1's rmse: 0.093051\n",
      "[525]\ttraining's rmse: 0.0892174\tvalid_1's rmse: 0.0930352\n",
      "[550]\ttraining's rmse: 0.0891584\tvalid_1's rmse: 0.0930207\n",
      "[575]\ttraining's rmse: 0.0891042\tvalid_1's rmse: 0.0930074\n",
      "[600]\ttraining's rmse: 0.0890535\tvalid_1's rmse: 0.0929942\n",
      "[625]\ttraining's rmse: 0.0890126\tvalid_1's rmse: 0.0929823\n",
      "[650]\ttraining's rmse: 0.0889607\tvalid_1's rmse: 0.0929708\n",
      "[675]\ttraining's rmse: 0.0889086\tvalid_1's rmse: 0.0929595\n",
      "[700]\ttraining's rmse: 0.0888638\tvalid_1's rmse: 0.0929491\n",
      "[725]\ttraining's rmse: 0.0888206\tvalid_1's rmse: 0.0929388\n",
      "[750]\ttraining's rmse: 0.0887815\tvalid_1's rmse: 0.0929291\n",
      "[775]\ttraining's rmse: 0.0887484\tvalid_1's rmse: 0.0929207\n",
      "[800]\ttraining's rmse: 0.0887041\tvalid_1's rmse: 0.0929118\n",
      "[825]\ttraining's rmse: 0.0886679\tvalid_1's rmse: 0.0929044\n",
      "[850]\ttraining's rmse: 0.0886321\tvalid_1's rmse: 0.0928983\n",
      "[875]\ttraining's rmse: 0.0885987\tvalid_1's rmse: 0.0928926\n",
      "[900]\ttraining's rmse: 0.0885658\tvalid_1's rmse: 0.0928861\n",
      "[925]\ttraining's rmse: 0.0885347\tvalid_1's rmse: 0.092881\n",
      "[950]\ttraining's rmse: 0.0885042\tvalid_1's rmse: 0.0928754\n",
      "[975]\ttraining's rmse: 0.0884769\tvalid_1's rmse: 0.0928705\n",
      "[1000]\ttraining's rmse: 0.0884517\tvalid_1's rmse: 0.0928658\n",
      "[1025]\ttraining's rmse: 0.0884199\tvalid_1's rmse: 0.0928617\n",
      "[1050]\ttraining's rmse: 0.0883937\tvalid_1's rmse: 0.0928572\n",
      "[1075]\ttraining's rmse: 0.088368\tvalid_1's rmse: 0.0928544\n",
      "[1100]\ttraining's rmse: 0.0883466\tvalid_1's rmse: 0.0928505\n",
      "[1125]\ttraining's rmse: 0.088323\tvalid_1's rmse: 0.092847\n",
      "[1150]\ttraining's rmse: 0.0882993\tvalid_1's rmse: 0.0928444\n",
      "[1175]\ttraining's rmse: 0.08828\tvalid_1's rmse: 0.0928421\n",
      "[1200]\ttraining's rmse: 0.0882592\tvalid_1's rmse: 0.092839\n",
      "[1225]\ttraining's rmse: 0.0882396\tvalid_1's rmse: 0.0928362\n",
      "[1250]\ttraining's rmse: 0.0882227\tvalid_1's rmse: 0.0928337\n",
      "[1275]\ttraining's rmse: 0.0882027\tvalid_1's rmse: 0.0928316\n",
      "[1300]\ttraining's rmse: 0.0881861\tvalid_1's rmse: 0.0928291\n",
      "[1325]\ttraining's rmse: 0.0881705\tvalid_1's rmse: 0.0928275\n",
      "[1350]\ttraining's rmse: 0.0881536\tvalid_1's rmse: 0.0928272\n",
      "[1375]\ttraining's rmse: 0.0881348\tvalid_1's rmse: 0.0928257\n",
      "[1400]\ttraining's rmse: 0.0881211\tvalid_1's rmse: 0.0928244\n",
      "[1425]\ttraining's rmse: 0.0881067\tvalid_1's rmse: 0.0928226\n",
      "[1450]\ttraining's rmse: 0.0880894\tvalid_1's rmse: 0.0928212\n",
      "[1475]\ttraining's rmse: 0.0880753\tvalid_1's rmse: 0.0928192\n",
      "[1500]\ttraining's rmse: 0.0880617\tvalid_1's rmse: 0.0928185\n",
      "[1525]\ttraining's rmse: 0.0880473\tvalid_1's rmse: 0.0928175\n",
      "[1550]\ttraining's rmse: 0.0880347\tvalid_1's rmse: 0.0928166\n",
      "[1575]\ttraining's rmse: 0.0880201\tvalid_1's rmse: 0.0928158\n",
      "[1600]\ttraining's rmse: 0.0880088\tvalid_1's rmse: 0.0928151\n",
      "[1625]\ttraining's rmse: 0.0879975\tvalid_1's rmse: 0.0928142\n",
      "[1650]\ttraining's rmse: 0.0879849\tvalid_1's rmse: 0.0928135\n",
      "[1675]\ttraining's rmse: 0.0879783\tvalid_1's rmse: 0.092812\n",
      "[1700]\ttraining's rmse: 0.0879701\tvalid_1's rmse: 0.0928108\n",
      "[1725]\ttraining's rmse: 0.0879619\tvalid_1's rmse: 0.0928101\n",
      "[1750]\ttraining's rmse: 0.0879531\tvalid_1's rmse: 0.0928095\n",
      "[1775]\ttraining's rmse: 0.0879463\tvalid_1's rmse: 0.0928091\n",
      "[1800]\ttraining's rmse: 0.0879392\tvalid_1's rmse: 0.0928087\n",
      "[1825]\ttraining's rmse: 0.0879317\tvalid_1's rmse: 0.0928083\n",
      "[1850]\ttraining's rmse: 0.0879252\tvalid_1's rmse: 0.0928074\n",
      "[1875]\ttraining's rmse: 0.0879185\tvalid_1's rmse: 0.0928073\n",
      "[1900]\ttraining's rmse: 0.0879127\tvalid_1's rmse: 0.0928069\n",
      "[1925]\ttraining's rmse: 0.087908\tvalid_1's rmse: 0.0928065\n",
      "[1950]\ttraining's rmse: 0.0879029\tvalid_1's rmse: 0.0928063\n",
      "[1975]\ttraining's rmse: 0.0878991\tvalid_1's rmse: 0.0928059\n",
      "[2000]\ttraining's rmse: 0.0878936\tvalid_1's rmse: 0.0928055\n",
      "[2025]\ttraining's rmse: 0.0878872\tvalid_1's rmse: 0.0928051\n",
      "[2050]\ttraining's rmse: 0.0878823\tvalid_1's rmse: 0.092805\n",
      "[2075]\ttraining's rmse: 0.0878784\tvalid_1's rmse: 0.0928042\n",
      "[2100]\ttraining's rmse: 0.0878744\tvalid_1's rmse: 0.092804\n",
      "[2125]\ttraining's rmse: 0.0878691\tvalid_1's rmse: 0.0928036\n",
      "[2150]\ttraining's rmse: 0.0878643\tvalid_1's rmse: 0.0928032\n",
      "[2175]\ttraining's rmse: 0.0878605\tvalid_1's rmse: 0.0928031\n",
      "[2200]\ttraining's rmse: 0.0878568\tvalid_1's rmse: 0.0928027\n",
      "[2225]\ttraining's rmse: 0.0878526\tvalid_1's rmse: 0.0928024\n",
      "[2250]\ttraining's rmse: 0.0878484\tvalid_1's rmse: 0.0928025\n",
      "[2275]\ttraining's rmse: 0.0878435\tvalid_1's rmse: 0.0928026\n",
      "[2300]\ttraining's rmse: 0.0878403\tvalid_1's rmse: 0.0928024\n",
      "[2325]\ttraining's rmse: 0.0878371\tvalid_1's rmse: 0.0928028\n",
      "Early stopping, best iteration is:\n",
      "[2284]\ttraining's rmse: 0.0878428\tvalid_1's rmse: 0.0928024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0934377\tvalid_1's rmse: 0.0888626\n",
      "[50]\ttraining's rmse: 0.0933007\tvalid_1's rmse: 0.0888126\n",
      "[75]\ttraining's rmse: 0.0931605\tvalid_1's rmse: 0.0887629\n",
      "[100]\ttraining's rmse: 0.0930332\tvalid_1's rmse: 0.0887172\n",
      "[125]\ttraining's rmse: 0.0928998\tvalid_1's rmse: 0.0886718\n",
      "[150]\ttraining's rmse: 0.0927793\tvalid_1's rmse: 0.0886344\n",
      "[175]\ttraining's rmse: 0.0926774\tvalid_1's rmse: 0.088606\n",
      "[200]\ttraining's rmse: 0.0925702\tvalid_1's rmse: 0.0885781\n",
      "[225]\ttraining's rmse: 0.0924638\tvalid_1's rmse: 0.0885461\n",
      "[250]\ttraining's rmse: 0.0923699\tvalid_1's rmse: 0.0885185\n",
      "[275]\ttraining's rmse: 0.0922882\tvalid_1's rmse: 0.0884927\n",
      "[300]\ttraining's rmse: 0.0922056\tvalid_1's rmse: 0.0884693\n",
      "[325]\ttraining's rmse: 0.0921213\tvalid_1's rmse: 0.0884441\n",
      "[350]\ttraining's rmse: 0.09204\tvalid_1's rmse: 0.0884204\n",
      "[375]\ttraining's rmse: 0.0919725\tvalid_1's rmse: 0.0884066\n",
      "[400]\ttraining's rmse: 0.0918996\tvalid_1's rmse: 0.088392\n",
      "[425]\ttraining's rmse: 0.0918313\tvalid_1's rmse: 0.0883738\n",
      "[450]\ttraining's rmse: 0.0917699\tvalid_1's rmse: 0.0883574\n",
      "[475]\ttraining's rmse: 0.0917125\tvalid_1's rmse: 0.0883433\n",
      "[500]\ttraining's rmse: 0.0916644\tvalid_1's rmse: 0.0883293\n",
      "[525]\ttraining's rmse: 0.0915984\tvalid_1's rmse: 0.0883157\n",
      "[550]\ttraining's rmse: 0.0915403\tvalid_1's rmse: 0.0883031\n",
      "[575]\ttraining's rmse: 0.0914865\tvalid_1's rmse: 0.0882917\n",
      "[600]\ttraining's rmse: 0.0914329\tvalid_1's rmse: 0.0882807\n",
      "[625]\ttraining's rmse: 0.0913908\tvalid_1's rmse: 0.0882713\n",
      "[650]\ttraining's rmse: 0.0913348\tvalid_1's rmse: 0.0882754\n",
      "[675]\ttraining's rmse: 0.0912807\tvalid_1's rmse: 0.0882811\n",
      "Early stopping, best iteration is:\n",
      "[639]\ttraining's rmse: 0.091362\tvalid_1's rmse: 0.0882651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0928521\tvalid_1's rmse: 0.0948762\n",
      "[50]\ttraining's rmse: 0.0926481\tvalid_1's rmse: 0.0948228\n",
      "[75]\ttraining's rmse: 0.0924557\tvalid_1's rmse: 0.09477\n",
      "[100]\ttraining's rmse: 0.0922754\tvalid_1's rmse: 0.0947224\n",
      "[125]\ttraining's rmse: 0.0920969\tvalid_1's rmse: 0.0946763\n",
      "[150]\ttraining's rmse: 0.0919338\tvalid_1's rmse: 0.0946324\n",
      "[175]\ttraining's rmse: 0.0917894\tvalid_1's rmse: 0.0945933\n",
      "[200]\ttraining's rmse: 0.0916415\tvalid_1's rmse: 0.094555\n",
      "[225]\ttraining's rmse: 0.0915018\tvalid_1's rmse: 0.0945185\n",
      "[250]\ttraining's rmse: 0.0913845\tvalid_1's rmse: 0.0944848\n",
      "[275]\ttraining's rmse: 0.0912723\tvalid_1's rmse: 0.0944539\n",
      "[300]\ttraining's rmse: 0.0911584\tvalid_1's rmse: 0.0944257\n",
      "[325]\ttraining's rmse: 0.0910507\tvalid_1's rmse: 0.0943999\n",
      "[350]\ttraining's rmse: 0.0909466\tvalid_1's rmse: 0.0943757\n",
      "[375]\ttraining's rmse: 0.0908553\tvalid_1's rmse: 0.0943527\n",
      "[400]\ttraining's rmse: 0.0907607\tvalid_1's rmse: 0.0943298\n",
      "[425]\ttraining's rmse: 0.0906759\tvalid_1's rmse: 0.0943077\n",
      "[450]\ttraining's rmse: 0.0905976\tvalid_1's rmse: 0.094284\n",
      "[475]\ttraining's rmse: 0.0905249\tvalid_1's rmse: 0.0942651\n",
      "[500]\ttraining's rmse: 0.090461\tvalid_1's rmse: 0.0942487\n",
      "[525]\ttraining's rmse: 0.0903873\tvalid_1's rmse: 0.0942297\n",
      "[550]\ttraining's rmse: 0.0903212\tvalid_1's rmse: 0.0942147\n",
      "[575]\ttraining's rmse: 0.09026\tvalid_1's rmse: 0.0942035\n",
      "[600]\ttraining's rmse: 0.0902005\tvalid_1's rmse: 0.0941898\n",
      "[625]\ttraining's rmse: 0.0901516\tvalid_1's rmse: 0.0941772\n",
      "[650]\ttraining's rmse: 0.0900953\tvalid_1's rmse: 0.0941632\n",
      "[675]\ttraining's rmse: 0.0900397\tvalid_1's rmse: 0.0941489\n",
      "[700]\ttraining's rmse: 0.0899878\tvalid_1's rmse: 0.0941377\n",
      "[725]\ttraining's rmse: 0.089943\tvalid_1's rmse: 0.0941267\n",
      "[750]\ttraining's rmse: 0.0899018\tvalid_1's rmse: 0.094116\n",
      "[775]\ttraining's rmse: 0.0898639\tvalid_1's rmse: 0.094104\n",
      "[800]\ttraining's rmse: 0.0898179\tvalid_1's rmse: 0.0940964\n",
      "[825]\ttraining's rmse: 0.0897822\tvalid_1's rmse: 0.0940879\n",
      "[850]\ttraining's rmse: 0.0897443\tvalid_1's rmse: 0.094081\n",
      "[875]\ttraining's rmse: 0.0897096\tvalid_1's rmse: 0.0940738\n",
      "[900]\ttraining's rmse: 0.08967\tvalid_1's rmse: 0.0940652\n",
      "[925]\ttraining's rmse: 0.089634\tvalid_1's rmse: 0.0940575\n",
      "[950]\ttraining's rmse: 0.0896026\tvalid_1's rmse: 0.094049\n",
      "[975]\ttraining's rmse: 0.0895724\tvalid_1's rmse: 0.0940432\n",
      "[1000]\ttraining's rmse: 0.0895435\tvalid_1's rmse: 0.0940374\n",
      "[1025]\ttraining's rmse: 0.0895142\tvalid_1's rmse: 0.0940311\n",
      "[1050]\ttraining's rmse: 0.0894884\tvalid_1's rmse: 0.0940228\n",
      "[1075]\ttraining's rmse: 0.0894641\tvalid_1's rmse: 0.0940172\n",
      "[1100]\ttraining's rmse: 0.089442\tvalid_1's rmse: 0.0940123\n",
      "[1125]\ttraining's rmse: 0.0894194\tvalid_1's rmse: 0.0940062\n",
      "[1150]\ttraining's rmse: 0.0893948\tvalid_1's rmse: 0.0940011\n",
      "[1175]\ttraining's rmse: 0.0893732\tvalid_1's rmse: 0.0939976\n",
      "[1200]\ttraining's rmse: 0.0893519\tvalid_1's rmse: 0.0939919\n",
      "[1225]\ttraining's rmse: 0.0893308\tvalid_1's rmse: 0.0939874\n",
      "[1250]\ttraining's rmse: 0.0893123\tvalid_1's rmse: 0.0939841\n",
      "[1275]\ttraining's rmse: 0.0892914\tvalid_1's rmse: 0.0939816\n",
      "[1300]\ttraining's rmse: 0.0892771\tvalid_1's rmse: 0.0939773\n",
      "[1325]\ttraining's rmse: 0.0892606\tvalid_1's rmse: 0.0939737\n",
      "[1350]\ttraining's rmse: 0.0892438\tvalid_1's rmse: 0.09397\n",
      "[1375]\ttraining's rmse: 0.0892266\tvalid_1's rmse: 0.0939672\n",
      "[1400]\ttraining's rmse: 0.0892142\tvalid_1's rmse: 0.0939643\n",
      "[1425]\ttraining's rmse: 0.0891943\tvalid_1's rmse: 0.0939594\n",
      "[1450]\ttraining's rmse: 0.0891756\tvalid_1's rmse: 0.0939561\n",
      "[1475]\ttraining's rmse: 0.0891616\tvalid_1's rmse: 0.0939529\n",
      "[1500]\ttraining's rmse: 0.0891477\tvalid_1's rmse: 0.09395\n",
      "[1525]\ttraining's rmse: 0.0891329\tvalid_1's rmse: 0.0939488\n",
      "[1550]\ttraining's rmse: 0.089118\tvalid_1's rmse: 0.093947\n",
      "[1575]\ttraining's rmse: 0.0891074\tvalid_1's rmse: 0.0939445\n",
      "[1600]\ttraining's rmse: 0.0890976\tvalid_1's rmse: 0.0939413\n",
      "[1625]\ttraining's rmse: 0.0890866\tvalid_1's rmse: 0.0939389\n",
      "[1650]\ttraining's rmse: 0.0890766\tvalid_1's rmse: 0.0939354\n",
      "[1675]\ttraining's rmse: 0.089067\tvalid_1's rmse: 0.0939333\n",
      "[1700]\ttraining's rmse: 0.0890578\tvalid_1's rmse: 0.09393\n",
      "[1725]\ttraining's rmse: 0.0890487\tvalid_1's rmse: 0.0939287\n",
      "[1750]\ttraining's rmse: 0.0890389\tvalid_1's rmse: 0.0939262\n",
      "[1775]\ttraining's rmse: 0.0890305\tvalid_1's rmse: 0.0939242\n",
      "[1800]\ttraining's rmse: 0.0890208\tvalid_1's rmse: 0.0939212\n",
      "[1825]\ttraining's rmse: 0.0890136\tvalid_1's rmse: 0.0939194\n",
      "[1850]\ttraining's rmse: 0.0890057\tvalid_1's rmse: 0.0939175\n",
      "[1875]\ttraining's rmse: 0.0889988\tvalid_1's rmse: 0.0939164\n",
      "[1900]\ttraining's rmse: 0.0889933\tvalid_1's rmse: 0.093916\n",
      "[1925]\ttraining's rmse: 0.0889871\tvalid_1's rmse: 0.0939143\n",
      "[1950]\ttraining's rmse: 0.0889802\tvalid_1's rmse: 0.0939128\n",
      "[1975]\ttraining's rmse: 0.0889752\tvalid_1's rmse: 0.0939114\n",
      "[2000]\ttraining's rmse: 0.0889707\tvalid_1's rmse: 0.09391\n",
      "[2025]\ttraining's rmse: 0.088967\tvalid_1's rmse: 0.0939078\n",
      "[2050]\ttraining's rmse: 0.0889621\tvalid_1's rmse: 0.0939069\n",
      "[2075]\ttraining's rmse: 0.0889585\tvalid_1's rmse: 0.0939058\n",
      "[2100]\ttraining's rmse: 0.0889532\tvalid_1's rmse: 0.0939046\n",
      "[2125]\ttraining's rmse: 0.0889496\tvalid_1's rmse: 0.0939023\n",
      "[2150]\ttraining's rmse: 0.0889455\tvalid_1's rmse: 0.0939008\n",
      "[2175]\ttraining's rmse: 0.0889428\tvalid_1's rmse: 0.0938992\n",
      "[2200]\ttraining's rmse: 0.0889388\tvalid_1's rmse: 0.093898\n",
      "[2225]\ttraining's rmse: 0.0889357\tvalid_1's rmse: 0.0938972\n",
      "[2250]\ttraining's rmse: 0.0889303\tvalid_1's rmse: 0.093896\n",
      "[2275]\ttraining's rmse: 0.0889236\tvalid_1's rmse: 0.0938952\n",
      "[2300]\ttraining's rmse: 0.0889186\tvalid_1's rmse: 0.0938942\n",
      "[2325]\ttraining's rmse: 0.0889134\tvalid_1's rmse: 0.0938932\n",
      "[2350]\ttraining's rmse: 0.0889093\tvalid_1's rmse: 0.0938925\n",
      "[2375]\ttraining's rmse: 0.0889063\tvalid_1's rmse: 0.0938919\n",
      "[2400]\ttraining's rmse: 0.088902\tvalid_1's rmse: 0.093891\n",
      "[2425]\ttraining's rmse: 0.088898\tvalid_1's rmse: 0.09389\n",
      "[2450]\ttraining's rmse: 0.0888959\tvalid_1's rmse: 0.0938896\n",
      "[2475]\ttraining's rmse: 0.0888928\tvalid_1's rmse: 0.0938885\n",
      "[2500]\ttraining's rmse: 0.0888901\tvalid_1's rmse: 0.0938885\n",
      "[2525]\ttraining's rmse: 0.0888866\tvalid_1's rmse: 0.0938871\n",
      "[2550]\ttraining's rmse: 0.0888841\tvalid_1's rmse: 0.0938867\n",
      "[2575]\ttraining's rmse: 0.0888813\tvalid_1's rmse: 0.0938862\n",
      "[2600]\ttraining's rmse: 0.0888786\tvalid_1's rmse: 0.0938858\n",
      "[2625]\ttraining's rmse: 0.0888765\tvalid_1's rmse: 0.0938843\n",
      "[2650]\ttraining's rmse: 0.088875\tvalid_1's rmse: 0.0938839\n",
      "[2675]\ttraining's rmse: 0.088873\tvalid_1's rmse: 0.0938837\n",
      "[2700]\ttraining's rmse: 0.0888704\tvalid_1's rmse: 0.093882\n",
      "[2725]\ttraining's rmse: 0.0888671\tvalid_1's rmse: 0.0938817\n",
      "[2750]\ttraining's rmse: 0.0888648\tvalid_1's rmse: 0.0938815\n",
      "[2775]\ttraining's rmse: 0.0888634\tvalid_1's rmse: 0.0938815\n",
      "Early stopping, best iteration is:\n",
      "[2741]\ttraining's rmse: 0.0888654\tvalid_1's rmse: 0.0938812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0929351\tvalid_1's rmse: 0.0947328\n",
      "[50]\ttraining's rmse: 0.0927529\tvalid_1's rmse: 0.0946757\n",
      "[75]\ttraining's rmse: 0.0925659\tvalid_1's rmse: 0.0946187\n",
      "[100]\ttraining's rmse: 0.0924001\tvalid_1's rmse: 0.094569\n",
      "[125]\ttraining's rmse: 0.0922335\tvalid_1's rmse: 0.0945203\n",
      "[150]\ttraining's rmse: 0.0920816\tvalid_1's rmse: 0.094474\n",
      "[175]\ttraining's rmse: 0.0919529\tvalid_1's rmse: 0.0944359\n",
      "[200]\ttraining's rmse: 0.0918145\tvalid_1's rmse: 0.094398\n",
      "[225]\ttraining's rmse: 0.0916874\tvalid_1's rmse: 0.0943624\n",
      "[250]\ttraining's rmse: 0.0915741\tvalid_1's rmse: 0.0943301\n",
      "[275]\ttraining's rmse: 0.0914686\tvalid_1's rmse: 0.0943004\n",
      "[300]\ttraining's rmse: 0.0913682\tvalid_1's rmse: 0.0942729\n",
      "[325]\ttraining's rmse: 0.0912674\tvalid_1's rmse: 0.094246\n",
      "[350]\ttraining's rmse: 0.0911705\tvalid_1's rmse: 0.0942214\n",
      "[375]\ttraining's rmse: 0.0910919\tvalid_1's rmse: 0.0942\n",
      "[400]\ttraining's rmse: 0.0910061\tvalid_1's rmse: 0.0941802\n",
      "[425]\ttraining's rmse: 0.0909259\tvalid_1's rmse: 0.0941606\n",
      "[450]\ttraining's rmse: 0.0908531\tvalid_1's rmse: 0.0941425\n",
      "[475]\ttraining's rmse: 0.0907875\tvalid_1's rmse: 0.0941265\n",
      "[500]\ttraining's rmse: 0.0907293\tvalid_1's rmse: 0.0941094\n",
      "[525]\ttraining's rmse: 0.0906576\tvalid_1's rmse: 0.0940939\n",
      "[550]\ttraining's rmse: 0.0905923\tvalid_1's rmse: 0.09408\n",
      "[575]\ttraining's rmse: 0.090533\tvalid_1's rmse: 0.0940673\n",
      "[600]\ttraining's rmse: 0.0904759\tvalid_1's rmse: 0.0940538\n",
      "[625]\ttraining's rmse: 0.090429\tvalid_1's rmse: 0.0940433\n",
      "[650]\ttraining's rmse: 0.0903718\tvalid_1's rmse: 0.0940299\n",
      "[675]\ttraining's rmse: 0.0903181\tvalid_1's rmse: 0.094018\n",
      "[700]\ttraining's rmse: 0.0902695\tvalid_1's rmse: 0.0940082\n",
      "[725]\ttraining's rmse: 0.0902273\tvalid_1's rmse: 0.0939991\n",
      "[750]\ttraining's rmse: 0.0901836\tvalid_1's rmse: 0.0939893\n",
      "[775]\ttraining's rmse: 0.0901463\tvalid_1's rmse: 0.0939797\n",
      "[800]\ttraining's rmse: 0.0901007\tvalid_1's rmse: 0.0939697\n",
      "[825]\ttraining's rmse: 0.0900666\tvalid_1's rmse: 0.0939631\n",
      "[850]\ttraining's rmse: 0.0900288\tvalid_1's rmse: 0.093956\n",
      "[875]\ttraining's rmse: 0.0899953\tvalid_1's rmse: 0.09395\n",
      "[900]\ttraining's rmse: 0.0899599\tvalid_1's rmse: 0.0939438\n",
      "[925]\ttraining's rmse: 0.0899252\tvalid_1's rmse: 0.0939384\n",
      "[950]\ttraining's rmse: 0.0898948\tvalid_1's rmse: 0.0939329\n",
      "[975]\ttraining's rmse: 0.089863\tvalid_1's rmse: 0.0939279\n",
      "[1000]\ttraining's rmse: 0.0898351\tvalid_1's rmse: 0.093923\n",
      "[1025]\ttraining's rmse: 0.089804\tvalid_1's rmse: 0.0939184\n",
      "[1050]\ttraining's rmse: 0.0897777\tvalid_1's rmse: 0.0939144\n",
      "[1075]\ttraining's rmse: 0.0897518\tvalid_1's rmse: 0.0939112\n",
      "[1100]\ttraining's rmse: 0.0897312\tvalid_1's rmse: 0.0939079\n",
      "[1125]\ttraining's rmse: 0.0897075\tvalid_1's rmse: 0.0939051\n",
      "[1150]\ttraining's rmse: 0.0896839\tvalid_1's rmse: 0.0939032\n",
      "[1175]\ttraining's rmse: 0.0896625\tvalid_1's rmse: 0.0939018\n",
      "[1200]\ttraining's rmse: 0.0896413\tvalid_1's rmse: 0.0938989\n",
      "[1225]\ttraining's rmse: 0.0896223\tvalid_1's rmse: 0.0938964\n",
      "[1250]\ttraining's rmse: 0.0896055\tvalid_1's rmse: 0.0938947\n",
      "[1275]\ttraining's rmse: 0.0895864\tvalid_1's rmse: 0.0938927\n",
      "[1300]\ttraining's rmse: 0.0895684\tvalid_1's rmse: 0.0938905\n",
      "[1325]\ttraining's rmse: 0.0895475\tvalid_1's rmse: 0.0938886\n",
      "[1350]\ttraining's rmse: 0.0895283\tvalid_1's rmse: 0.0938865\n",
      "[1375]\ttraining's rmse: 0.0895104\tvalid_1's rmse: 0.0938858\n",
      "[1400]\ttraining's rmse: 0.0894949\tvalid_1's rmse: 0.0938837\n",
      "[1425]\ttraining's rmse: 0.08948\tvalid_1's rmse: 0.0938821\n",
      "[1450]\ttraining's rmse: 0.0894639\tvalid_1's rmse: 0.0938808\n",
      "[1475]\ttraining's rmse: 0.0894493\tvalid_1's rmse: 0.0938787\n",
      "[1500]\ttraining's rmse: 0.0894375\tvalid_1's rmse: 0.0938774\n",
      "[1525]\ttraining's rmse: 0.0894235\tvalid_1's rmse: 0.0938773\n",
      "[1550]\ttraining's rmse: 0.0894113\tvalid_1's rmse: 0.0938765\n",
      "[1575]\ttraining's rmse: 0.0893983\tvalid_1's rmse: 0.0938747\n",
      "[1600]\ttraining's rmse: 0.089387\tvalid_1's rmse: 0.0938739\n",
      "[1625]\ttraining's rmse: 0.0893774\tvalid_1's rmse: 0.0938722\n",
      "[1650]\ttraining's rmse: 0.0893658\tvalid_1's rmse: 0.0938714\n",
      "[1675]\ttraining's rmse: 0.089357\tvalid_1's rmse: 0.0938708\n",
      "[1700]\ttraining's rmse: 0.0893482\tvalid_1's rmse: 0.0938696\n",
      "[1725]\ttraining's rmse: 0.0893383\tvalid_1's rmse: 0.0938692\n",
      "[1750]\ttraining's rmse: 0.0893282\tvalid_1's rmse: 0.0938696\n",
      "[1775]\ttraining's rmse: 0.0893204\tvalid_1's rmse: 0.0938684\n",
      "[1800]\ttraining's rmse: 0.0893122\tvalid_1's rmse: 0.0938681\n",
      "[1825]\ttraining's rmse: 0.0893042\tvalid_1's rmse: 0.0938682\n",
      "[1850]\ttraining's rmse: 0.0892964\tvalid_1's rmse: 0.0938674\n",
      "[1875]\ttraining's rmse: 0.0892901\tvalid_1's rmse: 0.0938664\n",
      "[1900]\ttraining's rmse: 0.0892841\tvalid_1's rmse: 0.0938663\n",
      "[1925]\ttraining's rmse: 0.0892772\tvalid_1's rmse: 0.093866\n",
      "[1950]\ttraining's rmse: 0.0892729\tvalid_1's rmse: 0.0938655\n",
      "[1975]\ttraining's rmse: 0.0892678\tvalid_1's rmse: 0.0938647\n",
      "[2000]\ttraining's rmse: 0.0892608\tvalid_1's rmse: 0.0938641\n",
      "[2025]\ttraining's rmse: 0.0892549\tvalid_1's rmse: 0.0938636\n",
      "[2050]\ttraining's rmse: 0.089248\tvalid_1's rmse: 0.0938629\n",
      "[2075]\ttraining's rmse: 0.0892433\tvalid_1's rmse: 0.0938627\n",
      "[2100]\ttraining's rmse: 0.0892391\tvalid_1's rmse: 0.0938624\n",
      "[2125]\ttraining's rmse: 0.0892357\tvalid_1's rmse: 0.0938623\n",
      "[2150]\ttraining's rmse: 0.0892319\tvalid_1's rmse: 0.0938618\n",
      "[2175]\ttraining's rmse: 0.089227\tvalid_1's rmse: 0.0938618\n",
      "[2200]\ttraining's rmse: 0.0892233\tvalid_1's rmse: 0.093862\n",
      "[2225]\ttraining's rmse: 0.0892191\tvalid_1's rmse: 0.0938615\n",
      "[2250]\ttraining's rmse: 0.0892152\tvalid_1's rmse: 0.0938609\n",
      "[2275]\ttraining's rmse: 0.0892102\tvalid_1's rmse: 0.0938603\n",
      "[2300]\ttraining's rmse: 0.0892058\tvalid_1's rmse: 0.0938599\n",
      "[2325]\ttraining's rmse: 0.0892012\tvalid_1's rmse: 0.0938599\n",
      "[2350]\ttraining's rmse: 0.0891983\tvalid_1's rmse: 0.0938601\n",
      "Early stopping, best iteration is:\n",
      "[2318]\ttraining's rmse: 0.0892027\tvalid_1's rmse: 0.0938598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0946508\tvalid_1's rmse: 0.0913327\n",
      "[50]\ttraining's rmse: 0.0945125\tvalid_1's rmse: 0.0912821\n",
      "[75]\ttraining's rmse: 0.0943663\tvalid_1's rmse: 0.0912306\n",
      "[100]\ttraining's rmse: 0.0942331\tvalid_1's rmse: 0.0911867\n",
      "[125]\ttraining's rmse: 0.094095\tvalid_1's rmse: 0.091143\n",
      "[150]\ttraining's rmse: 0.093972\tvalid_1's rmse: 0.0911032\n",
      "[175]\ttraining's rmse: 0.0938683\tvalid_1's rmse: 0.0910727\n",
      "[200]\ttraining's rmse: 0.093753\tvalid_1's rmse: 0.0910401\n",
      "[225]\ttraining's rmse: 0.0936417\tvalid_1's rmse: 0.0910076\n",
      "[250]\ttraining's rmse: 0.0935448\tvalid_1's rmse: 0.0909806\n",
      "[275]\ttraining's rmse: 0.0934614\tvalid_1's rmse: 0.0909554\n",
      "[300]\ttraining's rmse: 0.0933729\tvalid_1's rmse: 0.0909315\n",
      "[325]\ttraining's rmse: 0.0932854\tvalid_1's rmse: 0.0909103\n",
      "[350]\ttraining's rmse: 0.0932022\tvalid_1's rmse: 0.0908886\n",
      "[375]\ttraining's rmse: 0.093132\tvalid_1's rmse: 0.0908713\n",
      "[400]\ttraining's rmse: 0.0930565\tvalid_1's rmse: 0.0908519\n",
      "[425]\ttraining's rmse: 0.092984\tvalid_1's rmse: 0.0908352\n",
      "[450]\ttraining's rmse: 0.0929165\tvalid_1's rmse: 0.0908224\n",
      "[475]\ttraining's rmse: 0.0928537\tvalid_1's rmse: 0.0908082\n",
      "[500]\ttraining's rmse: 0.0928028\tvalid_1's rmse: 0.0907938\n",
      "[525]\ttraining's rmse: 0.0927333\tvalid_1's rmse: 0.0907805\n",
      "[550]\ttraining's rmse: 0.0926755\tvalid_1's rmse: 0.090766\n",
      "[575]\ttraining's rmse: 0.0926184\tvalid_1's rmse: 0.0907561\n",
      "[600]\ttraining's rmse: 0.0925613\tvalid_1's rmse: 0.0907555\n",
      "[625]\ttraining's rmse: 0.0925174\tvalid_1's rmse: 0.0907458\n",
      "[650]\ttraining's rmse: 0.0924618\tvalid_1's rmse: 0.090743\n",
      "[675]\ttraining's rmse: 0.0924087\tvalid_1's rmse: 0.0907349\n",
      "[700]\ttraining's rmse: 0.0923606\tvalid_1's rmse: 0.0907285\n",
      "[725]\ttraining's rmse: 0.0923168\tvalid_1's rmse: 0.0907281\n",
      "[750]\ttraining's rmse: 0.0922762\tvalid_1's rmse: 0.0907233\n",
      "[775]\ttraining's rmse: 0.0922392\tvalid_1's rmse: 0.0907241\n",
      "[800]\ttraining's rmse: 0.0921927\tvalid_1's rmse: 0.0907205\n",
      "[825]\ttraining's rmse: 0.0921524\tvalid_1's rmse: 0.0907212\n",
      "[850]\ttraining's rmse: 0.0921133\tvalid_1's rmse: 0.0907164\n",
      "[875]\ttraining's rmse: 0.0920783\tvalid_1's rmse: 0.0907235\n",
      "[900]\ttraining's rmse: 0.0920395\tvalid_1's rmse: 0.0907255\n",
      "Early stopping, best iteration is:\n",
      "[872]\ttraining's rmse: 0.0920806\tvalid_1's rmse: 0.0907127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0914794\tvalid_1's rmse: 0.0939564\n",
      "[50]\ttraining's rmse: 0.0913233\tvalid_1's rmse: 0.0938973\n",
      "[75]\ttraining's rmse: 0.0911703\tvalid_1's rmse: 0.0938422\n",
      "[100]\ttraining's rmse: 0.0910231\tvalid_1's rmse: 0.0937933\n",
      "[125]\ttraining's rmse: 0.0908801\tvalid_1's rmse: 0.0937413\n",
      "[150]\ttraining's rmse: 0.0907471\tvalid_1's rmse: 0.0936943\n",
      "[175]\ttraining's rmse: 0.0906349\tvalid_1's rmse: 0.0936546\n",
      "[200]\ttraining's rmse: 0.0905177\tvalid_1's rmse: 0.093614\n",
      "[225]\ttraining's rmse: 0.0903992\tvalid_1's rmse: 0.0935756\n",
      "[250]\ttraining's rmse: 0.0903044\tvalid_1's rmse: 0.0935408\n",
      "[275]\ttraining's rmse: 0.0902109\tvalid_1's rmse: 0.0935096\n",
      "[300]\ttraining's rmse: 0.0901203\tvalid_1's rmse: 0.0934798\n",
      "[325]\ttraining's rmse: 0.0900319\tvalid_1's rmse: 0.0934509\n",
      "[350]\ttraining's rmse: 0.0899452\tvalid_1's rmse: 0.0934228\n",
      "[375]\ttraining's rmse: 0.089872\tvalid_1's rmse: 0.0933984\n",
      "[400]\ttraining's rmse: 0.089792\tvalid_1's rmse: 0.0933767\n",
      "[425]\ttraining's rmse: 0.0897187\tvalid_1's rmse: 0.0933553\n",
      "[450]\ttraining's rmse: 0.0896519\tvalid_1's rmse: 0.0933341\n",
      "[475]\ttraining's rmse: 0.0895878\tvalid_1's rmse: 0.0933152\n",
      "[500]\ttraining's rmse: 0.0895324\tvalid_1's rmse: 0.0932939\n",
      "[525]\ttraining's rmse: 0.0894692\tvalid_1's rmse: 0.0932772\n",
      "[550]\ttraining's rmse: 0.0894081\tvalid_1's rmse: 0.0932612\n",
      "[575]\ttraining's rmse: 0.0893535\tvalid_1's rmse: 0.0932483\n",
      "[600]\ttraining's rmse: 0.0893038\tvalid_1's rmse: 0.0932354\n",
      "[625]\ttraining's rmse: 0.08926\tvalid_1's rmse: 0.0932222\n",
      "[650]\ttraining's rmse: 0.0892076\tvalid_1's rmse: 0.0932062\n",
      "[675]\ttraining's rmse: 0.0891567\tvalid_1's rmse: 0.0931934\n",
      "[700]\ttraining's rmse: 0.0891126\tvalid_1's rmse: 0.0931816\n",
      "[725]\ttraining's rmse: 0.0890706\tvalid_1's rmse: 0.0931705\n",
      "[750]\ttraining's rmse: 0.0890283\tvalid_1's rmse: 0.0931607\n",
      "[775]\ttraining's rmse: 0.088997\tvalid_1's rmse: 0.093149\n",
      "[800]\ttraining's rmse: 0.0889576\tvalid_1's rmse: 0.0931403\n",
      "[825]\ttraining's rmse: 0.0889231\tvalid_1's rmse: 0.0931302\n",
      "[850]\ttraining's rmse: 0.0888858\tvalid_1's rmse: 0.0931216\n",
      "[875]\ttraining's rmse: 0.0888537\tvalid_1's rmse: 0.0931141\n",
      "[900]\ttraining's rmse: 0.088819\tvalid_1's rmse: 0.0931068\n",
      "[925]\ttraining's rmse: 0.0887858\tvalid_1's rmse: 0.0930972\n",
      "[950]\ttraining's rmse: 0.0887568\tvalid_1's rmse: 0.0930905\n",
      "[975]\ttraining's rmse: 0.0887331\tvalid_1's rmse: 0.0930833\n",
      "[1000]\ttraining's rmse: 0.088706\tvalid_1's rmse: 0.0930752\n",
      "[1025]\ttraining's rmse: 0.0886806\tvalid_1's rmse: 0.093069\n",
      "[1050]\ttraining's rmse: 0.0886596\tvalid_1's rmse: 0.0930614\n",
      "[1075]\ttraining's rmse: 0.0886341\tvalid_1's rmse: 0.0930554\n",
      "[1100]\ttraining's rmse: 0.0886137\tvalid_1's rmse: 0.0930499\n",
      "[1125]\ttraining's rmse: 0.0885931\tvalid_1's rmse: 0.0930439\n",
      "[1150]\ttraining's rmse: 0.0885711\tvalid_1's rmse: 0.0930384\n",
      "[1175]\ttraining's rmse: 0.0885534\tvalid_1's rmse: 0.0930355\n",
      "[1200]\ttraining's rmse: 0.0885344\tvalid_1's rmse: 0.0930297\n",
      "[1225]\ttraining's rmse: 0.0885152\tvalid_1's rmse: 0.0930256\n",
      "[1250]\ttraining's rmse: 0.0884982\tvalid_1's rmse: 0.0930202\n",
      "[1275]\ttraining's rmse: 0.088477\tvalid_1's rmse: 0.0930162\n",
      "[1300]\ttraining's rmse: 0.0884635\tvalid_1's rmse: 0.0930117\n",
      "[1325]\ttraining's rmse: 0.0884492\tvalid_1's rmse: 0.0930089\n",
      "[1350]\ttraining's rmse: 0.0884312\tvalid_1's rmse: 0.0930063\n",
      "[1375]\ttraining's rmse: 0.088416\tvalid_1's rmse: 0.0930024\n",
      "[1400]\ttraining's rmse: 0.0884056\tvalid_1's rmse: 0.0929996\n",
      "[1425]\ttraining's rmse: 0.0883888\tvalid_1's rmse: 0.0929965\n",
      "[1450]\ttraining's rmse: 0.0883725\tvalid_1's rmse: 0.0929925\n",
      "[1475]\ttraining's rmse: 0.0883578\tvalid_1's rmse: 0.0929892\n",
      "[1500]\ttraining's rmse: 0.0883454\tvalid_1's rmse: 0.092987\n",
      "[1525]\ttraining's rmse: 0.0883344\tvalid_1's rmse: 0.0929843\n",
      "[1550]\ttraining's rmse: 0.0883232\tvalid_1's rmse: 0.0929824\n",
      "[1575]\ttraining's rmse: 0.0883124\tvalid_1's rmse: 0.0929806\n",
      "[1600]\ttraining's rmse: 0.0883034\tvalid_1's rmse: 0.0929783\n",
      "[1625]\ttraining's rmse: 0.0882941\tvalid_1's rmse: 0.0929758\n",
      "[1650]\ttraining's rmse: 0.0882877\tvalid_1's rmse: 0.0929738\n",
      "[1675]\ttraining's rmse: 0.0882813\tvalid_1's rmse: 0.0929717\n",
      "[1700]\ttraining's rmse: 0.0882722\tvalid_1's rmse: 0.0929691\n",
      "[1725]\ttraining's rmse: 0.0882639\tvalid_1's rmse: 0.0929669\n",
      "[1750]\ttraining's rmse: 0.0882552\tvalid_1's rmse: 0.0929659\n",
      "[1775]\ttraining's rmse: 0.0882473\tvalid_1's rmse: 0.0929628\n",
      "[1800]\ttraining's rmse: 0.0882405\tvalid_1's rmse: 0.0929613\n",
      "[1825]\ttraining's rmse: 0.0882338\tvalid_1's rmse: 0.0929613\n",
      "[1850]\ttraining's rmse: 0.0882264\tvalid_1's rmse: 0.0929579\n",
      "[1875]\ttraining's rmse: 0.0882197\tvalid_1's rmse: 0.0929568\n",
      "[1900]\ttraining's rmse: 0.0882128\tvalid_1's rmse: 0.0929552\n",
      "[1925]\ttraining's rmse: 0.0882053\tvalid_1's rmse: 0.0929543\n",
      "[1950]\ttraining's rmse: 0.0882016\tvalid_1's rmse: 0.0929517\n",
      "[1975]\ttraining's rmse: 0.0881961\tvalid_1's rmse: 0.0929499\n",
      "[2000]\ttraining's rmse: 0.0881928\tvalid_1's rmse: 0.0929485\n",
      "[2025]\ttraining's rmse: 0.0881886\tvalid_1's rmse: 0.0929471\n",
      "[2050]\ttraining's rmse: 0.0881829\tvalid_1's rmse: 0.0929452\n",
      "[2075]\ttraining's rmse: 0.0881793\tvalid_1's rmse: 0.092944\n",
      "[2100]\ttraining's rmse: 0.0881745\tvalid_1's rmse: 0.0929428\n",
      "[2125]\ttraining's rmse: 0.0881712\tvalid_1's rmse: 0.0929422\n",
      "[2150]\ttraining's rmse: 0.0881664\tvalid_1's rmse: 0.0929406\n",
      "[2175]\ttraining's rmse: 0.0881621\tvalid_1's rmse: 0.0929398\n",
      "[2200]\ttraining's rmse: 0.0881593\tvalid_1's rmse: 0.0929386\n",
      "[2225]\ttraining's rmse: 0.088155\tvalid_1's rmse: 0.0929381\n",
      "[2250]\ttraining's rmse: 0.0881508\tvalid_1's rmse: 0.0929375\n",
      "[2275]\ttraining's rmse: 0.0881478\tvalid_1's rmse: 0.0929366\n",
      "[2300]\ttraining's rmse: 0.0881443\tvalid_1's rmse: 0.0929347\n",
      "[2325]\ttraining's rmse: 0.0881397\tvalid_1's rmse: 0.0929333\n",
      "[2350]\ttraining's rmse: 0.0881374\tvalid_1's rmse: 0.0929324\n",
      "[2375]\ttraining's rmse: 0.088135\tvalid_1's rmse: 0.0929315\n",
      "[2400]\ttraining's rmse: 0.0881304\tvalid_1's rmse: 0.0929314\n",
      "[2425]\ttraining's rmse: 0.0881287\tvalid_1's rmse: 0.0929307\n",
      "[2450]\ttraining's rmse: 0.0881258\tvalid_1's rmse: 0.0929303\n",
      "[2475]\ttraining's rmse: 0.0881227\tvalid_1's rmse: 0.0929304\n",
      "[2500]\ttraining's rmse: 0.0881202\tvalid_1's rmse: 0.0929296\n",
      "[2525]\ttraining's rmse: 0.0881165\tvalid_1's rmse: 0.0929291\n",
      "[2550]\ttraining's rmse: 0.0881149\tvalid_1's rmse: 0.0929292\n",
      "[2575]\ttraining's rmse: 0.0881114\tvalid_1's rmse: 0.0929279\n",
      "[2600]\ttraining's rmse: 0.088109\tvalid_1's rmse: 0.0929273\n",
      "[2625]\ttraining's rmse: 0.0881069\tvalid_1's rmse: 0.0929262\n",
      "[2650]\ttraining's rmse: 0.0881052\tvalid_1's rmse: 0.0929255\n",
      "[2675]\ttraining's rmse: 0.088102\tvalid_1's rmse: 0.092925\n",
      "[2700]\ttraining's rmse: 0.0881001\tvalid_1's rmse: 0.0929246\n",
      "[2725]\ttraining's rmse: 0.0880948\tvalid_1's rmse: 0.0929239\n",
      "[2750]\ttraining's rmse: 0.0880926\tvalid_1's rmse: 0.0929237\n",
      "[2775]\ttraining's rmse: 0.0880892\tvalid_1's rmse: 0.0929232\n",
      "[2800]\ttraining's rmse: 0.0880868\tvalid_1's rmse: 0.0929219\n",
      "[2825]\ttraining's rmse: 0.0880848\tvalid_1's rmse: 0.0929212\n",
      "[2850]\ttraining's rmse: 0.0880823\tvalid_1's rmse: 0.0929215\n",
      "Early stopping, best iteration is:\n",
      "[2814]\ttraining's rmse: 0.0880854\tvalid_1's rmse: 0.0929209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0915105\tvalid_1's rmse: 0.0939155\n",
      "[50]\ttraining's rmse: 0.0913701\tvalid_1's rmse: 0.0938585\n",
      "[75]\ttraining's rmse: 0.0912214\tvalid_1's rmse: 0.0938034\n",
      "[100]\ttraining's rmse: 0.0910899\tvalid_1's rmse: 0.0937537\n",
      "[125]\ttraining's rmse: 0.0909519\tvalid_1's rmse: 0.0937025\n",
      "[150]\ttraining's rmse: 0.0908276\tvalid_1's rmse: 0.0936562\n",
      "[175]\ttraining's rmse: 0.0907222\tvalid_1's rmse: 0.0936164\n",
      "[200]\ttraining's rmse: 0.0906086\tvalid_1's rmse: 0.09358\n",
      "[225]\ttraining's rmse: 0.0905026\tvalid_1's rmse: 0.0935446\n",
      "[250]\ttraining's rmse: 0.0904107\tvalid_1's rmse: 0.0935119\n",
      "[275]\ttraining's rmse: 0.0903241\tvalid_1's rmse: 0.093483\n",
      "[300]\ttraining's rmse: 0.0902403\tvalid_1's rmse: 0.0934558\n",
      "[325]\ttraining's rmse: 0.0901573\tvalid_1's rmse: 0.0934302\n",
      "[350]\ttraining's rmse: 0.0900762\tvalid_1's rmse: 0.093406\n",
      "[375]\ttraining's rmse: 0.0900104\tvalid_1's rmse: 0.0933846\n",
      "[400]\ttraining's rmse: 0.0899321\tvalid_1's rmse: 0.0933629\n",
      "[425]\ttraining's rmse: 0.0898638\tvalid_1's rmse: 0.0933413\n",
      "[450]\ttraining's rmse: 0.0898016\tvalid_1's rmse: 0.0933215\n",
      "[475]\ttraining's rmse: 0.0897427\tvalid_1's rmse: 0.0933036\n",
      "[500]\ttraining's rmse: 0.0896932\tvalid_1's rmse: 0.0932872\n",
      "[525]\ttraining's rmse: 0.0896297\tvalid_1's rmse: 0.0932712\n",
      "[550]\ttraining's rmse: 0.0895689\tvalid_1's rmse: 0.0932562\n",
      "[575]\ttraining's rmse: 0.0895156\tvalid_1's rmse: 0.0932423\n",
      "[600]\ttraining's rmse: 0.0894626\tvalid_1's rmse: 0.0932299\n",
      "[625]\ttraining's rmse: 0.0894207\tvalid_1's rmse: 0.0932192\n",
      "[650]\ttraining's rmse: 0.0893681\tvalid_1's rmse: 0.0932053\n",
      "[675]\ttraining's rmse: 0.0893153\tvalid_1's rmse: 0.0931943\n",
      "[700]\ttraining's rmse: 0.0892707\tvalid_1's rmse: 0.0931838\n",
      "[725]\ttraining's rmse: 0.0892289\tvalid_1's rmse: 0.0931744\n",
      "[750]\ttraining's rmse: 0.0891895\tvalid_1's rmse: 0.0931657\n",
      "[775]\ttraining's rmse: 0.0891549\tvalid_1's rmse: 0.0931563\n",
      "[800]\ttraining's rmse: 0.0891118\tvalid_1's rmse: 0.0931485\n",
      "[825]\ttraining's rmse: 0.0890758\tvalid_1's rmse: 0.0931413\n",
      "[850]\ttraining's rmse: 0.0890422\tvalid_1's rmse: 0.0931357\n",
      "[875]\ttraining's rmse: 0.0890113\tvalid_1's rmse: 0.0931296\n",
      "[900]\ttraining's rmse: 0.0889784\tvalid_1's rmse: 0.0931231\n",
      "[925]\ttraining's rmse: 0.0889462\tvalid_1's rmse: 0.093117\n",
      "[950]\ttraining's rmse: 0.0889162\tvalid_1's rmse: 0.0931119\n",
      "[975]\ttraining's rmse: 0.0888897\tvalid_1's rmse: 0.0931062\n",
      "[1000]\ttraining's rmse: 0.0888638\tvalid_1's rmse: 0.0931018\n",
      "[1025]\ttraining's rmse: 0.0888322\tvalid_1's rmse: 0.0930977\n",
      "[1050]\ttraining's rmse: 0.0888054\tvalid_1's rmse: 0.0930922\n",
      "[1075]\ttraining's rmse: 0.0887804\tvalid_1's rmse: 0.0930893\n",
      "[1100]\ttraining's rmse: 0.0887586\tvalid_1's rmse: 0.0930853\n",
      "[1125]\ttraining's rmse: 0.0887354\tvalid_1's rmse: 0.0930823\n",
      "[1150]\ttraining's rmse: 0.0887105\tvalid_1's rmse: 0.0930793\n",
      "[1175]\ttraining's rmse: 0.0886908\tvalid_1's rmse: 0.0930763\n",
      "[1200]\ttraining's rmse: 0.088668\tvalid_1's rmse: 0.0930737\n",
      "[1225]\ttraining's rmse: 0.0886487\tvalid_1's rmse: 0.0930714\n",
      "[1250]\ttraining's rmse: 0.0886318\tvalid_1's rmse: 0.0930691\n",
      "[1275]\ttraining's rmse: 0.0886119\tvalid_1's rmse: 0.0930675\n",
      "[1300]\ttraining's rmse: 0.0885965\tvalid_1's rmse: 0.0930651\n",
      "[1325]\ttraining's rmse: 0.0885783\tvalid_1's rmse: 0.0930634\n",
      "[1350]\ttraining's rmse: 0.0885595\tvalid_1's rmse: 0.0930619\n",
      "[1375]\ttraining's rmse: 0.0885439\tvalid_1's rmse: 0.0930607\n",
      "[1400]\ttraining's rmse: 0.0885286\tvalid_1's rmse: 0.0930589\n",
      "[1425]\ttraining's rmse: 0.0885144\tvalid_1's rmse: 0.0930582\n",
      "[1450]\ttraining's rmse: 0.0884992\tvalid_1's rmse: 0.093057\n",
      "[1475]\ttraining's rmse: 0.088485\tvalid_1's rmse: 0.0930561\n",
      "[1500]\ttraining's rmse: 0.0884697\tvalid_1's rmse: 0.0930543\n",
      "[1525]\ttraining's rmse: 0.0884567\tvalid_1's rmse: 0.093054\n",
      "[1550]\ttraining's rmse: 0.0884462\tvalid_1's rmse: 0.0930535\n",
      "[1575]\ttraining's rmse: 0.0884341\tvalid_1's rmse: 0.0930523\n",
      "[1600]\ttraining's rmse: 0.0884227\tvalid_1's rmse: 0.0930521\n",
      "[1625]\ttraining's rmse: 0.0884132\tvalid_1's rmse: 0.0930517\n",
      "[1650]\ttraining's rmse: 0.0884032\tvalid_1's rmse: 0.0930514\n",
      "[1675]\ttraining's rmse: 0.0883945\tvalid_1's rmse: 0.0930505\n",
      "[1700]\ttraining's rmse: 0.0883878\tvalid_1's rmse: 0.0930494\n",
      "[1725]\ttraining's rmse: 0.0883802\tvalid_1's rmse: 0.0930492\n",
      "[1750]\ttraining's rmse: 0.0883708\tvalid_1's rmse: 0.0930489\n",
      "[1775]\ttraining's rmse: 0.0883638\tvalid_1's rmse: 0.0930493\n",
      "[1800]\ttraining's rmse: 0.0883552\tvalid_1's rmse: 0.0930492\n",
      "Early stopping, best iteration is:\n",
      "[1752]\ttraining's rmse: 0.0883705\tvalid_1's rmse: 0.0930488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0937889\tvalid_1's rmse: 0.0892855\n",
      "[50]\ttraining's rmse: 0.0936545\tvalid_1's rmse: 0.0892352\n",
      "[75]\ttraining's rmse: 0.0935131\tvalid_1's rmse: 0.0891835\n",
      "[100]\ttraining's rmse: 0.093385\tvalid_1's rmse: 0.08914\n",
      "[125]\ttraining's rmse: 0.0932534\tvalid_1's rmse: 0.0890954\n",
      "[150]\ttraining's rmse: 0.0931314\tvalid_1's rmse: 0.0890558\n",
      "[175]\ttraining's rmse: 0.0930289\tvalid_1's rmse: 0.089027\n",
      "[200]\ttraining's rmse: 0.0929202\tvalid_1's rmse: 0.0889954\n",
      "[225]\ttraining's rmse: 0.0928139\tvalid_1's rmse: 0.0889629\n",
      "[250]\ttraining's rmse: 0.0927208\tvalid_1's rmse: 0.0889338\n",
      "[275]\ttraining's rmse: 0.0926396\tvalid_1's rmse: 0.0889075\n",
      "[300]\ttraining's rmse: 0.0925564\tvalid_1's rmse: 0.0888817\n",
      "[325]\ttraining's rmse: 0.0924718\tvalid_1's rmse: 0.0888588\n",
      "[350]\ttraining's rmse: 0.092389\tvalid_1's rmse: 0.088835\n",
      "[375]\ttraining's rmse: 0.0923221\tvalid_1's rmse: 0.0888234\n",
      "[400]\ttraining's rmse: 0.0922481\tvalid_1's rmse: 0.0888102\n",
      "[425]\ttraining's rmse: 0.0921798\tvalid_1's rmse: 0.0887962\n",
      "[450]\ttraining's rmse: 0.0921164\tvalid_1's rmse: 0.0887791\n",
      "[475]\ttraining's rmse: 0.0920577\tvalid_1's rmse: 0.0887658\n",
      "[500]\ttraining's rmse: 0.0920083\tvalid_1's rmse: 0.0887529\n",
      "[525]\ttraining's rmse: 0.0919427\tvalid_1's rmse: 0.0887388\n",
      "[550]\ttraining's rmse: 0.0918838\tvalid_1's rmse: 0.0887248\n",
      "[575]\ttraining's rmse: 0.0918315\tvalid_1's rmse: 0.0887133\n",
      "[600]\ttraining's rmse: 0.0917774\tvalid_1's rmse: 0.0887065\n",
      "[625]\ttraining's rmse: 0.0917342\tvalid_1's rmse: 0.0886966\n",
      "[650]\ttraining's rmse: 0.0916804\tvalid_1's rmse: 0.0886913\n",
      "[675]\ttraining's rmse: 0.0916255\tvalid_1's rmse: 0.0886983\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttraining's rmse: 0.0916828\tvalid_1's rmse: 0.0886869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0925889\tvalid_1's rmse: 0.0943989\n",
      "[50]\ttraining's rmse: 0.0923902\tvalid_1's rmse: 0.0943432\n",
      "[75]\ttraining's rmse: 0.0921948\tvalid_1's rmse: 0.0942858\n",
      "[100]\ttraining's rmse: 0.0920141\tvalid_1's rmse: 0.0942365\n",
      "[125]\ttraining's rmse: 0.0918366\tvalid_1's rmse: 0.0941891\n",
      "[150]\ttraining's rmse: 0.091674\tvalid_1's rmse: 0.0941448\n",
      "[175]\ttraining's rmse: 0.0915407\tvalid_1's rmse: 0.0941071\n",
      "[200]\ttraining's rmse: 0.091393\tvalid_1's rmse: 0.0940683\n",
      "[225]\ttraining's rmse: 0.091256\tvalid_1's rmse: 0.0940323\n",
      "[250]\ttraining's rmse: 0.0911364\tvalid_1's rmse: 0.0939976\n",
      "[275]\ttraining's rmse: 0.0910245\tvalid_1's rmse: 0.0939676\n",
      "[300]\ttraining's rmse: 0.0909128\tvalid_1's rmse: 0.0939375\n",
      "[325]\ttraining's rmse: 0.0908075\tvalid_1's rmse: 0.0939091\n",
      "[350]\ttraining's rmse: 0.0907018\tvalid_1's rmse: 0.0938826\n",
      "[375]\ttraining's rmse: 0.0906128\tvalid_1's rmse: 0.0938593\n",
      "[400]\ttraining's rmse: 0.0905199\tvalid_1's rmse: 0.0938376\n",
      "[425]\ttraining's rmse: 0.0904355\tvalid_1's rmse: 0.0938155\n",
      "[450]\ttraining's rmse: 0.0903582\tvalid_1's rmse: 0.0937935\n",
      "[475]\ttraining's rmse: 0.0902859\tvalid_1's rmse: 0.0937723\n",
      "[500]\ttraining's rmse: 0.0902221\tvalid_1's rmse: 0.0937569\n",
      "[525]\ttraining's rmse: 0.090149\tvalid_1's rmse: 0.0937396\n",
      "[550]\ttraining's rmse: 0.0900812\tvalid_1's rmse: 0.0937243\n",
      "[575]\ttraining's rmse: 0.0900213\tvalid_1's rmse: 0.0937104\n",
      "[600]\ttraining's rmse: 0.089963\tvalid_1's rmse: 0.0936961\n",
      "[625]\ttraining's rmse: 0.0899147\tvalid_1's rmse: 0.0936836\n",
      "[650]\ttraining's rmse: 0.0898603\tvalid_1's rmse: 0.0936699\n",
      "[675]\ttraining's rmse: 0.0898072\tvalid_1's rmse: 0.0936556\n",
      "[700]\ttraining's rmse: 0.0897538\tvalid_1's rmse: 0.0936444\n",
      "[725]\ttraining's rmse: 0.0897107\tvalid_1's rmse: 0.0936332\n",
      "[750]\ttraining's rmse: 0.0896634\tvalid_1's rmse: 0.0936228\n",
      "[775]\ttraining's rmse: 0.0896257\tvalid_1's rmse: 0.0936119\n",
      "[800]\ttraining's rmse: 0.0895799\tvalid_1's rmse: 0.0936015\n",
      "[825]\ttraining's rmse: 0.0895435\tvalid_1's rmse: 0.0935921\n",
      "[850]\ttraining's rmse: 0.0895025\tvalid_1's rmse: 0.0935835\n",
      "[875]\ttraining's rmse: 0.0894706\tvalid_1's rmse: 0.0935752\n",
      "[900]\ttraining's rmse: 0.089436\tvalid_1's rmse: 0.0935674\n",
      "[925]\ttraining's rmse: 0.0894034\tvalid_1's rmse: 0.0935604\n",
      "[950]\ttraining's rmse: 0.0893733\tvalid_1's rmse: 0.0935527\n",
      "[975]\ttraining's rmse: 0.0893433\tvalid_1's rmse: 0.0935453\n",
      "[1000]\ttraining's rmse: 0.0893119\tvalid_1's rmse: 0.0935381\n",
      "[1025]\ttraining's rmse: 0.0892802\tvalid_1's rmse: 0.093531\n",
      "[1050]\ttraining's rmse: 0.0892542\tvalid_1's rmse: 0.093523\n",
      "[1075]\ttraining's rmse: 0.0892289\tvalid_1's rmse: 0.0935179\n",
      "[1100]\ttraining's rmse: 0.0892071\tvalid_1's rmse: 0.0935117\n",
      "[1125]\ttraining's rmse: 0.0891853\tvalid_1's rmse: 0.0935073\n",
      "[1150]\ttraining's rmse: 0.0891656\tvalid_1's rmse: 0.0935011\n",
      "[1175]\ttraining's rmse: 0.0891464\tvalid_1's rmse: 0.0934977\n",
      "[1200]\ttraining's rmse: 0.0891254\tvalid_1's rmse: 0.0934929\n",
      "[1225]\ttraining's rmse: 0.0891042\tvalid_1's rmse: 0.0934872\n",
      "[1250]\ttraining's rmse: 0.0890848\tvalid_1's rmse: 0.0934822\n",
      "[1275]\ttraining's rmse: 0.0890629\tvalid_1's rmse: 0.0934778\n",
      "[1300]\ttraining's rmse: 0.0890477\tvalid_1's rmse: 0.093472\n",
      "[1325]\ttraining's rmse: 0.089027\tvalid_1's rmse: 0.0934671\n",
      "[1350]\ttraining's rmse: 0.0890087\tvalid_1's rmse: 0.0934641\n",
      "[1375]\ttraining's rmse: 0.0889892\tvalid_1's rmse: 0.0934608\n",
      "[1400]\ttraining's rmse: 0.0889753\tvalid_1's rmse: 0.0934563\n",
      "[1425]\ttraining's rmse: 0.088961\tvalid_1's rmse: 0.0934524\n",
      "[1450]\ttraining's rmse: 0.0889423\tvalid_1's rmse: 0.0934488\n",
      "[1475]\ttraining's rmse: 0.0889281\tvalid_1's rmse: 0.0934455\n",
      "[1500]\ttraining's rmse: 0.0889152\tvalid_1's rmse: 0.0934434\n",
      "[1525]\ttraining's rmse: 0.0889015\tvalid_1's rmse: 0.0934401\n",
      "[1550]\ttraining's rmse: 0.0888904\tvalid_1's rmse: 0.0934371\n",
      "[1575]\ttraining's rmse: 0.0888778\tvalid_1's rmse: 0.0934349\n",
      "[1600]\ttraining's rmse: 0.088869\tvalid_1's rmse: 0.0934336\n",
      "[1625]\ttraining's rmse: 0.0888591\tvalid_1's rmse: 0.0934302\n",
      "[1650]\ttraining's rmse: 0.0888474\tvalid_1's rmse: 0.0934269\n",
      "[1675]\ttraining's rmse: 0.088838\tvalid_1's rmse: 0.0934258\n",
      "[1700]\ttraining's rmse: 0.0888296\tvalid_1's rmse: 0.0934231\n",
      "[1725]\ttraining's rmse: 0.0888186\tvalid_1's rmse: 0.0934211\n",
      "[1750]\ttraining's rmse: 0.08881\tvalid_1's rmse: 0.0934186\n",
      "[1775]\ttraining's rmse: 0.0887999\tvalid_1's rmse: 0.0934172\n",
      "[1800]\ttraining's rmse: 0.0887934\tvalid_1's rmse: 0.0934164\n",
      "[1825]\ttraining's rmse: 0.088786\tvalid_1's rmse: 0.0934149\n",
      "[1850]\ttraining's rmse: 0.0887795\tvalid_1's rmse: 0.0934122\n",
      "[1875]\ttraining's rmse: 0.0887732\tvalid_1's rmse: 0.0934113\n",
      "[1900]\ttraining's rmse: 0.0887661\tvalid_1's rmse: 0.093409\n",
      "[1925]\ttraining's rmse: 0.0887603\tvalid_1's rmse: 0.093408\n",
      "[1950]\ttraining's rmse: 0.0887555\tvalid_1's rmse: 0.0934055\n",
      "[1975]\ttraining's rmse: 0.0887513\tvalid_1's rmse: 0.0934042\n",
      "[2000]\ttraining's rmse: 0.0887454\tvalid_1's rmse: 0.0934024\n",
      "[2025]\ttraining's rmse: 0.0887385\tvalid_1's rmse: 0.0934014\n",
      "[2050]\ttraining's rmse: 0.0887338\tvalid_1's rmse: 0.0933997\n",
      "[2075]\ttraining's rmse: 0.0887291\tvalid_1's rmse: 0.0933982\n",
      "[2100]\ttraining's rmse: 0.0887244\tvalid_1's rmse: 0.093397\n",
      "[2125]\ttraining's rmse: 0.0887187\tvalid_1's rmse: 0.0933956\n",
      "[2150]\ttraining's rmse: 0.0887133\tvalid_1's rmse: 0.0933936\n",
      "[2175]\ttraining's rmse: 0.0887087\tvalid_1's rmse: 0.0933928\n",
      "[2200]\ttraining's rmse: 0.0887044\tvalid_1's rmse: 0.0933916\n",
      "[2225]\ttraining's rmse: 0.0887012\tvalid_1's rmse: 0.093389\n",
      "[2250]\ttraining's rmse: 0.0886975\tvalid_1's rmse: 0.0933885\n",
      "[2275]\ttraining's rmse: 0.0886939\tvalid_1's rmse: 0.0933889\n",
      "[2300]\ttraining's rmse: 0.0886909\tvalid_1's rmse: 0.0933876\n",
      "[2325]\ttraining's rmse: 0.0886866\tvalid_1's rmse: 0.093386\n",
      "[2350]\ttraining's rmse: 0.0886833\tvalid_1's rmse: 0.0933854\n",
      "[2375]\ttraining's rmse: 0.0886787\tvalid_1's rmse: 0.0933837\n",
      "[2400]\ttraining's rmse: 0.0886745\tvalid_1's rmse: 0.0933826\n",
      "[2425]\ttraining's rmse: 0.0886709\tvalid_1's rmse: 0.0933817\n",
      "[2450]\ttraining's rmse: 0.0886676\tvalid_1's rmse: 0.0933806\n",
      "[2475]\ttraining's rmse: 0.0886644\tvalid_1's rmse: 0.0933802\n",
      "[2500]\ttraining's rmse: 0.0886615\tvalid_1's rmse: 0.0933796\n",
      "[2525]\ttraining's rmse: 0.0886586\tvalid_1's rmse: 0.0933797\n",
      "[2550]\ttraining's rmse: 0.0886551\tvalid_1's rmse: 0.0933791\n",
      "[2575]\ttraining's rmse: 0.0886515\tvalid_1's rmse: 0.0933791\n",
      "[2600]\ttraining's rmse: 0.0886474\tvalid_1's rmse: 0.0933785\n",
      "[2625]\ttraining's rmse: 0.0886457\tvalid_1's rmse: 0.0933768\n",
      "[2650]\ttraining's rmse: 0.088643\tvalid_1's rmse: 0.0933758\n",
      "[2675]\ttraining's rmse: 0.0886408\tvalid_1's rmse: 0.0933757\n",
      "[2700]\ttraining's rmse: 0.0886381\tvalid_1's rmse: 0.0933749\n",
      "[2725]\ttraining's rmse: 0.088636\tvalid_1's rmse: 0.0933753\n",
      "[2750]\ttraining's rmse: 0.0886342\tvalid_1's rmse: 0.0933749\n",
      "[2775]\ttraining's rmse: 0.0886302\tvalid_1's rmse: 0.0933748\n",
      "[2800]\ttraining's rmse: 0.088629\tvalid_1's rmse: 0.0933747\n",
      "[2825]\ttraining's rmse: 0.0886271\tvalid_1's rmse: 0.0933742\n",
      "[2850]\ttraining's rmse: 0.0886249\tvalid_1's rmse: 0.0933743\n",
      "[2875]\ttraining's rmse: 0.0886225\tvalid_1's rmse: 0.0933738\n",
      "[2900]\ttraining's rmse: 0.0886207\tvalid_1's rmse: 0.0933733\n",
      "[2925]\ttraining's rmse: 0.0886199\tvalid_1's rmse: 0.0933734\n",
      "[2950]\ttraining's rmse: 0.0886186\tvalid_1's rmse: 0.0933733\n",
      "[2975]\ttraining's rmse: 0.0886174\tvalid_1's rmse: 0.0933731\n",
      "[3000]\ttraining's rmse: 0.0886151\tvalid_1's rmse: 0.0933734\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.0886151\tvalid_1's rmse: 0.0933734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0924031\tvalid_1's rmse: 0.0947932\n",
      "[50]\ttraining's rmse: 0.0922273\tvalid_1's rmse: 0.0947346\n",
      "[75]\ttraining's rmse: 0.092049\tvalid_1's rmse: 0.0946805\n",
      "[100]\ttraining's rmse: 0.0918825\tvalid_1's rmse: 0.0946308\n",
      "[125]\ttraining's rmse: 0.0917246\tvalid_1's rmse: 0.0945826\n",
      "[150]\ttraining's rmse: 0.0915771\tvalid_1's rmse: 0.0945362\n",
      "[175]\ttraining's rmse: 0.0914481\tvalid_1's rmse: 0.0944999\n",
      "[200]\ttraining's rmse: 0.091314\tvalid_1's rmse: 0.0944611\n",
      "[225]\ttraining's rmse: 0.0911891\tvalid_1's rmse: 0.0944275\n",
      "[250]\ttraining's rmse: 0.0910804\tvalid_1's rmse: 0.0943947\n",
      "[275]\ttraining's rmse: 0.0909823\tvalid_1's rmse: 0.0943669\n",
      "[300]\ttraining's rmse: 0.0908812\tvalid_1's rmse: 0.0943382\n",
      "[325]\ttraining's rmse: 0.0907823\tvalid_1's rmse: 0.0943117\n",
      "[350]\ttraining's rmse: 0.090688\tvalid_1's rmse: 0.0942873\n",
      "[375]\ttraining's rmse: 0.0906126\tvalid_1's rmse: 0.094266\n",
      "[400]\ttraining's rmse: 0.0905299\tvalid_1's rmse: 0.094245\n",
      "[425]\ttraining's rmse: 0.0904508\tvalid_1's rmse: 0.0942243\n",
      "[450]\ttraining's rmse: 0.0903821\tvalid_1's rmse: 0.094205\n",
      "[475]\ttraining's rmse: 0.090318\tvalid_1's rmse: 0.0941879\n",
      "[500]\ttraining's rmse: 0.0902618\tvalid_1's rmse: 0.0941712\n",
      "[525]\ttraining's rmse: 0.0901917\tvalid_1's rmse: 0.0941538\n",
      "[550]\ttraining's rmse: 0.0901243\tvalid_1's rmse: 0.0941383\n",
      "[575]\ttraining's rmse: 0.0900659\tvalid_1's rmse: 0.094124\n",
      "[600]\ttraining's rmse: 0.090012\tvalid_1's rmse: 0.0941114\n",
      "[625]\ttraining's rmse: 0.0899644\tvalid_1's rmse: 0.0940988\n",
      "[650]\ttraining's rmse: 0.0899078\tvalid_1's rmse: 0.0940863\n",
      "[675]\ttraining's rmse: 0.0898536\tvalid_1's rmse: 0.0940755\n",
      "[700]\ttraining's rmse: 0.0898064\tvalid_1's rmse: 0.0940641\n",
      "[725]\ttraining's rmse: 0.089762\tvalid_1's rmse: 0.0940543\n",
      "[750]\ttraining's rmse: 0.0897197\tvalid_1's rmse: 0.0940452\n",
      "[775]\ttraining's rmse: 0.0896845\tvalid_1's rmse: 0.0940359\n",
      "[800]\ttraining's rmse: 0.0896421\tvalid_1's rmse: 0.0940272\n",
      "[825]\ttraining's rmse: 0.0896065\tvalid_1's rmse: 0.0940186\n",
      "[850]\ttraining's rmse: 0.0895703\tvalid_1's rmse: 0.0940116\n",
      "[875]\ttraining's rmse: 0.0895361\tvalid_1's rmse: 0.0940047\n",
      "[900]\ttraining's rmse: 0.0895006\tvalid_1's rmse: 0.0939974\n",
      "[925]\ttraining's rmse: 0.0894654\tvalid_1's rmse: 0.0939907\n",
      "[950]\ttraining's rmse: 0.0894326\tvalid_1's rmse: 0.0939854\n",
      "[975]\ttraining's rmse: 0.0894011\tvalid_1's rmse: 0.0939798\n",
      "[1000]\ttraining's rmse: 0.0893746\tvalid_1's rmse: 0.0939746\n",
      "[1025]\ttraining's rmse: 0.0893455\tvalid_1's rmse: 0.0939701\n",
      "[1050]\ttraining's rmse: 0.0893171\tvalid_1's rmse: 0.0939644\n",
      "[1075]\ttraining's rmse: 0.0892921\tvalid_1's rmse: 0.0939612\n",
      "[1100]\ttraining's rmse: 0.0892688\tvalid_1's rmse: 0.0939573\n",
      "[1125]\ttraining's rmse: 0.0892439\tvalid_1's rmse: 0.0939537\n",
      "[1150]\ttraining's rmse: 0.0892206\tvalid_1's rmse: 0.0939505\n",
      "[1175]\ttraining's rmse: 0.0892011\tvalid_1's rmse: 0.0939475\n",
      "[1200]\ttraining's rmse: 0.0891812\tvalid_1's rmse: 0.093944\n",
      "[1225]\ttraining's rmse: 0.0891622\tvalid_1's rmse: 0.0939416\n",
      "[1250]\ttraining's rmse: 0.0891431\tvalid_1's rmse: 0.0939386\n",
      "[1275]\ttraining's rmse: 0.0891213\tvalid_1's rmse: 0.0939361\n",
      "[1300]\ttraining's rmse: 0.0891048\tvalid_1's rmse: 0.0939336\n",
      "[1325]\ttraining's rmse: 0.0890889\tvalid_1's rmse: 0.0939319\n",
      "[1350]\ttraining's rmse: 0.0890704\tvalid_1's rmse: 0.0939304\n",
      "[1375]\ttraining's rmse: 0.0890519\tvalid_1's rmse: 0.0939299\n",
      "[1400]\ttraining's rmse: 0.0890382\tvalid_1's rmse: 0.0939278\n",
      "[1425]\ttraining's rmse: 0.0890221\tvalid_1's rmse: 0.0939262\n",
      "[1450]\ttraining's rmse: 0.0890058\tvalid_1's rmse: 0.0939256\n",
      "[1475]\ttraining's rmse: 0.0889895\tvalid_1's rmse: 0.0939235\n",
      "[1500]\ttraining's rmse: 0.0889772\tvalid_1's rmse: 0.093922\n",
      "[1525]\ttraining's rmse: 0.0889648\tvalid_1's rmse: 0.0939207\n",
      "[1550]\ttraining's rmse: 0.0889518\tvalid_1's rmse: 0.0939197\n",
      "[1575]\ttraining's rmse: 0.0889404\tvalid_1's rmse: 0.0939185\n",
      "[1600]\ttraining's rmse: 0.0889295\tvalid_1's rmse: 0.0939172\n",
      "[1625]\ttraining's rmse: 0.0889188\tvalid_1's rmse: 0.0939162\n",
      "[1650]\ttraining's rmse: 0.0889088\tvalid_1's rmse: 0.0939158\n",
      "[1675]\ttraining's rmse: 0.0889021\tvalid_1's rmse: 0.0939148\n",
      "[1700]\ttraining's rmse: 0.0888933\tvalid_1's rmse: 0.0939139\n",
      "[1725]\ttraining's rmse: 0.0888847\tvalid_1's rmse: 0.0939127\n",
      "[1750]\ttraining's rmse: 0.0888741\tvalid_1's rmse: 0.0939128\n",
      "[1775]\ttraining's rmse: 0.088865\tvalid_1's rmse: 0.0939117\n",
      "[1800]\ttraining's rmse: 0.0888564\tvalid_1's rmse: 0.0939115\n",
      "[1825]\ttraining's rmse: 0.0888474\tvalid_1's rmse: 0.0939108\n",
      "[1850]\ttraining's rmse: 0.0888402\tvalid_1's rmse: 0.09391\n",
      "[1875]\ttraining's rmse: 0.0888328\tvalid_1's rmse: 0.0939101\n",
      "[1900]\ttraining's rmse: 0.0888277\tvalid_1's rmse: 0.09391\n",
      "[1925]\ttraining's rmse: 0.0888217\tvalid_1's rmse: 0.0939095\n",
      "[1950]\ttraining's rmse: 0.0888144\tvalid_1's rmse: 0.0939087\n",
      "[1975]\ttraining's rmse: 0.08881\tvalid_1's rmse: 0.0939084\n",
      "[2000]\ttraining's rmse: 0.0888052\tvalid_1's rmse: 0.0939084\n",
      "[2025]\ttraining's rmse: 0.0887988\tvalid_1's rmse: 0.0939073\n",
      "[2050]\ttraining's rmse: 0.0887935\tvalid_1's rmse: 0.0939073\n",
      "[2075]\ttraining's rmse: 0.0887898\tvalid_1's rmse: 0.0939071\n",
      "[2100]\ttraining's rmse: 0.0887862\tvalid_1's rmse: 0.0939069\n",
      "[2125]\ttraining's rmse: 0.0887831\tvalid_1's rmse: 0.0939068\n",
      "[2150]\ttraining's rmse: 0.0887775\tvalid_1's rmse: 0.0939069\n",
      "Early stopping, best iteration is:\n",
      "[2116]\ttraining's rmse: 0.0887843\tvalid_1's rmse: 0.0939065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0944408\tvalid_1's rmse: 0.0907356\n",
      "[50]\ttraining's rmse: 0.0943009\tvalid_1's rmse: 0.0906843\n",
      "[75]\ttraining's rmse: 0.094151\tvalid_1's rmse: 0.090634\n",
      "[100]\ttraining's rmse: 0.0940183\tvalid_1's rmse: 0.0905905\n",
      "[125]\ttraining's rmse: 0.0938821\tvalid_1's rmse: 0.0905473\n",
      "[150]\ttraining's rmse: 0.093753\tvalid_1's rmse: 0.0905061\n",
      "[175]\ttraining's rmse: 0.0936471\tvalid_1's rmse: 0.0904786\n",
      "[200]\ttraining's rmse: 0.0935355\tvalid_1's rmse: 0.0904459\n",
      "[225]\ttraining's rmse: 0.0934219\tvalid_1's rmse: 0.0904158\n",
      "[250]\ttraining's rmse: 0.0933269\tvalid_1's rmse: 0.0903883\n",
      "[275]\ttraining's rmse: 0.0932399\tvalid_1's rmse: 0.0903629\n",
      "[300]\ttraining's rmse: 0.093153\tvalid_1's rmse: 0.0903415\n",
      "[325]\ttraining's rmse: 0.0930626\tvalid_1's rmse: 0.0903181\n",
      "[350]\ttraining's rmse: 0.0929765\tvalid_1's rmse: 0.0902947\n",
      "[375]\ttraining's rmse: 0.0929038\tvalid_1's rmse: 0.090277\n",
      "[400]\ttraining's rmse: 0.0928293\tvalid_1's rmse: 0.0902638\n",
      "[425]\ttraining's rmse: 0.0927582\tvalid_1's rmse: 0.0902469\n",
      "[450]\ttraining's rmse: 0.0926935\tvalid_1's rmse: 0.0902352\n",
      "[475]\ttraining's rmse: 0.09263\tvalid_1's rmse: 0.0902218\n",
      "[500]\ttraining's rmse: 0.0925798\tvalid_1's rmse: 0.0902089\n",
      "[525]\ttraining's rmse: 0.092514\tvalid_1's rmse: 0.0901954\n",
      "[550]\ttraining's rmse: 0.0924542\tvalid_1's rmse: 0.0901832\n",
      "[575]\ttraining's rmse: 0.0923979\tvalid_1's rmse: 0.090175\n",
      "[600]\ttraining's rmse: 0.0923438\tvalid_1's rmse: 0.0901697\n",
      "[625]\ttraining's rmse: 0.0922988\tvalid_1's rmse: 0.0901654\n",
      "[650]\ttraining's rmse: 0.0922439\tvalid_1's rmse: 0.0901624\n",
      "[675]\ttraining's rmse: 0.0921897\tvalid_1's rmse: 0.0901593\n",
      "[700]\ttraining's rmse: 0.0921397\tvalid_1's rmse: 0.090158\n",
      "[725]\ttraining's rmse: 0.0920938\tvalid_1's rmse: 0.0901642\n",
      "[750]\ttraining's rmse: 0.0920486\tvalid_1's rmse: 0.0901625\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 0.0921308\tvalid_1's rmse: 0.0901576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.092226\tvalid_1's rmse: 0.0941403\n",
      "[50]\ttraining's rmse: 0.0920336\tvalid_1's rmse: 0.0940813\n",
      "[75]\ttraining's rmse: 0.0918422\tvalid_1's rmse: 0.0940226\n",
      "[100]\ttraining's rmse: 0.0916663\tvalid_1's rmse: 0.0939741\n",
      "[125]\ttraining's rmse: 0.0914909\tvalid_1's rmse: 0.0939245\n",
      "[150]\ttraining's rmse: 0.0913348\tvalid_1's rmse: 0.0938777\n",
      "[175]\ttraining's rmse: 0.0912011\tvalid_1's rmse: 0.0938391\n",
      "[200]\ttraining's rmse: 0.0910627\tvalid_1's rmse: 0.0937994\n",
      "[225]\ttraining's rmse: 0.0909248\tvalid_1's rmse: 0.0937628\n",
      "[250]\ttraining's rmse: 0.0908089\tvalid_1's rmse: 0.0937292\n",
      "[275]\ttraining's rmse: 0.0907001\tvalid_1's rmse: 0.0936969\n",
      "[300]\ttraining's rmse: 0.0905964\tvalid_1's rmse: 0.0936676\n",
      "[325]\ttraining's rmse: 0.0904928\tvalid_1's rmse: 0.0936399\n",
      "[350]\ttraining's rmse: 0.090393\tvalid_1's rmse: 0.0936122\n",
      "[375]\ttraining's rmse: 0.0903047\tvalid_1's rmse: 0.0935896\n",
      "[400]\ttraining's rmse: 0.0902156\tvalid_1's rmse: 0.0935667\n",
      "[425]\ttraining's rmse: 0.0901325\tvalid_1's rmse: 0.0935451\n",
      "[450]\ttraining's rmse: 0.0900602\tvalid_1's rmse: 0.0935228\n",
      "[475]\ttraining's rmse: 0.0899907\tvalid_1's rmse: 0.0935018\n",
      "[500]\ttraining's rmse: 0.0899277\tvalid_1's rmse: 0.0934838\n",
      "[525]\ttraining's rmse: 0.0898557\tvalid_1's rmse: 0.093466\n",
      "[550]\ttraining's rmse: 0.089787\tvalid_1's rmse: 0.093449\n",
      "[575]\ttraining's rmse: 0.0897256\tvalid_1's rmse: 0.0934323\n",
      "[600]\ttraining's rmse: 0.089668\tvalid_1's rmse: 0.0934188\n",
      "[625]\ttraining's rmse: 0.0896191\tvalid_1's rmse: 0.093404\n",
      "[650]\ttraining's rmse: 0.0895574\tvalid_1's rmse: 0.0933894\n",
      "[675]\ttraining's rmse: 0.0895021\tvalid_1's rmse: 0.0933743\n",
      "[700]\ttraining's rmse: 0.0894526\tvalid_1's rmse: 0.0933616\n",
      "[725]\ttraining's rmse: 0.0894064\tvalid_1's rmse: 0.0933503\n",
      "[750]\ttraining's rmse: 0.0893634\tvalid_1's rmse: 0.0933398\n",
      "[775]\ttraining's rmse: 0.0893289\tvalid_1's rmse: 0.0933301\n",
      "[800]\ttraining's rmse: 0.0892822\tvalid_1's rmse: 0.0933199\n",
      "[825]\ttraining's rmse: 0.0892452\tvalid_1's rmse: 0.0933118\n",
      "[850]\ttraining's rmse: 0.0892062\tvalid_1's rmse: 0.0933044\n",
      "[875]\ttraining's rmse: 0.0891703\tvalid_1's rmse: 0.0932947\n",
      "[900]\ttraining's rmse: 0.0891355\tvalid_1's rmse: 0.0932858\n",
      "[925]\ttraining's rmse: 0.0891053\tvalid_1's rmse: 0.0932786\n",
      "[950]\ttraining's rmse: 0.0890723\tvalid_1's rmse: 0.0932701\n",
      "[975]\ttraining's rmse: 0.0890425\tvalid_1's rmse: 0.0932634\n",
      "[1000]\ttraining's rmse: 0.0890162\tvalid_1's rmse: 0.0932576\n",
      "[1025]\ttraining's rmse: 0.0889846\tvalid_1's rmse: 0.0932501\n",
      "[1050]\ttraining's rmse: 0.0889593\tvalid_1's rmse: 0.093243\n",
      "[1075]\ttraining's rmse: 0.0889324\tvalid_1's rmse: 0.0932389\n",
      "[1100]\ttraining's rmse: 0.0889076\tvalid_1's rmse: 0.093234\n",
      "[1125]\ttraining's rmse: 0.088887\tvalid_1's rmse: 0.0932265\n",
      "[1150]\ttraining's rmse: 0.0888616\tvalid_1's rmse: 0.093222\n",
      "[1175]\ttraining's rmse: 0.0888429\tvalid_1's rmse: 0.0932191\n",
      "[1200]\ttraining's rmse: 0.0888236\tvalid_1's rmse: 0.093214\n",
      "[1225]\ttraining's rmse: 0.0888049\tvalid_1's rmse: 0.0932091\n",
      "[1250]\ttraining's rmse: 0.0887892\tvalid_1's rmse: 0.0932058\n",
      "[1275]\ttraining's rmse: 0.088767\tvalid_1's rmse: 0.0932022\n",
      "[1300]\ttraining's rmse: 0.0887508\tvalid_1's rmse: 0.0931987\n",
      "[1325]\ttraining's rmse: 0.0887331\tvalid_1's rmse: 0.0931949\n",
      "[1350]\ttraining's rmse: 0.088717\tvalid_1's rmse: 0.0931912\n",
      "[1375]\ttraining's rmse: 0.0886978\tvalid_1's rmse: 0.093187\n",
      "[1400]\ttraining's rmse: 0.0886851\tvalid_1's rmse: 0.0931817\n",
      "[1425]\ttraining's rmse: 0.0886678\tvalid_1's rmse: 0.0931778\n",
      "[1450]\ttraining's rmse: 0.0886503\tvalid_1's rmse: 0.0931754\n",
      "[1475]\ttraining's rmse: 0.0886372\tvalid_1's rmse: 0.0931719\n",
      "[1500]\ttraining's rmse: 0.088625\tvalid_1's rmse: 0.09317\n",
      "[1525]\ttraining's rmse: 0.088614\tvalid_1's rmse: 0.0931668\n",
      "[1550]\ttraining's rmse: 0.0886037\tvalid_1's rmse: 0.0931649\n",
      "[1575]\ttraining's rmse: 0.0885941\tvalid_1's rmse: 0.0931618\n",
      "[1600]\ttraining's rmse: 0.0885854\tvalid_1's rmse: 0.0931591\n",
      "[1625]\ttraining's rmse: 0.0885749\tvalid_1's rmse: 0.0931567\n",
      "[1650]\ttraining's rmse: 0.0885628\tvalid_1's rmse: 0.093154\n",
      "[1675]\ttraining's rmse: 0.0885547\tvalid_1's rmse: 0.0931509\n",
      "[1700]\ttraining's rmse: 0.0885469\tvalid_1's rmse: 0.0931482\n",
      "[1725]\ttraining's rmse: 0.0885387\tvalid_1's rmse: 0.0931462\n",
      "[1750]\ttraining's rmse: 0.088529\tvalid_1's rmse: 0.0931421\n",
      "[1775]\ttraining's rmse: 0.0885206\tvalid_1's rmse: 0.09314\n",
      "[1800]\ttraining's rmse: 0.0885118\tvalid_1's rmse: 0.0931383\n",
      "[1825]\ttraining's rmse: 0.0885033\tvalid_1's rmse: 0.0931362\n",
      "[1850]\ttraining's rmse: 0.0884976\tvalid_1's rmse: 0.0931346\n",
      "[1875]\ttraining's rmse: 0.0884912\tvalid_1's rmse: 0.093133\n",
      "[1900]\ttraining's rmse: 0.0884852\tvalid_1's rmse: 0.093131\n",
      "[1925]\ttraining's rmse: 0.0884785\tvalid_1's rmse: 0.09313\n",
      "[1950]\ttraining's rmse: 0.0884745\tvalid_1's rmse: 0.0931283\n",
      "[1975]\ttraining's rmse: 0.08847\tvalid_1's rmse: 0.093126\n",
      "[2000]\ttraining's rmse: 0.0884644\tvalid_1's rmse: 0.0931243\n",
      "[2025]\ttraining's rmse: 0.0884594\tvalid_1's rmse: 0.0931233\n",
      "[2050]\ttraining's rmse: 0.088454\tvalid_1's rmse: 0.0931233\n",
      "[2075]\ttraining's rmse: 0.0884506\tvalid_1's rmse: 0.0931222\n",
      "[2100]\ttraining's rmse: 0.0884468\tvalid_1's rmse: 0.0931218\n",
      "[2125]\ttraining's rmse: 0.0884429\tvalid_1's rmse: 0.0931206\n",
      "[2150]\ttraining's rmse: 0.0884383\tvalid_1's rmse: 0.0931198\n",
      "[2175]\ttraining's rmse: 0.0884347\tvalid_1's rmse: 0.0931184\n",
      "[2200]\ttraining's rmse: 0.08843\tvalid_1's rmse: 0.0931183\n",
      "[2225]\ttraining's rmse: 0.0884257\tvalid_1's rmse: 0.0931169\n",
      "[2250]\ttraining's rmse: 0.0884219\tvalid_1's rmse: 0.0931168\n",
      "[2275]\ttraining's rmse: 0.0884179\tvalid_1's rmse: 0.093116\n",
      "[2300]\ttraining's rmse: 0.0884143\tvalid_1's rmse: 0.0931146\n",
      "[2325]\ttraining's rmse: 0.0884098\tvalid_1's rmse: 0.0931132\n",
      "[2350]\ttraining's rmse: 0.0884063\tvalid_1's rmse: 0.0931132\n",
      "[2375]\ttraining's rmse: 0.0884025\tvalid_1's rmse: 0.0931115\n",
      "[2400]\ttraining's rmse: 0.088398\tvalid_1's rmse: 0.0931099\n",
      "[2425]\ttraining's rmse: 0.0883952\tvalid_1's rmse: 0.0931099\n",
      "[2450]\ttraining's rmse: 0.0883936\tvalid_1's rmse: 0.0931088\n",
      "[2475]\ttraining's rmse: 0.088391\tvalid_1's rmse: 0.0931086\n",
      "[2500]\ttraining's rmse: 0.0883875\tvalid_1's rmse: 0.0931069\n",
      "[2525]\ttraining's rmse: 0.0883842\tvalid_1's rmse: 0.0931061\n",
      "[2550]\ttraining's rmse: 0.0883812\tvalid_1's rmse: 0.0931055\n",
      "[2575]\ttraining's rmse: 0.0883783\tvalid_1's rmse: 0.0931047\n",
      "[2600]\ttraining's rmse: 0.0883753\tvalid_1's rmse: 0.0931037\n",
      "[2625]\ttraining's rmse: 0.0883728\tvalid_1's rmse: 0.0931025\n",
      "[2650]\ttraining's rmse: 0.0883702\tvalid_1's rmse: 0.0931021\n",
      "[2675]\ttraining's rmse: 0.0883679\tvalid_1's rmse: 0.0931018\n",
      "[2700]\ttraining's rmse: 0.0883655\tvalid_1's rmse: 0.0931013\n",
      "[2725]\ttraining's rmse: 0.0883635\tvalid_1's rmse: 0.0931012\n",
      "[2750]\ttraining's rmse: 0.0883615\tvalid_1's rmse: 0.0931002\n",
      "[2775]\ttraining's rmse: 0.0883591\tvalid_1's rmse: 0.0931004\n",
      "[2800]\ttraining's rmse: 0.0883572\tvalid_1's rmse: 0.0930996\n",
      "[2825]\ttraining's rmse: 0.0883548\tvalid_1's rmse: 0.0930992\n",
      "[2850]\ttraining's rmse: 0.0883524\tvalid_1's rmse: 0.0930991\n",
      "[2875]\ttraining's rmse: 0.0883494\tvalid_1's rmse: 0.0930988\n",
      "[2900]\ttraining's rmse: 0.0883472\tvalid_1's rmse: 0.0930979\n",
      "[2925]\ttraining's rmse: 0.0883456\tvalid_1's rmse: 0.0930977\n",
      "[2950]\ttraining's rmse: 0.0883446\tvalid_1's rmse: 0.0930975\n",
      "[2975]\ttraining's rmse: 0.0883429\tvalid_1's rmse: 0.0930972\n",
      "[3000]\ttraining's rmse: 0.0883408\tvalid_1's rmse: 0.0930959\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\ttraining's rmse: 0.0883408\tvalid_1's rmse: 0.0930959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.092145\tvalid_1's rmse: 0.0943085\n",
      "[50]\ttraining's rmse: 0.0919684\tvalid_1's rmse: 0.0942507\n",
      "[75]\ttraining's rmse: 0.0917878\tvalid_1's rmse: 0.0941948\n",
      "[100]\ttraining's rmse: 0.0916249\tvalid_1's rmse: 0.094144\n",
      "[125]\ttraining's rmse: 0.0914591\tvalid_1's rmse: 0.0940935\n",
      "[150]\ttraining's rmse: 0.0913094\tvalid_1's rmse: 0.0940468\n",
      "[175]\ttraining's rmse: 0.09118\tvalid_1's rmse: 0.0940092\n",
      "[200]\ttraining's rmse: 0.0910479\tvalid_1's rmse: 0.0939714\n",
      "[225]\ttraining's rmse: 0.0909257\tvalid_1's rmse: 0.0939368\n",
      "[250]\ttraining's rmse: 0.0908137\tvalid_1's rmse: 0.0939033\n",
      "[275]\ttraining's rmse: 0.0907114\tvalid_1's rmse: 0.0938743\n",
      "[300]\ttraining's rmse: 0.090611\tvalid_1's rmse: 0.0938458\n",
      "[325]\ttraining's rmse: 0.0905119\tvalid_1's rmse: 0.0938192\n",
      "[350]\ttraining's rmse: 0.0904177\tvalid_1's rmse: 0.0937937\n",
      "[375]\ttraining's rmse: 0.0903403\tvalid_1's rmse: 0.093773\n",
      "[400]\ttraining's rmse: 0.0902574\tvalid_1's rmse: 0.0937513\n",
      "[425]\ttraining's rmse: 0.0901806\tvalid_1's rmse: 0.093731\n",
      "[450]\ttraining's rmse: 0.0901113\tvalid_1's rmse: 0.093711\n",
      "[475]\ttraining's rmse: 0.0900448\tvalid_1's rmse: 0.0936921\n",
      "[500]\ttraining's rmse: 0.0899868\tvalid_1's rmse: 0.0936753\n",
      "[525]\ttraining's rmse: 0.0899178\tvalid_1's rmse: 0.0936589\n",
      "[550]\ttraining's rmse: 0.0898552\tvalid_1's rmse: 0.0936433\n",
      "[575]\ttraining's rmse: 0.0897972\tvalid_1's rmse: 0.0936292\n",
      "[600]\ttraining's rmse: 0.0897414\tvalid_1's rmse: 0.0936175\n",
      "[625]\ttraining's rmse: 0.0896941\tvalid_1's rmse: 0.0936052\n",
      "[650]\ttraining's rmse: 0.0896377\tvalid_1's rmse: 0.0935916\n",
      "[675]\ttraining's rmse: 0.0895837\tvalid_1's rmse: 0.093581\n",
      "[700]\ttraining's rmse: 0.0895353\tvalid_1's rmse: 0.0935701\n",
      "[725]\ttraining's rmse: 0.0894879\tvalid_1's rmse: 0.0935591\n",
      "[750]\ttraining's rmse: 0.0894473\tvalid_1's rmse: 0.0935504\n",
      "[775]\ttraining's rmse: 0.0894116\tvalid_1's rmse: 0.0935418\n",
      "[800]\ttraining's rmse: 0.0893672\tvalid_1's rmse: 0.0935337\n",
      "[825]\ttraining's rmse: 0.0893304\tvalid_1's rmse: 0.0935257\n",
      "[850]\ttraining's rmse: 0.0892921\tvalid_1's rmse: 0.0935187\n",
      "[875]\ttraining's rmse: 0.0892606\tvalid_1's rmse: 0.0935116\n",
      "[900]\ttraining's rmse: 0.089225\tvalid_1's rmse: 0.0935055\n",
      "[925]\ttraining's rmse: 0.089191\tvalid_1's rmse: 0.0934995\n",
      "[950]\ttraining's rmse: 0.0891579\tvalid_1's rmse: 0.0934926\n",
      "[975]\ttraining's rmse: 0.0891287\tvalid_1's rmse: 0.0934868\n",
      "[1000]\ttraining's rmse: 0.0891013\tvalid_1's rmse: 0.0934817\n",
      "[1025]\ttraining's rmse: 0.0890678\tvalid_1's rmse: 0.0934763\n",
      "[1050]\ttraining's rmse: 0.0890407\tvalid_1's rmse: 0.093471\n",
      "[1075]\ttraining's rmse: 0.0890135\tvalid_1's rmse: 0.0934675\n",
      "[1100]\ttraining's rmse: 0.0889927\tvalid_1's rmse: 0.0934633\n",
      "[1125]\ttraining's rmse: 0.0889685\tvalid_1's rmse: 0.0934588\n",
      "[1150]\ttraining's rmse: 0.0889452\tvalid_1's rmse: 0.093456\n",
      "[1175]\ttraining's rmse: 0.0889254\tvalid_1's rmse: 0.0934534\n",
      "[1200]\ttraining's rmse: 0.0889051\tvalid_1's rmse: 0.09345\n",
      "[1225]\ttraining's rmse: 0.088884\tvalid_1's rmse: 0.0934473\n",
      "[1250]\ttraining's rmse: 0.0888654\tvalid_1's rmse: 0.0934447\n",
      "[1275]\ttraining's rmse: 0.0888439\tvalid_1's rmse: 0.0934434\n",
      "[1300]\ttraining's rmse: 0.0888278\tvalid_1's rmse: 0.0934407\n",
      "[1325]\ttraining's rmse: 0.0888106\tvalid_1's rmse: 0.0934394\n",
      "[1350]\ttraining's rmse: 0.0887913\tvalid_1's rmse: 0.0934374\n",
      "[1375]\ttraining's rmse: 0.088774\tvalid_1's rmse: 0.093436\n",
      "[1400]\ttraining's rmse: 0.0887599\tvalid_1's rmse: 0.0934339\n",
      "[1425]\ttraining's rmse: 0.0887444\tvalid_1's rmse: 0.0934324\n",
      "[1450]\ttraining's rmse: 0.0887278\tvalid_1's rmse: 0.0934312\n",
      "[1475]\ttraining's rmse: 0.0887123\tvalid_1's rmse: 0.0934293\n",
      "[1500]\ttraining's rmse: 0.0886986\tvalid_1's rmse: 0.0934288\n",
      "[1525]\ttraining's rmse: 0.0886883\tvalid_1's rmse: 0.0934274\n",
      "[1550]\ttraining's rmse: 0.0886766\tvalid_1's rmse: 0.0934264\n",
      "[1575]\ttraining's rmse: 0.0886636\tvalid_1's rmse: 0.0934251\n",
      "[1600]\ttraining's rmse: 0.088652\tvalid_1's rmse: 0.093425\n",
      "[1625]\ttraining's rmse: 0.0886415\tvalid_1's rmse: 0.0934244\n",
      "[1650]\ttraining's rmse: 0.0886307\tvalid_1's rmse: 0.0934228\n",
      "[1675]\ttraining's rmse: 0.0886212\tvalid_1's rmse: 0.0934215\n",
      "[1700]\ttraining's rmse: 0.0886133\tvalid_1's rmse: 0.0934204\n",
      "[1725]\ttraining's rmse: 0.0886054\tvalid_1's rmse: 0.0934194\n",
      "[1750]\ttraining's rmse: 0.0885957\tvalid_1's rmse: 0.0934188\n",
      "[1775]\ttraining's rmse: 0.0885871\tvalid_1's rmse: 0.0934178\n",
      "[1800]\ttraining's rmse: 0.0885782\tvalid_1's rmse: 0.0934171\n",
      "[1825]\ttraining's rmse: 0.0885697\tvalid_1's rmse: 0.0934167\n",
      "[1850]\ttraining's rmse: 0.0885633\tvalid_1's rmse: 0.0934159\n",
      "[1875]\ttraining's rmse: 0.0885564\tvalid_1's rmse: 0.0934162\n",
      "[1900]\ttraining's rmse: 0.0885509\tvalid_1's rmse: 0.093416\n",
      "[1925]\ttraining's rmse: 0.088545\tvalid_1's rmse: 0.0934159\n",
      "[1950]\ttraining's rmse: 0.0885404\tvalid_1's rmse: 0.0934151\n",
      "[1975]\ttraining's rmse: 0.0885332\tvalid_1's rmse: 0.0934144\n",
      "[2000]\ttraining's rmse: 0.0885282\tvalid_1's rmse: 0.0934143\n",
      "[2025]\ttraining's rmse: 0.0885228\tvalid_1's rmse: 0.0934142\n",
      "[2050]\ttraining's rmse: 0.0885166\tvalid_1's rmse: 0.0934146\n",
      "[2075]\ttraining's rmse: 0.0885124\tvalid_1's rmse: 0.0934143\n",
      "Early stopping, best iteration is:\n",
      "[2029]\ttraining's rmse: 0.0885217\tvalid_1's rmse: 0.093414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0940764\tvalid_1's rmse: 0.0904769\n",
      "[50]\ttraining's rmse: 0.0939419\tvalid_1's rmse: 0.0904285\n",
      "[75]\ttraining's rmse: 0.0937945\tvalid_1's rmse: 0.0903772\n",
      "[100]\ttraining's rmse: 0.0936634\tvalid_1's rmse: 0.0903339\n",
      "[125]\ttraining's rmse: 0.0935304\tvalid_1's rmse: 0.0902906\n",
      "[150]\ttraining's rmse: 0.0934062\tvalid_1's rmse: 0.0902529\n",
      "[175]\ttraining's rmse: 0.0933043\tvalid_1's rmse: 0.090221\n",
      "[200]\ttraining's rmse: 0.0931953\tvalid_1's rmse: 0.0901884\n",
      "[225]\ttraining's rmse: 0.0930868\tvalid_1's rmse: 0.0901569\n",
      "[250]\ttraining's rmse: 0.0929943\tvalid_1's rmse: 0.0901282\n",
      "[275]\ttraining's rmse: 0.0929082\tvalid_1's rmse: 0.0901027\n",
      "[300]\ttraining's rmse: 0.0928212\tvalid_1's rmse: 0.0900788\n",
      "[325]\ttraining's rmse: 0.0927366\tvalid_1's rmse: 0.0900562\n",
      "[350]\ttraining's rmse: 0.0926575\tvalid_1's rmse: 0.0900347\n",
      "[375]\ttraining's rmse: 0.0925911\tvalid_1's rmse: 0.0900164\n",
      "[400]\ttraining's rmse: 0.0925167\tvalid_1's rmse: 0.0899975\n",
      "[425]\ttraining's rmse: 0.0924487\tvalid_1's rmse: 0.08998\n",
      "[450]\ttraining's rmse: 0.0923857\tvalid_1's rmse: 0.0899635\n",
      "[475]\ttraining's rmse: 0.0923273\tvalid_1's rmse: 0.0899488\n",
      "[500]\ttraining's rmse: 0.0922777\tvalid_1's rmse: 0.0899341\n",
      "[525]\ttraining's rmse: 0.0922139\tvalid_1's rmse: 0.0899254\n",
      "[550]\ttraining's rmse: 0.0921548\tvalid_1's rmse: 0.089912\n",
      "[575]\ttraining's rmse: 0.0920984\tvalid_1's rmse: 0.0899122\n",
      "[600]\ttraining's rmse: 0.0920443\tvalid_1's rmse: 0.0899033\n",
      "[625]\ttraining's rmse: 0.092\tvalid_1's rmse: 0.0898989\n",
      "[650]\ttraining's rmse: 0.0919436\tvalid_1's rmse: 0.0898953\n",
      "[675]\ttraining's rmse: 0.0918875\tvalid_1's rmse: 0.0898888\n",
      "[700]\ttraining's rmse: 0.0918394\tvalid_1's rmse: 0.0898872\n",
      "[725]\ttraining's rmse: 0.0917951\tvalid_1's rmse: 0.0899005\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 0.0918532\tvalid_1's rmse: 0.0898832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0932979\tvalid_1's rmse: 0.0952666\n",
      "[50]\ttraining's rmse: 0.0930995\tvalid_1's rmse: 0.0952114\n",
      "[75]\ttraining's rmse: 0.0928971\tvalid_1's rmse: 0.0951535\n",
      "[100]\ttraining's rmse: 0.0927152\tvalid_1's rmse: 0.0951055\n",
      "[125]\ttraining's rmse: 0.092538\tvalid_1's rmse: 0.0950588\n",
      "[150]\ttraining's rmse: 0.092374\tvalid_1's rmse: 0.0950122\n",
      "[175]\ttraining's rmse: 0.0922322\tvalid_1's rmse: 0.094973\n",
      "[200]\ttraining's rmse: 0.092087\tvalid_1's rmse: 0.094936\n",
      "[225]\ttraining's rmse: 0.0919476\tvalid_1's rmse: 0.0948991\n",
      "[250]\ttraining's rmse: 0.0918319\tvalid_1's rmse: 0.0948675\n",
      "[275]\ttraining's rmse: 0.0917147\tvalid_1's rmse: 0.0948375\n",
      "[300]\ttraining's rmse: 0.0915973\tvalid_1's rmse: 0.0948066\n",
      "[325]\ttraining's rmse: 0.0914898\tvalid_1's rmse: 0.0947781\n",
      "[350]\ttraining's rmse: 0.0913855\tvalid_1's rmse: 0.094752\n",
      "[375]\ttraining's rmse: 0.0912955\tvalid_1's rmse: 0.094732\n",
      "[400]\ttraining's rmse: 0.0911997\tvalid_1's rmse: 0.0947105\n",
      "[425]\ttraining's rmse: 0.0911138\tvalid_1's rmse: 0.0946913\n",
      "[450]\ttraining's rmse: 0.0910342\tvalid_1's rmse: 0.0946702\n",
      "[475]\ttraining's rmse: 0.0909609\tvalid_1's rmse: 0.0946502\n",
      "[500]\ttraining's rmse: 0.0908986\tvalid_1's rmse: 0.0946324\n",
      "[525]\ttraining's rmse: 0.0908238\tvalid_1's rmse: 0.0946157\n",
      "[550]\ttraining's rmse: 0.0907604\tvalid_1's rmse: 0.0946009\n",
      "[575]\ttraining's rmse: 0.0906918\tvalid_1's rmse: 0.0945894\n",
      "[600]\ttraining's rmse: 0.0906328\tvalid_1's rmse: 0.0945752\n",
      "[625]\ttraining's rmse: 0.0905838\tvalid_1's rmse: 0.0945626\n",
      "[650]\ttraining's rmse: 0.0905265\tvalid_1's rmse: 0.0945501\n",
      "[675]\ttraining's rmse: 0.0904723\tvalid_1's rmse: 0.0945376\n",
      "[700]\ttraining's rmse: 0.090423\tvalid_1's rmse: 0.0945259\n",
      "[725]\ttraining's rmse: 0.0903743\tvalid_1's rmse: 0.0945149\n",
      "[750]\ttraining's rmse: 0.0903271\tvalid_1's rmse: 0.0945042\n",
      "[775]\ttraining's rmse: 0.0902916\tvalid_1's rmse: 0.0944939\n",
      "[800]\ttraining's rmse: 0.0902457\tvalid_1's rmse: 0.0944836\n",
      "[825]\ttraining's rmse: 0.090207\tvalid_1's rmse: 0.0944744\n",
      "[850]\ttraining's rmse: 0.0901697\tvalid_1's rmse: 0.0944672\n",
      "[875]\ttraining's rmse: 0.0901352\tvalid_1's rmse: 0.0944589\n",
      "[900]\ttraining's rmse: 0.0900972\tvalid_1's rmse: 0.0944509\n",
      "[925]\ttraining's rmse: 0.0900593\tvalid_1's rmse: 0.0944422\n",
      "[950]\ttraining's rmse: 0.0900292\tvalid_1's rmse: 0.0944355\n",
      "[975]\ttraining's rmse: 0.089998\tvalid_1's rmse: 0.094428\n",
      "[1000]\ttraining's rmse: 0.0899685\tvalid_1's rmse: 0.0944225\n",
      "[1025]\ttraining's rmse: 0.0899398\tvalid_1's rmse: 0.0944163\n",
      "[1050]\ttraining's rmse: 0.0899127\tvalid_1's rmse: 0.0944089\n",
      "[1075]\ttraining's rmse: 0.0898852\tvalid_1's rmse: 0.0944046\n",
      "[1100]\ttraining's rmse: 0.0898604\tvalid_1's rmse: 0.0943991\n",
      "[1125]\ttraining's rmse: 0.0898377\tvalid_1's rmse: 0.094394\n",
      "[1150]\ttraining's rmse: 0.0898147\tvalid_1's rmse: 0.0943892\n",
      "[1175]\ttraining's rmse: 0.0897911\tvalid_1's rmse: 0.0943846\n",
      "[1200]\ttraining's rmse: 0.0897705\tvalid_1's rmse: 0.0943775\n",
      "[1225]\ttraining's rmse: 0.0897505\tvalid_1's rmse: 0.094372\n",
      "[1250]\ttraining's rmse: 0.0897306\tvalid_1's rmse: 0.0943673\n",
      "[1275]\ttraining's rmse: 0.0897089\tvalid_1's rmse: 0.0943634\n",
      "[1300]\ttraining's rmse: 0.0896938\tvalid_1's rmse: 0.0943591\n",
      "[1325]\ttraining's rmse: 0.0896779\tvalid_1's rmse: 0.0943562\n",
      "[1350]\ttraining's rmse: 0.0896623\tvalid_1's rmse: 0.0943542\n",
      "[1375]\ttraining's rmse: 0.0896446\tvalid_1's rmse: 0.0943511\n",
      "[1400]\ttraining's rmse: 0.0896271\tvalid_1's rmse: 0.0943472\n",
      "[1425]\ttraining's rmse: 0.0896109\tvalid_1's rmse: 0.094344\n",
      "[1450]\ttraining's rmse: 0.0895942\tvalid_1's rmse: 0.0943415\n",
      "[1475]\ttraining's rmse: 0.0895826\tvalid_1's rmse: 0.0943372\n",
      "[1500]\ttraining's rmse: 0.0895684\tvalid_1's rmse: 0.0943338\n",
      "[1525]\ttraining's rmse: 0.0895549\tvalid_1's rmse: 0.0943316\n",
      "[1550]\ttraining's rmse: 0.0895429\tvalid_1's rmse: 0.0943299\n",
      "[1575]\ttraining's rmse: 0.08953\tvalid_1's rmse: 0.0943257\n",
      "[1600]\ttraining's rmse: 0.0895212\tvalid_1's rmse: 0.0943235\n",
      "[1625]\ttraining's rmse: 0.0895104\tvalid_1's rmse: 0.0943195\n",
      "[1650]\ttraining's rmse: 0.089498\tvalid_1's rmse: 0.0943164\n",
      "[1675]\ttraining's rmse: 0.0894897\tvalid_1's rmse: 0.0943132\n",
      "[1700]\ttraining's rmse: 0.0894815\tvalid_1's rmse: 0.0943125\n",
      "[1725]\ttraining's rmse: 0.0894711\tvalid_1's rmse: 0.0943098\n",
      "[1750]\ttraining's rmse: 0.0894622\tvalid_1's rmse: 0.0943077\n",
      "[1775]\ttraining's rmse: 0.0894534\tvalid_1's rmse: 0.0943058\n",
      "[1800]\ttraining's rmse: 0.0894448\tvalid_1's rmse: 0.0943036\n",
      "[1825]\ttraining's rmse: 0.0894353\tvalid_1's rmse: 0.0943018\n",
      "[1850]\ttraining's rmse: 0.0894288\tvalid_1's rmse: 0.0943\n",
      "[1875]\ttraining's rmse: 0.08942\tvalid_1's rmse: 0.0942986\n",
      "[1900]\ttraining's rmse: 0.0894136\tvalid_1's rmse: 0.0942956\n",
      "[1925]\ttraining's rmse: 0.0894086\tvalid_1's rmse: 0.0942945\n",
      "[1950]\ttraining's rmse: 0.0894038\tvalid_1's rmse: 0.0942931\n",
      "[1975]\ttraining's rmse: 0.0893985\tvalid_1's rmse: 0.0942916\n",
      "[2000]\ttraining's rmse: 0.0893928\tvalid_1's rmse: 0.0942909\n",
      "[2025]\ttraining's rmse: 0.0893871\tvalid_1's rmse: 0.0942895\n",
      "[2050]\ttraining's rmse: 0.0893806\tvalid_1's rmse: 0.0942894\n",
      "[2075]\ttraining's rmse: 0.0893754\tvalid_1's rmse: 0.0942879\n",
      "[2100]\ttraining's rmse: 0.0893708\tvalid_1's rmse: 0.0942867\n",
      "[2125]\ttraining's rmse: 0.0893658\tvalid_1's rmse: 0.0942854\n",
      "[2150]\ttraining's rmse: 0.0893618\tvalid_1's rmse: 0.0942842\n",
      "[2175]\ttraining's rmse: 0.089358\tvalid_1's rmse: 0.094284\n",
      "[2200]\ttraining's rmse: 0.0893533\tvalid_1's rmse: 0.0942821\n",
      "[2225]\ttraining's rmse: 0.0893482\tvalid_1's rmse: 0.0942804\n",
      "[2250]\ttraining's rmse: 0.0893442\tvalid_1's rmse: 0.0942792\n",
      "[2275]\ttraining's rmse: 0.0893388\tvalid_1's rmse: 0.0942776\n",
      "[2300]\ttraining's rmse: 0.089335\tvalid_1's rmse: 0.0942762\n",
      "[2325]\ttraining's rmse: 0.0893305\tvalid_1's rmse: 0.094274\n",
      "[2350]\ttraining's rmse: 0.0893269\tvalid_1's rmse: 0.094273\n",
      "[2375]\ttraining's rmse: 0.0893239\tvalid_1's rmse: 0.094272\n",
      "[2400]\ttraining's rmse: 0.0893211\tvalid_1's rmse: 0.0942717\n",
      "[2425]\ttraining's rmse: 0.0893164\tvalid_1's rmse: 0.094271\n",
      "[2450]\ttraining's rmse: 0.0893141\tvalid_1's rmse: 0.0942711\n",
      "[2475]\ttraining's rmse: 0.0893102\tvalid_1's rmse: 0.0942707\n",
      "[2500]\ttraining's rmse: 0.089307\tvalid_1's rmse: 0.0942701\n",
      "[2525]\ttraining's rmse: 0.0893038\tvalid_1's rmse: 0.0942686\n",
      "[2550]\ttraining's rmse: 0.089301\tvalid_1's rmse: 0.094268\n",
      "[2575]\ttraining's rmse: 0.0892978\tvalid_1's rmse: 0.0942677\n",
      "[2600]\ttraining's rmse: 0.0892949\tvalid_1's rmse: 0.0942667\n",
      "[2625]\ttraining's rmse: 0.0892929\tvalid_1's rmse: 0.094266\n",
      "[2650]\ttraining's rmse: 0.089291\tvalid_1's rmse: 0.0942654\n",
      "[2675]\ttraining's rmse: 0.0892887\tvalid_1's rmse: 0.0942652\n",
      "[2700]\ttraining's rmse: 0.0892857\tvalid_1's rmse: 0.0942646\n",
      "[2725]\ttraining's rmse: 0.0892824\tvalid_1's rmse: 0.0942642\n",
      "[2750]\ttraining's rmse: 0.0892799\tvalid_1's rmse: 0.0942635\n",
      "[2775]\ttraining's rmse: 0.0892776\tvalid_1's rmse: 0.0942626\n",
      "[2800]\ttraining's rmse: 0.0892744\tvalid_1's rmse: 0.0942616\n",
      "[2825]\ttraining's rmse: 0.0892717\tvalid_1's rmse: 0.0942612\n",
      "[2850]\ttraining's rmse: 0.0892691\tvalid_1's rmse: 0.0942607\n",
      "[2875]\ttraining's rmse: 0.0892656\tvalid_1's rmse: 0.0942606\n",
      "[2900]\ttraining's rmse: 0.0892636\tvalid_1's rmse: 0.0942605\n",
      "[2925]\ttraining's rmse: 0.0892611\tvalid_1's rmse: 0.0942607\n",
      "Early stopping, best iteration is:\n",
      "[2884]\ttraining's rmse: 0.0892653\tvalid_1's rmse: 0.0942605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0933201\tvalid_1's rmse: 0.0952407\n",
      "[50]\ttraining's rmse: 0.0931352\tvalid_1's rmse: 0.0951825\n",
      "[75]\ttraining's rmse: 0.092951\tvalid_1's rmse: 0.0951262\n",
      "[100]\ttraining's rmse: 0.0927832\tvalid_1's rmse: 0.0950758\n",
      "[125]\ttraining's rmse: 0.0926163\tvalid_1's rmse: 0.0950272\n",
      "[150]\ttraining's rmse: 0.0924632\tvalid_1's rmse: 0.09498\n",
      "[175]\ttraining's rmse: 0.0923335\tvalid_1's rmse: 0.0949417\n",
      "[200]\ttraining's rmse: 0.0921958\tvalid_1's rmse: 0.0949027\n",
      "[225]\ttraining's rmse: 0.0920675\tvalid_1's rmse: 0.0948659\n",
      "[250]\ttraining's rmse: 0.0919538\tvalid_1's rmse: 0.0948324\n",
      "[275]\ttraining's rmse: 0.0918515\tvalid_1's rmse: 0.0948046\n",
      "[300]\ttraining's rmse: 0.0917493\tvalid_1's rmse: 0.0947768\n",
      "[325]\ttraining's rmse: 0.0916477\tvalid_1's rmse: 0.0947509\n",
      "[350]\ttraining's rmse: 0.0915511\tvalid_1's rmse: 0.0947264\n",
      "[375]\ttraining's rmse: 0.0914731\tvalid_1's rmse: 0.0947052\n",
      "[400]\ttraining's rmse: 0.0913871\tvalid_1's rmse: 0.0946841\n",
      "[425]\ttraining's rmse: 0.0913095\tvalid_1's rmse: 0.0946636\n",
      "[450]\ttraining's rmse: 0.0912366\tvalid_1's rmse: 0.0946449\n",
      "[475]\ttraining's rmse: 0.0911699\tvalid_1's rmse: 0.0946278\n",
      "[500]\ttraining's rmse: 0.0911109\tvalid_1's rmse: 0.094611\n",
      "[525]\ttraining's rmse: 0.0910407\tvalid_1's rmse: 0.0945936\n",
      "[550]\ttraining's rmse: 0.0909734\tvalid_1's rmse: 0.0945789\n",
      "[575]\ttraining's rmse: 0.0909132\tvalid_1's rmse: 0.0945656\n",
      "[600]\ttraining's rmse: 0.090854\tvalid_1's rmse: 0.0945523\n",
      "[625]\ttraining's rmse: 0.0908038\tvalid_1's rmse: 0.0945397\n",
      "[650]\ttraining's rmse: 0.0907458\tvalid_1's rmse: 0.0945271\n",
      "[675]\ttraining's rmse: 0.090691\tvalid_1's rmse: 0.0945154\n",
      "[700]\ttraining's rmse: 0.0906447\tvalid_1's rmse: 0.0945054\n",
      "[725]\ttraining's rmse: 0.0906019\tvalid_1's rmse: 0.0944977\n",
      "[750]\ttraining's rmse: 0.0905598\tvalid_1's rmse: 0.0944896\n",
      "[775]\ttraining's rmse: 0.0905222\tvalid_1's rmse: 0.0944807\n",
      "[800]\ttraining's rmse: 0.0904767\tvalid_1's rmse: 0.0944734\n",
      "[825]\ttraining's rmse: 0.0904372\tvalid_1's rmse: 0.0944656\n",
      "[850]\ttraining's rmse: 0.0903971\tvalid_1's rmse: 0.0944583\n",
      "[875]\ttraining's rmse: 0.090364\tvalid_1's rmse: 0.0944518\n",
      "[900]\ttraining's rmse: 0.0903284\tvalid_1's rmse: 0.0944455\n",
      "[925]\ttraining's rmse: 0.0902951\tvalid_1's rmse: 0.0944398\n",
      "[950]\ttraining's rmse: 0.0902634\tvalid_1's rmse: 0.0944347\n",
      "[975]\ttraining's rmse: 0.0902298\tvalid_1's rmse: 0.0944292\n",
      "[1000]\ttraining's rmse: 0.0902004\tvalid_1's rmse: 0.0944246\n",
      "[1025]\ttraining's rmse: 0.09017\tvalid_1's rmse: 0.0944205\n",
      "[1050]\ttraining's rmse: 0.0901429\tvalid_1's rmse: 0.0944164\n",
      "[1075]\ttraining's rmse: 0.0901159\tvalid_1's rmse: 0.0944138\n",
      "[1100]\ttraining's rmse: 0.0900924\tvalid_1's rmse: 0.0944103\n",
      "[1125]\ttraining's rmse: 0.0900697\tvalid_1's rmse: 0.0944074\n",
      "[1150]\ttraining's rmse: 0.0900455\tvalid_1's rmse: 0.0944046\n",
      "[1175]\ttraining's rmse: 0.090025\tvalid_1's rmse: 0.0944026\n",
      "[1200]\ttraining's rmse: 0.0900033\tvalid_1's rmse: 0.0943993\n",
      "[1225]\ttraining's rmse: 0.0899815\tvalid_1's rmse: 0.0943974\n",
      "[1250]\ttraining's rmse: 0.0899622\tvalid_1's rmse: 0.0943954\n",
      "[1275]\ttraining's rmse: 0.0899407\tvalid_1's rmse: 0.0943932\n",
      "[1300]\ttraining's rmse: 0.0899236\tvalid_1's rmse: 0.0943908\n",
      "[1325]\ttraining's rmse: 0.0899046\tvalid_1's rmse: 0.0943887\n",
      "[1350]\ttraining's rmse: 0.0898841\tvalid_1's rmse: 0.0943873\n",
      "[1375]\ttraining's rmse: 0.0898649\tvalid_1's rmse: 0.0943856\n",
      "[1400]\ttraining's rmse: 0.0898513\tvalid_1's rmse: 0.0943841\n",
      "[1425]\ttraining's rmse: 0.0898339\tvalid_1's rmse: 0.0943833\n",
      "[1450]\ttraining's rmse: 0.0898185\tvalid_1's rmse: 0.0943822\n",
      "[1475]\ttraining's rmse: 0.0898037\tvalid_1's rmse: 0.0943799\n",
      "[1500]\ttraining's rmse: 0.089791\tvalid_1's rmse: 0.0943792\n",
      "[1525]\ttraining's rmse: 0.0897766\tvalid_1's rmse: 0.0943785\n",
      "[1550]\ttraining's rmse: 0.089763\tvalid_1's rmse: 0.0943779\n",
      "[1575]\ttraining's rmse: 0.0897496\tvalid_1's rmse: 0.0943762\n",
      "[1600]\ttraining's rmse: 0.0897395\tvalid_1's rmse: 0.0943759\n",
      "[1625]\ttraining's rmse: 0.0897267\tvalid_1's rmse: 0.0943749\n",
      "[1650]\ttraining's rmse: 0.0897145\tvalid_1's rmse: 0.0943744\n",
      "[1675]\ttraining's rmse: 0.0897069\tvalid_1's rmse: 0.0943737\n",
      "[1700]\ttraining's rmse: 0.0896982\tvalid_1's rmse: 0.0943735\n",
      "[1725]\ttraining's rmse: 0.0896879\tvalid_1's rmse: 0.0943728\n",
      "[1750]\ttraining's rmse: 0.0896781\tvalid_1's rmse: 0.0943724\n",
      "[1775]\ttraining's rmse: 0.0896688\tvalid_1's rmse: 0.0943723\n",
      "[1800]\ttraining's rmse: 0.0896594\tvalid_1's rmse: 0.0943719\n",
      "[1825]\ttraining's rmse: 0.0896504\tvalid_1's rmse: 0.0943709\n",
      "[1850]\ttraining's rmse: 0.0896427\tvalid_1's rmse: 0.09437\n",
      "[1875]\ttraining's rmse: 0.0896362\tvalid_1's rmse: 0.0943698\n",
      "[1900]\ttraining's rmse: 0.0896303\tvalid_1's rmse: 0.0943699\n",
      "[1925]\ttraining's rmse: 0.0896228\tvalid_1's rmse: 0.0943697\n",
      "[1950]\ttraining's rmse: 0.0896181\tvalid_1's rmse: 0.0943689\n",
      "[1975]\ttraining's rmse: 0.0896106\tvalid_1's rmse: 0.0943684\n",
      "[2000]\ttraining's rmse: 0.0896035\tvalid_1's rmse: 0.0943684\n",
      "[2025]\ttraining's rmse: 0.089598\tvalid_1's rmse: 0.0943678\n",
      "[2050]\ttraining's rmse: 0.0895935\tvalid_1's rmse: 0.0943678\n",
      "[2075]\ttraining's rmse: 0.0895876\tvalid_1's rmse: 0.0943673\n",
      "[2100]\ttraining's rmse: 0.0895835\tvalid_1's rmse: 0.0943672\n",
      "[2125]\ttraining's rmse: 0.0895796\tvalid_1's rmse: 0.0943672\n",
      "[2150]\ttraining's rmse: 0.0895745\tvalid_1's rmse: 0.0943672\n",
      "Early stopping, best iteration is:\n",
      "[2115]\ttraining's rmse: 0.0895812\tvalid_1's rmse: 0.094367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0950968\tvalid_1's rmse: 0.0917187\n",
      "[50]\ttraining's rmse: 0.0949572\tvalid_1's rmse: 0.0916673\n",
      "[75]\ttraining's rmse: 0.0948068\tvalid_1's rmse: 0.091615\n",
      "[100]\ttraining's rmse: 0.0946691\tvalid_1's rmse: 0.0915706\n",
      "[125]\ttraining's rmse: 0.0945292\tvalid_1's rmse: 0.0915281\n",
      "[150]\ttraining's rmse: 0.0944036\tvalid_1's rmse: 0.0914878\n",
      "[175]\ttraining's rmse: 0.0942983\tvalid_1's rmse: 0.0914563\n",
      "[200]\ttraining's rmse: 0.0941837\tvalid_1's rmse: 0.0914239\n",
      "[225]\ttraining's rmse: 0.0940726\tvalid_1's rmse: 0.0913929\n",
      "[250]\ttraining's rmse: 0.0939762\tvalid_1's rmse: 0.091364\n",
      "[275]\ttraining's rmse: 0.0938889\tvalid_1's rmse: 0.0913389\n",
      "[300]\ttraining's rmse: 0.0938001\tvalid_1's rmse: 0.0913149\n",
      "[325]\ttraining's rmse: 0.0937142\tvalid_1's rmse: 0.0912916\n",
      "[350]\ttraining's rmse: 0.0936303\tvalid_1's rmse: 0.0912703\n",
      "[375]\ttraining's rmse: 0.0935583\tvalid_1's rmse: 0.0912635\n",
      "[400]\ttraining's rmse: 0.0934792\tvalid_1's rmse: 0.0912461\n",
      "[425]\ttraining's rmse: 0.0934081\tvalid_1's rmse: 0.0912377\n",
      "[450]\ttraining's rmse: 0.0933431\tvalid_1's rmse: 0.0912213\n",
      "[475]\ttraining's rmse: 0.0932798\tvalid_1's rmse: 0.0912062\n",
      "[500]\ttraining's rmse: 0.0932271\tvalid_1's rmse: 0.091192\n",
      "[525]\ttraining's rmse: 0.0931584\tvalid_1's rmse: 0.0911772\n",
      "[550]\ttraining's rmse: 0.0930976\tvalid_1's rmse: 0.091165\n",
      "[575]\ttraining's rmse: 0.093042\tvalid_1's rmse: 0.0911607\n",
      "[600]\ttraining's rmse: 0.0929852\tvalid_1's rmse: 0.0911502\n",
      "[625]\ttraining's rmse: 0.0929406\tvalid_1's rmse: 0.0911408\n",
      "[650]\ttraining's rmse: 0.0928857\tvalid_1's rmse: 0.0911399\n",
      "[675]\ttraining's rmse: 0.0928292\tvalid_1's rmse: 0.0911399\n",
      "[700]\ttraining's rmse: 0.0927807\tvalid_1's rmse: 0.0911322\n",
      "[725]\ttraining's rmse: 0.0927356\tvalid_1's rmse: 0.0911269\n",
      "[750]\ttraining's rmse: 0.0926933\tvalid_1's rmse: 0.0911217\n",
      "[775]\ttraining's rmse: 0.0926574\tvalid_1's rmse: 0.0911223\n",
      "[800]\ttraining's rmse: 0.0926091\tvalid_1's rmse: 0.0911182\n",
      "[825]\ttraining's rmse: 0.0925698\tvalid_1's rmse: 0.0911215\n",
      "[850]\ttraining's rmse: 0.0925311\tvalid_1's rmse: 0.0911159\n",
      "[875]\ttraining's rmse: 0.0924964\tvalid_1's rmse: 0.0911162\n",
      "[900]\ttraining's rmse: 0.0924555\tvalid_1's rmse: 0.0911199\n",
      "[925]\ttraining's rmse: 0.0924209\tvalid_1's rmse: 0.0911237\n",
      "Early stopping, best iteration is:\n",
      "[881]\ttraining's rmse: 0.0924871\tvalid_1's rmse: 0.0911144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0925467\tvalid_1's rmse: 0.0946064\n",
      "[50]\ttraining's rmse: 0.0923501\tvalid_1's rmse: 0.0945474\n",
      "[75]\ttraining's rmse: 0.0921606\tvalid_1's rmse: 0.094491\n",
      "[100]\ttraining's rmse: 0.0919848\tvalid_1's rmse: 0.0944419\n",
      "[125]\ttraining's rmse: 0.0918107\tvalid_1's rmse: 0.0943935\n",
      "[150]\ttraining's rmse: 0.0916517\tvalid_1's rmse: 0.0943463\n",
      "[175]\ttraining's rmse: 0.0915182\tvalid_1's rmse: 0.094307\n",
      "[200]\ttraining's rmse: 0.0913788\tvalid_1's rmse: 0.0942705\n",
      "[225]\ttraining's rmse: 0.0912408\tvalid_1's rmse: 0.0942311\n",
      "[250]\ttraining's rmse: 0.0911238\tvalid_1's rmse: 0.0941967\n",
      "[275]\ttraining's rmse: 0.0910127\tvalid_1's rmse: 0.0941656\n",
      "[300]\ttraining's rmse: 0.0909059\tvalid_1's rmse: 0.0941356\n",
      "[325]\ttraining's rmse: 0.0908024\tvalid_1's rmse: 0.0941073\n",
      "[350]\ttraining's rmse: 0.0907013\tvalid_1's rmse: 0.0940812\n",
      "[375]\ttraining's rmse: 0.090615\tvalid_1's rmse: 0.0940587\n",
      "[400]\ttraining's rmse: 0.0905243\tvalid_1's rmse: 0.0940349\n",
      "[425]\ttraining's rmse: 0.0904422\tvalid_1's rmse: 0.0940123\n",
      "[450]\ttraining's rmse: 0.0903687\tvalid_1's rmse: 0.0939911\n",
      "[475]\ttraining's rmse: 0.0902966\tvalid_1's rmse: 0.0939722\n",
      "[500]\ttraining's rmse: 0.0902347\tvalid_1's rmse: 0.0939518\n",
      "[525]\ttraining's rmse: 0.0901652\tvalid_1's rmse: 0.0939335\n",
      "[550]\ttraining's rmse: 0.0901023\tvalid_1's rmse: 0.0939177\n",
      "[575]\ttraining's rmse: 0.0900429\tvalid_1's rmse: 0.093903\n",
      "[600]\ttraining's rmse: 0.0899842\tvalid_1's rmse: 0.093889\n",
      "[625]\ttraining's rmse: 0.0899358\tvalid_1's rmse: 0.0938747\n",
      "[650]\ttraining's rmse: 0.089879\tvalid_1's rmse: 0.0938617\n",
      "[675]\ttraining's rmse: 0.0898244\tvalid_1's rmse: 0.0938469\n",
      "[700]\ttraining's rmse: 0.0897767\tvalid_1's rmse: 0.0938349\n",
      "[725]\ttraining's rmse: 0.0897316\tvalid_1's rmse: 0.0938243\n",
      "[750]\ttraining's rmse: 0.0896886\tvalid_1's rmse: 0.0938144\n",
      "[775]\ttraining's rmse: 0.0896505\tvalid_1's rmse: 0.0938008\n",
      "[800]\ttraining's rmse: 0.0896028\tvalid_1's rmse: 0.0937914\n",
      "[825]\ttraining's rmse: 0.0895635\tvalid_1's rmse: 0.0937803\n",
      "[850]\ttraining's rmse: 0.0895221\tvalid_1's rmse: 0.0937722\n",
      "[875]\ttraining's rmse: 0.0894898\tvalid_1's rmse: 0.093765\n",
      "[900]\ttraining's rmse: 0.0894564\tvalid_1's rmse: 0.0937552\n",
      "[925]\ttraining's rmse: 0.0894236\tvalid_1's rmse: 0.0937474\n",
      "[950]\ttraining's rmse: 0.0893898\tvalid_1's rmse: 0.0937422\n",
      "[975]\ttraining's rmse: 0.0893568\tvalid_1's rmse: 0.0937341\n",
      "[1000]\ttraining's rmse: 0.089328\tvalid_1's rmse: 0.0937268\n",
      "[1025]\ttraining's rmse: 0.0892953\tvalid_1's rmse: 0.0937199\n",
      "[1050]\ttraining's rmse: 0.0892684\tvalid_1's rmse: 0.0937121\n",
      "[1075]\ttraining's rmse: 0.0892414\tvalid_1's rmse: 0.0937062\n",
      "[1100]\ttraining's rmse: 0.0892211\tvalid_1's rmse: 0.0936997\n",
      "[1125]\ttraining's rmse: 0.0891964\tvalid_1's rmse: 0.0936939\n",
      "[1150]\ttraining's rmse: 0.0891738\tvalid_1's rmse: 0.0936894\n",
      "[1175]\ttraining's rmse: 0.0891529\tvalid_1's rmse: 0.0936858\n",
      "[1200]\ttraining's rmse: 0.089133\tvalid_1's rmse: 0.0936803\n",
      "[1225]\ttraining's rmse: 0.0891142\tvalid_1's rmse: 0.0936765\n",
      "[1250]\ttraining's rmse: 0.0890947\tvalid_1's rmse: 0.0936722\n",
      "[1275]\ttraining's rmse: 0.0890739\tvalid_1's rmse: 0.0936665\n",
      "[1300]\ttraining's rmse: 0.0890602\tvalid_1's rmse: 0.0936625\n",
      "[1325]\ttraining's rmse: 0.0890426\tvalid_1's rmse: 0.0936592\n",
      "[1350]\ttraining's rmse: 0.089025\tvalid_1's rmse: 0.0936552\n",
      "[1375]\ttraining's rmse: 0.089009\tvalid_1's rmse: 0.0936513\n",
      "[1400]\ttraining's rmse: 0.0889905\tvalid_1's rmse: 0.0936474\n",
      "[1425]\ttraining's rmse: 0.0889765\tvalid_1's rmse: 0.0936444\n",
      "[1450]\ttraining's rmse: 0.0889601\tvalid_1's rmse: 0.0936427\n",
      "[1475]\ttraining's rmse: 0.0889477\tvalid_1's rmse: 0.0936383\n",
      "[1500]\ttraining's rmse: 0.088936\tvalid_1's rmse: 0.0936351\n",
      "[1525]\ttraining's rmse: 0.0889211\tvalid_1's rmse: 0.0936316\n",
      "[1550]\ttraining's rmse: 0.0889077\tvalid_1's rmse: 0.0936285\n",
      "[1575]\ttraining's rmse: 0.0888978\tvalid_1's rmse: 0.0936249\n",
      "[1600]\ttraining's rmse: 0.0888883\tvalid_1's rmse: 0.093622\n",
      "[1625]\ttraining's rmse: 0.0888792\tvalid_1's rmse: 0.0936185\n",
      "[1650]\ttraining's rmse: 0.0888707\tvalid_1's rmse: 0.093616\n",
      "[1675]\ttraining's rmse: 0.0888616\tvalid_1's rmse: 0.0936146\n",
      "[1700]\ttraining's rmse: 0.0888509\tvalid_1's rmse: 0.0936124\n",
      "[1725]\ttraining's rmse: 0.0888424\tvalid_1's rmse: 0.0936105\n",
      "[1750]\ttraining's rmse: 0.0888326\tvalid_1's rmse: 0.0936083\n",
      "[1775]\ttraining's rmse: 0.0888255\tvalid_1's rmse: 0.0936072\n",
      "[1800]\ttraining's rmse: 0.0888161\tvalid_1's rmse: 0.0936051\n",
      "[1825]\ttraining's rmse: 0.0888085\tvalid_1's rmse: 0.0936035\n",
      "[1850]\ttraining's rmse: 0.0888012\tvalid_1's rmse: 0.0936028\n",
      "[1875]\ttraining's rmse: 0.0887944\tvalid_1's rmse: 0.0936016\n",
      "[1900]\ttraining's rmse: 0.0887877\tvalid_1's rmse: 0.0936007\n",
      "[1925]\ttraining's rmse: 0.0887812\tvalid_1's rmse: 0.0935996\n",
      "[1950]\ttraining's rmse: 0.0887751\tvalid_1's rmse: 0.0935975\n",
      "[1975]\ttraining's rmse: 0.0887701\tvalid_1's rmse: 0.0935965\n",
      "[2000]\ttraining's rmse: 0.0887648\tvalid_1's rmse: 0.0935958\n",
      "[2025]\ttraining's rmse: 0.0887591\tvalid_1's rmse: 0.0935942\n",
      "[2050]\ttraining's rmse: 0.0887524\tvalid_1's rmse: 0.0935927\n",
      "[2075]\ttraining's rmse: 0.0887466\tvalid_1's rmse: 0.0935919\n",
      "[2100]\ttraining's rmse: 0.0887426\tvalid_1's rmse: 0.0935916\n",
      "[2125]\ttraining's rmse: 0.0887388\tvalid_1's rmse: 0.0935901\n",
      "[2150]\ttraining's rmse: 0.0887336\tvalid_1's rmse: 0.0935896\n",
      "[2175]\ttraining's rmse: 0.0887303\tvalid_1's rmse: 0.0935882\n",
      "[2200]\ttraining's rmse: 0.0887259\tvalid_1's rmse: 0.0935861\n",
      "[2225]\ttraining's rmse: 0.0887227\tvalid_1's rmse: 0.0935851\n",
      "[2250]\ttraining's rmse: 0.0887187\tvalid_1's rmse: 0.093584\n",
      "[2275]\ttraining's rmse: 0.0887145\tvalid_1's rmse: 0.0935828\n",
      "[2300]\ttraining's rmse: 0.0887102\tvalid_1's rmse: 0.0935815\n",
      "[2325]\ttraining's rmse: 0.0887063\tvalid_1's rmse: 0.0935806\n",
      "[2350]\ttraining's rmse: 0.0887031\tvalid_1's rmse: 0.0935794\n",
      "[2375]\ttraining's rmse: 0.0887004\tvalid_1's rmse: 0.0935782\n",
      "[2400]\ttraining's rmse: 0.0886977\tvalid_1's rmse: 0.0935781\n",
      "[2425]\ttraining's rmse: 0.0886957\tvalid_1's rmse: 0.0935782\n",
      "[2450]\ttraining's rmse: 0.0886933\tvalid_1's rmse: 0.0935771\n",
      "[2475]\ttraining's rmse: 0.0886907\tvalid_1's rmse: 0.0935767\n",
      "[2500]\ttraining's rmse: 0.0886876\tvalid_1's rmse: 0.0935764\n",
      "[2525]\ttraining's rmse: 0.0886841\tvalid_1's rmse: 0.0935752\n",
      "[2550]\ttraining's rmse: 0.0886804\tvalid_1's rmse: 0.0935739\n",
      "[2575]\ttraining's rmse: 0.0886781\tvalid_1's rmse: 0.0935737\n",
      "[2600]\ttraining's rmse: 0.0886759\tvalid_1's rmse: 0.0935728\n",
      "[2625]\ttraining's rmse: 0.0886734\tvalid_1's rmse: 0.093572\n",
      "[2650]\ttraining's rmse: 0.0886721\tvalid_1's rmse: 0.0935709\n",
      "[2675]\ttraining's rmse: 0.0886696\tvalid_1's rmse: 0.0935707\n",
      "[2700]\ttraining's rmse: 0.0886679\tvalid_1's rmse: 0.0935704\n",
      "[2725]\ttraining's rmse: 0.0886651\tvalid_1's rmse: 0.0935699\n",
      "[2750]\ttraining's rmse: 0.0886628\tvalid_1's rmse: 0.0935691\n",
      "[2775]\ttraining's rmse: 0.0886595\tvalid_1's rmse: 0.0935679\n",
      "[2800]\ttraining's rmse: 0.0886577\tvalid_1's rmse: 0.0935671\n",
      "[2825]\ttraining's rmse: 0.0886538\tvalid_1's rmse: 0.0935668\n",
      "[2850]\ttraining's rmse: 0.0886513\tvalid_1's rmse: 0.0935668\n",
      "[2875]\ttraining's rmse: 0.0886493\tvalid_1's rmse: 0.0935667\n",
      "Early stopping, best iteration is:\n",
      "[2832]\ttraining's rmse: 0.0886527\tvalid_1's rmse: 0.0935665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0925788\tvalid_1's rmse: 0.0945508\n",
      "[50]\ttraining's rmse: 0.0924006\tvalid_1's rmse: 0.0944921\n",
      "[75]\ttraining's rmse: 0.0922194\tvalid_1's rmse: 0.0944348\n",
      "[100]\ttraining's rmse: 0.0920554\tvalid_1's rmse: 0.0943844\n",
      "[125]\ttraining's rmse: 0.0918894\tvalid_1's rmse: 0.0943355\n",
      "[150]\ttraining's rmse: 0.0917407\tvalid_1's rmse: 0.0942897\n",
      "[175]\ttraining's rmse: 0.0916132\tvalid_1's rmse: 0.0942522\n",
      "[200]\ttraining's rmse: 0.091479\tvalid_1's rmse: 0.0942142\n",
      "[225]\ttraining's rmse: 0.0913537\tvalid_1's rmse: 0.094178\n",
      "[250]\ttraining's rmse: 0.0912421\tvalid_1's rmse: 0.0941451\n",
      "[275]\ttraining's rmse: 0.0911405\tvalid_1's rmse: 0.0941144\n",
      "[300]\ttraining's rmse: 0.0910419\tvalid_1's rmse: 0.0940871\n",
      "[325]\ttraining's rmse: 0.0909425\tvalid_1's rmse: 0.0940598\n",
      "[350]\ttraining's rmse: 0.0908443\tvalid_1's rmse: 0.0940328\n",
      "[375]\ttraining's rmse: 0.0907638\tvalid_1's rmse: 0.0940115\n",
      "[400]\ttraining's rmse: 0.0906814\tvalid_1's rmse: 0.0939909\n",
      "[425]\ttraining's rmse: 0.0906019\tvalid_1's rmse: 0.0939696\n",
      "[450]\ttraining's rmse: 0.0905276\tvalid_1's rmse: 0.0939504\n",
      "[475]\ttraining's rmse: 0.0904619\tvalid_1's rmse: 0.0939327\n",
      "[500]\ttraining's rmse: 0.0904036\tvalid_1's rmse: 0.0939154\n",
      "[525]\ttraining's rmse: 0.0903342\tvalid_1's rmse: 0.0938968\n",
      "[550]\ttraining's rmse: 0.0902686\tvalid_1's rmse: 0.0938814\n",
      "[575]\ttraining's rmse: 0.0902115\tvalid_1's rmse: 0.093867\n",
      "[600]\ttraining's rmse: 0.0901569\tvalid_1's rmse: 0.0938551\n",
      "[625]\ttraining's rmse: 0.0901106\tvalid_1's rmse: 0.0938429\n",
      "[650]\ttraining's rmse: 0.0900551\tvalid_1's rmse: 0.0938302\n",
      "[675]\ttraining's rmse: 0.0900007\tvalid_1's rmse: 0.0938181\n",
      "[700]\ttraining's rmse: 0.0899515\tvalid_1's rmse: 0.0938073\n",
      "[725]\ttraining's rmse: 0.0899064\tvalid_1's rmse: 0.0937971\n",
      "[750]\ttraining's rmse: 0.0898652\tvalid_1's rmse: 0.0937888\n",
      "[775]\ttraining's rmse: 0.0898291\tvalid_1's rmse: 0.0937803\n",
      "[800]\ttraining's rmse: 0.089781\tvalid_1's rmse: 0.0937716\n",
      "[825]\ttraining's rmse: 0.089742\tvalid_1's rmse: 0.0937632\n",
      "[850]\ttraining's rmse: 0.0897035\tvalid_1's rmse: 0.0937557\n",
      "[875]\ttraining's rmse: 0.0896701\tvalid_1's rmse: 0.0937496\n",
      "[900]\ttraining's rmse: 0.0896337\tvalid_1's rmse: 0.093743\n",
      "[925]\ttraining's rmse: 0.0896004\tvalid_1's rmse: 0.0937378\n",
      "[950]\ttraining's rmse: 0.0895709\tvalid_1's rmse: 0.0937318\n",
      "[975]\ttraining's rmse: 0.0895416\tvalid_1's rmse: 0.0937273\n",
      "[1000]\ttraining's rmse: 0.0895128\tvalid_1's rmse: 0.0937215\n",
      "[1025]\ttraining's rmse: 0.0894796\tvalid_1's rmse: 0.093717\n",
      "[1050]\ttraining's rmse: 0.089452\tvalid_1's rmse: 0.0937122\n",
      "[1075]\ttraining's rmse: 0.0894245\tvalid_1's rmse: 0.0937084\n",
      "[1100]\ttraining's rmse: 0.0894022\tvalid_1's rmse: 0.0937047\n",
      "[1125]\ttraining's rmse: 0.0893757\tvalid_1's rmse: 0.0936991\n",
      "[1150]\ttraining's rmse: 0.0893522\tvalid_1's rmse: 0.0936969\n",
      "[1175]\ttraining's rmse: 0.0893311\tvalid_1's rmse: 0.0936944\n",
      "[1200]\ttraining's rmse: 0.0893063\tvalid_1's rmse: 0.0936909\n",
      "[1225]\ttraining's rmse: 0.0892843\tvalid_1's rmse: 0.0936878\n",
      "[1250]\ttraining's rmse: 0.0892643\tvalid_1's rmse: 0.0936856\n",
      "[1275]\ttraining's rmse: 0.0892454\tvalid_1's rmse: 0.0936845\n",
      "[1300]\ttraining's rmse: 0.0892292\tvalid_1's rmse: 0.0936823\n",
      "[1325]\ttraining's rmse: 0.089211\tvalid_1's rmse: 0.0936807\n",
      "[1350]\ttraining's rmse: 0.089194\tvalid_1's rmse: 0.0936794\n",
      "[1375]\ttraining's rmse: 0.0891783\tvalid_1's rmse: 0.0936778\n",
      "[1400]\ttraining's rmse: 0.0891642\tvalid_1's rmse: 0.0936755\n",
      "[1425]\ttraining's rmse: 0.0891472\tvalid_1's rmse: 0.0936745\n",
      "[1450]\ttraining's rmse: 0.0891329\tvalid_1's rmse: 0.0936735\n",
      "[1475]\ttraining's rmse: 0.0891215\tvalid_1's rmse: 0.0936721\n",
      "[1500]\ttraining's rmse: 0.089109\tvalid_1's rmse: 0.093671\n",
      "[1525]\ttraining's rmse: 0.0890954\tvalid_1's rmse: 0.0936701\n",
      "[1550]\ttraining's rmse: 0.0890837\tvalid_1's rmse: 0.093669\n",
      "[1575]\ttraining's rmse: 0.0890719\tvalid_1's rmse: 0.0936685\n",
      "[1600]\ttraining's rmse: 0.0890613\tvalid_1's rmse: 0.0936676\n",
      "[1625]\ttraining's rmse: 0.0890501\tvalid_1's rmse: 0.0936663\n",
      "[1650]\ttraining's rmse: 0.0890401\tvalid_1's rmse: 0.093666\n",
      "[1675]\ttraining's rmse: 0.0890327\tvalid_1's rmse: 0.093665\n",
      "[1700]\ttraining's rmse: 0.0890233\tvalid_1's rmse: 0.0936637\n",
      "[1725]\ttraining's rmse: 0.0890144\tvalid_1's rmse: 0.0936628\n",
      "[1750]\ttraining's rmse: 0.0890042\tvalid_1's rmse: 0.0936627\n",
      "[1775]\ttraining's rmse: 0.088995\tvalid_1's rmse: 0.0936628\n",
      "Early stopping, best iteration is:\n",
      "[1739]\ttraining's rmse: 0.0890097\tvalid_1's rmse: 0.0936622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0944275\tvalid_1's rmse: 0.090891\n",
      "[50]\ttraining's rmse: 0.0942932\tvalid_1's rmse: 0.0908419\n",
      "[75]\ttraining's rmse: 0.0941491\tvalid_1's rmse: 0.090792\n",
      "[100]\ttraining's rmse: 0.0940203\tvalid_1's rmse: 0.0907498\n",
      "[125]\ttraining's rmse: 0.093885\tvalid_1's rmse: 0.0907064\n",
      "[150]\ttraining's rmse: 0.0937602\tvalid_1's rmse: 0.0906703\n",
      "[175]\ttraining's rmse: 0.0936581\tvalid_1's rmse: 0.0906373\n",
      "[200]\ttraining's rmse: 0.0935468\tvalid_1's rmse: 0.0906047\n",
      "[225]\ttraining's rmse: 0.0934385\tvalid_1's rmse: 0.0905717\n",
      "[250]\ttraining's rmse: 0.0933454\tvalid_1's rmse: 0.0905439\n",
      "[275]\ttraining's rmse: 0.0932592\tvalid_1's rmse: 0.0905178\n",
      "[300]\ttraining's rmse: 0.0931736\tvalid_1's rmse: 0.0904924\n",
      "[325]\ttraining's rmse: 0.0930861\tvalid_1's rmse: 0.0904704\n",
      "[350]\ttraining's rmse: 0.0930025\tvalid_1's rmse: 0.0904474\n",
      "[375]\ttraining's rmse: 0.0929343\tvalid_1's rmse: 0.0904359\n",
      "[400]\ttraining's rmse: 0.09286\tvalid_1's rmse: 0.0904234\n",
      "[425]\ttraining's rmse: 0.0927884\tvalid_1's rmse: 0.0904129\n",
      "[450]\ttraining's rmse: 0.0927259\tvalid_1's rmse: 0.0904012\n",
      "[475]\ttraining's rmse: 0.0926647\tvalid_1's rmse: 0.0903862\n",
      "[500]\ttraining's rmse: 0.0926132\tvalid_1's rmse: 0.0903779\n",
      "[525]\ttraining's rmse: 0.0925481\tvalid_1's rmse: 0.0903653\n",
      "[550]\ttraining's rmse: 0.0924893\tvalid_1's rmse: 0.0903527\n",
      "[575]\ttraining's rmse: 0.0924352\tvalid_1's rmse: 0.0903418\n",
      "[600]\ttraining's rmse: 0.0923822\tvalid_1's rmse: 0.0903316\n",
      "[625]\ttraining's rmse: 0.0923362\tvalid_1's rmse: 0.0903269\n",
      "[650]\ttraining's rmse: 0.092282\tvalid_1's rmse: 0.0903171\n",
      "[675]\ttraining's rmse: 0.0922285\tvalid_1's rmse: 0.0903203\n",
      "[700]\ttraining's rmse: 0.092179\tvalid_1's rmse: 0.0903171\n",
      "[725]\ttraining's rmse: 0.0921348\tvalid_1's rmse: 0.0903177\n",
      "[750]\ttraining's rmse: 0.0920923\tvalid_1's rmse: 0.0903148\n",
      "[775]\ttraining's rmse: 0.0920557\tvalid_1's rmse: 0.0903085\n",
      "[800]\ttraining's rmse: 0.0920118\tvalid_1's rmse: 0.0903022\n",
      "[825]\ttraining's rmse: 0.0919721\tvalid_1's rmse: 0.0902967\n",
      "[850]\ttraining's rmse: 0.091933\tvalid_1's rmse: 0.090292\n",
      "[875]\ttraining's rmse: 0.0918994\tvalid_1's rmse: 0.0902937\n",
      "[900]\ttraining's rmse: 0.0918614\tvalid_1's rmse: 0.0902887\n",
      "[925]\ttraining's rmse: 0.0918258\tvalid_1's rmse: 0.0902915\n",
      "[950]\ttraining's rmse: 0.0917939\tvalid_1's rmse: 0.0902958\n",
      "Early stopping, best iteration is:\n",
      "[918]\ttraining's rmse: 0.0918375\tvalid_1's rmse: 0.090285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0935568\tvalid_1's rmse: 0.0955468\n",
      "[50]\ttraining's rmse: 0.0933555\tvalid_1's rmse: 0.09549\n",
      "[75]\ttraining's rmse: 0.093158\tvalid_1's rmse: 0.0954345\n",
      "[100]\ttraining's rmse: 0.0929748\tvalid_1's rmse: 0.0953858\n",
      "[125]\ttraining's rmse: 0.0927928\tvalid_1's rmse: 0.0953395\n",
      "[150]\ttraining's rmse: 0.0926244\tvalid_1's rmse: 0.095294\n",
      "[175]\ttraining's rmse: 0.0924813\tvalid_1's rmse: 0.0952548\n",
      "[200]\ttraining's rmse: 0.0923334\tvalid_1's rmse: 0.0952158\n",
      "[225]\ttraining's rmse: 0.0921923\tvalid_1's rmse: 0.0951777\n",
      "[250]\ttraining's rmse: 0.0920723\tvalid_1's rmse: 0.0951447\n",
      "[275]\ttraining's rmse: 0.091956\tvalid_1's rmse: 0.0951145\n",
      "[300]\ttraining's rmse: 0.0918433\tvalid_1's rmse: 0.0950828\n",
      "[325]\ttraining's rmse: 0.0917304\tvalid_1's rmse: 0.0950538\n",
      "[350]\ttraining's rmse: 0.0916273\tvalid_1's rmse: 0.0950276\n",
      "[375]\ttraining's rmse: 0.0915351\tvalid_1's rmse: 0.0950053\n",
      "[400]\ttraining's rmse: 0.0914423\tvalid_1's rmse: 0.0949829\n",
      "[425]\ttraining's rmse: 0.091356\tvalid_1's rmse: 0.0949605\n",
      "[450]\ttraining's rmse: 0.0912764\tvalid_1's rmse: 0.0949394\n",
      "[475]\ttraining's rmse: 0.0912047\tvalid_1's rmse: 0.0949185\n",
      "[500]\ttraining's rmse: 0.091141\tvalid_1's rmse: 0.0949008\n",
      "[525]\ttraining's rmse: 0.091066\tvalid_1's rmse: 0.0948829\n",
      "[550]\ttraining's rmse: 0.0909995\tvalid_1's rmse: 0.0948655\n",
      "[575]\ttraining's rmse: 0.0909354\tvalid_1's rmse: 0.0948499\n",
      "[600]\ttraining's rmse: 0.0908747\tvalid_1's rmse: 0.0948357\n",
      "[625]\ttraining's rmse: 0.0908228\tvalid_1's rmse: 0.0948229\n",
      "[650]\ttraining's rmse: 0.0907643\tvalid_1's rmse: 0.0948101\n",
      "[675]\ttraining's rmse: 0.0907046\tvalid_1's rmse: 0.0947951\n",
      "[700]\ttraining's rmse: 0.0906574\tvalid_1's rmse: 0.0947824\n",
      "[725]\ttraining's rmse: 0.0906137\tvalid_1's rmse: 0.0947713\n",
      "[750]\ttraining's rmse: 0.0905697\tvalid_1's rmse: 0.0947625\n",
      "[775]\ttraining's rmse: 0.0905311\tvalid_1's rmse: 0.0947506\n",
      "[800]\ttraining's rmse: 0.0904844\tvalid_1's rmse: 0.09474\n",
      "[825]\ttraining's rmse: 0.090445\tvalid_1's rmse: 0.0947303\n",
      "[850]\ttraining's rmse: 0.0904069\tvalid_1's rmse: 0.0947217\n",
      "[875]\ttraining's rmse: 0.0903691\tvalid_1's rmse: 0.0947136\n",
      "[900]\ttraining's rmse: 0.0903295\tvalid_1's rmse: 0.0947057\n",
      "[925]\ttraining's rmse: 0.0902944\tvalid_1's rmse: 0.094698\n",
      "[950]\ttraining's rmse: 0.0902628\tvalid_1's rmse: 0.0946906\n",
      "[975]\ttraining's rmse: 0.0902318\tvalid_1's rmse: 0.094684\n",
      "[1000]\ttraining's rmse: 0.0902023\tvalid_1's rmse: 0.0946781\n",
      "[1025]\ttraining's rmse: 0.0901709\tvalid_1's rmse: 0.0946713\n",
      "[1050]\ttraining's rmse: 0.090144\tvalid_1's rmse: 0.094663\n",
      "[1075]\ttraining's rmse: 0.0901188\tvalid_1's rmse: 0.0946577\n",
      "[1100]\ttraining's rmse: 0.0900983\tvalid_1's rmse: 0.0946532\n",
      "[1125]\ttraining's rmse: 0.0900756\tvalid_1's rmse: 0.0946466\n",
      "[1150]\ttraining's rmse: 0.090051\tvalid_1's rmse: 0.0946413\n",
      "[1175]\ttraining's rmse: 0.090029\tvalid_1's rmse: 0.0946377\n",
      "[1200]\ttraining's rmse: 0.0900082\tvalid_1's rmse: 0.0946334\n",
      "[1225]\ttraining's rmse: 0.0899891\tvalid_1's rmse: 0.0946284\n",
      "[1250]\ttraining's rmse: 0.0899696\tvalid_1's rmse: 0.0946224\n",
      "[1275]\ttraining's rmse: 0.0899434\tvalid_1's rmse: 0.0946181\n",
      "[1300]\ttraining's rmse: 0.0899279\tvalid_1's rmse: 0.0946135\n",
      "[1325]\ttraining's rmse: 0.0899102\tvalid_1's rmse: 0.0946099\n",
      "[1350]\ttraining's rmse: 0.0898932\tvalid_1's rmse: 0.0946068\n",
      "[1375]\ttraining's rmse: 0.0898779\tvalid_1's rmse: 0.0946049\n",
      "[1400]\ttraining's rmse: 0.089864\tvalid_1's rmse: 0.0946023\n",
      "[1425]\ttraining's rmse: 0.0898491\tvalid_1's rmse: 0.0945999\n",
      "[1450]\ttraining's rmse: 0.089832\tvalid_1's rmse: 0.0945974\n",
      "[1475]\ttraining's rmse: 0.0898195\tvalid_1's rmse: 0.094593\n",
      "[1500]\ttraining's rmse: 0.0898089\tvalid_1's rmse: 0.0945902\n",
      "[1525]\ttraining's rmse: 0.0897963\tvalid_1's rmse: 0.0945871\n",
      "[1550]\ttraining's rmse: 0.0897838\tvalid_1's rmse: 0.0945859\n",
      "[1575]\ttraining's rmse: 0.0897757\tvalid_1's rmse: 0.0945839\n",
      "[1600]\ttraining's rmse: 0.0897663\tvalid_1's rmse: 0.0945807\n",
      "[1625]\ttraining's rmse: 0.0897556\tvalid_1's rmse: 0.0945771\n",
      "[1650]\ttraining's rmse: 0.0897472\tvalid_1's rmse: 0.0945748\n",
      "[1675]\ttraining's rmse: 0.0897391\tvalid_1's rmse: 0.0945727\n",
      "[1700]\ttraining's rmse: 0.0897296\tvalid_1's rmse: 0.0945706\n",
      "[1725]\ttraining's rmse: 0.0897222\tvalid_1's rmse: 0.0945685\n",
      "[1750]\ttraining's rmse: 0.0897133\tvalid_1's rmse: 0.0945671\n",
      "[1775]\ttraining's rmse: 0.0897025\tvalid_1's rmse: 0.094565\n",
      "[1800]\ttraining's rmse: 0.0896935\tvalid_1's rmse: 0.0945642\n",
      "[1825]\ttraining's rmse: 0.0896871\tvalid_1's rmse: 0.0945618\n",
      "[1850]\ttraining's rmse: 0.0896811\tvalid_1's rmse: 0.0945594\n",
      "[1875]\ttraining's rmse: 0.0896722\tvalid_1's rmse: 0.0945574\n",
      "[1900]\ttraining's rmse: 0.0896647\tvalid_1's rmse: 0.0945559\n",
      "[1925]\ttraining's rmse: 0.0896581\tvalid_1's rmse: 0.0945544\n",
      "[1950]\ttraining's rmse: 0.0896531\tvalid_1's rmse: 0.0945533\n",
      "[1975]\ttraining's rmse: 0.0896465\tvalid_1's rmse: 0.0945515\n",
      "[2000]\ttraining's rmse: 0.0896408\tvalid_1's rmse: 0.0945503\n",
      "[2025]\ttraining's rmse: 0.0896361\tvalid_1's rmse: 0.0945491\n",
      "[2050]\ttraining's rmse: 0.0896314\tvalid_1's rmse: 0.094548\n",
      "[2075]\ttraining's rmse: 0.0896267\tvalid_1's rmse: 0.0945477\n",
      "[2100]\ttraining's rmse: 0.0896227\tvalid_1's rmse: 0.0945471\n",
      "[2125]\ttraining's rmse: 0.0896185\tvalid_1's rmse: 0.0945464\n",
      "[2150]\ttraining's rmse: 0.0896132\tvalid_1's rmse: 0.0945447\n",
      "[2175]\ttraining's rmse: 0.0896089\tvalid_1's rmse: 0.0945428\n",
      "[2200]\ttraining's rmse: 0.0896056\tvalid_1's rmse: 0.0945417\n",
      "[2225]\ttraining's rmse: 0.0896011\tvalid_1's rmse: 0.0945401\n",
      "[2250]\ttraining's rmse: 0.0895975\tvalid_1's rmse: 0.0945397\n",
      "[2275]\ttraining's rmse: 0.0895946\tvalid_1's rmse: 0.0945397\n",
      "[2300]\ttraining's rmse: 0.0895902\tvalid_1's rmse: 0.0945392\n",
      "[2325]\ttraining's rmse: 0.0895869\tvalid_1's rmse: 0.0945384\n",
      "[2350]\ttraining's rmse: 0.089583\tvalid_1's rmse: 0.0945369\n",
      "[2375]\ttraining's rmse: 0.0895788\tvalid_1's rmse: 0.0945363\n",
      "[2400]\ttraining's rmse: 0.0895753\tvalid_1's rmse: 0.0945364\n",
      "[2425]\ttraining's rmse: 0.0895732\tvalid_1's rmse: 0.0945363\n",
      "Early stopping, best iteration is:\n",
      "[2383]\ttraining's rmse: 0.0895776\tvalid_1's rmse: 0.0945358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0935943\tvalid_1's rmse: 0.0954939\n",
      "[50]\ttraining's rmse: 0.0934096\tvalid_1's rmse: 0.0954368\n",
      "[75]\ttraining's rmse: 0.0932201\tvalid_1's rmse: 0.09538\n",
      "[100]\ttraining's rmse: 0.093053\tvalid_1's rmse: 0.0953288\n",
      "[125]\ttraining's rmse: 0.0928806\tvalid_1's rmse: 0.0952787\n",
      "[150]\ttraining's rmse: 0.0927262\tvalid_1's rmse: 0.0952305\n",
      "[175]\ttraining's rmse: 0.092593\tvalid_1's rmse: 0.0951937\n",
      "[200]\ttraining's rmse: 0.0924584\tvalid_1's rmse: 0.0951546\n",
      "[225]\ttraining's rmse: 0.0923304\tvalid_1's rmse: 0.0951192\n",
      "[250]\ttraining's rmse: 0.0922189\tvalid_1's rmse: 0.0950868\n",
      "[275]\ttraining's rmse: 0.0921164\tvalid_1's rmse: 0.095058\n",
      "[300]\ttraining's rmse: 0.0920146\tvalid_1's rmse: 0.0950311\n",
      "[325]\ttraining's rmse: 0.0919134\tvalid_1's rmse: 0.0950029\n",
      "[350]\ttraining's rmse: 0.0918172\tvalid_1's rmse: 0.0949775\n",
      "[375]\ttraining's rmse: 0.0917372\tvalid_1's rmse: 0.0949575\n",
      "[400]\ttraining's rmse: 0.0916527\tvalid_1's rmse: 0.0949364\n",
      "[425]\ttraining's rmse: 0.0915746\tvalid_1's rmse: 0.0949158\n",
      "[450]\ttraining's rmse: 0.0915036\tvalid_1's rmse: 0.0948979\n",
      "[475]\ttraining's rmse: 0.0914361\tvalid_1's rmse: 0.0948808\n",
      "[500]\ttraining's rmse: 0.091378\tvalid_1's rmse: 0.0948648\n",
      "[525]\ttraining's rmse: 0.0913049\tvalid_1's rmse: 0.0948467\n",
      "[550]\ttraining's rmse: 0.0912377\tvalid_1's rmse: 0.0948305\n",
      "[575]\ttraining's rmse: 0.091177\tvalid_1's rmse: 0.0948156\n",
      "[600]\ttraining's rmse: 0.0911187\tvalid_1's rmse: 0.0948034\n",
      "[625]\ttraining's rmse: 0.0910656\tvalid_1's rmse: 0.0947904\n",
      "[650]\ttraining's rmse: 0.0910094\tvalid_1's rmse: 0.0947789\n",
      "[675]\ttraining's rmse: 0.0909564\tvalid_1's rmse: 0.0947683\n",
      "[700]\ttraining's rmse: 0.0909064\tvalid_1's rmse: 0.0947574\n",
      "[725]\ttraining's rmse: 0.0908624\tvalid_1's rmse: 0.0947477\n",
      "[750]\ttraining's rmse: 0.0908207\tvalid_1's rmse: 0.0947378\n",
      "[775]\ttraining's rmse: 0.0907842\tvalid_1's rmse: 0.0947289\n",
      "[800]\ttraining's rmse: 0.0907394\tvalid_1's rmse: 0.09472\n",
      "[825]\ttraining's rmse: 0.0907033\tvalid_1's rmse: 0.094712\n",
      "[850]\ttraining's rmse: 0.0906641\tvalid_1's rmse: 0.0947056\n",
      "[875]\ttraining's rmse: 0.0906295\tvalid_1's rmse: 0.0946981\n",
      "[900]\ttraining's rmse: 0.0905918\tvalid_1's rmse: 0.0946911\n",
      "[925]\ttraining's rmse: 0.0905573\tvalid_1's rmse: 0.0946851\n",
      "[950]\ttraining's rmse: 0.090526\tvalid_1's rmse: 0.09468\n",
      "[975]\ttraining's rmse: 0.0904966\tvalid_1's rmse: 0.0946749\n",
      "[1000]\ttraining's rmse: 0.0904679\tvalid_1's rmse: 0.0946706\n",
      "[1025]\ttraining's rmse: 0.0904341\tvalid_1's rmse: 0.0946672\n",
      "[1050]\ttraining's rmse: 0.0904067\tvalid_1's rmse: 0.0946622\n",
      "[1075]\ttraining's rmse: 0.0903779\tvalid_1's rmse: 0.0946594\n",
      "[1100]\ttraining's rmse: 0.0903558\tvalid_1's rmse: 0.0946561\n",
      "[1125]\ttraining's rmse: 0.0903319\tvalid_1's rmse: 0.0946525\n",
      "[1150]\ttraining's rmse: 0.090309\tvalid_1's rmse: 0.0946501\n",
      "[1175]\ttraining's rmse: 0.0902868\tvalid_1's rmse: 0.0946485\n",
      "[1200]\ttraining's rmse: 0.0902646\tvalid_1's rmse: 0.0946454\n",
      "[1225]\ttraining's rmse: 0.0902446\tvalid_1's rmse: 0.0946441\n",
      "[1250]\ttraining's rmse: 0.0902275\tvalid_1's rmse: 0.0946425\n",
      "[1275]\ttraining's rmse: 0.090206\tvalid_1's rmse: 0.0946404\n",
      "[1300]\ttraining's rmse: 0.0901889\tvalid_1's rmse: 0.0946381\n",
      "[1325]\ttraining's rmse: 0.090169\tvalid_1's rmse: 0.0946367\n",
      "[1350]\ttraining's rmse: 0.0901518\tvalid_1's rmse: 0.0946354\n",
      "[1375]\ttraining's rmse: 0.0901331\tvalid_1's rmse: 0.0946335\n",
      "[1400]\ttraining's rmse: 0.0901181\tvalid_1's rmse: 0.0946313\n",
      "[1425]\ttraining's rmse: 0.0901\tvalid_1's rmse: 0.0946307\n",
      "[1450]\ttraining's rmse: 0.0900821\tvalid_1's rmse: 0.0946295\n",
      "[1475]\ttraining's rmse: 0.0900702\tvalid_1's rmse: 0.0946285\n",
      "[1500]\ttraining's rmse: 0.0900579\tvalid_1's rmse: 0.0946278\n",
      "[1525]\ttraining's rmse: 0.0900408\tvalid_1's rmse: 0.0946268\n",
      "[1550]\ttraining's rmse: 0.0900257\tvalid_1's rmse: 0.0946266\n",
      "[1575]\ttraining's rmse: 0.0900144\tvalid_1's rmse: 0.0946255\n",
      "[1600]\ttraining's rmse: 0.0900037\tvalid_1's rmse: 0.0946245\n",
      "[1625]\ttraining's rmse: 0.0899935\tvalid_1's rmse: 0.0946241\n",
      "[1650]\ttraining's rmse: 0.089982\tvalid_1's rmse: 0.0946236\n",
      "[1675]\ttraining's rmse: 0.0899728\tvalid_1's rmse: 0.0946228\n",
      "[1700]\ttraining's rmse: 0.0899625\tvalid_1's rmse: 0.0946223\n",
      "[1725]\ttraining's rmse: 0.0899532\tvalid_1's rmse: 0.0946218\n",
      "[1750]\ttraining's rmse: 0.0899424\tvalid_1's rmse: 0.0946208\n",
      "[1775]\ttraining's rmse: 0.0899317\tvalid_1's rmse: 0.0946199\n",
      "[1800]\ttraining's rmse: 0.0899233\tvalid_1's rmse: 0.0946195\n",
      "[1825]\ttraining's rmse: 0.0899149\tvalid_1's rmse: 0.0946188\n",
      "[1850]\ttraining's rmse: 0.0899072\tvalid_1's rmse: 0.0946182\n",
      "[1875]\ttraining's rmse: 0.089899\tvalid_1's rmse: 0.0946184\n",
      "[1900]\ttraining's rmse: 0.0898936\tvalid_1's rmse: 0.0946184\n",
      "[1925]\ttraining's rmse: 0.0898875\tvalid_1's rmse: 0.094618\n",
      "[1950]\ttraining's rmse: 0.0898818\tvalid_1's rmse: 0.0946175\n",
      "[1975]\ttraining's rmse: 0.0898763\tvalid_1's rmse: 0.0946173\n",
      "[2000]\ttraining's rmse: 0.0898698\tvalid_1's rmse: 0.0946167\n",
      "[2025]\ttraining's rmse: 0.0898643\tvalid_1's rmse: 0.0946167\n",
      "[2050]\ttraining's rmse: 0.0898595\tvalid_1's rmse: 0.0946165\n",
      "Early stopping, best iteration is:\n",
      "[2009]\ttraining's rmse: 0.0898683\tvalid_1's rmse: 0.0946164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0953655\tvalid_1's rmse: 0.0919856\n",
      "[50]\ttraining's rmse: 0.0952257\tvalid_1's rmse: 0.0919355\n",
      "[75]\ttraining's rmse: 0.0950731\tvalid_1's rmse: 0.0918823\n",
      "[100]\ttraining's rmse: 0.0949375\tvalid_1's rmse: 0.0918383\n",
      "[125]\ttraining's rmse: 0.094801\tvalid_1's rmse: 0.0917941\n",
      "[150]\ttraining's rmse: 0.0946701\tvalid_1's rmse: 0.0917531\n",
      "[175]\ttraining's rmse: 0.094562\tvalid_1's rmse: 0.0917207\n",
      "[200]\ttraining's rmse: 0.0944435\tvalid_1's rmse: 0.091688\n",
      "[225]\ttraining's rmse: 0.0943318\tvalid_1's rmse: 0.0916545\n",
      "[250]\ttraining's rmse: 0.0942343\tvalid_1's rmse: 0.0916272\n",
      "[275]\ttraining's rmse: 0.094146\tvalid_1's rmse: 0.0916014\n",
      "[300]\ttraining's rmse: 0.0940581\tvalid_1's rmse: 0.0915776\n",
      "[325]\ttraining's rmse: 0.0939662\tvalid_1's rmse: 0.0915527\n",
      "[350]\ttraining's rmse: 0.0938809\tvalid_1's rmse: 0.0915294\n",
      "[375]\ttraining's rmse: 0.0938107\tvalid_1's rmse: 0.0915111\n",
      "[400]\ttraining's rmse: 0.0937354\tvalid_1's rmse: 0.0914922\n",
      "[425]\ttraining's rmse: 0.093665\tvalid_1's rmse: 0.091475\n",
      "[450]\ttraining's rmse: 0.0935989\tvalid_1's rmse: 0.091465\n",
      "[475]\ttraining's rmse: 0.0935349\tvalid_1's rmse: 0.0914493\n",
      "[500]\ttraining's rmse: 0.0934816\tvalid_1's rmse: 0.0914365\n",
      "[525]\ttraining's rmse: 0.0934113\tvalid_1's rmse: 0.0914233\n",
      "[550]\ttraining's rmse: 0.0933476\tvalid_1's rmse: 0.0914088\n",
      "[575]\ttraining's rmse: 0.0932884\tvalid_1's rmse: 0.0913993\n",
      "[600]\ttraining's rmse: 0.0932334\tvalid_1's rmse: 0.0913901\n",
      "[625]\ttraining's rmse: 0.0931897\tvalid_1's rmse: 0.0913851\n",
      "[650]\ttraining's rmse: 0.0931298\tvalid_1's rmse: 0.0913833\n",
      "[675]\ttraining's rmse: 0.0930709\tvalid_1's rmse: 0.09138\n",
      "[700]\ttraining's rmse: 0.0930229\tvalid_1's rmse: 0.0913725\n",
      "[725]\ttraining's rmse: 0.092978\tvalid_1's rmse: 0.0913724\n",
      "[750]\ttraining's rmse: 0.0929352\tvalid_1's rmse: 0.0913669\n",
      "[775]\ttraining's rmse: 0.0928969\tvalid_1's rmse: 0.0913609\n",
      "[800]\ttraining's rmse: 0.0928493\tvalid_1's rmse: 0.0913563\n",
      "[825]\ttraining's rmse: 0.0928128\tvalid_1's rmse: 0.0913526\n",
      "[850]\ttraining's rmse: 0.0927727\tvalid_1's rmse: 0.0913529\n",
      "[875]\ttraining's rmse: 0.0927376\tvalid_1's rmse: 0.0913514\n",
      "[900]\ttraining's rmse: 0.0926986\tvalid_1's rmse: 0.0913536\n",
      "Early stopping, best iteration is:\n",
      "[872]\ttraining's rmse: 0.0927396\tvalid_1's rmse: 0.0913478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0931804\tvalid_1's rmse: 0.0951409\n",
      "[50]\ttraining's rmse: 0.0929787\tvalid_1's rmse: 0.0950835\n",
      "[75]\ttraining's rmse: 0.092784\tvalid_1's rmse: 0.0950266\n",
      "[100]\ttraining's rmse: 0.0926086\tvalid_1's rmse: 0.094976\n",
      "[125]\ttraining's rmse: 0.0924307\tvalid_1's rmse: 0.0949262\n",
      "[150]\ttraining's rmse: 0.0922664\tvalid_1's rmse: 0.0948784\n",
      "[175]\ttraining's rmse: 0.0921256\tvalid_1's rmse: 0.0948402\n",
      "[200]\ttraining's rmse: 0.0919841\tvalid_1's rmse: 0.0948026\n",
      "[225]\ttraining's rmse: 0.0918448\tvalid_1's rmse: 0.0947639\n",
      "[250]\ttraining's rmse: 0.0917253\tvalid_1's rmse: 0.0947294\n",
      "[275]\ttraining's rmse: 0.0916133\tvalid_1's rmse: 0.0946997\n",
      "[300]\ttraining's rmse: 0.0914995\tvalid_1's rmse: 0.094671\n",
      "[325]\ttraining's rmse: 0.0913945\tvalid_1's rmse: 0.0946419\n",
      "[350]\ttraining's rmse: 0.0912855\tvalid_1's rmse: 0.094613\n",
      "[375]\ttraining's rmse: 0.0911965\tvalid_1's rmse: 0.0945895\n",
      "[400]\ttraining's rmse: 0.091103\tvalid_1's rmse: 0.0945648\n",
      "[425]\ttraining's rmse: 0.0910166\tvalid_1's rmse: 0.0945414\n",
      "[450]\ttraining's rmse: 0.0909388\tvalid_1's rmse: 0.0945212\n",
      "[475]\ttraining's rmse: 0.0908651\tvalid_1's rmse: 0.094499\n",
      "[500]\ttraining's rmse: 0.0908008\tvalid_1's rmse: 0.0944804\n",
      "[525]\ttraining's rmse: 0.0907252\tvalid_1's rmse: 0.0944609\n",
      "[550]\ttraining's rmse: 0.090659\tvalid_1's rmse: 0.0944449\n",
      "[575]\ttraining's rmse: 0.0905941\tvalid_1's rmse: 0.0944311\n",
      "[600]\ttraining's rmse: 0.0905317\tvalid_1's rmse: 0.0944152\n",
      "[625]\ttraining's rmse: 0.0904834\tvalid_1's rmse: 0.0944013\n",
      "[650]\ttraining's rmse: 0.0904239\tvalid_1's rmse: 0.0943893\n",
      "[675]\ttraining's rmse: 0.0903643\tvalid_1's rmse: 0.0943749\n",
      "[700]\ttraining's rmse: 0.0903141\tvalid_1's rmse: 0.0943635\n",
      "[725]\ttraining's rmse: 0.0902691\tvalid_1's rmse: 0.0943524\n",
      "[750]\ttraining's rmse: 0.0902226\tvalid_1's rmse: 0.0943425\n",
      "[775]\ttraining's rmse: 0.0901848\tvalid_1's rmse: 0.0943326\n",
      "[800]\ttraining's rmse: 0.0901367\tvalid_1's rmse: 0.0943221\n",
      "[825]\ttraining's rmse: 0.0901008\tvalid_1's rmse: 0.0943107\n",
      "[850]\ttraining's rmse: 0.0900601\tvalid_1's rmse: 0.0943042\n",
      "[875]\ttraining's rmse: 0.0900282\tvalid_1's rmse: 0.0942956\n",
      "[900]\ttraining's rmse: 0.0899916\tvalid_1's rmse: 0.0942854\n",
      "[925]\ttraining's rmse: 0.0899581\tvalid_1's rmse: 0.0942776\n",
      "[950]\ttraining's rmse: 0.0899249\tvalid_1's rmse: 0.0942691\n",
      "[975]\ttraining's rmse: 0.0898957\tvalid_1's rmse: 0.0942624\n",
      "[1000]\ttraining's rmse: 0.0898642\tvalid_1's rmse: 0.0942561\n",
      "[1025]\ttraining's rmse: 0.0898336\tvalid_1's rmse: 0.0942503\n",
      "[1050]\ttraining's rmse: 0.0898102\tvalid_1's rmse: 0.0942422\n",
      "[1075]\ttraining's rmse: 0.0897853\tvalid_1's rmse: 0.0942374\n",
      "[1100]\ttraining's rmse: 0.0897629\tvalid_1's rmse: 0.094232\n",
      "[1125]\ttraining's rmse: 0.0897388\tvalid_1's rmse: 0.0942269\n",
      "[1150]\ttraining's rmse: 0.0897171\tvalid_1's rmse: 0.0942226\n",
      "[1175]\ttraining's rmse: 0.0896932\tvalid_1's rmse: 0.0942189\n",
      "[1200]\ttraining's rmse: 0.0896714\tvalid_1's rmse: 0.0942122\n",
      "[1225]\ttraining's rmse: 0.0896519\tvalid_1's rmse: 0.0942067\n",
      "[1250]\ttraining's rmse: 0.0896345\tvalid_1's rmse: 0.0942026\n",
      "[1275]\ttraining's rmse: 0.0896141\tvalid_1's rmse: 0.0941979\n",
      "[1300]\ttraining's rmse: 0.0895996\tvalid_1's rmse: 0.0941935\n",
      "[1325]\ttraining's rmse: 0.0895828\tvalid_1's rmse: 0.0941895\n",
      "[1350]\ttraining's rmse: 0.089567\tvalid_1's rmse: 0.0941864\n",
      "[1375]\ttraining's rmse: 0.0895497\tvalid_1's rmse: 0.0941837\n",
      "[1400]\ttraining's rmse: 0.0895363\tvalid_1's rmse: 0.0941804\n",
      "[1425]\ttraining's rmse: 0.0895182\tvalid_1's rmse: 0.094177\n",
      "[1450]\ttraining's rmse: 0.0895004\tvalid_1's rmse: 0.0941748\n",
      "[1475]\ttraining's rmse: 0.0894867\tvalid_1's rmse: 0.0941712\n",
      "[1500]\ttraining's rmse: 0.089474\tvalid_1's rmse: 0.0941692\n",
      "[1525]\ttraining's rmse: 0.0894625\tvalid_1's rmse: 0.0941664\n",
      "[1550]\ttraining's rmse: 0.0894511\tvalid_1's rmse: 0.094165\n",
      "[1575]\ttraining's rmse: 0.0894404\tvalid_1's rmse: 0.0941621\n",
      "[1600]\ttraining's rmse: 0.0894301\tvalid_1's rmse: 0.0941604\n",
      "[1625]\ttraining's rmse: 0.0894196\tvalid_1's rmse: 0.0941575\n",
      "[1650]\ttraining's rmse: 0.0894104\tvalid_1's rmse: 0.094156\n",
      "[1675]\ttraining's rmse: 0.0894025\tvalid_1's rmse: 0.0941539\n",
      "[1700]\ttraining's rmse: 0.0893933\tvalid_1's rmse: 0.094153\n",
      "[1725]\ttraining's rmse: 0.0893828\tvalid_1's rmse: 0.0941504\n",
      "[1750]\ttraining's rmse: 0.0893743\tvalid_1's rmse: 0.0941473\n",
      "[1775]\ttraining's rmse: 0.0893652\tvalid_1's rmse: 0.0941462\n",
      "[1800]\ttraining's rmse: 0.0893576\tvalid_1's rmse: 0.0941452\n",
      "[1825]\ttraining's rmse: 0.0893509\tvalid_1's rmse: 0.0941437\n",
      "[1850]\ttraining's rmse: 0.0893453\tvalid_1's rmse: 0.094141\n",
      "[1875]\ttraining's rmse: 0.0893403\tvalid_1's rmse: 0.0941396\n",
      "[1900]\ttraining's rmse: 0.0893347\tvalid_1's rmse: 0.0941387\n",
      "[1925]\ttraining's rmse: 0.0893257\tvalid_1's rmse: 0.0941364\n",
      "[1950]\ttraining's rmse: 0.0893202\tvalid_1's rmse: 0.0941345\n",
      "[1975]\ttraining's rmse: 0.0893147\tvalid_1's rmse: 0.0941323\n",
      "[2000]\ttraining's rmse: 0.0893076\tvalid_1's rmse: 0.0941317\n",
      "[2025]\ttraining's rmse: 0.0893041\tvalid_1's rmse: 0.094131\n",
      "[2050]\ttraining's rmse: 0.0892989\tvalid_1's rmse: 0.0941287\n",
      "[2075]\ttraining's rmse: 0.0892948\tvalid_1's rmse: 0.0941265\n",
      "[2100]\ttraining's rmse: 0.0892909\tvalid_1's rmse: 0.0941249\n",
      "[2125]\ttraining's rmse: 0.0892862\tvalid_1's rmse: 0.0941231\n",
      "[2150]\ttraining's rmse: 0.0892819\tvalid_1's rmse: 0.0941227\n",
      "[2175]\ttraining's rmse: 0.0892777\tvalid_1's rmse: 0.0941219\n",
      "[2200]\ttraining's rmse: 0.089272\tvalid_1's rmse: 0.0941209\n",
      "[2225]\ttraining's rmse: 0.0892686\tvalid_1's rmse: 0.0941198\n",
      "[2250]\ttraining's rmse: 0.0892656\tvalid_1's rmse: 0.0941185\n",
      "[2275]\ttraining's rmse: 0.0892625\tvalid_1's rmse: 0.0941174\n",
      "[2300]\ttraining's rmse: 0.089259\tvalid_1's rmse: 0.0941165\n",
      "[2325]\ttraining's rmse: 0.089256\tvalid_1's rmse: 0.0941149\n",
      "[2350]\ttraining's rmse: 0.0892518\tvalid_1's rmse: 0.0941136\n",
      "[2375]\ttraining's rmse: 0.0892474\tvalid_1's rmse: 0.0941136\n",
      "[2400]\ttraining's rmse: 0.0892425\tvalid_1's rmse: 0.094113\n",
      "[2425]\ttraining's rmse: 0.0892402\tvalid_1's rmse: 0.0941122\n",
      "[2450]\ttraining's rmse: 0.0892368\tvalid_1's rmse: 0.0941112\n",
      "[2475]\ttraining's rmse: 0.0892335\tvalid_1's rmse: 0.0941112\n",
      "[2500]\ttraining's rmse: 0.0892317\tvalid_1's rmse: 0.0941099\n",
      "[2525]\ttraining's rmse: 0.0892276\tvalid_1's rmse: 0.0941084\n",
      "[2550]\ttraining's rmse: 0.0892248\tvalid_1's rmse: 0.0941081\n",
      "[2575]\ttraining's rmse: 0.0892224\tvalid_1's rmse: 0.0941077\n",
      "[2600]\ttraining's rmse: 0.0892197\tvalid_1's rmse: 0.094107\n",
      "[2625]\ttraining's rmse: 0.0892172\tvalid_1's rmse: 0.0941061\n",
      "[2650]\ttraining's rmse: 0.0892159\tvalid_1's rmse: 0.0941062\n",
      "[2675]\ttraining's rmse: 0.0892134\tvalid_1's rmse: 0.0941056\n",
      "[2700]\ttraining's rmse: 0.0892099\tvalid_1's rmse: 0.0941047\n",
      "[2725]\ttraining's rmse: 0.0892073\tvalid_1's rmse: 0.0941044\n",
      "[2750]\ttraining's rmse: 0.0892051\tvalid_1's rmse: 0.0941039\n",
      "[2775]\ttraining's rmse: 0.0892033\tvalid_1's rmse: 0.0941042\n",
      "Early stopping, best iteration is:\n",
      "[2742]\ttraining's rmse: 0.0892057\tvalid_1's rmse: 0.0941037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0931086\tvalid_1's rmse: 0.0952906\n",
      "[50]\ttraining's rmse: 0.0929298\tvalid_1's rmse: 0.0952336\n",
      "[75]\ttraining's rmse: 0.0927518\tvalid_1's rmse: 0.095176\n",
      "[100]\ttraining's rmse: 0.0925892\tvalid_1's rmse: 0.0951253\n",
      "[125]\ttraining's rmse: 0.0924215\tvalid_1's rmse: 0.0950754\n",
      "[150]\ttraining's rmse: 0.0922733\tvalid_1's rmse: 0.0950288\n",
      "[175]\ttraining's rmse: 0.0921467\tvalid_1's rmse: 0.0949899\n",
      "[200]\ttraining's rmse: 0.0920115\tvalid_1's rmse: 0.0949524\n",
      "[225]\ttraining's rmse: 0.0918869\tvalid_1's rmse: 0.0949163\n",
      "[250]\ttraining's rmse: 0.0917762\tvalid_1's rmse: 0.0948825\n",
      "[275]\ttraining's rmse: 0.0916721\tvalid_1's rmse: 0.0948518\n",
      "[300]\ttraining's rmse: 0.0915701\tvalid_1's rmse: 0.094823\n",
      "[325]\ttraining's rmse: 0.0914699\tvalid_1's rmse: 0.0947964\n",
      "[350]\ttraining's rmse: 0.0913756\tvalid_1's rmse: 0.0947723\n",
      "[375]\ttraining's rmse: 0.0912997\tvalid_1's rmse: 0.0947511\n",
      "[400]\ttraining's rmse: 0.0912149\tvalid_1's rmse: 0.0947293\n",
      "[425]\ttraining's rmse: 0.0911376\tvalid_1's rmse: 0.0947092\n",
      "[450]\ttraining's rmse: 0.0910649\tvalid_1's rmse: 0.0946898\n",
      "[475]\ttraining's rmse: 0.0909969\tvalid_1's rmse: 0.0946717\n",
      "[500]\ttraining's rmse: 0.0909393\tvalid_1's rmse: 0.0946535\n",
      "[525]\ttraining's rmse: 0.090869\tvalid_1's rmse: 0.0946361\n",
      "[550]\ttraining's rmse: 0.0908032\tvalid_1's rmse: 0.0946218\n",
      "[575]\ttraining's rmse: 0.0907408\tvalid_1's rmse: 0.0946075\n",
      "[600]\ttraining's rmse: 0.0906825\tvalid_1's rmse: 0.0945939\n",
      "[625]\ttraining's rmse: 0.0906372\tvalid_1's rmse: 0.0945813\n",
      "[650]\ttraining's rmse: 0.0905816\tvalid_1's rmse: 0.0945688\n",
      "[675]\ttraining's rmse: 0.090528\tvalid_1's rmse: 0.0945561\n",
      "[700]\ttraining's rmse: 0.090478\tvalid_1's rmse: 0.0945446\n",
      "[725]\ttraining's rmse: 0.0904345\tvalid_1's rmse: 0.0945351\n",
      "[750]\ttraining's rmse: 0.0903951\tvalid_1's rmse: 0.0945261\n",
      "[775]\ttraining's rmse: 0.090359\tvalid_1's rmse: 0.0945171\n",
      "[800]\ttraining's rmse: 0.0903141\tvalid_1's rmse: 0.0945087\n",
      "[825]\ttraining's rmse: 0.0902777\tvalid_1's rmse: 0.0945002\n",
      "[850]\ttraining's rmse: 0.0902423\tvalid_1's rmse: 0.0944931\n",
      "[875]\ttraining's rmse: 0.0902073\tvalid_1's rmse: 0.0944861\n",
      "[900]\ttraining's rmse: 0.0901707\tvalid_1's rmse: 0.0944798\n",
      "[925]\ttraining's rmse: 0.0901381\tvalid_1's rmse: 0.0944743\n",
      "[950]\ttraining's rmse: 0.0901072\tvalid_1's rmse: 0.0944692\n",
      "[975]\ttraining's rmse: 0.0900789\tvalid_1's rmse: 0.0944634\n",
      "[1000]\ttraining's rmse: 0.0900507\tvalid_1's rmse: 0.0944586\n",
      "[1025]\ttraining's rmse: 0.0900165\tvalid_1's rmse: 0.0944545\n",
      "[1050]\ttraining's rmse: 0.0899898\tvalid_1's rmse: 0.0944504\n",
      "[1075]\ttraining's rmse: 0.0899646\tvalid_1's rmse: 0.0944475\n",
      "[1100]\ttraining's rmse: 0.0899418\tvalid_1's rmse: 0.0944429\n",
      "[1125]\ttraining's rmse: 0.0899169\tvalid_1's rmse: 0.0944393\n",
      "[1150]\ttraining's rmse: 0.0898914\tvalid_1's rmse: 0.0944357\n",
      "[1175]\ttraining's rmse: 0.0898697\tvalid_1's rmse: 0.0944327\n",
      "[1200]\ttraining's rmse: 0.0898482\tvalid_1's rmse: 0.0944296\n",
      "[1225]\ttraining's rmse: 0.0898273\tvalid_1's rmse: 0.0944274\n",
      "[1250]\ttraining's rmse: 0.089811\tvalid_1's rmse: 0.0944253\n",
      "[1275]\ttraining's rmse: 0.0897887\tvalid_1's rmse: 0.0944233\n",
      "[1300]\ttraining's rmse: 0.089772\tvalid_1's rmse: 0.0944201\n",
      "[1325]\ttraining's rmse: 0.0897562\tvalid_1's rmse: 0.094418\n",
      "[1350]\ttraining's rmse: 0.0897379\tvalid_1's rmse: 0.0944166\n",
      "[1375]\ttraining's rmse: 0.089718\tvalid_1's rmse: 0.0944152\n",
      "[1400]\ttraining's rmse: 0.0897038\tvalid_1's rmse: 0.0944132\n",
      "[1425]\ttraining's rmse: 0.0896855\tvalid_1's rmse: 0.0944116\n",
      "[1450]\ttraining's rmse: 0.0896676\tvalid_1's rmse: 0.0944093\n",
      "[1475]\ttraining's rmse: 0.0896549\tvalid_1's rmse: 0.0944075\n",
      "[1500]\ttraining's rmse: 0.0896405\tvalid_1's rmse: 0.094406\n",
      "[1525]\ttraining's rmse: 0.0896244\tvalid_1's rmse: 0.0944051\n",
      "[1550]\ttraining's rmse: 0.0896132\tvalid_1's rmse: 0.0944043\n",
      "[1575]\ttraining's rmse: 0.0896026\tvalid_1's rmse: 0.0944036\n",
      "[1600]\ttraining's rmse: 0.0895926\tvalid_1's rmse: 0.094403\n",
      "[1625]\ttraining's rmse: 0.0895814\tvalid_1's rmse: 0.0944018\n",
      "[1650]\ttraining's rmse: 0.0895721\tvalid_1's rmse: 0.0944016\n",
      "[1675]\ttraining's rmse: 0.0895641\tvalid_1's rmse: 0.0944004\n",
      "[1700]\ttraining's rmse: 0.089555\tvalid_1's rmse: 0.0943992\n",
      "[1725]\ttraining's rmse: 0.0895462\tvalid_1's rmse: 0.0943986\n",
      "[1750]\ttraining's rmse: 0.0895333\tvalid_1's rmse: 0.0943983\n",
      "[1775]\ttraining's rmse: 0.0895236\tvalid_1's rmse: 0.0943986\n",
      "[1800]\ttraining's rmse: 0.089516\tvalid_1's rmse: 0.094398\n",
      "[1825]\ttraining's rmse: 0.0895074\tvalid_1's rmse: 0.094397\n",
      "[1850]\ttraining's rmse: 0.0895009\tvalid_1's rmse: 0.094397\n",
      "[1875]\ttraining's rmse: 0.0894941\tvalid_1's rmse: 0.0943966\n",
      "[1900]\ttraining's rmse: 0.0894869\tvalid_1's rmse: 0.0943968\n",
      "[1925]\ttraining's rmse: 0.0894821\tvalid_1's rmse: 0.0943969\n",
      "[1950]\ttraining's rmse: 0.089476\tvalid_1's rmse: 0.094396\n",
      "[1975]\ttraining's rmse: 0.0894709\tvalid_1's rmse: 0.0943956\n",
      "[2000]\ttraining's rmse: 0.0894649\tvalid_1's rmse: 0.0943948\n",
      "[2025]\ttraining's rmse: 0.0894603\tvalid_1's rmse: 0.0943943\n",
      "[2050]\ttraining's rmse: 0.0894557\tvalid_1's rmse: 0.0943941\n",
      "[2075]\ttraining's rmse: 0.0894516\tvalid_1's rmse: 0.0943935\n",
      "[2100]\ttraining's rmse: 0.0894476\tvalid_1's rmse: 0.0943936\n",
      "Early stopping, best iteration is:\n",
      "[2071]\ttraining's rmse: 0.0894523\tvalid_1's rmse: 0.0943933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.0950586\tvalid_1's rmse: 0.0914166\n",
      "[50]\ttraining's rmse: 0.0949146\tvalid_1's rmse: 0.091372\n",
      "[75]\ttraining's rmse: 0.0947639\tvalid_1's rmse: 0.0913203\n",
      "[100]\ttraining's rmse: 0.0946293\tvalid_1's rmse: 0.0912747\n",
      "[125]\ttraining's rmse: 0.0944912\tvalid_1's rmse: 0.0912311\n",
      "[150]\ttraining's rmse: 0.0943644\tvalid_1's rmse: 0.0911933\n",
      "[175]\ttraining's rmse: 0.0942604\tvalid_1's rmse: 0.0911612\n",
      "[200]\ttraining's rmse: 0.0941414\tvalid_1's rmse: 0.0911285\n",
      "[225]\ttraining's rmse: 0.0940305\tvalid_1's rmse: 0.0910968\n",
      "[250]\ttraining's rmse: 0.0939347\tvalid_1's rmse: 0.091071\n",
      "[275]\ttraining's rmse: 0.0938452\tvalid_1's rmse: 0.0910471\n",
      "[300]\ttraining's rmse: 0.0937566\tvalid_1's rmse: 0.0910229\n",
      "[325]\ttraining's rmse: 0.093666\tvalid_1's rmse: 0.0910011\n",
      "[350]\ttraining's rmse: 0.0935794\tvalid_1's rmse: 0.0909778\n",
      "[375]\ttraining's rmse: 0.0935077\tvalid_1's rmse: 0.0909591\n",
      "[400]\ttraining's rmse: 0.0934308\tvalid_1's rmse: 0.0909399\n",
      "[425]\ttraining's rmse: 0.0933567\tvalid_1's rmse: 0.0909291\n",
      "[450]\ttraining's rmse: 0.0932888\tvalid_1's rmse: 0.0909176\n",
      "[475]\ttraining's rmse: 0.0932259\tvalid_1's rmse: 0.0909057\n",
      "[500]\ttraining's rmse: 0.0931739\tvalid_1's rmse: 0.0908927\n",
      "[525]\ttraining's rmse: 0.0931041\tvalid_1's rmse: 0.0908773\n",
      "[550]\ttraining's rmse: 0.0930405\tvalid_1's rmse: 0.0908654\n",
      "[575]\ttraining's rmse: 0.0929837\tvalid_1's rmse: 0.0908553\n",
      "[600]\ttraining's rmse: 0.0929257\tvalid_1's rmse: 0.0908512\n",
      "[625]\ttraining's rmse: 0.09288\tvalid_1's rmse: 0.0908473\n",
      "[650]\ttraining's rmse: 0.0928239\tvalid_1's rmse: 0.0908378\n",
      "[675]\ttraining's rmse: 0.0927677\tvalid_1's rmse: 0.0908311\n",
      "[700]\ttraining's rmse: 0.0927162\tvalid_1's rmse: 0.090832\n",
      "[725]\ttraining's rmse: 0.0926711\tvalid_1's rmse: 0.0908359\n",
      "Early stopping, best iteration is:\n",
      "[684]\ttraining's rmse: 0.0927481\tvalid_1's rmse: 0.0908276\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import json\n",
    "outlier_lists = [0.33, 0.35, 0.38, 0.4, 0.42, 0.44, 0.46, 0.48, 0.5, 0.52,0.54, 0.56, 0.58, 0.6]\n",
    "outlier_dict = {str([10, 10]): check_rmse([50,50])}\n",
    "for i in outlier_lists:\n",
    "    outlier_dict[str([i,i])] = check_rmse([i,i])\n",
    "for i in combinations(outlier_lists, 2):\n",
    "    outlier_dict[str(list(i))] = check_rmse(list(i))\n",
    "    j = [i[1], i[0]]\n",
    "    outlier_dict[str(list(j))] = check_rmse(list(j))\n",
    "outlier_df = pd.DataFrame.from_dict(outlier_dict, orient = 'index')\n",
    "outlier_df = outlier_df.reset_index().rename(columns = {'index': 'outlier_list', 0: 'rmse'})\n",
    "outlier_df.outlier_list = outlier_df.outlier_list.apply(json.loads)\n",
    "outlier_df.to_csv('./output/plot_csv/outlier_strategy.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "temp_df = pd.read_csv('./output/plot_csv/outlier_strategy.csv')\n",
    "temp_df.outlier_list = temp_df.outlier_list.apply(json.loads)\n",
    "temp_df['first'] = temp_df.outlier_list.apply(lambda x: x[0])\n",
    "temp_df['second'] = temp_df.outlier_list.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ningzesun/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "temp_df['shape'] = 0\n",
    "\n",
    "for i in temp_df.index:\n",
    "    df = df_merge.loc[df_merge.logerror >= - (temp_df['first'][i]),:]\n",
    "    df = df.loc[df.logerror <= temp_df['second'][i],:]\n",
    "    temp_df['shape'][i] = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier_list</th>\n",
       "      <th>rmse</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>0.163689</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>183639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.33, 0.33]</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>178365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.35, 0.35]</td>\n",
       "      <td>0.076437</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>178875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.38, 0.38]</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>179459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.4, 0.4]</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>179803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>[0.58, 0.56]</td>\n",
       "      <td>0.092131</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>181497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[0.56, 0.6]</td>\n",
       "      <td>0.093247</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>181615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[0.6, 0.56]</td>\n",
       "      <td>0.092505</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "      <td>181533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[0.58, 0.6]</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>181643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[0.6, 0.58]</td>\n",
       "      <td>0.093108</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>181600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlier_list      rmse  first  second   shape\n",
       "0        [10, 10]  0.163689  10.00   10.00  183639\n",
       "1    [0.33, 0.33]  0.074418   0.33    0.33  178365\n",
       "2    [0.35, 0.35]  0.076437   0.35    0.35  178875\n",
       "3    [0.38, 0.38]  0.079000   0.38    0.38  179459\n",
       "4      [0.4, 0.4]  0.080700   0.40    0.40  179803\n",
       "..            ...       ...    ...     ...     ...\n",
       "192  [0.58, 0.56]  0.092131   0.58    0.56  181497\n",
       "193   [0.56, 0.6]  0.093247   0.56    0.60  181615\n",
       "194   [0.6, 0.56]  0.092505   0.60    0.56  181533\n",
       "195   [0.58, 0.6]  0.093500   0.58    0.60  181643\n",
       "196   [0.6, 0.58]  0.093108   0.60    0.58  181600\n",
       "\n",
       "[197 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "remove_df = temp_df.loc[temp_df['first'] < 5,:]\n",
    "sns.scatterplot(x='shape', y='rmse', data=temp_df)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier_list</th>\n",
       "      <th>rmse</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.33, 0.33]</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>178365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.35, 0.33]</td>\n",
       "      <td>0.075134</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.33</td>\n",
       "      <td>178537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.33, 0.35]</td>\n",
       "      <td>0.075731</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.35</td>\n",
       "      <td>178703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.38, 0.33]</td>\n",
       "      <td>0.076160</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>178750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.4, 0.33]</td>\n",
       "      <td>0.076793</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.33</td>\n",
       "      <td>178869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[0.6, 0.58]</td>\n",
       "      <td>0.093108</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>181600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[0.56, 0.6]</td>\n",
       "      <td>0.093247</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>181615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[0.58, 0.6]</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>181643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.6, 0.6]</td>\n",
       "      <td>0.093869</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>181679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>0.163689</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>183639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlier_list      rmse  first  second   shape\n",
       "1    [0.33, 0.33]  0.074418   0.33    0.33  178365\n",
       "16   [0.35, 0.33]  0.075134   0.35    0.33  178537\n",
       "15   [0.33, 0.35]  0.075731   0.33    0.35  178703\n",
       "18   [0.38, 0.33]  0.076160   0.38    0.33  178750\n",
       "20    [0.4, 0.33]  0.076793   0.40    0.33  178869\n",
       "..            ...       ...    ...     ...     ...\n",
       "196   [0.6, 0.58]  0.093108   0.60    0.58  181600\n",
       "193   [0.56, 0.6]  0.093247   0.56    0.60  181615\n",
       "195   [0.58, 0.6]  0.093500   0.58    0.60  181643\n",
       "14     [0.6, 0.6]  0.093869   0.60    0.60  181679\n",
       "0        [10, 10]  0.163689  10.00   10.00  183639\n",
       "\n",
       "[197 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.sort_values('shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989326885901143"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "181679/183639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_ValueRatio</th>\n",
       "      <th>N_life</th>\n",
       "      <th>N_zip_count</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingqualitytypeid_fill</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>finishedfloor1squarefeet</th>\n",
       "      <th>...</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>threequarterbathnbr</th>\n",
       "      <th>unitcnt_fill</th>\n",
       "      <th>yardbuildingsqft17</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>logerror</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.470371</td>\n",
       "      <td>59.0</td>\n",
       "      <td>14719.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>122754.0</td>\n",
       "      <td>6735.879883</td>\n",
       "      <td>0</td>\n",
       "      <td>360170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.670425</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17682.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>346458.0</td>\n",
       "      <td>10153.019531</td>\n",
       "      <td>0</td>\n",
       "      <td>585529.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.168400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.440699</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4422.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>61994.0</td>\n",
       "      <td>11484.480469</td>\n",
       "      <td>0</td>\n",
       "      <td>119906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.321709</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7293.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>171518.0</td>\n",
       "      <td>3048.739990</td>\n",
       "      <td>0</td>\n",
       "      <td>244880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.168182</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9875.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169574.0</td>\n",
       "      <td>5488.959961</td>\n",
       "      <td>0</td>\n",
       "      <td>434551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183634</th>\n",
       "      <td>60.682812</td>\n",
       "      <td>54.0</td>\n",
       "      <td>17169.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50683.0</td>\n",
       "      <td>1107.479980</td>\n",
       "      <td>0</td>\n",
       "      <td>67205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183635</th>\n",
       "      <td>60.682812</td>\n",
       "      <td>54.0</td>\n",
       "      <td>17169.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50683.0</td>\n",
       "      <td>1107.479980</td>\n",
       "      <td>0</td>\n",
       "      <td>67205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183636</th>\n",
       "      <td>60.682812</td>\n",
       "      <td>54.0</td>\n",
       "      <td>17169.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50683.0</td>\n",
       "      <td>1107.479980</td>\n",
       "      <td>0</td>\n",
       "      <td>67205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183637</th>\n",
       "      <td>56.531612</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5666.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32797.0</td>\n",
       "      <td>876.429993</td>\n",
       "      <td>0</td>\n",
       "      <td>49546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183638</th>\n",
       "      <td>82.632202</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6235.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>6317.149902</td>\n",
       "      <td>0</td>\n",
       "      <td>522000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183639 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        N_ValueRatio  N_life  N_zip_count  airconditioningtypeid  \\\n",
       "0          53.470371    59.0      14719.0                      0   \n",
       "1          57.670425     4.0      17682.0                      7   \n",
       "2          10.440699    78.0       4422.0                      0   \n",
       "3          80.321709    31.0       7293.0                      0   \n",
       "4          79.168182    37.0       9875.0                      7   \n",
       "...              ...     ...          ...                    ...   \n",
       "183634     60.682812    54.0      17169.0                      7   \n",
       "183635     60.682812    54.0      17169.0                      7   \n",
       "183636     60.682812    54.0      17169.0                      7   \n",
       "183637     56.531612    64.0       5666.0                      0   \n",
       "183638     82.632202    63.0       6235.0                      7   \n",
       "\n",
       "        basementsqft  bedroomcnt  buildingqualitytypeid_fill  \\\n",
       "0                0.0         3.0                           7   \n",
       "1                0.0         4.0                           0   \n",
       "2                0.0         2.0                           7   \n",
       "3                0.0         2.0                           7   \n",
       "4                0.0         4.0                           7   \n",
       "...              ...         ...                         ...   \n",
       "183634           0.0         4.0                           0   \n",
       "183635           0.0         4.0                           0   \n",
       "183636           0.0         4.0                           0   \n",
       "183637           0.0         3.0                           7   \n",
       "183638           0.0         3.0                           9   \n",
       "\n",
       "        calculatedbathnbr  calculatedfinishedsquarefeet  \\\n",
       "0                     2.0                        1684.0   \n",
       "1                     3.5                        2263.0   \n",
       "2                     3.0                        2217.0   \n",
       "3                     2.0                         839.0   \n",
       "4                     2.5                        2283.0   \n",
       "...                   ...                           ...   \n",
       "183634                2.0                        1612.0   \n",
       "183635                2.0                        1612.0   \n",
       "183636                2.0                        1612.0   \n",
       "183637                1.0                        1032.0   \n",
       "183638                2.0                        1762.0   \n",
       "\n",
       "        finishedfloor1squarefeet  ...  structuretaxvaluedollarcnt  \\\n",
       "0                            NaN  ...                    122754.0   \n",
       "1                            NaN  ...                    346458.0   \n",
       "2                            NaN  ...                     61994.0   \n",
       "3                            NaN  ...                    171518.0   \n",
       "4                            NaN  ...                    169574.0   \n",
       "...                          ...  ...                         ...   \n",
       "183634                    1612.0  ...                     50683.0   \n",
       "183635                    1612.0  ...                     50683.0   \n",
       "183636                    1612.0  ...                     50683.0   \n",
       "183637                       NaN  ...                     32797.0   \n",
       "183638                       NaN  ...                    140000.0   \n",
       "\n",
       "           taxamount  taxdelinquencyflag  taxvaluedollarcnt  \\\n",
       "0        6735.879883                   0           360170.0   \n",
       "1       10153.019531                   0           585529.0   \n",
       "2       11484.480469                   0           119906.0   \n",
       "3        3048.739990                   0           244880.0   \n",
       "4        5488.959961                   0           434551.0   \n",
       "...              ...                 ...                ...   \n",
       "183634   1107.479980                   0            67205.0   \n",
       "183635   1107.479980                   0            67205.0   \n",
       "183636   1107.479980                   0            67205.0   \n",
       "183637    876.429993                   0            49546.0   \n",
       "183638   6317.149902                   0           522000.0   \n",
       "\n",
       "        threequarterbathnbr  unitcnt_fill  yardbuildingsqft17  month  year  \\\n",
       "0                       0.0           1.0                 NaN      1     0   \n",
       "1                       1.0           4.0                 NaN      1     0   \n",
       "2                       0.0           1.0                 NaN      1     0   \n",
       "3                       0.0           1.0                 NaN      1     0   \n",
       "4                       1.0           2.0                 NaN      1     0   \n",
       "...                     ...           ...                 ...    ...   ...   \n",
       "183634                  0.0           2.0               656.0      9     1   \n",
       "183635                  0.0           2.0               656.0      9     1   \n",
       "183636                  0.0           2.0               656.0      9     1   \n",
       "183637                  0.0           1.0                 NaN      9     1   \n",
       "183638                  0.0           1.0                 NaN      9     1   \n",
       "\n",
       "        logerror  \n",
       "0       0.027600  \n",
       "1      -0.168400  \n",
       "2      -0.004000  \n",
       "3       0.021800  \n",
       "4      -0.005000  \n",
       "...          ...  \n",
       "183634  0.013209  \n",
       "183635  0.013209  \n",
       "183636  0.013209  \n",
       "183637  0.037129  \n",
       "183638  0.007204  \n",
       "\n",
       "[183639 rows x 47 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6,0.6 0.4, 0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
